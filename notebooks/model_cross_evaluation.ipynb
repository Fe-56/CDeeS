{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Cross-Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torcheval.metrics import R2Score\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import math\n",
    "\n",
    "import sys\n",
    "sys.path.insert(1, '../utils')\n",
    "from paths import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the feed-forward neural network used for all featuresets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(1, '../models')\n",
    "from feedforward_nn import NeuralNetwork"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define neural network parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model Testing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(trained_model, input_test_data, target_test_labels):\n",
    "  input_test_data = input_test_data.float()\n",
    "  target_test_labels = target_test_labels.float()\n",
    "  \n",
    "  with torch.no_grad():\n",
    "    test_pred = trained_model(input_test_data)\n",
    "    test_loss = criterion(test_pred.float(), target_test_labels)\n",
    "\n",
    "    # Separate the output into valence and arousal\n",
    "    valence_pred = test_pred[:, 0]\n",
    "    arousal_pred = test_pred[:, 1]\n",
    "        \n",
    "    valence_target = target_test_labels[:, 0]\n",
    "    arousal_target = target_test_labels[:, 1]\n",
    "\n",
    "     # Calculate RMSE for valence and arousal separately\n",
    "    valence_rmse = math.sqrt(mean_squared_error(valence_pred, valence_target))\n",
    "    arousal_rmse = math.sqrt(mean_squared_error(arousal_pred, arousal_target))\n",
    "\n",
    "  rmse = math.sqrt(test_loss.item())\n",
    "  print(f'Test RMSE: {round(rmse, 4)}')\n",
    "\n",
    "  print(f'Valence RMSE: {round(valence_rmse, 4)}')\n",
    "  print(f'Arousal RMSE: {round(arousal_rmse, 4)}')\n",
    "\n",
    "  metric = R2Score(multioutput=\"raw_values\")\n",
    "  metric.update(test_pred, target_test_labels)\n",
    "  r2_score = metric.compute()\n",
    "  print(f'Test R^2 score: {r2_score}')\n",
    "\n",
    "  num_of_test_samples = input_test_data.shape[0]\n",
    "  num_of_test_features = input_test_data.shape[1] \n",
    "\n",
    "  if num_of_test_features < num_of_test_samples:\n",
    "    metric = R2Score(multioutput=\"raw_values\", num_regressors=input_test_data.shape[1])\n",
    "    metric.update(test_pred, target_test_labels)\n",
    "    adjusted_r2_score = metric.compute()\n",
    "    print(f'Test Adjusted R^2 score: {adjusted_r2_score}')\n",
    "\n",
    "  metric = R2Score()\n",
    "  metric.update(test_pred, target_test_labels)\n",
    "  r2_score = metric.compute()\n",
    "  print(f'Test R^2 score (overall): {r2_score}')\n",
    "  return test_pred, rmse, adjusted_r2_score, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load static annotations for DEAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>valence_mean_mapped</th>\n",
       "      <th>arousal_mean_mapped</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.475</td>\n",
       "      <td>-0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.375</td>\n",
       "      <td>-0.425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.175</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.150</td>\n",
       "      <td>0.075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.200</td>\n",
       "      <td>0.350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1739</th>\n",
       "      <td>-0.275</td>\n",
       "      <td>0.225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1740</th>\n",
       "      <td>0.075</td>\n",
       "      <td>-0.275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1741</th>\n",
       "      <td>0.350</td>\n",
       "      <td>0.300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1742</th>\n",
       "      <td>-0.100</td>\n",
       "      <td>0.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1743</th>\n",
       "      <td>0.200</td>\n",
       "      <td>0.250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1744 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      valence_mean_mapped  arousal_mean_mapped\n",
       "0                  -0.475               -0.500\n",
       "1                  -0.375               -0.425\n",
       "2                   0.175                0.125\n",
       "3                  -0.150                0.075\n",
       "4                   0.200                0.350\n",
       "...                   ...                  ...\n",
       "1739               -0.275                0.225\n",
       "1740                0.075               -0.275\n",
       "1741                0.350                0.300\n",
       "1742               -0.100                0.100\n",
       "1743                0.200                0.250\n",
       "\n",
       "[1744 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_deam_annotations = pd.read_csv('../data/DEAM/processed/annotations/deam_static_annotations.csv')\n",
    "df_deam_annotations = df_deam_annotations.drop('song_id', axis=1)\n",
    "df_deam_annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load static annotations for PMEmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>valence_mean_mapped</th>\n",
       "      <th>arousal_mean_mapped</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.150</td>\n",
       "      <td>-0.200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.425</td>\n",
       "      <td>-0.475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.600</td>\n",
       "      <td>-0.700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.300</td>\n",
       "      <td>0.025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.450</td>\n",
       "      <td>0.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762</th>\n",
       "      <td>0.525</td>\n",
       "      <td>0.725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>0.125</td>\n",
       "      <td>0.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>0.325</td>\n",
       "      <td>0.425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>0.550</td>\n",
       "      <td>0.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>0.150</td>\n",
       "      <td>0.325</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>767 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     valence_mean_mapped  arousal_mean_mapped\n",
       "0                  0.150               -0.200\n",
       "1                 -0.425               -0.475\n",
       "2                 -0.600               -0.700\n",
       "3                 -0.300                0.025\n",
       "4                  0.450                0.400\n",
       "..                   ...                  ...\n",
       "762                0.525                0.725\n",
       "763                0.125                0.750\n",
       "764                0.325                0.425\n",
       "765                0.550                0.750\n",
       "766                0.150                0.325\n",
       "\n",
       "[767 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pmemo_annotations = pd.read_csv('../data/PMEmo/PMEmo2019/processed/annotations/pmemo_static_annotations.csv')\n",
    "df_pmemo_annotations = df_pmemo_annotations.drop('song_id', axis=1)\n",
    "df_pmemo_annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Function to prepare the annotations, features, and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_annotations_features_model(path_to_feature_set, test_annotations_dataset, path_to_model):\n",
    "  # load the feature set\n",
    "  features = pd.read_csv(path_to_feature_set)\n",
    "\n",
    "  # drop Unnamed:0 column\n",
    "  features = features[features.columns[1:]]\n",
    "\n",
    "  features = features.drop('song_id', axis=1)\n",
    "  \n",
    "  # get the correct annotations\n",
    "  test_annotations_dataset = df_pmemo_annotations if test_annotations_dataset == 'pmemo' else df_deam_annotations\n",
    "\n",
    "  # create tensors for the test features and test annotations\n",
    "  features_tensor = torch.tensor(features.values, dtype=torch.float64)\n",
    "  annotations_tensor = torch.tensor(test_annotations_dataset.values, dtype=torch.float64)\n",
    "\n",
    "  # set the seed\n",
    "  seed = 42 \n",
    "  torch.manual_seed(seed)\n",
    "\n",
    "  # load the model\n",
    "  model = NeuralNetwork(features_tensor.shape[1])\n",
    "  model.load_state_dict(torch.load(path_to_model))\n",
    "  model.eval()\n",
    "\n",
    "  return model, features_tensor, annotations_tensor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inter-Dataset Model Evaluations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature set used in model: <ins>DEAM Essentia Best Overall & openSMILE GeMAPS Normalised</ins>\n",
    "### Feature set tested on: <ins>PMEmo Essentia Best Overall & openSMILE GeMAPS Normalised</ins>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.3015\n",
      "Valence RMSE: 0.2838\n",
      "Arousal RMSE: 0.3182\n",
      "Test R^2 score: tensor([0.2314, 0.2581])\n",
      "Test Adjusted R^2 score: tensor([0.1174, 0.1480])\n",
      "Test R^2 score (overall): 0.2447582483291626\n"
     ]
    }
   ],
   "source": [
    "model, features_tensor, annotations_tensor = prepare_annotations_features_model(\n",
    "  path_to_feature_set='../data/PMEmo/PMEmo2019/processed/features/integrated/normalised_essentia_best_overall_opensmile_gemaps_features.csv',\n",
    "  test_annotations_dataset='pmemo',\n",
    "  path_to_model='../models/deam_feedforward_nn_essentia_best_overall_opensmile_gemaps_normalised.pt'\n",
    ")\n",
    "test_pred, rmse, adjusted_r2_score, r2_score = test_model(model, features_tensor, annotations_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature set used in model: <ins>DEAM Essentia Best Overall & openSMILE eGeMAPS Normalised</ins>\n",
    "### Feature set tested on: <ins>PMEmo Essentia Best Overall & openSMILE eGeMAPS Normalised</ins>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.2849\n",
      "Valence RMSE: 0.2835\n",
      "Arousal RMSE: 0.2863\n",
      "Test R^2 score: tensor([0.2330, 0.3992])\n",
      "Test Adjusted R^2 score: tensor([0.0835, 0.2820])\n",
      "Test R^2 score (overall): 0.3161044418811798\n"
     ]
    }
   ],
   "source": [
    "model, features_tensor, annotations_tensor = prepare_annotations_features_model(\n",
    "  path_to_feature_set='../data/PMEmo/PMEmo2019/processed/features/integrated/normalised_essentia_best_overall_opensmile_egemaps_features.csv',\n",
    "  test_annotations_dataset='pmemo',\n",
    "  path_to_model='../models/deam_feedforward_nn_essentia_best_overall_opensmile_egemaps_normalised.pt'\n",
    ")\n",
    "test_pred, rmse, adjusted_r2_score, r2_score = test_model(model, features_tensor, annotations_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature set used in model: <ins>DEAM Essentia Best Overall Mean Normalised</ins>\n",
    "### Feature set tested on: <ins>PMEmo Essentia Best Overall Mean Normalised</ins>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.3414\n",
      "Valence RMSE: 0.3262\n",
      "Arousal RMSE: 0.3561\n",
      "Test R^2 score: tensor([-0.0149,  0.0708])\n",
      "Test Adjusted R^2 score: tensor([-0.0664,  0.0237])\n",
      "Test R^2 score (overall): 0.027972787618637085\n"
     ]
    }
   ],
   "source": [
    "model, features_tensor, annotations_tensor = prepare_annotations_features_model(\n",
    "  path_to_feature_set='../data/PMEmo/PMEmo2019/processed/features/normalised_essentia_best_overall_features.csv',\n",
    "  test_annotations_dataset='pmemo',\n",
    "  path_to_model='../models/deam_feedforward_nn_essentia_best_overall_mean_normalised.pt'\n",
    ")\n",
    "test_pred, rmse, adjusted_r2_score, r2_score = test_model(model, features_tensor, annotations_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature set used in model: <ins>DEAM Essentia Best Valence Mean Normalised</ins>\n",
    "### Feature set tested on: <ins>PMEmo Essentia Best Valence Mean Normalised</ins>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.2787\n",
      "Valence RMSE: 0.2642\n",
      "Arousal RMSE: 0.2924\n",
      "Test R^2 score: tensor([0.3343, 0.3733])\n",
      "Test Adjusted R^2 score: tensor([0.2715, 0.3142])\n",
      "Test R^2 score (overall): 0.35377374291419983\n"
     ]
    }
   ],
   "source": [
    "model, features_tensor, annotations_tensor = prepare_annotations_features_model(\n",
    "  path_to_feature_set='../data/PMEmo/PMEmo2019/processed/features/normalised_essentia_best_valence_features.csv',\n",
    "  test_annotations_dataset='pmemo',\n",
    "  path_to_model='../models/deam_feedforward_nn_essentia_best_valence_mean_normalised.pt'\n",
    ")\n",
    "test_pred, rmse, adjusted_r2_score, r2_score = test_model(model, features_tensor, annotations_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature set used in model: <ins>DEAM Essentia Best Arousal Mean Normalised</ins>\n",
    "### Feature set tested on: <ins>PMEmo Essentia Best Arousal Mean Normalised</ins>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.289\n",
      "Valence RMSE: 0.2848\n",
      "Arousal RMSE: 0.2931\n",
      "Test R^2 score: tensor([0.2260, 0.3704])\n",
      "Test Adjusted R^2 score: tensor([-0.2833, -0.0438])\n",
      "Test R^2 score (overall): 0.2982364296913147\n"
     ]
    }
   ],
   "source": [
    "model, features_tensor, annotations_tensor = prepare_annotations_features_model(\n",
    "  path_to_feature_set='../data/PMEmo/PMEmo2019/processed/features/normalised_essentia_best_arousal_features.csv',\n",
    "  test_annotations_dataset='pmemo',\n",
    "  path_to_model='../models/deam_feedforward_nn_essentia_best_arousal_mean_normalised.pt'\n",
    ")\n",
    "test_pred, rmse, adjusted_r2_score, r2_score = test_model(model, features_tensor, annotations_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature set used in model: <ins>PMEmo Essentia Best Overall & openSMILE GeMAPS Standardised</ins>\n",
    "### Feature set tested on: <ins>DEAM Essentia Best Overall & openSMILE GeMAPS Standardised</ins>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.3607\n",
      "Valence RMSE: 0.3254\n",
      "Arousal RMSE: 0.3928\n",
      "Test R^2 score: tensor([-0.2302, -0.4862])\n",
      "Test Adjusted R^2 score: tensor([-0.3043, -0.5757])\n",
      "Test R^2 score (overall): -0.3581765294075012\n"
     ]
    }
   ],
   "source": [
    "model, features_tensor, annotations_tensor = prepare_annotations_features_model(\n",
    "  path_to_feature_set='../data/DEAM/processed/features/integrated/standardised_essentia_best_overall_opensmile_gemaps_features.csv',\n",
    "  test_annotations_dataset='deam',\n",
    "  path_to_model='../models/pmemo_feedforward_nn_essentia_best_overall_opensmile_gemaps_standardised.pt'\n",
    ")\n",
    "test_pred, rmse, adjusted_r2_score, r2_score = test_model(model, features_tensor, annotations_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature set used in model: <ins>PMEmo Essentia Best Overall & openSMILE eGeMAPS Standardised</ins>\n",
    "### Feature set tested on: <ins>DEAM Essentia Best Overall & openSMILE eGeMAPS Standardised</ins>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.3747\n",
      "Valence RMSE: 0.3291\n",
      "Arousal RMSE: 0.4152\n",
      "Test R^2 score: tensor([-0.2585, -0.6604])\n",
      "Test Adjusted R^2 score: tensor([-0.3558, -0.7887])\n",
      "Test R^2 score (overall): -0.45946526527404785\n"
     ]
    }
   ],
   "source": [
    "model, features_tensor, annotations_tensor = prepare_annotations_features_model(\n",
    "  path_to_feature_set='../data/DEAM/processed/features/integrated/standardised_essentia_best_overall_opensmile_egemaps_features.csv',\n",
    "  test_annotations_dataset='deam',\n",
    "  path_to_model='../models/pmemo_feedforward_nn_essentia_best_overall_opensmile_egemaps_standardised.pt'\n",
    ")\n",
    "test_pred, rmse, adjusted_r2_score, r2_score = test_model(model, features_tensor, annotations_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature set used in model: <ins>PMEmo Essentia Best Overall Mean Standardised</ins>\n",
    "### Feature set tested on: <ins>DEAM Essentia Best Overall Mean Standardised</ins>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.3956\n",
      "Valence RMSE: 0.3573\n",
      "Arousal RMSE: 0.4305\n",
      "Test R^2 score: tensor([-0.4832, -0.7845])\n",
      "Test Adjusted R^2 score: tensor([-0.5153, -0.8232])\n",
      "Test R^2 score (overall): -0.6338290572166443\n"
     ]
    }
   ],
   "source": [
    "model, features_tensor, annotations_tensor = prepare_annotations_features_model(\n",
    "  path_to_feature_set='../data/DEAM/processed/features/standardised_essentia_best_overall_features.csv',\n",
    "  test_annotations_dataset='deam',\n",
    "  path_to_model='../models/pmemo_feedforward_nn_essentia_best_overall_mean_standardised.pt'\n",
    ")\n",
    "test_pred, rmse, adjusted_r2_score, r2_score = test_model(model, features_tensor, annotations_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature set used in model: <ins>PMEmo Essentia Best Valence Mean Standardised</ins>\n",
    "### Feature set tested on: <ins>DEAM Essentia Best Valence Mean Standardised</ins>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.3601\n",
      "Valence RMSE: 0.3299\n",
      "Arousal RMSE: 0.3879\n",
      "Test R^2 score: tensor([-0.2644, -0.4489])\n",
      "Test Adjusted R^2 score: tensor([-0.3142, -0.5059])\n",
      "Test R^2 score (overall): -0.3566470146179199\n"
     ]
    }
   ],
   "source": [
    "model, features_tensor, annotations_tensor = prepare_annotations_features_model(\n",
    "  path_to_feature_set='../data/DEAM/processed/features/standardised_essentia_best_valence_features.csv',\n",
    "  test_annotations_dataset='deam',\n",
    "  path_to_model='../models/pmemo_feedforward_nn_essentia_best_valence_mean_standardised.pt'\n",
    ")\n",
    "test_pred, rmse, adjusted_r2_score, r2_score = test_model(model, features_tensor, annotations_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature set used in model: <ins>PMEmo Essentia Best Arousal Mean Normalised</ins>\n",
    "### Feature set tested on: <ins>DEAM Essentia Best Arousal Mean Normalised</ins>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.2963\n",
      "Valence RMSE: 0.2626\n",
      "Arousal RMSE: 0.3265\n",
      "Test R^2 score: tensor([ 0.1991, -0.0268])\n",
      "Test Adjusted R^2 score: tensor([ 0.0299, -0.2438])\n",
      "Test R^2 score (overall): 0.08614605665206909\n"
     ]
    }
   ],
   "source": [
    "model, features_tensor, annotations_tensor = prepare_annotations_features_model(\n",
    "  path_to_feature_set='../data/DEAM/processed/features/normalised_essentia_best_arousal_features.csv',\n",
    "  test_annotations_dataset='deam',\n",
    "  path_to_model='../models/pmemo_feedforward_nn_essentia_best_arousal_mean_normalised.pt'\n",
    ")\n",
    "test_pred, rmse, adjusted_r2_score, r2_score = test_model(model, features_tensor, annotations_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
