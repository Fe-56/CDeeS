{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Cross-Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torcheval.metrics import R2Score\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import math\n",
    "\n",
    "import sys\n",
    "sys.path.insert(1, '../utils')\n",
    "from paths import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the feed-forward neural network used for all featuresets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_size, math.ceil((input_size**0.5) * 2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(math.ceil((input_size**0.5) * 2), math.ceil((input_size**0.5) * 2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(math.ceil((input_size**0.5) * 2), math.ceil((input_size**0.5) * 2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(math.ceil((input_size**0.5) * 2), math.ceil((input_size**0.5) * 2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(math.ceil((input_size**0.5) * 2), math.ceil((input_size**0.5) * 2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(math.ceil((input_size**0.5) * 2), math.ceil((input_size**0.5) * 2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(math.ceil((input_size**0.5) * 2), math.ceil((input_size**0.5) * 2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(math.ceil((input_size**0.5) * 2), math.ceil((input_size**0.5) * 2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(math.ceil((input_size**0.5) * 2), math.ceil((input_size**0.5) * 2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(math.ceil((input_size**0.5) * 2), math.ceil((input_size**0.5) * 2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(math.ceil((input_size**0.5) * 2), math.ceil((input_size**0.5) * 2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(math.ceil((input_size**0.5) * 2), 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define neural network parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model Testing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(trained_model, input_test_data, target_test_labels):\n",
    "  input_test_data = input_test_data.float()\n",
    "  target_test_labels = target_test_labels.float()\n",
    "  \n",
    "  with torch.no_grad():\n",
    "    test_pred = trained_model(input_test_data)\n",
    "    test_loss = criterion(test_pred.float(), target_test_labels)\n",
    "\n",
    "    # Separate the output into valence and arousal\n",
    "    valence_pred = test_pred[:, 0]\n",
    "    arousal_pred = test_pred[:, 1]\n",
    "        \n",
    "    valence_target = target_test_labels[:, 0]\n",
    "    arousal_target = target_test_labels[:, 1]\n",
    "\n",
    "     # Calculate RMSE for valence and arousal separately\n",
    "    valence_rmse = math.sqrt(mean_squared_error(valence_pred, valence_target))\n",
    "    arousal_rmse = math.sqrt(mean_squared_error(arousal_pred, arousal_target))\n",
    "\n",
    "  rmse = math.sqrt(test_loss.item())\n",
    "  print(f'Test RMSE: {round(rmse, 4)}')\n",
    "\n",
    "  print(f'Valence RMSE: {round(valence_rmse, 4)}')\n",
    "  print(f'Arousal RMSE: {round(arousal_rmse, 4)}')\n",
    "\n",
    "  metric = R2Score(multioutput=\"raw_values\")\n",
    "  metric.update(test_pred, target_test_labels)\n",
    "  r2_score = metric.compute()\n",
    "  print(f'Test R^2 score: {r2_score}')\n",
    "\n",
    "  num_of_test_samples = input_test_data.shape[0]\n",
    "  num_of_test_features = input_test_data.shape[1] \n",
    "\n",
    "  if num_of_test_features < num_of_test_samples:\n",
    "    metric = R2Score(multioutput=\"raw_values\", num_regressors=input_test_data.shape[1])\n",
    "    metric.update(test_pred, target_test_labels)\n",
    "    adjusted_r2_score = metric.compute()\n",
    "    print(f'Test Adjusted R^2 score: {adjusted_r2_score}')\n",
    "\n",
    "  metric = R2Score()\n",
    "  metric.update(test_pred, target_test_labels)\n",
    "  r2_score = metric.compute()\n",
    "  print(f'Test R^2 score (overall): {r2_score}')\n",
    "  return test_pred, rmse, adjusted_r2_score, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load static annotations for DEAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>valence_mean_mapped</th>\n",
       "      <th>arousal_mean_mapped</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.475</td>\n",
       "      <td>-0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.375</td>\n",
       "      <td>-0.425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.175</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.150</td>\n",
       "      <td>0.075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.200</td>\n",
       "      <td>0.350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1739</th>\n",
       "      <td>-0.275</td>\n",
       "      <td>0.225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1740</th>\n",
       "      <td>0.075</td>\n",
       "      <td>-0.275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1741</th>\n",
       "      <td>0.350</td>\n",
       "      <td>0.300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1742</th>\n",
       "      <td>-0.100</td>\n",
       "      <td>0.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1743</th>\n",
       "      <td>0.200</td>\n",
       "      <td>0.250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1744 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      valence_mean_mapped  arousal_mean_mapped\n",
       "0                  -0.475               -0.500\n",
       "1                  -0.375               -0.425\n",
       "2                   0.175                0.125\n",
       "3                  -0.150                0.075\n",
       "4                   0.200                0.350\n",
       "...                   ...                  ...\n",
       "1739               -0.275                0.225\n",
       "1740                0.075               -0.275\n",
       "1741                0.350                0.300\n",
       "1742               -0.100                0.100\n",
       "1743                0.200                0.250\n",
       "\n",
       "[1744 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_deam_annotations = pd.read_csv('../data/DEAM/processed/annotations/deam_static_annotations.csv')\n",
    "df_deam_annotations = df_deam_annotations.drop('song_id', axis=1)\n",
    "df_deam_annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load static annotations for PMEmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>valence_mean_mapped</th>\n",
       "      <th>arousal_mean_mapped</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.150</td>\n",
       "      <td>-0.200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.425</td>\n",
       "      <td>-0.475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.600</td>\n",
       "      <td>-0.700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.300</td>\n",
       "      <td>0.025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.450</td>\n",
       "      <td>0.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762</th>\n",
       "      <td>0.525</td>\n",
       "      <td>0.725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>0.125</td>\n",
       "      <td>0.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>0.325</td>\n",
       "      <td>0.425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>0.550</td>\n",
       "      <td>0.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>0.150</td>\n",
       "      <td>0.325</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>767 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     valence_mean_mapped  arousal_mean_mapped\n",
       "0                  0.150               -0.200\n",
       "1                 -0.425               -0.475\n",
       "2                 -0.600               -0.700\n",
       "3                 -0.300                0.025\n",
       "4                  0.450                0.400\n",
       "..                   ...                  ...\n",
       "762                0.525                0.725\n",
       "763                0.125                0.750\n",
       "764                0.325                0.425\n",
       "765                0.550                0.750\n",
       "766                0.150                0.325\n",
       "\n",
       "[767 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pmemo_annotations = pd.read_csv('../data/PMEmo/PMEmo2019/processed/annotations/pmemo_static_annotations.csv')\n",
    "df_pmemo_annotations = df_pmemo_annotations.drop('song_id', axis=1)\n",
    "df_pmemo_annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Function to prepare the annotations, features, and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_annotations_features_model(path_to_feature_set, test_annotations_dataset, path_to_model):\n",
    "  # load the feature set\n",
    "  features = pd.read_csv(path_to_feature_set)\n",
    "\n",
    "  # drop Unnamed:0 column\n",
    "  features = features[features.columns[1:]]\n",
    "\n",
    "  features = features.drop('song_id', axis=1)\n",
    "  \n",
    "  # get the correct annotations\n",
    "  test_annotations_dataset = df_pmemo_annotations if test_annotations_dataset == 'pmemo' else df_deam_annotations\n",
    "\n",
    "  # create tensors for the test features and test annotations\n",
    "  features_tensor = torch.tensor(features.values, dtype=torch.float64)\n",
    "  annotations_tensor = torch.tensor(test_annotations_dataset.values, dtype=torch.float64)\n",
    "\n",
    "  # set the seed\n",
    "  seed = 42 \n",
    "  torch.manual_seed(seed)\n",
    "\n",
    "  # load the model\n",
    "  model = NeuralNetwork(features_tensor.shape[1])\n",
    "  model.load_state_dict(torch.load(path_to_model))\n",
    "  model.eval()\n",
    "\n",
    "  return model, features_tensor, annotations_tensor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inter-Dataset Model Evaluations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature set used in model: <ins>DEAM Essentia Best Overall & openSMILE GeMAPS Normalised</ins>\n",
    "### Feature set tested on: <ins>PMEmo Essentia Best Overall & openSMILE GeMAPS Normalised</ins>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.3021\n",
      "Valence RMSE: 0.2929\n",
      "Arousal RMSE: 0.311\n",
      "Test R^2 score: tensor([0.1818, 0.2910])\n",
      "Test Adjusted R^2 score: tensor([0.0603, 0.1858])\n",
      "Test R^2 score (overall): 0.23637059330940247\n"
     ]
    }
   ],
   "source": [
    "model, features_tensor, annotations_tensor = prepare_annotations_features_model(\n",
    "  path_to_feature_set='../data/PMEmo/PMEmo2019/processed/features/integrated/normalised_essentia_best_overall_opensmile_gemaps_features.csv',\n",
    "  test_annotations_dataset='pmemo',\n",
    "  path_to_model='../models/deam_feedforward_nn_essentia_best_overall_opensmile_gemaps_normalised.pt'\n",
    ")\n",
    "test_pred, rmse, adjusted_r2_score, r2_score = test_model(model, features_tensor, annotations_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature set used in model: <ins>DEAM Essentia Best Overall & openSMILE eGeMAPS Normalised</ins>\n",
    "### Feature set tested on: <ins>PMEmo Essentia Best Overall & openSMILE eGeMAPS Normalised</ins>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.2927\n",
      "Valence RMSE: 0.2803\n",
      "Arousal RMSE: 0.3046\n",
      "Test R^2 score: tensor([0.2504, 0.3202])\n",
      "Test Adjusted R^2 score: tensor([0.1042, 0.1876])\n",
      "Test R^2 score (overall): 0.28529879450798035\n"
     ]
    }
   ],
   "source": [
    "model, features_tensor, annotations_tensor = prepare_annotations_features_model(\n",
    "  path_to_feature_set='../data/PMEmo/PMEmo2019/processed/features/integrated/normalised_essentia_best_overall_opensmile_egemaps_features.csv',\n",
    "  test_annotations_dataset='pmemo',\n",
    "  path_to_model='../models/deam_feedforward_nn_essentia_best_overall_opensmile_egemaps_normalised.pt'\n",
    ")\n",
    "test_pred, rmse, adjusted_r2_score, r2_score = test_model(model, features_tensor, annotations_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature set used in model: <ins>DEAM Essentia Best Overall Mean Standardised</ins>\n",
    "### Feature set tested on: <ins>PMEmo Essentia Best Overall Mean Standardised</ins>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.4078\n",
      "Valence RMSE: 0.3881\n",
      "Arousal RMSE: 0.4267\n",
      "Test R^2 score: tensor([-0.4367, -0.3343])\n",
      "Test Adjusted R^2 score: tensor([-0.5096, -0.4020])\n",
      "Test R^2 score (overall): -0.3854754567146301\n"
     ]
    }
   ],
   "source": [
    "model, features_tensor, annotations_tensor = prepare_annotations_features_model(\n",
    "  path_to_feature_set='../data/PMEmo/PMEmo2019/processed/features/standardised_essentia_best_overall_features.csv',\n",
    "  test_annotations_dataset='pmemo',\n",
    "  path_to_model='../models/deam_feedforward_nn_essentia_best_overall_mean_standardised.pt'\n",
    ")\n",
    "test_pred, rmse, adjusted_r2_score, r2_score = test_model(model, features_tensor, annotations_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature set used in model: <ins>DEAM Essentia Best Valence Mean Normalised</ins>\n",
    "### Feature set tested on: <ins>PMEmo Essentia Best Valence Mean Normalised</ins>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.2897\n",
      "Valence RMSE: 0.2743\n",
      "Arousal RMSE: 0.3044\n",
      "Test R^2 score: tensor([0.2822, 0.3209])\n",
      "Test Adjusted R^2 score: tensor([0.2145, 0.2568])\n",
      "Test R^2 score (overall): 0.3015197813510895\n"
     ]
    }
   ],
   "source": [
    "model, features_tensor, annotations_tensor = prepare_annotations_features_model(\n",
    "  path_to_feature_set='../data/PMEmo/PMEmo2019/processed/features/normalised_essentia_best_valence_features.csv',\n",
    "  test_annotations_dataset='pmemo',\n",
    "  path_to_model='../models/deam_feedforward_nn_essentia_best_valence_mean_normalised.pt'\n",
    ")\n",
    "test_pred, rmse, adjusted_r2_score, r2_score = test_model(model, features_tensor, annotations_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature set used in model: <ins>DEAM Essentia Best Arousal Mean Normalised</ins>\n",
    "### Feature set tested on: <ins>PMEmo Essentia Best Arousal Mean Normalised</ins>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.2942\n",
      "Valence RMSE: 0.2902\n",
      "Arousal RMSE: 0.298\n",
      "Test R^2 score: tensor([0.1963, 0.3491])\n",
      "Test Adjusted R^2 score: tensor([-0.3325, -0.0792])\n",
      "Test R^2 score (overall): 0.27270883321762085\n"
     ]
    }
   ],
   "source": [
    "model, features_tensor, annotations_tensor = prepare_annotations_features_model(\n",
    "  path_to_feature_set='../data/PMEmo/PMEmo2019/processed/features/normalised_essentia_best_arousal_features.csv',\n",
    "  test_annotations_dataset='pmemo',\n",
    "  path_to_model='../models/deam_feedforward_nn_essentia_best_arousal_mean_normalised.pt'\n",
    ")\n",
    "test_pred, rmse, adjusted_r2_score, r2_score = test_model(model, features_tensor, annotations_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature set used in model: <ins>PMEmo Essentia Best Overall & openSMILE GeMAPS Normalised</ins>\n",
    "### Feature set tested on: <ins>DEAM Essentia Best Overall & openSMILE GeMAPS Normalised</ins>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.286\n",
      "Valence RMSE: 0.2621\n",
      "Arousal RMSE: 0.3081\n",
      "Test R^2 score: tensor([0.2017, 0.0860])\n",
      "Test Adjusted R^2 score: tensor([0.1536, 0.0310])\n",
      "Test R^2 score (overall): 0.14386922121047974\n"
     ]
    }
   ],
   "source": [
    "model, features_tensor, annotations_tensor = prepare_annotations_features_model(\n",
    "  path_to_feature_set='../data/DEAM/processed/features/integrated/normalised_essentia_best_overall_opensmile_gemaps_features.csv',\n",
    "  test_annotations_dataset='deam',\n",
    "  path_to_model='../models/pmemo_feedforward_nn_essentia_best_overall_opensmile_gemaps_normalised.pt'\n",
    ")\n",
    "test_pred, rmse, adjusted_r2_score, r2_score = test_model(model, features_tensor, annotations_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature set used in model: <ins>PMEmo Essentia Best Overall & openSMILE eGeMAPS Standardised</ins>\n",
    "### Feature set tested on: <ins>DEAM Essentia Best Overall & openSMILE eGeMAPS Standardised</ins>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.3704\n",
      "Valence RMSE: 0.3292\n",
      "Arousal RMSE: 0.4074\n",
      "Test R^2 score: tensor([-0.2590, -0.5984])\n",
      "Test Adjusted R^2 score: tensor([-0.3562, -0.7219])\n",
      "Test R^2 score (overall): -0.428708016872406\n"
     ]
    }
   ],
   "source": [
    "model, features_tensor, annotations_tensor = prepare_annotations_features_model(\n",
    "  path_to_feature_set='../data/DEAM/processed/features/integrated/standardised_essentia_best_overall_opensmile_egemaps_features.csv',\n",
    "  test_annotations_dataset='deam',\n",
    "  path_to_model='../models/pmemo_feedforward_nn_essentia_best_overall_opensmile_egemaps_standardised.pt'\n",
    ")\n",
    "test_pred, rmse, adjusted_r2_score, r2_score = test_model(model, features_tensor, annotations_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature set used in model: <ins>PMEmo Essentia Best Overall Mean Standardised</ins>\n",
    "### Feature set tested on: <ins>DEAM Essentia Best Overall Mean Standardised</ins>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.3927\n",
      "Valence RMSE: 0.343\n",
      "Arousal RMSE: 0.4368\n",
      "Test R^2 score: tensor([-0.3670, -0.8369])\n",
      "Test Adjusted R^2 score: tensor([-0.3966, -0.8768])\n",
      "Test R^2 score (overall): -0.6019524335861206\n"
     ]
    }
   ],
   "source": [
    "model, features_tensor, annotations_tensor = prepare_annotations_features_model(\n",
    "  path_to_feature_set='../data/DEAM/processed/features/standardised_essentia_best_overall_features.csv',\n",
    "  test_annotations_dataset='deam',\n",
    "  path_to_model='../models/pmemo_feedforward_nn_essentia_best_overall_mean_standardised.pt'\n",
    ")\n",
    "test_pred, rmse, adjusted_r2_score, r2_score = test_model(model, features_tensor, annotations_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature set used in model: <ins>PMEmo Essentia Best Valence Mean Standardised</ins>\n",
    "### Feature set tested on: <ins>DEAM Essentia Best Valence Mean Standardised</ins>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.3697\n",
      "Valence RMSE: 0.3285\n",
      "Arousal RMSE: 0.4068\n",
      "Test R^2 score: tensor([-0.2537, -0.5937])\n",
      "Test Adjusted R^2 score: tensor([-0.3031, -0.6564])\n",
      "Test R^2 score (overall): -0.42371445894241333\n"
     ]
    }
   ],
   "source": [
    "model, features_tensor, annotations_tensor = prepare_annotations_features_model(\n",
    "  path_to_feature_set='../data/DEAM/processed/features/standardised_essentia_best_valence_features.csv',\n",
    "  test_annotations_dataset='deam',\n",
    "  path_to_model='../models/pmemo_feedforward_nn_essentia_best_valence_mean_standardised.pt'\n",
    ")\n",
    "test_pred, rmse, adjusted_r2_score, r2_score = test_model(model, features_tensor, annotations_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature set used in model: <ins>PMEmo Essentia Best Arousal Mean Normalised</ins>\n",
    "### Feature set tested on: <ins>DEAM Essentia Best Arousal Mean Normalised</ins>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.29\n",
      "Valence RMSE: 0.2686\n",
      "Arousal RMSE: 0.3099\n",
      "Test R^2 score: tensor([0.1617, 0.0751])\n",
      "Test Adjusted R^2 score: tensor([-0.0154, -0.1203])\n",
      "Test R^2 score (overall): 0.1183919906616211\n"
     ]
    }
   ],
   "source": [
    "model, features_tensor, annotations_tensor = prepare_annotations_features_model(\n",
    "  path_to_feature_set='../data/DEAM/processed/features/normalised_essentia_best_arousal_features.csv',\n",
    "  test_annotations_dataset='deam',\n",
    "  path_to_model='../models/pmemo_feedforward_nn_essentia_best_arousal_mean_normalised.pt'\n",
    ")\n",
    "test_pred, rmse, adjusted_r2_score, r2_score = test_model(model, features_tensor, annotations_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "song_id                115.00\n",
      "valence_mean_mapped      0.85\n",
      "arousal_mean_mapped      0.70\n",
      "Name: 89, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "temp = pd.read_csv('../data/DEAM/processed/annotations/deam_static_annotations.csv')\n",
    "max_valence_row = temp.loc[temp['valence_mean_mapped'].idxmin()]\n",
    "print(max_valence_row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
