{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEAM Dataset - Feed Forward Neural Network\n",
    "## Essentia Best Overall Mean Featureset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torcheval.metrics import R2Score\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import math\n",
    "\n",
    "import sys\n",
    "sys.path.insert(1, '../../utils')\n",
    "from paths import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import annotations dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song_id</th>\n",
       "      <th>valence_mean_mapped</th>\n",
       "      <th>arousal_mean_mapped</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.475</td>\n",
       "      <td>-0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.375</td>\n",
       "      <td>-0.425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>-0.150</td>\n",
       "      <td>0.075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1739</th>\n",
       "      <td>1996</td>\n",
       "      <td>-0.275</td>\n",
       "      <td>0.225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1740</th>\n",
       "      <td>1997</td>\n",
       "      <td>0.075</td>\n",
       "      <td>-0.275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1741</th>\n",
       "      <td>1998</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1742</th>\n",
       "      <td>1999</td>\n",
       "      <td>-0.100</td>\n",
       "      <td>0.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1743</th>\n",
       "      <td>2000</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1744 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      song_id  valence_mean_mapped  arousal_mean_mapped\n",
       "0           2               -0.475               -0.500\n",
       "1           3               -0.375               -0.425\n",
       "2           4                0.175                0.125\n",
       "3           5               -0.150                0.075\n",
       "4           7                0.200                0.350\n",
       "...       ...                  ...                  ...\n",
       "1739     1996               -0.275                0.225\n",
       "1740     1997                0.075               -0.275\n",
       "1741     1998                0.350                0.300\n",
       "1742     1999               -0.100                0.100\n",
       "1743     2000                0.200                0.250\n",
       "\n",
       "[1744 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_annotations = pd.read_csv(get_deam_path('processed/annotations/deam_static_annotations.csv'))\n",
    "df_annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the featureset\n",
    "\n",
    "This is where you should change between normalised and standardised, and untouched featuresets!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song_id</th>\n",
       "      <th>lowlevel.melbands_kurtosis.mean</th>\n",
       "      <th>lowlevel.melbands_skewness.mean</th>\n",
       "      <th>lowlevel.spectral_energy.mean</th>\n",
       "      <th>tonal.chords_strength.mean</th>\n",
       "      <th>tonal.hpcp_entropy.mean</th>\n",
       "      <th>tonal.key_edma.strength</th>\n",
       "      <th>tonal.key_temperley.strength</th>\n",
       "      <th>rhythm.beats_loudness_band_ratio.mean_0</th>\n",
       "      <th>rhythm.beats_loudness_band_ratio.mean_1</th>\n",
       "      <th>...</th>\n",
       "      <th>tonal.chords_histogram_14</th>\n",
       "      <th>tonal.chords_histogram_15</th>\n",
       "      <th>tonal.chords_histogram_16</th>\n",
       "      <th>tonal.chords_histogram_17</th>\n",
       "      <th>tonal.chords_histogram_18</th>\n",
       "      <th>tonal.chords_histogram_19</th>\n",
       "      <th>tonal.chords_histogram_20</th>\n",
       "      <th>tonal.chords_histogram_21</th>\n",
       "      <th>tonal.chords_histogram_22</th>\n",
       "      <th>tonal.chords_histogram_23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.023745</td>\n",
       "      <td>0.224209</td>\n",
       "      <td>0.054855</td>\n",
       "      <td>0.392382</td>\n",
       "      <td>0.631265</td>\n",
       "      <td>0.625832</td>\n",
       "      <td>0.593381</td>\n",
       "      <td>0.579839</td>\n",
       "      <td>0.267674</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023256</td>\n",
       "      <td>0.010375</td>\n",
       "      <td>0.064544</td>\n",
       "      <td>0.026229</td>\n",
       "      <td>0.046262</td>\n",
       "      <td>0.005850</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.083526</td>\n",
       "      <td>0.035887</td>\n",
       "      <td>0.012672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0.082083</td>\n",
       "      <td>0.348482</td>\n",
       "      <td>0.211289</td>\n",
       "      <td>0.402792</td>\n",
       "      <td>0.543954</td>\n",
       "      <td>0.677312</td>\n",
       "      <td>0.677951</td>\n",
       "      <td>0.907102</td>\n",
       "      <td>0.118704</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038179</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023489</td>\n",
       "      <td>0.035942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0.018062</td>\n",
       "      <td>0.213582</td>\n",
       "      <td>0.084731</td>\n",
       "      <td>0.661722</td>\n",
       "      <td>0.554446</td>\n",
       "      <td>0.593904</td>\n",
       "      <td>0.570916</td>\n",
       "      <td>0.686407</td>\n",
       "      <td>0.209877</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001484</td>\n",
       "      <td>0.002937</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.049618</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>0.016018</td>\n",
       "      <td>0.181322</td>\n",
       "      <td>0.041096</td>\n",
       "      <td>0.651524</td>\n",
       "      <td>0.395875</td>\n",
       "      <td>0.900862</td>\n",
       "      <td>0.900318</td>\n",
       "      <td>0.274781</td>\n",
       "      <td>0.429967</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.049780</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.005017</td>\n",
       "      <td>0.127117</td>\n",
       "      <td>0.022199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>0.107675</td>\n",
       "      <td>0.349349</td>\n",
       "      <td>0.197274</td>\n",
       "      <td>0.181959</td>\n",
       "      <td>0.602087</td>\n",
       "      <td>0.450784</td>\n",
       "      <td>0.432106</td>\n",
       "      <td>0.938413</td>\n",
       "      <td>0.080032</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.068694</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.162351</td>\n",
       "      <td>0.18304</td>\n",
       "      <td>0.125289</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1739</th>\n",
       "      <td>1996</td>\n",
       "      <td>0.013781</td>\n",
       "      <td>0.186248</td>\n",
       "      <td>0.077709</td>\n",
       "      <td>0.476088</td>\n",
       "      <td>0.626271</td>\n",
       "      <td>0.772039</td>\n",
       "      <td>0.770549</td>\n",
       "      <td>0.239129</td>\n",
       "      <td>0.649168</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009682</td>\n",
       "      <td>0.021164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1740</th>\n",
       "      <td>1997</td>\n",
       "      <td>0.012825</td>\n",
       "      <td>0.189153</td>\n",
       "      <td>0.073405</td>\n",
       "      <td>0.471430</td>\n",
       "      <td>0.576407</td>\n",
       "      <td>0.551288</td>\n",
       "      <td>0.577018</td>\n",
       "      <td>0.631457</td>\n",
       "      <td>0.278428</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021985</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.140613</td>\n",
       "      <td>0.222683</td>\n",
       "      <td>0.275132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1741</th>\n",
       "      <td>1998</td>\n",
       "      <td>0.016787</td>\n",
       "      <td>0.199106</td>\n",
       "      <td>0.055710</td>\n",
       "      <td>0.467379</td>\n",
       "      <td>0.654543</td>\n",
       "      <td>0.722595</td>\n",
       "      <td>0.743935</td>\n",
       "      <td>0.634282</td>\n",
       "      <td>0.178965</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017823</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.426784</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.353219</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038728</td>\n",
       "      <td>0.001058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1742</th>\n",
       "      <td>1999</td>\n",
       "      <td>0.022245</td>\n",
       "      <td>0.224935</td>\n",
       "      <td>0.054033</td>\n",
       "      <td>0.255286</td>\n",
       "      <td>0.625434</td>\n",
       "      <td>0.669501</td>\n",
       "      <td>0.701341</td>\n",
       "      <td>0.558181</td>\n",
       "      <td>0.293156</td>\n",
       "      <td>...</td>\n",
       "      <td>0.068617</td>\n",
       "      <td>0.016337</td>\n",
       "      <td>0.336617</td>\n",
       "      <td>0.005006</td>\n",
       "      <td>0.185430</td>\n",
       "      <td>0.054229</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.468710</td>\n",
       "      <td>0.100968</td>\n",
       "      <td>0.176720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1743</th>\n",
       "      <td>2000</td>\n",
       "      <td>0.026978</td>\n",
       "      <td>0.227259</td>\n",
       "      <td>0.061269</td>\n",
       "      <td>0.375683</td>\n",
       "      <td>0.733147</td>\n",
       "      <td>0.651635</td>\n",
       "      <td>0.590380</td>\n",
       "      <td>0.632072</td>\n",
       "      <td>0.167496</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028482</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.005022</td>\n",
       "      <td>0.002766</td>\n",
       "      <td>0.003175</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1744 rows Ã— 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      song_id  lowlevel.melbands_kurtosis.mean  \\\n",
       "0           2                         0.023745   \n",
       "1           3                         0.082083   \n",
       "2           4                         0.018062   \n",
       "3           5                         0.016018   \n",
       "4           7                         0.107675   \n",
       "...       ...                              ...   \n",
       "1739     1996                         0.013781   \n",
       "1740     1997                         0.012825   \n",
       "1741     1998                         0.016787   \n",
       "1742     1999                         0.022245   \n",
       "1743     2000                         0.026978   \n",
       "\n",
       "      lowlevel.melbands_skewness.mean  lowlevel.spectral_energy.mean  \\\n",
       "0                            0.224209                       0.054855   \n",
       "1                            0.348482                       0.211289   \n",
       "2                            0.213582                       0.084731   \n",
       "3                            0.181322                       0.041096   \n",
       "4                            0.349349                       0.197274   \n",
       "...                               ...                            ...   \n",
       "1739                         0.186248                       0.077709   \n",
       "1740                         0.189153                       0.073405   \n",
       "1741                         0.199106                       0.055710   \n",
       "1742                         0.224935                       0.054033   \n",
       "1743                         0.227259                       0.061269   \n",
       "\n",
       "      tonal.chords_strength.mean  tonal.hpcp_entropy.mean  \\\n",
       "0                       0.392382                 0.631265   \n",
       "1                       0.402792                 0.543954   \n",
       "2                       0.661722                 0.554446   \n",
       "3                       0.651524                 0.395875   \n",
       "4                       0.181959                 0.602087   \n",
       "...                          ...                      ...   \n",
       "1739                    0.476088                 0.626271   \n",
       "1740                    0.471430                 0.576407   \n",
       "1741                    0.467379                 0.654543   \n",
       "1742                    0.255286                 0.625434   \n",
       "1743                    0.375683                 0.733147   \n",
       "\n",
       "      tonal.key_edma.strength  tonal.key_temperley.strength  \\\n",
       "0                    0.625832                      0.593381   \n",
       "1                    0.677312                      0.677951   \n",
       "2                    0.593904                      0.570916   \n",
       "3                    0.900862                      0.900318   \n",
       "4                    0.450784                      0.432106   \n",
       "...                       ...                           ...   \n",
       "1739                 0.772039                      0.770549   \n",
       "1740                 0.551288                      0.577018   \n",
       "1741                 0.722595                      0.743935   \n",
       "1742                 0.669501                      0.701341   \n",
       "1743                 0.651635                      0.590380   \n",
       "\n",
       "      rhythm.beats_loudness_band_ratio.mean_0  \\\n",
       "0                                    0.579839   \n",
       "1                                    0.907102   \n",
       "2                                    0.686407   \n",
       "3                                    0.274781   \n",
       "4                                    0.938413   \n",
       "...                                       ...   \n",
       "1739                                 0.239129   \n",
       "1740                                 0.631457   \n",
       "1741                                 0.634282   \n",
       "1742                                 0.558181   \n",
       "1743                                 0.632072   \n",
       "\n",
       "      rhythm.beats_loudness_band_ratio.mean_1  ...  tonal.chords_histogram_14  \\\n",
       "0                                    0.267674  ...                   0.023256   \n",
       "1                                    0.118704  ...                   0.000000   \n",
       "2                                    0.209877  ...                   0.000000   \n",
       "3                                    0.429967  ...                   0.000000   \n",
       "4                                    0.080032  ...                   0.000000   \n",
       "...                                       ...  ...                        ...   \n",
       "1739                                 0.649168  ...                   0.000000   \n",
       "1740                                 0.278428  ...                   0.000000   \n",
       "1741                                 0.178965  ...                   0.000000   \n",
       "1742                                 0.293156  ...                   0.068617   \n",
       "1743                                 0.167496  ...                   0.028482   \n",
       "\n",
       "      tonal.chords_histogram_15  tonal.chords_histogram_16  \\\n",
       "0                      0.010375                   0.064544   \n",
       "1                      0.000000                   0.038179   \n",
       "2                      0.001484                   0.002937   \n",
       "3                      0.000000                   0.000000   \n",
       "4                      0.000000                   0.000000   \n",
       "...                         ...                        ...   \n",
       "1739                   0.000000                   0.000000   \n",
       "1740                   0.000000                   0.000000   \n",
       "1741                   0.017823                   0.000000   \n",
       "1742                   0.016337                   0.336617   \n",
       "1743                   0.000000                   0.000000   \n",
       "\n",
       "      tonal.chords_histogram_17  tonal.chords_histogram_18  \\\n",
       "0                      0.026229                   0.046262   \n",
       "1                      0.000000                   0.000000   \n",
       "2                      0.000000                   0.049618   \n",
       "3                      0.000000                   0.000000   \n",
       "4                      0.068694                   0.000000   \n",
       "...                         ...                        ...   \n",
       "1739                   0.000000                   0.000000   \n",
       "1740                   0.000000                   0.000000   \n",
       "1741                   0.426784                   0.000000   \n",
       "1742                   0.005006                   0.185430   \n",
       "1743                   0.000000                   0.000000   \n",
       "\n",
       "      tonal.chords_histogram_19  tonal.chords_histogram_20  \\\n",
       "0                      0.005850                    0.00000   \n",
       "1                      0.000000                    0.00000   \n",
       "2                      0.000000                    0.00000   \n",
       "3                      0.049780                    0.00000   \n",
       "4                      0.162351                    0.18304   \n",
       "...                         ...                        ...   \n",
       "1739                   0.000000                    0.00000   \n",
       "1740                   0.021985                    0.00000   \n",
       "1741                   0.353219                    0.00000   \n",
       "1742                   0.054229                    0.00000   \n",
       "1743                   0.000000                    0.00000   \n",
       "\n",
       "      tonal.chords_histogram_21  tonal.chords_histogram_22  \\\n",
       "0                      0.083526                   0.035887   \n",
       "1                      0.000000                   0.023489   \n",
       "2                      0.000000                   0.000000   \n",
       "3                      0.005017                   0.127117   \n",
       "4                      0.125289                   0.000000   \n",
       "...                         ...                        ...   \n",
       "1739                   0.000000                   0.009682   \n",
       "1740                   0.140613                   0.222683   \n",
       "1741                   0.000000                   0.038728   \n",
       "1742                   0.468710                   0.100968   \n",
       "1743                   0.005022                   0.002766   \n",
       "\n",
       "      tonal.chords_histogram_23  \n",
       "0                      0.012672  \n",
       "1                      0.035942  \n",
       "2                      0.001057  \n",
       "3                      0.022199  \n",
       "4                      0.015840  \n",
       "...                         ...  \n",
       "1739                   0.021164  \n",
       "1740                   0.275132  \n",
       "1741                   0.001058  \n",
       "1742                   0.176720  \n",
       "1743                   0.003175  \n",
       "\n",
       "[1744 rows x 38 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_essentia_best_overall_features_mean = pd.read_csv(get_deam_path('processed/features/normalised_essentia_best_overall_features_mean.csv'))\n",
    "\n",
    "# drop Unnamed:0 column\n",
    "df_essentia_best_overall_features_mean = df_essentia_best_overall_features_mean[df_essentia_best_overall_features_mean.columns[1:]]\n",
    "\n",
    "df_essentia_best_overall_features_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1744 entries, 0 to 1743\n",
      "Data columns (total 38 columns):\n",
      " #   Column                                   Non-Null Count  Dtype  \n",
      "---  ------                                   --------------  -----  \n",
      " 0   song_id                                  1744 non-null   int64  \n",
      " 1   lowlevel.melbands_kurtosis.mean          1744 non-null   float64\n",
      " 2   lowlevel.melbands_skewness.mean          1744 non-null   float64\n",
      " 3   lowlevel.spectral_energy.mean            1744 non-null   float64\n",
      " 4   tonal.chords_strength.mean               1744 non-null   float64\n",
      " 5   tonal.hpcp_entropy.mean                  1744 non-null   float64\n",
      " 6   tonal.key_edma.strength                  1744 non-null   float64\n",
      " 7   tonal.key_temperley.strength             1744 non-null   float64\n",
      " 8   rhythm.beats_loudness_band_ratio.mean_0  1744 non-null   float64\n",
      " 9   rhythm.beats_loudness_band_ratio.mean_1  1744 non-null   float64\n",
      " 10  rhythm.beats_loudness_band_ratio.mean_2  1744 non-null   float64\n",
      " 11  rhythm.beats_loudness_band_ratio.mean_3  1744 non-null   float64\n",
      " 12  rhythm.beats_loudness_band_ratio.mean_4  1744 non-null   float64\n",
      " 13  rhythm.beats_loudness_band_ratio.mean_5  1744 non-null   float64\n",
      " 14  tonal.chords_histogram_0                 1744 non-null   float64\n",
      " 15  tonal.chords_histogram_1                 1744 non-null   float64\n",
      " 16  tonal.chords_histogram_2                 1744 non-null   float64\n",
      " 17  tonal.chords_histogram_3                 1744 non-null   float64\n",
      " 18  tonal.chords_histogram_4                 1744 non-null   float64\n",
      " 19  tonal.chords_histogram_5                 1744 non-null   float64\n",
      " 20  tonal.chords_histogram_6                 1744 non-null   float64\n",
      " 21  tonal.chords_histogram_7                 1744 non-null   float64\n",
      " 22  tonal.chords_histogram_8                 1744 non-null   float64\n",
      " 23  tonal.chords_histogram_9                 1744 non-null   float64\n",
      " 24  tonal.chords_histogram_10                1744 non-null   float64\n",
      " 25  tonal.chords_histogram_11                1744 non-null   float64\n",
      " 26  tonal.chords_histogram_12                1744 non-null   float64\n",
      " 27  tonal.chords_histogram_13                1744 non-null   float64\n",
      " 28  tonal.chords_histogram_14                1744 non-null   float64\n",
      " 29  tonal.chords_histogram_15                1744 non-null   float64\n",
      " 30  tonal.chords_histogram_16                1744 non-null   float64\n",
      " 31  tonal.chords_histogram_17                1744 non-null   float64\n",
      " 32  tonal.chords_histogram_18                1744 non-null   float64\n",
      " 33  tonal.chords_histogram_19                1744 non-null   float64\n",
      " 34  tonal.chords_histogram_20                1744 non-null   float64\n",
      " 35  tonal.chords_histogram_21                1744 non-null   float64\n",
      " 36  tonal.chords_histogram_22                1744 non-null   float64\n",
      " 37  tonal.chords_histogram_23                1744 non-null   float64\n",
      "dtypes: float64(37), int64(1)\n",
      "memory usage: 517.9 KB\n"
     ]
    }
   ],
   "source": [
    "df_essentia_best_overall_features_mean.info(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join both the featureset and annotation set together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lowlevel.melbands_kurtosis.mean</th>\n",
       "      <th>lowlevel.melbands_skewness.mean</th>\n",
       "      <th>lowlevel.spectral_energy.mean</th>\n",
       "      <th>tonal.chords_strength.mean</th>\n",
       "      <th>tonal.hpcp_entropy.mean</th>\n",
       "      <th>tonal.key_edma.strength</th>\n",
       "      <th>tonal.key_temperley.strength</th>\n",
       "      <th>rhythm.beats_loudness_band_ratio.mean_0</th>\n",
       "      <th>rhythm.beats_loudness_band_ratio.mean_1</th>\n",
       "      <th>rhythm.beats_loudness_band_ratio.mean_2</th>\n",
       "      <th>...</th>\n",
       "      <th>tonal.chords_histogram_16</th>\n",
       "      <th>tonal.chords_histogram_17</th>\n",
       "      <th>tonal.chords_histogram_18</th>\n",
       "      <th>tonal.chords_histogram_19</th>\n",
       "      <th>tonal.chords_histogram_20</th>\n",
       "      <th>tonal.chords_histogram_21</th>\n",
       "      <th>tonal.chords_histogram_22</th>\n",
       "      <th>tonal.chords_histogram_23</th>\n",
       "      <th>valence_mean_mapped</th>\n",
       "      <th>arousal_mean_mapped</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.023745</td>\n",
       "      <td>0.224209</td>\n",
       "      <td>0.054855</td>\n",
       "      <td>0.392382</td>\n",
       "      <td>0.631265</td>\n",
       "      <td>0.625832</td>\n",
       "      <td>0.593381</td>\n",
       "      <td>0.579839</td>\n",
       "      <td>0.267674</td>\n",
       "      <td>0.163056</td>\n",
       "      <td>...</td>\n",
       "      <td>0.064544</td>\n",
       "      <td>0.026229</td>\n",
       "      <td>0.046262</td>\n",
       "      <td>0.005850</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.083526</td>\n",
       "      <td>0.035887</td>\n",
       "      <td>0.012672</td>\n",
       "      <td>-0.475</td>\n",
       "      <td>-0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.082083</td>\n",
       "      <td>0.348482</td>\n",
       "      <td>0.211289</td>\n",
       "      <td>0.402792</td>\n",
       "      <td>0.543954</td>\n",
       "      <td>0.677312</td>\n",
       "      <td>0.677951</td>\n",
       "      <td>0.907102</td>\n",
       "      <td>0.118704</td>\n",
       "      <td>0.015192</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038179</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023489</td>\n",
       "      <td>0.035942</td>\n",
       "      <td>-0.375</td>\n",
       "      <td>-0.425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.018062</td>\n",
       "      <td>0.213582</td>\n",
       "      <td>0.084731</td>\n",
       "      <td>0.661722</td>\n",
       "      <td>0.554446</td>\n",
       "      <td>0.593904</td>\n",
       "      <td>0.570916</td>\n",
       "      <td>0.686407</td>\n",
       "      <td>0.209877</td>\n",
       "      <td>0.085901</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002937</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.049618</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001057</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.016018</td>\n",
       "      <td>0.181322</td>\n",
       "      <td>0.041096</td>\n",
       "      <td>0.651524</td>\n",
       "      <td>0.395875</td>\n",
       "      <td>0.900862</td>\n",
       "      <td>0.900318</td>\n",
       "      <td>0.274781</td>\n",
       "      <td>0.429967</td>\n",
       "      <td>0.346099</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.049780</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.005017</td>\n",
       "      <td>0.127117</td>\n",
       "      <td>0.022199</td>\n",
       "      <td>-0.150</td>\n",
       "      <td>0.075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.107675</td>\n",
       "      <td>0.349349</td>\n",
       "      <td>0.197274</td>\n",
       "      <td>0.181959</td>\n",
       "      <td>0.602087</td>\n",
       "      <td>0.450784</td>\n",
       "      <td>0.432106</td>\n",
       "      <td>0.938413</td>\n",
       "      <td>0.080032</td>\n",
       "      <td>0.025854</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.068694</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.162351</td>\n",
       "      <td>0.18304</td>\n",
       "      <td>0.125289</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015840</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1739</th>\n",
       "      <td>0.013781</td>\n",
       "      <td>0.186248</td>\n",
       "      <td>0.077709</td>\n",
       "      <td>0.476088</td>\n",
       "      <td>0.626271</td>\n",
       "      <td>0.772039</td>\n",
       "      <td>0.770549</td>\n",
       "      <td>0.239129</td>\n",
       "      <td>0.649168</td>\n",
       "      <td>0.208802</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009682</td>\n",
       "      <td>0.021164</td>\n",
       "      <td>-0.275</td>\n",
       "      <td>0.225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1740</th>\n",
       "      <td>0.012825</td>\n",
       "      <td>0.189153</td>\n",
       "      <td>0.073405</td>\n",
       "      <td>0.471430</td>\n",
       "      <td>0.576407</td>\n",
       "      <td>0.551288</td>\n",
       "      <td>0.577018</td>\n",
       "      <td>0.631457</td>\n",
       "      <td>0.278428</td>\n",
       "      <td>0.138446</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021985</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.140613</td>\n",
       "      <td>0.222683</td>\n",
       "      <td>0.275132</td>\n",
       "      <td>0.075</td>\n",
       "      <td>-0.275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1741</th>\n",
       "      <td>0.016787</td>\n",
       "      <td>0.199106</td>\n",
       "      <td>0.055710</td>\n",
       "      <td>0.467379</td>\n",
       "      <td>0.654543</td>\n",
       "      <td>0.722595</td>\n",
       "      <td>0.743935</td>\n",
       "      <td>0.634282</td>\n",
       "      <td>0.178965</td>\n",
       "      <td>0.163915</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.426784</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.353219</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038728</td>\n",
       "      <td>0.001058</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1742</th>\n",
       "      <td>0.022245</td>\n",
       "      <td>0.224935</td>\n",
       "      <td>0.054033</td>\n",
       "      <td>0.255286</td>\n",
       "      <td>0.625434</td>\n",
       "      <td>0.669501</td>\n",
       "      <td>0.701341</td>\n",
       "      <td>0.558181</td>\n",
       "      <td>0.293156</td>\n",
       "      <td>0.168323</td>\n",
       "      <td>...</td>\n",
       "      <td>0.336617</td>\n",
       "      <td>0.005006</td>\n",
       "      <td>0.185430</td>\n",
       "      <td>0.054229</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.468710</td>\n",
       "      <td>0.100968</td>\n",
       "      <td>0.176720</td>\n",
       "      <td>-0.100</td>\n",
       "      <td>0.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1743</th>\n",
       "      <td>0.026978</td>\n",
       "      <td>0.227259</td>\n",
       "      <td>0.061269</td>\n",
       "      <td>0.375683</td>\n",
       "      <td>0.733147</td>\n",
       "      <td>0.651635</td>\n",
       "      <td>0.590380</td>\n",
       "      <td>0.632072</td>\n",
       "      <td>0.167496</td>\n",
       "      <td>0.103663</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.005022</td>\n",
       "      <td>0.002766</td>\n",
       "      <td>0.003175</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1744 rows Ã— 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      lowlevel.melbands_kurtosis.mean  lowlevel.melbands_skewness.mean  \\\n",
       "0                            0.023745                         0.224209   \n",
       "1                            0.082083                         0.348482   \n",
       "2                            0.018062                         0.213582   \n",
       "3                            0.016018                         0.181322   \n",
       "4                            0.107675                         0.349349   \n",
       "...                               ...                              ...   \n",
       "1739                         0.013781                         0.186248   \n",
       "1740                         0.012825                         0.189153   \n",
       "1741                         0.016787                         0.199106   \n",
       "1742                         0.022245                         0.224935   \n",
       "1743                         0.026978                         0.227259   \n",
       "\n",
       "      lowlevel.spectral_energy.mean  tonal.chords_strength.mean  \\\n",
       "0                          0.054855                    0.392382   \n",
       "1                          0.211289                    0.402792   \n",
       "2                          0.084731                    0.661722   \n",
       "3                          0.041096                    0.651524   \n",
       "4                          0.197274                    0.181959   \n",
       "...                             ...                         ...   \n",
       "1739                       0.077709                    0.476088   \n",
       "1740                       0.073405                    0.471430   \n",
       "1741                       0.055710                    0.467379   \n",
       "1742                       0.054033                    0.255286   \n",
       "1743                       0.061269                    0.375683   \n",
       "\n",
       "      tonal.hpcp_entropy.mean  tonal.key_edma.strength  \\\n",
       "0                    0.631265                 0.625832   \n",
       "1                    0.543954                 0.677312   \n",
       "2                    0.554446                 0.593904   \n",
       "3                    0.395875                 0.900862   \n",
       "4                    0.602087                 0.450784   \n",
       "...                       ...                      ...   \n",
       "1739                 0.626271                 0.772039   \n",
       "1740                 0.576407                 0.551288   \n",
       "1741                 0.654543                 0.722595   \n",
       "1742                 0.625434                 0.669501   \n",
       "1743                 0.733147                 0.651635   \n",
       "\n",
       "      tonal.key_temperley.strength  rhythm.beats_loudness_band_ratio.mean_0  \\\n",
       "0                         0.593381                                 0.579839   \n",
       "1                         0.677951                                 0.907102   \n",
       "2                         0.570916                                 0.686407   \n",
       "3                         0.900318                                 0.274781   \n",
       "4                         0.432106                                 0.938413   \n",
       "...                            ...                                      ...   \n",
       "1739                      0.770549                                 0.239129   \n",
       "1740                      0.577018                                 0.631457   \n",
       "1741                      0.743935                                 0.634282   \n",
       "1742                      0.701341                                 0.558181   \n",
       "1743                      0.590380                                 0.632072   \n",
       "\n",
       "      rhythm.beats_loudness_band_ratio.mean_1  \\\n",
       "0                                    0.267674   \n",
       "1                                    0.118704   \n",
       "2                                    0.209877   \n",
       "3                                    0.429967   \n",
       "4                                    0.080032   \n",
       "...                                       ...   \n",
       "1739                                 0.649168   \n",
       "1740                                 0.278428   \n",
       "1741                                 0.178965   \n",
       "1742                                 0.293156   \n",
       "1743                                 0.167496   \n",
       "\n",
       "      rhythm.beats_loudness_band_ratio.mean_2  ...  tonal.chords_histogram_16  \\\n",
       "0                                    0.163056  ...                   0.064544   \n",
       "1                                    0.015192  ...                   0.038179   \n",
       "2                                    0.085901  ...                   0.002937   \n",
       "3                                    0.346099  ...                   0.000000   \n",
       "4                                    0.025854  ...                   0.000000   \n",
       "...                                       ...  ...                        ...   \n",
       "1739                                 0.208802  ...                   0.000000   \n",
       "1740                                 0.138446  ...                   0.000000   \n",
       "1741                                 0.163915  ...                   0.000000   \n",
       "1742                                 0.168323  ...                   0.336617   \n",
       "1743                                 0.103663  ...                   0.000000   \n",
       "\n",
       "      tonal.chords_histogram_17  tonal.chords_histogram_18  \\\n",
       "0                      0.026229                   0.046262   \n",
       "1                      0.000000                   0.000000   \n",
       "2                      0.000000                   0.049618   \n",
       "3                      0.000000                   0.000000   \n",
       "4                      0.068694                   0.000000   \n",
       "...                         ...                        ...   \n",
       "1739                   0.000000                   0.000000   \n",
       "1740                   0.000000                   0.000000   \n",
       "1741                   0.426784                   0.000000   \n",
       "1742                   0.005006                   0.185430   \n",
       "1743                   0.000000                   0.000000   \n",
       "\n",
       "      tonal.chords_histogram_19  tonal.chords_histogram_20  \\\n",
       "0                      0.005850                    0.00000   \n",
       "1                      0.000000                    0.00000   \n",
       "2                      0.000000                    0.00000   \n",
       "3                      0.049780                    0.00000   \n",
       "4                      0.162351                    0.18304   \n",
       "...                         ...                        ...   \n",
       "1739                   0.000000                    0.00000   \n",
       "1740                   0.021985                    0.00000   \n",
       "1741                   0.353219                    0.00000   \n",
       "1742                   0.054229                    0.00000   \n",
       "1743                   0.000000                    0.00000   \n",
       "\n",
       "      tonal.chords_histogram_21  tonal.chords_histogram_22  \\\n",
       "0                      0.083526                   0.035887   \n",
       "1                      0.000000                   0.023489   \n",
       "2                      0.000000                   0.000000   \n",
       "3                      0.005017                   0.127117   \n",
       "4                      0.125289                   0.000000   \n",
       "...                         ...                        ...   \n",
       "1739                   0.000000                   0.009682   \n",
       "1740                   0.140613                   0.222683   \n",
       "1741                   0.000000                   0.038728   \n",
       "1742                   0.468710                   0.100968   \n",
       "1743                   0.005022                   0.002766   \n",
       "\n",
       "      tonal.chords_histogram_23  valence_mean_mapped  arousal_mean_mapped  \n",
       "0                      0.012672               -0.475               -0.500  \n",
       "1                      0.035942               -0.375               -0.425  \n",
       "2                      0.001057                0.175                0.125  \n",
       "3                      0.022199               -0.150                0.075  \n",
       "4                      0.015840                0.200                0.350  \n",
       "...                         ...                  ...                  ...  \n",
       "1739                   0.021164               -0.275                0.225  \n",
       "1740                   0.275132                0.075               -0.275  \n",
       "1741                   0.001058                0.350                0.300  \n",
       "1742                   0.176720               -0.100                0.100  \n",
       "1743                   0.003175                0.200                0.250  \n",
       "\n",
       "[1744 rows x 39 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_essentia_best_overall_features_mean_whole = pd.merge(df_essentia_best_overall_features_mean, df_annotations, how='inner', on='song_id')\n",
    "df_essentia_best_overall_features_mean_whole = df_essentia_best_overall_features_mean_whole.drop('song_id', axis=1)\n",
    "df_essentia_best_overall_features_mean_whole"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare dataframes for the neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform splitting of the dataframe into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lowlevel.melbands_kurtosis.mean</th>\n",
       "      <th>lowlevel.melbands_skewness.mean</th>\n",
       "      <th>lowlevel.spectral_energy.mean</th>\n",
       "      <th>tonal.chords_strength.mean</th>\n",
       "      <th>tonal.hpcp_entropy.mean</th>\n",
       "      <th>tonal.key_edma.strength</th>\n",
       "      <th>tonal.key_temperley.strength</th>\n",
       "      <th>rhythm.beats_loudness_band_ratio.mean_0</th>\n",
       "      <th>rhythm.beats_loudness_band_ratio.mean_1</th>\n",
       "      <th>rhythm.beats_loudness_band_ratio.mean_2</th>\n",
       "      <th>...</th>\n",
       "      <th>tonal.chords_histogram_14</th>\n",
       "      <th>tonal.chords_histogram_15</th>\n",
       "      <th>tonal.chords_histogram_16</th>\n",
       "      <th>tonal.chords_histogram_17</th>\n",
       "      <th>tonal.chords_histogram_18</th>\n",
       "      <th>tonal.chords_histogram_19</th>\n",
       "      <th>tonal.chords_histogram_20</th>\n",
       "      <th>tonal.chords_histogram_21</th>\n",
       "      <th>tonal.chords_histogram_22</th>\n",
       "      <th>tonal.chords_histogram_23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.023745</td>\n",
       "      <td>0.224209</td>\n",
       "      <td>0.054855</td>\n",
       "      <td>0.392382</td>\n",
       "      <td>0.631265</td>\n",
       "      <td>0.625832</td>\n",
       "      <td>0.593381</td>\n",
       "      <td>0.579839</td>\n",
       "      <td>0.267674</td>\n",
       "      <td>0.163056</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023256</td>\n",
       "      <td>0.010375</td>\n",
       "      <td>0.064544</td>\n",
       "      <td>0.026229</td>\n",
       "      <td>0.046262</td>\n",
       "      <td>0.005850</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.083526</td>\n",
       "      <td>0.035887</td>\n",
       "      <td>0.012672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.082083</td>\n",
       "      <td>0.348482</td>\n",
       "      <td>0.211289</td>\n",
       "      <td>0.402792</td>\n",
       "      <td>0.543954</td>\n",
       "      <td>0.677312</td>\n",
       "      <td>0.677951</td>\n",
       "      <td>0.907102</td>\n",
       "      <td>0.118704</td>\n",
       "      <td>0.015192</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038179</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023489</td>\n",
       "      <td>0.035942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.018062</td>\n",
       "      <td>0.213582</td>\n",
       "      <td>0.084731</td>\n",
       "      <td>0.661722</td>\n",
       "      <td>0.554446</td>\n",
       "      <td>0.593904</td>\n",
       "      <td>0.570916</td>\n",
       "      <td>0.686407</td>\n",
       "      <td>0.209877</td>\n",
       "      <td>0.085901</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001484</td>\n",
       "      <td>0.002937</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.049618</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.016018</td>\n",
       "      <td>0.181322</td>\n",
       "      <td>0.041096</td>\n",
       "      <td>0.651524</td>\n",
       "      <td>0.395875</td>\n",
       "      <td>0.900862</td>\n",
       "      <td>0.900318</td>\n",
       "      <td>0.274781</td>\n",
       "      <td>0.429967</td>\n",
       "      <td>0.346099</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.049780</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.005017</td>\n",
       "      <td>0.127117</td>\n",
       "      <td>0.022199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.107675</td>\n",
       "      <td>0.349349</td>\n",
       "      <td>0.197274</td>\n",
       "      <td>0.181959</td>\n",
       "      <td>0.602087</td>\n",
       "      <td>0.450784</td>\n",
       "      <td>0.432106</td>\n",
       "      <td>0.938413</td>\n",
       "      <td>0.080032</td>\n",
       "      <td>0.025854</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.068694</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.162351</td>\n",
       "      <td>0.18304</td>\n",
       "      <td>0.125289</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1739</th>\n",
       "      <td>0.013781</td>\n",
       "      <td>0.186248</td>\n",
       "      <td>0.077709</td>\n",
       "      <td>0.476088</td>\n",
       "      <td>0.626271</td>\n",
       "      <td>0.772039</td>\n",
       "      <td>0.770549</td>\n",
       "      <td>0.239129</td>\n",
       "      <td>0.649168</td>\n",
       "      <td>0.208802</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009682</td>\n",
       "      <td>0.021164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1740</th>\n",
       "      <td>0.012825</td>\n",
       "      <td>0.189153</td>\n",
       "      <td>0.073405</td>\n",
       "      <td>0.471430</td>\n",
       "      <td>0.576407</td>\n",
       "      <td>0.551288</td>\n",
       "      <td>0.577018</td>\n",
       "      <td>0.631457</td>\n",
       "      <td>0.278428</td>\n",
       "      <td>0.138446</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021985</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.140613</td>\n",
       "      <td>0.222683</td>\n",
       "      <td>0.275132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1741</th>\n",
       "      <td>0.016787</td>\n",
       "      <td>0.199106</td>\n",
       "      <td>0.055710</td>\n",
       "      <td>0.467379</td>\n",
       "      <td>0.654543</td>\n",
       "      <td>0.722595</td>\n",
       "      <td>0.743935</td>\n",
       "      <td>0.634282</td>\n",
       "      <td>0.178965</td>\n",
       "      <td>0.163915</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017823</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.426784</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.353219</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038728</td>\n",
       "      <td>0.001058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1742</th>\n",
       "      <td>0.022245</td>\n",
       "      <td>0.224935</td>\n",
       "      <td>0.054033</td>\n",
       "      <td>0.255286</td>\n",
       "      <td>0.625434</td>\n",
       "      <td>0.669501</td>\n",
       "      <td>0.701341</td>\n",
       "      <td>0.558181</td>\n",
       "      <td>0.293156</td>\n",
       "      <td>0.168323</td>\n",
       "      <td>...</td>\n",
       "      <td>0.068617</td>\n",
       "      <td>0.016337</td>\n",
       "      <td>0.336617</td>\n",
       "      <td>0.005006</td>\n",
       "      <td>0.185430</td>\n",
       "      <td>0.054229</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.468710</td>\n",
       "      <td>0.100968</td>\n",
       "      <td>0.176720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1743</th>\n",
       "      <td>0.026978</td>\n",
       "      <td>0.227259</td>\n",
       "      <td>0.061269</td>\n",
       "      <td>0.375683</td>\n",
       "      <td>0.733147</td>\n",
       "      <td>0.651635</td>\n",
       "      <td>0.590380</td>\n",
       "      <td>0.632072</td>\n",
       "      <td>0.167496</td>\n",
       "      <td>0.103663</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028482</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.005022</td>\n",
       "      <td>0.002766</td>\n",
       "      <td>0.003175</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1744 rows Ã— 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      lowlevel.melbands_kurtosis.mean  lowlevel.melbands_skewness.mean  \\\n",
       "0                            0.023745                         0.224209   \n",
       "1                            0.082083                         0.348482   \n",
       "2                            0.018062                         0.213582   \n",
       "3                            0.016018                         0.181322   \n",
       "4                            0.107675                         0.349349   \n",
       "...                               ...                              ...   \n",
       "1739                         0.013781                         0.186248   \n",
       "1740                         0.012825                         0.189153   \n",
       "1741                         0.016787                         0.199106   \n",
       "1742                         0.022245                         0.224935   \n",
       "1743                         0.026978                         0.227259   \n",
       "\n",
       "      lowlevel.spectral_energy.mean  tonal.chords_strength.mean  \\\n",
       "0                          0.054855                    0.392382   \n",
       "1                          0.211289                    0.402792   \n",
       "2                          0.084731                    0.661722   \n",
       "3                          0.041096                    0.651524   \n",
       "4                          0.197274                    0.181959   \n",
       "...                             ...                         ...   \n",
       "1739                       0.077709                    0.476088   \n",
       "1740                       0.073405                    0.471430   \n",
       "1741                       0.055710                    0.467379   \n",
       "1742                       0.054033                    0.255286   \n",
       "1743                       0.061269                    0.375683   \n",
       "\n",
       "      tonal.hpcp_entropy.mean  tonal.key_edma.strength  \\\n",
       "0                    0.631265                 0.625832   \n",
       "1                    0.543954                 0.677312   \n",
       "2                    0.554446                 0.593904   \n",
       "3                    0.395875                 0.900862   \n",
       "4                    0.602087                 0.450784   \n",
       "...                       ...                      ...   \n",
       "1739                 0.626271                 0.772039   \n",
       "1740                 0.576407                 0.551288   \n",
       "1741                 0.654543                 0.722595   \n",
       "1742                 0.625434                 0.669501   \n",
       "1743                 0.733147                 0.651635   \n",
       "\n",
       "      tonal.key_temperley.strength  rhythm.beats_loudness_band_ratio.mean_0  \\\n",
       "0                         0.593381                                 0.579839   \n",
       "1                         0.677951                                 0.907102   \n",
       "2                         0.570916                                 0.686407   \n",
       "3                         0.900318                                 0.274781   \n",
       "4                         0.432106                                 0.938413   \n",
       "...                            ...                                      ...   \n",
       "1739                      0.770549                                 0.239129   \n",
       "1740                      0.577018                                 0.631457   \n",
       "1741                      0.743935                                 0.634282   \n",
       "1742                      0.701341                                 0.558181   \n",
       "1743                      0.590380                                 0.632072   \n",
       "\n",
       "      rhythm.beats_loudness_band_ratio.mean_1  \\\n",
       "0                                    0.267674   \n",
       "1                                    0.118704   \n",
       "2                                    0.209877   \n",
       "3                                    0.429967   \n",
       "4                                    0.080032   \n",
       "...                                       ...   \n",
       "1739                                 0.649168   \n",
       "1740                                 0.278428   \n",
       "1741                                 0.178965   \n",
       "1742                                 0.293156   \n",
       "1743                                 0.167496   \n",
       "\n",
       "      rhythm.beats_loudness_band_ratio.mean_2  ...  tonal.chords_histogram_14  \\\n",
       "0                                    0.163056  ...                   0.023256   \n",
       "1                                    0.015192  ...                   0.000000   \n",
       "2                                    0.085901  ...                   0.000000   \n",
       "3                                    0.346099  ...                   0.000000   \n",
       "4                                    0.025854  ...                   0.000000   \n",
       "...                                       ...  ...                        ...   \n",
       "1739                                 0.208802  ...                   0.000000   \n",
       "1740                                 0.138446  ...                   0.000000   \n",
       "1741                                 0.163915  ...                   0.000000   \n",
       "1742                                 0.168323  ...                   0.068617   \n",
       "1743                                 0.103663  ...                   0.028482   \n",
       "\n",
       "      tonal.chords_histogram_15  tonal.chords_histogram_16  \\\n",
       "0                      0.010375                   0.064544   \n",
       "1                      0.000000                   0.038179   \n",
       "2                      0.001484                   0.002937   \n",
       "3                      0.000000                   0.000000   \n",
       "4                      0.000000                   0.000000   \n",
       "...                         ...                        ...   \n",
       "1739                   0.000000                   0.000000   \n",
       "1740                   0.000000                   0.000000   \n",
       "1741                   0.017823                   0.000000   \n",
       "1742                   0.016337                   0.336617   \n",
       "1743                   0.000000                   0.000000   \n",
       "\n",
       "      tonal.chords_histogram_17  tonal.chords_histogram_18  \\\n",
       "0                      0.026229                   0.046262   \n",
       "1                      0.000000                   0.000000   \n",
       "2                      0.000000                   0.049618   \n",
       "3                      0.000000                   0.000000   \n",
       "4                      0.068694                   0.000000   \n",
       "...                         ...                        ...   \n",
       "1739                   0.000000                   0.000000   \n",
       "1740                   0.000000                   0.000000   \n",
       "1741                   0.426784                   0.000000   \n",
       "1742                   0.005006                   0.185430   \n",
       "1743                   0.000000                   0.000000   \n",
       "\n",
       "      tonal.chords_histogram_19  tonal.chords_histogram_20  \\\n",
       "0                      0.005850                    0.00000   \n",
       "1                      0.000000                    0.00000   \n",
       "2                      0.000000                    0.00000   \n",
       "3                      0.049780                    0.00000   \n",
       "4                      0.162351                    0.18304   \n",
       "...                         ...                        ...   \n",
       "1739                   0.000000                    0.00000   \n",
       "1740                   0.021985                    0.00000   \n",
       "1741                   0.353219                    0.00000   \n",
       "1742                   0.054229                    0.00000   \n",
       "1743                   0.000000                    0.00000   \n",
       "\n",
       "      tonal.chords_histogram_21  tonal.chords_histogram_22  \\\n",
       "0                      0.083526                   0.035887   \n",
       "1                      0.000000                   0.023489   \n",
       "2                      0.000000                   0.000000   \n",
       "3                      0.005017                   0.127117   \n",
       "4                      0.125289                   0.000000   \n",
       "...                         ...                        ...   \n",
       "1739                   0.000000                   0.009682   \n",
       "1740                   0.140613                   0.222683   \n",
       "1741                   0.000000                   0.038728   \n",
       "1742                   0.468710                   0.100968   \n",
       "1743                   0.005022                   0.002766   \n",
       "\n",
       "      tonal.chords_histogram_23  \n",
       "0                      0.012672  \n",
       "1                      0.035942  \n",
       "2                      0.001057  \n",
       "3                      0.022199  \n",
       "4                      0.015840  \n",
       "...                         ...  \n",
       "1739                   0.021164  \n",
       "1740                   0.275132  \n",
       "1741                   0.001058  \n",
       "1742                   0.176720  \n",
       "1743                   0.003175  \n",
       "\n",
       "[1744 rows x 37 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = df_essentia_best_overall_features_mean.drop('song_id', axis=1)\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>valence_mean_mapped</th>\n",
       "      <th>arousal_mean_mapped</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.475</td>\n",
       "      <td>-0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.375</td>\n",
       "      <td>-0.425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.175</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.150</td>\n",
       "      <td>0.075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.200</td>\n",
       "      <td>0.350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1739</th>\n",
       "      <td>-0.275</td>\n",
       "      <td>0.225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1740</th>\n",
       "      <td>0.075</td>\n",
       "      <td>-0.275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1741</th>\n",
       "      <td>0.350</td>\n",
       "      <td>0.300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1742</th>\n",
       "      <td>-0.100</td>\n",
       "      <td>0.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1743</th>\n",
       "      <td>0.200</td>\n",
       "      <td>0.250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1744 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      valence_mean_mapped  arousal_mean_mapped\n",
       "0                  -0.475               -0.500\n",
       "1                  -0.375               -0.425\n",
       "2                   0.175                0.125\n",
       "3                  -0.150                0.075\n",
       "4                   0.200                0.350\n",
       "...                   ...                  ...\n",
       "1739               -0.275                0.225\n",
       "1740                0.075               -0.275\n",
       "1741                0.350                0.300\n",
       "1742               -0.100                0.100\n",
       "1743                0.200                0.250\n",
       "\n",
       "[1744 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets = df_annotations.drop('song_id', axis=1)\n",
    "targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform 80-20 train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, targets, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create tensors for X_train and X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float64)\n",
    "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create tensors for Y_train and Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float64)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define neural network parameters and instantitate neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 1\n",
    "hidden_size = 20 \n",
    "output_size = 2  # Output size for valence and arousal\n",
    "learning_rate = 0.001\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set a random seed to ensure consistent initial weights of the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x120033e50>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the seed\n",
    "seed = 42\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_size, math.ceil((input_size**0.5) * 2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(math.ceil((input_size**0.5) * 2), math.ceil((input_size**0.5) * 2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(math.ceil((input_size**0.5) * 2), math.ceil((input_size**0.5) * 2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(math.ceil((input_size**0.5) * 2), math.ceil((input_size**0.5) * 2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(math.ceil((input_size**0.5) * 2), math.ceil((input_size**0.5) * 2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(math.ceil((input_size**0.5) * 2), math.ceil((input_size**0.5) * 2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(math.ceil((input_size**0.5) * 2), math.ceil((input_size**0.5) * 2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(math.ceil((input_size**0.5) * 2), math.ceil((input_size**0.5) * 2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(math.ceil((input_size**0.5) * 2), math.ceil((input_size**0.5) * 2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(math.ceil((input_size**0.5) * 2), math.ceil((input_size**0.5) * 2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(math.ceil((input_size**0.5) * 2), math.ceil((input_size**0.5) * 2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(math.ceil((input_size**0.5) * 2), 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare input_train_data and target_train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1395, 37])\n"
     ]
    }
   ],
   "source": [
    "input_train_data = X_train_tensor.float()\n",
    "\n",
    "# input_train_data = input_train_data.view(input_train_data.shape[1], -1)\n",
    "print(input_train_data.shape)\n",
    "\n",
    "target_train_labels = y_train_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(num_epochs):\n",
    "  model = NeuralNetwork(input_size=input_train_data.shape[1])\n",
    "  optimiser = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "  \n",
    "  for epoch in range(num_epochs):\n",
    "    optimiser.zero_grad()\n",
    "    \n",
    "    # forward pass\n",
    "    output = model(input_train_data)\n",
    "\n",
    "    # calculate loss\n",
    "    loss = torch.sqrt(criterion(output.float(), target_train_labels.float()))\n",
    "\n",
    "    # backward pass\n",
    "    loss.backward()\n",
    "    # update weights\n",
    "    optimiser.step()\n",
    "\n",
    "    print(f'Epoch {epoch + 1}, Loss: {math.sqrt(loss.item())}')\n",
    "\n",
    "  print(\"Training completed.\")\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.6117393889666376\n",
      "Epoch 2, Loss: 0.6100286499315085\n",
      "Epoch 3, Loss: 0.6083391384170024\n",
      "Epoch 4, Loss: 0.606697828515189\n",
      "Epoch 5, Loss: 0.6051904346316515\n",
      "Epoch 6, Loss: 0.6036947287065404\n",
      "Epoch 7, Loss: 0.6022119607990583\n",
      "Epoch 8, Loss: 0.6007433925254181\n",
      "Epoch 9, Loss: 0.599289078545509\n",
      "Epoch 10, Loss: 0.5978484249936177\n",
      "Epoch 11, Loss: 0.5964208063153662\n",
      "Epoch 12, Loss: 0.5953973954910371\n",
      "Epoch 13, Loss: 0.5943932060959207\n",
      "Epoch 14, Loss: 0.5933711449445846\n",
      "Epoch 15, Loss: 0.5923408551297583\n",
      "Epoch 16, Loss: 0.5913077621391112\n",
      "Epoch 17, Loss: 0.5902755369505391\n",
      "Epoch 18, Loss: 0.5892467888448013\n",
      "Epoch 19, Loss: 0.588223537334592\n",
      "Epoch 20, Loss: 0.5872073844884498\n",
      "Epoch 21, Loss: 0.5861995111209622\n",
      "Epoch 22, Loss: 0.585200978544451\n",
      "Epoch 23, Loss: 0.5842126253535979\n",
      "Epoch 24, Loss: 0.5832351675767833\n",
      "Epoch 25, Loss: 0.5822692230985602\n",
      "Epoch 26, Loss: 0.5813153107159604\n",
      "Epoch 27, Loss: 0.580373874884227\n",
      "Epoch 28, Loss: 0.5794452850111784\n",
      "Epoch 29, Loss: 0.5785298605229274\n",
      "Epoch 30, Loss: 0.5776277929988484\n",
      "Epoch 31, Loss: 0.5767393259715088\n",
      "Epoch 32, Loss: 0.5758644965149398\n",
      "Epoch 33, Loss: 0.5750033927900313\n",
      "Epoch 34, Loss: 0.5741559986937601\n",
      "Epoch 35, Loss: 0.5733223230345269\n",
      "Epoch 36, Loss: 0.5725022695737937\n",
      "Epoch 37, Loss: 0.5716958708666888\n",
      "Epoch 38, Loss: 0.5709030542699218\n",
      "Epoch 39, Loss: 0.5701239287189237\n",
      "Epoch 40, Loss: 0.5693567445594213\n",
      "Epoch 41, Loss: 0.5686001611711379\n",
      "Epoch 42, Loss: 0.5678551918486388\n",
      "Epoch 43, Loss: 0.5671225392366211\n",
      "Epoch 44, Loss: 0.5664026983741692\n",
      "Epoch 45, Loss: 0.5656961659716078\n",
      "Epoch 46, Loss: 0.5650035458006197\n",
      "Epoch 47, Loss: 0.5643645484353663\n",
      "Epoch 48, Loss: 0.563789664139787\n",
      "Epoch 49, Loss: 0.5632216275176618\n",
      "Epoch 50, Loss: 0.5626624720429879\n",
      "Epoch 51, Loss: 0.5621141063711089\n",
      "Epoch 52, Loss: 0.5615784991261425\n",
      "Epoch 53, Loss: 0.5610566960940029\n",
      "Epoch 54, Loss: 0.5605459445852606\n",
      "Epoch 55, Loss: 0.5600513567535911\n",
      "Epoch 56, Loss: 0.5595775290884318\n",
      "Epoch 57, Loss: 0.5591272860539362\n",
      "Epoch 58, Loss: 0.5587033517724352\n",
      "Epoch 59, Loss: 0.5583085085441006\n",
      "Epoch 60, Loss: 0.5579456490995937\n",
      "Epoch 61, Loss: 0.5576168401018922\n",
      "Epoch 62, Loss: 0.5573238529881236\n",
      "Epoch 63, Loss: 0.5570684294845677\n",
      "Epoch 64, Loss: 0.556851477591791\n",
      "Epoch 65, Loss: 0.5566731761315737\n",
      "Epoch 66, Loss: 0.5565324912529966\n",
      "Epoch 67, Loss: 0.5564271216266072\n",
      "Epoch 68, Loss: 0.556353551891306\n",
      "Epoch 69, Loss: 0.5563060089373779\n",
      "Epoch 70, Loss: 0.5562800260005009\n",
      "Epoch 71, Loss: 0.5562689627940532\n",
      "Epoch 72, Loss: 0.5562679984363345\n",
      "Epoch 73, Loss: 0.5562728469957149\n",
      "Epoch 74, Loss: 0.5562803206591657\n",
      "Epoch 75, Loss: 0.5562879013693358\n",
      "Epoch 76, Loss: 0.5562947051696487\n",
      "Epoch 77, Loss: 0.5562997409997557\n",
      "Epoch 78, Loss: 0.5563024196142184\n",
      "Epoch 79, Loss: 0.5563025267585288\n",
      "Epoch 80, Loss: 0.5562997677859641\n",
      "Epoch 81, Loss: 0.5562941158674014\n",
      "Epoch 82, Loss: 0.556285624488443\n",
      "Epoch 83, Loss: 0.5562743470939243\n",
      "Epoch 84, Loss: 0.55626068533589\n",
      "Epoch 85, Loss: 0.5562449069272164\n",
      "Epoch 86, Loss: 0.5562274671126851\n",
      "Epoch 87, Loss: 0.5562087943856058\n",
      "Epoch 88, Loss: 0.556189451244021\n",
      "Epoch 89, Loss: 0.5561698662975726\n",
      "Epoch 90, Loss: 0.5561504950086563\n",
      "Epoch 91, Loss: 0.5561316321370441\n",
      "Epoch 92, Loss: 0.5561136260718379\n",
      "Epoch 93, Loss: 0.5560966108762503\n",
      "Epoch 94, Loss: 0.556080693828291\n",
      "Epoch 95, Loss: 0.5560658214273093\n",
      "Epoch 96, Loss: 0.5560518329682422\n",
      "Epoch 97, Loss: 0.5560384873287035\n",
      "Epoch 98, Loss: 0.5560255433602664\n",
      "Epoch 99, Loss: 0.5560125454904067\n",
      "Epoch 100, Loss: 0.5559991453064723\n",
      "Epoch 101, Loss: 0.5559846191422867\n",
      "Epoch 102, Loss: 0.5559681092402717\n",
      "Epoch 103, Loss: 0.5559489721494392\n",
      "Epoch 104, Loss: 0.5559269127526503\n",
      "Epoch 105, Loss: 0.555902037923515\n",
      "Epoch 106, Loss: 0.5558747225778521\n",
      "Epoch 107, Loss: 0.5558446178501351\n",
      "Epoch 108, Loss: 0.5558111334727835\n",
      "Epoch 109, Loss: 0.5557736789808643\n",
      "Epoch 110, Loss: 0.5557320122495503\n",
      "Epoch 111, Loss: 0.5556856764627359\n",
      "Epoch 112, Loss: 0.5556341072683505\n",
      "Epoch 113, Loss: 0.5555769008933362\n",
      "Epoch 114, Loss: 0.5555134386416539\n",
      "Epoch 115, Loss: 0.5554424574755127\n",
      "Epoch 116, Loss: 0.5553635252102646\n",
      "Epoch 117, Loss: 0.5552737402068127\n",
      "Epoch 118, Loss: 0.5551655817898301\n",
      "Epoch 119, Loss: 0.5550291325681418\n",
      "Epoch 120, Loss: 0.5548641568263297\n",
      "Epoch 121, Loss: 0.5546776676649747\n",
      "Epoch 122, Loss: 0.5544710946043441\n",
      "Epoch 123, Loss: 0.5542501686639663\n",
      "Epoch 124, Loss: 0.5540197140546287\n",
      "Epoch 125, Loss: 0.5537690900779934\n",
      "Epoch 126, Loss: 0.5534903273525558\n",
      "Epoch 127, Loss: 0.5531783730138953\n",
      "Epoch 128, Loss: 0.5528284269187423\n",
      "Epoch 129, Loss: 0.5524360741446814\n",
      "Epoch 130, Loss: 0.5519967701064167\n",
      "Epoch 131, Loss: 0.5515040801667722\n",
      "Epoch 132, Loss: 0.5509532903268192\n",
      "Epoch 133, Loss: 0.5503421412840784\n",
      "Epoch 134, Loss: 0.5496666906168655\n",
      "Epoch 135, Loss: 0.5489235248665209\n",
      "Epoch 136, Loss: 0.548106904117173\n",
      "Epoch 137, Loss: 0.5472131228806547\n",
      "Epoch 138, Loss: 0.5462369466396069\n",
      "Epoch 139, Loss: 0.5451806933848262\n",
      "Epoch 140, Loss: 0.5440460604879559\n",
      "Epoch 141, Loss: 0.5428321172477882\n",
      "Epoch 142, Loss: 0.5415406691899683\n",
      "Epoch 143, Loss: 0.5401840429242855\n",
      "Epoch 144, Loss: 0.5387775386666768\n",
      "Epoch 145, Loss: 0.5373385963292628\n",
      "Epoch 146, Loss: 0.535858028291711\n",
      "Epoch 147, Loss: 0.5343951082071394\n",
      "Epoch 148, Loss: 0.5330299403600622\n",
      "Epoch 149, Loss: 0.531832824092722\n",
      "Epoch 150, Loss: 0.530815451673653\n",
      "Epoch 151, Loss: 0.5299222566608021\n",
      "Epoch 152, Loss: 0.5291019094697668\n",
      "Epoch 153, Loss: 0.5283033611518506\n",
      "Epoch 154, Loss: 0.5274776995044459\n",
      "Epoch 155, Loss: 0.5266030089420249\n",
      "Epoch 156, Loss: 0.5256978097715824\n",
      "Epoch 157, Loss: 0.5248043944766523\n",
      "Epoch 158, Loss: 0.5239636637705359\n",
      "Epoch 159, Loss: 0.5232036124972356\n",
      "Epoch 160, Loss: 0.5225422163157575\n",
      "Epoch 161, Loss: 0.5219573258663571\n",
      "Epoch 162, Loss: 0.5214188495287696\n",
      "Epoch 163, Loss: 0.5208931761376874\n",
      "Epoch 164, Loss: 0.5203596695147513\n",
      "Epoch 165, Loss: 0.5198208568176909\n",
      "Epoch 166, Loss: 0.5192980135197424\n",
      "Epoch 167, Loss: 0.5188104892990915\n",
      "Epoch 168, Loss: 0.518392332706662\n",
      "Epoch 169, Loss: 0.5180159534332143\n",
      "Epoch 170, Loss: 0.5176629626722316\n",
      "Epoch 171, Loss: 0.5173206768691636\n",
      "Epoch 172, Loss: 0.5169780491479861\n",
      "Epoch 173, Loss: 0.5166455197877556\n",
      "Epoch 174, Loss: 0.5163182309115127\n",
      "Epoch 175, Loss: 0.5160093320106196\n",
      "Epoch 176, Loss: 0.5157214276863118\n",
      "Epoch 177, Loss: 0.5154684869604258\n",
      "Epoch 178, Loss: 0.5152422611538278\n",
      "Epoch 179, Loss: 0.5150325724106398\n",
      "Epoch 180, Loss: 0.5148218720437352\n",
      "Epoch 181, Loss: 0.5146134887642079\n",
      "Epoch 182, Loss: 0.5144157390290526\n",
      "Epoch 183, Loss: 0.5142292726147735\n",
      "Epoch 184, Loss: 0.5140585078864183\n",
      "Epoch 185, Loss: 0.5139022716578158\n",
      "Epoch 186, Loss: 0.5137547763314708\n",
      "Epoch 187, Loss: 0.5136043663772919\n",
      "Epoch 188, Loss: 0.5134387049135545\n",
      "Epoch 189, Loss: 0.5132591997632995\n",
      "Epoch 190, Loss: 0.5130859049726983\n",
      "Epoch 191, Loss: 0.5129194950249929\n",
      "Epoch 192, Loss: 0.5127691306605122\n",
      "Epoch 193, Loss: 0.5126239545300345\n",
      "Epoch 194, Loss: 0.5124834185918494\n",
      "Epoch 195, Loss: 0.5123420297419876\n",
      "Epoch 196, Loss: 0.512204383865075\n",
      "Epoch 197, Loss: 0.5120755764234327\n",
      "Epoch 198, Loss: 0.5119580881223694\n",
      "Epoch 199, Loss: 0.5118426689771424\n",
      "Epoch 200, Loss: 0.511725156321719\n",
      "Epoch 201, Loss: 0.5116072380343538\n",
      "Epoch 202, Loss: 0.5114839903487867\n",
      "Epoch 203, Loss: 0.5113629567498209\n",
      "Epoch 204, Loss: 0.5112571672902512\n",
      "Epoch 205, Loss: 0.5111583232526251\n",
      "Epoch 206, Loss: 0.5110748841253712\n",
      "Epoch 207, Loss: 0.5109891859504114\n",
      "Epoch 208, Loss: 0.5108952484392993\n",
      "Epoch 209, Loss: 0.5107975012620287\n",
      "Epoch 210, Loss: 0.5107037035591732\n",
      "Epoch 211, Loss: 0.5106119022533886\n",
      "Epoch 212, Loss: 0.5105206682035901\n",
      "Epoch 213, Loss: 0.510425447531186\n",
      "Epoch 214, Loss: 0.5103320194302635\n",
      "Epoch 215, Loss: 0.5102460212645847\n",
      "Epoch 216, Loss: 0.5101601546460869\n",
      "Epoch 217, Loss: 0.5100708555573237\n",
      "Epoch 218, Loss: 0.5099753463620518\n",
      "Epoch 219, Loss: 0.5098708471684141\n",
      "Epoch 220, Loss: 0.509784391211239\n",
      "Epoch 221, Loss: 0.5096918980860681\n",
      "Epoch 222, Loss: 0.5095952651851149\n",
      "Epoch 223, Loss: 0.5095051359323953\n",
      "Epoch 224, Loss: 0.5094099009440181\n",
      "Epoch 225, Loss: 0.5093068071366218\n",
      "Epoch 226, Loss: 0.5091962009059716\n",
      "Epoch 227, Loss: 0.5090998251516611\n",
      "Epoch 228, Loss: 0.5090164291582044\n",
      "Epoch 229, Loss: 0.5089401050207231\n",
      "Epoch 230, Loss: 0.5088695381937793\n",
      "Epoch 231, Loss: 0.5087918155178337\n",
      "Epoch 232, Loss: 0.5087125870822096\n",
      "Epoch 233, Loss: 0.5086387075310066\n",
      "Epoch 234, Loss: 0.5085647879468541\n",
      "Epoch 235, Loss: 0.5084850552574891\n",
      "Epoch 236, Loss: 0.5084014411805298\n",
      "Epoch 237, Loss: 0.5083209206936506\n",
      "Epoch 238, Loss: 0.5082387748957279\n",
      "Epoch 239, Loss: 0.5081538300353086\n",
      "Epoch 240, Loss: 0.5080678151270656\n",
      "Epoch 241, Loss: 0.507984689716475\n",
      "Epoch 242, Loss: 0.5079028709401081\n",
      "Epoch 243, Loss: 0.5078200119636693\n",
      "Epoch 244, Loss: 0.5077354666162118\n",
      "Epoch 245, Loss: 0.5076507310693534\n",
      "Epoch 246, Loss: 0.5075655997211835\n",
      "Epoch 247, Loss: 0.5074793382958065\n",
      "Epoch 248, Loss: 0.5073943250311707\n",
      "Epoch 249, Loss: 0.5073108542832604\n",
      "Epoch 250, Loss: 0.5072276635758439\n",
      "Epoch 251, Loss: 0.5071446355168729\n",
      "Epoch 252, Loss: 0.5070586845134968\n",
      "Epoch 253, Loss: 0.506967516451016\n",
      "Epoch 254, Loss: 0.5068752736609458\n",
      "Epoch 255, Loss: 0.5067777508390623\n",
      "Epoch 256, Loss: 0.5066873556804816\n",
      "Epoch 257, Loss: 0.5065959148929011\n",
      "Epoch 258, Loss: 0.5065056932191507\n",
      "Epoch 259, Loss: 0.5064135722825925\n",
      "Epoch 260, Loss: 0.5063232592569779\n",
      "Epoch 261, Loss: 0.5062266897792478\n",
      "Epoch 262, Loss: 0.5061344591793905\n",
      "Epoch 263, Loss: 0.50604945555161\n",
      "Epoch 264, Loss: 0.505962434970646\n",
      "Epoch 265, Loss: 0.5058736320460143\n",
      "Epoch 266, Loss: 0.5057817495282911\n",
      "Epoch 267, Loss: 0.5056893493765626\n",
      "Epoch 268, Loss: 0.5056024731214162\n",
      "Epoch 269, Loss: 0.5055145797117351\n",
      "Epoch 270, Loss: 0.5054241944947744\n",
      "Epoch 271, Loss: 0.5053363585398329\n",
      "Epoch 272, Loss: 0.5052482123874183\n",
      "Epoch 273, Loss: 0.5051545937130764\n",
      "Epoch 274, Loss: 0.5050641440737825\n",
      "Epoch 275, Loss: 0.5049798455323944\n",
      "Epoch 276, Loss: 0.5048913715160941\n",
      "Epoch 277, Loss: 0.5048017307600194\n",
      "Epoch 278, Loss: 0.5047116607457235\n",
      "Epoch 279, Loss: 0.5046227853578545\n",
      "Epoch 280, Loss: 0.5045299071397156\n",
      "Epoch 281, Loss: 0.504435682510658\n",
      "Epoch 282, Loss: 0.50434096754519\n",
      "Epoch 283, Loss: 0.5042477714572545\n",
      "Epoch 284, Loss: 0.5041532872003653\n",
      "Epoch 285, Loss: 0.5040572184258193\n",
      "Epoch 286, Loss: 0.5039604512717234\n",
      "Epoch 287, Loss: 0.5038658244159436\n",
      "Epoch 288, Loss: 0.5037663879284634\n",
      "Epoch 289, Loss: 0.5036658963215\n",
      "Epoch 290, Loss: 0.5035702672034789\n",
      "Epoch 291, Loss: 0.5034727553295367\n",
      "Epoch 292, Loss: 0.5033726787452044\n",
      "Epoch 293, Loss: 0.5032742403354097\n",
      "Epoch 294, Loss: 0.5031747165544377\n",
      "Epoch 295, Loss: 0.5030723295423277\n",
      "Epoch 296, Loss: 0.502972884313746\n",
      "Epoch 297, Loss: 0.5028687968012541\n",
      "Epoch 298, Loss: 0.5027579894073623\n",
      "Epoch 299, Loss: 0.5026494106293443\n",
      "Epoch 300, Loss: 0.502543328775265\n",
      "Training completed.\n"
     ]
    }
   ],
   "source": [
    "model = train_model(num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare input_test_data and target_test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([349, 37])\n"
     ]
    }
   ],
   "source": [
    "input_test_data = X_test_tensor.float()\n",
    "\n",
    "# input_test_data = input_test_data.view(input_test_data.shape[1], -1)\n",
    "print(input_test_data.shape)\n",
    "\n",
    "target_test_labels = y_test_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(trained_model):\n",
    "  with torch.no_grad():\n",
    "    test_pred = trained_model(input_test_data)\n",
    "    test_loss = criterion(test_pred.float(), target_test_labels)\n",
    "\n",
    "    # Separate the output into valence and arousal\n",
    "    valence_pred = test_pred[:, 0]\n",
    "    arousal_pred = test_pred[:, 1]\n",
    "        \n",
    "    valence_target = target_test_labels[:, 0]\n",
    "    arousal_target = target_test_labels[:, 1]\n",
    "\n",
    "     # Calculate RMSE for valence and arousal separately\n",
    "    valence_rmse = math.sqrt(mean_squared_error(valence_pred, valence_target))\n",
    "    arousal_rmse = math.sqrt(mean_squared_error(arousal_pred, arousal_target))\n",
    "\n",
    "  rmse = math.sqrt(test_loss.item())\n",
    "  print(f'Test RMSE: {rmse}')\n",
    "\n",
    "  print(f'Valence RMSE: {valence_rmse}')\n",
    "  print(f'Arousal RMSE: {arousal_rmse}')\n",
    "\n",
    "  metric = R2Score(multioutput=\"raw_values\")\n",
    "  metric.update(test_pred, target_test_labels)\n",
    "  r2_score = metric.compute()\n",
    "  print(f'Test R^2 score: {r2_score}')\n",
    "  return test_pred, rmse, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.2617223227763994\n",
      "Valence RMSE: 0.24813536391514343\n",
      "Arousal RMSE: 0.2746379246456085\n",
      "Test R^2 score: tensor([0.2538, 0.2532], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "test_pred, rmse, r2_score = test_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), '../../models/deam_feedforward_nn_essentia_best_overall_mean_normalised.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "True values (test set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_valence = test_pred[:, 0]\n",
    "pred_arousal = test_pred[1]\n",
    "real_valence = target_test_labels[0]\n",
    "real_arousal = target_test_labels[1]\n",
    "\n",
    "\n",
    "metric = R2Score(multioutput='raw_values')\n",
    "metric.update(test_pred, target_test_labels)\n",
    "print(metric.compute())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse relationship between epochs and r^2 score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create lists to store the epochs and R^2 scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs_list = [i for i in range(1, 301)]\n",
    "r2_scores_list = []\n",
    "rmse_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conduct training and testing for each num_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for num_epochs in num_epochs_list:\n",
    "  # Set the seed\n",
    "  torch.manual_seed(seed)\n",
    "\n",
    "  print(f'Num of epochs: {num_epochs}')\n",
    "  \n",
    "  model = train_model(num_epochs)\n",
    "\n",
    "  print(\"Training completed.\")\n",
    "  print(\"Testing model...\")\n",
    "\n",
    "  test_pred, rmse, r2_score = test_model(model)\n",
    "  r2_scores_list.append(r2_score)\n",
    "  rmse_list.append(rmse)\n",
    "\n",
    "print(\"Completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the graph to visualise the relationship between epochs and r^2 score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_scores_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the line graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(num_epochs_list, r2_scores_list, color='b', linestyle='-')\n",
    "plt.title('num_epochs vs. R^2 score')\n",
    "plt.xlabel('num_epochs')\n",
    "plt.ylabel('r^2 score') \n",
    "plt.grid(True)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_r2_score = max(r2_scores_list)\n",
    "corresponding_rmse = rmse_list[r2_scores_list.index(max_r2_score)]\n",
    "corresponding_num_epochs = num_epochs_list[r2_scores_list.index(max_r2_score)]\n",
    "\n",
    "print(f'Max R^2 score: {max_r2_score}')\n",
    "print(f'Corresponding RMSE: {corresponding_rmse}')\n",
    "print(f'Corresponding num_epochs: {corresponding_num_epochs}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
