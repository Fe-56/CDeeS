{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEAM Dataset - Feed Forward Neural Network\n",
    "## Essentia Best Overall & openSMILE emobase Featureset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torcheval.metrics import R2Score\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import math\n",
    "\n",
    "import sys\n",
    "sys.path.insert(1, '../../utils')\n",
    "from paths import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import annotations dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song_id</th>\n",
       "      <th>valence_mean_mapped</th>\n",
       "      <th>arousal_mean_mapped</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.475</td>\n",
       "      <td>-0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.375</td>\n",
       "      <td>-0.425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>-0.150</td>\n",
       "      <td>0.075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1739</th>\n",
       "      <td>1996</td>\n",
       "      <td>-0.275</td>\n",
       "      <td>0.225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1740</th>\n",
       "      <td>1997</td>\n",
       "      <td>0.075</td>\n",
       "      <td>-0.275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1741</th>\n",
       "      <td>1998</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1742</th>\n",
       "      <td>1999</td>\n",
       "      <td>-0.100</td>\n",
       "      <td>0.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1743</th>\n",
       "      <td>2000</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1744 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      song_id  valence_mean_mapped  arousal_mean_mapped\n",
       "0           2               -0.475               -0.500\n",
       "1           3               -0.375               -0.425\n",
       "2           4                0.175                0.125\n",
       "3           5               -0.150                0.075\n",
       "4           7                0.200                0.350\n",
       "...       ...                  ...                  ...\n",
       "1739     1996               -0.275                0.225\n",
       "1740     1997                0.075               -0.275\n",
       "1741     1998                0.350                0.300\n",
       "1742     1999               -0.100                0.100\n",
       "1743     2000                0.200                0.250\n",
       "\n",
       "[1744 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_annotations = pd.read_csv(get_deam_path('processed/annotations/deam_static_annotations.csv'))\n",
    "df_annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the featureset\n",
    "\n",
    "This is where you should change between normalised and standardised, and untouched featuresets!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song_id</th>\n",
       "      <th>lowlevel.melbands_kurtosis.dmean</th>\n",
       "      <th>lowlevel.melbands_kurtosis.dmean2</th>\n",
       "      <th>lowlevel.melbands_kurtosis.dvar</th>\n",
       "      <th>lowlevel.melbands_kurtosis.dvar2</th>\n",
       "      <th>lowlevel.melbands_kurtosis.max</th>\n",
       "      <th>lowlevel.melbands_kurtosis.mean</th>\n",
       "      <th>lowlevel.melbands_kurtosis.median</th>\n",
       "      <th>lowlevel.melbands_kurtosis.min</th>\n",
       "      <th>lowlevel.melbands_kurtosis.stdev</th>\n",
       "      <th>...</th>\n",
       "      <th>F0env_sma_de_linregerrQ</th>\n",
       "      <th>F0env_sma_de_stddev</th>\n",
       "      <th>F0env_sma_de_skewness</th>\n",
       "      <th>F0env_sma_de_kurtosis</th>\n",
       "      <th>F0env_sma_de_quartile1</th>\n",
       "      <th>F0env_sma_de_quartile2</th>\n",
       "      <th>F0env_sma_de_quartile3</th>\n",
       "      <th>F0env_sma_de_iqr1-2</th>\n",
       "      <th>F0env_sma_de_iqr2-3</th>\n",
       "      <th>F0env_sma_de_iqr1-3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.005020</td>\n",
       "      <td>0.004055</td>\n",
       "      <td>1.866850e-06</td>\n",
       "      <td>1.524876e-06</td>\n",
       "      <td>0.001798</td>\n",
       "      <td>0.023745</td>\n",
       "      <td>0.027549</td>\n",
       "      <td>0.131211</td>\n",
       "      <td>0.003891</td>\n",
       "      <td>...</td>\n",
       "      <td>0.427306</td>\n",
       "      <td>0.633121</td>\n",
       "      <td>0.052970</td>\n",
       "      <td>0.008991</td>\n",
       "      <td>0.546204</td>\n",
       "      <td>0.931732</td>\n",
       "      <td>0.403270</td>\n",
       "      <td>0.453796</td>\n",
       "      <td>0.401456</td>\n",
       "      <td>0.428889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0.009253</td>\n",
       "      <td>0.007287</td>\n",
       "      <td>3.311122e-06</td>\n",
       "      <td>2.524975e-06</td>\n",
       "      <td>0.002593</td>\n",
       "      <td>0.082083</td>\n",
       "      <td>0.140294</td>\n",
       "      <td>0.151787</td>\n",
       "      <td>0.005776</td>\n",
       "      <td>...</td>\n",
       "      <td>0.141595</td>\n",
       "      <td>0.340520</td>\n",
       "      <td>0.068615</td>\n",
       "      <td>0.031988</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.931732</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0.004331</td>\n",
       "      <td>0.003332</td>\n",
       "      <td>9.901372e-07</td>\n",
       "      <td>7.146511e-07</td>\n",
       "      <td>0.000979</td>\n",
       "      <td>0.018062</td>\n",
       "      <td>0.026788</td>\n",
       "      <td>0.102714</td>\n",
       "      <td>0.002002</td>\n",
       "      <td>...</td>\n",
       "      <td>0.399049</td>\n",
       "      <td>0.609771</td>\n",
       "      <td>0.048627</td>\n",
       "      <td>0.007233</td>\n",
       "      <td>0.706684</td>\n",
       "      <td>0.931732</td>\n",
       "      <td>0.238975</td>\n",
       "      <td>0.293316</td>\n",
       "      <td>0.237900</td>\n",
       "      <td>0.266529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>0.003204</td>\n",
       "      <td>0.002534</td>\n",
       "      <td>4.937064e-07</td>\n",
       "      <td>4.159568e-07</td>\n",
       "      <td>0.000692</td>\n",
       "      <td>0.016018</td>\n",
       "      <td>0.024134</td>\n",
       "      <td>0.052080</td>\n",
       "      <td>0.001598</td>\n",
       "      <td>...</td>\n",
       "      <td>0.416902</td>\n",
       "      <td>0.624603</td>\n",
       "      <td>0.046268</td>\n",
       "      <td>0.006583</td>\n",
       "      <td>0.578416</td>\n",
       "      <td>0.931732</td>\n",
       "      <td>0.412816</td>\n",
       "      <td>0.421584</td>\n",
       "      <td>0.410959</td>\n",
       "      <td>0.417262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>0.025812</td>\n",
       "      <td>0.019064</td>\n",
       "      <td>1.650024e-05</td>\n",
       "      <td>1.234842e-05</td>\n",
       "      <td>0.003508</td>\n",
       "      <td>0.107675</td>\n",
       "      <td>0.179964</td>\n",
       "      <td>0.143354</td>\n",
       "      <td>0.008974</td>\n",
       "      <td>...</td>\n",
       "      <td>0.291508</td>\n",
       "      <td>0.512783</td>\n",
       "      <td>0.052501</td>\n",
       "      <td>0.011769</td>\n",
       "      <td>0.740093</td>\n",
       "      <td>0.931732</td>\n",
       "      <td>0.256946</td>\n",
       "      <td>0.259907</td>\n",
       "      <td>0.255790</td>\n",
       "      <td>0.258448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1739</th>\n",
       "      <td>1996</td>\n",
       "      <td>0.003420</td>\n",
       "      <td>0.002785</td>\n",
       "      <td>5.455507e-07</td>\n",
       "      <td>4.706971e-07</td>\n",
       "      <td>0.000535</td>\n",
       "      <td>0.013781</td>\n",
       "      <td>0.024485</td>\n",
       "      <td>0.111224</td>\n",
       "      <td>0.001102</td>\n",
       "      <td>...</td>\n",
       "      <td>0.108314</td>\n",
       "      <td>0.291082</td>\n",
       "      <td>0.272948</td>\n",
       "      <td>0.173102</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.931732</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1740</th>\n",
       "      <td>1997</td>\n",
       "      <td>0.003040</td>\n",
       "      <td>0.002581</td>\n",
       "      <td>4.429354e-07</td>\n",
       "      <td>4.051469e-07</td>\n",
       "      <td>0.000492</td>\n",
       "      <td>0.012825</td>\n",
       "      <td>0.018914</td>\n",
       "      <td>0.078724</td>\n",
       "      <td>0.001181</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023071</td>\n",
       "      <td>0.109289</td>\n",
       "      <td>0.090879</td>\n",
       "      <td>0.028913</td>\n",
       "      <td>0.962139</td>\n",
       "      <td>0.931732</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.037861</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1741</th>\n",
       "      <td>1998</td>\n",
       "      <td>0.004671</td>\n",
       "      <td>0.003816</td>\n",
       "      <td>2.087614e-06</td>\n",
       "      <td>1.831211e-06</td>\n",
       "      <td>0.002208</td>\n",
       "      <td>0.016787</td>\n",
       "      <td>0.025345</td>\n",
       "      <td>0.058193</td>\n",
       "      <td>0.002020</td>\n",
       "      <td>...</td>\n",
       "      <td>0.139224</td>\n",
       "      <td>0.337426</td>\n",
       "      <td>0.046131</td>\n",
       "      <td>0.017807</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.931732</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1742</th>\n",
       "      <td>1999</td>\n",
       "      <td>0.004212</td>\n",
       "      <td>0.003390</td>\n",
       "      <td>7.172558e-07</td>\n",
       "      <td>5.847591e-07</td>\n",
       "      <td>0.001355</td>\n",
       "      <td>0.022245</td>\n",
       "      <td>0.041198</td>\n",
       "      <td>0.244618</td>\n",
       "      <td>0.001735</td>\n",
       "      <td>...</td>\n",
       "      <td>0.096113</td>\n",
       "      <td>0.271372</td>\n",
       "      <td>0.160770</td>\n",
       "      <td>0.069559</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.931732</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1743</th>\n",
       "      <td>2000</td>\n",
       "      <td>0.006225</td>\n",
       "      <td>0.004963</td>\n",
       "      <td>1.643816e-06</td>\n",
       "      <td>1.337893e-06</td>\n",
       "      <td>0.001744</td>\n",
       "      <td>0.026978</td>\n",
       "      <td>0.035143</td>\n",
       "      <td>0.008661</td>\n",
       "      <td>0.003243</td>\n",
       "      <td>...</td>\n",
       "      <td>0.204641</td>\n",
       "      <td>0.420434</td>\n",
       "      <td>0.037200</td>\n",
       "      <td>0.008816</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.931732</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1744 rows × 1125 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      song_id  lowlevel.melbands_kurtosis.dmean  \\\n",
       "0           2                          0.005020   \n",
       "1           3                          0.009253   \n",
       "2           4                          0.004331   \n",
       "3           5                          0.003204   \n",
       "4           7                          0.025812   \n",
       "...       ...                               ...   \n",
       "1739     1996                          0.003420   \n",
       "1740     1997                          0.003040   \n",
       "1741     1998                          0.004671   \n",
       "1742     1999                          0.004212   \n",
       "1743     2000                          0.006225   \n",
       "\n",
       "      lowlevel.melbands_kurtosis.dmean2  lowlevel.melbands_kurtosis.dvar  \\\n",
       "0                              0.004055                     1.866850e-06   \n",
       "1                              0.007287                     3.311122e-06   \n",
       "2                              0.003332                     9.901372e-07   \n",
       "3                              0.002534                     4.937064e-07   \n",
       "4                              0.019064                     1.650024e-05   \n",
       "...                                 ...                              ...   \n",
       "1739                           0.002785                     5.455507e-07   \n",
       "1740                           0.002581                     4.429354e-07   \n",
       "1741                           0.003816                     2.087614e-06   \n",
       "1742                           0.003390                     7.172558e-07   \n",
       "1743                           0.004963                     1.643816e-06   \n",
       "\n",
       "      lowlevel.melbands_kurtosis.dvar2  lowlevel.melbands_kurtosis.max  \\\n",
       "0                         1.524876e-06                        0.001798   \n",
       "1                         2.524975e-06                        0.002593   \n",
       "2                         7.146511e-07                        0.000979   \n",
       "3                         4.159568e-07                        0.000692   \n",
       "4                         1.234842e-05                        0.003508   \n",
       "...                                ...                             ...   \n",
       "1739                      4.706971e-07                        0.000535   \n",
       "1740                      4.051469e-07                        0.000492   \n",
       "1741                      1.831211e-06                        0.002208   \n",
       "1742                      5.847591e-07                        0.001355   \n",
       "1743                      1.337893e-06                        0.001744   \n",
       "\n",
       "      lowlevel.melbands_kurtosis.mean  lowlevel.melbands_kurtosis.median  \\\n",
       "0                            0.023745                           0.027549   \n",
       "1                            0.082083                           0.140294   \n",
       "2                            0.018062                           0.026788   \n",
       "3                            0.016018                           0.024134   \n",
       "4                            0.107675                           0.179964   \n",
       "...                               ...                                ...   \n",
       "1739                         0.013781                           0.024485   \n",
       "1740                         0.012825                           0.018914   \n",
       "1741                         0.016787                           0.025345   \n",
       "1742                         0.022245                           0.041198   \n",
       "1743                         0.026978                           0.035143   \n",
       "\n",
       "      lowlevel.melbands_kurtosis.min  lowlevel.melbands_kurtosis.stdev  ...  \\\n",
       "0                           0.131211                          0.003891  ...   \n",
       "1                           0.151787                          0.005776  ...   \n",
       "2                           0.102714                          0.002002  ...   \n",
       "3                           0.052080                          0.001598  ...   \n",
       "4                           0.143354                          0.008974  ...   \n",
       "...                              ...                               ...  ...   \n",
       "1739                        0.111224                          0.001102  ...   \n",
       "1740                        0.078724                          0.001181  ...   \n",
       "1741                        0.058193                          0.002020  ...   \n",
       "1742                        0.244618                          0.001735  ...   \n",
       "1743                        0.008661                          0.003243  ...   \n",
       "\n",
       "      F0env_sma_de_linregerrQ  F0env_sma_de_stddev  F0env_sma_de_skewness  \\\n",
       "0                    0.427306             0.633121               0.052970   \n",
       "1                    0.141595             0.340520               0.068615   \n",
       "2                    0.399049             0.609771               0.048627   \n",
       "3                    0.416902             0.624603               0.046268   \n",
       "4                    0.291508             0.512783               0.052501   \n",
       "...                       ...                  ...                    ...   \n",
       "1739                 0.108314             0.291082               0.272948   \n",
       "1740                 0.023071             0.109289               0.090879   \n",
       "1741                 0.139224             0.337426               0.046131   \n",
       "1742                 0.096113             0.271372               0.160770   \n",
       "1743                 0.204641             0.420434               0.037200   \n",
       "\n",
       "      F0env_sma_de_kurtosis  F0env_sma_de_quartile1  F0env_sma_de_quartile2  \\\n",
       "0                  0.008991                0.546204                0.931732   \n",
       "1                  0.031988                1.000000                0.931732   \n",
       "2                  0.007233                0.706684                0.931732   \n",
       "3                  0.006583                0.578416                0.931732   \n",
       "4                  0.011769                0.740093                0.931732   \n",
       "...                     ...                     ...                     ...   \n",
       "1739               0.173102                1.000000                0.931732   \n",
       "1740               0.028913                0.962139                0.931732   \n",
       "1741               0.017807                1.000000                0.931732   \n",
       "1742               0.069559                1.000000                0.931732   \n",
       "1743               0.008816                1.000000                0.931732   \n",
       "\n",
       "      F0env_sma_de_quartile3  F0env_sma_de_iqr1-2  F0env_sma_de_iqr2-3  \\\n",
       "0                   0.403270             0.453796             0.401456   \n",
       "1                   0.000000             0.000000             0.000000   \n",
       "2                   0.238975             0.293316             0.237900   \n",
       "3                   0.412816             0.421584             0.410959   \n",
       "4                   0.256946             0.259907             0.255790   \n",
       "...                      ...                  ...                  ...   \n",
       "1739                0.000000             0.000000             0.000000   \n",
       "1740                0.000000             0.037861             0.000000   \n",
       "1741                0.000000             0.000000             0.000000   \n",
       "1742                0.000000             0.000000             0.000000   \n",
       "1743                0.000000             0.000000             0.000000   \n",
       "\n",
       "      F0env_sma_de_iqr1-3  \n",
       "0                0.428889  \n",
       "1                0.000000  \n",
       "2                0.266529  \n",
       "3                0.417262  \n",
       "4                0.258448  \n",
       "...                   ...  \n",
       "1739             0.000000  \n",
       "1740             0.019198  \n",
       "1741             0.000000  \n",
       "1742             0.000000  \n",
       "1743             0.000000  \n",
       "\n",
       "[1744 rows x 1125 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_essentia_best_overall_opensmile_emnobase_features = pd.read_csv(get_deam_path('processed/features/integrated/normalised_essentia_best_overall_opensmile_emobase_features.csv'))\n",
    "\n",
    "# drop Unnamed:0 column\n",
    "df_essentia_best_overall_opensmile_emnobase_features = df_essentia_best_overall_opensmile_emnobase_features[df_essentia_best_overall_opensmile_emnobase_features.columns[1:]]\n",
    "\n",
    "df_essentia_best_overall_opensmile_emnobase_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1744 entries, 0 to 1743\n",
      "Data columns (total 1125 columns):\n",
      " #     Column                                     Dtype  \n",
      "---    ------                                     -----  \n",
      " 0     song_id                                    int64  \n",
      " 1     lowlevel.melbands_kurtosis.dmean           float64\n",
      " 2     lowlevel.melbands_kurtosis.dmean2          float64\n",
      " 3     lowlevel.melbands_kurtosis.dvar            float64\n",
      " 4     lowlevel.melbands_kurtosis.dvar2           float64\n",
      " 5     lowlevel.melbands_kurtosis.max             float64\n",
      " 6     lowlevel.melbands_kurtosis.mean            float64\n",
      " 7     lowlevel.melbands_kurtosis.median          float64\n",
      " 8     lowlevel.melbands_kurtosis.min             float64\n",
      " 9     lowlevel.melbands_kurtosis.stdev           float64\n",
      " 10    lowlevel.melbands_kurtosis.var             float64\n",
      " 11    lowlevel.melbands_skewness.dmean           float64\n",
      " 12    lowlevel.melbands_skewness.dmean2          float64\n",
      " 13    lowlevel.melbands_skewness.dvar            float64\n",
      " 14    lowlevel.melbands_skewness.dvar2           float64\n",
      " 15    lowlevel.melbands_skewness.max             float64\n",
      " 16    lowlevel.melbands_skewness.mean            float64\n",
      " 17    lowlevel.melbands_skewness.median          float64\n",
      " 18    lowlevel.melbands_skewness.min             float64\n",
      " 19    lowlevel.melbands_skewness.stdev           float64\n",
      " 20    lowlevel.melbands_skewness.var             float64\n",
      " 21    lowlevel.spectral_energy.dmean             float64\n",
      " 22    lowlevel.spectral_energy.dmean2            float64\n",
      " 23    lowlevel.spectral_energy.dvar              float64\n",
      " 24    lowlevel.spectral_energy.dvar2             float64\n",
      " 25    lowlevel.spectral_energy.max               float64\n",
      " 26    lowlevel.spectral_energy.mean              float64\n",
      " 27    lowlevel.spectral_energy.median            float64\n",
      " 28    lowlevel.spectral_energy.min               float64\n",
      " 29    lowlevel.spectral_energy.stdev             float64\n",
      " 30    lowlevel.spectral_energy.var               float64\n",
      " 31    tonal.chords_strength.dmean                float64\n",
      " 32    tonal.chords_strength.dmean2               float64\n",
      " 33    tonal.chords_strength.dvar                 float64\n",
      " 34    tonal.chords_strength.dvar2                float64\n",
      " 35    tonal.chords_strength.max                  float64\n",
      " 36    tonal.chords_strength.mean                 float64\n",
      " 37    tonal.chords_strength.median               float64\n",
      " 38    tonal.chords_strength.min                  float64\n",
      " 39    tonal.chords_strength.stdev                float64\n",
      " 40    tonal.chords_strength.var                  float64\n",
      " 41    tonal.hpcp_entropy.dmean                   float64\n",
      " 42    tonal.hpcp_entropy.dmean2                  float64\n",
      " 43    tonal.hpcp_entropy.dvar                    float64\n",
      " 44    tonal.hpcp_entropy.dvar2                   float64\n",
      " 45    tonal.hpcp_entropy.max                     float64\n",
      " 46    tonal.hpcp_entropy.mean                    float64\n",
      " 47    tonal.hpcp_entropy.median                  float64\n",
      " 48    tonal.hpcp_entropy.min                     float64\n",
      " 49    tonal.hpcp_entropy.stdev                   float64\n",
      " 50    tonal.hpcp_entropy.var                     float64\n",
      " 51    tonal.key_edma.strength                    float64\n",
      " 52    tonal.key_temperley.strength               float64\n",
      " 53    rhythm.beats_loudness_band_ratio.dmean_0   float64\n",
      " 54    rhythm.beats_loudness_band_ratio.dmean_1   float64\n",
      " 55    rhythm.beats_loudness_band_ratio.dmean_2   float64\n",
      " 56    rhythm.beats_loudness_band_ratio.dmean_3   float64\n",
      " 57    rhythm.beats_loudness_band_ratio.dmean_4   float64\n",
      " 58    rhythm.beats_loudness_band_ratio.dmean_5   float64\n",
      " 59    rhythm.beats_loudness_band_ratio.dmean2_0  float64\n",
      " 60    rhythm.beats_loudness_band_ratio.dmean2_1  float64\n",
      " 61    rhythm.beats_loudness_band_ratio.dmean2_2  float64\n",
      " 62    rhythm.beats_loudness_band_ratio.dmean2_3  float64\n",
      " 63    rhythm.beats_loudness_band_ratio.dmean2_4  float64\n",
      " 64    rhythm.beats_loudness_band_ratio.dmean2_5  float64\n",
      " 65    rhythm.beats_loudness_band_ratio.dvar_0    float64\n",
      " 66    rhythm.beats_loudness_band_ratio.dvar_1    float64\n",
      " 67    rhythm.beats_loudness_band_ratio.dvar_2    float64\n",
      " 68    rhythm.beats_loudness_band_ratio.dvar_3    float64\n",
      " 69    rhythm.beats_loudness_band_ratio.dvar_4    float64\n",
      " 70    rhythm.beats_loudness_band_ratio.dvar_5    float64\n",
      " 71    rhythm.beats_loudness_band_ratio.dvar2_0   float64\n",
      " 72    rhythm.beats_loudness_band_ratio.dvar2_1   float64\n",
      " 73    rhythm.beats_loudness_band_ratio.dvar2_2   float64\n",
      " 74    rhythm.beats_loudness_band_ratio.dvar2_3   float64\n",
      " 75    rhythm.beats_loudness_band_ratio.dvar2_4   float64\n",
      " 76    rhythm.beats_loudness_band_ratio.dvar2_5   float64\n",
      " 77    rhythm.beats_loudness_band_ratio.max_0     float64\n",
      " 78    rhythm.beats_loudness_band_ratio.max_1     float64\n",
      " 79    rhythm.beats_loudness_band_ratio.max_2     float64\n",
      " 80    rhythm.beats_loudness_band_ratio.max_3     float64\n",
      " 81    rhythm.beats_loudness_band_ratio.max_4     float64\n",
      " 82    rhythm.beats_loudness_band_ratio.max_5     float64\n",
      " 83    rhythm.beats_loudness_band_ratio.mean_0    float64\n",
      " 84    rhythm.beats_loudness_band_ratio.mean_1    float64\n",
      " 85    rhythm.beats_loudness_band_ratio.mean_2    float64\n",
      " 86    rhythm.beats_loudness_band_ratio.mean_3    float64\n",
      " 87    rhythm.beats_loudness_band_ratio.mean_4    float64\n",
      " 88    rhythm.beats_loudness_band_ratio.mean_5    float64\n",
      " 89    rhythm.beats_loudness_band_ratio.median_0  float64\n",
      " 90    rhythm.beats_loudness_band_ratio.median_1  float64\n",
      " 91    rhythm.beats_loudness_band_ratio.median_2  float64\n",
      " 92    rhythm.beats_loudness_band_ratio.median_3  float64\n",
      " 93    rhythm.beats_loudness_band_ratio.median_4  float64\n",
      " 94    rhythm.beats_loudness_band_ratio.median_5  float64\n",
      " 95    rhythm.beats_loudness_band_ratio.min_0     float64\n",
      " 96    rhythm.beats_loudness_band_ratio.min_1     float64\n",
      " 97    rhythm.beats_loudness_band_ratio.min_2     float64\n",
      " 98    rhythm.beats_loudness_band_ratio.min_3     float64\n",
      " 99    rhythm.beats_loudness_band_ratio.min_4     float64\n",
      " 100   rhythm.beats_loudness_band_ratio.min_5     float64\n",
      " 101   rhythm.beats_loudness_band_ratio.stdev_0   float64\n",
      " 102   rhythm.beats_loudness_band_ratio.stdev_1   float64\n",
      " 103   rhythm.beats_loudness_band_ratio.stdev_2   float64\n",
      " 104   rhythm.beats_loudness_band_ratio.stdev_3   float64\n",
      " 105   rhythm.beats_loudness_band_ratio.stdev_4   float64\n",
      " 106   rhythm.beats_loudness_band_ratio.stdev_5   float64\n",
      " 107   rhythm.beats_loudness_band_ratio.var_0     float64\n",
      " 108   rhythm.beats_loudness_band_ratio.var_1     float64\n",
      " 109   rhythm.beats_loudness_band_ratio.var_2     float64\n",
      " 110   rhythm.beats_loudness_band_ratio.var_3     float64\n",
      " 111   rhythm.beats_loudness_band_ratio.var_4     float64\n",
      " 112   rhythm.beats_loudness_band_ratio.var_5     float64\n",
      " 113   tonal.chords_histogram_0                   float64\n",
      " 114   tonal.chords_histogram_1                   float64\n",
      " 115   tonal.chords_histogram_2                   float64\n",
      " 116   tonal.chords_histogram_3                   float64\n",
      " 117   tonal.chords_histogram_4                   float64\n",
      " 118   tonal.chords_histogram_5                   float64\n",
      " 119   tonal.chords_histogram_6                   float64\n",
      " 120   tonal.chords_histogram_7                   float64\n",
      " 121   tonal.chords_histogram_8                   float64\n",
      " 122   tonal.chords_histogram_9                   float64\n",
      " 123   tonal.chords_histogram_10                  float64\n",
      " 124   tonal.chords_histogram_11                  float64\n",
      " 125   tonal.chords_histogram_12                  float64\n",
      " 126   tonal.chords_histogram_13                  float64\n",
      " 127   tonal.chords_histogram_14                  float64\n",
      " 128   tonal.chords_histogram_15                  float64\n",
      " 129   tonal.chords_histogram_16                  float64\n",
      " 130   tonal.chords_histogram_17                  float64\n",
      " 131   tonal.chords_histogram_18                  float64\n",
      " 132   tonal.chords_histogram_19                  float64\n",
      " 133   tonal.chords_histogram_20                  float64\n",
      " 134   tonal.chords_histogram_21                  float64\n",
      " 135   tonal.chords_histogram_22                  float64\n",
      " 136   tonal.chords_histogram_23                  float64\n",
      " 137   pcm_intensity_sma_max                      float64\n",
      " 138   pcm_intensity_sma_min                      float64\n",
      " 139   pcm_intensity_sma_range                    float64\n",
      " 140   pcm_intensity_sma_maxPos                   float64\n",
      " 141   pcm_intensity_sma_minPos                   float64\n",
      " 142   pcm_intensity_sma_amean                    float64\n",
      " 143   pcm_intensity_sma_linregc1                 float64\n",
      " 144   pcm_intensity_sma_linregc2                 float64\n",
      " 145   pcm_intensity_sma_linregerrA               float64\n",
      " 146   pcm_intensity_sma_linregerrQ               float64\n",
      " 147   pcm_intensity_sma_stddev                   float64\n",
      " 148   pcm_intensity_sma_skewness                 float64\n",
      " 149   pcm_intensity_sma_kurtosis                 float64\n",
      " 150   pcm_intensity_sma_quartile1                float64\n",
      " 151   pcm_intensity_sma_quartile2                float64\n",
      " 152   pcm_intensity_sma_quartile3                float64\n",
      " 153   pcm_intensity_sma_iqr1-2                   float64\n",
      " 154   pcm_intensity_sma_iqr2-3                   float64\n",
      " 155   pcm_intensity_sma_iqr1-3                   float64\n",
      " 156   pcm_loudness_sma_max                       float64\n",
      " 157   pcm_loudness_sma_min                       float64\n",
      " 158   pcm_loudness_sma_range                     float64\n",
      " 159   pcm_loudness_sma_maxPos                    float64\n",
      " 160   pcm_loudness_sma_minPos                    float64\n",
      " 161   pcm_loudness_sma_amean                     float64\n",
      " 162   pcm_loudness_sma_linregc1                  float64\n",
      " 163   pcm_loudness_sma_linregc2                  float64\n",
      " 164   pcm_loudness_sma_linregerrA                float64\n",
      " 165   pcm_loudness_sma_linregerrQ                float64\n",
      " 166   pcm_loudness_sma_stddev                    float64\n",
      " 167   pcm_loudness_sma_skewness                  float64\n",
      " 168   pcm_loudness_sma_kurtosis                  float64\n",
      " 169   pcm_loudness_sma_quartile1                 float64\n",
      " 170   pcm_loudness_sma_quartile2                 float64\n",
      " 171   pcm_loudness_sma_quartile3                 float64\n",
      " 172   pcm_loudness_sma_iqr1-2                    float64\n",
      " 173   pcm_loudness_sma_iqr2-3                    float64\n",
      " 174   pcm_loudness_sma_iqr1-3                    float64\n",
      " 175   mfcc_sma[1]_max                            float64\n",
      " 176   mfcc_sma[1]_min                            float64\n",
      " 177   mfcc_sma[1]_range                          float64\n",
      " 178   mfcc_sma[1]_maxPos                         float64\n",
      " 179   mfcc_sma[1]_minPos                         float64\n",
      " 180   mfcc_sma[1]_amean                          float64\n",
      " 181   mfcc_sma[1]_linregc1                       float64\n",
      " 182   mfcc_sma[1]_linregc2                       float64\n",
      " 183   mfcc_sma[1]_linregerrA                     float64\n",
      " 184   mfcc_sma[1]_linregerrQ                     float64\n",
      " 185   mfcc_sma[1]_stddev                         float64\n",
      " 186   mfcc_sma[1]_skewness                       float64\n",
      " 187   mfcc_sma[1]_kurtosis                       float64\n",
      " 188   mfcc_sma[1]_quartile1                      float64\n",
      " 189   mfcc_sma[1]_quartile2                      float64\n",
      " 190   mfcc_sma[1]_quartile3                      float64\n",
      " 191   mfcc_sma[1]_iqr1-2                         float64\n",
      " 192   mfcc_sma[1]_iqr2-3                         float64\n",
      " 193   mfcc_sma[1]_iqr1-3                         float64\n",
      " 194   mfcc_sma[2]_max                            float64\n",
      " 195   mfcc_sma[2]_min                            float64\n",
      " 196   mfcc_sma[2]_range                          float64\n",
      " 197   mfcc_sma[2]_maxPos                         float64\n",
      " 198   mfcc_sma[2]_minPos                         float64\n",
      " 199   mfcc_sma[2]_amean                          float64\n",
      " 200   mfcc_sma[2]_linregc1                       float64\n",
      " 201   mfcc_sma[2]_linregc2                       float64\n",
      " 202   mfcc_sma[2]_linregerrA                     float64\n",
      " 203   mfcc_sma[2]_linregerrQ                     float64\n",
      " 204   mfcc_sma[2]_stddev                         float64\n",
      " 205   mfcc_sma[2]_skewness                       float64\n",
      " 206   mfcc_sma[2]_kurtosis                       float64\n",
      " 207   mfcc_sma[2]_quartile1                      float64\n",
      " 208   mfcc_sma[2]_quartile2                      float64\n",
      " 209   mfcc_sma[2]_quartile3                      float64\n",
      " 210   mfcc_sma[2]_iqr1-2                         float64\n",
      " 211   mfcc_sma[2]_iqr2-3                         float64\n",
      " 212   mfcc_sma[2]_iqr1-3                         float64\n",
      " 213   mfcc_sma[3]_max                            float64\n",
      " 214   mfcc_sma[3]_min                            float64\n",
      " 215   mfcc_sma[3]_range                          float64\n",
      " 216   mfcc_sma[3]_maxPos                         float64\n",
      " 217   mfcc_sma[3]_minPos                         float64\n",
      " 218   mfcc_sma[3]_amean                          float64\n",
      " 219   mfcc_sma[3]_linregc1                       float64\n",
      " 220   mfcc_sma[3]_linregc2                       float64\n",
      " 221   mfcc_sma[3]_linregerrA                     float64\n",
      " 222   mfcc_sma[3]_linregerrQ                     float64\n",
      " 223   mfcc_sma[3]_stddev                         float64\n",
      " 224   mfcc_sma[3]_skewness                       float64\n",
      " 225   mfcc_sma[3]_kurtosis                       float64\n",
      " 226   mfcc_sma[3]_quartile1                      float64\n",
      " 227   mfcc_sma[3]_quartile2                      float64\n",
      " 228   mfcc_sma[3]_quartile3                      float64\n",
      " 229   mfcc_sma[3]_iqr1-2                         float64\n",
      " 230   mfcc_sma[3]_iqr2-3                         float64\n",
      " 231   mfcc_sma[3]_iqr1-3                         float64\n",
      " 232   mfcc_sma[4]_max                            float64\n",
      " 233   mfcc_sma[4]_min                            float64\n",
      " 234   mfcc_sma[4]_range                          float64\n",
      " 235   mfcc_sma[4]_maxPos                         float64\n",
      " 236   mfcc_sma[4]_minPos                         float64\n",
      " 237   mfcc_sma[4]_amean                          float64\n",
      " 238   mfcc_sma[4]_linregc1                       float64\n",
      " 239   mfcc_sma[4]_linregc2                       float64\n",
      " 240   mfcc_sma[4]_linregerrA                     float64\n",
      " 241   mfcc_sma[4]_linregerrQ                     float64\n",
      " 242   mfcc_sma[4]_stddev                         float64\n",
      " 243   mfcc_sma[4]_skewness                       float64\n",
      " 244   mfcc_sma[4]_kurtosis                       float64\n",
      " 245   mfcc_sma[4]_quartile1                      float64\n",
      " 246   mfcc_sma[4]_quartile2                      float64\n",
      " 247   mfcc_sma[4]_quartile3                      float64\n",
      " 248   mfcc_sma[4]_iqr1-2                         float64\n",
      " 249   mfcc_sma[4]_iqr2-3                         float64\n",
      " 250   mfcc_sma[4]_iqr1-3                         float64\n",
      " 251   mfcc_sma[5]_max                            float64\n",
      " 252   mfcc_sma[5]_min                            float64\n",
      " 253   mfcc_sma[5]_range                          float64\n",
      " 254   mfcc_sma[5]_maxPos                         float64\n",
      " 255   mfcc_sma[5]_minPos                         float64\n",
      " 256   mfcc_sma[5]_amean                          float64\n",
      " 257   mfcc_sma[5]_linregc1                       float64\n",
      " 258   mfcc_sma[5]_linregc2                       float64\n",
      " 259   mfcc_sma[5]_linregerrA                     float64\n",
      " 260   mfcc_sma[5]_linregerrQ                     float64\n",
      " 261   mfcc_sma[5]_stddev                         float64\n",
      " 262   mfcc_sma[5]_skewness                       float64\n",
      " 263   mfcc_sma[5]_kurtosis                       float64\n",
      " 264   mfcc_sma[5]_quartile1                      float64\n",
      " 265   mfcc_sma[5]_quartile2                      float64\n",
      " 266   mfcc_sma[5]_quartile3                      float64\n",
      " 267   mfcc_sma[5]_iqr1-2                         float64\n",
      " 268   mfcc_sma[5]_iqr2-3                         float64\n",
      " 269   mfcc_sma[5]_iqr1-3                         float64\n",
      " 270   mfcc_sma[6]_max                            float64\n",
      " 271   mfcc_sma[6]_min                            float64\n",
      " 272   mfcc_sma[6]_range                          float64\n",
      " 273   mfcc_sma[6]_maxPos                         float64\n",
      " 274   mfcc_sma[6]_minPos                         float64\n",
      " 275   mfcc_sma[6]_amean                          float64\n",
      " 276   mfcc_sma[6]_linregc1                       float64\n",
      " 277   mfcc_sma[6]_linregc2                       float64\n",
      " 278   mfcc_sma[6]_linregerrA                     float64\n",
      " 279   mfcc_sma[6]_linregerrQ                     float64\n",
      " 280   mfcc_sma[6]_stddev                         float64\n",
      " 281   mfcc_sma[6]_skewness                       float64\n",
      " 282   mfcc_sma[6]_kurtosis                       float64\n",
      " 283   mfcc_sma[6]_quartile1                      float64\n",
      " 284   mfcc_sma[6]_quartile2                      float64\n",
      " 285   mfcc_sma[6]_quartile3                      float64\n",
      " 286   mfcc_sma[6]_iqr1-2                         float64\n",
      " 287   mfcc_sma[6]_iqr2-3                         float64\n",
      " 288   mfcc_sma[6]_iqr1-3                         float64\n",
      " 289   mfcc_sma[7]_max                            float64\n",
      " 290   mfcc_sma[7]_min                            float64\n",
      " 291   mfcc_sma[7]_range                          float64\n",
      " 292   mfcc_sma[7]_maxPos                         float64\n",
      " 293   mfcc_sma[7]_minPos                         float64\n",
      " 294   mfcc_sma[7]_amean                          float64\n",
      " 295   mfcc_sma[7]_linregc1                       float64\n",
      " 296   mfcc_sma[7]_linregc2                       float64\n",
      " 297   mfcc_sma[7]_linregerrA                     float64\n",
      " 298   mfcc_sma[7]_linregerrQ                     float64\n",
      " 299   mfcc_sma[7]_stddev                         float64\n",
      " 300   mfcc_sma[7]_skewness                       float64\n",
      " 301   mfcc_sma[7]_kurtosis                       float64\n",
      " 302   mfcc_sma[7]_quartile1                      float64\n",
      " 303   mfcc_sma[7]_quartile2                      float64\n",
      " 304   mfcc_sma[7]_quartile3                      float64\n",
      " 305   mfcc_sma[7]_iqr1-2                         float64\n",
      " 306   mfcc_sma[7]_iqr2-3                         float64\n",
      " 307   mfcc_sma[7]_iqr1-3                         float64\n",
      " 308   mfcc_sma[8]_max                            float64\n",
      " 309   mfcc_sma[8]_min                            float64\n",
      " 310   mfcc_sma[8]_range                          float64\n",
      " 311   mfcc_sma[8]_maxPos                         float64\n",
      " 312   mfcc_sma[8]_minPos                         float64\n",
      " 313   mfcc_sma[8]_amean                          float64\n",
      " 314   mfcc_sma[8]_linregc1                       float64\n",
      " 315   mfcc_sma[8]_linregc2                       float64\n",
      " 316   mfcc_sma[8]_linregerrA                     float64\n",
      " 317   mfcc_sma[8]_linregerrQ                     float64\n",
      " 318   mfcc_sma[8]_stddev                         float64\n",
      " 319   mfcc_sma[8]_skewness                       float64\n",
      " 320   mfcc_sma[8]_kurtosis                       float64\n",
      " 321   mfcc_sma[8]_quartile1                      float64\n",
      " 322   mfcc_sma[8]_quartile2                      float64\n",
      " 323   mfcc_sma[8]_quartile3                      float64\n",
      " 324   mfcc_sma[8]_iqr1-2                         float64\n",
      " 325   mfcc_sma[8]_iqr2-3                         float64\n",
      " 326   mfcc_sma[8]_iqr1-3                         float64\n",
      " 327   mfcc_sma[9]_max                            float64\n",
      " 328   mfcc_sma[9]_min                            float64\n",
      " 329   mfcc_sma[9]_range                          float64\n",
      " 330   mfcc_sma[9]_maxPos                         float64\n",
      " 331   mfcc_sma[9]_minPos                         float64\n",
      " 332   mfcc_sma[9]_amean                          float64\n",
      " 333   mfcc_sma[9]_linregc1                       float64\n",
      " 334   mfcc_sma[9]_linregc2                       float64\n",
      " 335   mfcc_sma[9]_linregerrA                     float64\n",
      " 336   mfcc_sma[9]_linregerrQ                     float64\n",
      " 337   mfcc_sma[9]_stddev                         float64\n",
      " 338   mfcc_sma[9]_skewness                       float64\n",
      " 339   mfcc_sma[9]_kurtosis                       float64\n",
      " 340   mfcc_sma[9]_quartile1                      float64\n",
      " 341   mfcc_sma[9]_quartile2                      float64\n",
      " 342   mfcc_sma[9]_quartile3                      float64\n",
      " 343   mfcc_sma[9]_iqr1-2                         float64\n",
      " 344   mfcc_sma[9]_iqr2-3                         float64\n",
      " 345   mfcc_sma[9]_iqr1-3                         float64\n",
      " 346   mfcc_sma[10]_max                           float64\n",
      " 347   mfcc_sma[10]_min                           float64\n",
      " 348   mfcc_sma[10]_range                         float64\n",
      " 349   mfcc_sma[10]_maxPos                        float64\n",
      " 350   mfcc_sma[10]_minPos                        float64\n",
      " 351   mfcc_sma[10]_amean                         float64\n",
      " 352   mfcc_sma[10]_linregc1                      float64\n",
      " 353   mfcc_sma[10]_linregc2                      float64\n",
      " 354   mfcc_sma[10]_linregerrA                    float64\n",
      " 355   mfcc_sma[10]_linregerrQ                    float64\n",
      " 356   mfcc_sma[10]_stddev                        float64\n",
      " 357   mfcc_sma[10]_skewness                      float64\n",
      " 358   mfcc_sma[10]_kurtosis                      float64\n",
      " 359   mfcc_sma[10]_quartile1                     float64\n",
      " 360   mfcc_sma[10]_quartile2                     float64\n",
      " 361   mfcc_sma[10]_quartile3                     float64\n",
      " 362   mfcc_sma[10]_iqr1-2                        float64\n",
      " 363   mfcc_sma[10]_iqr2-3                        float64\n",
      " 364   mfcc_sma[10]_iqr1-3                        float64\n",
      " 365   mfcc_sma[11]_max                           float64\n",
      " 366   mfcc_sma[11]_min                           float64\n",
      " 367   mfcc_sma[11]_range                         float64\n",
      " 368   mfcc_sma[11]_maxPos                        float64\n",
      " 369   mfcc_sma[11]_minPos                        float64\n",
      " 370   mfcc_sma[11]_amean                         float64\n",
      " 371   mfcc_sma[11]_linregc1                      float64\n",
      " 372   mfcc_sma[11]_linregc2                      float64\n",
      " 373   mfcc_sma[11]_linregerrA                    float64\n",
      " 374   mfcc_sma[11]_linregerrQ                    float64\n",
      " 375   mfcc_sma[11]_stddev                        float64\n",
      " 376   mfcc_sma[11]_skewness                      float64\n",
      " 377   mfcc_sma[11]_kurtosis                      float64\n",
      " 378   mfcc_sma[11]_quartile1                     float64\n",
      " 379   mfcc_sma[11]_quartile2                     float64\n",
      " 380   mfcc_sma[11]_quartile3                     float64\n",
      " 381   mfcc_sma[11]_iqr1-2                        float64\n",
      " 382   mfcc_sma[11]_iqr2-3                        float64\n",
      " 383   mfcc_sma[11]_iqr1-3                        float64\n",
      " 384   mfcc_sma[12]_max                           float64\n",
      " 385   mfcc_sma[12]_min                           float64\n",
      " 386   mfcc_sma[12]_range                         float64\n",
      " 387   mfcc_sma[12]_maxPos                        float64\n",
      " 388   mfcc_sma[12]_minPos                        float64\n",
      " 389   mfcc_sma[12]_amean                         float64\n",
      " 390   mfcc_sma[12]_linregc1                      float64\n",
      " 391   mfcc_sma[12]_linregc2                      float64\n",
      " 392   mfcc_sma[12]_linregerrA                    float64\n",
      " 393   mfcc_sma[12]_linregerrQ                    float64\n",
      " 394   mfcc_sma[12]_stddev                        float64\n",
      " 395   mfcc_sma[12]_skewness                      float64\n",
      " 396   mfcc_sma[12]_kurtosis                      float64\n",
      " 397   mfcc_sma[12]_quartile1                     float64\n",
      " 398   mfcc_sma[12]_quartile2                     float64\n",
      " 399   mfcc_sma[12]_quartile3                     float64\n",
      " 400   mfcc_sma[12]_iqr1-2                        float64\n",
      " 401   mfcc_sma[12]_iqr2-3                        float64\n",
      " 402   mfcc_sma[12]_iqr1-3                        float64\n",
      " 403   lspFreq_sma[0]_max                         float64\n",
      " 404   lspFreq_sma[0]_min                         float64\n",
      " 405   lspFreq_sma[0]_range                       float64\n",
      " 406   lspFreq_sma[0]_maxPos                      float64\n",
      " 407   lspFreq_sma[0]_minPos                      float64\n",
      " 408   lspFreq_sma[0]_amean                       float64\n",
      " 409   lspFreq_sma[0]_linregc1                    float64\n",
      " 410   lspFreq_sma[0]_linregc2                    float64\n",
      " 411   lspFreq_sma[0]_linregerrA                  float64\n",
      " 412   lspFreq_sma[0]_linregerrQ                  float64\n",
      " 413   lspFreq_sma[0]_stddev                      float64\n",
      " 414   lspFreq_sma[0]_skewness                    float64\n",
      " 415   lspFreq_sma[0]_kurtosis                    float64\n",
      " 416   lspFreq_sma[0]_quartile1                   float64\n",
      " 417   lspFreq_sma[0]_quartile2                   float64\n",
      " 418   lspFreq_sma[0]_quartile3                   float64\n",
      " 419   lspFreq_sma[0]_iqr1-2                      float64\n",
      " 420   lspFreq_sma[0]_iqr2-3                      float64\n",
      " 421   lspFreq_sma[0]_iqr1-3                      float64\n",
      " 422   lspFreq_sma[1]_max                         float64\n",
      " 423   lspFreq_sma[1]_min                         float64\n",
      " 424   lspFreq_sma[1]_range                       float64\n",
      " 425   lspFreq_sma[1]_maxPos                      float64\n",
      " 426   lspFreq_sma[1]_minPos                      float64\n",
      " 427   lspFreq_sma[1]_amean                       float64\n",
      " 428   lspFreq_sma[1]_linregc1                    float64\n",
      " 429   lspFreq_sma[1]_linregc2                    float64\n",
      " 430   lspFreq_sma[1]_linregerrA                  float64\n",
      " 431   lspFreq_sma[1]_linregerrQ                  float64\n",
      " 432   lspFreq_sma[1]_stddev                      float64\n",
      " 433   lspFreq_sma[1]_skewness                    float64\n",
      " 434   lspFreq_sma[1]_kurtosis                    float64\n",
      " 435   lspFreq_sma[1]_quartile1                   float64\n",
      " 436   lspFreq_sma[1]_quartile2                   float64\n",
      " 437   lspFreq_sma[1]_quartile3                   float64\n",
      " 438   lspFreq_sma[1]_iqr1-2                      float64\n",
      " 439   lspFreq_sma[1]_iqr2-3                      float64\n",
      " 440   lspFreq_sma[1]_iqr1-3                      float64\n",
      " 441   lspFreq_sma[2]_max                         float64\n",
      " 442   lspFreq_sma[2]_min                         float64\n",
      " 443   lspFreq_sma[2]_range                       float64\n",
      " 444   lspFreq_sma[2]_maxPos                      float64\n",
      " 445   lspFreq_sma[2]_minPos                      float64\n",
      " 446   lspFreq_sma[2]_amean                       float64\n",
      " 447   lspFreq_sma[2]_linregc1                    float64\n",
      " 448   lspFreq_sma[2]_linregc2                    float64\n",
      " 449   lspFreq_sma[2]_linregerrA                  float64\n",
      " 450   lspFreq_sma[2]_linregerrQ                  float64\n",
      " 451   lspFreq_sma[2]_stddev                      float64\n",
      " 452   lspFreq_sma[2]_skewness                    float64\n",
      " 453   lspFreq_sma[2]_kurtosis                    float64\n",
      " 454   lspFreq_sma[2]_quartile1                   float64\n",
      " 455   lspFreq_sma[2]_quartile2                   float64\n",
      " 456   lspFreq_sma[2]_quartile3                   float64\n",
      " 457   lspFreq_sma[2]_iqr1-2                      float64\n",
      " 458   lspFreq_sma[2]_iqr2-3                      float64\n",
      " 459   lspFreq_sma[2]_iqr1-3                      float64\n",
      " 460   lspFreq_sma[3]_max                         float64\n",
      " 461   lspFreq_sma[3]_min                         float64\n",
      " 462   lspFreq_sma[3]_range                       float64\n",
      " 463   lspFreq_sma[3]_maxPos                      float64\n",
      " 464   lspFreq_sma[3]_minPos                      float64\n",
      " 465   lspFreq_sma[3]_amean                       float64\n",
      " 466   lspFreq_sma[3]_linregc1                    float64\n",
      " 467   lspFreq_sma[3]_linregc2                    float64\n",
      " 468   lspFreq_sma[3]_linregerrA                  float64\n",
      " 469   lspFreq_sma[3]_linregerrQ                  float64\n",
      " 470   lspFreq_sma[3]_stddev                      float64\n",
      " 471   lspFreq_sma[3]_skewness                    float64\n",
      " 472   lspFreq_sma[3]_kurtosis                    float64\n",
      " 473   lspFreq_sma[3]_quartile1                   float64\n",
      " 474   lspFreq_sma[3]_quartile2                   float64\n",
      " 475   lspFreq_sma[3]_quartile3                   float64\n",
      " 476   lspFreq_sma[3]_iqr1-2                      float64\n",
      " 477   lspFreq_sma[3]_iqr2-3                      float64\n",
      " 478   lspFreq_sma[3]_iqr1-3                      float64\n",
      " 479   lspFreq_sma[4]_max                         float64\n",
      " 480   lspFreq_sma[4]_min                         float64\n",
      " 481   lspFreq_sma[4]_range                       float64\n",
      " 482   lspFreq_sma[4]_maxPos                      float64\n",
      " 483   lspFreq_sma[4]_minPos                      float64\n",
      " 484   lspFreq_sma[4]_amean                       float64\n",
      " 485   lspFreq_sma[4]_linregc1                    float64\n",
      " 486   lspFreq_sma[4]_linregc2                    float64\n",
      " 487   lspFreq_sma[4]_linregerrA                  float64\n",
      " 488   lspFreq_sma[4]_linregerrQ                  float64\n",
      " 489   lspFreq_sma[4]_stddev                      float64\n",
      " 490   lspFreq_sma[4]_skewness                    float64\n",
      " 491   lspFreq_sma[4]_kurtosis                    float64\n",
      " 492   lspFreq_sma[4]_quartile1                   float64\n",
      " 493   lspFreq_sma[4]_quartile2                   float64\n",
      " 494   lspFreq_sma[4]_quartile3                   float64\n",
      " 495   lspFreq_sma[4]_iqr1-2                      float64\n",
      " 496   lspFreq_sma[4]_iqr2-3                      float64\n",
      " 497   lspFreq_sma[4]_iqr1-3                      float64\n",
      " 498   lspFreq_sma[5]_max                         float64\n",
      " 499   lspFreq_sma[5]_min                         float64\n",
      " 500   lspFreq_sma[5]_range                       float64\n",
      " 501   lspFreq_sma[5]_maxPos                      float64\n",
      " 502   lspFreq_sma[5]_minPos                      float64\n",
      " 503   lspFreq_sma[5]_amean                       float64\n",
      " 504   lspFreq_sma[5]_linregc1                    float64\n",
      " 505   lspFreq_sma[5]_linregc2                    float64\n",
      " 506   lspFreq_sma[5]_linregerrA                  float64\n",
      " 507   lspFreq_sma[5]_linregerrQ                  float64\n",
      " 508   lspFreq_sma[5]_stddev                      float64\n",
      " 509   lspFreq_sma[5]_skewness                    float64\n",
      " 510   lspFreq_sma[5]_kurtosis                    float64\n",
      " 511   lspFreq_sma[5]_quartile1                   float64\n",
      " 512   lspFreq_sma[5]_quartile2                   float64\n",
      " 513   lspFreq_sma[5]_quartile3                   float64\n",
      " 514   lspFreq_sma[5]_iqr1-2                      float64\n",
      " 515   lspFreq_sma[5]_iqr2-3                      float64\n",
      " 516   lspFreq_sma[5]_iqr1-3                      float64\n",
      " 517   lspFreq_sma[6]_max                         float64\n",
      " 518   lspFreq_sma[6]_min                         float64\n",
      " 519   lspFreq_sma[6]_range                       float64\n",
      " 520   lspFreq_sma[6]_maxPos                      float64\n",
      " 521   lspFreq_sma[6]_minPos                      float64\n",
      " 522   lspFreq_sma[6]_amean                       float64\n",
      " 523   lspFreq_sma[6]_linregc1                    float64\n",
      " 524   lspFreq_sma[6]_linregc2                    float64\n",
      " 525   lspFreq_sma[6]_linregerrA                  float64\n",
      " 526   lspFreq_sma[6]_linregerrQ                  float64\n",
      " 527   lspFreq_sma[6]_stddev                      float64\n",
      " 528   lspFreq_sma[6]_skewness                    float64\n",
      " 529   lspFreq_sma[6]_kurtosis                    float64\n",
      " 530   lspFreq_sma[6]_quartile1                   float64\n",
      " 531   lspFreq_sma[6]_quartile2                   float64\n",
      " 532   lspFreq_sma[6]_quartile3                   float64\n",
      " 533   lspFreq_sma[6]_iqr1-2                      float64\n",
      " 534   lspFreq_sma[6]_iqr2-3                      float64\n",
      " 535   lspFreq_sma[6]_iqr1-3                      float64\n",
      " 536   lspFreq_sma[7]_max                         float64\n",
      " 537   lspFreq_sma[7]_min                         float64\n",
      " 538   lspFreq_sma[7]_range                       float64\n",
      " 539   lspFreq_sma[7]_maxPos                      float64\n",
      " 540   lspFreq_sma[7]_minPos                      float64\n",
      " 541   lspFreq_sma[7]_amean                       float64\n",
      " 542   lspFreq_sma[7]_linregc1                    float64\n",
      " 543   lspFreq_sma[7]_linregc2                    float64\n",
      " 544   lspFreq_sma[7]_linregerrA                  float64\n",
      " 545   lspFreq_sma[7]_linregerrQ                  float64\n",
      " 546   lspFreq_sma[7]_stddev                      float64\n",
      " 547   lspFreq_sma[7]_skewness                    float64\n",
      " 548   lspFreq_sma[7]_kurtosis                    float64\n",
      " 549   lspFreq_sma[7]_quartile1                   float64\n",
      " 550   lspFreq_sma[7]_quartile2                   float64\n",
      " 551   lspFreq_sma[7]_quartile3                   float64\n",
      " 552   lspFreq_sma[7]_iqr1-2                      float64\n",
      " 553   lspFreq_sma[7]_iqr2-3                      float64\n",
      " 554   lspFreq_sma[7]_iqr1-3                      float64\n",
      " 555   pcm_zcr_sma_max                            float64\n",
      " 556   pcm_zcr_sma_min                            float64\n",
      " 557   pcm_zcr_sma_range                          float64\n",
      " 558   pcm_zcr_sma_maxPos                         float64\n",
      " 559   pcm_zcr_sma_minPos                         float64\n",
      " 560   pcm_zcr_sma_amean                          float64\n",
      " 561   pcm_zcr_sma_linregc1                       float64\n",
      " 562   pcm_zcr_sma_linregc2                       float64\n",
      " 563   pcm_zcr_sma_linregerrA                     float64\n",
      " 564   pcm_zcr_sma_linregerrQ                     float64\n",
      " 565   pcm_zcr_sma_stddev                         float64\n",
      " 566   pcm_zcr_sma_skewness                       float64\n",
      " 567   pcm_zcr_sma_kurtosis                       float64\n",
      " 568   pcm_zcr_sma_quartile1                      float64\n",
      " 569   pcm_zcr_sma_quartile2                      float64\n",
      " 570   pcm_zcr_sma_quartile3                      float64\n",
      " 571   pcm_zcr_sma_iqr1-2                         float64\n",
      " 572   pcm_zcr_sma_iqr2-3                         float64\n",
      " 573   pcm_zcr_sma_iqr1-3                         float64\n",
      " 574   voiceProb_sma_max                          float64\n",
      " 575   voiceProb_sma_min                          float64\n",
      " 576   voiceProb_sma_range                        float64\n",
      " 577   voiceProb_sma_maxPos                       float64\n",
      " 578   voiceProb_sma_minPos                       float64\n",
      " 579   voiceProb_sma_amean                        float64\n",
      " 580   voiceProb_sma_linregc1                     float64\n",
      " 581   voiceProb_sma_linregc2                     float64\n",
      " 582   voiceProb_sma_linregerrA                   float64\n",
      " 583   voiceProb_sma_linregerrQ                   float64\n",
      " 584   voiceProb_sma_stddev                       float64\n",
      " 585   voiceProb_sma_skewness                     float64\n",
      " 586   voiceProb_sma_kurtosis                     float64\n",
      " 587   voiceProb_sma_quartile1                    float64\n",
      " 588   voiceProb_sma_quartile2                    float64\n",
      " 589   voiceProb_sma_quartile3                    float64\n",
      " 590   voiceProb_sma_iqr1-2                       float64\n",
      " 591   voiceProb_sma_iqr2-3                       float64\n",
      " 592   voiceProb_sma_iqr1-3                       float64\n",
      " 593   F0_sma_max                                 float64\n",
      " 594   F0_sma_min                                 float64\n",
      " 595   F0_sma_range                               float64\n",
      " 596   F0_sma_maxPos                              float64\n",
      " 597   F0_sma_minPos                              float64\n",
      " 598   F0_sma_amean                               float64\n",
      " 599   F0_sma_linregc1                            float64\n",
      " 600   F0_sma_linregc2                            float64\n",
      " 601   F0_sma_linregerrA                          float64\n",
      " 602   F0_sma_linregerrQ                          float64\n",
      " 603   F0_sma_stddev                              float64\n",
      " 604   F0_sma_skewness                            float64\n",
      " 605   F0_sma_kurtosis                            float64\n",
      " 606   F0_sma_quartile1                           float64\n",
      " 607   F0_sma_quartile2                           float64\n",
      " 608   F0_sma_quartile3                           float64\n",
      " 609   F0_sma_iqr1-2                              float64\n",
      " 610   F0_sma_iqr2-3                              float64\n",
      " 611   F0_sma_iqr1-3                              float64\n",
      " 612   F0env_sma_max                              float64\n",
      " 613   F0env_sma_min                              float64\n",
      " 614   F0env_sma_range                            float64\n",
      " 615   F0env_sma_maxPos                           float64\n",
      " 616   F0env_sma_minPos                           float64\n",
      " 617   F0env_sma_amean                            float64\n",
      " 618   F0env_sma_linregc1                         float64\n",
      " 619   F0env_sma_linregc2                         float64\n",
      " 620   F0env_sma_linregerrA                       float64\n",
      " 621   F0env_sma_linregerrQ                       float64\n",
      " 622   F0env_sma_stddev                           float64\n",
      " 623   F0env_sma_skewness                         float64\n",
      " 624   F0env_sma_kurtosis                         float64\n",
      " 625   F0env_sma_quartile1                        float64\n",
      " 626   F0env_sma_quartile2                        float64\n",
      " 627   F0env_sma_quartile3                        float64\n",
      " 628   F0env_sma_iqr1-2                           float64\n",
      " 629   F0env_sma_iqr2-3                           float64\n",
      " 630   F0env_sma_iqr1-3                           float64\n",
      " 631   pcm_intensity_sma_de_max                   float64\n",
      " 632   pcm_intensity_sma_de_min                   float64\n",
      " 633   pcm_intensity_sma_de_range                 float64\n",
      " 634   pcm_intensity_sma_de_maxPos                float64\n",
      " 635   pcm_intensity_sma_de_minPos                float64\n",
      " 636   pcm_intensity_sma_de_amean                 float64\n",
      " 637   pcm_intensity_sma_de_linregc1              float64\n",
      " 638   pcm_intensity_sma_de_linregc2              float64\n",
      " 639   pcm_intensity_sma_de_linregerrA            float64\n",
      " 640   pcm_intensity_sma_de_linregerrQ            float64\n",
      " 641   pcm_intensity_sma_de_stddev                float64\n",
      " 642   pcm_intensity_sma_de_skewness              float64\n",
      " 643   pcm_intensity_sma_de_kurtosis              float64\n",
      " 644   pcm_intensity_sma_de_quartile1             float64\n",
      " 645   pcm_intensity_sma_de_quartile2             float64\n",
      " 646   pcm_intensity_sma_de_quartile3             float64\n",
      " 647   pcm_intensity_sma_de_iqr1-2                float64\n",
      " 648   pcm_intensity_sma_de_iqr2-3                float64\n",
      " 649   pcm_intensity_sma_de_iqr1-3                float64\n",
      " 650   pcm_loudness_sma_de_max                    float64\n",
      " 651   pcm_loudness_sma_de_min                    float64\n",
      " 652   pcm_loudness_sma_de_range                  float64\n",
      " 653   pcm_loudness_sma_de_maxPos                 float64\n",
      " 654   pcm_loudness_sma_de_minPos                 float64\n",
      " 655   pcm_loudness_sma_de_amean                  float64\n",
      " 656   pcm_loudness_sma_de_linregc1               float64\n",
      " 657   pcm_loudness_sma_de_linregc2               float64\n",
      " 658   pcm_loudness_sma_de_linregerrA             float64\n",
      " 659   pcm_loudness_sma_de_linregerrQ             float64\n",
      " 660   pcm_loudness_sma_de_stddev                 float64\n",
      " 661   pcm_loudness_sma_de_skewness               float64\n",
      " 662   pcm_loudness_sma_de_kurtosis               float64\n",
      " 663   pcm_loudness_sma_de_quartile1              float64\n",
      " 664   pcm_loudness_sma_de_quartile2              float64\n",
      " 665   pcm_loudness_sma_de_quartile3              float64\n",
      " 666   pcm_loudness_sma_de_iqr1-2                 float64\n",
      " 667   pcm_loudness_sma_de_iqr2-3                 float64\n",
      " 668   pcm_loudness_sma_de_iqr1-3                 float64\n",
      " 669   mfcc_sma_de[1]_max                         float64\n",
      " 670   mfcc_sma_de[1]_min                         float64\n",
      " 671   mfcc_sma_de[1]_range                       float64\n",
      " 672   mfcc_sma_de[1]_maxPos                      float64\n",
      " 673   mfcc_sma_de[1]_minPos                      float64\n",
      " 674   mfcc_sma_de[1]_amean                       float64\n",
      " 675   mfcc_sma_de[1]_linregc1                    float64\n",
      " 676   mfcc_sma_de[1]_linregc2                    float64\n",
      " 677   mfcc_sma_de[1]_linregerrA                  float64\n",
      " 678   mfcc_sma_de[1]_linregerrQ                  float64\n",
      " 679   mfcc_sma_de[1]_stddev                      float64\n",
      " 680   mfcc_sma_de[1]_skewness                    float64\n",
      " 681   mfcc_sma_de[1]_kurtosis                    float64\n",
      " 682   mfcc_sma_de[1]_quartile1                   float64\n",
      " 683   mfcc_sma_de[1]_quartile2                   float64\n",
      " 684   mfcc_sma_de[1]_quartile3                   float64\n",
      " 685   mfcc_sma_de[1]_iqr1-2                      float64\n",
      " 686   mfcc_sma_de[1]_iqr2-3                      float64\n",
      " 687   mfcc_sma_de[1]_iqr1-3                      float64\n",
      " 688   mfcc_sma_de[2]_max                         float64\n",
      " 689   mfcc_sma_de[2]_min                         float64\n",
      " 690   mfcc_sma_de[2]_range                       float64\n",
      " 691   mfcc_sma_de[2]_maxPos                      float64\n",
      " 692   mfcc_sma_de[2]_minPos                      float64\n",
      " 693   mfcc_sma_de[2]_amean                       float64\n",
      " 694   mfcc_sma_de[2]_linregc1                    float64\n",
      " 695   mfcc_sma_de[2]_linregc2                    float64\n",
      " 696   mfcc_sma_de[2]_linregerrA                  float64\n",
      " 697   mfcc_sma_de[2]_linregerrQ                  float64\n",
      " 698   mfcc_sma_de[2]_stddev                      float64\n",
      " 699   mfcc_sma_de[2]_skewness                    float64\n",
      " 700   mfcc_sma_de[2]_kurtosis                    float64\n",
      " 701   mfcc_sma_de[2]_quartile1                   float64\n",
      " 702   mfcc_sma_de[2]_quartile2                   float64\n",
      " 703   mfcc_sma_de[2]_quartile3                   float64\n",
      " 704   mfcc_sma_de[2]_iqr1-2                      float64\n",
      " 705   mfcc_sma_de[2]_iqr2-3                      float64\n",
      " 706   mfcc_sma_de[2]_iqr1-3                      float64\n",
      " 707   mfcc_sma_de[3]_max                         float64\n",
      " 708   mfcc_sma_de[3]_min                         float64\n",
      " 709   mfcc_sma_de[3]_range                       float64\n",
      " 710   mfcc_sma_de[3]_maxPos                      float64\n",
      " 711   mfcc_sma_de[3]_minPos                      float64\n",
      " 712   mfcc_sma_de[3]_amean                       float64\n",
      " 713   mfcc_sma_de[3]_linregc1                    float64\n",
      " 714   mfcc_sma_de[3]_linregc2                    float64\n",
      " 715   mfcc_sma_de[3]_linregerrA                  float64\n",
      " 716   mfcc_sma_de[3]_linregerrQ                  float64\n",
      " 717   mfcc_sma_de[3]_stddev                      float64\n",
      " 718   mfcc_sma_de[3]_skewness                    float64\n",
      " 719   mfcc_sma_de[3]_kurtosis                    float64\n",
      " 720   mfcc_sma_de[3]_quartile1                   float64\n",
      " 721   mfcc_sma_de[3]_quartile2                   float64\n",
      " 722   mfcc_sma_de[3]_quartile3                   float64\n",
      " 723   mfcc_sma_de[3]_iqr1-2                      float64\n",
      " 724   mfcc_sma_de[3]_iqr2-3                      float64\n",
      " 725   mfcc_sma_de[3]_iqr1-3                      float64\n",
      " 726   mfcc_sma_de[4]_max                         float64\n",
      " 727   mfcc_sma_de[4]_min                         float64\n",
      " 728   mfcc_sma_de[4]_range                       float64\n",
      " 729   mfcc_sma_de[4]_maxPos                      float64\n",
      " 730   mfcc_sma_de[4]_minPos                      float64\n",
      " 731   mfcc_sma_de[4]_amean                       float64\n",
      " 732   mfcc_sma_de[4]_linregc1                    float64\n",
      " 733   mfcc_sma_de[4]_linregc2                    float64\n",
      " 734   mfcc_sma_de[4]_linregerrA                  float64\n",
      " 735   mfcc_sma_de[4]_linregerrQ                  float64\n",
      " 736   mfcc_sma_de[4]_stddev                      float64\n",
      " 737   mfcc_sma_de[4]_skewness                    float64\n",
      " 738   mfcc_sma_de[4]_kurtosis                    float64\n",
      " 739   mfcc_sma_de[4]_quartile1                   float64\n",
      " 740   mfcc_sma_de[4]_quartile2                   float64\n",
      " 741   mfcc_sma_de[4]_quartile3                   float64\n",
      " 742   mfcc_sma_de[4]_iqr1-2                      float64\n",
      " 743   mfcc_sma_de[4]_iqr2-3                      float64\n",
      " 744   mfcc_sma_de[4]_iqr1-3                      float64\n",
      " 745   mfcc_sma_de[5]_max                         float64\n",
      " 746   mfcc_sma_de[5]_min                         float64\n",
      " 747   mfcc_sma_de[5]_range                       float64\n",
      " 748   mfcc_sma_de[5]_maxPos                      float64\n",
      " 749   mfcc_sma_de[5]_minPos                      float64\n",
      " 750   mfcc_sma_de[5]_amean                       float64\n",
      " 751   mfcc_sma_de[5]_linregc1                    float64\n",
      " 752   mfcc_sma_de[5]_linregc2                    float64\n",
      " 753   mfcc_sma_de[5]_linregerrA                  float64\n",
      " 754   mfcc_sma_de[5]_linregerrQ                  float64\n",
      " 755   mfcc_sma_de[5]_stddev                      float64\n",
      " 756   mfcc_sma_de[5]_skewness                    float64\n",
      " 757   mfcc_sma_de[5]_kurtosis                    float64\n",
      " 758   mfcc_sma_de[5]_quartile1                   float64\n",
      " 759   mfcc_sma_de[5]_quartile2                   float64\n",
      " 760   mfcc_sma_de[5]_quartile3                   float64\n",
      " 761   mfcc_sma_de[5]_iqr1-2                      float64\n",
      " 762   mfcc_sma_de[5]_iqr2-3                      float64\n",
      " 763   mfcc_sma_de[5]_iqr1-3                      float64\n",
      " 764   mfcc_sma_de[6]_max                         float64\n",
      " 765   mfcc_sma_de[6]_min                         float64\n",
      " 766   mfcc_sma_de[6]_range                       float64\n",
      " 767   mfcc_sma_de[6]_maxPos                      float64\n",
      " 768   mfcc_sma_de[6]_minPos                      float64\n",
      " 769   mfcc_sma_de[6]_amean                       float64\n",
      " 770   mfcc_sma_de[6]_linregc1                    float64\n",
      " 771   mfcc_sma_de[6]_linregc2                    float64\n",
      " 772   mfcc_sma_de[6]_linregerrA                  float64\n",
      " 773   mfcc_sma_de[6]_linregerrQ                  float64\n",
      " 774   mfcc_sma_de[6]_stddev                      float64\n",
      " 775   mfcc_sma_de[6]_skewness                    float64\n",
      " 776   mfcc_sma_de[6]_kurtosis                    float64\n",
      " 777   mfcc_sma_de[6]_quartile1                   float64\n",
      " 778   mfcc_sma_de[6]_quartile2                   float64\n",
      " 779   mfcc_sma_de[6]_quartile3                   float64\n",
      " 780   mfcc_sma_de[6]_iqr1-2                      float64\n",
      " 781   mfcc_sma_de[6]_iqr2-3                      float64\n",
      " 782   mfcc_sma_de[6]_iqr1-3                      float64\n",
      " 783   mfcc_sma_de[7]_max                         float64\n",
      " 784   mfcc_sma_de[7]_min                         float64\n",
      " 785   mfcc_sma_de[7]_range                       float64\n",
      " 786   mfcc_sma_de[7]_maxPos                      float64\n",
      " 787   mfcc_sma_de[7]_minPos                      float64\n",
      " 788   mfcc_sma_de[7]_amean                       float64\n",
      " 789   mfcc_sma_de[7]_linregc1                    float64\n",
      " 790   mfcc_sma_de[7]_linregc2                    float64\n",
      " 791   mfcc_sma_de[7]_linregerrA                  float64\n",
      " 792   mfcc_sma_de[7]_linregerrQ                  float64\n",
      " 793   mfcc_sma_de[7]_stddev                      float64\n",
      " 794   mfcc_sma_de[7]_skewness                    float64\n",
      " 795   mfcc_sma_de[7]_kurtosis                    float64\n",
      " 796   mfcc_sma_de[7]_quartile1                   float64\n",
      " 797   mfcc_sma_de[7]_quartile2                   float64\n",
      " 798   mfcc_sma_de[7]_quartile3                   float64\n",
      " 799   mfcc_sma_de[7]_iqr1-2                      float64\n",
      " 800   mfcc_sma_de[7]_iqr2-3                      float64\n",
      " 801   mfcc_sma_de[7]_iqr1-3                      float64\n",
      " 802   mfcc_sma_de[8]_max                         float64\n",
      " 803   mfcc_sma_de[8]_min                         float64\n",
      " 804   mfcc_sma_de[8]_range                       float64\n",
      " 805   mfcc_sma_de[8]_maxPos                      float64\n",
      " 806   mfcc_sma_de[8]_minPos                      float64\n",
      " 807   mfcc_sma_de[8]_amean                       float64\n",
      " 808   mfcc_sma_de[8]_linregc1                    float64\n",
      " 809   mfcc_sma_de[8]_linregc2                    float64\n",
      " 810   mfcc_sma_de[8]_linregerrA                  float64\n",
      " 811   mfcc_sma_de[8]_linregerrQ                  float64\n",
      " 812   mfcc_sma_de[8]_stddev                      float64\n",
      " 813   mfcc_sma_de[8]_skewness                    float64\n",
      " 814   mfcc_sma_de[8]_kurtosis                    float64\n",
      " 815   mfcc_sma_de[8]_quartile1                   float64\n",
      " 816   mfcc_sma_de[8]_quartile2                   float64\n",
      " 817   mfcc_sma_de[8]_quartile3                   float64\n",
      " 818   mfcc_sma_de[8]_iqr1-2                      float64\n",
      " 819   mfcc_sma_de[8]_iqr2-3                      float64\n",
      " 820   mfcc_sma_de[8]_iqr1-3                      float64\n",
      " 821   mfcc_sma_de[9]_max                         float64\n",
      " 822   mfcc_sma_de[9]_min                         float64\n",
      " 823   mfcc_sma_de[9]_range                       float64\n",
      " 824   mfcc_sma_de[9]_maxPos                      float64\n",
      " 825   mfcc_sma_de[9]_minPos                      float64\n",
      " 826   mfcc_sma_de[9]_amean                       float64\n",
      " 827   mfcc_sma_de[9]_linregc1                    float64\n",
      " 828   mfcc_sma_de[9]_linregc2                    float64\n",
      " 829   mfcc_sma_de[9]_linregerrA                  float64\n",
      " 830   mfcc_sma_de[9]_linregerrQ                  float64\n",
      " 831   mfcc_sma_de[9]_stddev                      float64\n",
      " 832   mfcc_sma_de[9]_skewness                    float64\n",
      " 833   mfcc_sma_de[9]_kurtosis                    float64\n",
      " 834   mfcc_sma_de[9]_quartile1                   float64\n",
      " 835   mfcc_sma_de[9]_quartile2                   float64\n",
      " 836   mfcc_sma_de[9]_quartile3                   float64\n",
      " 837   mfcc_sma_de[9]_iqr1-2                      float64\n",
      " 838   mfcc_sma_de[9]_iqr2-3                      float64\n",
      " 839   mfcc_sma_de[9]_iqr1-3                      float64\n",
      " 840   mfcc_sma_de[10]_max                        float64\n",
      " 841   mfcc_sma_de[10]_min                        float64\n",
      " 842   mfcc_sma_de[10]_range                      float64\n",
      " 843   mfcc_sma_de[10]_maxPos                     float64\n",
      " 844   mfcc_sma_de[10]_minPos                     float64\n",
      " 845   mfcc_sma_de[10]_amean                      float64\n",
      " 846   mfcc_sma_de[10]_linregc1                   float64\n",
      " 847   mfcc_sma_de[10]_linregc2                   float64\n",
      " 848   mfcc_sma_de[10]_linregerrA                 float64\n",
      " 849   mfcc_sma_de[10]_linregerrQ                 float64\n",
      " 850   mfcc_sma_de[10]_stddev                     float64\n",
      " 851   mfcc_sma_de[10]_skewness                   float64\n",
      " 852   mfcc_sma_de[10]_kurtosis                   float64\n",
      " 853   mfcc_sma_de[10]_quartile1                  float64\n",
      " 854   mfcc_sma_de[10]_quartile2                  float64\n",
      " 855   mfcc_sma_de[10]_quartile3                  float64\n",
      " 856   mfcc_sma_de[10]_iqr1-2                     float64\n",
      " 857   mfcc_sma_de[10]_iqr2-3                     float64\n",
      " 858   mfcc_sma_de[10]_iqr1-3                     float64\n",
      " 859   mfcc_sma_de[11]_max                        float64\n",
      " 860   mfcc_sma_de[11]_min                        float64\n",
      " 861   mfcc_sma_de[11]_range                      float64\n",
      " 862   mfcc_sma_de[11]_maxPos                     float64\n",
      " 863   mfcc_sma_de[11]_minPos                     float64\n",
      " 864   mfcc_sma_de[11]_amean                      float64\n",
      " 865   mfcc_sma_de[11]_linregc1                   float64\n",
      " 866   mfcc_sma_de[11]_linregc2                   float64\n",
      " 867   mfcc_sma_de[11]_linregerrA                 float64\n",
      " 868   mfcc_sma_de[11]_linregerrQ                 float64\n",
      " 869   mfcc_sma_de[11]_stddev                     float64\n",
      " 870   mfcc_sma_de[11]_skewness                   float64\n",
      " 871   mfcc_sma_de[11]_kurtosis                   float64\n",
      " 872   mfcc_sma_de[11]_quartile1                  float64\n",
      " 873   mfcc_sma_de[11]_quartile2                  float64\n",
      " 874   mfcc_sma_de[11]_quartile3                  float64\n",
      " 875   mfcc_sma_de[11]_iqr1-2                     float64\n",
      " 876   mfcc_sma_de[11]_iqr2-3                     float64\n",
      " 877   mfcc_sma_de[11]_iqr1-3                     float64\n",
      " 878   mfcc_sma_de[12]_max                        float64\n",
      " 879   mfcc_sma_de[12]_min                        float64\n",
      " 880   mfcc_sma_de[12]_range                      float64\n",
      " 881   mfcc_sma_de[12]_maxPos                     float64\n",
      " 882   mfcc_sma_de[12]_minPos                     float64\n",
      " 883   mfcc_sma_de[12]_amean                      float64\n",
      " 884   mfcc_sma_de[12]_linregc1                   float64\n",
      " 885   mfcc_sma_de[12]_linregc2                   float64\n",
      " 886   mfcc_sma_de[12]_linregerrA                 float64\n",
      " 887   mfcc_sma_de[12]_linregerrQ                 float64\n",
      " 888   mfcc_sma_de[12]_stddev                     float64\n",
      " 889   mfcc_sma_de[12]_skewness                   float64\n",
      " 890   mfcc_sma_de[12]_kurtosis                   float64\n",
      " 891   mfcc_sma_de[12]_quartile1                  float64\n",
      " 892   mfcc_sma_de[12]_quartile2                  float64\n",
      " 893   mfcc_sma_de[12]_quartile3                  float64\n",
      " 894   mfcc_sma_de[12]_iqr1-2                     float64\n",
      " 895   mfcc_sma_de[12]_iqr2-3                     float64\n",
      " 896   mfcc_sma_de[12]_iqr1-3                     float64\n",
      " 897   lspFreq_sma_de[0]_max                      float64\n",
      " 898   lspFreq_sma_de[0]_min                      float64\n",
      " 899   lspFreq_sma_de[0]_range                    float64\n",
      " 900   lspFreq_sma_de[0]_maxPos                   float64\n",
      " 901   lspFreq_sma_de[0]_minPos                   float64\n",
      " 902   lspFreq_sma_de[0]_amean                    float64\n",
      " 903   lspFreq_sma_de[0]_linregc1                 float64\n",
      " 904   lspFreq_sma_de[0]_linregc2                 float64\n",
      " 905   lspFreq_sma_de[0]_linregerrA               float64\n",
      " 906   lspFreq_sma_de[0]_linregerrQ               float64\n",
      " 907   lspFreq_sma_de[0]_stddev                   float64\n",
      " 908   lspFreq_sma_de[0]_skewness                 float64\n",
      " 909   lspFreq_sma_de[0]_kurtosis                 float64\n",
      " 910   lspFreq_sma_de[0]_quartile1                float64\n",
      " 911   lspFreq_sma_de[0]_quartile2                float64\n",
      " 912   lspFreq_sma_de[0]_quartile3                float64\n",
      " 913   lspFreq_sma_de[0]_iqr1-2                   float64\n",
      " 914   lspFreq_sma_de[0]_iqr2-3                   float64\n",
      " 915   lspFreq_sma_de[0]_iqr1-3                   float64\n",
      " 916   lspFreq_sma_de[1]_max                      float64\n",
      " 917   lspFreq_sma_de[1]_min                      float64\n",
      " 918   lspFreq_sma_de[1]_range                    float64\n",
      " 919   lspFreq_sma_de[1]_maxPos                   float64\n",
      " 920   lspFreq_sma_de[1]_minPos                   float64\n",
      " 921   lspFreq_sma_de[1]_amean                    float64\n",
      " 922   lspFreq_sma_de[1]_linregc1                 float64\n",
      " 923   lspFreq_sma_de[1]_linregc2                 float64\n",
      " 924   lspFreq_sma_de[1]_linregerrA               float64\n",
      " 925   lspFreq_sma_de[1]_linregerrQ               float64\n",
      " 926   lspFreq_sma_de[1]_stddev                   float64\n",
      " 927   lspFreq_sma_de[1]_skewness                 float64\n",
      " 928   lspFreq_sma_de[1]_kurtosis                 float64\n",
      " 929   lspFreq_sma_de[1]_quartile1                float64\n",
      " 930   lspFreq_sma_de[1]_quartile2                float64\n",
      " 931   lspFreq_sma_de[1]_quartile3                float64\n",
      " 932   lspFreq_sma_de[1]_iqr1-2                   float64\n",
      " 933   lspFreq_sma_de[1]_iqr2-3                   float64\n",
      " 934   lspFreq_sma_de[1]_iqr1-3                   float64\n",
      " 935   lspFreq_sma_de[2]_max                      float64\n",
      " 936   lspFreq_sma_de[2]_min                      float64\n",
      " 937   lspFreq_sma_de[2]_range                    float64\n",
      " 938   lspFreq_sma_de[2]_maxPos                   float64\n",
      " 939   lspFreq_sma_de[2]_minPos                   float64\n",
      " 940   lspFreq_sma_de[2]_amean                    float64\n",
      " 941   lspFreq_sma_de[2]_linregc1                 float64\n",
      " 942   lspFreq_sma_de[2]_linregc2                 float64\n",
      " 943   lspFreq_sma_de[2]_linregerrA               float64\n",
      " 944   lspFreq_sma_de[2]_linregerrQ               float64\n",
      " 945   lspFreq_sma_de[2]_stddev                   float64\n",
      " 946   lspFreq_sma_de[2]_skewness                 float64\n",
      " 947   lspFreq_sma_de[2]_kurtosis                 float64\n",
      " 948   lspFreq_sma_de[2]_quartile1                float64\n",
      " 949   lspFreq_sma_de[2]_quartile2                float64\n",
      " 950   lspFreq_sma_de[2]_quartile3                float64\n",
      " 951   lspFreq_sma_de[2]_iqr1-2                   float64\n",
      " 952   lspFreq_sma_de[2]_iqr2-3                   float64\n",
      " 953   lspFreq_sma_de[2]_iqr1-3                   float64\n",
      " 954   lspFreq_sma_de[3]_max                      float64\n",
      " 955   lspFreq_sma_de[3]_min                      float64\n",
      " 956   lspFreq_sma_de[3]_range                    float64\n",
      " 957   lspFreq_sma_de[3]_maxPos                   float64\n",
      " 958   lspFreq_sma_de[3]_minPos                   float64\n",
      " 959   lspFreq_sma_de[3]_amean                    float64\n",
      " 960   lspFreq_sma_de[3]_linregc1                 float64\n",
      " 961   lspFreq_sma_de[3]_linregc2                 float64\n",
      " 962   lspFreq_sma_de[3]_linregerrA               float64\n",
      " 963   lspFreq_sma_de[3]_linregerrQ               float64\n",
      " 964   lspFreq_sma_de[3]_stddev                   float64\n",
      " 965   lspFreq_sma_de[3]_skewness                 float64\n",
      " 966   lspFreq_sma_de[3]_kurtosis                 float64\n",
      " 967   lspFreq_sma_de[3]_quartile1                float64\n",
      " 968   lspFreq_sma_de[3]_quartile2                float64\n",
      " 969   lspFreq_sma_de[3]_quartile3                float64\n",
      " 970   lspFreq_sma_de[3]_iqr1-2                   float64\n",
      " 971   lspFreq_sma_de[3]_iqr2-3                   float64\n",
      " 972   lspFreq_sma_de[3]_iqr1-3                   float64\n",
      " 973   lspFreq_sma_de[4]_max                      float64\n",
      " 974   lspFreq_sma_de[4]_min                      float64\n",
      " 975   lspFreq_sma_de[4]_range                    float64\n",
      " 976   lspFreq_sma_de[4]_maxPos                   float64\n",
      " 977   lspFreq_sma_de[4]_minPos                   float64\n",
      " 978   lspFreq_sma_de[4]_amean                    float64\n",
      " 979   lspFreq_sma_de[4]_linregc1                 float64\n",
      " 980   lspFreq_sma_de[4]_linregc2                 float64\n",
      " 981   lspFreq_sma_de[4]_linregerrA               float64\n",
      " 982   lspFreq_sma_de[4]_linregerrQ               float64\n",
      " 983   lspFreq_sma_de[4]_stddev                   float64\n",
      " 984   lspFreq_sma_de[4]_skewness                 float64\n",
      " 985   lspFreq_sma_de[4]_kurtosis                 float64\n",
      " 986   lspFreq_sma_de[4]_quartile1                float64\n",
      " 987   lspFreq_sma_de[4]_quartile2                float64\n",
      " 988   lspFreq_sma_de[4]_quartile3                float64\n",
      " 989   lspFreq_sma_de[4]_iqr1-2                   float64\n",
      " 990   lspFreq_sma_de[4]_iqr2-3                   float64\n",
      " 991   lspFreq_sma_de[4]_iqr1-3                   float64\n",
      " 992   lspFreq_sma_de[5]_max                      float64\n",
      " 993   lspFreq_sma_de[5]_min                      float64\n",
      " 994   lspFreq_sma_de[5]_range                    float64\n",
      " 995   lspFreq_sma_de[5]_maxPos                   float64\n",
      " 996   lspFreq_sma_de[5]_minPos                   float64\n",
      " 997   lspFreq_sma_de[5]_amean                    float64\n",
      " 998   lspFreq_sma_de[5]_linregc1                 float64\n",
      " 999   lspFreq_sma_de[5]_linregc2                 float64\n",
      " 1000  lspFreq_sma_de[5]_linregerrA               float64\n",
      " 1001  lspFreq_sma_de[5]_linregerrQ               float64\n",
      " 1002  lspFreq_sma_de[5]_stddev                   float64\n",
      " 1003  lspFreq_sma_de[5]_skewness                 float64\n",
      " 1004  lspFreq_sma_de[5]_kurtosis                 float64\n",
      " 1005  lspFreq_sma_de[5]_quartile1                float64\n",
      " 1006  lspFreq_sma_de[5]_quartile2                float64\n",
      " 1007  lspFreq_sma_de[5]_quartile3                float64\n",
      " 1008  lspFreq_sma_de[5]_iqr1-2                   float64\n",
      " 1009  lspFreq_sma_de[5]_iqr2-3                   float64\n",
      " 1010  lspFreq_sma_de[5]_iqr1-3                   float64\n",
      " 1011  lspFreq_sma_de[6]_max                      float64\n",
      " 1012  lspFreq_sma_de[6]_min                      float64\n",
      " 1013  lspFreq_sma_de[6]_range                    float64\n",
      " 1014  lspFreq_sma_de[6]_maxPos                   float64\n",
      " 1015  lspFreq_sma_de[6]_minPos                   float64\n",
      " 1016  lspFreq_sma_de[6]_amean                    float64\n",
      " 1017  lspFreq_sma_de[6]_linregc1                 float64\n",
      " 1018  lspFreq_sma_de[6]_linregc2                 float64\n",
      " 1019  lspFreq_sma_de[6]_linregerrA               float64\n",
      " 1020  lspFreq_sma_de[6]_linregerrQ               float64\n",
      " 1021  lspFreq_sma_de[6]_stddev                   float64\n",
      " 1022  lspFreq_sma_de[6]_skewness                 float64\n",
      " 1023  lspFreq_sma_de[6]_kurtosis                 float64\n",
      " 1024  lspFreq_sma_de[6]_quartile1                float64\n",
      " 1025  lspFreq_sma_de[6]_quartile2                float64\n",
      " 1026  lspFreq_sma_de[6]_quartile3                float64\n",
      " 1027  lspFreq_sma_de[6]_iqr1-2                   float64\n",
      " 1028  lspFreq_sma_de[6]_iqr2-3                   float64\n",
      " 1029  lspFreq_sma_de[6]_iqr1-3                   float64\n",
      " 1030  lspFreq_sma_de[7]_max                      float64\n",
      " 1031  lspFreq_sma_de[7]_min                      float64\n",
      " 1032  lspFreq_sma_de[7]_range                    float64\n",
      " 1033  lspFreq_sma_de[7]_maxPos                   float64\n",
      " 1034  lspFreq_sma_de[7]_minPos                   float64\n",
      " 1035  lspFreq_sma_de[7]_amean                    float64\n",
      " 1036  lspFreq_sma_de[7]_linregc1                 float64\n",
      " 1037  lspFreq_sma_de[7]_linregc2                 float64\n",
      " 1038  lspFreq_sma_de[7]_linregerrA               float64\n",
      " 1039  lspFreq_sma_de[7]_linregerrQ               float64\n",
      " 1040  lspFreq_sma_de[7]_stddev                   float64\n",
      " 1041  lspFreq_sma_de[7]_skewness                 float64\n",
      " 1042  lspFreq_sma_de[7]_kurtosis                 float64\n",
      " 1043  lspFreq_sma_de[7]_quartile1                float64\n",
      " 1044  lspFreq_sma_de[7]_quartile2                float64\n",
      " 1045  lspFreq_sma_de[7]_quartile3                float64\n",
      " 1046  lspFreq_sma_de[7]_iqr1-2                   float64\n",
      " 1047  lspFreq_sma_de[7]_iqr2-3                   float64\n",
      " 1048  lspFreq_sma_de[7]_iqr1-3                   float64\n",
      " 1049  pcm_zcr_sma_de_max                         float64\n",
      " 1050  pcm_zcr_sma_de_min                         float64\n",
      " 1051  pcm_zcr_sma_de_range                       float64\n",
      " 1052  pcm_zcr_sma_de_maxPos                      float64\n",
      " 1053  pcm_zcr_sma_de_minPos                      float64\n",
      " 1054  pcm_zcr_sma_de_amean                       float64\n",
      " 1055  pcm_zcr_sma_de_linregc1                    float64\n",
      " 1056  pcm_zcr_sma_de_linregc2                    float64\n",
      " 1057  pcm_zcr_sma_de_linregerrA                  float64\n",
      " 1058  pcm_zcr_sma_de_linregerrQ                  float64\n",
      " 1059  pcm_zcr_sma_de_stddev                      float64\n",
      " 1060  pcm_zcr_sma_de_skewness                    float64\n",
      " 1061  pcm_zcr_sma_de_kurtosis                    float64\n",
      " 1062  pcm_zcr_sma_de_quartile1                   float64\n",
      " 1063  pcm_zcr_sma_de_quartile2                   float64\n",
      " 1064  pcm_zcr_sma_de_quartile3                   float64\n",
      " 1065  pcm_zcr_sma_de_iqr1-2                      float64\n",
      " 1066  pcm_zcr_sma_de_iqr2-3                      float64\n",
      " 1067  pcm_zcr_sma_de_iqr1-3                      float64\n",
      " 1068  voiceProb_sma_de_max                       float64\n",
      " 1069  voiceProb_sma_de_min                       float64\n",
      " 1070  voiceProb_sma_de_range                     float64\n",
      " 1071  voiceProb_sma_de_maxPos                    float64\n",
      " 1072  voiceProb_sma_de_minPos                    float64\n",
      " 1073  voiceProb_sma_de_amean                     float64\n",
      " 1074  voiceProb_sma_de_linregc1                  float64\n",
      " 1075  voiceProb_sma_de_linregc2                  float64\n",
      " 1076  voiceProb_sma_de_linregerrA                float64\n",
      " 1077  voiceProb_sma_de_linregerrQ                float64\n",
      " 1078  voiceProb_sma_de_stddev                    float64\n",
      " 1079  voiceProb_sma_de_skewness                  float64\n",
      " 1080  voiceProb_sma_de_kurtosis                  float64\n",
      " 1081  voiceProb_sma_de_quartile1                 float64\n",
      " 1082  voiceProb_sma_de_quartile2                 float64\n",
      " 1083  voiceProb_sma_de_quartile3                 float64\n",
      " 1084  voiceProb_sma_de_iqr1-2                    float64\n",
      " 1085  voiceProb_sma_de_iqr2-3                    float64\n",
      " 1086  voiceProb_sma_de_iqr1-3                    float64\n",
      " 1087  F0_sma_de_max                              float64\n",
      " 1088  F0_sma_de_min                              float64\n",
      " 1089  F0_sma_de_range                            float64\n",
      " 1090  F0_sma_de_maxPos                           float64\n",
      " 1091  F0_sma_de_minPos                           float64\n",
      " 1092  F0_sma_de_amean                            float64\n",
      " 1093  F0_sma_de_linregc1                         float64\n",
      " 1094  F0_sma_de_linregc2                         float64\n",
      " 1095  F0_sma_de_linregerrA                       float64\n",
      " 1096  F0_sma_de_linregerrQ                       float64\n",
      " 1097  F0_sma_de_stddev                           float64\n",
      " 1098  F0_sma_de_skewness                         float64\n",
      " 1099  F0_sma_de_kurtosis                         float64\n",
      " 1100  F0_sma_de_quartile1                        float64\n",
      " 1101  F0_sma_de_quartile2                        float64\n",
      " 1102  F0_sma_de_quartile3                        float64\n",
      " 1103  F0_sma_de_iqr1-2                           float64\n",
      " 1104  F0_sma_de_iqr2-3                           float64\n",
      " 1105  F0_sma_de_iqr1-3                           float64\n",
      " 1106  F0env_sma_de_max                           float64\n",
      " 1107  F0env_sma_de_min                           float64\n",
      " 1108  F0env_sma_de_range                         float64\n",
      " 1109  F0env_sma_de_maxPos                        float64\n",
      " 1110  F0env_sma_de_minPos                        float64\n",
      " 1111  F0env_sma_de_amean                         float64\n",
      " 1112  F0env_sma_de_linregc1                      float64\n",
      " 1113  F0env_sma_de_linregc2                      float64\n",
      " 1114  F0env_sma_de_linregerrA                    float64\n",
      " 1115  F0env_sma_de_linregerrQ                    float64\n",
      " 1116  F0env_sma_de_stddev                        float64\n",
      " 1117  F0env_sma_de_skewness                      float64\n",
      " 1118  F0env_sma_de_kurtosis                      float64\n",
      " 1119  F0env_sma_de_quartile1                     float64\n",
      " 1120  F0env_sma_de_quartile2                     float64\n",
      " 1121  F0env_sma_de_quartile3                     float64\n",
      " 1122  F0env_sma_de_iqr1-2                        float64\n",
      " 1123  F0env_sma_de_iqr2-3                        float64\n",
      " 1124  F0env_sma_de_iqr1-3                        float64\n",
      "dtypes: float64(1124), int64(1)\n",
      "memory usage: 15.0 MB\n"
     ]
    }
   ],
   "source": [
    "df_essentia_best_overall_opensmile_emnobase_features.info(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join both the featureset and annotation set together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lowlevel.melbands_kurtosis.dmean</th>\n",
       "      <th>lowlevel.melbands_kurtosis.dmean2</th>\n",
       "      <th>lowlevel.melbands_kurtosis.dvar</th>\n",
       "      <th>lowlevel.melbands_kurtosis.dvar2</th>\n",
       "      <th>lowlevel.melbands_kurtosis.max</th>\n",
       "      <th>lowlevel.melbands_kurtosis.mean</th>\n",
       "      <th>lowlevel.melbands_kurtosis.median</th>\n",
       "      <th>lowlevel.melbands_kurtosis.min</th>\n",
       "      <th>lowlevel.melbands_kurtosis.stdev</th>\n",
       "      <th>lowlevel.melbands_kurtosis.var</th>\n",
       "      <th>...</th>\n",
       "      <th>F0env_sma_de_skewness</th>\n",
       "      <th>F0env_sma_de_kurtosis</th>\n",
       "      <th>F0env_sma_de_quartile1</th>\n",
       "      <th>F0env_sma_de_quartile2</th>\n",
       "      <th>F0env_sma_de_quartile3</th>\n",
       "      <th>F0env_sma_de_iqr1-2</th>\n",
       "      <th>F0env_sma_de_iqr2-3</th>\n",
       "      <th>F0env_sma_de_iqr1-3</th>\n",
       "      <th>valence_mean_mapped</th>\n",
       "      <th>arousal_mean_mapped</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.005020</td>\n",
       "      <td>0.004055</td>\n",
       "      <td>1.866850e-06</td>\n",
       "      <td>1.524876e-06</td>\n",
       "      <td>0.001798</td>\n",
       "      <td>0.023745</td>\n",
       "      <td>0.027549</td>\n",
       "      <td>0.131211</td>\n",
       "      <td>0.003891</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052970</td>\n",
       "      <td>0.008991</td>\n",
       "      <td>0.546204</td>\n",
       "      <td>0.931732</td>\n",
       "      <td>0.403270</td>\n",
       "      <td>0.453796</td>\n",
       "      <td>0.401456</td>\n",
       "      <td>0.428889</td>\n",
       "      <td>-0.475</td>\n",
       "      <td>-0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.009253</td>\n",
       "      <td>0.007287</td>\n",
       "      <td>3.311122e-06</td>\n",
       "      <td>2.524975e-06</td>\n",
       "      <td>0.002593</td>\n",
       "      <td>0.082083</td>\n",
       "      <td>0.140294</td>\n",
       "      <td>0.151787</td>\n",
       "      <td>0.005776</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>...</td>\n",
       "      <td>0.068615</td>\n",
       "      <td>0.031988</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.931732</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.375</td>\n",
       "      <td>-0.425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.004331</td>\n",
       "      <td>0.003332</td>\n",
       "      <td>9.901372e-07</td>\n",
       "      <td>7.146511e-07</td>\n",
       "      <td>0.000979</td>\n",
       "      <td>0.018062</td>\n",
       "      <td>0.026788</td>\n",
       "      <td>0.102714</td>\n",
       "      <td>0.002002</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>...</td>\n",
       "      <td>0.048627</td>\n",
       "      <td>0.007233</td>\n",
       "      <td>0.706684</td>\n",
       "      <td>0.931732</td>\n",
       "      <td>0.238975</td>\n",
       "      <td>0.293316</td>\n",
       "      <td>0.237900</td>\n",
       "      <td>0.266529</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.003204</td>\n",
       "      <td>0.002534</td>\n",
       "      <td>4.937064e-07</td>\n",
       "      <td>4.159568e-07</td>\n",
       "      <td>0.000692</td>\n",
       "      <td>0.016018</td>\n",
       "      <td>0.024134</td>\n",
       "      <td>0.052080</td>\n",
       "      <td>0.001598</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046268</td>\n",
       "      <td>0.006583</td>\n",
       "      <td>0.578416</td>\n",
       "      <td>0.931732</td>\n",
       "      <td>0.412816</td>\n",
       "      <td>0.421584</td>\n",
       "      <td>0.410959</td>\n",
       "      <td>0.417262</td>\n",
       "      <td>-0.150</td>\n",
       "      <td>0.075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.025812</td>\n",
       "      <td>0.019064</td>\n",
       "      <td>1.650024e-05</td>\n",
       "      <td>1.234842e-05</td>\n",
       "      <td>0.003508</td>\n",
       "      <td>0.107675</td>\n",
       "      <td>0.179964</td>\n",
       "      <td>0.143354</td>\n",
       "      <td>0.008974</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052501</td>\n",
       "      <td>0.011769</td>\n",
       "      <td>0.740093</td>\n",
       "      <td>0.931732</td>\n",
       "      <td>0.256946</td>\n",
       "      <td>0.259907</td>\n",
       "      <td>0.255790</td>\n",
       "      <td>0.258448</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1739</th>\n",
       "      <td>0.003420</td>\n",
       "      <td>0.002785</td>\n",
       "      <td>5.455507e-07</td>\n",
       "      <td>4.706971e-07</td>\n",
       "      <td>0.000535</td>\n",
       "      <td>0.013781</td>\n",
       "      <td>0.024485</td>\n",
       "      <td>0.111224</td>\n",
       "      <td>0.001102</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.272948</td>\n",
       "      <td>0.173102</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.931732</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.275</td>\n",
       "      <td>0.225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1740</th>\n",
       "      <td>0.003040</td>\n",
       "      <td>0.002581</td>\n",
       "      <td>4.429354e-07</td>\n",
       "      <td>4.051469e-07</td>\n",
       "      <td>0.000492</td>\n",
       "      <td>0.012825</td>\n",
       "      <td>0.018914</td>\n",
       "      <td>0.078724</td>\n",
       "      <td>0.001181</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>...</td>\n",
       "      <td>0.090879</td>\n",
       "      <td>0.028913</td>\n",
       "      <td>0.962139</td>\n",
       "      <td>0.931732</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.037861</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019198</td>\n",
       "      <td>0.075</td>\n",
       "      <td>-0.275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1741</th>\n",
       "      <td>0.004671</td>\n",
       "      <td>0.003816</td>\n",
       "      <td>2.087614e-06</td>\n",
       "      <td>1.831211e-06</td>\n",
       "      <td>0.002208</td>\n",
       "      <td>0.016787</td>\n",
       "      <td>0.025345</td>\n",
       "      <td>0.058193</td>\n",
       "      <td>0.002020</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046131</td>\n",
       "      <td>0.017807</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.931732</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1742</th>\n",
       "      <td>0.004212</td>\n",
       "      <td>0.003390</td>\n",
       "      <td>7.172558e-07</td>\n",
       "      <td>5.847591e-07</td>\n",
       "      <td>0.001355</td>\n",
       "      <td>0.022245</td>\n",
       "      <td>0.041198</td>\n",
       "      <td>0.244618</td>\n",
       "      <td>0.001735</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>...</td>\n",
       "      <td>0.160770</td>\n",
       "      <td>0.069559</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.931732</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.100</td>\n",
       "      <td>0.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1743</th>\n",
       "      <td>0.006225</td>\n",
       "      <td>0.004963</td>\n",
       "      <td>1.643816e-06</td>\n",
       "      <td>1.337893e-06</td>\n",
       "      <td>0.001744</td>\n",
       "      <td>0.026978</td>\n",
       "      <td>0.035143</td>\n",
       "      <td>0.008661</td>\n",
       "      <td>0.003243</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037200</td>\n",
       "      <td>0.008816</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.931732</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1744 rows × 1126 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      lowlevel.melbands_kurtosis.dmean  lowlevel.melbands_kurtosis.dmean2  \\\n",
       "0                             0.005020                           0.004055   \n",
       "1                             0.009253                           0.007287   \n",
       "2                             0.004331                           0.003332   \n",
       "3                             0.003204                           0.002534   \n",
       "4                             0.025812                           0.019064   \n",
       "...                                ...                                ...   \n",
       "1739                          0.003420                           0.002785   \n",
       "1740                          0.003040                           0.002581   \n",
       "1741                          0.004671                           0.003816   \n",
       "1742                          0.004212                           0.003390   \n",
       "1743                          0.006225                           0.004963   \n",
       "\n",
       "      lowlevel.melbands_kurtosis.dvar  lowlevel.melbands_kurtosis.dvar2  \\\n",
       "0                        1.866850e-06                      1.524876e-06   \n",
       "1                        3.311122e-06                      2.524975e-06   \n",
       "2                        9.901372e-07                      7.146511e-07   \n",
       "3                        4.937064e-07                      4.159568e-07   \n",
       "4                        1.650024e-05                      1.234842e-05   \n",
       "...                               ...                               ...   \n",
       "1739                     5.455507e-07                      4.706971e-07   \n",
       "1740                     4.429354e-07                      4.051469e-07   \n",
       "1741                     2.087614e-06                      1.831211e-06   \n",
       "1742                     7.172558e-07                      5.847591e-07   \n",
       "1743                     1.643816e-06                      1.337893e-06   \n",
       "\n",
       "      lowlevel.melbands_kurtosis.max  lowlevel.melbands_kurtosis.mean  \\\n",
       "0                           0.001798                         0.023745   \n",
       "1                           0.002593                         0.082083   \n",
       "2                           0.000979                         0.018062   \n",
       "3                           0.000692                         0.016018   \n",
       "4                           0.003508                         0.107675   \n",
       "...                              ...                              ...   \n",
       "1739                        0.000535                         0.013781   \n",
       "1740                        0.000492                         0.012825   \n",
       "1741                        0.002208                         0.016787   \n",
       "1742                        0.001355                         0.022245   \n",
       "1743                        0.001744                         0.026978   \n",
       "\n",
       "      lowlevel.melbands_kurtosis.median  lowlevel.melbands_kurtosis.min  \\\n",
       "0                              0.027549                        0.131211   \n",
       "1                              0.140294                        0.151787   \n",
       "2                              0.026788                        0.102714   \n",
       "3                              0.024134                        0.052080   \n",
       "4                              0.179964                        0.143354   \n",
       "...                                 ...                             ...   \n",
       "1739                           0.024485                        0.111224   \n",
       "1740                           0.018914                        0.078724   \n",
       "1741                           0.025345                        0.058193   \n",
       "1742                           0.041198                        0.244618   \n",
       "1743                           0.035143                        0.008661   \n",
       "\n",
       "      lowlevel.melbands_kurtosis.stdev  lowlevel.melbands_kurtosis.var  ...  \\\n",
       "0                             0.003891                        0.000016  ...   \n",
       "1                             0.005776                        0.000035  ...   \n",
       "2                             0.002002                        0.000004  ...   \n",
       "3                             0.001598                        0.000003  ...   \n",
       "4                             0.008974                        0.000083  ...   \n",
       "...                                ...                             ...  ...   \n",
       "1739                          0.001102                        0.000001  ...   \n",
       "1740                          0.001181                        0.000002  ...   \n",
       "1741                          0.002020                        0.000005  ...   \n",
       "1742                          0.001735                        0.000003  ...   \n",
       "1743                          0.003243                        0.000011  ...   \n",
       "\n",
       "      F0env_sma_de_skewness  F0env_sma_de_kurtosis  F0env_sma_de_quartile1  \\\n",
       "0                  0.052970               0.008991                0.546204   \n",
       "1                  0.068615               0.031988                1.000000   \n",
       "2                  0.048627               0.007233                0.706684   \n",
       "3                  0.046268               0.006583                0.578416   \n",
       "4                  0.052501               0.011769                0.740093   \n",
       "...                     ...                    ...                     ...   \n",
       "1739               0.272948               0.173102                1.000000   \n",
       "1740               0.090879               0.028913                0.962139   \n",
       "1741               0.046131               0.017807                1.000000   \n",
       "1742               0.160770               0.069559                1.000000   \n",
       "1743               0.037200               0.008816                1.000000   \n",
       "\n",
       "      F0env_sma_de_quartile2  F0env_sma_de_quartile3  F0env_sma_de_iqr1-2  \\\n",
       "0                   0.931732                0.403270             0.453796   \n",
       "1                   0.931732                0.000000             0.000000   \n",
       "2                   0.931732                0.238975             0.293316   \n",
       "3                   0.931732                0.412816             0.421584   \n",
       "4                   0.931732                0.256946             0.259907   \n",
       "...                      ...                     ...                  ...   \n",
       "1739                0.931732                0.000000             0.000000   \n",
       "1740                0.931732                0.000000             0.037861   \n",
       "1741                0.931732                0.000000             0.000000   \n",
       "1742                0.931732                0.000000             0.000000   \n",
       "1743                0.931732                0.000000             0.000000   \n",
       "\n",
       "      F0env_sma_de_iqr2-3  F0env_sma_de_iqr1-3  valence_mean_mapped  \\\n",
       "0                0.401456             0.428889               -0.475   \n",
       "1                0.000000             0.000000               -0.375   \n",
       "2                0.237900             0.266529                0.175   \n",
       "3                0.410959             0.417262               -0.150   \n",
       "4                0.255790             0.258448                0.200   \n",
       "...                   ...                  ...                  ...   \n",
       "1739             0.000000             0.000000               -0.275   \n",
       "1740             0.000000             0.019198                0.075   \n",
       "1741             0.000000             0.000000                0.350   \n",
       "1742             0.000000             0.000000               -0.100   \n",
       "1743             0.000000             0.000000                0.200   \n",
       "\n",
       "      arousal_mean_mapped  \n",
       "0                  -0.500  \n",
       "1                  -0.425  \n",
       "2                   0.125  \n",
       "3                   0.075  \n",
       "4                   0.350  \n",
       "...                   ...  \n",
       "1739                0.225  \n",
       "1740               -0.275  \n",
       "1741                0.300  \n",
       "1742                0.100  \n",
       "1743                0.250  \n",
       "\n",
       "[1744 rows x 1126 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_essentia_best_overall_opensmile_emobase_whole = pd.merge(df_essentia_best_overall_opensmile_emnobase_features, df_annotations, how='inner', on='song_id')\n",
    "df_essentia_best_overall_opensmile_emobase_whole = df_essentia_best_overall_opensmile_emobase_whole.drop('song_id', axis=1)\n",
    "df_essentia_best_overall_opensmile_emobase_whole"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare dataframes for the neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform splitting of the dataframe into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lowlevel.melbands_kurtosis.dmean</th>\n",
       "      <th>lowlevel.melbands_kurtosis.dmean2</th>\n",
       "      <th>lowlevel.melbands_kurtosis.dvar</th>\n",
       "      <th>lowlevel.melbands_kurtosis.dvar2</th>\n",
       "      <th>lowlevel.melbands_kurtosis.max</th>\n",
       "      <th>lowlevel.melbands_kurtosis.mean</th>\n",
       "      <th>lowlevel.melbands_kurtosis.median</th>\n",
       "      <th>lowlevel.melbands_kurtosis.min</th>\n",
       "      <th>lowlevel.melbands_kurtosis.stdev</th>\n",
       "      <th>lowlevel.melbands_kurtosis.var</th>\n",
       "      <th>...</th>\n",
       "      <th>F0env_sma_de_linregerrQ</th>\n",
       "      <th>F0env_sma_de_stddev</th>\n",
       "      <th>F0env_sma_de_skewness</th>\n",
       "      <th>F0env_sma_de_kurtosis</th>\n",
       "      <th>F0env_sma_de_quartile1</th>\n",
       "      <th>F0env_sma_de_quartile2</th>\n",
       "      <th>F0env_sma_de_quartile3</th>\n",
       "      <th>F0env_sma_de_iqr1-2</th>\n",
       "      <th>F0env_sma_de_iqr2-3</th>\n",
       "      <th>F0env_sma_de_iqr1-3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.005020</td>\n",
       "      <td>0.004055</td>\n",
       "      <td>1.866850e-06</td>\n",
       "      <td>1.524876e-06</td>\n",
       "      <td>0.001798</td>\n",
       "      <td>0.023745</td>\n",
       "      <td>0.027549</td>\n",
       "      <td>0.131211</td>\n",
       "      <td>0.003891</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>...</td>\n",
       "      <td>0.427306</td>\n",
       "      <td>0.633121</td>\n",
       "      <td>0.052970</td>\n",
       "      <td>0.008991</td>\n",
       "      <td>0.546204</td>\n",
       "      <td>0.931732</td>\n",
       "      <td>0.403270</td>\n",
       "      <td>0.453796</td>\n",
       "      <td>0.401456</td>\n",
       "      <td>0.428889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.009253</td>\n",
       "      <td>0.007287</td>\n",
       "      <td>3.311122e-06</td>\n",
       "      <td>2.524975e-06</td>\n",
       "      <td>0.002593</td>\n",
       "      <td>0.082083</td>\n",
       "      <td>0.140294</td>\n",
       "      <td>0.151787</td>\n",
       "      <td>0.005776</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>...</td>\n",
       "      <td>0.141595</td>\n",
       "      <td>0.340520</td>\n",
       "      <td>0.068615</td>\n",
       "      <td>0.031988</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.931732</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.004331</td>\n",
       "      <td>0.003332</td>\n",
       "      <td>9.901372e-07</td>\n",
       "      <td>7.146511e-07</td>\n",
       "      <td>0.000979</td>\n",
       "      <td>0.018062</td>\n",
       "      <td>0.026788</td>\n",
       "      <td>0.102714</td>\n",
       "      <td>0.002002</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>...</td>\n",
       "      <td>0.399049</td>\n",
       "      <td>0.609771</td>\n",
       "      <td>0.048627</td>\n",
       "      <td>0.007233</td>\n",
       "      <td>0.706684</td>\n",
       "      <td>0.931732</td>\n",
       "      <td>0.238975</td>\n",
       "      <td>0.293316</td>\n",
       "      <td>0.237900</td>\n",
       "      <td>0.266529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.003204</td>\n",
       "      <td>0.002534</td>\n",
       "      <td>4.937064e-07</td>\n",
       "      <td>4.159568e-07</td>\n",
       "      <td>0.000692</td>\n",
       "      <td>0.016018</td>\n",
       "      <td>0.024134</td>\n",
       "      <td>0.052080</td>\n",
       "      <td>0.001598</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>...</td>\n",
       "      <td>0.416902</td>\n",
       "      <td>0.624603</td>\n",
       "      <td>0.046268</td>\n",
       "      <td>0.006583</td>\n",
       "      <td>0.578416</td>\n",
       "      <td>0.931732</td>\n",
       "      <td>0.412816</td>\n",
       "      <td>0.421584</td>\n",
       "      <td>0.410959</td>\n",
       "      <td>0.417262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.025812</td>\n",
       "      <td>0.019064</td>\n",
       "      <td>1.650024e-05</td>\n",
       "      <td>1.234842e-05</td>\n",
       "      <td>0.003508</td>\n",
       "      <td>0.107675</td>\n",
       "      <td>0.179964</td>\n",
       "      <td>0.143354</td>\n",
       "      <td>0.008974</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>...</td>\n",
       "      <td>0.291508</td>\n",
       "      <td>0.512783</td>\n",
       "      <td>0.052501</td>\n",
       "      <td>0.011769</td>\n",
       "      <td>0.740093</td>\n",
       "      <td>0.931732</td>\n",
       "      <td>0.256946</td>\n",
       "      <td>0.259907</td>\n",
       "      <td>0.255790</td>\n",
       "      <td>0.258448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1739</th>\n",
       "      <td>0.003420</td>\n",
       "      <td>0.002785</td>\n",
       "      <td>5.455507e-07</td>\n",
       "      <td>4.706971e-07</td>\n",
       "      <td>0.000535</td>\n",
       "      <td>0.013781</td>\n",
       "      <td>0.024485</td>\n",
       "      <td>0.111224</td>\n",
       "      <td>0.001102</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.108314</td>\n",
       "      <td>0.291082</td>\n",
       "      <td>0.272948</td>\n",
       "      <td>0.173102</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.931732</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1740</th>\n",
       "      <td>0.003040</td>\n",
       "      <td>0.002581</td>\n",
       "      <td>4.429354e-07</td>\n",
       "      <td>4.051469e-07</td>\n",
       "      <td>0.000492</td>\n",
       "      <td>0.012825</td>\n",
       "      <td>0.018914</td>\n",
       "      <td>0.078724</td>\n",
       "      <td>0.001181</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023071</td>\n",
       "      <td>0.109289</td>\n",
       "      <td>0.090879</td>\n",
       "      <td>0.028913</td>\n",
       "      <td>0.962139</td>\n",
       "      <td>0.931732</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.037861</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1741</th>\n",
       "      <td>0.004671</td>\n",
       "      <td>0.003816</td>\n",
       "      <td>2.087614e-06</td>\n",
       "      <td>1.831211e-06</td>\n",
       "      <td>0.002208</td>\n",
       "      <td>0.016787</td>\n",
       "      <td>0.025345</td>\n",
       "      <td>0.058193</td>\n",
       "      <td>0.002020</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>...</td>\n",
       "      <td>0.139224</td>\n",
       "      <td>0.337426</td>\n",
       "      <td>0.046131</td>\n",
       "      <td>0.017807</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.931732</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1742</th>\n",
       "      <td>0.004212</td>\n",
       "      <td>0.003390</td>\n",
       "      <td>7.172558e-07</td>\n",
       "      <td>5.847591e-07</td>\n",
       "      <td>0.001355</td>\n",
       "      <td>0.022245</td>\n",
       "      <td>0.041198</td>\n",
       "      <td>0.244618</td>\n",
       "      <td>0.001735</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>...</td>\n",
       "      <td>0.096113</td>\n",
       "      <td>0.271372</td>\n",
       "      <td>0.160770</td>\n",
       "      <td>0.069559</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.931732</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1743</th>\n",
       "      <td>0.006225</td>\n",
       "      <td>0.004963</td>\n",
       "      <td>1.643816e-06</td>\n",
       "      <td>1.337893e-06</td>\n",
       "      <td>0.001744</td>\n",
       "      <td>0.026978</td>\n",
       "      <td>0.035143</td>\n",
       "      <td>0.008661</td>\n",
       "      <td>0.003243</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>...</td>\n",
       "      <td>0.204641</td>\n",
       "      <td>0.420434</td>\n",
       "      <td>0.037200</td>\n",
       "      <td>0.008816</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.931732</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1744 rows × 1124 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      lowlevel.melbands_kurtosis.dmean  lowlevel.melbands_kurtosis.dmean2  \\\n",
       "0                             0.005020                           0.004055   \n",
       "1                             0.009253                           0.007287   \n",
       "2                             0.004331                           0.003332   \n",
       "3                             0.003204                           0.002534   \n",
       "4                             0.025812                           0.019064   \n",
       "...                                ...                                ...   \n",
       "1739                          0.003420                           0.002785   \n",
       "1740                          0.003040                           0.002581   \n",
       "1741                          0.004671                           0.003816   \n",
       "1742                          0.004212                           0.003390   \n",
       "1743                          0.006225                           0.004963   \n",
       "\n",
       "      lowlevel.melbands_kurtosis.dvar  lowlevel.melbands_kurtosis.dvar2  \\\n",
       "0                        1.866850e-06                      1.524876e-06   \n",
       "1                        3.311122e-06                      2.524975e-06   \n",
       "2                        9.901372e-07                      7.146511e-07   \n",
       "3                        4.937064e-07                      4.159568e-07   \n",
       "4                        1.650024e-05                      1.234842e-05   \n",
       "...                               ...                               ...   \n",
       "1739                     5.455507e-07                      4.706971e-07   \n",
       "1740                     4.429354e-07                      4.051469e-07   \n",
       "1741                     2.087614e-06                      1.831211e-06   \n",
       "1742                     7.172558e-07                      5.847591e-07   \n",
       "1743                     1.643816e-06                      1.337893e-06   \n",
       "\n",
       "      lowlevel.melbands_kurtosis.max  lowlevel.melbands_kurtosis.mean  \\\n",
       "0                           0.001798                         0.023745   \n",
       "1                           0.002593                         0.082083   \n",
       "2                           0.000979                         0.018062   \n",
       "3                           0.000692                         0.016018   \n",
       "4                           0.003508                         0.107675   \n",
       "...                              ...                              ...   \n",
       "1739                        0.000535                         0.013781   \n",
       "1740                        0.000492                         0.012825   \n",
       "1741                        0.002208                         0.016787   \n",
       "1742                        0.001355                         0.022245   \n",
       "1743                        0.001744                         0.026978   \n",
       "\n",
       "      lowlevel.melbands_kurtosis.median  lowlevel.melbands_kurtosis.min  \\\n",
       "0                              0.027549                        0.131211   \n",
       "1                              0.140294                        0.151787   \n",
       "2                              0.026788                        0.102714   \n",
       "3                              0.024134                        0.052080   \n",
       "4                              0.179964                        0.143354   \n",
       "...                                 ...                             ...   \n",
       "1739                           0.024485                        0.111224   \n",
       "1740                           0.018914                        0.078724   \n",
       "1741                           0.025345                        0.058193   \n",
       "1742                           0.041198                        0.244618   \n",
       "1743                           0.035143                        0.008661   \n",
       "\n",
       "      lowlevel.melbands_kurtosis.stdev  lowlevel.melbands_kurtosis.var  ...  \\\n",
       "0                             0.003891                        0.000016  ...   \n",
       "1                             0.005776                        0.000035  ...   \n",
       "2                             0.002002                        0.000004  ...   \n",
       "3                             0.001598                        0.000003  ...   \n",
       "4                             0.008974                        0.000083  ...   \n",
       "...                                ...                             ...  ...   \n",
       "1739                          0.001102                        0.000001  ...   \n",
       "1740                          0.001181                        0.000002  ...   \n",
       "1741                          0.002020                        0.000005  ...   \n",
       "1742                          0.001735                        0.000003  ...   \n",
       "1743                          0.003243                        0.000011  ...   \n",
       "\n",
       "      F0env_sma_de_linregerrQ  F0env_sma_de_stddev  F0env_sma_de_skewness  \\\n",
       "0                    0.427306             0.633121               0.052970   \n",
       "1                    0.141595             0.340520               0.068615   \n",
       "2                    0.399049             0.609771               0.048627   \n",
       "3                    0.416902             0.624603               0.046268   \n",
       "4                    0.291508             0.512783               0.052501   \n",
       "...                       ...                  ...                    ...   \n",
       "1739                 0.108314             0.291082               0.272948   \n",
       "1740                 0.023071             0.109289               0.090879   \n",
       "1741                 0.139224             0.337426               0.046131   \n",
       "1742                 0.096113             0.271372               0.160770   \n",
       "1743                 0.204641             0.420434               0.037200   \n",
       "\n",
       "      F0env_sma_de_kurtosis  F0env_sma_de_quartile1  F0env_sma_de_quartile2  \\\n",
       "0                  0.008991                0.546204                0.931732   \n",
       "1                  0.031988                1.000000                0.931732   \n",
       "2                  0.007233                0.706684                0.931732   \n",
       "3                  0.006583                0.578416                0.931732   \n",
       "4                  0.011769                0.740093                0.931732   \n",
       "...                     ...                     ...                     ...   \n",
       "1739               0.173102                1.000000                0.931732   \n",
       "1740               0.028913                0.962139                0.931732   \n",
       "1741               0.017807                1.000000                0.931732   \n",
       "1742               0.069559                1.000000                0.931732   \n",
       "1743               0.008816                1.000000                0.931732   \n",
       "\n",
       "      F0env_sma_de_quartile3  F0env_sma_de_iqr1-2  F0env_sma_de_iqr2-3  \\\n",
       "0                   0.403270             0.453796             0.401456   \n",
       "1                   0.000000             0.000000             0.000000   \n",
       "2                   0.238975             0.293316             0.237900   \n",
       "3                   0.412816             0.421584             0.410959   \n",
       "4                   0.256946             0.259907             0.255790   \n",
       "...                      ...                  ...                  ...   \n",
       "1739                0.000000             0.000000             0.000000   \n",
       "1740                0.000000             0.037861             0.000000   \n",
       "1741                0.000000             0.000000             0.000000   \n",
       "1742                0.000000             0.000000             0.000000   \n",
       "1743                0.000000             0.000000             0.000000   \n",
       "\n",
       "      F0env_sma_de_iqr1-3  \n",
       "0                0.428889  \n",
       "1                0.000000  \n",
       "2                0.266529  \n",
       "3                0.417262  \n",
       "4                0.258448  \n",
       "...                   ...  \n",
       "1739             0.000000  \n",
       "1740             0.019198  \n",
       "1741             0.000000  \n",
       "1742             0.000000  \n",
       "1743             0.000000  \n",
       "\n",
       "[1744 rows x 1124 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = df_essentia_best_overall_opensmile_emnobase_features.drop('song_id', axis=1)\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>valence_mean_mapped</th>\n",
       "      <th>arousal_mean_mapped</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.475</td>\n",
       "      <td>-0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.375</td>\n",
       "      <td>-0.425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.175</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.150</td>\n",
       "      <td>0.075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.200</td>\n",
       "      <td>0.350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1739</th>\n",
       "      <td>-0.275</td>\n",
       "      <td>0.225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1740</th>\n",
       "      <td>0.075</td>\n",
       "      <td>-0.275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1741</th>\n",
       "      <td>0.350</td>\n",
       "      <td>0.300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1742</th>\n",
       "      <td>-0.100</td>\n",
       "      <td>0.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1743</th>\n",
       "      <td>0.200</td>\n",
       "      <td>0.250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1744 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      valence_mean_mapped  arousal_mean_mapped\n",
       "0                  -0.475               -0.500\n",
       "1                  -0.375               -0.425\n",
       "2                   0.175                0.125\n",
       "3                  -0.150                0.075\n",
       "4                   0.200                0.350\n",
       "...                   ...                  ...\n",
       "1739               -0.275                0.225\n",
       "1740                0.075               -0.275\n",
       "1741                0.350                0.300\n",
       "1742               -0.100                0.100\n",
       "1743                0.200                0.250\n",
       "\n",
       "[1744 rows x 2 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets = df_annotations.drop('song_id', axis=1)\n",
    "targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform 80-20 train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, targets, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create tensors for X_train and X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float64)\n",
    "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create tensors for Y_train and Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float64)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define neural network parameters and instantitate neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 1\n",
    "hidden_size = 20 \n",
    "output_size = 2  # Output size for valence and arousal\n",
    "learning_rate = 0.001\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 157"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set a random seed to ensure consistent initial weights of the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x11c733e50>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the seed\n",
    "seed = 42\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_size, math.ceil((input_size**0.5) * 2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(math.ceil((input_size**0.5) * 2), math.ceil((input_size**0.5) * 2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(math.ceil((input_size**0.5) * 2), math.ceil((input_size**0.5) * 2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(math.ceil((input_size**0.5) * 2), math.ceil((input_size**0.5) * 2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(math.ceil((input_size**0.5) * 2), math.ceil((input_size**0.5) * 2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(math.ceil((input_size**0.5) * 2), math.ceil((input_size**0.5) * 2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(math.ceil((input_size**0.5) * 2), math.ceil((input_size**0.5) * 2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(math.ceil((input_size**0.5) * 2), math.ceil((input_size**0.5) * 2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(math.ceil((input_size**0.5) * 2), math.ceil((input_size**0.5) * 2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(math.ceil((input_size**0.5) * 2), math.ceil((input_size**0.5) * 2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(math.ceil((input_size**0.5) * 2), math.ceil((input_size**0.5) * 2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(math.ceil((input_size**0.5) * 2), 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare input_train_data and target_train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1395, 1124])\n"
     ]
    }
   ],
   "source": [
    "input_train_data = X_train_tensor.float()\n",
    "\n",
    "# input_train_data = input_train_data.view(input_train_data.shape[1], -1)\n",
    "print(input_train_data.shape)\n",
    "\n",
    "target_train_labels = y_train_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(num_epochs):\n",
    "  model = NeuralNetwork(input_size=input_train_data.shape[1])\n",
    "  optimiser = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "  \n",
    "  for epoch in range(num_epochs):\n",
    "    optimiser.zero_grad()\n",
    "    \n",
    "    # forward pass\n",
    "    output = model(input_train_data)\n",
    "\n",
    "    # calculate loss\n",
    "    loss = torch.sqrt(criterion(output.float(), target_train_labels.float()))\n",
    "\n",
    "    # backward pass\n",
    "    loss.backward()\n",
    "    # update weights\n",
    "    optimiser.step()\n",
    "\n",
    "    print(f'Epoch {epoch + 1}, Loss: {math.sqrt(loss.item())}')\n",
    "\n",
    "  print(\"Training completed.\")\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Training completed.\n"
     ]
    }
   ],
   "source": [
    "model = train_model(num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare input_test_data and target_test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([349, 1124])\n"
     ]
    }
   ],
   "source": [
    "input_test_data = X_test_tensor.float()\n",
    "\n",
    "# input_test_data = input_test_data.view(input_test_data.shape[1], -1)\n",
    "print(input_test_data.shape)\n",
    "\n",
    "target_test_labels = y_test_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(trained_model):\n",
    "  with torch.no_grad():\n",
    "    test_pred = trained_model(input_test_data)\n",
    "    test_loss = criterion(test_pred.float(), target_test_labels)\n",
    "\n",
    "    # Separate the output into valence and arousal\n",
    "    valence_pred = test_pred[:, 0]\n",
    "    arousal_pred = test_pred[:, 1]\n",
    "        \n",
    "    valence_target = target_test_labels[:, 0]\n",
    "    arousal_target = target_test_labels[:, 1]\n",
    "\n",
    "     # Calculate RMSE for valence and arousal separately\n",
    "    valence_rmse = math.sqrt(mean_squared_error(valence_pred, valence_target))\n",
    "    arousal_rmse = math.sqrt(mean_squared_error(arousal_pred, arousal_target))\n",
    "\n",
    "  rmse = math.sqrt(test_loss.item())\n",
    "  print(f'Test RMSE: {rmse}')\n",
    "\n",
    "  print(f'Valence RMSE: {valence_rmse}')\n",
    "  print(f'Arousal RMSE: {arousal_rmse}')\n",
    "\n",
    "  metric = R2Score(multioutput=\"raw_values\")\n",
    "  metric.update(test_pred, target_test_labels)\n",
    "  adjusted_r2_score = metric.compute()\n",
    "  print(f'Test R^2 score: {adjusted_r2_score}')\n",
    "\n",
    "  # metric = R2Score(multioutput=\"raw_values\", num_regressors=input_test_data.shape[1])\n",
    "  # metric.update(test_pred, target_test_labels)\n",
    "  # adjusted_r2_score = metric.compute()\n",
    "  # print(f'Test Adjusted R^2 score: {adjusted_r2_score}')\n",
    "\n",
    "  metric = R2Score()\n",
    "  metric.update(test_pred, target_test_labels)\n",
    "  r2_score = metric.compute()\n",
    "  print(f'Test R^2 score (overall): {r2_score}')\n",
    "  return test_pred, rmse, adjusted_r2_score, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.2029850378970027\n",
      "Valence RMSE: 0.1882725399978853\n",
      "Arousal RMSE: 0.2167009503967159\n",
      "Test R^2 score: tensor([0.5704, 0.5350], dtype=torch.float64)\n",
      "Test R^2 score (overall): 0.5527237125409493\n"
     ]
    }
   ],
   "source": [
    "test_pred, rmse, adjusted_r2_score, r2_score = test_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), '../../models/deam_feedforward_nn_essentia_best_overall_opensmile_emobase_normalised.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "True values (test set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1500, -0.1500],\n",
       "        [-0.3000, -0.1000],\n",
       "        [ 0.2000,  0.3500],\n",
       "        [ 0.2250,  0.4500],\n",
       "        [-0.1750, -0.2000],\n",
       "        [-0.5250, -0.3000],\n",
       "        [-0.2500, -0.7750],\n",
       "        [ 0.3000,  0.3000],\n",
       "        [-0.1750, -0.4000],\n",
       "        [ 0.4500,  0.1500],\n",
       "        [ 0.1750,  0.0250],\n",
       "        [-0.1750, -0.0250],\n",
       "        [-0.0500, -0.3000],\n",
       "        [ 0.1250,  0.3000],\n",
       "        [-0.0750, -0.1500],\n",
       "        [-0.2000, -0.2750],\n",
       "        [-0.6000, -0.2250],\n",
       "        [ 0.1500, -0.2000],\n",
       "        [ 0.2750,  0.6000],\n",
       "        [-0.1500, -0.4500],\n",
       "        [-0.2250, -0.6250],\n",
       "        [-0.0250, -0.4500],\n",
       "        [-0.5250, -0.1250],\n",
       "        [ 0.0000,  0.3250],\n",
       "        [ 0.1250,  0.3750],\n",
       "        [ 0.1500, -0.2500],\n",
       "        [ 0.4500,  0.3250],\n",
       "        [ 0.2500,  0.2250],\n",
       "        [-0.1000,  0.0750],\n",
       "        [ 0.4250,  0.1250],\n",
       "        [-0.4500, -0.3500],\n",
       "        [-0.0500,  0.3750],\n",
       "        [-0.4750, -0.2000],\n",
       "        [-0.2750, -0.4000],\n",
       "        [-0.4000, -0.2250],\n",
       "        [ 0.1000, -0.4500],\n",
       "        [-0.2250, -0.6750],\n",
       "        [ 0.3000,  0.1250],\n",
       "        [-0.2000, -0.2250],\n",
       "        [ 0.2500,  0.3750],\n",
       "        [-0.3250, -0.4750],\n",
       "        [ 0.2250,  0.2000],\n",
       "        [ 0.0500,  0.1250],\n",
       "        [-0.5750, -0.6000],\n",
       "        [-0.1250, -0.3500],\n",
       "        [ 0.5000,  0.6000],\n",
       "        [-0.1500,  0.3250],\n",
       "        [-0.1750,  0.0250],\n",
       "        [-0.2750, -0.3250],\n",
       "        [ 0.2500,  0.3500],\n",
       "        [-0.3250, -0.7500],\n",
       "        [ 0.3000,  0.4000],\n",
       "        [ 0.0250,  0.2000],\n",
       "        [ 0.3750,  0.2250],\n",
       "        [-0.4250, -0.3750],\n",
       "        [-0.4250, -0.2500],\n",
       "        [-0.5250, -0.1750],\n",
       "        [-0.0500, -0.1500],\n",
       "        [ 0.1250, -0.1000],\n",
       "        [-0.3250, -0.5000],\n",
       "        [-0.4000, -0.0750],\n",
       "        [ 0.1500, -0.0500],\n",
       "        [-0.3000, -0.6500],\n",
       "        [-0.7000, -0.3750],\n",
       "        [ 0.5500,  0.2500],\n",
       "        [-0.2000, -0.1500],\n",
       "        [ 0.0750,  0.0750],\n",
       "        [-0.3000, -0.4000],\n",
       "        [-0.4250, -0.3750],\n",
       "        [-0.5750, -0.1000],\n",
       "        [ 0.2750, -0.1250],\n",
       "        [-0.1750, -0.2000],\n",
       "        [-0.2750, -0.6250],\n",
       "        [-0.4750, -0.3750],\n",
       "        [ 0.2750,  0.1250],\n",
       "        [ 0.3250,  0.4250],\n",
       "        [-0.3000, -0.1500],\n",
       "        [ 0.0500,  0.0750],\n",
       "        [ 0.2750, -0.2500],\n",
       "        [-0.3000, -0.6500],\n",
       "        [-0.3000,  0.2250],\n",
       "        [-0.4000, -0.0500],\n",
       "        [-0.0250, -0.3500],\n",
       "        [ 0.0000, -0.0500],\n",
       "        [-0.3000, -0.1000],\n",
       "        [ 0.3500, -0.3750],\n",
       "        [ 0.0250,  0.2000],\n",
       "        [-0.2500, -0.2250],\n",
       "        [ 0.0000, -0.3250],\n",
       "        [ 0.1500,  0.0000],\n",
       "        [-0.3500, -0.4750],\n",
       "        [-0.1750, -0.1250],\n",
       "        [-0.6750, -0.6000],\n",
       "        [ 0.2500,  0.2750],\n",
       "        [-0.3000, -0.5750],\n",
       "        [-0.1750, -0.5250],\n",
       "        [ 0.2750,  0.3250],\n",
       "        [ 0.3250, -0.1000],\n",
       "        [ 0.1000,  0.1750],\n",
       "        [-0.0750,  0.2000],\n",
       "        [ 0.2250, -0.3250],\n",
       "        [ 0.3750,  0.5500],\n",
       "        [-0.5250, -0.2500],\n",
       "        [-0.1000,  0.1500],\n",
       "        [ 0.1250,  0.1000],\n",
       "        [-0.3750, -0.3250],\n",
       "        [-0.4750, -0.3500],\n",
       "        [-0.2750, -0.2750],\n",
       "        [-0.2000, -0.0750],\n",
       "        [ 0.2750,  0.6000],\n",
       "        [-0.0500, -0.2500],\n",
       "        [-0.0500,  0.2500],\n",
       "        [-0.4750, -0.2000],\n",
       "        [-0.0250,  0.2000],\n",
       "        [-0.0750,  0.1500],\n",
       "        [ 0.6000,  0.6500],\n",
       "        [ 0.3250,  0.1500],\n",
       "        [-0.3500,  0.0000],\n",
       "        [ 0.2500,  0.2000],\n",
       "        [-0.1500,  0.3750],\n",
       "        [ 0.2250,  0.1000],\n",
       "        [ 0.2750, -0.4250],\n",
       "        [-0.0750,  0.6250],\n",
       "        [-0.1750, -0.3000],\n",
       "        [-0.0750, -0.6500],\n",
       "        [-0.1250,  0.1000],\n",
       "        [ 0.0000, -0.0250],\n",
       "        [ 0.0500,  0.0500],\n",
       "        [-0.1000,  0.0250],\n",
       "        [ 0.2000, -0.0750],\n",
       "        [-0.2750,  0.2250],\n",
       "        [-0.3750,  0.1250],\n",
       "        [-0.0750,  0.0500],\n",
       "        [ 0.3000,  0.0000],\n",
       "        [ 0.2000,  0.3000],\n",
       "        [ 0.3500,  0.1000],\n",
       "        [ 0.5750,  0.6000],\n",
       "        [-0.2750,  0.1250],\n",
       "        [ 0.0750, -0.3500],\n",
       "        [-0.0750, -0.3750],\n",
       "        [ 0.3750,  0.1000],\n",
       "        [ 0.0500, -0.0750],\n",
       "        [-0.4000, -0.0500],\n",
       "        [-0.1750, -0.2750],\n",
       "        [ 0.2000, -0.1750],\n",
       "        [ 0.2750,  0.1000],\n",
       "        [-0.0500, -0.2750],\n",
       "        [-0.3000, -0.4000],\n",
       "        [-0.1250, -0.0500],\n",
       "        [ 0.0250, -0.3500],\n",
       "        [-0.2000, -0.8500],\n",
       "        [ 0.1500,  0.0250],\n",
       "        [ 0.2250, -0.4000],\n",
       "        [-0.1250, -0.2000],\n",
       "        [ 0.3500,  0.1000],\n",
       "        [-0.2000,  0.0000],\n",
       "        [ 0.0250, -0.3500],\n",
       "        [-0.2250,  0.0000],\n",
       "        [-0.0750,  0.1250],\n",
       "        [-0.1000,  0.2000],\n",
       "        [-0.2500, -0.6000],\n",
       "        [ 0.2250,  0.1000],\n",
       "        [ 0.0250,  0.4250],\n",
       "        [-0.2250, -0.2500],\n",
       "        [ 0.1750,  0.3000],\n",
       "        [-0.1500,  0.0500],\n",
       "        [-0.3500, -0.0500],\n",
       "        [-0.4000,  0.2250],\n",
       "        [-0.1000,  0.1500],\n",
       "        [ 0.0000, -0.4750],\n",
       "        [-0.1500, -0.4500],\n",
       "        [ 0.1500,  0.2250],\n",
       "        [ 0.2250,  0.0750],\n",
       "        [ 0.3500,  0.0750],\n",
       "        [ 0.5250,  0.3750],\n",
       "        [ 0.2500,  0.2000],\n",
       "        [ 0.3500,  0.2000],\n",
       "        [-0.0250, -0.3000],\n",
       "        [-0.4000,  0.0750],\n",
       "        [-0.1500,  0.4750],\n",
       "        [-0.4750, -0.6750],\n",
       "        [-0.0750, -0.1750],\n",
       "        [-0.5250, -0.3750],\n",
       "        [ 0.2750, -0.2750],\n",
       "        [ 0.6000,  0.4000],\n",
       "        [-0.4250, -0.5500],\n",
       "        [-0.1500, -0.5750],\n",
       "        [ 0.2250,  0.4500],\n",
       "        [ 0.6500,  0.7000],\n",
       "        [ 0.1750,  0.3250],\n",
       "        [-0.2750, -0.1250],\n",
       "        [-0.2500, -0.4000],\n",
       "        [-0.0250, -0.1250],\n",
       "        [-0.0250, -0.2500],\n",
       "        [-0.1500, -0.3750],\n",
       "        [ 0.3500,  0.4000],\n",
       "        [ 0.5750, -0.4250],\n",
       "        [-0.0750,  0.0750],\n",
       "        [-0.0500, -0.1250],\n",
       "        [ 0.0750,  0.2000],\n",
       "        [-0.1500, -0.0500],\n",
       "        [-0.1500, -0.3000],\n",
       "        [-0.0500,  0.2500],\n",
       "        [-0.3000, -0.4250],\n",
       "        [-0.3000, -0.3500],\n",
       "        [-0.4000, -0.1000],\n",
       "        [-0.1500, -0.5750],\n",
       "        [-0.0750, -0.3750],\n",
       "        [-0.3500, -0.3500],\n",
       "        [ 0.2250,  0.2250],\n",
       "        [ 0.1250,  0.0000],\n",
       "        [-0.1750, -0.2000],\n",
       "        [-0.0750, -0.3000],\n",
       "        [ 0.5000,  0.4000],\n",
       "        [-0.2000, -0.2250],\n",
       "        [-0.2000, -0.4750],\n",
       "        [ 0.3000,  0.1750],\n",
       "        [ 0.1250,  0.0000],\n",
       "        [ 0.1750,  0.4750],\n",
       "        [ 0.1750, -0.2500],\n",
       "        [-0.1250,  0.4250],\n",
       "        [ 0.2000,  0.4750],\n",
       "        [-0.3000, -0.4000],\n",
       "        [-0.1250, -0.5250],\n",
       "        [-0.5750, -0.0750],\n",
       "        [ 0.1750, -0.0250],\n",
       "        [ 0.4000,  0.3500],\n",
       "        [-0.2500,  0.0000],\n",
       "        [-0.4750, -0.3000],\n",
       "        [ 0.1250,  0.2750],\n",
       "        [ 0.0750,  0.1750],\n",
       "        [ 0.3750,  0.1500],\n",
       "        [-0.1750, -0.2250],\n",
       "        [ 0.1250,  0.2750],\n",
       "        [-0.4500, -0.3250],\n",
       "        [ 0.3000,  0.0750],\n",
       "        [-0.3000,  0.0250],\n",
       "        [-0.3250, -0.5250],\n",
       "        [-0.1250, -0.0250],\n",
       "        [ 0.1250,  0.2000],\n",
       "        [-0.3750,  0.0500],\n",
       "        [-0.3250, -0.0500],\n",
       "        [ 0.0500,  0.3000],\n",
       "        [-0.5500, -0.3250],\n",
       "        [-0.2750, -0.3000],\n",
       "        [-0.2750, -0.5500],\n",
       "        [-0.1750, -0.5750],\n",
       "        [ 0.4500,  0.3000],\n",
       "        [-0.2500,  0.1250],\n",
       "        [-0.1000, -0.3250],\n",
       "        [ 0.1250,  0.2250],\n",
       "        [ 0.4750,  0.2750],\n",
       "        [-0.2250, -0.0250],\n",
       "        [ 0.3750,  0.3500],\n",
       "        [ 0.0000,  0.1750],\n",
       "        [-0.4250, -0.1000],\n",
       "        [ 0.1000, -0.1000],\n",
       "        [ 0.2000,  0.1500],\n",
       "        [ 0.1250,  0.0250],\n",
       "        [-0.2500,  0.1750],\n",
       "        [-0.3250, -0.6500],\n",
       "        [-0.0750, -0.3000],\n",
       "        [ 0.0750, -0.1500],\n",
       "        [ 0.5250,  0.5250],\n",
       "        [-0.0750,  0.2250],\n",
       "        [-0.1750,  0.0000],\n",
       "        [ 0.3000, -0.0500],\n",
       "        [-0.3500, -0.4000],\n",
       "        [-0.2250, -0.2000],\n",
       "        [ 0.4750,  0.5500],\n",
       "        [ 0.1000, -0.4750],\n",
       "        [-0.1250,  0.0000],\n",
       "        [-0.3000,  0.0000],\n",
       "        [-0.2750, -0.4500],\n",
       "        [-0.1500, -0.3000],\n",
       "        [ 0.1500, -0.1250],\n",
       "        [ 0.0500, -0.1250],\n",
       "        [ 0.0750,  0.1750],\n",
       "        [-0.1250, -0.1250],\n",
       "        [ 0.5750,  0.2500],\n",
       "        [-0.3750, -0.0500],\n",
       "        [ 0.2250,  0.1000],\n",
       "        [ 0.3250, -0.2000],\n",
       "        [ 0.4750,  0.4500],\n",
       "        [-0.1750, -0.4000],\n",
       "        [ 0.3500,  0.3750],\n",
       "        [-0.4000,  0.1250],\n",
       "        [-0.1500, -0.2750],\n",
       "        [ 0.5750, -0.3750],\n",
       "        [-0.2500,  0.2000],\n",
       "        [ 0.0000,  0.1500],\n",
       "        [ 0.4500, -0.1250],\n",
       "        [-0.1000, -0.0250],\n",
       "        [ 0.1500,  0.0750],\n",
       "        [ 0.2000, -0.1000],\n",
       "        [ 0.0500,  0.0250],\n",
       "        [ 0.3500,  0.4250],\n",
       "        [-0.3500, -0.5500],\n",
       "        [-0.4250, -0.6000],\n",
       "        [ 0.1750,  0.5500],\n",
       "        [ 0.2000,  0.0250],\n",
       "        [-0.2250, -0.1250],\n",
       "        [ 0.2500,  0.1750],\n",
       "        [-0.3750, -0.0500],\n",
       "        [-0.4750, -0.4500],\n",
       "        [-0.3250, -0.5500],\n",
       "        [-0.1250,  0.1750],\n",
       "        [-0.2500, -0.0500],\n",
       "        [ 0.0000,  0.1250],\n",
       "        [-0.6250, -0.1500],\n",
       "        [-0.4250, -0.5500],\n",
       "        [ 0.0250, -0.2000],\n",
       "        [ 0.3250,  0.3750],\n",
       "        [ 0.1750,  0.1500],\n",
       "        [-0.1750, -0.6500],\n",
       "        [ 0.0750,  0.4250],\n",
       "        [-0.4500, -0.3750],\n",
       "        [-0.1250, -0.1750],\n",
       "        [ 0.0500, -0.3000],\n",
       "        [-0.0500,  0.3750],\n",
       "        [-0.2750,  0.0500],\n",
       "        [-0.4750, -0.3250],\n",
       "        [ 0.0000, -0.3000],\n",
       "        [ 0.3750, -0.1000],\n",
       "        [ 0.1750,  0.1000],\n",
       "        [-0.2250, -0.5500],\n",
       "        [ 0.1500,  0.2250],\n",
       "        [-0.6250, -0.5750],\n",
       "        [ 0.0750, -0.2750],\n",
       "        [ 0.3500,  0.6250],\n",
       "        [-0.0500,  0.2500],\n",
       "        [ 0.0750,  0.3500],\n",
       "        [ 0.2000, -0.3000],\n",
       "        [ 0.2000, -0.1500],\n",
       "        [-0.0250, -0.1500],\n",
       "        [-0.3000, -0.1000],\n",
       "        [-0.1250,  0.1000],\n",
       "        [-0.6750, -0.6250],\n",
       "        [-0.0750, -0.1250],\n",
       "        [ 0.2750,  0.2000],\n",
       "        [ 0.0250,  0.0500],\n",
       "        [-0.4750, -0.1500],\n",
       "        [-0.1500, -0.0500],\n",
       "        [ 0.2000,  0.0250],\n",
       "        [-0.1750,  0.1750],\n",
       "        [ 0.2750,  0.2250],\n",
       "        [ 0.2500,  0.2500],\n",
       "        [-0.1750, -0.2250],\n",
       "        [-0.5750, -0.7000]], dtype=torch.float64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.2970e-02, -1.9066e-02],\n",
       "        [-3.2469e-01, -3.5401e-01],\n",
       "        [ 2.3141e-02, -1.8568e-02],\n",
       "        [ 2.3107e-02, -1.8782e-02],\n",
       "        [-2.8362e-02, -6.5895e-02],\n",
       "        [-2.2796e-01, -2.5084e-01],\n",
       "        [-4.9962e-01, -5.4406e-01],\n",
       "        [ 2.3166e-02, -1.8643e-02],\n",
       "        [-2.9738e-01, -3.2467e-01],\n",
       "        [ 2.3150e-02, -1.8592e-02],\n",
       "        [ 2.3124e-02, -1.8716e-02],\n",
       "        [-7.4875e-03, -4.7453e-02],\n",
       "        [-3.6687e-01, -4.0015e-01],\n",
       "        [ 2.3148e-02, -1.8631e-02],\n",
       "        [ 1.9762e-02, -2.2687e-02],\n",
       "        [-2.5819e-01, -2.8247e-01],\n",
       "        [-5.3937e-01, -5.8748e-01],\n",
       "        [ 1.2540e-02, -2.9661e-02],\n",
       "        [ 2.3160e-02, -1.8607e-02],\n",
       "        [-7.8467e-02, -1.1110e-01],\n",
       "        [-4.2613e-01, -4.6416e-01],\n",
       "        [-5.3008e-02, -8.8263e-02],\n",
       "        [-3.2782e-01, -3.5745e-01],\n",
       "        [ 2.2955e-02, -1.9081e-02],\n",
       "        [ 2.3181e-02, -1.8618e-02],\n",
       "        [ 2.3091e-02, -1.8805e-02],\n",
       "        [ 2.3153e-02, -1.8618e-02],\n",
       "        [ 2.3169e-02, -1.8601e-02],\n",
       "        [ 2.2959e-02, -1.9089e-02],\n",
       "        [ 2.3134e-02, -1.8590e-02],\n",
       "        [-5.9353e-01, -6.4680e-01],\n",
       "        [-6.0976e-04, -4.1301e-02],\n",
       "        [ 2.2642e-02, -1.9653e-02],\n",
       "        [-5.4160e-02, -8.9308e-02],\n",
       "        [-2.5170e-01, -2.7537e-01],\n",
       "        [ 1.8168e-02, -2.4267e-02],\n",
       "        [-6.2441e-01, -6.8087e-01],\n",
       "        [ 2.3146e-02, -1.8579e-02],\n",
       "        [ 2.2974e-02, -1.9051e-02],\n",
       "        [ 2.3138e-02, -1.8590e-02],\n",
       "        [-2.7338e-02, -6.4960e-02],\n",
       "        [ 1.8880e-02, -2.3558e-02],\n",
       "        [ 2.2944e-02, -1.9152e-02],\n",
       "        [-1.8663e-01, -2.1085e-01],\n",
       "        [ 1.0786e-02, -3.1197e-02],\n",
       "        [ 2.3148e-02, -1.8607e-02],\n",
       "        [ 2.3157e-02, -1.8621e-02],\n",
       "        [ 2.1256e-02, -2.1106e-02],\n",
       "        [-1.3334e-01, -1.6309e-01],\n",
       "        [ 2.3148e-02, -1.8591e-02],\n",
       "        [-2.3605e-01, -2.5909e-01],\n",
       "        [ 2.3161e-02, -1.8617e-02],\n",
       "        [ 2.3166e-02, -1.8615e-02],\n",
       "        [ 2.3141e-02, -1.8553e-02],\n",
       "        [-7.7997e-02, -1.1065e-01],\n",
       "        [ 2.3155e-02, -1.8599e-02],\n",
       "        [-6.1068e-01, -6.6574e-01],\n",
       "        [-1.7454e-01, -2.0001e-01],\n",
       "        [ 2.3151e-02, -1.8610e-02],\n",
       "        [-2.8751e-01, -3.1408e-01],\n",
       "        [-1.8486e-01, -2.0928e-01],\n",
       "        [ 2.3156e-02, -1.8602e-02],\n",
       "        [-3.1257e-01, -3.4098e-01],\n",
       "        [-5.5589e-01, -6.0553e-01],\n",
       "        [ 2.3023e-02, -1.8944e-02],\n",
       "        [ 2.3110e-02, -1.8748e-02],\n",
       "        [ 2.3143e-02, -1.8568e-02],\n",
       "        [-2.3399e-01, -2.5701e-01],\n",
       "        [-1.0508e-02, -5.0176e-02],\n",
       "        [-4.8339e-01, -5.2637e-01],\n",
       "        [ 2.2991e-02, -1.9012e-02],\n",
       "        [-2.4480e-01, -2.6808e-01],\n",
       "        [-3.9771e-01, -4.3344e-01],\n",
       "        [-2.5774e-01, -2.8198e-01],\n",
       "        [ 2.3147e-02, -1.8600e-02],\n",
       "        [ 2.3167e-02, -1.8621e-02],\n",
       "        [-1.8319e-01, -2.0776e-01],\n",
       "        [ 2.2652e-02, -1.9632e-02],\n",
       "        [ 2.3120e-02, -1.8713e-02],\n",
       "        [-4.1924e-01, -4.5670e-01],\n",
       "        [-5.1794e-02, -8.7160e-02],\n",
       "        [ 2.3080e-02, -1.8809e-02],\n",
       "        [ 2.3154e-02, -1.8631e-02],\n",
       "        [ 2.3164e-02, -1.8621e-02],\n",
       "        [ 2.1162e-02, -2.1216e-02],\n",
       "        [ 2.3099e-02, -1.8780e-02],\n",
       "        [ 2.3163e-02, -1.8627e-02],\n",
       "        [ 6.2662e-03, -3.5178e-02],\n",
       "        [ 1.6720e-02, -2.5831e-02],\n",
       "        [ 2.3164e-02, -1.8639e-02],\n",
       "        [-3.8802e-01, -4.2298e-01],\n",
       "        [ 2.3177e-02, -1.8597e-02],\n",
       "        [-5.9312e-01, -6.4635e-01],\n",
       "        [ 2.3040e-02, -1.8908e-02],\n",
       "        [-2.8475e-01, -3.1111e-01],\n",
       "        [-1.0570e-01, -1.3737e-01],\n",
       "        [ 2.2547e-02, -1.9752e-02],\n",
       "        [ 2.2336e-02, -1.9973e-02],\n",
       "        [ 2.3134e-02, -1.8701e-02],\n",
       "        [ 2.3078e-02, -1.8824e-02],\n",
       "        [ 2.3144e-02, -1.8573e-02],\n",
       "        [ 2.3149e-02, -1.8585e-02],\n",
       "        [-5.0486e-01, -5.4978e-01],\n",
       "        [ 2.3146e-02, -1.8582e-02],\n",
       "        [ 1.7868e-02, -2.4580e-02],\n",
       "        [-2.4136e-01, -2.6459e-01],\n",
       "        [-5.4100e-02, -8.9257e-02],\n",
       "        [-1.6456e-01, -1.9106e-01],\n",
       "        [-1.0029e-01, -1.3219e-01],\n",
       "        [ 2.3161e-02, -1.8621e-02],\n",
       "        [-1.2775e-01, -1.5814e-01],\n",
       "        [ 2.3133e-02, -1.8700e-02],\n",
       "        [-5.4786e-01, -5.9677e-01],\n",
       "        [ 2.2908e-02, -1.9188e-02],\n",
       "        [-5.5264e-02, -9.0324e-02],\n",
       "        [ 2.3123e-02, -1.8563e-02],\n",
       "        [ 2.3013e-02, -1.8975e-02],\n",
       "        [ 2.3155e-02, -1.8607e-02],\n",
       "        [ 2.3152e-02, -1.8614e-02],\n",
       "        [ 2.3153e-02, -1.8605e-02],\n",
       "        [ 2.3080e-02, -1.8817e-02],\n",
       "        [ 2.2721e-02, -1.9501e-02],\n",
       "        [ 2.3148e-02, -1.8607e-02],\n",
       "        [-6.3613e-02, -9.7729e-02],\n",
       "        [-2.5868e-01, -2.8301e-01],\n",
       "        [ 2.3101e-02, -1.8777e-02],\n",
       "        [ 2.3156e-02, -1.8592e-02],\n",
       "        [ 2.3148e-02, -1.8584e-02],\n",
       "        [ 2.3140e-02, -1.8582e-02],\n",
       "        [ 2.3148e-02, -1.8598e-02],\n",
       "        [ 1.9588e-02, -2.2840e-02],\n",
       "        [-4.7058e-02, -8.2886e-02],\n",
       "        [ 2.3165e-02, -1.8612e-02],\n",
       "        [ 2.3152e-02, -1.8572e-02],\n",
       "        [ 2.3172e-02, -1.8599e-02],\n",
       "        [ 2.3157e-02, -1.8670e-02],\n",
       "        [ 2.3164e-02, -1.8597e-02],\n",
       "        [ 1.6381e-02, -2.6170e-02],\n",
       "        [ 1.6818e-03, -3.9280e-02],\n",
       "        [-3.5594e-02, -7.2493e-02],\n",
       "        [-1.0090e-01, -1.3278e-01],\n",
       "        [ 2.3176e-02, -1.8627e-02],\n",
       "        [-2.1005e-01, -2.3299e-01],\n",
       "        [-2.3139e-01, -2.5431e-01],\n",
       "        [ 2.3146e-02, -1.8583e-02],\n",
       "        [ 2.3161e-02, -1.8612e-02],\n",
       "        [ 2.2957e-02, -1.9064e-02],\n",
       "        [-2.1387e-01, -2.3671e-01],\n",
       "        [ 2.2091e-02, -2.0211e-02],\n",
       "        [ 2.3152e-02, -1.8605e-02],\n",
       "        [-9.9101e-02, -1.3104e-01],\n",
       "        [ 2.2021e-02, -2.0303e-02],\n",
       "        [-1.3218e-02, -5.2502e-02],\n",
       "        [ 1.8164e-03, -3.9164e-02],\n",
       "        [ 2.3047e-02, -1.8893e-02],\n",
       "        [ 1.6606e-03, -3.9287e-02],\n",
       "        [-7.7307e-02, -1.0998e-01],\n",
       "        [-1.6997e-01, -1.9591e-01],\n",
       "        [ 2.2960e-02, -1.9108e-02],\n",
       "        [-8.1766e-03, -4.8072e-02],\n",
       "        [-4.4605e-01, -4.8574e-01],\n",
       "        [ 2.2961e-02, -1.9097e-02],\n",
       "        [ 2.2824e-02, -1.9331e-02],\n",
       "        [ 2.3168e-02, -1.8619e-02],\n",
       "        [ 2.1569e-02, -2.0797e-02],\n",
       "        [-2.3455e-01, -2.5758e-01],\n",
       "        [-2.3575e-01, -2.5885e-01],\n",
       "        [ 2.3155e-02, -1.8660e-02],\n",
       "        [ 2.3159e-02, -1.8636e-02],\n",
       "        [-2.4426e-01, -2.6754e-01],\n",
       "        [-4.5812e-01, -4.9887e-01],\n",
       "        [ 2.3149e-02, -1.8586e-02],\n",
       "        [ 2.3152e-02, -1.8679e-02],\n",
       "        [ 2.3162e-02, -1.8595e-02],\n",
       "        [ 2.3045e-02, -1.8881e-02],\n",
       "        [ 2.2978e-02, -1.9041e-02],\n",
       "        [ 2.2859e-02, -1.9285e-02],\n",
       "        [ 2.3134e-02, -1.8603e-02],\n",
       "        [-1.3699e-01, -1.6638e-01],\n",
       "        [ 2.3143e-02, -1.8572e-02],\n",
       "        [-3.1293e-01, -3.4135e-01],\n",
       "        [ 2.2690e-02, -1.9540e-02],\n",
       "        [-2.1127e-01, -2.3418e-01],\n",
       "        [ 2.2814e-02, -1.9350e-02],\n",
       "        [ 2.3134e-02, -1.8581e-02],\n",
       "        [-2.7598e-01, -3.0172e-01],\n",
       "        [-3.4501e-01, -3.7624e-01],\n",
       "        [ 2.3131e-02, -1.8569e-02],\n",
       "        [ 2.3148e-02, -1.8582e-02],\n",
       "        [-2.0610e-02, -5.8906e-02],\n",
       "        [-5.3908e-01, -5.8718e-01],\n",
       "        [-1.8491e-01, -2.0933e-01],\n",
       "        [-3.3682e-02, -7.0724e-02],\n",
       "        [-5.0401e-02, -8.5900e-02],\n",
       "        [-1.2540e-01, -1.5604e-01],\n",
       "        [ 2.3181e-02, -1.8610e-02],\n",
       "        [ 2.3136e-02, -1.8579e-02],\n",
       "        [ 2.2987e-02, -1.9037e-02],\n",
       "        [ 1.9612e-02, -2.2829e-02],\n",
       "        [ 2.3043e-02, -1.8897e-02],\n",
       "        [ 1.9904e-02, -2.2555e-02],\n",
       "        [ 3.7375e-03, -3.7433e-02],\n",
       "        [ 2.3128e-02, -1.8706e-02],\n",
       "        [-2.8724e-01, -3.1381e-01],\n",
       "        [-6.3722e-02, -9.7833e-02],\n",
       "        [ 2.3145e-02, -1.8677e-02],\n",
       "        [-3.0193e-01, -3.2955e-01],\n",
       "        [-4.0443e-03, -4.4338e-02],\n",
       "        [-7.6650e-04, -4.1438e-02],\n",
       "        [ 2.3139e-02, -1.8575e-02],\n",
       "        [ 2.3149e-02, -1.8579e-02],\n",
       "        [ 1.6734e-02, -2.5805e-02],\n",
       "        [-1.7835e-01, -2.0346e-01],\n",
       "        [ 2.3141e-02, -1.8577e-02],\n",
       "        [-2.2187e-01, -2.4464e-01],\n",
       "        [-8.0359e-02, -1.1293e-01],\n",
       "        [ 2.3171e-02, -1.8591e-02],\n",
       "        [ 2.3120e-02, -1.8714e-02],\n",
       "        [-3.4438e-01, -3.7555e-01],\n",
       "        [ 2.3056e-02, -1.8866e-02],\n",
       "        [ 1.9367e-02, -2.3068e-02],\n",
       "        [ 2.2317e-02, -2.0000e-02],\n",
       "        [-4.0032e-01, -4.3627e-01],\n",
       "        [ 2.3031e-02, -1.8934e-02],\n",
       "        [-5.6379e-01, -6.1417e-01],\n",
       "        [ 2.2921e-02, -1.9165e-02],\n",
       "        [ 2.3149e-02, -1.8583e-02],\n",
       "        [ 2.3078e-02, -1.8838e-02],\n",
       "        [-3.4891e-01, -3.8052e-01],\n",
       "        [ 2.3141e-02, -1.8574e-02],\n",
       "        [ 7.5983e-03, -3.4007e-02],\n",
       "        [ 2.3133e-02, -1.8567e-02],\n",
       "        [-1.4046e-01, -1.6944e-01],\n",
       "        [ 2.3168e-02, -1.8588e-02],\n",
       "        [-1.1118e-01, -1.4269e-01],\n",
       "        [ 2.2532e-02, -1.9766e-02],\n",
       "        [ 2.3147e-02, -1.8603e-02],\n",
       "        [-9.6963e-02, -1.2898e-01],\n",
       "        [ 2.2749e-02, -1.9472e-02],\n",
       "        [ 2.3157e-02, -1.8626e-02],\n",
       "        [-9.2424e-03, -4.9074e-02],\n",
       "        [-5.1506e-01, -5.6092e-01],\n",
       "        [ 2.3112e-02, -1.8555e-02],\n",
       "        [-3.3999e-01, -3.7075e-01],\n",
       "        [-4.6790e-02, -8.2645e-02],\n",
       "        [-2.1451e-01, -2.3741e-01],\n",
       "        [-9.9644e-02, -1.3157e-01],\n",
       "        [ 2.3173e-02, -1.8612e-02],\n",
       "        [ 1.7870e-02, -2.4572e-02],\n",
       "        [-4.0139e-02, -7.6618e-02],\n",
       "        [-6.0203e-02, -9.4743e-02],\n",
       "        [ 2.3111e-02, -1.8563e-02],\n",
       "        [-1.4080e-01, -1.6979e-01],\n",
       "        [ 2.3162e-02, -1.8591e-02],\n",
       "        [ 2.3119e-02, -1.8568e-02],\n",
       "        [-1.3811e-01, -1.6738e-01],\n",
       "        [-1.0544e-01, -1.3712e-01],\n",
       "        [-1.1034e-01, -1.4187e-01],\n",
       "        [ 2.3159e-02, -1.8642e-02],\n",
       "        [-1.0827e-01, -1.3987e-01],\n",
       "        [-2.7290e-01, -2.9840e-01],\n",
       "        [-4.7226e-02, -8.3031e-02],\n",
       "        [ 2.3108e-02, -1.8568e-02],\n",
       "        [ 2.3154e-02, -1.8589e-02],\n",
       "        [ 2.2926e-02, -1.9173e-02],\n",
       "        [ 2.3136e-02, -1.8569e-02],\n",
       "        [ 2.3122e-02, -1.8704e-02],\n",
       "        [ 2.0126e-02, -2.2299e-02],\n",
       "        [ 2.2374e-02, -1.9930e-02],\n",
       "        [ 2.3127e-02, -1.8565e-02],\n",
       "        [-1.7379e-01, -1.9938e-01],\n",
       "        [ 2.2926e-02, -1.9139e-02],\n",
       "        [-3.3298e-01, -3.6307e-01],\n",
       "        [-3.9366e-01, -4.2908e-01],\n",
       "        [-2.4932e-02, -6.2797e-02],\n",
       "        [ 2.3147e-02, -1.8690e-02],\n",
       "        [ 2.3101e-02, -1.8554e-02],\n",
       "        [ 2.3137e-02, -1.8600e-02],\n",
       "        [ 2.3143e-02, -1.8584e-02],\n",
       "        [ 2.3142e-02, -1.8685e-02],\n",
       "        [-3.4757e-01, -3.7907e-01],\n",
       "        [ 2.3127e-02, -1.8560e-02],\n",
       "        [ 2.2973e-02, -1.9051e-02],\n",
       "        [ 2.3138e-02, -1.8598e-02],\n",
       "        [-1.5630e-01, -1.8364e-01],\n",
       "        [ 2.3158e-02, -1.8582e-02],\n",
       "        [-2.8389e-01, -3.1018e-01],\n",
       "        [-1.4017e-02, -5.3196e-02],\n",
       "        [ 2.3139e-02, -1.8622e-02],\n",
       "        [ 2.3143e-02, -1.8559e-02],\n",
       "        [ 2.3129e-02, -1.8560e-02],\n",
       "        [ 2.2770e-02, -1.9407e-02],\n",
       "        [ 2.2418e-02, -1.9897e-02],\n",
       "        [ 2.3133e-02, -1.8584e-02],\n",
       "        [ 2.1209e-02, -2.1155e-02],\n",
       "        [ 2.3128e-02, -1.8712e-02],\n",
       "        [ 2.3139e-02, -1.8580e-02],\n",
       "        [-6.3569e-01, -6.9331e-01],\n",
       "        [-4.5979e-01, -5.0068e-01],\n",
       "        [ 2.3140e-02, -1.8557e-02],\n",
       "        [ 2.2883e-02, -1.9245e-02],\n",
       "        [-5.6011e-02, -9.0978e-02],\n",
       "        [ 2.2762e-02, -1.9436e-02],\n",
       "        [-4.5866e-01, -4.9948e-01],\n",
       "        [ 3.4240e-03, -3.7712e-02],\n",
       "        [-1.5527e-01, -1.8273e-01],\n",
       "        [ 1.7321e-02, -2.5178e-02],\n",
       "        [-1.6651e-01, -1.9279e-01],\n",
       "        [ 2.3134e-02, -1.8556e-02],\n",
       "        [-1.3000e-02, -5.2300e-02],\n",
       "        [-2.9072e-01, -3.1751e-01],\n",
       "        [ 1.3608e-02, -2.8726e-02],\n",
       "        [ 2.3148e-02, -1.8587e-02],\n",
       "        [ 2.3098e-02, -1.8772e-02],\n",
       "        [-2.2843e-01, -2.5130e-01],\n",
       "        [ 2.3147e-02, -1.8609e-02],\n",
       "        [-2.9091e-01, -3.1771e-01],\n",
       "        [ 1.3719e-02, -2.8630e-02],\n",
       "        [ 2.2341e-02, -1.9966e-02],\n",
       "        [ 2.3142e-02, -1.8591e-02],\n",
       "        [ 2.0299e-02, -2.2133e-02],\n",
       "        [-3.6697e-01, -4.0027e-01],\n",
       "        [-6.8773e-02, -1.0232e-01],\n",
       "        [ 2.3135e-02, -1.8702e-02],\n",
       "        [ 2.3119e-02, -1.8582e-02],\n",
       "        [-1.8601e-01, -2.1033e-01],\n",
       "        [ 2.3133e-02, -1.8567e-02],\n",
       "        [-2.5090e-01, -2.7449e-01],\n",
       "        [-1.3203e-01, -1.6191e-01],\n",
       "        [ 2.0797e-02, -2.1604e-02],\n",
       "        [ 2.2965e-02, -1.9109e-02],\n",
       "        [ 2.3130e-02, -1.8591e-02],\n",
       "        [ 2.3061e-02, -1.8869e-02],\n",
       "        [ 2.3145e-02, -1.8596e-02],\n",
       "        [ 2.1394e-02, -2.0978e-02],\n",
       "        [-7.9691e-02, -1.1228e-01],\n",
       "        [ 2.3097e-02, -1.8778e-02],\n",
       "        [-1.0801e-01, -1.3963e-01],\n",
       "        [ 1.9812e-02, -2.2622e-02],\n",
       "        [ 2.3144e-02, -1.8574e-02],\n",
       "        [ 2.3124e-02, -1.8728e-02],\n",
       "        [-2.3965e-01, -2.6282e-01],\n",
       "        [ 2.2918e-02, -1.9161e-02],\n",
       "        [ 2.3146e-02, -1.8627e-02],\n",
       "        [ 2.3123e-02, -1.8725e-02],\n",
       "        [ 2.3068e-02, -1.8847e-02],\n",
       "        [ 2.3156e-02, -1.8606e-02],\n",
       "        [-5.7138e-02, -9.2006e-02],\n",
       "        [-2.1225e-01, -2.3513e-01]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse relationship between epochs and r^2 score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create lists to store the epochs and R^2 scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs_list = [i for i in range(1, 301)]\n",
    "r2_scores_list = []\n",
    "rmse_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conduct training and testing for each num_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of epochs: 1\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.3275871324205851\n",
      "Test R^2 score: -0.1700001869073665\n",
      "Num of epochs: 2\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.3237414455694503\n",
      "Test R^2 score: -0.1424245115660614\n",
      "Num of epochs: 3\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.3202369261768672\n",
      "Test R^2 score: -0.11759274216462934\n",
      "Num of epochs: 4\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.3170576251644705\n",
      "Test R^2 score: -0.09534284228933132\n",
      "Num of epochs: 5\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.3142050466448601\n",
      "Test R^2 score: -0.07559009845094455\n",
      "Num of epochs: 6\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.31167515568095505\n",
      "Test R^2 score: -0.05822318435063145\n",
      "Num of epochs: 7\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.30943891711220495\n",
      "Test R^2 score: -0.043030230212775744\n",
      "Num of epochs: 8\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.30753264065535996\n",
      "Test R^2 score: -0.030212756981492728\n",
      "Num of epochs: 9\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.305954647836232\n",
      "Test R^2 score: -0.019711210909134858\n",
      "Num of epochs: 10\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.3047089329008634\n",
      "Test R^2 score: -0.011503706030553396\n",
      "Num of epochs: 11\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.3037725089382346\n",
      "Test R^2 score: -0.00541616228436459\n",
      "Num of epochs: 12\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.3032289538796045\n",
      "Test R^2 score: -0.001969448724638667\n",
      "Num of epochs: 13\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.30296325777279237\n",
      "Test R^2 score: -0.00031094223058325543\n",
      "Num of epochs: 14\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.3028748072336636\n",
      "Test R^2 score: 0.00023350835347557553\n",
      "Num of epochs: 15\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.30286742190962895\n",
      "Test R^2 score: 0.00027466840693546324\n",
      "Num of epochs: 16\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.30289064528885923\n",
      "Test R^2 score: 0.00011411099107933032\n",
      "Num of epochs: 17\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.30294403320628677\n",
      "Test R^2 score: -0.0002637878606110422\n",
      "Num of epochs: 18\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.30302301272979437\n",
      "Test R^2 score: -0.000830523693997054\n",
      "Num of epochs: 19\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.3031181032602305\n",
      "Test R^2 score: -0.0015289259106820996\n",
      "Num of epochs: 20\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.3032137622902571\n",
      "Test R^2 score: -0.0022553741143767625\n",
      "Num of epochs: 21\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.3032953586305004\n",
      "Test R^2 score: -0.0028761027503560466\n",
      "Num of epochs: 22\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.3034078875711045\n",
      "Test R^2 score: -0.0036976516001974713\n",
      "Num of epochs: 23\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.3035019287620554\n",
      "Test R^2 score: -0.004375219054210733\n",
      "Num of epochs: 24\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.30357161670294036\n",
      "Test R^2 score: -0.004860354954552171\n",
      "Num of epochs: 25\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.3036255822439651\n",
      "Test R^2 score: -0.005213458525565762\n",
      "Num of epochs: 26\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.30365373701705095\n",
      "Test R^2 score: -0.005367820905556209\n",
      "Num of epochs: 27\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.30367180667472404\n",
      "Test R^2 score: -0.005438372187367202\n",
      "Num of epochs: 28\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.3036813066446031\n",
      "Test R^2 score: -0.005442241328407538\n",
      "Num of epochs: 29\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.3036789138614825\n",
      "Test R^2 score: -0.005356349345031708\n",
      "Num of epochs: 30\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.3036675685998823\n",
      "Test R^2 score: -0.005206739435550278\n",
      "Num of epochs: 31\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.3036467057514582\n",
      "Test R^2 score: -0.004995800282604934\n",
      "Num of epochs: 32\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.3036098833826696\n",
      "Test R^2 score: -0.004687301425359447\n",
      "Num of epochs: 33\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.3035491799605391\n",
      "Test R^2 score: -0.004234593881606075\n",
      "Num of epochs: 34\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.30349787663550565\n",
      "Test R^2 score: -0.0038650727279878616\n",
      "Num of epochs: 35\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.30342095233724353\n",
      "Test R^2 score: -0.003319320682360405\n",
      "Num of epochs: 36\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.30333524618866725\n",
      "Test R^2 score: -0.0027266724092485095\n",
      "Num of epochs: 37\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.30322368201965605\n",
      "Test R^2 score: -0.0019773434627214925\n",
      "Num of epochs: 38\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.3030546252997248\n",
      "Test R^2 score: -0.000853282106687836\n",
      "Num of epochs: 39\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.3028156582512151\n",
      "Test R^2 score: 0.0007275035228641036\n",
      "Num of epochs: 40\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.3024737276226354\n",
      "Test R^2 score: 0.002986904738824292\n",
      "Num of epochs: 41\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.3020016022728472\n",
      "Test R^2 score: 0.006105249414737723\n",
      "Num of epochs: 42\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.30133862880270185\n",
      "Test R^2 score: 0.010477104936065462\n",
      "Num of epochs: 43\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.30035371815487777\n",
      "Test R^2 score: 0.01696256292044651\n",
      "Num of epochs: 44\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.29894276174141604\n",
      "Test R^2 score: 0.026257457616739144\n",
      "Num of epochs: 45\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.296887210794254\n",
      "Test R^2 score: 0.03977492167327046\n",
      "Num of epochs: 46\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.29384374067069924\n",
      "Test R^2 score: 0.05969367676305187\n",
      "Num of epochs: 47\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.28939277313813266\n",
      "Test R^2 score: 0.08853041671364853\n",
      "Num of epochs: 48\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2833759670338646\n",
      "Test R^2 score: 0.12686948424435746\n",
      "Num of epochs: 49\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2753091531182999\n",
      "Test R^2 score: 0.1769468123455391\n",
      "Num of epochs: 50\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.26569722922665967\n",
      "Test R^2 score: 0.23450257939340918\n",
      "Num of epochs: 51\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.25680209935248416\n",
      "Test R^2 score: 0.2858599614026012\n",
      "Num of epochs: 52\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.25247162850794486\n",
      "Test R^2 score: 0.3102261200308776\n",
      "Num of epochs: 53\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.25530969438500334\n",
      "Test R^2 score: 0.29451001815486866\n",
      "Num of epochs: 54\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.25205265072672134\n",
      "Test R^2 score: 0.31328760064624667\n",
      "Num of epochs: 55\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.24747951045916375\n",
      "Test R^2 score: 0.3375468452192559\n",
      "Num of epochs: 56\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2422548745890318\n",
      "Test R^2 score: 0.36469494200463004\n",
      "Num of epochs: 57\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.23865792248370515\n",
      "Test R^2 score: 0.383428544275905\n",
      "Num of epochs: 58\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.23922714142505447\n",
      "Test R^2 score: 0.37985506597718194\n",
      "Num of epochs: 59\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.23635908098710992\n",
      "Test R^2 score: 0.3951892808794154\n",
      "Num of epochs: 60\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.23156782187179542\n",
      "Test R^2 score: 0.41995507652347946\n",
      "Num of epochs: 61\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22971153552562895\n",
      "Test R^2 score: 0.4290722645615866\n",
      "Num of epochs: 62\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2280948754457699\n",
      "Test R^2 score: 0.43658157699086164\n",
      "Num of epochs: 63\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22610184773498743\n",
      "Test R^2 score: 0.4461672682054492\n",
      "Num of epochs: 64\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2277541107954943\n",
      "Test R^2 score: 0.43714464116474944\n",
      "Num of epochs: 65\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2235470651692292\n",
      "Test R^2 score: 0.4579117568399104\n",
      "Num of epochs: 66\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22303344759814028\n",
      "Test R^2 score: 0.45960296499978515\n",
      "Num of epochs: 67\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22370955958696567\n",
      "Test R^2 score: 0.4560812664886876\n",
      "Num of epochs: 68\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22005477342364854\n",
      "Test R^2 score: 0.47457720799843855\n",
      "Num of epochs: 69\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22492830635260497\n",
      "Test R^2 score: 0.45126713903916604\n",
      "Num of epochs: 70\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2186907379373943\n",
      "Test R^2 score: 0.4808031610335267\n",
      "Num of epochs: 71\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22396310077203643\n",
      "Test R^2 score: 0.4554716375820421\n",
      "Num of epochs: 72\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22010115987156248\n",
      "Test R^2 score: 0.4738342659236635\n",
      "Num of epochs: 73\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21963230666682532\n",
      "Test R^2 score: 0.4759414846414184\n",
      "Num of epochs: 74\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22440711508505243\n",
      "Test R^2 score: 0.45217972684567503\n",
      "Num of epochs: 75\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21872270823616433\n",
      "Test R^2 score: 0.480425365145275\n",
      "Num of epochs: 76\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2197808865153476\n",
      "Test R^2 score: 0.47568287612396215\n",
      "Num of epochs: 77\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22133088459914538\n",
      "Test R^2 score: 0.4687618891482298\n",
      "Num of epochs: 78\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21690219547329906\n",
      "Test R^2 score: 0.4895893467894558\n",
      "Num of epochs: 79\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22091350940787033\n",
      "Test R^2 score: 0.4706086646369991\n",
      "Num of epochs: 80\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.217169250390045\n",
      "Test R^2 score: 0.4881401379070297\n",
      "Num of epochs: 81\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21653021818730211\n",
      "Test R^2 score: 0.49100089241303185\n",
      "Num of epochs: 82\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2197851295407267\n",
      "Test R^2 score: 0.47502497242367814\n",
      "Num of epochs: 83\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21523404964904977\n",
      "Test R^2 score: 0.4971346203696733\n",
      "Num of epochs: 84\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2160106727716768\n",
      "Test R^2 score: 0.49353623486849013\n",
      "Num of epochs: 85\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21680890129459368\n",
      "Test R^2 score: 0.48999107440903944\n",
      "Num of epochs: 86\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21379203423265544\n",
      "Test R^2 score: 0.5042375384782498\n",
      "Num of epochs: 87\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21591917043367723\n",
      "Test R^2 score: 0.4942534898677726\n",
      "Num of epochs: 88\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21447846392504172\n",
      "Test R^2 score: 0.5008740189473404\n",
      "Num of epochs: 89\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21324007908603115\n",
      "Test R^2 score: 0.506608799798111\n",
      "Num of epochs: 90\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21586308082456387\n",
      "Test R^2 score: 0.49392755072363\n",
      "Num of epochs: 91\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2127494420752613\n",
      "Test R^2 score: 0.50884664189765\n",
      "Num of epochs: 92\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2136696775701282\n",
      "Test R^2 score: 0.5044562046015815\n",
      "Num of epochs: 93\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21342852168563287\n",
      "Test R^2 score: 0.5057132398306081\n",
      "Num of epochs: 94\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2116534605021768\n",
      "Test R^2 score: 0.5141417806455351\n",
      "Num of epochs: 95\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21375042604494057\n",
      "Test R^2 score: 0.5043739596819248\n",
      "Num of epochs: 96\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21112921833338197\n",
      "Test R^2 score: 0.5165746882628248\n",
      "Num of epochs: 97\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21224806480236222\n",
      "Test R^2 score: 0.5112658099695704\n",
      "Num of epochs: 98\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21144739618422684\n",
      "Test R^2 score: 0.514922990142427\n",
      "Num of epochs: 99\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21061867059265568\n",
      "Test R^2 score: 0.5187637914035317\n",
      "Num of epochs: 100\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21215528851356713\n",
      "Test R^2 score: 0.5115314773616685\n",
      "Num of epochs: 101\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2091358445011732\n",
      "Test R^2 score: 0.5257217305655595\n",
      "Num of epochs: 102\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21435307524910943\n",
      "Test R^2 score: 0.5013291136092914\n",
      "Num of epochs: 103\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20835142384083313\n",
      "Test R^2 score: 0.5294196176855203\n",
      "Num of epochs: 104\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21713120208408077\n",
      "Test R^2 score: 0.4882134708682091\n",
      "Num of epochs: 105\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2079495768734665\n",
      "Test R^2 score: 0.5310765719568207\n",
      "Num of epochs: 106\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20824030545513555\n",
      "Test R^2 score: 0.5296865871364764\n",
      "Num of epochs: 107\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2143658273667991\n",
      "Test R^2 score: 0.5011990830756129\n",
      "Num of epochs: 108\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20720172442291132\n",
      "Test R^2 score: 0.534541543888686\n",
      "Num of epochs: 109\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20858134388252533\n",
      "Test R^2 score: 0.5281593990271027\n",
      "Num of epochs: 110\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21167681615798242\n",
      "Test R^2 score: 0.5138060536521887\n",
      "Num of epochs: 111\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20669646353780965\n",
      "Test R^2 score: 0.5368238687603456\n",
      "Num of epochs: 112\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20887764817977578\n",
      "Test R^2 score: 0.5267318858596638\n",
      "Num of epochs: 113\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20966862318264037\n",
      "Test R^2 score: 0.5230792697249089\n",
      "Num of epochs: 114\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20616188492443896\n",
      "Test R^2 score: 0.539121596179186\n",
      "Num of epochs: 115\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20914192598630393\n",
      "Test R^2 score: 0.5255374385511594\n",
      "Num of epochs: 116\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20784957495055775\n",
      "Test R^2 score: 0.5314496155737622\n",
      "Num of epochs: 117\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20563820599729987\n",
      "Test R^2 score: 0.541463636037949\n",
      "Num of epochs: 118\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20976536240873853\n",
      "Test R^2 score: 0.522627267313359\n",
      "Num of epochs: 119\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20603314108562076\n",
      "Test R^2 score: 0.5395962906965568\n",
      "Num of epochs: 120\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20586810760246527\n",
      "Test R^2 score: 0.5402989851206323\n",
      "Num of epochs: 121\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20892501234456562\n",
      "Test R^2 score: 0.5263920827802626\n",
      "Num of epochs: 122\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2049041649788637\n",
      "Test R^2 score: 0.5446227716725349\n",
      "Num of epochs: 123\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20726065816749117\n",
      "Test R^2 score: 0.5340059151527008\n",
      "Num of epochs: 124\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.206240936118608\n",
      "Test R^2 score: 0.5386111920896326\n",
      "Num of epochs: 125\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20485491529360492\n",
      "Test R^2 score: 0.5448012231786101\n",
      "Num of epochs: 126\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20804379854541105\n",
      "Test R^2 score: 0.5304351440863062\n",
      "Num of epochs: 127\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20438041302146503\n",
      "Test R^2 score: 0.5468418305920868\n",
      "Num of epochs: 128\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20725492413426277\n",
      "Test R^2 score: 0.5339478000398814\n",
      "Num of epochs: 129\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20479295451079613\n",
      "Test R^2 score: 0.5449831845135983\n",
      "Num of epochs: 130\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20521062402038068\n",
      "Test R^2 score: 0.5431157558049928\n",
      "Num of epochs: 131\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20615953366393425\n",
      "Test R^2 score: 0.5388444518246017\n",
      "Num of epochs: 132\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20401193543048837\n",
      "Test R^2 score: 0.5483664316717107\n",
      "Num of epochs: 133\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2076746571383439\n",
      "Test R^2 score: 0.531966727630623\n",
      "Num of epochs: 134\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2035336793350142\n",
      "Test R^2 score: 0.5503715542362535\n",
      "Num of epochs: 135\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2099694749409429\n",
      "Test R^2 score: 0.5215079819717598\n",
      "Num of epochs: 136\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2034627708786758\n",
      "Test R^2 score: 0.5506446270309779\n",
      "Num of epochs: 137\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2090957594539973\n",
      "Test R^2 score: 0.5254560751978181\n",
      "Num of epochs: 138\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20363457994526324\n",
      "Test R^2 score: 0.5499310358551571\n",
      "Num of epochs: 139\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20439247588924858\n",
      "Test R^2 score: 0.5466013103080379\n",
      "Num of epochs: 140\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20687266315883446\n",
      "Test R^2 score: 0.5355741644186687\n",
      "Num of epochs: 141\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20316853138309413\n",
      "Test R^2 score: 0.5519906691319802\n",
      "Num of epochs: 142\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2083387826934233\n",
      "Test R^2 score: 0.5289684181477528\n",
      "Num of epochs: 143\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20326222376915423\n",
      "Test R^2 score: 0.551549324148531\n",
      "Num of epochs: 144\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.205196820145313\n",
      "Test R^2 score: 0.5429782481785494\n",
      "Num of epochs: 145\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20536240609598458\n",
      "Test R^2 score: 0.5422392386734898\n",
      "Num of epochs: 146\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2032832334942777\n",
      "Test R^2 score: 0.551423309155511\n",
      "Num of epochs: 147\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20757638845086449\n",
      "Test R^2 score: 0.5324445404160782\n",
      "Num of epochs: 148\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20306911230628696\n",
      "Test R^2 score: 0.5523960267470325\n",
      "Num of epochs: 149\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20660602898218405\n",
      "Test R^2 score: 0.5367775266610864\n",
      "Num of epochs: 150\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20363438020948352\n",
      "Test R^2 score: 0.5499170462333689\n",
      "Num of epochs: 151\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2043968999648328\n",
      "Test R^2 score: 0.5465476724009815\n",
      "Num of epochs: 152\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2049976478063056\n",
      "Test R^2 score: 0.5438919066768444\n",
      "Num of epochs: 153\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20332908498959124\n",
      "Test R^2 score: 0.551257079346312\n",
      "Num of epochs: 154\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20681053224089763\n",
      "Test R^2 score: 0.5357928225188815\n",
      "Num of epochs: 155\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2031386808231956\n",
      "Test R^2 score: 0.5520316784258512\n",
      "Num of epochs: 156\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2080366680112152\n",
      "Test R^2 score: 0.5303062880743801\n",
      "Num of epochs: 157\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2029850378970027\n",
      "Test R^2 score: 0.5527237125409493\n",
      "Num of epochs: 158\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2069068219013592\n",
      "Test R^2 score: 0.5353573420970423\n",
      "Num of epochs: 159\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20343618072577552\n",
      "Test R^2 score: 0.5507523821078032\n",
      "Num of epochs: 160\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20448454775507954\n",
      "Test R^2 score: 0.5461866664269545\n",
      "Num of epochs: 161\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20503209229651415\n",
      "Test R^2 score: 0.5438312279379878\n",
      "Num of epochs: 162\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20315823487961635\n",
      "Test R^2 score: 0.5521321143951737\n",
      "Num of epochs: 163\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20739734801566032\n",
      "Test R^2 score: 0.5332653932098674\n",
      "Num of epochs: 164\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20330795062186463\n",
      "Test R^2 score: 0.5513201674084693\n",
      "Num of epochs: 165\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20838331259773576\n",
      "Test R^2 score: 0.5287178684997795\n",
      "Num of epochs: 166\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20327808433850886\n",
      "Test R^2 score: 0.5514351038494107\n",
      "Num of epochs: 167\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20545907626790097\n",
      "Test R^2 score: 0.5419452665983886\n",
      "Num of epochs: 168\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20440969028223155\n",
      "Test R^2 score: 0.5466585842705404\n",
      "Num of epochs: 169\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20335413997552204\n",
      "Test R^2 score: 0.5513001103630368\n",
      "Num of epochs: 170\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20713700394510887\n",
      "Test R^2 score: 0.5344885132643893\n",
      "Num of epochs: 171\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20340504679104077\n",
      "Test R^2 score: 0.5508942768925387\n",
      "Num of epochs: 172\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20811809121101787\n",
      "Test R^2 score: 0.529917748628723\n",
      "Num of epochs: 173\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2033167440321986\n",
      "Test R^2 score: 0.5512710429239333\n",
      "Num of epochs: 174\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20527920841593847\n",
      "Test R^2 score: 0.5427225436055102\n",
      "Num of epochs: 175\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20480823809225024\n",
      "Test R^2 score: 0.5448961930730208\n",
      "Num of epochs: 176\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20344972369050193\n",
      "Test R^2 score: 0.5508750130990571\n",
      "Num of epochs: 177\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20742903988496508\n",
      "Test R^2 score: 0.5332997048938268\n",
      "Num of epochs: 178\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20345670889764106\n",
      "Test R^2 score: 0.5506893685690909\n",
      "Num of epochs: 179\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Epoch 179, Loss: 0.44257338842027333\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20813063997696707\n",
      "Test R^2 score: 0.5299192125364447\n",
      "Num of epochs: 180\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Epoch 179, Loss: 0.44257338842027333\n",
      "Epoch 180, Loss: 0.44223043415311275\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2035518321362745\n",
      "Test R^2 score: 0.5502022313320087\n",
      "Num of epochs: 181\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Epoch 179, Loss: 0.44257338842027333\n",
      "Epoch 180, Loss: 0.44223043415311275\n",
      "Epoch 181, Loss: 0.4412573335324542\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20513956487539575\n",
      "Test R^2 score: 0.5433272204691257\n",
      "Num of epochs: 182\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Epoch 179, Loss: 0.44257338842027333\n",
      "Epoch 180, Loss: 0.44223043415311275\n",
      "Epoch 181, Loss: 0.4412573335324542\n",
      "Epoch 182, Loss: 0.4403093939212056\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20529264229559213\n",
      "Test R^2 score: 0.5427715707837119\n",
      "Num of epochs: 183\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Epoch 179, Loss: 0.44257338842027333\n",
      "Epoch 180, Loss: 0.44223043415311275\n",
      "Epoch 181, Loss: 0.4412573335324542\n",
      "Epoch 182, Loss: 0.4403093939212056\n",
      "Epoch 183, Loss: 0.440210765892682\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2034830153916529\n",
      "Test R^2 score: 0.550714199976328\n",
      "Num of epochs: 184\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Epoch 179, Loss: 0.44257338842027333\n",
      "Epoch 180, Loss: 0.44223043415311275\n",
      "Epoch 181, Loss: 0.4412573335324542\n",
      "Epoch 182, Loss: 0.4403093939212056\n",
      "Epoch 183, Loss: 0.440210765892682\n",
      "Epoch 184, Loss: 0.4406913267766654\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20783495175297897\n",
      "Test R^2 score: 0.5314269387467603\n",
      "Num of epochs: 185\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Epoch 179, Loss: 0.44257338842027333\n",
      "Epoch 180, Loss: 0.44223043415311275\n",
      "Epoch 181, Loss: 0.4412573335324542\n",
      "Epoch 182, Loss: 0.4403093939212056\n",
      "Epoch 183, Loss: 0.440210765892682\n",
      "Epoch 184, Loss: 0.4406913267766654\n",
      "Epoch 185, Loss: 0.44119678016972247\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20373170270051538\n",
      "Test R^2 score: 0.5493601317145367\n",
      "Num of epochs: 186\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Epoch 179, Loss: 0.44257338842027333\n",
      "Epoch 180, Loss: 0.44223043415311275\n",
      "Epoch 181, Loss: 0.4412573335324542\n",
      "Epoch 182, Loss: 0.4403093939212056\n",
      "Epoch 183, Loss: 0.440210765892682\n",
      "Epoch 184, Loss: 0.4406913267766654\n",
      "Epoch 185, Loss: 0.44119678016972247\n",
      "Epoch 186, Loss: 0.4414768331353019\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20803123388344827\n",
      "Test R^2 score: 0.5303910672257844\n",
      "Num of epochs: 187\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Epoch 179, Loss: 0.44257338842027333\n",
      "Epoch 180, Loss: 0.44223043415311275\n",
      "Epoch 181, Loss: 0.4412573335324542\n",
      "Epoch 182, Loss: 0.4403093939212056\n",
      "Epoch 183, Loss: 0.440210765892682\n",
      "Epoch 184, Loss: 0.4406913267766654\n",
      "Epoch 185, Loss: 0.44119678016972247\n",
      "Epoch 186, Loss: 0.4414768331353019\n",
      "Epoch 187, Loss: 0.44098509893198107\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2036650862587524\n",
      "Test R^2 score: 0.5497886980934209\n",
      "Num of epochs: 188\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Epoch 179, Loss: 0.44257338842027333\n",
      "Epoch 180, Loss: 0.44223043415311275\n",
      "Epoch 181, Loss: 0.4412573335324542\n",
      "Epoch 182, Loss: 0.4403093939212056\n",
      "Epoch 183, Loss: 0.440210765892682\n",
      "Epoch 184, Loss: 0.4406913267766654\n",
      "Epoch 185, Loss: 0.44119678016972247\n",
      "Epoch 186, Loss: 0.4414768331353019\n",
      "Epoch 187, Loss: 0.44098509893198107\n",
      "Epoch 188, Loss: 0.4399157822542188\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20508719173411316\n",
      "Test R^2 score: 0.5436575171943688\n",
      "Num of epochs: 189\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Epoch 179, Loss: 0.44257338842027333\n",
      "Epoch 180, Loss: 0.44223043415311275\n",
      "Epoch 181, Loss: 0.4412573335324542\n",
      "Epoch 182, Loss: 0.4403093939212056\n",
      "Epoch 183, Loss: 0.440210765892682\n",
      "Epoch 184, Loss: 0.4406913267766654\n",
      "Epoch 185, Loss: 0.44119678016972247\n",
      "Epoch 186, Loss: 0.4414768331353019\n",
      "Epoch 187, Loss: 0.44098509893198107\n",
      "Epoch 188, Loss: 0.4399157822542188\n",
      "Epoch 189, Loss: 0.43913002852403843\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20558855567209972\n",
      "Test R^2 score: 0.5414953952172291\n",
      "Num of epochs: 190\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Epoch 179, Loss: 0.44257338842027333\n",
      "Epoch 180, Loss: 0.44223043415311275\n",
      "Epoch 181, Loss: 0.4412573335324542\n",
      "Epoch 182, Loss: 0.4403093939212056\n",
      "Epoch 183, Loss: 0.440210765892682\n",
      "Epoch 184, Loss: 0.4406913267766654\n",
      "Epoch 185, Loss: 0.44119678016972247\n",
      "Epoch 186, Loss: 0.4414768331353019\n",
      "Epoch 187, Loss: 0.44098509893198107\n",
      "Epoch 188, Loss: 0.4399157822542188\n",
      "Epoch 189, Loss: 0.43913002852403843\n",
      "Epoch 190, Loss: 0.43912120575952834\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20381437112149492\n",
      "Test R^2 score: 0.5492079972939848\n",
      "Num of epochs: 191\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Epoch 179, Loss: 0.44257338842027333\n",
      "Epoch 180, Loss: 0.44223043415311275\n",
      "Epoch 181, Loss: 0.4412573335324542\n",
      "Epoch 182, Loss: 0.4403093939212056\n",
      "Epoch 183, Loss: 0.440210765892682\n",
      "Epoch 184, Loss: 0.4406913267766654\n",
      "Epoch 185, Loss: 0.44119678016972247\n",
      "Epoch 186, Loss: 0.4414768331353019\n",
      "Epoch 187, Loss: 0.44098509893198107\n",
      "Epoch 188, Loss: 0.4399157822542188\n",
      "Epoch 189, Loss: 0.43913002852403843\n",
      "Epoch 190, Loss: 0.43912120575952834\n",
      "Epoch 191, Loss: 0.43958194116248417\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20764787520460204\n",
      "Test R^2 score: 0.5322734893271467\n",
      "Num of epochs: 192\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Epoch 179, Loss: 0.44257338842027333\n",
      "Epoch 180, Loss: 0.44223043415311275\n",
      "Epoch 181, Loss: 0.4412573335324542\n",
      "Epoch 182, Loss: 0.4403093939212056\n",
      "Epoch 183, Loss: 0.440210765892682\n",
      "Epoch 184, Loss: 0.4406913267766654\n",
      "Epoch 185, Loss: 0.44119678016972247\n",
      "Epoch 186, Loss: 0.4414768331353019\n",
      "Epoch 187, Loss: 0.44098509893198107\n",
      "Epoch 188, Loss: 0.4399157822542188\n",
      "Epoch 189, Loss: 0.43913002852403843\n",
      "Epoch 190, Loss: 0.43912120575952834\n",
      "Epoch 191, Loss: 0.43958194116248417\n",
      "Epoch 192, Loss: 0.43991779767875194\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20370550764084144\n",
      "Test R^2 score: 0.549501432447857\n",
      "Num of epochs: 193\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Epoch 179, Loss: 0.44257338842027333\n",
      "Epoch 180, Loss: 0.44223043415311275\n",
      "Epoch 181, Loss: 0.4412573335324542\n",
      "Epoch 182, Loss: 0.4403093939212056\n",
      "Epoch 183, Loss: 0.440210765892682\n",
      "Epoch 184, Loss: 0.4406913267766654\n",
      "Epoch 185, Loss: 0.44119678016972247\n",
      "Epoch 186, Loss: 0.4414768331353019\n",
      "Epoch 187, Loss: 0.44098509893198107\n",
      "Epoch 188, Loss: 0.4399157822542188\n",
      "Epoch 189, Loss: 0.43913002852403843\n",
      "Epoch 190, Loss: 0.43912120575952834\n",
      "Epoch 191, Loss: 0.43958194116248417\n",
      "Epoch 192, Loss: 0.43991779767875194\n",
      "Epoch 193, Loss: 0.4402464762584031\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20793794127762563\n",
      "Test R^2 score: 0.5308177591076586\n",
      "Num of epochs: 194\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Epoch 179, Loss: 0.44257338842027333\n",
      "Epoch 180, Loss: 0.44223043415311275\n",
      "Epoch 181, Loss: 0.4412573335324542\n",
      "Epoch 182, Loss: 0.4403093939212056\n",
      "Epoch 183, Loss: 0.440210765892682\n",
      "Epoch 184, Loss: 0.4406913267766654\n",
      "Epoch 185, Loss: 0.44119678016972247\n",
      "Epoch 186, Loss: 0.4414768331353019\n",
      "Epoch 187, Loss: 0.44098509893198107\n",
      "Epoch 188, Loss: 0.4399157822542188\n",
      "Epoch 189, Loss: 0.43913002852403843\n",
      "Epoch 190, Loss: 0.43912120575952834\n",
      "Epoch 191, Loss: 0.43958194116248417\n",
      "Epoch 192, Loss: 0.43991779767875194\n",
      "Epoch 193, Loss: 0.4402464762584031\n",
      "Epoch 194, Loss: 0.4397939928277301\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2037858877156277\n",
      "Test R^2 score: 0.5491861649964376\n",
      "Num of epochs: 195\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Epoch 179, Loss: 0.44257338842027333\n",
      "Epoch 180, Loss: 0.44223043415311275\n",
      "Epoch 181, Loss: 0.4412573335324542\n",
      "Epoch 182, Loss: 0.4403093939212056\n",
      "Epoch 183, Loss: 0.440210765892682\n",
      "Epoch 184, Loss: 0.4406913267766654\n",
      "Epoch 185, Loss: 0.44119678016972247\n",
      "Epoch 186, Loss: 0.4414768331353019\n",
      "Epoch 187, Loss: 0.44098509893198107\n",
      "Epoch 188, Loss: 0.4399157822542188\n",
      "Epoch 189, Loss: 0.43913002852403843\n",
      "Epoch 190, Loss: 0.43912120575952834\n",
      "Epoch 191, Loss: 0.43958194116248417\n",
      "Epoch 192, Loss: 0.43991779767875194\n",
      "Epoch 193, Loss: 0.4402464762584031\n",
      "Epoch 194, Loss: 0.4397939928277301\n",
      "Epoch 195, Loss: 0.4389848715145781\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2056510358413463\n",
      "Test R^2 score: 0.5411288815725317\n",
      "Num of epochs: 196\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Epoch 179, Loss: 0.44257338842027333\n",
      "Epoch 180, Loss: 0.44223043415311275\n",
      "Epoch 181, Loss: 0.4412573335324542\n",
      "Epoch 182, Loss: 0.4403093939212056\n",
      "Epoch 183, Loss: 0.440210765892682\n",
      "Epoch 184, Loss: 0.4406913267766654\n",
      "Epoch 185, Loss: 0.44119678016972247\n",
      "Epoch 186, Loss: 0.4414768331353019\n",
      "Epoch 187, Loss: 0.44098509893198107\n",
      "Epoch 188, Loss: 0.4399157822542188\n",
      "Epoch 189, Loss: 0.43913002852403843\n",
      "Epoch 190, Loss: 0.43912120575952834\n",
      "Epoch 191, Loss: 0.43958194116248417\n",
      "Epoch 192, Loss: 0.43991779767875194\n",
      "Epoch 193, Loss: 0.4402464762584031\n",
      "Epoch 194, Loss: 0.4397939928277301\n",
      "Epoch 195, Loss: 0.4389848715145781\n",
      "Epoch 196, Loss: 0.43812834372448495\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20517832351178283\n",
      "Test R^2 score: 0.5432790044821327\n",
      "Num of epochs: 197\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Epoch 179, Loss: 0.44257338842027333\n",
      "Epoch 180, Loss: 0.44223043415311275\n",
      "Epoch 181, Loss: 0.4412573335324542\n",
      "Epoch 182, Loss: 0.4403093939212056\n",
      "Epoch 183, Loss: 0.440210765892682\n",
      "Epoch 184, Loss: 0.4406913267766654\n",
      "Epoch 185, Loss: 0.44119678016972247\n",
      "Epoch 186, Loss: 0.4414768331353019\n",
      "Epoch 187, Loss: 0.44098509893198107\n",
      "Epoch 188, Loss: 0.4399157822542188\n",
      "Epoch 189, Loss: 0.43913002852403843\n",
      "Epoch 190, Loss: 0.43912120575952834\n",
      "Epoch 191, Loss: 0.43958194116248417\n",
      "Epoch 192, Loss: 0.43991779767875194\n",
      "Epoch 193, Loss: 0.4402464762584031\n",
      "Epoch 194, Loss: 0.4397939928277301\n",
      "Epoch 195, Loss: 0.4389848715145781\n",
      "Epoch 196, Loss: 0.43812834372448495\n",
      "Epoch 197, Loss: 0.4378789384628316\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20411656002363393\n",
      "Test R^2 score: 0.547898797350175\n",
      "Num of epochs: 198\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Epoch 179, Loss: 0.44257338842027333\n",
      "Epoch 180, Loss: 0.44223043415311275\n",
      "Epoch 181, Loss: 0.4412573335324542\n",
      "Epoch 182, Loss: 0.4403093939212056\n",
      "Epoch 183, Loss: 0.440210765892682\n",
      "Epoch 184, Loss: 0.4406913267766654\n",
      "Epoch 185, Loss: 0.44119678016972247\n",
      "Epoch 186, Loss: 0.4414768331353019\n",
      "Epoch 187, Loss: 0.44098509893198107\n",
      "Epoch 188, Loss: 0.4399157822542188\n",
      "Epoch 189, Loss: 0.43913002852403843\n",
      "Epoch 190, Loss: 0.43912120575952834\n",
      "Epoch 191, Loss: 0.43958194116248417\n",
      "Epoch 192, Loss: 0.43991779767875194\n",
      "Epoch 193, Loss: 0.4402464762584031\n",
      "Epoch 194, Loss: 0.4397939928277301\n",
      "Epoch 195, Loss: 0.4389848715145781\n",
      "Epoch 196, Loss: 0.43812834372448495\n",
      "Epoch 197, Loss: 0.4378789384628316\n",
      "Epoch 198, Loss: 0.4380569659316353\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20745969846909257\n",
      "Test R^2 score: 0.5331070695942057\n",
      "Num of epochs: 199\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Epoch 179, Loss: 0.44257338842027333\n",
      "Epoch 180, Loss: 0.44223043415311275\n",
      "Epoch 181, Loss: 0.4412573335324542\n",
      "Epoch 182, Loss: 0.4403093939212056\n",
      "Epoch 183, Loss: 0.440210765892682\n",
      "Epoch 184, Loss: 0.4406913267766654\n",
      "Epoch 185, Loss: 0.44119678016972247\n",
      "Epoch 186, Loss: 0.4414768331353019\n",
      "Epoch 187, Loss: 0.44098509893198107\n",
      "Epoch 188, Loss: 0.4399157822542188\n",
      "Epoch 189, Loss: 0.43913002852403843\n",
      "Epoch 190, Loss: 0.43912120575952834\n",
      "Epoch 191, Loss: 0.43958194116248417\n",
      "Epoch 192, Loss: 0.43991779767875194\n",
      "Epoch 193, Loss: 0.4402464762584031\n",
      "Epoch 194, Loss: 0.4397939928277301\n",
      "Epoch 195, Loss: 0.4389848715145781\n",
      "Epoch 196, Loss: 0.43812834372448495\n",
      "Epoch 197, Loss: 0.4378789384628316\n",
      "Epoch 198, Loss: 0.4380569659316353\n",
      "Epoch 199, Loss: 0.4385928231376636\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20396585868149766\n",
      "Test R^2 score: 0.5483095919762253\n",
      "Num of epochs: 200\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Epoch 179, Loss: 0.44257338842027333\n",
      "Epoch 180, Loss: 0.44223043415311275\n",
      "Epoch 181, Loss: 0.4412573335324542\n",
      "Epoch 182, Loss: 0.4403093939212056\n",
      "Epoch 183, Loss: 0.440210765892682\n",
      "Epoch 184, Loss: 0.4406913267766654\n",
      "Epoch 185, Loss: 0.44119678016972247\n",
      "Epoch 186, Loss: 0.4414768331353019\n",
      "Epoch 187, Loss: 0.44098509893198107\n",
      "Epoch 188, Loss: 0.4399157822542188\n",
      "Epoch 189, Loss: 0.43913002852403843\n",
      "Epoch 190, Loss: 0.43912120575952834\n",
      "Epoch 191, Loss: 0.43958194116248417\n",
      "Epoch 192, Loss: 0.43991779767875194\n",
      "Epoch 193, Loss: 0.4402464762584031\n",
      "Epoch 194, Loss: 0.4397939928277301\n",
      "Epoch 195, Loss: 0.4389848715145781\n",
      "Epoch 196, Loss: 0.43812834372448495\n",
      "Epoch 197, Loss: 0.4378789384628316\n",
      "Epoch 198, Loss: 0.4380569659316353\n",
      "Epoch 199, Loss: 0.4385928231376636\n",
      "Epoch 200, Loss: 0.4396870477941122\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2098391789458775\n",
      "Test R^2 score: 0.5221805620989538\n",
      "Num of epochs: 201\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Epoch 179, Loss: 0.44257338842027333\n",
      "Epoch 180, Loss: 0.44223043415311275\n",
      "Epoch 181, Loss: 0.4412573335324542\n",
      "Epoch 182, Loss: 0.4403093939212056\n",
      "Epoch 183, Loss: 0.440210765892682\n",
      "Epoch 184, Loss: 0.4406913267766654\n",
      "Epoch 185, Loss: 0.44119678016972247\n",
      "Epoch 186, Loss: 0.4414768331353019\n",
      "Epoch 187, Loss: 0.44098509893198107\n",
      "Epoch 188, Loss: 0.4399157822542188\n",
      "Epoch 189, Loss: 0.43913002852403843\n",
      "Epoch 190, Loss: 0.43912120575952834\n",
      "Epoch 191, Loss: 0.43958194116248417\n",
      "Epoch 192, Loss: 0.43991779767875194\n",
      "Epoch 193, Loss: 0.4402464762584031\n",
      "Epoch 194, Loss: 0.4397939928277301\n",
      "Epoch 195, Loss: 0.4389848715145781\n",
      "Epoch 196, Loss: 0.43812834372448495\n",
      "Epoch 197, Loss: 0.4378789384628316\n",
      "Epoch 198, Loss: 0.4380569659316353\n",
      "Epoch 199, Loss: 0.4385928231376636\n",
      "Epoch 200, Loss: 0.4396870477941122\n",
      "Epoch 201, Loss: 0.44003322037003134\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.204108704010809\n",
      "Test R^2 score: 0.5475769598729048\n",
      "Num of epochs: 202\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Epoch 179, Loss: 0.44257338842027333\n",
      "Epoch 180, Loss: 0.44223043415311275\n",
      "Epoch 181, Loss: 0.4412573335324542\n",
      "Epoch 182, Loss: 0.4403093939212056\n",
      "Epoch 183, Loss: 0.440210765892682\n",
      "Epoch 184, Loss: 0.4406913267766654\n",
      "Epoch 185, Loss: 0.44119678016972247\n",
      "Epoch 186, Loss: 0.4414768331353019\n",
      "Epoch 187, Loss: 0.44098509893198107\n",
      "Epoch 188, Loss: 0.4399157822542188\n",
      "Epoch 189, Loss: 0.43913002852403843\n",
      "Epoch 190, Loss: 0.43912120575952834\n",
      "Epoch 191, Loss: 0.43958194116248417\n",
      "Epoch 192, Loss: 0.43991779767875194\n",
      "Epoch 193, Loss: 0.4402464762584031\n",
      "Epoch 194, Loss: 0.4397939928277301\n",
      "Epoch 195, Loss: 0.4389848715145781\n",
      "Epoch 196, Loss: 0.43812834372448495\n",
      "Epoch 197, Loss: 0.4378789384628316\n",
      "Epoch 198, Loss: 0.4380569659316353\n",
      "Epoch 199, Loss: 0.4385928231376636\n",
      "Epoch 200, Loss: 0.4396870477941122\n",
      "Epoch 201, Loss: 0.44003322037003134\n",
      "Epoch 202, Loss: 0.4396387344028484\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20750292109014737\n",
      "Test R^2 score: 0.5328331138601292\n",
      "Num of epochs: 203\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Epoch 179, Loss: 0.44257338842027333\n",
      "Epoch 180, Loss: 0.44223043415311275\n",
      "Epoch 181, Loss: 0.4412573335324542\n",
      "Epoch 182, Loss: 0.4403093939212056\n",
      "Epoch 183, Loss: 0.440210765892682\n",
      "Epoch 184, Loss: 0.4406913267766654\n",
      "Epoch 185, Loss: 0.44119678016972247\n",
      "Epoch 186, Loss: 0.4414768331353019\n",
      "Epoch 187, Loss: 0.44098509893198107\n",
      "Epoch 188, Loss: 0.4399157822542188\n",
      "Epoch 189, Loss: 0.43913002852403843\n",
      "Epoch 190, Loss: 0.43912120575952834\n",
      "Epoch 191, Loss: 0.43958194116248417\n",
      "Epoch 192, Loss: 0.43991779767875194\n",
      "Epoch 193, Loss: 0.4402464762584031\n",
      "Epoch 194, Loss: 0.4397939928277301\n",
      "Epoch 195, Loss: 0.4389848715145781\n",
      "Epoch 196, Loss: 0.43812834372448495\n",
      "Epoch 197, Loss: 0.4378789384628316\n",
      "Epoch 198, Loss: 0.4380569659316353\n",
      "Epoch 199, Loss: 0.4385928231376636\n",
      "Epoch 200, Loss: 0.4396870477941122\n",
      "Epoch 201, Loss: 0.44003322037003134\n",
      "Epoch 202, Loss: 0.4396387344028484\n",
      "Epoch 203, Loss: 0.43797246081508234\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2043310539171926\n",
      "Test R^2 score: 0.5469304825166121\n",
      "Num of epochs: 204\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Epoch 179, Loss: 0.44257338842027333\n",
      "Epoch 180, Loss: 0.44223043415311275\n",
      "Epoch 181, Loss: 0.4412573335324542\n",
      "Epoch 182, Loss: 0.4403093939212056\n",
      "Epoch 183, Loss: 0.440210765892682\n",
      "Epoch 184, Loss: 0.4406913267766654\n",
      "Epoch 185, Loss: 0.44119678016972247\n",
      "Epoch 186, Loss: 0.4414768331353019\n",
      "Epoch 187, Loss: 0.44098509893198107\n",
      "Epoch 188, Loss: 0.4399157822542188\n",
      "Epoch 189, Loss: 0.43913002852403843\n",
      "Epoch 190, Loss: 0.43912120575952834\n",
      "Epoch 191, Loss: 0.43958194116248417\n",
      "Epoch 192, Loss: 0.43991779767875194\n",
      "Epoch 193, Loss: 0.4402464762584031\n",
      "Epoch 194, Loss: 0.4397939928277301\n",
      "Epoch 195, Loss: 0.4389848715145781\n",
      "Epoch 196, Loss: 0.43812834372448495\n",
      "Epoch 197, Loss: 0.4378789384628316\n",
      "Epoch 198, Loss: 0.4380569659316353\n",
      "Epoch 199, Loss: 0.4385928231376636\n",
      "Epoch 200, Loss: 0.4396870477941122\n",
      "Epoch 201, Loss: 0.44003322037003134\n",
      "Epoch 202, Loss: 0.4396387344028484\n",
      "Epoch 203, Loss: 0.43797246081508234\n",
      "Epoch 204, Loss: 0.4368868004619995\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20455399419034956\n",
      "Test R^2 score: 0.5460209936310225\n",
      "Num of epochs: 205\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Epoch 179, Loss: 0.44257338842027333\n",
      "Epoch 180, Loss: 0.44223043415311275\n",
      "Epoch 181, Loss: 0.4412573335324542\n",
      "Epoch 182, Loss: 0.4403093939212056\n",
      "Epoch 183, Loss: 0.440210765892682\n",
      "Epoch 184, Loss: 0.4406913267766654\n",
      "Epoch 185, Loss: 0.44119678016972247\n",
      "Epoch 186, Loss: 0.4414768331353019\n",
      "Epoch 187, Loss: 0.44098509893198107\n",
      "Epoch 188, Loss: 0.4399157822542188\n",
      "Epoch 189, Loss: 0.43913002852403843\n",
      "Epoch 190, Loss: 0.43912120575952834\n",
      "Epoch 191, Loss: 0.43958194116248417\n",
      "Epoch 192, Loss: 0.43991779767875194\n",
      "Epoch 193, Loss: 0.4402464762584031\n",
      "Epoch 194, Loss: 0.4397939928277301\n",
      "Epoch 195, Loss: 0.4389848715145781\n",
      "Epoch 196, Loss: 0.43812834372448495\n",
      "Epoch 197, Loss: 0.4378789384628316\n",
      "Epoch 198, Loss: 0.4380569659316353\n",
      "Epoch 199, Loss: 0.4385928231376636\n",
      "Epoch 200, Loss: 0.4396870477941122\n",
      "Epoch 201, Loss: 0.44003322037003134\n",
      "Epoch 202, Loss: 0.4396387344028484\n",
      "Epoch 203, Loss: 0.43797246081508234\n",
      "Epoch 204, Loss: 0.4368868004619995\n",
      "Epoch 205, Loss: 0.4366217722212388\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20685862685878514\n",
      "Test R^2 score: 0.5358321122034021\n",
      "Num of epochs: 206\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Epoch 179, Loss: 0.44257338842027333\n",
      "Epoch 180, Loss: 0.44223043415311275\n",
      "Epoch 181, Loss: 0.4412573335324542\n",
      "Epoch 182, Loss: 0.4403093939212056\n",
      "Epoch 183, Loss: 0.440210765892682\n",
      "Epoch 184, Loss: 0.4406913267766654\n",
      "Epoch 185, Loss: 0.44119678016972247\n",
      "Epoch 186, Loss: 0.4414768331353019\n",
      "Epoch 187, Loss: 0.44098509893198107\n",
      "Epoch 188, Loss: 0.4399157822542188\n",
      "Epoch 189, Loss: 0.43913002852403843\n",
      "Epoch 190, Loss: 0.43912120575952834\n",
      "Epoch 191, Loss: 0.43958194116248417\n",
      "Epoch 192, Loss: 0.43991779767875194\n",
      "Epoch 193, Loss: 0.4402464762584031\n",
      "Epoch 194, Loss: 0.4397939928277301\n",
      "Epoch 195, Loss: 0.4389848715145781\n",
      "Epoch 196, Loss: 0.43812834372448495\n",
      "Epoch 197, Loss: 0.4378789384628316\n",
      "Epoch 198, Loss: 0.4380569659316353\n",
      "Epoch 199, Loss: 0.4385928231376636\n",
      "Epoch 200, Loss: 0.4396870477941122\n",
      "Epoch 201, Loss: 0.44003322037003134\n",
      "Epoch 202, Loss: 0.4396387344028484\n",
      "Epoch 203, Loss: 0.43797246081508234\n",
      "Epoch 204, Loss: 0.4368868004619995\n",
      "Epoch 205, Loss: 0.4366217722212388\n",
      "Epoch 206, Loss: 0.4370735508315267\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2040985858921733\n",
      "Test R^2 score: 0.5477450354324802\n",
      "Num of epochs: 207\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Epoch 179, Loss: 0.44257338842027333\n",
      "Epoch 180, Loss: 0.44223043415311275\n",
      "Epoch 181, Loss: 0.4412573335324542\n",
      "Epoch 182, Loss: 0.4403093939212056\n",
      "Epoch 183, Loss: 0.440210765892682\n",
      "Epoch 184, Loss: 0.4406913267766654\n",
      "Epoch 185, Loss: 0.44119678016972247\n",
      "Epoch 186, Loss: 0.4414768331353019\n",
      "Epoch 187, Loss: 0.44098509893198107\n",
      "Epoch 188, Loss: 0.4399157822542188\n",
      "Epoch 189, Loss: 0.43913002852403843\n",
      "Epoch 190, Loss: 0.43912120575952834\n",
      "Epoch 191, Loss: 0.43958194116248417\n",
      "Epoch 192, Loss: 0.43991779767875194\n",
      "Epoch 193, Loss: 0.4402464762584031\n",
      "Epoch 194, Loss: 0.4397939928277301\n",
      "Epoch 195, Loss: 0.4389848715145781\n",
      "Epoch 196, Loss: 0.43812834372448495\n",
      "Epoch 197, Loss: 0.4378789384628316\n",
      "Epoch 198, Loss: 0.4380569659316353\n",
      "Epoch 199, Loss: 0.4385928231376636\n",
      "Epoch 200, Loss: 0.4396870477941122\n",
      "Epoch 201, Loss: 0.44003322037003134\n",
      "Epoch 202, Loss: 0.4396387344028484\n",
      "Epoch 203, Loss: 0.43797246081508234\n",
      "Epoch 204, Loss: 0.4368868004619995\n",
      "Epoch 205, Loss: 0.4366217722212388\n",
      "Epoch 206, Loss: 0.4370735508315267\n",
      "Epoch 207, Loss: 0.438056659783102\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2092000653013037\n",
      "Test R^2 score: 0.5251227071317075\n",
      "Num of epochs: 208\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Epoch 179, Loss: 0.44257338842027333\n",
      "Epoch 180, Loss: 0.44223043415311275\n",
      "Epoch 181, Loss: 0.4412573335324542\n",
      "Epoch 182, Loss: 0.4403093939212056\n",
      "Epoch 183, Loss: 0.440210765892682\n",
      "Epoch 184, Loss: 0.4406913267766654\n",
      "Epoch 185, Loss: 0.44119678016972247\n",
      "Epoch 186, Loss: 0.4414768331353019\n",
      "Epoch 187, Loss: 0.44098509893198107\n",
      "Epoch 188, Loss: 0.4399157822542188\n",
      "Epoch 189, Loss: 0.43913002852403843\n",
      "Epoch 190, Loss: 0.43912120575952834\n",
      "Epoch 191, Loss: 0.43958194116248417\n",
      "Epoch 192, Loss: 0.43991779767875194\n",
      "Epoch 193, Loss: 0.4402464762584031\n",
      "Epoch 194, Loss: 0.4397939928277301\n",
      "Epoch 195, Loss: 0.4389848715145781\n",
      "Epoch 196, Loss: 0.43812834372448495\n",
      "Epoch 197, Loss: 0.4378789384628316\n",
      "Epoch 198, Loss: 0.4380569659316353\n",
      "Epoch 199, Loss: 0.4385928231376636\n",
      "Epoch 200, Loss: 0.4396870477941122\n",
      "Epoch 201, Loss: 0.44003322037003134\n",
      "Epoch 202, Loss: 0.4396387344028484\n",
      "Epoch 203, Loss: 0.43797246081508234\n",
      "Epoch 204, Loss: 0.4368868004619995\n",
      "Epoch 205, Loss: 0.4366217722212388\n",
      "Epoch 206, Loss: 0.4370735508315267\n",
      "Epoch 207, Loss: 0.438056659783102\n",
      "Epoch 208, Loss: 0.43828697608838324\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20408687934121578\n",
      "Test R^2 score: 0.5477157778766886\n",
      "Num of epochs: 209\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Epoch 179, Loss: 0.44257338842027333\n",
      "Epoch 180, Loss: 0.44223043415311275\n",
      "Epoch 181, Loss: 0.4412573335324542\n",
      "Epoch 182, Loss: 0.4403093939212056\n",
      "Epoch 183, Loss: 0.440210765892682\n",
      "Epoch 184, Loss: 0.4406913267766654\n",
      "Epoch 185, Loss: 0.44119678016972247\n",
      "Epoch 186, Loss: 0.4414768331353019\n",
      "Epoch 187, Loss: 0.44098509893198107\n",
      "Epoch 188, Loss: 0.4399157822542188\n",
      "Epoch 189, Loss: 0.43913002852403843\n",
      "Epoch 190, Loss: 0.43912120575952834\n",
      "Epoch 191, Loss: 0.43958194116248417\n",
      "Epoch 192, Loss: 0.43991779767875194\n",
      "Epoch 193, Loss: 0.4402464762584031\n",
      "Epoch 194, Loss: 0.4397939928277301\n",
      "Epoch 195, Loss: 0.4389848715145781\n",
      "Epoch 196, Loss: 0.43812834372448495\n",
      "Epoch 197, Loss: 0.4378789384628316\n",
      "Epoch 198, Loss: 0.4380569659316353\n",
      "Epoch 199, Loss: 0.4385928231376636\n",
      "Epoch 200, Loss: 0.4396870477941122\n",
      "Epoch 201, Loss: 0.44003322037003134\n",
      "Epoch 202, Loss: 0.4396387344028484\n",
      "Epoch 203, Loss: 0.43797246081508234\n",
      "Epoch 204, Loss: 0.4368868004619995\n",
      "Epoch 205, Loss: 0.4366217722212388\n",
      "Epoch 206, Loss: 0.4370735508315267\n",
      "Epoch 207, Loss: 0.438056659783102\n",
      "Epoch 208, Loss: 0.43828697608838324\n",
      "Epoch 209, Loss: 0.4380426277456835\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2074563586578635\n",
      "Test R^2 score: 0.5329909865443361\n",
      "Num of epochs: 210\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Epoch 179, Loss: 0.44257338842027333\n",
      "Epoch 180, Loss: 0.44223043415311275\n",
      "Epoch 181, Loss: 0.4412573335324542\n",
      "Epoch 182, Loss: 0.4403093939212056\n",
      "Epoch 183, Loss: 0.440210765892682\n",
      "Epoch 184, Loss: 0.4406913267766654\n",
      "Epoch 185, Loss: 0.44119678016972247\n",
      "Epoch 186, Loss: 0.4414768331353019\n",
      "Epoch 187, Loss: 0.44098509893198107\n",
      "Epoch 188, Loss: 0.4399157822542188\n",
      "Epoch 189, Loss: 0.43913002852403843\n",
      "Epoch 190, Loss: 0.43912120575952834\n",
      "Epoch 191, Loss: 0.43958194116248417\n",
      "Epoch 192, Loss: 0.43991779767875194\n",
      "Epoch 193, Loss: 0.4402464762584031\n",
      "Epoch 194, Loss: 0.4397939928277301\n",
      "Epoch 195, Loss: 0.4389848715145781\n",
      "Epoch 196, Loss: 0.43812834372448495\n",
      "Epoch 197, Loss: 0.4378789384628316\n",
      "Epoch 198, Loss: 0.4380569659316353\n",
      "Epoch 199, Loss: 0.4385928231376636\n",
      "Epoch 200, Loss: 0.4396870477941122\n",
      "Epoch 201, Loss: 0.44003322037003134\n",
      "Epoch 202, Loss: 0.4396387344028484\n",
      "Epoch 203, Loss: 0.43797246081508234\n",
      "Epoch 204, Loss: 0.4368868004619995\n",
      "Epoch 205, Loss: 0.4366217722212388\n",
      "Epoch 206, Loss: 0.4370735508315267\n",
      "Epoch 207, Loss: 0.438056659783102\n",
      "Epoch 208, Loss: 0.43828697608838324\n",
      "Epoch 209, Loss: 0.4380426277456835\n",
      "Epoch 210, Loss: 0.4367571723427673\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20447046459972007\n",
      "Test R^2 score: 0.5462363593225891\n",
      "Num of epochs: 211\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Epoch 179, Loss: 0.44257338842027333\n",
      "Epoch 180, Loss: 0.44223043415311275\n",
      "Epoch 181, Loss: 0.4412573335324542\n",
      "Epoch 182, Loss: 0.4403093939212056\n",
      "Epoch 183, Loss: 0.440210765892682\n",
      "Epoch 184, Loss: 0.4406913267766654\n",
      "Epoch 185, Loss: 0.44119678016972247\n",
      "Epoch 186, Loss: 0.4414768331353019\n",
      "Epoch 187, Loss: 0.44098509893198107\n",
      "Epoch 188, Loss: 0.4399157822542188\n",
      "Epoch 189, Loss: 0.43913002852403843\n",
      "Epoch 190, Loss: 0.43912120575952834\n",
      "Epoch 191, Loss: 0.43958194116248417\n",
      "Epoch 192, Loss: 0.43991779767875194\n",
      "Epoch 193, Loss: 0.4402464762584031\n",
      "Epoch 194, Loss: 0.4397939928277301\n",
      "Epoch 195, Loss: 0.4389848715145781\n",
      "Epoch 196, Loss: 0.43812834372448495\n",
      "Epoch 197, Loss: 0.4378789384628316\n",
      "Epoch 198, Loss: 0.4380569659316353\n",
      "Epoch 199, Loss: 0.4385928231376636\n",
      "Epoch 200, Loss: 0.4396870477941122\n",
      "Epoch 201, Loss: 0.44003322037003134\n",
      "Epoch 202, Loss: 0.4396387344028484\n",
      "Epoch 203, Loss: 0.43797246081508234\n",
      "Epoch 204, Loss: 0.4368868004619995\n",
      "Epoch 205, Loss: 0.4366217722212388\n",
      "Epoch 206, Loss: 0.4370735508315267\n",
      "Epoch 207, Loss: 0.438056659783102\n",
      "Epoch 208, Loss: 0.43828697608838324\n",
      "Epoch 209, Loss: 0.4380426277456835\n",
      "Epoch 210, Loss: 0.4367571723427673\n",
      "Epoch 211, Loss: 0.4358287121793394\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20486049151316835\n",
      "Test R^2 score: 0.5446388959088131\n",
      "Num of epochs: 212\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Epoch 179, Loss: 0.44257338842027333\n",
      "Epoch 180, Loss: 0.44223043415311275\n",
      "Epoch 181, Loss: 0.4412573335324542\n",
      "Epoch 182, Loss: 0.4403093939212056\n",
      "Epoch 183, Loss: 0.440210765892682\n",
      "Epoch 184, Loss: 0.4406913267766654\n",
      "Epoch 185, Loss: 0.44119678016972247\n",
      "Epoch 186, Loss: 0.4414768331353019\n",
      "Epoch 187, Loss: 0.44098509893198107\n",
      "Epoch 188, Loss: 0.4399157822542188\n",
      "Epoch 189, Loss: 0.43913002852403843\n",
      "Epoch 190, Loss: 0.43912120575952834\n",
      "Epoch 191, Loss: 0.43958194116248417\n",
      "Epoch 192, Loss: 0.43991779767875194\n",
      "Epoch 193, Loss: 0.4402464762584031\n",
      "Epoch 194, Loss: 0.4397939928277301\n",
      "Epoch 195, Loss: 0.4389848715145781\n",
      "Epoch 196, Loss: 0.43812834372448495\n",
      "Epoch 197, Loss: 0.4378789384628316\n",
      "Epoch 198, Loss: 0.4380569659316353\n",
      "Epoch 199, Loss: 0.4385928231376636\n",
      "Epoch 200, Loss: 0.4396870477941122\n",
      "Epoch 201, Loss: 0.44003322037003134\n",
      "Epoch 202, Loss: 0.4396387344028484\n",
      "Epoch 203, Loss: 0.43797246081508234\n",
      "Epoch 204, Loss: 0.4368868004619995\n",
      "Epoch 205, Loss: 0.4366217722212388\n",
      "Epoch 206, Loss: 0.4370735508315267\n",
      "Epoch 207, Loss: 0.438056659783102\n",
      "Epoch 208, Loss: 0.43828697608838324\n",
      "Epoch 209, Loss: 0.4380426277456835\n",
      "Epoch 210, Loss: 0.4367571723427673\n",
      "Epoch 211, Loss: 0.4358287121793394\n",
      "Epoch 212, Loss: 0.43549599799409766\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2063937130723004\n",
      "Test R^2 score: 0.5379356787358491\n",
      "Num of epochs: 213\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Epoch 179, Loss: 0.44257338842027333\n",
      "Epoch 180, Loss: 0.44223043415311275\n",
      "Epoch 181, Loss: 0.4412573335324542\n",
      "Epoch 182, Loss: 0.4403093939212056\n",
      "Epoch 183, Loss: 0.440210765892682\n",
      "Epoch 184, Loss: 0.4406913267766654\n",
      "Epoch 185, Loss: 0.44119678016972247\n",
      "Epoch 186, Loss: 0.4414768331353019\n",
      "Epoch 187, Loss: 0.44098509893198107\n",
      "Epoch 188, Loss: 0.4399157822542188\n",
      "Epoch 189, Loss: 0.43913002852403843\n",
      "Epoch 190, Loss: 0.43912120575952834\n",
      "Epoch 191, Loss: 0.43958194116248417\n",
      "Epoch 192, Loss: 0.43991779767875194\n",
      "Epoch 193, Loss: 0.4402464762584031\n",
      "Epoch 194, Loss: 0.4397939928277301\n",
      "Epoch 195, Loss: 0.4389848715145781\n",
      "Epoch 196, Loss: 0.43812834372448495\n",
      "Epoch 197, Loss: 0.4378789384628316\n",
      "Epoch 198, Loss: 0.4380569659316353\n",
      "Epoch 199, Loss: 0.4385928231376636\n",
      "Epoch 200, Loss: 0.4396870477941122\n",
      "Epoch 201, Loss: 0.44003322037003134\n",
      "Epoch 202, Loss: 0.4396387344028484\n",
      "Epoch 203, Loss: 0.43797246081508234\n",
      "Epoch 204, Loss: 0.4368868004619995\n",
      "Epoch 205, Loss: 0.4366217722212388\n",
      "Epoch 206, Loss: 0.4370735508315267\n",
      "Epoch 207, Loss: 0.438056659783102\n",
      "Epoch 208, Loss: 0.43828697608838324\n",
      "Epoch 209, Loss: 0.4380426277456835\n",
      "Epoch 210, Loss: 0.4367571723427673\n",
      "Epoch 211, Loss: 0.4358287121793394\n",
      "Epoch 212, Loss: 0.43549599799409766\n",
      "Epoch 213, Loss: 0.435693177425488\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20423373673456624\n",
      "Test R^2 score: 0.5472019216428925\n",
      "Num of epochs: 214\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Epoch 179, Loss: 0.44257338842027333\n",
      "Epoch 180, Loss: 0.44223043415311275\n",
      "Epoch 181, Loss: 0.4412573335324542\n",
      "Epoch 182, Loss: 0.4403093939212056\n",
      "Epoch 183, Loss: 0.440210765892682\n",
      "Epoch 184, Loss: 0.4406913267766654\n",
      "Epoch 185, Loss: 0.44119678016972247\n",
      "Epoch 186, Loss: 0.4414768331353019\n",
      "Epoch 187, Loss: 0.44098509893198107\n",
      "Epoch 188, Loss: 0.4399157822542188\n",
      "Epoch 189, Loss: 0.43913002852403843\n",
      "Epoch 190, Loss: 0.43912120575952834\n",
      "Epoch 191, Loss: 0.43958194116248417\n",
      "Epoch 192, Loss: 0.43991779767875194\n",
      "Epoch 193, Loss: 0.4402464762584031\n",
      "Epoch 194, Loss: 0.4397939928277301\n",
      "Epoch 195, Loss: 0.4389848715145781\n",
      "Epoch 196, Loss: 0.43812834372448495\n",
      "Epoch 197, Loss: 0.4378789384628316\n",
      "Epoch 198, Loss: 0.4380569659316353\n",
      "Epoch 199, Loss: 0.4385928231376636\n",
      "Epoch 200, Loss: 0.4396870477941122\n",
      "Epoch 201, Loss: 0.44003322037003134\n",
      "Epoch 202, Loss: 0.4396387344028484\n",
      "Epoch 203, Loss: 0.43797246081508234\n",
      "Epoch 204, Loss: 0.4368868004619995\n",
      "Epoch 205, Loss: 0.4366217722212388\n",
      "Epoch 206, Loss: 0.4370735508315267\n",
      "Epoch 207, Loss: 0.438056659783102\n",
      "Epoch 208, Loss: 0.43828697608838324\n",
      "Epoch 209, Loss: 0.4380426277456835\n",
      "Epoch 210, Loss: 0.4367571723427673\n",
      "Epoch 211, Loss: 0.4358287121793394\n",
      "Epoch 212, Loss: 0.43549599799409766\n",
      "Epoch 213, Loss: 0.435693177425488\n",
      "Epoch 214, Loss: 0.43638716241086417\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20936238488918502\n",
      "Test R^2 score: 0.5244167809739486\n",
      "Num of epochs: 215\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Epoch 179, Loss: 0.44257338842027333\n",
      "Epoch 180, Loss: 0.44223043415311275\n",
      "Epoch 181, Loss: 0.4412573335324542\n",
      "Epoch 182, Loss: 0.4403093939212056\n",
      "Epoch 183, Loss: 0.440210765892682\n",
      "Epoch 184, Loss: 0.4406913267766654\n",
      "Epoch 185, Loss: 0.44119678016972247\n",
      "Epoch 186, Loss: 0.4414768331353019\n",
      "Epoch 187, Loss: 0.44098509893198107\n",
      "Epoch 188, Loss: 0.4399157822542188\n",
      "Epoch 189, Loss: 0.43913002852403843\n",
      "Epoch 190, Loss: 0.43912120575952834\n",
      "Epoch 191, Loss: 0.43958194116248417\n",
      "Epoch 192, Loss: 0.43991779767875194\n",
      "Epoch 193, Loss: 0.4402464762584031\n",
      "Epoch 194, Loss: 0.4397939928277301\n",
      "Epoch 195, Loss: 0.4389848715145781\n",
      "Epoch 196, Loss: 0.43812834372448495\n",
      "Epoch 197, Loss: 0.4378789384628316\n",
      "Epoch 198, Loss: 0.4380569659316353\n",
      "Epoch 199, Loss: 0.4385928231376636\n",
      "Epoch 200, Loss: 0.4396870477941122\n",
      "Epoch 201, Loss: 0.44003322037003134\n",
      "Epoch 202, Loss: 0.4396387344028484\n",
      "Epoch 203, Loss: 0.43797246081508234\n",
      "Epoch 204, Loss: 0.4368868004619995\n",
      "Epoch 205, Loss: 0.4366217722212388\n",
      "Epoch 206, Loss: 0.4370735508315267\n",
      "Epoch 207, Loss: 0.438056659783102\n",
      "Epoch 208, Loss: 0.43828697608838324\n",
      "Epoch 209, Loss: 0.4380426277456835\n",
      "Epoch 210, Loss: 0.4367571723427673\n",
      "Epoch 211, Loss: 0.4358287121793394\n",
      "Epoch 212, Loss: 0.43549599799409766\n",
      "Epoch 213, Loss: 0.435693177425488\n",
      "Epoch 214, Loss: 0.43638716241086417\n",
      "Epoch 215, Loss: 0.43723040175969713\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20448223307277436\n",
      "Test R^2 score: 0.5458246510467608\n",
      "Num of epochs: 216\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Epoch 179, Loss: 0.44257338842027333\n",
      "Epoch 180, Loss: 0.44223043415311275\n",
      "Epoch 181, Loss: 0.4412573335324542\n",
      "Epoch 182, Loss: 0.4403093939212056\n",
      "Epoch 183, Loss: 0.440210765892682\n",
      "Epoch 184, Loss: 0.4406913267766654\n",
      "Epoch 185, Loss: 0.44119678016972247\n",
      "Epoch 186, Loss: 0.4414768331353019\n",
      "Epoch 187, Loss: 0.44098509893198107\n",
      "Epoch 188, Loss: 0.4399157822542188\n",
      "Epoch 189, Loss: 0.43913002852403843\n",
      "Epoch 190, Loss: 0.43912120575952834\n",
      "Epoch 191, Loss: 0.43958194116248417\n",
      "Epoch 192, Loss: 0.43991779767875194\n",
      "Epoch 193, Loss: 0.4402464762584031\n",
      "Epoch 194, Loss: 0.4397939928277301\n",
      "Epoch 195, Loss: 0.4389848715145781\n",
      "Epoch 196, Loss: 0.43812834372448495\n",
      "Epoch 197, Loss: 0.4378789384628316\n",
      "Epoch 198, Loss: 0.4380569659316353\n",
      "Epoch 199, Loss: 0.4385928231376636\n",
      "Epoch 200, Loss: 0.4396870477941122\n",
      "Epoch 201, Loss: 0.44003322037003134\n",
      "Epoch 202, Loss: 0.4396387344028484\n",
      "Epoch 203, Loss: 0.43797246081508234\n",
      "Epoch 204, Loss: 0.4368868004619995\n",
      "Epoch 205, Loss: 0.4366217722212388\n",
      "Epoch 206, Loss: 0.4370735508315267\n",
      "Epoch 207, Loss: 0.438056659783102\n",
      "Epoch 208, Loss: 0.43828697608838324\n",
      "Epoch 209, Loss: 0.4380426277456835\n",
      "Epoch 210, Loss: 0.4367571723427673\n",
      "Epoch 211, Loss: 0.4358287121793394\n",
      "Epoch 212, Loss: 0.43549599799409766\n",
      "Epoch 213, Loss: 0.435693177425488\n",
      "Epoch 214, Loss: 0.43638716241086417\n",
      "Epoch 215, Loss: 0.43723040175969713\n",
      "Epoch 216, Loss: 0.4381875017781245\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20982564613205582\n",
      "Test R^2 score: 0.5221334340312765\n",
      "Num of epochs: 217\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Epoch 179, Loss: 0.44257338842027333\n",
      "Epoch 180, Loss: 0.44223043415311275\n",
      "Epoch 181, Loss: 0.4412573335324542\n",
      "Epoch 182, Loss: 0.4403093939212056\n",
      "Epoch 183, Loss: 0.440210765892682\n",
      "Epoch 184, Loss: 0.4406913267766654\n",
      "Epoch 185, Loss: 0.44119678016972247\n",
      "Epoch 186, Loss: 0.4414768331353019\n",
      "Epoch 187, Loss: 0.44098509893198107\n",
      "Epoch 188, Loss: 0.4399157822542188\n",
      "Epoch 189, Loss: 0.43913002852403843\n",
      "Epoch 190, Loss: 0.43912120575952834\n",
      "Epoch 191, Loss: 0.43958194116248417\n",
      "Epoch 192, Loss: 0.43991779767875194\n",
      "Epoch 193, Loss: 0.4402464762584031\n",
      "Epoch 194, Loss: 0.4397939928277301\n",
      "Epoch 195, Loss: 0.4389848715145781\n",
      "Epoch 196, Loss: 0.43812834372448495\n",
      "Epoch 197, Loss: 0.4378789384628316\n",
      "Epoch 198, Loss: 0.4380569659316353\n",
      "Epoch 199, Loss: 0.4385928231376636\n",
      "Epoch 200, Loss: 0.4396870477941122\n",
      "Epoch 201, Loss: 0.44003322037003134\n",
      "Epoch 202, Loss: 0.4396387344028484\n",
      "Epoch 203, Loss: 0.43797246081508234\n",
      "Epoch 204, Loss: 0.4368868004619995\n",
      "Epoch 205, Loss: 0.4366217722212388\n",
      "Epoch 206, Loss: 0.4370735508315267\n",
      "Epoch 207, Loss: 0.438056659783102\n",
      "Epoch 208, Loss: 0.43828697608838324\n",
      "Epoch 209, Loss: 0.4380426277456835\n",
      "Epoch 210, Loss: 0.4367571723427673\n",
      "Epoch 211, Loss: 0.4358287121793394\n",
      "Epoch 212, Loss: 0.43549599799409766\n",
      "Epoch 213, Loss: 0.435693177425488\n",
      "Epoch 214, Loss: 0.43638716241086417\n",
      "Epoch 215, Loss: 0.43723040175969713\n",
      "Epoch 216, Loss: 0.4381875017781245\n",
      "Epoch 217, Loss: 0.43727582910411245\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20422748145304306\n",
      "Test R^2 score: 0.5470556398497604\n",
      "Num of epochs: 218\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Epoch 179, Loss: 0.44257338842027333\n",
      "Epoch 180, Loss: 0.44223043415311275\n",
      "Epoch 181, Loss: 0.4412573335324542\n",
      "Epoch 182, Loss: 0.4403093939212056\n",
      "Epoch 183, Loss: 0.440210765892682\n",
      "Epoch 184, Loss: 0.4406913267766654\n",
      "Epoch 185, Loss: 0.44119678016972247\n",
      "Epoch 186, Loss: 0.4414768331353019\n",
      "Epoch 187, Loss: 0.44098509893198107\n",
      "Epoch 188, Loss: 0.4399157822542188\n",
      "Epoch 189, Loss: 0.43913002852403843\n",
      "Epoch 190, Loss: 0.43912120575952834\n",
      "Epoch 191, Loss: 0.43958194116248417\n",
      "Epoch 192, Loss: 0.43991779767875194\n",
      "Epoch 193, Loss: 0.4402464762584031\n",
      "Epoch 194, Loss: 0.4397939928277301\n",
      "Epoch 195, Loss: 0.4389848715145781\n",
      "Epoch 196, Loss: 0.43812834372448495\n",
      "Epoch 197, Loss: 0.4378789384628316\n",
      "Epoch 198, Loss: 0.4380569659316353\n",
      "Epoch 199, Loss: 0.4385928231376636\n",
      "Epoch 200, Loss: 0.4396870477941122\n",
      "Epoch 201, Loss: 0.44003322037003134\n",
      "Epoch 202, Loss: 0.4396387344028484\n",
      "Epoch 203, Loss: 0.43797246081508234\n",
      "Epoch 204, Loss: 0.4368868004619995\n",
      "Epoch 205, Loss: 0.4366217722212388\n",
      "Epoch 206, Loss: 0.4370735508315267\n",
      "Epoch 207, Loss: 0.438056659783102\n",
      "Epoch 208, Loss: 0.43828697608838324\n",
      "Epoch 209, Loss: 0.4380426277456835\n",
      "Epoch 210, Loss: 0.4367571723427673\n",
      "Epoch 211, Loss: 0.4358287121793394\n",
      "Epoch 212, Loss: 0.43549599799409766\n",
      "Epoch 213, Loss: 0.435693177425488\n",
      "Epoch 214, Loss: 0.43638716241086417\n",
      "Epoch 215, Loss: 0.43723040175969713\n",
      "Epoch 216, Loss: 0.4381875017781245\n",
      "Epoch 217, Loss: 0.43727582910411245\n",
      "Epoch 218, Loss: 0.4357251884259994\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2056393395275838\n",
      "Test R^2 score: 0.541157139120488\n",
      "Num of epochs: 219\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Epoch 179, Loss: 0.44257338842027333\n",
      "Epoch 180, Loss: 0.44223043415311275\n",
      "Epoch 181, Loss: 0.4412573335324542\n",
      "Epoch 182, Loss: 0.4403093939212056\n",
      "Epoch 183, Loss: 0.440210765892682\n",
      "Epoch 184, Loss: 0.4406913267766654\n",
      "Epoch 185, Loss: 0.44119678016972247\n",
      "Epoch 186, Loss: 0.4414768331353019\n",
      "Epoch 187, Loss: 0.44098509893198107\n",
      "Epoch 188, Loss: 0.4399157822542188\n",
      "Epoch 189, Loss: 0.43913002852403843\n",
      "Epoch 190, Loss: 0.43912120575952834\n",
      "Epoch 191, Loss: 0.43958194116248417\n",
      "Epoch 192, Loss: 0.43991779767875194\n",
      "Epoch 193, Loss: 0.4402464762584031\n",
      "Epoch 194, Loss: 0.4397939928277301\n",
      "Epoch 195, Loss: 0.4389848715145781\n",
      "Epoch 196, Loss: 0.43812834372448495\n",
      "Epoch 197, Loss: 0.4378789384628316\n",
      "Epoch 198, Loss: 0.4380569659316353\n",
      "Epoch 199, Loss: 0.4385928231376636\n",
      "Epoch 200, Loss: 0.4396870477941122\n",
      "Epoch 201, Loss: 0.44003322037003134\n",
      "Epoch 202, Loss: 0.4396387344028484\n",
      "Epoch 203, Loss: 0.43797246081508234\n",
      "Epoch 204, Loss: 0.4368868004619995\n",
      "Epoch 205, Loss: 0.4366217722212388\n",
      "Epoch 206, Loss: 0.4370735508315267\n",
      "Epoch 207, Loss: 0.438056659783102\n",
      "Epoch 208, Loss: 0.43828697608838324\n",
      "Epoch 209, Loss: 0.4380426277456835\n",
      "Epoch 210, Loss: 0.4367571723427673\n",
      "Epoch 211, Loss: 0.4358287121793394\n",
      "Epoch 212, Loss: 0.43549599799409766\n",
      "Epoch 213, Loss: 0.435693177425488\n",
      "Epoch 214, Loss: 0.43638716241086417\n",
      "Epoch 215, Loss: 0.43723040175969713\n",
      "Epoch 216, Loss: 0.4381875017781245\n",
      "Epoch 217, Loss: 0.43727582910411245\n",
      "Epoch 218, Loss: 0.4357251884259994\n",
      "Epoch 219, Loss: 0.43449740709117174\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2062364600621\n",
      "Test R^2 score: 0.5386439763356874\n",
      "Num of epochs: 220\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Epoch 179, Loss: 0.44257338842027333\n",
      "Epoch 180, Loss: 0.44223043415311275\n",
      "Epoch 181, Loss: 0.4412573335324542\n",
      "Epoch 182, Loss: 0.4403093939212056\n",
      "Epoch 183, Loss: 0.440210765892682\n",
      "Epoch 184, Loss: 0.4406913267766654\n",
      "Epoch 185, Loss: 0.44119678016972247\n",
      "Epoch 186, Loss: 0.4414768331353019\n",
      "Epoch 187, Loss: 0.44098509893198107\n",
      "Epoch 188, Loss: 0.4399157822542188\n",
      "Epoch 189, Loss: 0.43913002852403843\n",
      "Epoch 190, Loss: 0.43912120575952834\n",
      "Epoch 191, Loss: 0.43958194116248417\n",
      "Epoch 192, Loss: 0.43991779767875194\n",
      "Epoch 193, Loss: 0.4402464762584031\n",
      "Epoch 194, Loss: 0.4397939928277301\n",
      "Epoch 195, Loss: 0.4389848715145781\n",
      "Epoch 196, Loss: 0.43812834372448495\n",
      "Epoch 197, Loss: 0.4378789384628316\n",
      "Epoch 198, Loss: 0.4380569659316353\n",
      "Epoch 199, Loss: 0.4385928231376636\n",
      "Epoch 200, Loss: 0.4396870477941122\n",
      "Epoch 201, Loss: 0.44003322037003134\n",
      "Epoch 202, Loss: 0.4396387344028484\n",
      "Epoch 203, Loss: 0.43797246081508234\n",
      "Epoch 204, Loss: 0.4368868004619995\n",
      "Epoch 205, Loss: 0.4366217722212388\n",
      "Epoch 206, Loss: 0.4370735508315267\n",
      "Epoch 207, Loss: 0.438056659783102\n",
      "Epoch 208, Loss: 0.43828697608838324\n",
      "Epoch 209, Loss: 0.4380426277456835\n",
      "Epoch 210, Loss: 0.4367571723427673\n",
      "Epoch 211, Loss: 0.4358287121793394\n",
      "Epoch 212, Loss: 0.43549599799409766\n",
      "Epoch 213, Loss: 0.435693177425488\n",
      "Epoch 214, Loss: 0.43638716241086417\n",
      "Epoch 215, Loss: 0.43723040175969713\n",
      "Epoch 216, Loss: 0.4381875017781245\n",
      "Epoch 217, Loss: 0.43727582910411245\n",
      "Epoch 218, Loss: 0.4357251884259994\n",
      "Epoch 219, Loss: 0.43449740709117174\n",
      "Epoch 220, Loss: 0.4346007775761442\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2042152473081086\n",
      "Test R^2 score: 0.5472598843244323\n",
      "Num of epochs: 221\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Epoch 179, Loss: 0.44257338842027333\n",
      "Epoch 180, Loss: 0.44223043415311275\n",
      "Epoch 181, Loss: 0.4412573335324542\n",
      "Epoch 182, Loss: 0.4403093939212056\n",
      "Epoch 183, Loss: 0.440210765892682\n",
      "Epoch 184, Loss: 0.4406913267766654\n",
      "Epoch 185, Loss: 0.44119678016972247\n",
      "Epoch 186, Loss: 0.4414768331353019\n",
      "Epoch 187, Loss: 0.44098509893198107\n",
      "Epoch 188, Loss: 0.4399157822542188\n",
      "Epoch 189, Loss: 0.43913002852403843\n",
      "Epoch 190, Loss: 0.43912120575952834\n",
      "Epoch 191, Loss: 0.43958194116248417\n",
      "Epoch 192, Loss: 0.43991779767875194\n",
      "Epoch 193, Loss: 0.4402464762584031\n",
      "Epoch 194, Loss: 0.4397939928277301\n",
      "Epoch 195, Loss: 0.4389848715145781\n",
      "Epoch 196, Loss: 0.43812834372448495\n",
      "Epoch 197, Loss: 0.4378789384628316\n",
      "Epoch 198, Loss: 0.4380569659316353\n",
      "Epoch 199, Loss: 0.4385928231376636\n",
      "Epoch 200, Loss: 0.4396870477941122\n",
      "Epoch 201, Loss: 0.44003322037003134\n",
      "Epoch 202, Loss: 0.4396387344028484\n",
      "Epoch 203, Loss: 0.43797246081508234\n",
      "Epoch 204, Loss: 0.4368868004619995\n",
      "Epoch 205, Loss: 0.4366217722212388\n",
      "Epoch 206, Loss: 0.4370735508315267\n",
      "Epoch 207, Loss: 0.438056659783102\n",
      "Epoch 208, Loss: 0.43828697608838324\n",
      "Epoch 209, Loss: 0.4380426277456835\n",
      "Epoch 210, Loss: 0.4367571723427673\n",
      "Epoch 211, Loss: 0.4358287121793394\n",
      "Epoch 212, Loss: 0.43549599799409766\n",
      "Epoch 213, Loss: 0.435693177425488\n",
      "Epoch 214, Loss: 0.43638716241086417\n",
      "Epoch 215, Loss: 0.43723040175969713\n",
      "Epoch 216, Loss: 0.4381875017781245\n",
      "Epoch 217, Loss: 0.43727582910411245\n",
      "Epoch 218, Loss: 0.4357251884259994\n",
      "Epoch 219, Loss: 0.43449740709117174\n",
      "Epoch 220, Loss: 0.4346007775761442\n",
      "Epoch 221, Loss: 0.4356339371912412\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21021496409555454\n",
      "Test R^2 score: 0.5205084621351009\n",
      "Num of epochs: 222\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Epoch 179, Loss: 0.44257338842027333\n",
      "Epoch 180, Loss: 0.44223043415311275\n",
      "Epoch 181, Loss: 0.4412573335324542\n",
      "Epoch 182, Loss: 0.4403093939212056\n",
      "Epoch 183, Loss: 0.440210765892682\n",
      "Epoch 184, Loss: 0.4406913267766654\n",
      "Epoch 185, Loss: 0.44119678016972247\n",
      "Epoch 186, Loss: 0.4414768331353019\n",
      "Epoch 187, Loss: 0.44098509893198107\n",
      "Epoch 188, Loss: 0.4399157822542188\n",
      "Epoch 189, Loss: 0.43913002852403843\n",
      "Epoch 190, Loss: 0.43912120575952834\n",
      "Epoch 191, Loss: 0.43958194116248417\n",
      "Epoch 192, Loss: 0.43991779767875194\n",
      "Epoch 193, Loss: 0.4402464762584031\n",
      "Epoch 194, Loss: 0.4397939928277301\n",
      "Epoch 195, Loss: 0.4389848715145781\n",
      "Epoch 196, Loss: 0.43812834372448495\n",
      "Epoch 197, Loss: 0.4378789384628316\n",
      "Epoch 198, Loss: 0.4380569659316353\n",
      "Epoch 199, Loss: 0.4385928231376636\n",
      "Epoch 200, Loss: 0.4396870477941122\n",
      "Epoch 201, Loss: 0.44003322037003134\n",
      "Epoch 202, Loss: 0.4396387344028484\n",
      "Epoch 203, Loss: 0.43797246081508234\n",
      "Epoch 204, Loss: 0.4368868004619995\n",
      "Epoch 205, Loss: 0.4366217722212388\n",
      "Epoch 206, Loss: 0.4370735508315267\n",
      "Epoch 207, Loss: 0.438056659783102\n",
      "Epoch 208, Loss: 0.43828697608838324\n",
      "Epoch 209, Loss: 0.4380426277456835\n",
      "Epoch 210, Loss: 0.4367571723427673\n",
      "Epoch 211, Loss: 0.4358287121793394\n",
      "Epoch 212, Loss: 0.43549599799409766\n",
      "Epoch 213, Loss: 0.435693177425488\n",
      "Epoch 214, Loss: 0.43638716241086417\n",
      "Epoch 215, Loss: 0.43723040175969713\n",
      "Epoch 216, Loss: 0.4381875017781245\n",
      "Epoch 217, Loss: 0.43727582910411245\n",
      "Epoch 218, Loss: 0.4357251884259994\n",
      "Epoch 219, Loss: 0.43449740709117174\n",
      "Epoch 220, Loss: 0.4346007775761442\n",
      "Epoch 221, Loss: 0.4356339371912412\n",
      "Epoch 222, Loss: 0.43683657413065485\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2048163729689204\n",
      "Test R^2 score: 0.5441598848374121\n",
      "Num of epochs: 223\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Epoch 179, Loss: 0.44257338842027333\n",
      "Epoch 180, Loss: 0.44223043415311275\n",
      "Epoch 181, Loss: 0.4412573335324542\n",
      "Epoch 182, Loss: 0.4403093939212056\n",
      "Epoch 183, Loss: 0.440210765892682\n",
      "Epoch 184, Loss: 0.4406913267766654\n",
      "Epoch 185, Loss: 0.44119678016972247\n",
      "Epoch 186, Loss: 0.4414768331353019\n",
      "Epoch 187, Loss: 0.44098509893198107\n",
      "Epoch 188, Loss: 0.4399157822542188\n",
      "Epoch 189, Loss: 0.43913002852403843\n",
      "Epoch 190, Loss: 0.43912120575952834\n",
      "Epoch 191, Loss: 0.43958194116248417\n",
      "Epoch 192, Loss: 0.43991779767875194\n",
      "Epoch 193, Loss: 0.4402464762584031\n",
      "Epoch 194, Loss: 0.4397939928277301\n",
      "Epoch 195, Loss: 0.4389848715145781\n",
      "Epoch 196, Loss: 0.43812834372448495\n",
      "Epoch 197, Loss: 0.4378789384628316\n",
      "Epoch 198, Loss: 0.4380569659316353\n",
      "Epoch 199, Loss: 0.4385928231376636\n",
      "Epoch 200, Loss: 0.4396870477941122\n",
      "Epoch 201, Loss: 0.44003322037003134\n",
      "Epoch 202, Loss: 0.4396387344028484\n",
      "Epoch 203, Loss: 0.43797246081508234\n",
      "Epoch 204, Loss: 0.4368868004619995\n",
      "Epoch 205, Loss: 0.4366217722212388\n",
      "Epoch 206, Loss: 0.4370735508315267\n",
      "Epoch 207, Loss: 0.438056659783102\n",
      "Epoch 208, Loss: 0.43828697608838324\n",
      "Epoch 209, Loss: 0.4380426277456835\n",
      "Epoch 210, Loss: 0.4367571723427673\n",
      "Epoch 211, Loss: 0.4358287121793394\n",
      "Epoch 212, Loss: 0.43549599799409766\n",
      "Epoch 213, Loss: 0.435693177425488\n",
      "Epoch 214, Loss: 0.43638716241086417\n",
      "Epoch 215, Loss: 0.43723040175969713\n",
      "Epoch 216, Loss: 0.4381875017781245\n",
      "Epoch 217, Loss: 0.43727582910411245\n",
      "Epoch 218, Loss: 0.4357251884259994\n",
      "Epoch 219, Loss: 0.43449740709117174\n",
      "Epoch 220, Loss: 0.4346007775761442\n",
      "Epoch 221, Loss: 0.4356339371912412\n",
      "Epoch 222, Loss: 0.43683657413065485\n",
      "Epoch 223, Loss: 0.43732786198111706\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2082680635569449\n",
      "Test R^2 score: 0.5291940166165449\n",
      "Num of epochs: 224\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Epoch 179, Loss: 0.44257338842027333\n",
      "Epoch 180, Loss: 0.44223043415311275\n",
      "Epoch 181, Loss: 0.4412573335324542\n",
      "Epoch 182, Loss: 0.4403093939212056\n",
      "Epoch 183, Loss: 0.440210765892682\n",
      "Epoch 184, Loss: 0.4406913267766654\n",
      "Epoch 185, Loss: 0.44119678016972247\n",
      "Epoch 186, Loss: 0.4414768331353019\n",
      "Epoch 187, Loss: 0.44098509893198107\n",
      "Epoch 188, Loss: 0.4399157822542188\n",
      "Epoch 189, Loss: 0.43913002852403843\n",
      "Epoch 190, Loss: 0.43912120575952834\n",
      "Epoch 191, Loss: 0.43958194116248417\n",
      "Epoch 192, Loss: 0.43991779767875194\n",
      "Epoch 193, Loss: 0.4402464762584031\n",
      "Epoch 194, Loss: 0.4397939928277301\n",
      "Epoch 195, Loss: 0.4389848715145781\n",
      "Epoch 196, Loss: 0.43812834372448495\n",
      "Epoch 197, Loss: 0.4378789384628316\n",
      "Epoch 198, Loss: 0.4380569659316353\n",
      "Epoch 199, Loss: 0.4385928231376636\n",
      "Epoch 200, Loss: 0.4396870477941122\n",
      "Epoch 201, Loss: 0.44003322037003134\n",
      "Epoch 202, Loss: 0.4396387344028484\n",
      "Epoch 203, Loss: 0.43797246081508234\n",
      "Epoch 204, Loss: 0.4368868004619995\n",
      "Epoch 205, Loss: 0.4366217722212388\n",
      "Epoch 206, Loss: 0.4370735508315267\n",
      "Epoch 207, Loss: 0.438056659783102\n",
      "Epoch 208, Loss: 0.43828697608838324\n",
      "Epoch 209, Loss: 0.4380426277456835\n",
      "Epoch 210, Loss: 0.4367571723427673\n",
      "Epoch 211, Loss: 0.4358287121793394\n",
      "Epoch 212, Loss: 0.43549599799409766\n",
      "Epoch 213, Loss: 0.435693177425488\n",
      "Epoch 214, Loss: 0.43638716241086417\n",
      "Epoch 215, Loss: 0.43723040175969713\n",
      "Epoch 216, Loss: 0.4381875017781245\n",
      "Epoch 217, Loss: 0.43727582910411245\n",
      "Epoch 218, Loss: 0.4357251884259994\n",
      "Epoch 219, Loss: 0.43449740709117174\n",
      "Epoch 220, Loss: 0.4346007775761442\n",
      "Epoch 221, Loss: 0.4356339371912412\n",
      "Epoch 222, Loss: 0.43683657413065485\n",
      "Epoch 223, Loss: 0.43732786198111706\n",
      "Epoch 224, Loss: 0.43504045750484316\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20500380511232885\n",
      "Test R^2 score: 0.5438724428491786\n",
      "Num of epochs: 225\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Epoch 179, Loss: 0.44257338842027333\n",
      "Epoch 180, Loss: 0.44223043415311275\n",
      "Epoch 181, Loss: 0.4412573335324542\n",
      "Epoch 182, Loss: 0.4403093939212056\n",
      "Epoch 183, Loss: 0.440210765892682\n",
      "Epoch 184, Loss: 0.4406913267766654\n",
      "Epoch 185, Loss: 0.44119678016972247\n",
      "Epoch 186, Loss: 0.4414768331353019\n",
      "Epoch 187, Loss: 0.44098509893198107\n",
      "Epoch 188, Loss: 0.4399157822542188\n",
      "Epoch 189, Loss: 0.43913002852403843\n",
      "Epoch 190, Loss: 0.43912120575952834\n",
      "Epoch 191, Loss: 0.43958194116248417\n",
      "Epoch 192, Loss: 0.43991779767875194\n",
      "Epoch 193, Loss: 0.4402464762584031\n",
      "Epoch 194, Loss: 0.4397939928277301\n",
      "Epoch 195, Loss: 0.4389848715145781\n",
      "Epoch 196, Loss: 0.43812834372448495\n",
      "Epoch 197, Loss: 0.4378789384628316\n",
      "Epoch 198, Loss: 0.4380569659316353\n",
      "Epoch 199, Loss: 0.4385928231376636\n",
      "Epoch 200, Loss: 0.4396870477941122\n",
      "Epoch 201, Loss: 0.44003322037003134\n",
      "Epoch 202, Loss: 0.4396387344028484\n",
      "Epoch 203, Loss: 0.43797246081508234\n",
      "Epoch 204, Loss: 0.4368868004619995\n",
      "Epoch 205, Loss: 0.4366217722212388\n",
      "Epoch 206, Loss: 0.4370735508315267\n",
      "Epoch 207, Loss: 0.438056659783102\n",
      "Epoch 208, Loss: 0.43828697608838324\n",
      "Epoch 209, Loss: 0.4380426277456835\n",
      "Epoch 210, Loss: 0.4367571723427673\n",
      "Epoch 211, Loss: 0.4358287121793394\n",
      "Epoch 212, Loss: 0.43549599799409766\n",
      "Epoch 213, Loss: 0.435693177425488\n",
      "Epoch 214, Loss: 0.43638716241086417\n",
      "Epoch 215, Loss: 0.43723040175969713\n",
      "Epoch 216, Loss: 0.4381875017781245\n",
      "Epoch 217, Loss: 0.43727582910411245\n",
      "Epoch 218, Loss: 0.4357251884259994\n",
      "Epoch 219, Loss: 0.43449740709117174\n",
      "Epoch 220, Loss: 0.4346007775761442\n",
      "Epoch 221, Loss: 0.4356339371912412\n",
      "Epoch 222, Loss: 0.43683657413065485\n",
      "Epoch 223, Loss: 0.43732786198111706\n",
      "Epoch 224, Loss: 0.43504045750484316\n",
      "Epoch 225, Loss: 0.4336674601818588\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20451556057670545\n",
      "Test R^2 score: 0.5460532609969689\n",
      "Num of epochs: 226\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Epoch 179, Loss: 0.44257338842027333\n",
      "Epoch 180, Loss: 0.44223043415311275\n",
      "Epoch 181, Loss: 0.4412573335324542\n",
      "Epoch 182, Loss: 0.4403093939212056\n",
      "Epoch 183, Loss: 0.440210765892682\n",
      "Epoch 184, Loss: 0.4406913267766654\n",
      "Epoch 185, Loss: 0.44119678016972247\n",
      "Epoch 186, Loss: 0.4414768331353019\n",
      "Epoch 187, Loss: 0.44098509893198107\n",
      "Epoch 188, Loss: 0.4399157822542188\n",
      "Epoch 189, Loss: 0.43913002852403843\n",
      "Epoch 190, Loss: 0.43912120575952834\n",
      "Epoch 191, Loss: 0.43958194116248417\n",
      "Epoch 192, Loss: 0.43991779767875194\n",
      "Epoch 193, Loss: 0.4402464762584031\n",
      "Epoch 194, Loss: 0.4397939928277301\n",
      "Epoch 195, Loss: 0.4389848715145781\n",
      "Epoch 196, Loss: 0.43812834372448495\n",
      "Epoch 197, Loss: 0.4378789384628316\n",
      "Epoch 198, Loss: 0.4380569659316353\n",
      "Epoch 199, Loss: 0.4385928231376636\n",
      "Epoch 200, Loss: 0.4396870477941122\n",
      "Epoch 201, Loss: 0.44003322037003134\n",
      "Epoch 202, Loss: 0.4396387344028484\n",
      "Epoch 203, Loss: 0.43797246081508234\n",
      "Epoch 204, Loss: 0.4368868004619995\n",
      "Epoch 205, Loss: 0.4366217722212388\n",
      "Epoch 206, Loss: 0.4370735508315267\n",
      "Epoch 207, Loss: 0.438056659783102\n",
      "Epoch 208, Loss: 0.43828697608838324\n",
      "Epoch 209, Loss: 0.4380426277456835\n",
      "Epoch 210, Loss: 0.4367571723427673\n",
      "Epoch 211, Loss: 0.4358287121793394\n",
      "Epoch 212, Loss: 0.43549599799409766\n",
      "Epoch 213, Loss: 0.435693177425488\n",
      "Epoch 214, Loss: 0.43638716241086417\n",
      "Epoch 215, Loss: 0.43723040175969713\n",
      "Epoch 216, Loss: 0.4381875017781245\n",
      "Epoch 217, Loss: 0.43727582910411245\n",
      "Epoch 218, Loss: 0.4357251884259994\n",
      "Epoch 219, Loss: 0.43449740709117174\n",
      "Epoch 220, Loss: 0.4346007775761442\n",
      "Epoch 221, Loss: 0.4356339371912412\n",
      "Epoch 222, Loss: 0.43683657413065485\n",
      "Epoch 223, Loss: 0.43732786198111706\n",
      "Epoch 224, Loss: 0.43504045750484316\n",
      "Epoch 225, Loss: 0.4336674601818588\n",
      "Epoch 226, Loss: 0.4339570078903568\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20933659092624132\n",
      "Test R^2 score: 0.5246048754302343\n",
      "Num of epochs: 227\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Epoch 179, Loss: 0.44257338842027333\n",
      "Epoch 180, Loss: 0.44223043415311275\n",
      "Epoch 181, Loss: 0.4412573335324542\n",
      "Epoch 182, Loss: 0.4403093939212056\n",
      "Epoch 183, Loss: 0.440210765892682\n",
      "Epoch 184, Loss: 0.4406913267766654\n",
      "Epoch 185, Loss: 0.44119678016972247\n",
      "Epoch 186, Loss: 0.4414768331353019\n",
      "Epoch 187, Loss: 0.44098509893198107\n",
      "Epoch 188, Loss: 0.4399157822542188\n",
      "Epoch 189, Loss: 0.43913002852403843\n",
      "Epoch 190, Loss: 0.43912120575952834\n",
      "Epoch 191, Loss: 0.43958194116248417\n",
      "Epoch 192, Loss: 0.43991779767875194\n",
      "Epoch 193, Loss: 0.4402464762584031\n",
      "Epoch 194, Loss: 0.4397939928277301\n",
      "Epoch 195, Loss: 0.4389848715145781\n",
      "Epoch 196, Loss: 0.43812834372448495\n",
      "Epoch 197, Loss: 0.4378789384628316\n",
      "Epoch 198, Loss: 0.4380569659316353\n",
      "Epoch 199, Loss: 0.4385928231376636\n",
      "Epoch 200, Loss: 0.4396870477941122\n",
      "Epoch 201, Loss: 0.44003322037003134\n",
      "Epoch 202, Loss: 0.4396387344028484\n",
      "Epoch 203, Loss: 0.43797246081508234\n",
      "Epoch 204, Loss: 0.4368868004619995\n",
      "Epoch 205, Loss: 0.4366217722212388\n",
      "Epoch 206, Loss: 0.4370735508315267\n",
      "Epoch 207, Loss: 0.438056659783102\n",
      "Epoch 208, Loss: 0.43828697608838324\n",
      "Epoch 209, Loss: 0.4380426277456835\n",
      "Epoch 210, Loss: 0.4367571723427673\n",
      "Epoch 211, Loss: 0.4358287121793394\n",
      "Epoch 212, Loss: 0.43549599799409766\n",
      "Epoch 213, Loss: 0.435693177425488\n",
      "Epoch 214, Loss: 0.43638716241086417\n",
      "Epoch 215, Loss: 0.43723040175969713\n",
      "Epoch 216, Loss: 0.4381875017781245\n",
      "Epoch 217, Loss: 0.43727582910411245\n",
      "Epoch 218, Loss: 0.4357251884259994\n",
      "Epoch 219, Loss: 0.43449740709117174\n",
      "Epoch 220, Loss: 0.4346007775761442\n",
      "Epoch 221, Loss: 0.4356339371912412\n",
      "Epoch 222, Loss: 0.43683657413065485\n",
      "Epoch 223, Loss: 0.43732786198111706\n",
      "Epoch 224, Loss: 0.43504045750484316\n",
      "Epoch 225, Loss: 0.4336674601818588\n",
      "Epoch 226, Loss: 0.4339570078903568\n",
      "Epoch 227, Loss: 0.43524205442250136\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20519289144770753\n",
      "Test R^2 score: 0.5424777567759411\n",
      "Num of epochs: 228\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Epoch 179, Loss: 0.44257338842027333\n",
      "Epoch 180, Loss: 0.44223043415311275\n",
      "Epoch 181, Loss: 0.4412573335324542\n",
      "Epoch 182, Loss: 0.4403093939212056\n",
      "Epoch 183, Loss: 0.440210765892682\n",
      "Epoch 184, Loss: 0.4406913267766654\n",
      "Epoch 185, Loss: 0.44119678016972247\n",
      "Epoch 186, Loss: 0.4414768331353019\n",
      "Epoch 187, Loss: 0.44098509893198107\n",
      "Epoch 188, Loss: 0.4399157822542188\n",
      "Epoch 189, Loss: 0.43913002852403843\n",
      "Epoch 190, Loss: 0.43912120575952834\n",
      "Epoch 191, Loss: 0.43958194116248417\n",
      "Epoch 192, Loss: 0.43991779767875194\n",
      "Epoch 193, Loss: 0.4402464762584031\n",
      "Epoch 194, Loss: 0.4397939928277301\n",
      "Epoch 195, Loss: 0.4389848715145781\n",
      "Epoch 196, Loss: 0.43812834372448495\n",
      "Epoch 197, Loss: 0.4378789384628316\n",
      "Epoch 198, Loss: 0.4380569659316353\n",
      "Epoch 199, Loss: 0.4385928231376636\n",
      "Epoch 200, Loss: 0.4396870477941122\n",
      "Epoch 201, Loss: 0.44003322037003134\n",
      "Epoch 202, Loss: 0.4396387344028484\n",
      "Epoch 203, Loss: 0.43797246081508234\n",
      "Epoch 204, Loss: 0.4368868004619995\n",
      "Epoch 205, Loss: 0.4366217722212388\n",
      "Epoch 206, Loss: 0.4370735508315267\n",
      "Epoch 207, Loss: 0.438056659783102\n",
      "Epoch 208, Loss: 0.43828697608838324\n",
      "Epoch 209, Loss: 0.4380426277456835\n",
      "Epoch 210, Loss: 0.4367571723427673\n",
      "Epoch 211, Loss: 0.4358287121793394\n",
      "Epoch 212, Loss: 0.43549599799409766\n",
      "Epoch 213, Loss: 0.435693177425488\n",
      "Epoch 214, Loss: 0.43638716241086417\n",
      "Epoch 215, Loss: 0.43723040175969713\n",
      "Epoch 216, Loss: 0.4381875017781245\n",
      "Epoch 217, Loss: 0.43727582910411245\n",
      "Epoch 218, Loss: 0.4357251884259994\n",
      "Epoch 219, Loss: 0.43449740709117174\n",
      "Epoch 220, Loss: 0.4346007775761442\n",
      "Epoch 221, Loss: 0.4356339371912412\n",
      "Epoch 222, Loss: 0.43683657413065485\n",
      "Epoch 223, Loss: 0.43732786198111706\n",
      "Epoch 224, Loss: 0.43504045750484316\n",
      "Epoch 225, Loss: 0.4336674601818588\n",
      "Epoch 226, Loss: 0.4339570078903568\n",
      "Epoch 227, Loss: 0.43524205442250136\n",
      "Epoch 228, Loss: 0.43692856322479845\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21076626965982437\n",
      "Test R^2 score: 0.5178540930638673\n",
      "Num of epochs: 229\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Epoch 179, Loss: 0.44257338842027333\n",
      "Epoch 180, Loss: 0.44223043415311275\n",
      "Epoch 181, Loss: 0.4412573335324542\n",
      "Epoch 182, Loss: 0.4403093939212056\n",
      "Epoch 183, Loss: 0.440210765892682\n",
      "Epoch 184, Loss: 0.4406913267766654\n",
      "Epoch 185, Loss: 0.44119678016972247\n",
      "Epoch 186, Loss: 0.4414768331353019\n",
      "Epoch 187, Loss: 0.44098509893198107\n",
      "Epoch 188, Loss: 0.4399157822542188\n",
      "Epoch 189, Loss: 0.43913002852403843\n",
      "Epoch 190, Loss: 0.43912120575952834\n",
      "Epoch 191, Loss: 0.43958194116248417\n",
      "Epoch 192, Loss: 0.43991779767875194\n",
      "Epoch 193, Loss: 0.4402464762584031\n",
      "Epoch 194, Loss: 0.4397939928277301\n",
      "Epoch 195, Loss: 0.4389848715145781\n",
      "Epoch 196, Loss: 0.43812834372448495\n",
      "Epoch 197, Loss: 0.4378789384628316\n",
      "Epoch 198, Loss: 0.4380569659316353\n",
      "Epoch 199, Loss: 0.4385928231376636\n",
      "Epoch 200, Loss: 0.4396870477941122\n",
      "Epoch 201, Loss: 0.44003322037003134\n",
      "Epoch 202, Loss: 0.4396387344028484\n",
      "Epoch 203, Loss: 0.43797246081508234\n",
      "Epoch 204, Loss: 0.4368868004619995\n",
      "Epoch 205, Loss: 0.4366217722212388\n",
      "Epoch 206, Loss: 0.4370735508315267\n",
      "Epoch 207, Loss: 0.438056659783102\n",
      "Epoch 208, Loss: 0.43828697608838324\n",
      "Epoch 209, Loss: 0.4380426277456835\n",
      "Epoch 210, Loss: 0.4367571723427673\n",
      "Epoch 211, Loss: 0.4358287121793394\n",
      "Epoch 212, Loss: 0.43549599799409766\n",
      "Epoch 213, Loss: 0.435693177425488\n",
      "Epoch 214, Loss: 0.43638716241086417\n",
      "Epoch 215, Loss: 0.43723040175969713\n",
      "Epoch 216, Loss: 0.4381875017781245\n",
      "Epoch 217, Loss: 0.43727582910411245\n",
      "Epoch 218, Loss: 0.4357251884259994\n",
      "Epoch 219, Loss: 0.43449740709117174\n",
      "Epoch 220, Loss: 0.4346007775761442\n",
      "Epoch 221, Loss: 0.4356339371912412\n",
      "Epoch 222, Loss: 0.43683657413065485\n",
      "Epoch 223, Loss: 0.43732786198111706\n",
      "Epoch 224, Loss: 0.43504045750484316\n",
      "Epoch 225, Loss: 0.4336674601818588\n",
      "Epoch 226, Loss: 0.4339570078903568\n",
      "Epoch 227, Loss: 0.43524205442250136\n",
      "Epoch 228, Loss: 0.43692856322479845\n",
      "Epoch 229, Loss: 0.4361014833656456\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20462593526023246\n",
      "Test R^2 score: 0.5451630235916567\n",
      "Num of epochs: 230\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Epoch 179, Loss: 0.44257338842027333\n",
      "Epoch 180, Loss: 0.44223043415311275\n",
      "Epoch 181, Loss: 0.4412573335324542\n",
      "Epoch 182, Loss: 0.4403093939212056\n",
      "Epoch 183, Loss: 0.440210765892682\n",
      "Epoch 184, Loss: 0.4406913267766654\n",
      "Epoch 185, Loss: 0.44119678016972247\n",
      "Epoch 186, Loss: 0.4414768331353019\n",
      "Epoch 187, Loss: 0.44098509893198107\n",
      "Epoch 188, Loss: 0.4399157822542188\n",
      "Epoch 189, Loss: 0.43913002852403843\n",
      "Epoch 190, Loss: 0.43912120575952834\n",
      "Epoch 191, Loss: 0.43958194116248417\n",
      "Epoch 192, Loss: 0.43991779767875194\n",
      "Epoch 193, Loss: 0.4402464762584031\n",
      "Epoch 194, Loss: 0.4397939928277301\n",
      "Epoch 195, Loss: 0.4389848715145781\n",
      "Epoch 196, Loss: 0.43812834372448495\n",
      "Epoch 197, Loss: 0.4378789384628316\n",
      "Epoch 198, Loss: 0.4380569659316353\n",
      "Epoch 199, Loss: 0.4385928231376636\n",
      "Epoch 200, Loss: 0.4396870477941122\n",
      "Epoch 201, Loss: 0.44003322037003134\n",
      "Epoch 202, Loss: 0.4396387344028484\n",
      "Epoch 203, Loss: 0.43797246081508234\n",
      "Epoch 204, Loss: 0.4368868004619995\n",
      "Epoch 205, Loss: 0.4366217722212388\n",
      "Epoch 206, Loss: 0.4370735508315267\n",
      "Epoch 207, Loss: 0.438056659783102\n",
      "Epoch 208, Loss: 0.43828697608838324\n",
      "Epoch 209, Loss: 0.4380426277456835\n",
      "Epoch 210, Loss: 0.4367571723427673\n",
      "Epoch 211, Loss: 0.4358287121793394\n",
      "Epoch 212, Loss: 0.43549599799409766\n",
      "Epoch 213, Loss: 0.435693177425488\n",
      "Epoch 214, Loss: 0.43638716241086417\n",
      "Epoch 215, Loss: 0.43723040175969713\n",
      "Epoch 216, Loss: 0.4381875017781245\n",
      "Epoch 217, Loss: 0.43727582910411245\n",
      "Epoch 218, Loss: 0.4357251884259994\n",
      "Epoch 219, Loss: 0.43449740709117174\n",
      "Epoch 220, Loss: 0.4346007775761442\n",
      "Epoch 221, Loss: 0.4356339371912412\n",
      "Epoch 222, Loss: 0.43683657413065485\n",
      "Epoch 223, Loss: 0.43732786198111706\n",
      "Epoch 224, Loss: 0.43504045750484316\n",
      "Epoch 225, Loss: 0.4336674601818588\n",
      "Epoch 226, Loss: 0.4339570078903568\n",
      "Epoch 227, Loss: 0.43524205442250136\n",
      "Epoch 228, Loss: 0.43692856322479845\n",
      "Epoch 229, Loss: 0.4361014833656456\n",
      "Epoch 230, Loss: 0.43400818547427195\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20515564849360876\n",
      "Test R^2 score: 0.543254370671176\n",
      "Num of epochs: 231\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Epoch 179, Loss: 0.44257338842027333\n",
      "Epoch 180, Loss: 0.44223043415311275\n",
      "Epoch 181, Loss: 0.4412573335324542\n",
      "Epoch 182, Loss: 0.4403093939212056\n",
      "Epoch 183, Loss: 0.440210765892682\n",
      "Epoch 184, Loss: 0.4406913267766654\n",
      "Epoch 185, Loss: 0.44119678016972247\n",
      "Epoch 186, Loss: 0.4414768331353019\n",
      "Epoch 187, Loss: 0.44098509893198107\n",
      "Epoch 188, Loss: 0.4399157822542188\n",
      "Epoch 189, Loss: 0.43913002852403843\n",
      "Epoch 190, Loss: 0.43912120575952834\n",
      "Epoch 191, Loss: 0.43958194116248417\n",
      "Epoch 192, Loss: 0.43991779767875194\n",
      "Epoch 193, Loss: 0.4402464762584031\n",
      "Epoch 194, Loss: 0.4397939928277301\n",
      "Epoch 195, Loss: 0.4389848715145781\n",
      "Epoch 196, Loss: 0.43812834372448495\n",
      "Epoch 197, Loss: 0.4378789384628316\n",
      "Epoch 198, Loss: 0.4380569659316353\n",
      "Epoch 199, Loss: 0.4385928231376636\n",
      "Epoch 200, Loss: 0.4396870477941122\n",
      "Epoch 201, Loss: 0.44003322037003134\n",
      "Epoch 202, Loss: 0.4396387344028484\n",
      "Epoch 203, Loss: 0.43797246081508234\n",
      "Epoch 204, Loss: 0.4368868004619995\n",
      "Epoch 205, Loss: 0.4366217722212388\n",
      "Epoch 206, Loss: 0.4370735508315267\n",
      "Epoch 207, Loss: 0.438056659783102\n",
      "Epoch 208, Loss: 0.43828697608838324\n",
      "Epoch 209, Loss: 0.4380426277456835\n",
      "Epoch 210, Loss: 0.4367571723427673\n",
      "Epoch 211, Loss: 0.4358287121793394\n",
      "Epoch 212, Loss: 0.43549599799409766\n",
      "Epoch 213, Loss: 0.435693177425488\n",
      "Epoch 214, Loss: 0.43638716241086417\n",
      "Epoch 215, Loss: 0.43723040175969713\n",
      "Epoch 216, Loss: 0.4381875017781245\n",
      "Epoch 217, Loss: 0.43727582910411245\n",
      "Epoch 218, Loss: 0.4357251884259994\n",
      "Epoch 219, Loss: 0.43449740709117174\n",
      "Epoch 220, Loss: 0.4346007775761442\n",
      "Epoch 221, Loss: 0.4356339371912412\n",
      "Epoch 222, Loss: 0.43683657413065485\n",
      "Epoch 223, Loss: 0.43732786198111706\n",
      "Epoch 224, Loss: 0.43504045750484316\n",
      "Epoch 225, Loss: 0.4336674601818588\n",
      "Epoch 226, Loss: 0.4339570078903568\n",
      "Epoch 227, Loss: 0.43524205442250136\n",
      "Epoch 228, Loss: 0.43692856322479845\n",
      "Epoch 229, Loss: 0.4361014833656456\n",
      "Epoch 230, Loss: 0.43400818547427195\n",
      "Epoch 231, Loss: 0.43282550764678196\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2085659578345636\n",
      "Test R^2 score: 0.5281880629049286\n",
      "Num of epochs: 232\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Epoch 179, Loss: 0.44257338842027333\n",
      "Epoch 180, Loss: 0.44223043415311275\n",
      "Epoch 181, Loss: 0.4412573335324542\n",
      "Epoch 182, Loss: 0.4403093939212056\n",
      "Epoch 183, Loss: 0.440210765892682\n",
      "Epoch 184, Loss: 0.4406913267766654\n",
      "Epoch 185, Loss: 0.44119678016972247\n",
      "Epoch 186, Loss: 0.4414768331353019\n",
      "Epoch 187, Loss: 0.44098509893198107\n",
      "Epoch 188, Loss: 0.4399157822542188\n",
      "Epoch 189, Loss: 0.43913002852403843\n",
      "Epoch 190, Loss: 0.43912120575952834\n",
      "Epoch 191, Loss: 0.43958194116248417\n",
      "Epoch 192, Loss: 0.43991779767875194\n",
      "Epoch 193, Loss: 0.4402464762584031\n",
      "Epoch 194, Loss: 0.4397939928277301\n",
      "Epoch 195, Loss: 0.4389848715145781\n",
      "Epoch 196, Loss: 0.43812834372448495\n",
      "Epoch 197, Loss: 0.4378789384628316\n",
      "Epoch 198, Loss: 0.4380569659316353\n",
      "Epoch 199, Loss: 0.4385928231376636\n",
      "Epoch 200, Loss: 0.4396870477941122\n",
      "Epoch 201, Loss: 0.44003322037003134\n",
      "Epoch 202, Loss: 0.4396387344028484\n",
      "Epoch 203, Loss: 0.43797246081508234\n",
      "Epoch 204, Loss: 0.4368868004619995\n",
      "Epoch 205, Loss: 0.4366217722212388\n",
      "Epoch 206, Loss: 0.4370735508315267\n",
      "Epoch 207, Loss: 0.438056659783102\n",
      "Epoch 208, Loss: 0.43828697608838324\n",
      "Epoch 209, Loss: 0.4380426277456835\n",
      "Epoch 210, Loss: 0.4367571723427673\n",
      "Epoch 211, Loss: 0.4358287121793394\n",
      "Epoch 212, Loss: 0.43549599799409766\n",
      "Epoch 213, Loss: 0.435693177425488\n",
      "Epoch 214, Loss: 0.43638716241086417\n",
      "Epoch 215, Loss: 0.43723040175969713\n",
      "Epoch 216, Loss: 0.4381875017781245\n",
      "Epoch 217, Loss: 0.43727582910411245\n",
      "Epoch 218, Loss: 0.4357251884259994\n",
      "Epoch 219, Loss: 0.43449740709117174\n",
      "Epoch 220, Loss: 0.4346007775761442\n",
      "Epoch 221, Loss: 0.4356339371912412\n",
      "Epoch 222, Loss: 0.43683657413065485\n",
      "Epoch 223, Loss: 0.43732786198111706\n",
      "Epoch 224, Loss: 0.43504045750484316\n",
      "Epoch 225, Loss: 0.4336674601818588\n",
      "Epoch 226, Loss: 0.4339570078903568\n",
      "Epoch 227, Loss: 0.43524205442250136\n",
      "Epoch 228, Loss: 0.43692856322479845\n",
      "Epoch 229, Loss: 0.4361014833656456\n",
      "Epoch 230, Loss: 0.43400818547427195\n",
      "Epoch 231, Loss: 0.43282550764678196\n",
      "Epoch 232, Loss: 0.43422302771098475\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20486822755305423\n",
      "Test R^2 score: 0.5440732252517186\n",
      "Num of epochs: 233\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Epoch 179, Loss: 0.44257338842027333\n",
      "Epoch 180, Loss: 0.44223043415311275\n",
      "Epoch 181, Loss: 0.4412573335324542\n",
      "Epoch 182, Loss: 0.4403093939212056\n",
      "Epoch 183, Loss: 0.440210765892682\n",
      "Epoch 184, Loss: 0.4406913267766654\n",
      "Epoch 185, Loss: 0.44119678016972247\n",
      "Epoch 186, Loss: 0.4414768331353019\n",
      "Epoch 187, Loss: 0.44098509893198107\n",
      "Epoch 188, Loss: 0.4399157822542188\n",
      "Epoch 189, Loss: 0.43913002852403843\n",
      "Epoch 190, Loss: 0.43912120575952834\n",
      "Epoch 191, Loss: 0.43958194116248417\n",
      "Epoch 192, Loss: 0.43991779767875194\n",
      "Epoch 193, Loss: 0.4402464762584031\n",
      "Epoch 194, Loss: 0.4397939928277301\n",
      "Epoch 195, Loss: 0.4389848715145781\n",
      "Epoch 196, Loss: 0.43812834372448495\n",
      "Epoch 197, Loss: 0.4378789384628316\n",
      "Epoch 198, Loss: 0.4380569659316353\n",
      "Epoch 199, Loss: 0.4385928231376636\n",
      "Epoch 200, Loss: 0.4396870477941122\n",
      "Epoch 201, Loss: 0.44003322037003134\n",
      "Epoch 202, Loss: 0.4396387344028484\n",
      "Epoch 203, Loss: 0.43797246081508234\n",
      "Epoch 204, Loss: 0.4368868004619995\n",
      "Epoch 205, Loss: 0.4366217722212388\n",
      "Epoch 206, Loss: 0.4370735508315267\n",
      "Epoch 207, Loss: 0.438056659783102\n",
      "Epoch 208, Loss: 0.43828697608838324\n",
      "Epoch 209, Loss: 0.4380426277456835\n",
      "Epoch 210, Loss: 0.4367571723427673\n",
      "Epoch 211, Loss: 0.4358287121793394\n",
      "Epoch 212, Loss: 0.43549599799409766\n",
      "Epoch 213, Loss: 0.435693177425488\n",
      "Epoch 214, Loss: 0.43638716241086417\n",
      "Epoch 215, Loss: 0.43723040175969713\n",
      "Epoch 216, Loss: 0.4381875017781245\n",
      "Epoch 217, Loss: 0.43727582910411245\n",
      "Epoch 218, Loss: 0.4357251884259994\n",
      "Epoch 219, Loss: 0.43449740709117174\n",
      "Epoch 220, Loss: 0.4346007775761442\n",
      "Epoch 221, Loss: 0.4356339371912412\n",
      "Epoch 222, Loss: 0.43683657413065485\n",
      "Epoch 223, Loss: 0.43732786198111706\n",
      "Epoch 224, Loss: 0.43504045750484316\n",
      "Epoch 225, Loss: 0.4336674601818588\n",
      "Epoch 226, Loss: 0.4339570078903568\n",
      "Epoch 227, Loss: 0.43524205442250136\n",
      "Epoch 228, Loss: 0.43692856322479845\n",
      "Epoch 229, Loss: 0.4361014833656456\n",
      "Epoch 230, Loss: 0.43400818547427195\n",
      "Epoch 231, Loss: 0.43282550764678196\n",
      "Epoch 232, Loss: 0.43422302771098475\n",
      "Epoch 233, Loss: 0.43631150394157153\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21200644194896964\n",
      "Test R^2 score: 0.512125635783895\n",
      "Num of epochs: 234\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Epoch 179, Loss: 0.44257338842027333\n",
      "Epoch 180, Loss: 0.44223043415311275\n",
      "Epoch 181, Loss: 0.4412573335324542\n",
      "Epoch 182, Loss: 0.4403093939212056\n",
      "Epoch 183, Loss: 0.440210765892682\n",
      "Epoch 184, Loss: 0.4406913267766654\n",
      "Epoch 185, Loss: 0.44119678016972247\n",
      "Epoch 186, Loss: 0.4414768331353019\n",
      "Epoch 187, Loss: 0.44098509893198107\n",
      "Epoch 188, Loss: 0.4399157822542188\n",
      "Epoch 189, Loss: 0.43913002852403843\n",
      "Epoch 190, Loss: 0.43912120575952834\n",
      "Epoch 191, Loss: 0.43958194116248417\n",
      "Epoch 192, Loss: 0.43991779767875194\n",
      "Epoch 193, Loss: 0.4402464762584031\n",
      "Epoch 194, Loss: 0.4397939928277301\n",
      "Epoch 195, Loss: 0.4389848715145781\n",
      "Epoch 196, Loss: 0.43812834372448495\n",
      "Epoch 197, Loss: 0.4378789384628316\n",
      "Epoch 198, Loss: 0.4380569659316353\n",
      "Epoch 199, Loss: 0.4385928231376636\n",
      "Epoch 200, Loss: 0.4396870477941122\n",
      "Epoch 201, Loss: 0.44003322037003134\n",
      "Epoch 202, Loss: 0.4396387344028484\n",
      "Epoch 203, Loss: 0.43797246081508234\n",
      "Epoch 204, Loss: 0.4368868004619995\n",
      "Epoch 205, Loss: 0.4366217722212388\n",
      "Epoch 206, Loss: 0.4370735508315267\n",
      "Epoch 207, Loss: 0.438056659783102\n",
      "Epoch 208, Loss: 0.43828697608838324\n",
      "Epoch 209, Loss: 0.4380426277456835\n",
      "Epoch 210, Loss: 0.4367571723427673\n",
      "Epoch 211, Loss: 0.4358287121793394\n",
      "Epoch 212, Loss: 0.43549599799409766\n",
      "Epoch 213, Loss: 0.435693177425488\n",
      "Epoch 214, Loss: 0.43638716241086417\n",
      "Epoch 215, Loss: 0.43723040175969713\n",
      "Epoch 216, Loss: 0.4381875017781245\n",
      "Epoch 217, Loss: 0.43727582910411245\n",
      "Epoch 218, Loss: 0.4357251884259994\n",
      "Epoch 219, Loss: 0.43449740709117174\n",
      "Epoch 220, Loss: 0.4346007775761442\n",
      "Epoch 221, Loss: 0.4356339371912412\n",
      "Epoch 222, Loss: 0.43683657413065485\n",
      "Epoch 223, Loss: 0.43732786198111706\n",
      "Epoch 224, Loss: 0.43504045750484316\n",
      "Epoch 225, Loss: 0.4336674601818588\n",
      "Epoch 226, Loss: 0.4339570078903568\n",
      "Epoch 227, Loss: 0.43524205442250136\n",
      "Epoch 228, Loss: 0.43692856322479845\n",
      "Epoch 229, Loss: 0.4361014833656456\n",
      "Epoch 230, Loss: 0.43400818547427195\n",
      "Epoch 231, Loss: 0.43282550764678196\n",
      "Epoch 232, Loss: 0.43422302771098475\n",
      "Epoch 233, Loss: 0.43631150394157153\n",
      "Epoch 234, Loss: 0.4363944185143908\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20520940856825373\n",
      "Test R^2 score: 0.5422117834262584\n",
      "Num of epochs: 235\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Epoch 179, Loss: 0.44257338842027333\n",
      "Epoch 180, Loss: 0.44223043415311275\n",
      "Epoch 181, Loss: 0.4412573335324542\n",
      "Epoch 182, Loss: 0.4403093939212056\n",
      "Epoch 183, Loss: 0.440210765892682\n",
      "Epoch 184, Loss: 0.4406913267766654\n",
      "Epoch 185, Loss: 0.44119678016972247\n",
      "Epoch 186, Loss: 0.4414768331353019\n",
      "Epoch 187, Loss: 0.44098509893198107\n",
      "Epoch 188, Loss: 0.4399157822542188\n",
      "Epoch 189, Loss: 0.43913002852403843\n",
      "Epoch 190, Loss: 0.43912120575952834\n",
      "Epoch 191, Loss: 0.43958194116248417\n",
      "Epoch 192, Loss: 0.43991779767875194\n",
      "Epoch 193, Loss: 0.4402464762584031\n",
      "Epoch 194, Loss: 0.4397939928277301\n",
      "Epoch 195, Loss: 0.4389848715145781\n",
      "Epoch 196, Loss: 0.43812834372448495\n",
      "Epoch 197, Loss: 0.4378789384628316\n",
      "Epoch 198, Loss: 0.4380569659316353\n",
      "Epoch 199, Loss: 0.4385928231376636\n",
      "Epoch 200, Loss: 0.4396870477941122\n",
      "Epoch 201, Loss: 0.44003322037003134\n",
      "Epoch 202, Loss: 0.4396387344028484\n",
      "Epoch 203, Loss: 0.43797246081508234\n",
      "Epoch 204, Loss: 0.4368868004619995\n",
      "Epoch 205, Loss: 0.4366217722212388\n",
      "Epoch 206, Loss: 0.4370735508315267\n",
      "Epoch 207, Loss: 0.438056659783102\n",
      "Epoch 208, Loss: 0.43828697608838324\n",
      "Epoch 209, Loss: 0.4380426277456835\n",
      "Epoch 210, Loss: 0.4367571723427673\n",
      "Epoch 211, Loss: 0.4358287121793394\n",
      "Epoch 212, Loss: 0.43549599799409766\n",
      "Epoch 213, Loss: 0.435693177425488\n",
      "Epoch 214, Loss: 0.43638716241086417\n",
      "Epoch 215, Loss: 0.43723040175969713\n",
      "Epoch 216, Loss: 0.4381875017781245\n",
      "Epoch 217, Loss: 0.43727582910411245\n",
      "Epoch 218, Loss: 0.4357251884259994\n",
      "Epoch 219, Loss: 0.43449740709117174\n",
      "Epoch 220, Loss: 0.4346007775761442\n",
      "Epoch 221, Loss: 0.4356339371912412\n",
      "Epoch 222, Loss: 0.43683657413065485\n",
      "Epoch 223, Loss: 0.43732786198111706\n",
      "Epoch 224, Loss: 0.43504045750484316\n",
      "Epoch 225, Loss: 0.4336674601818588\n",
      "Epoch 226, Loss: 0.4339570078903568\n",
      "Epoch 227, Loss: 0.43524205442250136\n",
      "Epoch 228, Loss: 0.43692856322479845\n",
      "Epoch 229, Loss: 0.4361014833656456\n",
      "Epoch 230, Loss: 0.43400818547427195\n",
      "Epoch 231, Loss: 0.43282550764678196\n",
      "Epoch 232, Loss: 0.43422302771098475\n",
      "Epoch 233, Loss: 0.43631150394157153\n",
      "Epoch 234, Loss: 0.4363944185143908\n",
      "Epoch 235, Loss: 0.4344230831071679\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20583756390566188\n",
      "Test R^2 score: 0.5398717126391724\n",
      "Num of epochs: 236\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Epoch 179, Loss: 0.44257338842027333\n",
      "Epoch 180, Loss: 0.44223043415311275\n",
      "Epoch 181, Loss: 0.4412573335324542\n",
      "Epoch 182, Loss: 0.4403093939212056\n",
      "Epoch 183, Loss: 0.440210765892682\n",
      "Epoch 184, Loss: 0.4406913267766654\n",
      "Epoch 185, Loss: 0.44119678016972247\n",
      "Epoch 186, Loss: 0.4414768331353019\n",
      "Epoch 187, Loss: 0.44098509893198107\n",
      "Epoch 188, Loss: 0.4399157822542188\n",
      "Epoch 189, Loss: 0.43913002852403843\n",
      "Epoch 190, Loss: 0.43912120575952834\n",
      "Epoch 191, Loss: 0.43958194116248417\n",
      "Epoch 192, Loss: 0.43991779767875194\n",
      "Epoch 193, Loss: 0.4402464762584031\n",
      "Epoch 194, Loss: 0.4397939928277301\n",
      "Epoch 195, Loss: 0.4389848715145781\n",
      "Epoch 196, Loss: 0.43812834372448495\n",
      "Epoch 197, Loss: 0.4378789384628316\n",
      "Epoch 198, Loss: 0.4380569659316353\n",
      "Epoch 199, Loss: 0.4385928231376636\n",
      "Epoch 200, Loss: 0.4396870477941122\n",
      "Epoch 201, Loss: 0.44003322037003134\n",
      "Epoch 202, Loss: 0.4396387344028484\n",
      "Epoch 203, Loss: 0.43797246081508234\n",
      "Epoch 204, Loss: 0.4368868004619995\n",
      "Epoch 205, Loss: 0.4366217722212388\n",
      "Epoch 206, Loss: 0.4370735508315267\n",
      "Epoch 207, Loss: 0.438056659783102\n",
      "Epoch 208, Loss: 0.43828697608838324\n",
      "Epoch 209, Loss: 0.4380426277456835\n",
      "Epoch 210, Loss: 0.4367571723427673\n",
      "Epoch 211, Loss: 0.4358287121793394\n",
      "Epoch 212, Loss: 0.43549599799409766\n",
      "Epoch 213, Loss: 0.435693177425488\n",
      "Epoch 214, Loss: 0.43638716241086417\n",
      "Epoch 215, Loss: 0.43723040175969713\n",
      "Epoch 216, Loss: 0.4381875017781245\n",
      "Epoch 217, Loss: 0.43727582910411245\n",
      "Epoch 218, Loss: 0.4357251884259994\n",
      "Epoch 219, Loss: 0.43449740709117174\n",
      "Epoch 220, Loss: 0.4346007775761442\n",
      "Epoch 221, Loss: 0.4356339371912412\n",
      "Epoch 222, Loss: 0.43683657413065485\n",
      "Epoch 223, Loss: 0.43732786198111706\n",
      "Epoch 224, Loss: 0.43504045750484316\n",
      "Epoch 225, Loss: 0.4336674601818588\n",
      "Epoch 226, Loss: 0.4339570078903568\n",
      "Epoch 227, Loss: 0.43524205442250136\n",
      "Epoch 228, Loss: 0.43692856322479845\n",
      "Epoch 229, Loss: 0.4361014833656456\n",
      "Epoch 230, Loss: 0.43400818547427195\n",
      "Epoch 231, Loss: 0.43282550764678196\n",
      "Epoch 232, Loss: 0.43422302771098475\n",
      "Epoch 233, Loss: 0.43631150394157153\n",
      "Epoch 234, Loss: 0.4363944185143908\n",
      "Epoch 235, Loss: 0.4344230831071679\n",
      "Epoch 236, Loss: 0.43231983169663213\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20940367950448846\n",
      "Test R^2 score: 0.5242974696336593\n",
      "Num of epochs: 237\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Epoch 179, Loss: 0.44257338842027333\n",
      "Epoch 180, Loss: 0.44223043415311275\n",
      "Epoch 181, Loss: 0.4412573335324542\n",
      "Epoch 182, Loss: 0.4403093939212056\n",
      "Epoch 183, Loss: 0.440210765892682\n",
      "Epoch 184, Loss: 0.4406913267766654\n",
      "Epoch 185, Loss: 0.44119678016972247\n",
      "Epoch 186, Loss: 0.4414768331353019\n",
      "Epoch 187, Loss: 0.44098509893198107\n",
      "Epoch 188, Loss: 0.4399157822542188\n",
      "Epoch 189, Loss: 0.43913002852403843\n",
      "Epoch 190, Loss: 0.43912120575952834\n",
      "Epoch 191, Loss: 0.43958194116248417\n",
      "Epoch 192, Loss: 0.43991779767875194\n",
      "Epoch 193, Loss: 0.4402464762584031\n",
      "Epoch 194, Loss: 0.4397939928277301\n",
      "Epoch 195, Loss: 0.4389848715145781\n",
      "Epoch 196, Loss: 0.43812834372448495\n",
      "Epoch 197, Loss: 0.4378789384628316\n",
      "Epoch 198, Loss: 0.4380569659316353\n",
      "Epoch 199, Loss: 0.4385928231376636\n",
      "Epoch 200, Loss: 0.4396870477941122\n",
      "Epoch 201, Loss: 0.44003322037003134\n",
      "Epoch 202, Loss: 0.4396387344028484\n",
      "Epoch 203, Loss: 0.43797246081508234\n",
      "Epoch 204, Loss: 0.4368868004619995\n",
      "Epoch 205, Loss: 0.4366217722212388\n",
      "Epoch 206, Loss: 0.4370735508315267\n",
      "Epoch 207, Loss: 0.438056659783102\n",
      "Epoch 208, Loss: 0.43828697608838324\n",
      "Epoch 209, Loss: 0.4380426277456835\n",
      "Epoch 210, Loss: 0.4367571723427673\n",
      "Epoch 211, Loss: 0.4358287121793394\n",
      "Epoch 212, Loss: 0.43549599799409766\n",
      "Epoch 213, Loss: 0.435693177425488\n",
      "Epoch 214, Loss: 0.43638716241086417\n",
      "Epoch 215, Loss: 0.43723040175969713\n",
      "Epoch 216, Loss: 0.4381875017781245\n",
      "Epoch 217, Loss: 0.43727582910411245\n",
      "Epoch 218, Loss: 0.4357251884259994\n",
      "Epoch 219, Loss: 0.43449740709117174\n",
      "Epoch 220, Loss: 0.4346007775761442\n",
      "Epoch 221, Loss: 0.4356339371912412\n",
      "Epoch 222, Loss: 0.43683657413065485\n",
      "Epoch 223, Loss: 0.43732786198111706\n",
      "Epoch 224, Loss: 0.43504045750484316\n",
      "Epoch 225, Loss: 0.4336674601818588\n",
      "Epoch 226, Loss: 0.4339570078903568\n",
      "Epoch 227, Loss: 0.43524205442250136\n",
      "Epoch 228, Loss: 0.43692856322479845\n",
      "Epoch 229, Loss: 0.4361014833656456\n",
      "Epoch 230, Loss: 0.43400818547427195\n",
      "Epoch 231, Loss: 0.43282550764678196\n",
      "Epoch 232, Loss: 0.43422302771098475\n",
      "Epoch 233, Loss: 0.43631150394157153\n",
      "Epoch 234, Loss: 0.4363944185143908\n",
      "Epoch 235, Loss: 0.4344230831071679\n",
      "Epoch 236, Loss: 0.43231983169663213\n",
      "Epoch 237, Loss: 0.4338866438813009\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20542557773630726\n",
      "Test R^2 score: 0.5416993398044203\n",
      "Num of epochs: 238\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Epoch 179, Loss: 0.44257338842027333\n",
      "Epoch 180, Loss: 0.44223043415311275\n",
      "Epoch 181, Loss: 0.4412573335324542\n",
      "Epoch 182, Loss: 0.4403093939212056\n",
      "Epoch 183, Loss: 0.440210765892682\n",
      "Epoch 184, Loss: 0.4406913267766654\n",
      "Epoch 185, Loss: 0.44119678016972247\n",
      "Epoch 186, Loss: 0.4414768331353019\n",
      "Epoch 187, Loss: 0.44098509893198107\n",
      "Epoch 188, Loss: 0.4399157822542188\n",
      "Epoch 189, Loss: 0.43913002852403843\n",
      "Epoch 190, Loss: 0.43912120575952834\n",
      "Epoch 191, Loss: 0.43958194116248417\n",
      "Epoch 192, Loss: 0.43991779767875194\n",
      "Epoch 193, Loss: 0.4402464762584031\n",
      "Epoch 194, Loss: 0.4397939928277301\n",
      "Epoch 195, Loss: 0.4389848715145781\n",
      "Epoch 196, Loss: 0.43812834372448495\n",
      "Epoch 197, Loss: 0.4378789384628316\n",
      "Epoch 198, Loss: 0.4380569659316353\n",
      "Epoch 199, Loss: 0.4385928231376636\n",
      "Epoch 200, Loss: 0.4396870477941122\n",
      "Epoch 201, Loss: 0.44003322037003134\n",
      "Epoch 202, Loss: 0.4396387344028484\n",
      "Epoch 203, Loss: 0.43797246081508234\n",
      "Epoch 204, Loss: 0.4368868004619995\n",
      "Epoch 205, Loss: 0.4366217722212388\n",
      "Epoch 206, Loss: 0.4370735508315267\n",
      "Epoch 207, Loss: 0.438056659783102\n",
      "Epoch 208, Loss: 0.43828697608838324\n",
      "Epoch 209, Loss: 0.4380426277456835\n",
      "Epoch 210, Loss: 0.4367571723427673\n",
      "Epoch 211, Loss: 0.4358287121793394\n",
      "Epoch 212, Loss: 0.43549599799409766\n",
      "Epoch 213, Loss: 0.435693177425488\n",
      "Epoch 214, Loss: 0.43638716241086417\n",
      "Epoch 215, Loss: 0.43723040175969713\n",
      "Epoch 216, Loss: 0.4381875017781245\n",
      "Epoch 217, Loss: 0.43727582910411245\n",
      "Epoch 218, Loss: 0.4357251884259994\n",
      "Epoch 219, Loss: 0.43449740709117174\n",
      "Epoch 220, Loss: 0.4346007775761442\n",
      "Epoch 221, Loss: 0.4356339371912412\n",
      "Epoch 222, Loss: 0.43683657413065485\n",
      "Epoch 223, Loss: 0.43732786198111706\n",
      "Epoch 224, Loss: 0.43504045750484316\n",
      "Epoch 225, Loss: 0.4336674601818588\n",
      "Epoch 226, Loss: 0.4339570078903568\n",
      "Epoch 227, Loss: 0.43524205442250136\n",
      "Epoch 228, Loss: 0.43692856322479845\n",
      "Epoch 229, Loss: 0.4361014833656456\n",
      "Epoch 230, Loss: 0.43400818547427195\n",
      "Epoch 231, Loss: 0.43282550764678196\n",
      "Epoch 232, Loss: 0.43422302771098475\n",
      "Epoch 233, Loss: 0.43631150394157153\n",
      "Epoch 234, Loss: 0.4363944185143908\n",
      "Epoch 235, Loss: 0.4344230831071679\n",
      "Epoch 236, Loss: 0.43231983169663213\n",
      "Epoch 237, Loss: 0.4338866438813009\n",
      "Epoch 238, Loss: 0.4371328345881963\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.212594550538073\n",
      "Test R^2 score: 0.5093837651543531\n",
      "Num of epochs: 239\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Epoch 179, Loss: 0.44257338842027333\n",
      "Epoch 180, Loss: 0.44223043415311275\n",
      "Epoch 181, Loss: 0.4412573335324542\n",
      "Epoch 182, Loss: 0.4403093939212056\n",
      "Epoch 183, Loss: 0.440210765892682\n",
      "Epoch 184, Loss: 0.4406913267766654\n",
      "Epoch 185, Loss: 0.44119678016972247\n",
      "Epoch 186, Loss: 0.4414768331353019\n",
      "Epoch 187, Loss: 0.44098509893198107\n",
      "Epoch 188, Loss: 0.4399157822542188\n",
      "Epoch 189, Loss: 0.43913002852403843\n",
      "Epoch 190, Loss: 0.43912120575952834\n",
      "Epoch 191, Loss: 0.43958194116248417\n",
      "Epoch 192, Loss: 0.43991779767875194\n",
      "Epoch 193, Loss: 0.4402464762584031\n",
      "Epoch 194, Loss: 0.4397939928277301\n",
      "Epoch 195, Loss: 0.4389848715145781\n",
      "Epoch 196, Loss: 0.43812834372448495\n",
      "Epoch 197, Loss: 0.4378789384628316\n",
      "Epoch 198, Loss: 0.4380569659316353\n",
      "Epoch 199, Loss: 0.4385928231376636\n",
      "Epoch 200, Loss: 0.4396870477941122\n",
      "Epoch 201, Loss: 0.44003322037003134\n",
      "Epoch 202, Loss: 0.4396387344028484\n",
      "Epoch 203, Loss: 0.43797246081508234\n",
      "Epoch 204, Loss: 0.4368868004619995\n",
      "Epoch 205, Loss: 0.4366217722212388\n",
      "Epoch 206, Loss: 0.4370735508315267\n",
      "Epoch 207, Loss: 0.438056659783102\n",
      "Epoch 208, Loss: 0.43828697608838324\n",
      "Epoch 209, Loss: 0.4380426277456835\n",
      "Epoch 210, Loss: 0.4367571723427673\n",
      "Epoch 211, Loss: 0.4358287121793394\n",
      "Epoch 212, Loss: 0.43549599799409766\n",
      "Epoch 213, Loss: 0.435693177425488\n",
      "Epoch 214, Loss: 0.43638716241086417\n",
      "Epoch 215, Loss: 0.43723040175969713\n",
      "Epoch 216, Loss: 0.4381875017781245\n",
      "Epoch 217, Loss: 0.43727582910411245\n",
      "Epoch 218, Loss: 0.4357251884259994\n",
      "Epoch 219, Loss: 0.43449740709117174\n",
      "Epoch 220, Loss: 0.4346007775761442\n",
      "Epoch 221, Loss: 0.4356339371912412\n",
      "Epoch 222, Loss: 0.43683657413065485\n",
      "Epoch 223, Loss: 0.43732786198111706\n",
      "Epoch 224, Loss: 0.43504045750484316\n",
      "Epoch 225, Loss: 0.4336674601818588\n",
      "Epoch 226, Loss: 0.4339570078903568\n",
      "Epoch 227, Loss: 0.43524205442250136\n",
      "Epoch 228, Loss: 0.43692856322479845\n",
      "Epoch 229, Loss: 0.4361014833656456\n",
      "Epoch 230, Loss: 0.43400818547427195\n",
      "Epoch 231, Loss: 0.43282550764678196\n",
      "Epoch 232, Loss: 0.43422302771098475\n",
      "Epoch 233, Loss: 0.43631150394157153\n",
      "Epoch 234, Loss: 0.4363944185143908\n",
      "Epoch 235, Loss: 0.4344230831071679\n",
      "Epoch 236, Loss: 0.43231983169663213\n",
      "Epoch 237, Loss: 0.4338866438813009\n",
      "Epoch 238, Loss: 0.4371328345881963\n",
      "Epoch 239, Loss: 0.4361934054316967\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.205160620695524\n",
      "Test R^2 score: 0.5423703449781547\n",
      "Num of epochs: 240\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Epoch 179, Loss: 0.44257338842027333\n",
      "Epoch 180, Loss: 0.44223043415311275\n",
      "Epoch 181, Loss: 0.4412573335324542\n",
      "Epoch 182, Loss: 0.4403093939212056\n",
      "Epoch 183, Loss: 0.440210765892682\n",
      "Epoch 184, Loss: 0.4406913267766654\n",
      "Epoch 185, Loss: 0.44119678016972247\n",
      "Epoch 186, Loss: 0.4414768331353019\n",
      "Epoch 187, Loss: 0.44098509893198107\n",
      "Epoch 188, Loss: 0.4399157822542188\n",
      "Epoch 189, Loss: 0.43913002852403843\n",
      "Epoch 190, Loss: 0.43912120575952834\n",
      "Epoch 191, Loss: 0.43958194116248417\n",
      "Epoch 192, Loss: 0.43991779767875194\n",
      "Epoch 193, Loss: 0.4402464762584031\n",
      "Epoch 194, Loss: 0.4397939928277301\n",
      "Epoch 195, Loss: 0.4389848715145781\n",
      "Epoch 196, Loss: 0.43812834372448495\n",
      "Epoch 197, Loss: 0.4378789384628316\n",
      "Epoch 198, Loss: 0.4380569659316353\n",
      "Epoch 199, Loss: 0.4385928231376636\n",
      "Epoch 200, Loss: 0.4396870477941122\n",
      "Epoch 201, Loss: 0.44003322037003134\n",
      "Epoch 202, Loss: 0.4396387344028484\n",
      "Epoch 203, Loss: 0.43797246081508234\n",
      "Epoch 204, Loss: 0.4368868004619995\n",
      "Epoch 205, Loss: 0.4366217722212388\n",
      "Epoch 206, Loss: 0.4370735508315267\n",
      "Epoch 207, Loss: 0.438056659783102\n",
      "Epoch 208, Loss: 0.43828697608838324\n",
      "Epoch 209, Loss: 0.4380426277456835\n",
      "Epoch 210, Loss: 0.4367571723427673\n",
      "Epoch 211, Loss: 0.4358287121793394\n",
      "Epoch 212, Loss: 0.43549599799409766\n",
      "Epoch 213, Loss: 0.435693177425488\n",
      "Epoch 214, Loss: 0.43638716241086417\n",
      "Epoch 215, Loss: 0.43723040175969713\n",
      "Epoch 216, Loss: 0.4381875017781245\n",
      "Epoch 217, Loss: 0.43727582910411245\n",
      "Epoch 218, Loss: 0.4357251884259994\n",
      "Epoch 219, Loss: 0.43449740709117174\n",
      "Epoch 220, Loss: 0.4346007775761442\n",
      "Epoch 221, Loss: 0.4356339371912412\n",
      "Epoch 222, Loss: 0.43683657413065485\n",
      "Epoch 223, Loss: 0.43732786198111706\n",
      "Epoch 224, Loss: 0.43504045750484316\n",
      "Epoch 225, Loss: 0.4336674601818588\n",
      "Epoch 226, Loss: 0.4339570078903568\n",
      "Epoch 227, Loss: 0.43524205442250136\n",
      "Epoch 228, Loss: 0.43692856322479845\n",
      "Epoch 229, Loss: 0.4361014833656456\n",
      "Epoch 230, Loss: 0.43400818547427195\n",
      "Epoch 231, Loss: 0.43282550764678196\n",
      "Epoch 232, Loss: 0.43422302771098475\n",
      "Epoch 233, Loss: 0.43631150394157153\n",
      "Epoch 234, Loss: 0.4363944185143908\n",
      "Epoch 235, Loss: 0.4344230831071679\n",
      "Epoch 236, Loss: 0.43231983169663213\n",
      "Epoch 237, Loss: 0.4338866438813009\n",
      "Epoch 238, Loss: 0.4371328345881963\n",
      "Epoch 239, Loss: 0.4361934054316967\n",
      "Epoch 240, Loss: 0.4336558976182621\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20516675061851347\n",
      "Test R^2 score: 0.5425963931694955\n",
      "Num of epochs: 241\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Epoch 179, Loss: 0.44257338842027333\n",
      "Epoch 180, Loss: 0.44223043415311275\n",
      "Epoch 181, Loss: 0.4412573335324542\n",
      "Epoch 182, Loss: 0.4403093939212056\n",
      "Epoch 183, Loss: 0.440210765892682\n",
      "Epoch 184, Loss: 0.4406913267766654\n",
      "Epoch 185, Loss: 0.44119678016972247\n",
      "Epoch 186, Loss: 0.4414768331353019\n",
      "Epoch 187, Loss: 0.44098509893198107\n",
      "Epoch 188, Loss: 0.4399157822542188\n",
      "Epoch 189, Loss: 0.43913002852403843\n",
      "Epoch 190, Loss: 0.43912120575952834\n",
      "Epoch 191, Loss: 0.43958194116248417\n",
      "Epoch 192, Loss: 0.43991779767875194\n",
      "Epoch 193, Loss: 0.4402464762584031\n",
      "Epoch 194, Loss: 0.4397939928277301\n",
      "Epoch 195, Loss: 0.4389848715145781\n",
      "Epoch 196, Loss: 0.43812834372448495\n",
      "Epoch 197, Loss: 0.4378789384628316\n",
      "Epoch 198, Loss: 0.4380569659316353\n",
      "Epoch 199, Loss: 0.4385928231376636\n",
      "Epoch 200, Loss: 0.4396870477941122\n",
      "Epoch 201, Loss: 0.44003322037003134\n",
      "Epoch 202, Loss: 0.4396387344028484\n",
      "Epoch 203, Loss: 0.43797246081508234\n",
      "Epoch 204, Loss: 0.4368868004619995\n",
      "Epoch 205, Loss: 0.4366217722212388\n",
      "Epoch 206, Loss: 0.4370735508315267\n",
      "Epoch 207, Loss: 0.438056659783102\n",
      "Epoch 208, Loss: 0.43828697608838324\n",
      "Epoch 209, Loss: 0.4380426277456835\n",
      "Epoch 210, Loss: 0.4367571723427673\n",
      "Epoch 211, Loss: 0.4358287121793394\n",
      "Epoch 212, Loss: 0.43549599799409766\n",
      "Epoch 213, Loss: 0.435693177425488\n",
      "Epoch 214, Loss: 0.43638716241086417\n",
      "Epoch 215, Loss: 0.43723040175969713\n",
      "Epoch 216, Loss: 0.4381875017781245\n",
      "Epoch 217, Loss: 0.43727582910411245\n",
      "Epoch 218, Loss: 0.4357251884259994\n",
      "Epoch 219, Loss: 0.43449740709117174\n",
      "Epoch 220, Loss: 0.4346007775761442\n",
      "Epoch 221, Loss: 0.4356339371912412\n",
      "Epoch 222, Loss: 0.43683657413065485\n",
      "Epoch 223, Loss: 0.43732786198111706\n",
      "Epoch 224, Loss: 0.43504045750484316\n",
      "Epoch 225, Loss: 0.4336674601818588\n",
      "Epoch 226, Loss: 0.4339570078903568\n",
      "Epoch 227, Loss: 0.43524205442250136\n",
      "Epoch 228, Loss: 0.43692856322479845\n",
      "Epoch 229, Loss: 0.4361014833656456\n",
      "Epoch 230, Loss: 0.43400818547427195\n",
      "Epoch 231, Loss: 0.43282550764678196\n",
      "Epoch 232, Loss: 0.43422302771098475\n",
      "Epoch 233, Loss: 0.43631150394157153\n",
      "Epoch 234, Loss: 0.4363944185143908\n",
      "Epoch 235, Loss: 0.4344230831071679\n",
      "Epoch 236, Loss: 0.43231983169663213\n",
      "Epoch 237, Loss: 0.4338866438813009\n",
      "Epoch 238, Loss: 0.4371328345881963\n",
      "Epoch 239, Loss: 0.4361934054316967\n",
      "Epoch 240, Loss: 0.4336558976182621\n",
      "Epoch 241, Loss: 0.432399290161847\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2108136998377556\n",
      "Test R^2 score: 0.5179100961601562\n",
      "Num of epochs: 242\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Epoch 179, Loss: 0.44257338842027333\n",
      "Epoch 180, Loss: 0.44223043415311275\n",
      "Epoch 181, Loss: 0.4412573335324542\n",
      "Epoch 182, Loss: 0.4403093939212056\n",
      "Epoch 183, Loss: 0.440210765892682\n",
      "Epoch 184, Loss: 0.4406913267766654\n",
      "Epoch 185, Loss: 0.44119678016972247\n",
      "Epoch 186, Loss: 0.4414768331353019\n",
      "Epoch 187, Loss: 0.44098509893198107\n",
      "Epoch 188, Loss: 0.4399157822542188\n",
      "Epoch 189, Loss: 0.43913002852403843\n",
      "Epoch 190, Loss: 0.43912120575952834\n",
      "Epoch 191, Loss: 0.43958194116248417\n",
      "Epoch 192, Loss: 0.43991779767875194\n",
      "Epoch 193, Loss: 0.4402464762584031\n",
      "Epoch 194, Loss: 0.4397939928277301\n",
      "Epoch 195, Loss: 0.4389848715145781\n",
      "Epoch 196, Loss: 0.43812834372448495\n",
      "Epoch 197, Loss: 0.4378789384628316\n",
      "Epoch 198, Loss: 0.4380569659316353\n",
      "Epoch 199, Loss: 0.4385928231376636\n",
      "Epoch 200, Loss: 0.4396870477941122\n",
      "Epoch 201, Loss: 0.44003322037003134\n",
      "Epoch 202, Loss: 0.4396387344028484\n",
      "Epoch 203, Loss: 0.43797246081508234\n",
      "Epoch 204, Loss: 0.4368868004619995\n",
      "Epoch 205, Loss: 0.4366217722212388\n",
      "Epoch 206, Loss: 0.4370735508315267\n",
      "Epoch 207, Loss: 0.438056659783102\n",
      "Epoch 208, Loss: 0.43828697608838324\n",
      "Epoch 209, Loss: 0.4380426277456835\n",
      "Epoch 210, Loss: 0.4367571723427673\n",
      "Epoch 211, Loss: 0.4358287121793394\n",
      "Epoch 212, Loss: 0.43549599799409766\n",
      "Epoch 213, Loss: 0.435693177425488\n",
      "Epoch 214, Loss: 0.43638716241086417\n",
      "Epoch 215, Loss: 0.43723040175969713\n",
      "Epoch 216, Loss: 0.4381875017781245\n",
      "Epoch 217, Loss: 0.43727582910411245\n",
      "Epoch 218, Loss: 0.4357251884259994\n",
      "Epoch 219, Loss: 0.43449740709117174\n",
      "Epoch 220, Loss: 0.4346007775761442\n",
      "Epoch 221, Loss: 0.4356339371912412\n",
      "Epoch 222, Loss: 0.43683657413065485\n",
      "Epoch 223, Loss: 0.43732786198111706\n",
      "Epoch 224, Loss: 0.43504045750484316\n",
      "Epoch 225, Loss: 0.4336674601818588\n",
      "Epoch 226, Loss: 0.4339570078903568\n",
      "Epoch 227, Loss: 0.43524205442250136\n",
      "Epoch 228, Loss: 0.43692856322479845\n",
      "Epoch 229, Loss: 0.4361014833656456\n",
      "Epoch 230, Loss: 0.43400818547427195\n",
      "Epoch 231, Loss: 0.43282550764678196\n",
      "Epoch 232, Loss: 0.43422302771098475\n",
      "Epoch 233, Loss: 0.43631150394157153\n",
      "Epoch 234, Loss: 0.4363944185143908\n",
      "Epoch 235, Loss: 0.4344230831071679\n",
      "Epoch 236, Loss: 0.43231983169663213\n",
      "Epoch 237, Loss: 0.4338866438813009\n",
      "Epoch 238, Loss: 0.4371328345881963\n",
      "Epoch 239, Loss: 0.4361934054316967\n",
      "Epoch 240, Loss: 0.4336558976182621\n",
      "Epoch 241, Loss: 0.432399290161847\n",
      "Epoch 242, Loss: 0.43439426928256275\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20530422724527797\n",
      "Test R^2 score: 0.5422504605966845\n",
      "Num of epochs: 243\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Epoch 179, Loss: 0.44257338842027333\n",
      "Epoch 180, Loss: 0.44223043415311275\n",
      "Epoch 181, Loss: 0.4412573335324542\n",
      "Epoch 182, Loss: 0.4403093939212056\n",
      "Epoch 183, Loss: 0.440210765892682\n",
      "Epoch 184, Loss: 0.4406913267766654\n",
      "Epoch 185, Loss: 0.44119678016972247\n",
      "Epoch 186, Loss: 0.4414768331353019\n",
      "Epoch 187, Loss: 0.44098509893198107\n",
      "Epoch 188, Loss: 0.4399157822542188\n",
      "Epoch 189, Loss: 0.43913002852403843\n",
      "Epoch 190, Loss: 0.43912120575952834\n",
      "Epoch 191, Loss: 0.43958194116248417\n",
      "Epoch 192, Loss: 0.43991779767875194\n",
      "Epoch 193, Loss: 0.4402464762584031\n",
      "Epoch 194, Loss: 0.4397939928277301\n",
      "Epoch 195, Loss: 0.4389848715145781\n",
      "Epoch 196, Loss: 0.43812834372448495\n",
      "Epoch 197, Loss: 0.4378789384628316\n",
      "Epoch 198, Loss: 0.4380569659316353\n",
      "Epoch 199, Loss: 0.4385928231376636\n",
      "Epoch 200, Loss: 0.4396870477941122\n",
      "Epoch 201, Loss: 0.44003322037003134\n",
      "Epoch 202, Loss: 0.4396387344028484\n",
      "Epoch 203, Loss: 0.43797246081508234\n",
      "Epoch 204, Loss: 0.4368868004619995\n",
      "Epoch 205, Loss: 0.4366217722212388\n",
      "Epoch 206, Loss: 0.4370735508315267\n",
      "Epoch 207, Loss: 0.438056659783102\n",
      "Epoch 208, Loss: 0.43828697608838324\n",
      "Epoch 209, Loss: 0.4380426277456835\n",
      "Epoch 210, Loss: 0.4367571723427673\n",
      "Epoch 211, Loss: 0.4358287121793394\n",
      "Epoch 212, Loss: 0.43549599799409766\n",
      "Epoch 213, Loss: 0.435693177425488\n",
      "Epoch 214, Loss: 0.43638716241086417\n",
      "Epoch 215, Loss: 0.43723040175969713\n",
      "Epoch 216, Loss: 0.4381875017781245\n",
      "Epoch 217, Loss: 0.43727582910411245\n",
      "Epoch 218, Loss: 0.4357251884259994\n",
      "Epoch 219, Loss: 0.43449740709117174\n",
      "Epoch 220, Loss: 0.4346007775761442\n",
      "Epoch 221, Loss: 0.4356339371912412\n",
      "Epoch 222, Loss: 0.43683657413065485\n",
      "Epoch 223, Loss: 0.43732786198111706\n",
      "Epoch 224, Loss: 0.43504045750484316\n",
      "Epoch 225, Loss: 0.4336674601818588\n",
      "Epoch 226, Loss: 0.4339570078903568\n",
      "Epoch 227, Loss: 0.43524205442250136\n",
      "Epoch 228, Loss: 0.43692856322479845\n",
      "Epoch 229, Loss: 0.4361014833656456\n",
      "Epoch 230, Loss: 0.43400818547427195\n",
      "Epoch 231, Loss: 0.43282550764678196\n",
      "Epoch 232, Loss: 0.43422302771098475\n",
      "Epoch 233, Loss: 0.43631150394157153\n",
      "Epoch 234, Loss: 0.4363944185143908\n",
      "Epoch 235, Loss: 0.4344230831071679\n",
      "Epoch 236, Loss: 0.43231983169663213\n",
      "Epoch 237, Loss: 0.4338866438813009\n",
      "Epoch 238, Loss: 0.4371328345881963\n",
      "Epoch 239, Loss: 0.4361934054316967\n",
      "Epoch 240, Loss: 0.4336558976182621\n",
      "Epoch 241, Loss: 0.432399290161847\n",
      "Epoch 242, Loss: 0.43439426928256275\n",
      "Epoch 243, Loss: 0.43607225078754297\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2094816602303252\n",
      "Test R^2 score: 0.5239201445888451\n",
      "Num of epochs: 244\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Epoch 179, Loss: 0.44257338842027333\n",
      "Epoch 180, Loss: 0.44223043415311275\n",
      "Epoch 181, Loss: 0.4412573335324542\n",
      "Epoch 182, Loss: 0.4403093939212056\n",
      "Epoch 183, Loss: 0.440210765892682\n",
      "Epoch 184, Loss: 0.4406913267766654\n",
      "Epoch 185, Loss: 0.44119678016972247\n",
      "Epoch 186, Loss: 0.4414768331353019\n",
      "Epoch 187, Loss: 0.44098509893198107\n",
      "Epoch 188, Loss: 0.4399157822542188\n",
      "Epoch 189, Loss: 0.43913002852403843\n",
      "Epoch 190, Loss: 0.43912120575952834\n",
      "Epoch 191, Loss: 0.43958194116248417\n",
      "Epoch 192, Loss: 0.43991779767875194\n",
      "Epoch 193, Loss: 0.4402464762584031\n",
      "Epoch 194, Loss: 0.4397939928277301\n",
      "Epoch 195, Loss: 0.4389848715145781\n",
      "Epoch 196, Loss: 0.43812834372448495\n",
      "Epoch 197, Loss: 0.4378789384628316\n",
      "Epoch 198, Loss: 0.4380569659316353\n",
      "Epoch 199, Loss: 0.4385928231376636\n",
      "Epoch 200, Loss: 0.4396870477941122\n",
      "Epoch 201, Loss: 0.44003322037003134\n",
      "Epoch 202, Loss: 0.4396387344028484\n",
      "Epoch 203, Loss: 0.43797246081508234\n",
      "Epoch 204, Loss: 0.4368868004619995\n",
      "Epoch 205, Loss: 0.4366217722212388\n",
      "Epoch 206, Loss: 0.4370735508315267\n",
      "Epoch 207, Loss: 0.438056659783102\n",
      "Epoch 208, Loss: 0.43828697608838324\n",
      "Epoch 209, Loss: 0.4380426277456835\n",
      "Epoch 210, Loss: 0.4367571723427673\n",
      "Epoch 211, Loss: 0.4358287121793394\n",
      "Epoch 212, Loss: 0.43549599799409766\n",
      "Epoch 213, Loss: 0.435693177425488\n",
      "Epoch 214, Loss: 0.43638716241086417\n",
      "Epoch 215, Loss: 0.43723040175969713\n",
      "Epoch 216, Loss: 0.4381875017781245\n",
      "Epoch 217, Loss: 0.43727582910411245\n",
      "Epoch 218, Loss: 0.4357251884259994\n",
      "Epoch 219, Loss: 0.43449740709117174\n",
      "Epoch 220, Loss: 0.4346007775761442\n",
      "Epoch 221, Loss: 0.4356339371912412\n",
      "Epoch 222, Loss: 0.43683657413065485\n",
      "Epoch 223, Loss: 0.43732786198111706\n",
      "Epoch 224, Loss: 0.43504045750484316\n",
      "Epoch 225, Loss: 0.4336674601818588\n",
      "Epoch 226, Loss: 0.4339570078903568\n",
      "Epoch 227, Loss: 0.43524205442250136\n",
      "Epoch 228, Loss: 0.43692856322479845\n",
      "Epoch 229, Loss: 0.4361014833656456\n",
      "Epoch 230, Loss: 0.43400818547427195\n",
      "Epoch 231, Loss: 0.43282550764678196\n",
      "Epoch 232, Loss: 0.43422302771098475\n",
      "Epoch 233, Loss: 0.43631150394157153\n",
      "Epoch 234, Loss: 0.4363944185143908\n",
      "Epoch 235, Loss: 0.4344230831071679\n",
      "Epoch 236, Loss: 0.43231983169663213\n",
      "Epoch 237, Loss: 0.4338866438813009\n",
      "Epoch 238, Loss: 0.4371328345881963\n",
      "Epoch 239, Loss: 0.4361934054316967\n",
      "Epoch 240, Loss: 0.4336558976182621\n",
      "Epoch 241, Loss: 0.432399290161847\n",
      "Epoch 242, Loss: 0.43439426928256275\n",
      "Epoch 243, Loss: 0.43607225078754297\n",
      "Epoch 244, Loss: 0.432937520696398\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20617692375796515\n",
      "Test R^2 score: 0.5382432762728899\n",
      "Num of epochs: 245\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Epoch 179, Loss: 0.44257338842027333\n",
      "Epoch 180, Loss: 0.44223043415311275\n",
      "Epoch 181, Loss: 0.4412573335324542\n",
      "Epoch 182, Loss: 0.4403093939212056\n",
      "Epoch 183, Loss: 0.440210765892682\n",
      "Epoch 184, Loss: 0.4406913267766654\n",
      "Epoch 185, Loss: 0.44119678016972247\n",
      "Epoch 186, Loss: 0.4414768331353019\n",
      "Epoch 187, Loss: 0.44098509893198107\n",
      "Epoch 188, Loss: 0.4399157822542188\n",
      "Epoch 189, Loss: 0.43913002852403843\n",
      "Epoch 190, Loss: 0.43912120575952834\n",
      "Epoch 191, Loss: 0.43958194116248417\n",
      "Epoch 192, Loss: 0.43991779767875194\n",
      "Epoch 193, Loss: 0.4402464762584031\n",
      "Epoch 194, Loss: 0.4397939928277301\n",
      "Epoch 195, Loss: 0.4389848715145781\n",
      "Epoch 196, Loss: 0.43812834372448495\n",
      "Epoch 197, Loss: 0.4378789384628316\n",
      "Epoch 198, Loss: 0.4380569659316353\n",
      "Epoch 199, Loss: 0.4385928231376636\n",
      "Epoch 200, Loss: 0.4396870477941122\n",
      "Epoch 201, Loss: 0.44003322037003134\n",
      "Epoch 202, Loss: 0.4396387344028484\n",
      "Epoch 203, Loss: 0.43797246081508234\n",
      "Epoch 204, Loss: 0.4368868004619995\n",
      "Epoch 205, Loss: 0.4366217722212388\n",
      "Epoch 206, Loss: 0.4370735508315267\n",
      "Epoch 207, Loss: 0.438056659783102\n",
      "Epoch 208, Loss: 0.43828697608838324\n",
      "Epoch 209, Loss: 0.4380426277456835\n",
      "Epoch 210, Loss: 0.4367571723427673\n",
      "Epoch 211, Loss: 0.4358287121793394\n",
      "Epoch 212, Loss: 0.43549599799409766\n",
      "Epoch 213, Loss: 0.435693177425488\n",
      "Epoch 214, Loss: 0.43638716241086417\n",
      "Epoch 215, Loss: 0.43723040175969713\n",
      "Epoch 216, Loss: 0.4381875017781245\n",
      "Epoch 217, Loss: 0.43727582910411245\n",
      "Epoch 218, Loss: 0.4357251884259994\n",
      "Epoch 219, Loss: 0.43449740709117174\n",
      "Epoch 220, Loss: 0.4346007775761442\n",
      "Epoch 221, Loss: 0.4356339371912412\n",
      "Epoch 222, Loss: 0.43683657413065485\n",
      "Epoch 223, Loss: 0.43732786198111706\n",
      "Epoch 224, Loss: 0.43504045750484316\n",
      "Epoch 225, Loss: 0.4336674601818588\n",
      "Epoch 226, Loss: 0.4339570078903568\n",
      "Epoch 227, Loss: 0.43524205442250136\n",
      "Epoch 228, Loss: 0.43692856322479845\n",
      "Epoch 229, Loss: 0.4361014833656456\n",
      "Epoch 230, Loss: 0.43400818547427195\n",
      "Epoch 231, Loss: 0.43282550764678196\n",
      "Epoch 232, Loss: 0.43422302771098475\n",
      "Epoch 233, Loss: 0.43631150394157153\n",
      "Epoch 234, Loss: 0.4363944185143908\n",
      "Epoch 235, Loss: 0.4344230831071679\n",
      "Epoch 236, Loss: 0.43231983169663213\n",
      "Epoch 237, Loss: 0.4338866438813009\n",
      "Epoch 238, Loss: 0.4371328345881963\n",
      "Epoch 239, Loss: 0.4361934054316967\n",
      "Epoch 240, Loss: 0.4336558976182621\n",
      "Epoch 241, Loss: 0.432399290161847\n",
      "Epoch 242, Loss: 0.43439426928256275\n",
      "Epoch 243, Loss: 0.43607225078754297\n",
      "Epoch 244, Loss: 0.432937520696398\n",
      "Epoch 245, Loss: 0.4313183612820463\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20529901720454086\n",
      "Test R^2 score: 0.541837533531951\n",
      "Num of epochs: 246\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Epoch 179, Loss: 0.44257338842027333\n",
      "Epoch 180, Loss: 0.44223043415311275\n",
      "Epoch 181, Loss: 0.4412573335324542\n",
      "Epoch 182, Loss: 0.4403093939212056\n",
      "Epoch 183, Loss: 0.440210765892682\n",
      "Epoch 184, Loss: 0.4406913267766654\n",
      "Epoch 185, Loss: 0.44119678016972247\n",
      "Epoch 186, Loss: 0.4414768331353019\n",
      "Epoch 187, Loss: 0.44098509893198107\n",
      "Epoch 188, Loss: 0.4399157822542188\n",
      "Epoch 189, Loss: 0.43913002852403843\n",
      "Epoch 190, Loss: 0.43912120575952834\n",
      "Epoch 191, Loss: 0.43958194116248417\n",
      "Epoch 192, Loss: 0.43991779767875194\n",
      "Epoch 193, Loss: 0.4402464762584031\n",
      "Epoch 194, Loss: 0.4397939928277301\n",
      "Epoch 195, Loss: 0.4389848715145781\n",
      "Epoch 196, Loss: 0.43812834372448495\n",
      "Epoch 197, Loss: 0.4378789384628316\n",
      "Epoch 198, Loss: 0.4380569659316353\n",
      "Epoch 199, Loss: 0.4385928231376636\n",
      "Epoch 200, Loss: 0.4396870477941122\n",
      "Epoch 201, Loss: 0.44003322037003134\n",
      "Epoch 202, Loss: 0.4396387344028484\n",
      "Epoch 203, Loss: 0.43797246081508234\n",
      "Epoch 204, Loss: 0.4368868004619995\n",
      "Epoch 205, Loss: 0.4366217722212388\n",
      "Epoch 206, Loss: 0.4370735508315267\n",
      "Epoch 207, Loss: 0.438056659783102\n",
      "Epoch 208, Loss: 0.43828697608838324\n",
      "Epoch 209, Loss: 0.4380426277456835\n",
      "Epoch 210, Loss: 0.4367571723427673\n",
      "Epoch 211, Loss: 0.4358287121793394\n",
      "Epoch 212, Loss: 0.43549599799409766\n",
      "Epoch 213, Loss: 0.435693177425488\n",
      "Epoch 214, Loss: 0.43638716241086417\n",
      "Epoch 215, Loss: 0.43723040175969713\n",
      "Epoch 216, Loss: 0.4381875017781245\n",
      "Epoch 217, Loss: 0.43727582910411245\n",
      "Epoch 218, Loss: 0.4357251884259994\n",
      "Epoch 219, Loss: 0.43449740709117174\n",
      "Epoch 220, Loss: 0.4346007775761442\n",
      "Epoch 221, Loss: 0.4356339371912412\n",
      "Epoch 222, Loss: 0.43683657413065485\n",
      "Epoch 223, Loss: 0.43732786198111706\n",
      "Epoch 224, Loss: 0.43504045750484316\n",
      "Epoch 225, Loss: 0.4336674601818588\n",
      "Epoch 226, Loss: 0.4339570078903568\n",
      "Epoch 227, Loss: 0.43524205442250136\n",
      "Epoch 228, Loss: 0.43692856322479845\n",
      "Epoch 229, Loss: 0.4361014833656456\n",
      "Epoch 230, Loss: 0.43400818547427195\n",
      "Epoch 231, Loss: 0.43282550764678196\n",
      "Epoch 232, Loss: 0.43422302771098475\n",
      "Epoch 233, Loss: 0.43631150394157153\n",
      "Epoch 234, Loss: 0.4363944185143908\n",
      "Epoch 235, Loss: 0.4344230831071679\n",
      "Epoch 236, Loss: 0.43231983169663213\n",
      "Epoch 237, Loss: 0.4338866438813009\n",
      "Epoch 238, Loss: 0.4371328345881963\n",
      "Epoch 239, Loss: 0.4361934054316967\n",
      "Epoch 240, Loss: 0.4336558976182621\n",
      "Epoch 241, Loss: 0.432399290161847\n",
      "Epoch 242, Loss: 0.43439426928256275\n",
      "Epoch 243, Loss: 0.43607225078754297\n",
      "Epoch 244, Loss: 0.432937520696398\n",
      "Epoch 245, Loss: 0.4313183612820463\n",
      "Epoch 246, Loss: 0.432574819035821\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20966176151268323\n",
      "Test R^2 score: 0.5228773711337935\n",
      "Num of epochs: 247\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Epoch 179, Loss: 0.44257338842027333\n",
      "Epoch 180, Loss: 0.44223043415311275\n",
      "Epoch 181, Loss: 0.4412573335324542\n",
      "Epoch 182, Loss: 0.4403093939212056\n",
      "Epoch 183, Loss: 0.440210765892682\n",
      "Epoch 184, Loss: 0.4406913267766654\n",
      "Epoch 185, Loss: 0.44119678016972247\n",
      "Epoch 186, Loss: 0.4414768331353019\n",
      "Epoch 187, Loss: 0.44098509893198107\n",
      "Epoch 188, Loss: 0.4399157822542188\n",
      "Epoch 189, Loss: 0.43913002852403843\n",
      "Epoch 190, Loss: 0.43912120575952834\n",
      "Epoch 191, Loss: 0.43958194116248417\n",
      "Epoch 192, Loss: 0.43991779767875194\n",
      "Epoch 193, Loss: 0.4402464762584031\n",
      "Epoch 194, Loss: 0.4397939928277301\n",
      "Epoch 195, Loss: 0.4389848715145781\n",
      "Epoch 196, Loss: 0.43812834372448495\n",
      "Epoch 197, Loss: 0.4378789384628316\n",
      "Epoch 198, Loss: 0.4380569659316353\n",
      "Epoch 199, Loss: 0.4385928231376636\n",
      "Epoch 200, Loss: 0.4396870477941122\n",
      "Epoch 201, Loss: 0.44003322037003134\n",
      "Epoch 202, Loss: 0.4396387344028484\n",
      "Epoch 203, Loss: 0.43797246081508234\n",
      "Epoch 204, Loss: 0.4368868004619995\n",
      "Epoch 205, Loss: 0.4366217722212388\n",
      "Epoch 206, Loss: 0.4370735508315267\n",
      "Epoch 207, Loss: 0.438056659783102\n",
      "Epoch 208, Loss: 0.43828697608838324\n",
      "Epoch 209, Loss: 0.4380426277456835\n",
      "Epoch 210, Loss: 0.4367571723427673\n",
      "Epoch 211, Loss: 0.4358287121793394\n",
      "Epoch 212, Loss: 0.43549599799409766\n",
      "Epoch 213, Loss: 0.435693177425488\n",
      "Epoch 214, Loss: 0.43638716241086417\n",
      "Epoch 215, Loss: 0.43723040175969713\n",
      "Epoch 216, Loss: 0.4381875017781245\n",
      "Epoch 217, Loss: 0.43727582910411245\n",
      "Epoch 218, Loss: 0.4357251884259994\n",
      "Epoch 219, Loss: 0.43449740709117174\n",
      "Epoch 220, Loss: 0.4346007775761442\n",
      "Epoch 221, Loss: 0.4356339371912412\n",
      "Epoch 222, Loss: 0.43683657413065485\n",
      "Epoch 223, Loss: 0.43732786198111706\n",
      "Epoch 224, Loss: 0.43504045750484316\n",
      "Epoch 225, Loss: 0.4336674601818588\n",
      "Epoch 226, Loss: 0.4339570078903568\n",
      "Epoch 227, Loss: 0.43524205442250136\n",
      "Epoch 228, Loss: 0.43692856322479845\n",
      "Epoch 229, Loss: 0.4361014833656456\n",
      "Epoch 230, Loss: 0.43400818547427195\n",
      "Epoch 231, Loss: 0.43282550764678196\n",
      "Epoch 232, Loss: 0.43422302771098475\n",
      "Epoch 233, Loss: 0.43631150394157153\n",
      "Epoch 234, Loss: 0.4363944185143908\n",
      "Epoch 235, Loss: 0.4344230831071679\n",
      "Epoch 236, Loss: 0.43231983169663213\n",
      "Epoch 237, Loss: 0.4338866438813009\n",
      "Epoch 238, Loss: 0.4371328345881963\n",
      "Epoch 239, Loss: 0.4361934054316967\n",
      "Epoch 240, Loss: 0.4336558976182621\n",
      "Epoch 241, Loss: 0.432399290161847\n",
      "Epoch 242, Loss: 0.43439426928256275\n",
      "Epoch 243, Loss: 0.43607225078754297\n",
      "Epoch 244, Loss: 0.432937520696398\n",
      "Epoch 245, Loss: 0.4313183612820463\n",
      "Epoch 246, Loss: 0.432574819035821\n",
      "Epoch 247, Loss: 0.43256944517797463\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2051409551974392\n",
      "Test R^2 score: 0.5431930984889478\n",
      "Num of epochs: 248\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Epoch 179, Loss: 0.44257338842027333\n",
      "Epoch 180, Loss: 0.44223043415311275\n",
      "Epoch 181, Loss: 0.4412573335324542\n",
      "Epoch 182, Loss: 0.4403093939212056\n",
      "Epoch 183, Loss: 0.440210765892682\n",
      "Epoch 184, Loss: 0.4406913267766654\n",
      "Epoch 185, Loss: 0.44119678016972247\n",
      "Epoch 186, Loss: 0.4414768331353019\n",
      "Epoch 187, Loss: 0.44098509893198107\n",
      "Epoch 188, Loss: 0.4399157822542188\n",
      "Epoch 189, Loss: 0.43913002852403843\n",
      "Epoch 190, Loss: 0.43912120575952834\n",
      "Epoch 191, Loss: 0.43958194116248417\n",
      "Epoch 192, Loss: 0.43991779767875194\n",
      "Epoch 193, Loss: 0.4402464762584031\n",
      "Epoch 194, Loss: 0.4397939928277301\n",
      "Epoch 195, Loss: 0.4389848715145781\n",
      "Epoch 196, Loss: 0.43812834372448495\n",
      "Epoch 197, Loss: 0.4378789384628316\n",
      "Epoch 198, Loss: 0.4380569659316353\n",
      "Epoch 199, Loss: 0.4385928231376636\n",
      "Epoch 200, Loss: 0.4396870477941122\n",
      "Epoch 201, Loss: 0.44003322037003134\n",
      "Epoch 202, Loss: 0.4396387344028484\n",
      "Epoch 203, Loss: 0.43797246081508234\n",
      "Epoch 204, Loss: 0.4368868004619995\n",
      "Epoch 205, Loss: 0.4366217722212388\n",
      "Epoch 206, Loss: 0.4370735508315267\n",
      "Epoch 207, Loss: 0.438056659783102\n",
      "Epoch 208, Loss: 0.43828697608838324\n",
      "Epoch 209, Loss: 0.4380426277456835\n",
      "Epoch 210, Loss: 0.4367571723427673\n",
      "Epoch 211, Loss: 0.4358287121793394\n",
      "Epoch 212, Loss: 0.43549599799409766\n",
      "Epoch 213, Loss: 0.435693177425488\n",
      "Epoch 214, Loss: 0.43638716241086417\n",
      "Epoch 215, Loss: 0.43723040175969713\n",
      "Epoch 216, Loss: 0.4381875017781245\n",
      "Epoch 217, Loss: 0.43727582910411245\n",
      "Epoch 218, Loss: 0.4357251884259994\n",
      "Epoch 219, Loss: 0.43449740709117174\n",
      "Epoch 220, Loss: 0.4346007775761442\n",
      "Epoch 221, Loss: 0.4356339371912412\n",
      "Epoch 222, Loss: 0.43683657413065485\n",
      "Epoch 223, Loss: 0.43732786198111706\n",
      "Epoch 224, Loss: 0.43504045750484316\n",
      "Epoch 225, Loss: 0.4336674601818588\n",
      "Epoch 226, Loss: 0.4339570078903568\n",
      "Epoch 227, Loss: 0.43524205442250136\n",
      "Epoch 228, Loss: 0.43692856322479845\n",
      "Epoch 229, Loss: 0.4361014833656456\n",
      "Epoch 230, Loss: 0.43400818547427195\n",
      "Epoch 231, Loss: 0.43282550764678196\n",
      "Epoch 232, Loss: 0.43422302771098475\n",
      "Epoch 233, Loss: 0.43631150394157153\n",
      "Epoch 234, Loss: 0.4363944185143908\n",
      "Epoch 235, Loss: 0.4344230831071679\n",
      "Epoch 236, Loss: 0.43231983169663213\n",
      "Epoch 237, Loss: 0.4338866438813009\n",
      "Epoch 238, Loss: 0.4371328345881963\n",
      "Epoch 239, Loss: 0.4361934054316967\n",
      "Epoch 240, Loss: 0.4336558976182621\n",
      "Epoch 241, Loss: 0.432399290161847\n",
      "Epoch 242, Loss: 0.43439426928256275\n",
      "Epoch 243, Loss: 0.43607225078754297\n",
      "Epoch 244, Loss: 0.432937520696398\n",
      "Epoch 245, Loss: 0.4313183612820463\n",
      "Epoch 246, Loss: 0.432574819035821\n",
      "Epoch 247, Loss: 0.43256944517797463\n",
      "Epoch 248, Loss: 0.4313844637013701\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2058985500816261\n",
      "Test R^2 score: 0.5400672472650885\n",
      "Num of epochs: 249\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Epoch 179, Loss: 0.44257338842027333\n",
      "Epoch 180, Loss: 0.44223043415311275\n",
      "Epoch 181, Loss: 0.4412573335324542\n",
      "Epoch 182, Loss: 0.4403093939212056\n",
      "Epoch 183, Loss: 0.440210765892682\n",
      "Epoch 184, Loss: 0.4406913267766654\n",
      "Epoch 185, Loss: 0.44119678016972247\n",
      "Epoch 186, Loss: 0.4414768331353019\n",
      "Epoch 187, Loss: 0.44098509893198107\n",
      "Epoch 188, Loss: 0.4399157822542188\n",
      "Epoch 189, Loss: 0.43913002852403843\n",
      "Epoch 190, Loss: 0.43912120575952834\n",
      "Epoch 191, Loss: 0.43958194116248417\n",
      "Epoch 192, Loss: 0.43991779767875194\n",
      "Epoch 193, Loss: 0.4402464762584031\n",
      "Epoch 194, Loss: 0.4397939928277301\n",
      "Epoch 195, Loss: 0.4389848715145781\n",
      "Epoch 196, Loss: 0.43812834372448495\n",
      "Epoch 197, Loss: 0.4378789384628316\n",
      "Epoch 198, Loss: 0.4380569659316353\n",
      "Epoch 199, Loss: 0.4385928231376636\n",
      "Epoch 200, Loss: 0.4396870477941122\n",
      "Epoch 201, Loss: 0.44003322037003134\n",
      "Epoch 202, Loss: 0.4396387344028484\n",
      "Epoch 203, Loss: 0.43797246081508234\n",
      "Epoch 204, Loss: 0.4368868004619995\n",
      "Epoch 205, Loss: 0.4366217722212388\n",
      "Epoch 206, Loss: 0.4370735508315267\n",
      "Epoch 207, Loss: 0.438056659783102\n",
      "Epoch 208, Loss: 0.43828697608838324\n",
      "Epoch 209, Loss: 0.4380426277456835\n",
      "Epoch 210, Loss: 0.4367571723427673\n",
      "Epoch 211, Loss: 0.4358287121793394\n",
      "Epoch 212, Loss: 0.43549599799409766\n",
      "Epoch 213, Loss: 0.435693177425488\n",
      "Epoch 214, Loss: 0.43638716241086417\n",
      "Epoch 215, Loss: 0.43723040175969713\n",
      "Epoch 216, Loss: 0.4381875017781245\n",
      "Epoch 217, Loss: 0.43727582910411245\n",
      "Epoch 218, Loss: 0.4357251884259994\n",
      "Epoch 219, Loss: 0.43449740709117174\n",
      "Epoch 220, Loss: 0.4346007775761442\n",
      "Epoch 221, Loss: 0.4356339371912412\n",
      "Epoch 222, Loss: 0.43683657413065485\n",
      "Epoch 223, Loss: 0.43732786198111706\n",
      "Epoch 224, Loss: 0.43504045750484316\n",
      "Epoch 225, Loss: 0.4336674601818588\n",
      "Epoch 226, Loss: 0.4339570078903568\n",
      "Epoch 227, Loss: 0.43524205442250136\n",
      "Epoch 228, Loss: 0.43692856322479845\n",
      "Epoch 229, Loss: 0.4361014833656456\n",
      "Epoch 230, Loss: 0.43400818547427195\n",
      "Epoch 231, Loss: 0.43282550764678196\n",
      "Epoch 232, Loss: 0.43422302771098475\n",
      "Epoch 233, Loss: 0.43631150394157153\n",
      "Epoch 234, Loss: 0.4363944185143908\n",
      "Epoch 235, Loss: 0.4344230831071679\n",
      "Epoch 236, Loss: 0.43231983169663213\n",
      "Epoch 237, Loss: 0.4338866438813009\n",
      "Epoch 238, Loss: 0.4371328345881963\n",
      "Epoch 239, Loss: 0.4361934054316967\n",
      "Epoch 240, Loss: 0.4336558976182621\n",
      "Epoch 241, Loss: 0.432399290161847\n",
      "Epoch 242, Loss: 0.43439426928256275\n",
      "Epoch 243, Loss: 0.43607225078754297\n",
      "Epoch 244, Loss: 0.432937520696398\n",
      "Epoch 245, Loss: 0.4313183612820463\n",
      "Epoch 246, Loss: 0.432574819035821\n",
      "Epoch 247, Loss: 0.43256944517797463\n",
      "Epoch 248, Loss: 0.4313844637013701\n",
      "Epoch 249, Loss: 0.43068049739004677\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2076804790910522\n",
      "Test R^2 score: 0.5320936664045076\n",
      "Num of epochs: 250\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Epoch 179, Loss: 0.44257338842027333\n",
      "Epoch 180, Loss: 0.44223043415311275\n",
      "Epoch 181, Loss: 0.4412573335324542\n",
      "Epoch 182, Loss: 0.4403093939212056\n",
      "Epoch 183, Loss: 0.440210765892682\n",
      "Epoch 184, Loss: 0.4406913267766654\n",
      "Epoch 185, Loss: 0.44119678016972247\n",
      "Epoch 186, Loss: 0.4414768331353019\n",
      "Epoch 187, Loss: 0.44098509893198107\n",
      "Epoch 188, Loss: 0.4399157822542188\n",
      "Epoch 189, Loss: 0.43913002852403843\n",
      "Epoch 190, Loss: 0.43912120575952834\n",
      "Epoch 191, Loss: 0.43958194116248417\n",
      "Epoch 192, Loss: 0.43991779767875194\n",
      "Epoch 193, Loss: 0.4402464762584031\n",
      "Epoch 194, Loss: 0.4397939928277301\n",
      "Epoch 195, Loss: 0.4389848715145781\n",
      "Epoch 196, Loss: 0.43812834372448495\n",
      "Epoch 197, Loss: 0.4378789384628316\n",
      "Epoch 198, Loss: 0.4380569659316353\n",
      "Epoch 199, Loss: 0.4385928231376636\n",
      "Epoch 200, Loss: 0.4396870477941122\n",
      "Epoch 201, Loss: 0.44003322037003134\n",
      "Epoch 202, Loss: 0.4396387344028484\n",
      "Epoch 203, Loss: 0.43797246081508234\n",
      "Epoch 204, Loss: 0.4368868004619995\n",
      "Epoch 205, Loss: 0.4366217722212388\n",
      "Epoch 206, Loss: 0.4370735508315267\n",
      "Epoch 207, Loss: 0.438056659783102\n",
      "Epoch 208, Loss: 0.43828697608838324\n",
      "Epoch 209, Loss: 0.4380426277456835\n",
      "Epoch 210, Loss: 0.4367571723427673\n",
      "Epoch 211, Loss: 0.4358287121793394\n",
      "Epoch 212, Loss: 0.43549599799409766\n",
      "Epoch 213, Loss: 0.435693177425488\n",
      "Epoch 214, Loss: 0.43638716241086417\n",
      "Epoch 215, Loss: 0.43723040175969713\n",
      "Epoch 216, Loss: 0.4381875017781245\n",
      "Epoch 217, Loss: 0.43727582910411245\n",
      "Epoch 218, Loss: 0.4357251884259994\n",
      "Epoch 219, Loss: 0.43449740709117174\n",
      "Epoch 220, Loss: 0.4346007775761442\n",
      "Epoch 221, Loss: 0.4356339371912412\n",
      "Epoch 222, Loss: 0.43683657413065485\n",
      "Epoch 223, Loss: 0.43732786198111706\n",
      "Epoch 224, Loss: 0.43504045750484316\n",
      "Epoch 225, Loss: 0.4336674601818588\n",
      "Epoch 226, Loss: 0.4339570078903568\n",
      "Epoch 227, Loss: 0.43524205442250136\n",
      "Epoch 228, Loss: 0.43692856322479845\n",
      "Epoch 229, Loss: 0.4361014833656456\n",
      "Epoch 230, Loss: 0.43400818547427195\n",
      "Epoch 231, Loss: 0.43282550764678196\n",
      "Epoch 232, Loss: 0.43422302771098475\n",
      "Epoch 233, Loss: 0.43631150394157153\n",
      "Epoch 234, Loss: 0.4363944185143908\n",
      "Epoch 235, Loss: 0.4344230831071679\n",
      "Epoch 236, Loss: 0.43231983169663213\n",
      "Epoch 237, Loss: 0.4338866438813009\n",
      "Epoch 238, Loss: 0.4371328345881963\n",
      "Epoch 239, Loss: 0.4361934054316967\n",
      "Epoch 240, Loss: 0.4336558976182621\n",
      "Epoch 241, Loss: 0.432399290161847\n",
      "Epoch 242, Loss: 0.43439426928256275\n",
      "Epoch 243, Loss: 0.43607225078754297\n",
      "Epoch 244, Loss: 0.432937520696398\n",
      "Epoch 245, Loss: 0.4313183612820463\n",
      "Epoch 246, Loss: 0.432574819035821\n",
      "Epoch 247, Loss: 0.43256944517797463\n",
      "Epoch 248, Loss: 0.4313844637013701\n",
      "Epoch 249, Loss: 0.43068049739004677\n",
      "Epoch 250, Loss: 0.43099675551916994\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2049536143548361\n",
      "Test R^2 score: 0.543645996795602\n",
      "Num of epochs: 251\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Epoch 179, Loss: 0.44257338842027333\n",
      "Epoch 180, Loss: 0.44223043415311275\n",
      "Epoch 181, Loss: 0.4412573335324542\n",
      "Epoch 182, Loss: 0.4403093939212056\n",
      "Epoch 183, Loss: 0.440210765892682\n",
      "Epoch 184, Loss: 0.4406913267766654\n",
      "Epoch 185, Loss: 0.44119678016972247\n",
      "Epoch 186, Loss: 0.4414768331353019\n",
      "Epoch 187, Loss: 0.44098509893198107\n",
      "Epoch 188, Loss: 0.4399157822542188\n",
      "Epoch 189, Loss: 0.43913002852403843\n",
      "Epoch 190, Loss: 0.43912120575952834\n",
      "Epoch 191, Loss: 0.43958194116248417\n",
      "Epoch 192, Loss: 0.43991779767875194\n",
      "Epoch 193, Loss: 0.4402464762584031\n",
      "Epoch 194, Loss: 0.4397939928277301\n",
      "Epoch 195, Loss: 0.4389848715145781\n",
      "Epoch 196, Loss: 0.43812834372448495\n",
      "Epoch 197, Loss: 0.4378789384628316\n",
      "Epoch 198, Loss: 0.4380569659316353\n",
      "Epoch 199, Loss: 0.4385928231376636\n",
      "Epoch 200, Loss: 0.4396870477941122\n",
      "Epoch 201, Loss: 0.44003322037003134\n",
      "Epoch 202, Loss: 0.4396387344028484\n",
      "Epoch 203, Loss: 0.43797246081508234\n",
      "Epoch 204, Loss: 0.4368868004619995\n",
      "Epoch 205, Loss: 0.4366217722212388\n",
      "Epoch 206, Loss: 0.4370735508315267\n",
      "Epoch 207, Loss: 0.438056659783102\n",
      "Epoch 208, Loss: 0.43828697608838324\n",
      "Epoch 209, Loss: 0.4380426277456835\n",
      "Epoch 210, Loss: 0.4367571723427673\n",
      "Epoch 211, Loss: 0.4358287121793394\n",
      "Epoch 212, Loss: 0.43549599799409766\n",
      "Epoch 213, Loss: 0.435693177425488\n",
      "Epoch 214, Loss: 0.43638716241086417\n",
      "Epoch 215, Loss: 0.43723040175969713\n",
      "Epoch 216, Loss: 0.4381875017781245\n",
      "Epoch 217, Loss: 0.43727582910411245\n",
      "Epoch 218, Loss: 0.4357251884259994\n",
      "Epoch 219, Loss: 0.43449740709117174\n",
      "Epoch 220, Loss: 0.4346007775761442\n",
      "Epoch 221, Loss: 0.4356339371912412\n",
      "Epoch 222, Loss: 0.43683657413065485\n",
      "Epoch 223, Loss: 0.43732786198111706\n",
      "Epoch 224, Loss: 0.43504045750484316\n",
      "Epoch 225, Loss: 0.4336674601818588\n",
      "Epoch 226, Loss: 0.4339570078903568\n",
      "Epoch 227, Loss: 0.43524205442250136\n",
      "Epoch 228, Loss: 0.43692856322479845\n",
      "Epoch 229, Loss: 0.4361014833656456\n",
      "Epoch 230, Loss: 0.43400818547427195\n",
      "Epoch 231, Loss: 0.43282550764678196\n",
      "Epoch 232, Loss: 0.43422302771098475\n",
      "Epoch 233, Loss: 0.43631150394157153\n",
      "Epoch 234, Loss: 0.4363944185143908\n",
      "Epoch 235, Loss: 0.4344230831071679\n",
      "Epoch 236, Loss: 0.43231983169663213\n",
      "Epoch 237, Loss: 0.4338866438813009\n",
      "Epoch 238, Loss: 0.4371328345881963\n",
      "Epoch 239, Loss: 0.4361934054316967\n",
      "Epoch 240, Loss: 0.4336558976182621\n",
      "Epoch 241, Loss: 0.432399290161847\n",
      "Epoch 242, Loss: 0.43439426928256275\n",
      "Epoch 243, Loss: 0.43607225078754297\n",
      "Epoch 244, Loss: 0.432937520696398\n",
      "Epoch 245, Loss: 0.4313183612820463\n",
      "Epoch 246, Loss: 0.432574819035821\n",
      "Epoch 247, Loss: 0.43256944517797463\n",
      "Epoch 248, Loss: 0.4313844637013701\n",
      "Epoch 249, Loss: 0.43068049739004677\n",
      "Epoch 250, Loss: 0.43099675551916994\n",
      "Epoch 251, Loss: 0.43165141303618687\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20772010330114782\n",
      "Test R^2 score: 0.5316117783473724\n",
      "Num of epochs: 252\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Epoch 179, Loss: 0.44257338842027333\n",
      "Epoch 180, Loss: 0.44223043415311275\n",
      "Epoch 181, Loss: 0.4412573335324542\n",
      "Epoch 182, Loss: 0.4403093939212056\n",
      "Epoch 183, Loss: 0.440210765892682\n",
      "Epoch 184, Loss: 0.4406913267766654\n",
      "Epoch 185, Loss: 0.44119678016972247\n",
      "Epoch 186, Loss: 0.4414768331353019\n",
      "Epoch 187, Loss: 0.44098509893198107\n",
      "Epoch 188, Loss: 0.4399157822542188\n",
      "Epoch 189, Loss: 0.43913002852403843\n",
      "Epoch 190, Loss: 0.43912120575952834\n",
      "Epoch 191, Loss: 0.43958194116248417\n",
      "Epoch 192, Loss: 0.43991779767875194\n",
      "Epoch 193, Loss: 0.4402464762584031\n",
      "Epoch 194, Loss: 0.4397939928277301\n",
      "Epoch 195, Loss: 0.4389848715145781\n",
      "Epoch 196, Loss: 0.43812834372448495\n",
      "Epoch 197, Loss: 0.4378789384628316\n",
      "Epoch 198, Loss: 0.4380569659316353\n",
      "Epoch 199, Loss: 0.4385928231376636\n",
      "Epoch 200, Loss: 0.4396870477941122\n",
      "Epoch 201, Loss: 0.44003322037003134\n",
      "Epoch 202, Loss: 0.4396387344028484\n",
      "Epoch 203, Loss: 0.43797246081508234\n",
      "Epoch 204, Loss: 0.4368868004619995\n",
      "Epoch 205, Loss: 0.4366217722212388\n",
      "Epoch 206, Loss: 0.4370735508315267\n",
      "Epoch 207, Loss: 0.438056659783102\n",
      "Epoch 208, Loss: 0.43828697608838324\n",
      "Epoch 209, Loss: 0.4380426277456835\n",
      "Epoch 210, Loss: 0.4367571723427673\n",
      "Epoch 211, Loss: 0.4358287121793394\n",
      "Epoch 212, Loss: 0.43549599799409766\n",
      "Epoch 213, Loss: 0.435693177425488\n",
      "Epoch 214, Loss: 0.43638716241086417\n",
      "Epoch 215, Loss: 0.43723040175969713\n",
      "Epoch 216, Loss: 0.4381875017781245\n",
      "Epoch 217, Loss: 0.43727582910411245\n",
      "Epoch 218, Loss: 0.4357251884259994\n",
      "Epoch 219, Loss: 0.43449740709117174\n",
      "Epoch 220, Loss: 0.4346007775761442\n",
      "Epoch 221, Loss: 0.4356339371912412\n",
      "Epoch 222, Loss: 0.43683657413065485\n",
      "Epoch 223, Loss: 0.43732786198111706\n",
      "Epoch 224, Loss: 0.43504045750484316\n",
      "Epoch 225, Loss: 0.4336674601818588\n",
      "Epoch 226, Loss: 0.4339570078903568\n",
      "Epoch 227, Loss: 0.43524205442250136\n",
      "Epoch 228, Loss: 0.43692856322479845\n",
      "Epoch 229, Loss: 0.4361014833656456\n",
      "Epoch 230, Loss: 0.43400818547427195\n",
      "Epoch 231, Loss: 0.43282550764678196\n",
      "Epoch 232, Loss: 0.43422302771098475\n",
      "Epoch 233, Loss: 0.43631150394157153\n",
      "Epoch 234, Loss: 0.4363944185143908\n",
      "Epoch 235, Loss: 0.4344230831071679\n",
      "Epoch 236, Loss: 0.43231983169663213\n",
      "Epoch 237, Loss: 0.4338866438813009\n",
      "Epoch 238, Loss: 0.4371328345881963\n",
      "Epoch 239, Loss: 0.4361934054316967\n",
      "Epoch 240, Loss: 0.4336558976182621\n",
      "Epoch 241, Loss: 0.432399290161847\n",
      "Epoch 242, Loss: 0.43439426928256275\n",
      "Epoch 243, Loss: 0.43607225078754297\n",
      "Epoch 244, Loss: 0.432937520696398\n",
      "Epoch 245, Loss: 0.4313183612820463\n",
      "Epoch 246, Loss: 0.432574819035821\n",
      "Epoch 247, Loss: 0.43256944517797463\n",
      "Epoch 248, Loss: 0.4313844637013701\n",
      "Epoch 249, Loss: 0.43068049739004677\n",
      "Epoch 250, Loss: 0.43099675551916994\n",
      "Epoch 251, Loss: 0.43165141303618687\n",
      "Epoch 252, Loss: 0.43069838475760797\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2065552686389849\n",
      "Test R^2 score: 0.5368936124857355\n",
      "Num of epochs: 253\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Epoch 179, Loss: 0.44257338842027333\n",
      "Epoch 180, Loss: 0.44223043415311275\n",
      "Epoch 181, Loss: 0.4412573335324542\n",
      "Epoch 182, Loss: 0.4403093939212056\n",
      "Epoch 183, Loss: 0.440210765892682\n",
      "Epoch 184, Loss: 0.4406913267766654\n",
      "Epoch 185, Loss: 0.44119678016972247\n",
      "Epoch 186, Loss: 0.4414768331353019\n",
      "Epoch 187, Loss: 0.44098509893198107\n",
      "Epoch 188, Loss: 0.4399157822542188\n",
      "Epoch 189, Loss: 0.43913002852403843\n",
      "Epoch 190, Loss: 0.43912120575952834\n",
      "Epoch 191, Loss: 0.43958194116248417\n",
      "Epoch 192, Loss: 0.43991779767875194\n",
      "Epoch 193, Loss: 0.4402464762584031\n",
      "Epoch 194, Loss: 0.4397939928277301\n",
      "Epoch 195, Loss: 0.4389848715145781\n",
      "Epoch 196, Loss: 0.43812834372448495\n",
      "Epoch 197, Loss: 0.4378789384628316\n",
      "Epoch 198, Loss: 0.4380569659316353\n",
      "Epoch 199, Loss: 0.4385928231376636\n",
      "Epoch 200, Loss: 0.4396870477941122\n",
      "Epoch 201, Loss: 0.44003322037003134\n",
      "Epoch 202, Loss: 0.4396387344028484\n",
      "Epoch 203, Loss: 0.43797246081508234\n",
      "Epoch 204, Loss: 0.4368868004619995\n",
      "Epoch 205, Loss: 0.4366217722212388\n",
      "Epoch 206, Loss: 0.4370735508315267\n",
      "Epoch 207, Loss: 0.438056659783102\n",
      "Epoch 208, Loss: 0.43828697608838324\n",
      "Epoch 209, Loss: 0.4380426277456835\n",
      "Epoch 210, Loss: 0.4367571723427673\n",
      "Epoch 211, Loss: 0.4358287121793394\n",
      "Epoch 212, Loss: 0.43549599799409766\n",
      "Epoch 213, Loss: 0.435693177425488\n",
      "Epoch 214, Loss: 0.43638716241086417\n",
      "Epoch 215, Loss: 0.43723040175969713\n",
      "Epoch 216, Loss: 0.4381875017781245\n",
      "Epoch 217, Loss: 0.43727582910411245\n",
      "Epoch 218, Loss: 0.4357251884259994\n",
      "Epoch 219, Loss: 0.43449740709117174\n",
      "Epoch 220, Loss: 0.4346007775761442\n",
      "Epoch 221, Loss: 0.4356339371912412\n",
      "Epoch 222, Loss: 0.43683657413065485\n",
      "Epoch 223, Loss: 0.43732786198111706\n",
      "Epoch 224, Loss: 0.43504045750484316\n",
      "Epoch 225, Loss: 0.4336674601818588\n",
      "Epoch 226, Loss: 0.4339570078903568\n",
      "Epoch 227, Loss: 0.43524205442250136\n",
      "Epoch 228, Loss: 0.43692856322479845\n",
      "Epoch 229, Loss: 0.4361014833656456\n",
      "Epoch 230, Loss: 0.43400818547427195\n",
      "Epoch 231, Loss: 0.43282550764678196\n",
      "Epoch 232, Loss: 0.43422302771098475\n",
      "Epoch 233, Loss: 0.43631150394157153\n",
      "Epoch 234, Loss: 0.4363944185143908\n",
      "Epoch 235, Loss: 0.4344230831071679\n",
      "Epoch 236, Loss: 0.43231983169663213\n",
      "Epoch 237, Loss: 0.4338866438813009\n",
      "Epoch 238, Loss: 0.4371328345881963\n",
      "Epoch 239, Loss: 0.4361934054316967\n",
      "Epoch 240, Loss: 0.4336558976182621\n",
      "Epoch 241, Loss: 0.432399290161847\n",
      "Epoch 242, Loss: 0.43439426928256275\n",
      "Epoch 243, Loss: 0.43607225078754297\n",
      "Epoch 244, Loss: 0.432937520696398\n",
      "Epoch 245, Loss: 0.4313183612820463\n",
      "Epoch 246, Loss: 0.432574819035821\n",
      "Epoch 247, Loss: 0.43256944517797463\n",
      "Epoch 248, Loss: 0.4313844637013701\n",
      "Epoch 249, Loss: 0.43068049739004677\n",
      "Epoch 250, Loss: 0.43099675551916994\n",
      "Epoch 251, Loss: 0.43165141303618687\n",
      "Epoch 252, Loss: 0.43069838475760797\n",
      "Epoch 253, Loss: 0.4299371687594886\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20546702449711793\n",
      "Test R^2 score: 0.5416449572547799\n",
      "Num of epochs: 254\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Epoch 179, Loss: 0.44257338842027333\n",
      "Epoch 180, Loss: 0.44223043415311275\n",
      "Epoch 181, Loss: 0.4412573335324542\n",
      "Epoch 182, Loss: 0.4403093939212056\n",
      "Epoch 183, Loss: 0.440210765892682\n",
      "Epoch 184, Loss: 0.4406913267766654\n",
      "Epoch 185, Loss: 0.44119678016972247\n",
      "Epoch 186, Loss: 0.4414768331353019\n",
      "Epoch 187, Loss: 0.44098509893198107\n",
      "Epoch 188, Loss: 0.4399157822542188\n",
      "Epoch 189, Loss: 0.43913002852403843\n",
      "Epoch 190, Loss: 0.43912120575952834\n",
      "Epoch 191, Loss: 0.43958194116248417\n",
      "Epoch 192, Loss: 0.43991779767875194\n",
      "Epoch 193, Loss: 0.4402464762584031\n",
      "Epoch 194, Loss: 0.4397939928277301\n",
      "Epoch 195, Loss: 0.4389848715145781\n",
      "Epoch 196, Loss: 0.43812834372448495\n",
      "Epoch 197, Loss: 0.4378789384628316\n",
      "Epoch 198, Loss: 0.4380569659316353\n",
      "Epoch 199, Loss: 0.4385928231376636\n",
      "Epoch 200, Loss: 0.4396870477941122\n",
      "Epoch 201, Loss: 0.44003322037003134\n",
      "Epoch 202, Loss: 0.4396387344028484\n",
      "Epoch 203, Loss: 0.43797246081508234\n",
      "Epoch 204, Loss: 0.4368868004619995\n",
      "Epoch 205, Loss: 0.4366217722212388\n",
      "Epoch 206, Loss: 0.4370735508315267\n",
      "Epoch 207, Loss: 0.438056659783102\n",
      "Epoch 208, Loss: 0.43828697608838324\n",
      "Epoch 209, Loss: 0.4380426277456835\n",
      "Epoch 210, Loss: 0.4367571723427673\n",
      "Epoch 211, Loss: 0.4358287121793394\n",
      "Epoch 212, Loss: 0.43549599799409766\n",
      "Epoch 213, Loss: 0.435693177425488\n",
      "Epoch 214, Loss: 0.43638716241086417\n",
      "Epoch 215, Loss: 0.43723040175969713\n",
      "Epoch 216, Loss: 0.4381875017781245\n",
      "Epoch 217, Loss: 0.43727582910411245\n",
      "Epoch 218, Loss: 0.4357251884259994\n",
      "Epoch 219, Loss: 0.43449740709117174\n",
      "Epoch 220, Loss: 0.4346007775761442\n",
      "Epoch 221, Loss: 0.4356339371912412\n",
      "Epoch 222, Loss: 0.43683657413065485\n",
      "Epoch 223, Loss: 0.43732786198111706\n",
      "Epoch 224, Loss: 0.43504045750484316\n",
      "Epoch 225, Loss: 0.4336674601818588\n",
      "Epoch 226, Loss: 0.4339570078903568\n",
      "Epoch 227, Loss: 0.43524205442250136\n",
      "Epoch 228, Loss: 0.43692856322479845\n",
      "Epoch 229, Loss: 0.4361014833656456\n",
      "Epoch 230, Loss: 0.43400818547427195\n",
      "Epoch 231, Loss: 0.43282550764678196\n",
      "Epoch 232, Loss: 0.43422302771098475\n",
      "Epoch 233, Loss: 0.43631150394157153\n",
      "Epoch 234, Loss: 0.4363944185143908\n",
      "Epoch 235, Loss: 0.4344230831071679\n",
      "Epoch 236, Loss: 0.43231983169663213\n",
      "Epoch 237, Loss: 0.4338866438813009\n",
      "Epoch 238, Loss: 0.4371328345881963\n",
      "Epoch 239, Loss: 0.4361934054316967\n",
      "Epoch 240, Loss: 0.4336558976182621\n",
      "Epoch 241, Loss: 0.432399290161847\n",
      "Epoch 242, Loss: 0.43439426928256275\n",
      "Epoch 243, Loss: 0.43607225078754297\n",
      "Epoch 244, Loss: 0.432937520696398\n",
      "Epoch 245, Loss: 0.4313183612820463\n",
      "Epoch 246, Loss: 0.432574819035821\n",
      "Epoch 247, Loss: 0.43256944517797463\n",
      "Epoch 248, Loss: 0.4313844637013701\n",
      "Epoch 249, Loss: 0.43068049739004677\n",
      "Epoch 250, Loss: 0.43099675551916994\n",
      "Epoch 251, Loss: 0.43165141303618687\n",
      "Epoch 252, Loss: 0.43069838475760797\n",
      "Epoch 253, Loss: 0.4299371687594886\n",
      "Epoch 254, Loss: 0.43062274760638575\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2092260029251732\n",
      "Test R^2 score: 0.5250652060699486\n",
      "Num of epochs: 255\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Epoch 179, Loss: 0.44257338842027333\n",
      "Epoch 180, Loss: 0.44223043415311275\n",
      "Epoch 181, Loss: 0.4412573335324542\n",
      "Epoch 182, Loss: 0.4403093939212056\n",
      "Epoch 183, Loss: 0.440210765892682\n",
      "Epoch 184, Loss: 0.4406913267766654\n",
      "Epoch 185, Loss: 0.44119678016972247\n",
      "Epoch 186, Loss: 0.4414768331353019\n",
      "Epoch 187, Loss: 0.44098509893198107\n",
      "Epoch 188, Loss: 0.4399157822542188\n",
      "Epoch 189, Loss: 0.43913002852403843\n",
      "Epoch 190, Loss: 0.43912120575952834\n",
      "Epoch 191, Loss: 0.43958194116248417\n",
      "Epoch 192, Loss: 0.43991779767875194\n",
      "Epoch 193, Loss: 0.4402464762584031\n",
      "Epoch 194, Loss: 0.4397939928277301\n",
      "Epoch 195, Loss: 0.4389848715145781\n",
      "Epoch 196, Loss: 0.43812834372448495\n",
      "Epoch 197, Loss: 0.4378789384628316\n",
      "Epoch 198, Loss: 0.4380569659316353\n",
      "Epoch 199, Loss: 0.4385928231376636\n",
      "Epoch 200, Loss: 0.4396870477941122\n",
      "Epoch 201, Loss: 0.44003322037003134\n",
      "Epoch 202, Loss: 0.4396387344028484\n",
      "Epoch 203, Loss: 0.43797246081508234\n",
      "Epoch 204, Loss: 0.4368868004619995\n",
      "Epoch 205, Loss: 0.4366217722212388\n",
      "Epoch 206, Loss: 0.4370735508315267\n",
      "Epoch 207, Loss: 0.438056659783102\n",
      "Epoch 208, Loss: 0.43828697608838324\n",
      "Epoch 209, Loss: 0.4380426277456835\n",
      "Epoch 210, Loss: 0.4367571723427673\n",
      "Epoch 211, Loss: 0.4358287121793394\n",
      "Epoch 212, Loss: 0.43549599799409766\n",
      "Epoch 213, Loss: 0.435693177425488\n",
      "Epoch 214, Loss: 0.43638716241086417\n",
      "Epoch 215, Loss: 0.43723040175969713\n",
      "Epoch 216, Loss: 0.4381875017781245\n",
      "Epoch 217, Loss: 0.43727582910411245\n",
      "Epoch 218, Loss: 0.4357251884259994\n",
      "Epoch 219, Loss: 0.43449740709117174\n",
      "Epoch 220, Loss: 0.4346007775761442\n",
      "Epoch 221, Loss: 0.4356339371912412\n",
      "Epoch 222, Loss: 0.43683657413065485\n",
      "Epoch 223, Loss: 0.43732786198111706\n",
      "Epoch 224, Loss: 0.43504045750484316\n",
      "Epoch 225, Loss: 0.4336674601818588\n",
      "Epoch 226, Loss: 0.4339570078903568\n",
      "Epoch 227, Loss: 0.43524205442250136\n",
      "Epoch 228, Loss: 0.43692856322479845\n",
      "Epoch 229, Loss: 0.4361014833656456\n",
      "Epoch 230, Loss: 0.43400818547427195\n",
      "Epoch 231, Loss: 0.43282550764678196\n",
      "Epoch 232, Loss: 0.43422302771098475\n",
      "Epoch 233, Loss: 0.43631150394157153\n",
      "Epoch 234, Loss: 0.4363944185143908\n",
      "Epoch 235, Loss: 0.4344230831071679\n",
      "Epoch 236, Loss: 0.43231983169663213\n",
      "Epoch 237, Loss: 0.4338866438813009\n",
      "Epoch 238, Loss: 0.4371328345881963\n",
      "Epoch 239, Loss: 0.4361934054316967\n",
      "Epoch 240, Loss: 0.4336558976182621\n",
      "Epoch 241, Loss: 0.432399290161847\n",
      "Epoch 242, Loss: 0.43439426928256275\n",
      "Epoch 243, Loss: 0.43607225078754297\n",
      "Epoch 244, Loss: 0.432937520696398\n",
      "Epoch 245, Loss: 0.4313183612820463\n",
      "Epoch 246, Loss: 0.432574819035821\n",
      "Epoch 247, Loss: 0.43256944517797463\n",
      "Epoch 248, Loss: 0.4313844637013701\n",
      "Epoch 249, Loss: 0.43068049739004677\n",
      "Epoch 250, Loss: 0.43099675551916994\n",
      "Epoch 251, Loss: 0.43165141303618687\n",
      "Epoch 252, Loss: 0.43069838475760797\n",
      "Epoch 253, Loss: 0.4299371687594886\n",
      "Epoch 254, Loss: 0.43062274760638575\n",
      "Epoch 255, Loss: 0.4311277872870893\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2051929121676858\n",
      "Test R^2 score: 0.5424864264337638\n",
      "Num of epochs: 256\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Epoch 179, Loss: 0.44257338842027333\n",
      "Epoch 180, Loss: 0.44223043415311275\n",
      "Epoch 181, Loss: 0.4412573335324542\n",
      "Epoch 182, Loss: 0.4403093939212056\n",
      "Epoch 183, Loss: 0.440210765892682\n",
      "Epoch 184, Loss: 0.4406913267766654\n",
      "Epoch 185, Loss: 0.44119678016972247\n",
      "Epoch 186, Loss: 0.4414768331353019\n",
      "Epoch 187, Loss: 0.44098509893198107\n",
      "Epoch 188, Loss: 0.4399157822542188\n",
      "Epoch 189, Loss: 0.43913002852403843\n",
      "Epoch 190, Loss: 0.43912120575952834\n",
      "Epoch 191, Loss: 0.43958194116248417\n",
      "Epoch 192, Loss: 0.43991779767875194\n",
      "Epoch 193, Loss: 0.4402464762584031\n",
      "Epoch 194, Loss: 0.4397939928277301\n",
      "Epoch 195, Loss: 0.4389848715145781\n",
      "Epoch 196, Loss: 0.43812834372448495\n",
      "Epoch 197, Loss: 0.4378789384628316\n",
      "Epoch 198, Loss: 0.4380569659316353\n",
      "Epoch 199, Loss: 0.4385928231376636\n",
      "Epoch 200, Loss: 0.4396870477941122\n",
      "Epoch 201, Loss: 0.44003322037003134\n",
      "Epoch 202, Loss: 0.4396387344028484\n",
      "Epoch 203, Loss: 0.43797246081508234\n",
      "Epoch 204, Loss: 0.4368868004619995\n",
      "Epoch 205, Loss: 0.4366217722212388\n",
      "Epoch 206, Loss: 0.4370735508315267\n",
      "Epoch 207, Loss: 0.438056659783102\n",
      "Epoch 208, Loss: 0.43828697608838324\n",
      "Epoch 209, Loss: 0.4380426277456835\n",
      "Epoch 210, Loss: 0.4367571723427673\n",
      "Epoch 211, Loss: 0.4358287121793394\n",
      "Epoch 212, Loss: 0.43549599799409766\n",
      "Epoch 213, Loss: 0.435693177425488\n",
      "Epoch 214, Loss: 0.43638716241086417\n",
      "Epoch 215, Loss: 0.43723040175969713\n",
      "Epoch 216, Loss: 0.4381875017781245\n",
      "Epoch 217, Loss: 0.43727582910411245\n",
      "Epoch 218, Loss: 0.4357251884259994\n",
      "Epoch 219, Loss: 0.43449740709117174\n",
      "Epoch 220, Loss: 0.4346007775761442\n",
      "Epoch 221, Loss: 0.4356339371912412\n",
      "Epoch 222, Loss: 0.43683657413065485\n",
      "Epoch 223, Loss: 0.43732786198111706\n",
      "Epoch 224, Loss: 0.43504045750484316\n",
      "Epoch 225, Loss: 0.4336674601818588\n",
      "Epoch 226, Loss: 0.4339570078903568\n",
      "Epoch 227, Loss: 0.43524205442250136\n",
      "Epoch 228, Loss: 0.43692856322479845\n",
      "Epoch 229, Loss: 0.4361014833656456\n",
      "Epoch 230, Loss: 0.43400818547427195\n",
      "Epoch 231, Loss: 0.43282550764678196\n",
      "Epoch 232, Loss: 0.43422302771098475\n",
      "Epoch 233, Loss: 0.43631150394157153\n",
      "Epoch 234, Loss: 0.4363944185143908\n",
      "Epoch 235, Loss: 0.4344230831071679\n",
      "Epoch 236, Loss: 0.43231983169663213\n",
      "Epoch 237, Loss: 0.4338866438813009\n",
      "Epoch 238, Loss: 0.4371328345881963\n",
      "Epoch 239, Loss: 0.4361934054316967\n",
      "Epoch 240, Loss: 0.4336558976182621\n",
      "Epoch 241, Loss: 0.432399290161847\n",
      "Epoch 242, Loss: 0.43439426928256275\n",
      "Epoch 243, Loss: 0.43607225078754297\n",
      "Epoch 244, Loss: 0.432937520696398\n",
      "Epoch 245, Loss: 0.4313183612820463\n",
      "Epoch 246, Loss: 0.432574819035821\n",
      "Epoch 247, Loss: 0.43256944517797463\n",
      "Epoch 248, Loss: 0.4313844637013701\n",
      "Epoch 249, Loss: 0.43068049739004677\n",
      "Epoch 250, Loss: 0.43099675551916994\n",
      "Epoch 251, Loss: 0.43165141303618687\n",
      "Epoch 252, Loss: 0.43069838475760797\n",
      "Epoch 253, Loss: 0.4299371687594886\n",
      "Epoch 254, Loss: 0.43062274760638575\n",
      "Epoch 255, Loss: 0.4311277872870893\n",
      "Epoch 256, Loss: 0.4311714384142778\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2081311334219124\n",
      "Test R^2 score: 0.5296560567824288\n",
      "Num of epochs: 257\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Epoch 179, Loss: 0.44257338842027333\n",
      "Epoch 180, Loss: 0.44223043415311275\n",
      "Epoch 181, Loss: 0.4412573335324542\n",
      "Epoch 182, Loss: 0.4403093939212056\n",
      "Epoch 183, Loss: 0.440210765892682\n",
      "Epoch 184, Loss: 0.4406913267766654\n",
      "Epoch 185, Loss: 0.44119678016972247\n",
      "Epoch 186, Loss: 0.4414768331353019\n",
      "Epoch 187, Loss: 0.44098509893198107\n",
      "Epoch 188, Loss: 0.4399157822542188\n",
      "Epoch 189, Loss: 0.43913002852403843\n",
      "Epoch 190, Loss: 0.43912120575952834\n",
      "Epoch 191, Loss: 0.43958194116248417\n",
      "Epoch 192, Loss: 0.43991779767875194\n",
      "Epoch 193, Loss: 0.4402464762584031\n",
      "Epoch 194, Loss: 0.4397939928277301\n",
      "Epoch 195, Loss: 0.4389848715145781\n",
      "Epoch 196, Loss: 0.43812834372448495\n",
      "Epoch 197, Loss: 0.4378789384628316\n",
      "Epoch 198, Loss: 0.4380569659316353\n",
      "Epoch 199, Loss: 0.4385928231376636\n",
      "Epoch 200, Loss: 0.4396870477941122\n",
      "Epoch 201, Loss: 0.44003322037003134\n",
      "Epoch 202, Loss: 0.4396387344028484\n",
      "Epoch 203, Loss: 0.43797246081508234\n",
      "Epoch 204, Loss: 0.4368868004619995\n",
      "Epoch 205, Loss: 0.4366217722212388\n",
      "Epoch 206, Loss: 0.4370735508315267\n",
      "Epoch 207, Loss: 0.438056659783102\n",
      "Epoch 208, Loss: 0.43828697608838324\n",
      "Epoch 209, Loss: 0.4380426277456835\n",
      "Epoch 210, Loss: 0.4367571723427673\n",
      "Epoch 211, Loss: 0.4358287121793394\n",
      "Epoch 212, Loss: 0.43549599799409766\n",
      "Epoch 213, Loss: 0.435693177425488\n",
      "Epoch 214, Loss: 0.43638716241086417\n",
      "Epoch 215, Loss: 0.43723040175969713\n",
      "Epoch 216, Loss: 0.4381875017781245\n",
      "Epoch 217, Loss: 0.43727582910411245\n",
      "Epoch 218, Loss: 0.4357251884259994\n",
      "Epoch 219, Loss: 0.43449740709117174\n",
      "Epoch 220, Loss: 0.4346007775761442\n",
      "Epoch 221, Loss: 0.4356339371912412\n",
      "Epoch 222, Loss: 0.43683657413065485\n",
      "Epoch 223, Loss: 0.43732786198111706\n",
      "Epoch 224, Loss: 0.43504045750484316\n",
      "Epoch 225, Loss: 0.4336674601818588\n",
      "Epoch 226, Loss: 0.4339570078903568\n",
      "Epoch 227, Loss: 0.43524205442250136\n",
      "Epoch 228, Loss: 0.43692856322479845\n",
      "Epoch 229, Loss: 0.4361014833656456\n",
      "Epoch 230, Loss: 0.43400818547427195\n",
      "Epoch 231, Loss: 0.43282550764678196\n",
      "Epoch 232, Loss: 0.43422302771098475\n",
      "Epoch 233, Loss: 0.43631150394157153\n",
      "Epoch 234, Loss: 0.4363944185143908\n",
      "Epoch 235, Loss: 0.4344230831071679\n",
      "Epoch 236, Loss: 0.43231983169663213\n",
      "Epoch 237, Loss: 0.4338866438813009\n",
      "Epoch 238, Loss: 0.4371328345881963\n",
      "Epoch 239, Loss: 0.4361934054316967\n",
      "Epoch 240, Loss: 0.4336558976182621\n",
      "Epoch 241, Loss: 0.432399290161847\n",
      "Epoch 242, Loss: 0.43439426928256275\n",
      "Epoch 243, Loss: 0.43607225078754297\n",
      "Epoch 244, Loss: 0.432937520696398\n",
      "Epoch 245, Loss: 0.4313183612820463\n",
      "Epoch 246, Loss: 0.432574819035821\n",
      "Epoch 247, Loss: 0.43256944517797463\n",
      "Epoch 248, Loss: 0.4313844637013701\n",
      "Epoch 249, Loss: 0.43068049739004677\n",
      "Epoch 250, Loss: 0.43099675551916994\n",
      "Epoch 251, Loss: 0.43165141303618687\n",
      "Epoch 252, Loss: 0.43069838475760797\n",
      "Epoch 253, Loss: 0.4299371687594886\n",
      "Epoch 254, Loss: 0.43062274760638575\n",
      "Epoch 255, Loss: 0.4311277872870893\n",
      "Epoch 256, Loss: 0.4311714384142778\n",
      "Epoch 257, Loss: 0.43017855241729436\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20611295914278235\n",
      "Test R^2 score: 0.5386605691953488\n",
      "Num of epochs: 258\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Epoch 179, Loss: 0.44257338842027333\n",
      "Epoch 180, Loss: 0.44223043415311275\n",
      "Epoch 181, Loss: 0.4412573335324542\n",
      "Epoch 182, Loss: 0.4403093939212056\n",
      "Epoch 183, Loss: 0.440210765892682\n",
      "Epoch 184, Loss: 0.4406913267766654\n",
      "Epoch 185, Loss: 0.44119678016972247\n",
      "Epoch 186, Loss: 0.4414768331353019\n",
      "Epoch 187, Loss: 0.44098509893198107\n",
      "Epoch 188, Loss: 0.4399157822542188\n",
      "Epoch 189, Loss: 0.43913002852403843\n",
      "Epoch 190, Loss: 0.43912120575952834\n",
      "Epoch 191, Loss: 0.43958194116248417\n",
      "Epoch 192, Loss: 0.43991779767875194\n",
      "Epoch 193, Loss: 0.4402464762584031\n",
      "Epoch 194, Loss: 0.4397939928277301\n",
      "Epoch 195, Loss: 0.4389848715145781\n",
      "Epoch 196, Loss: 0.43812834372448495\n",
      "Epoch 197, Loss: 0.4378789384628316\n",
      "Epoch 198, Loss: 0.4380569659316353\n",
      "Epoch 199, Loss: 0.4385928231376636\n",
      "Epoch 200, Loss: 0.4396870477941122\n",
      "Epoch 201, Loss: 0.44003322037003134\n",
      "Epoch 202, Loss: 0.4396387344028484\n",
      "Epoch 203, Loss: 0.43797246081508234\n",
      "Epoch 204, Loss: 0.4368868004619995\n",
      "Epoch 205, Loss: 0.4366217722212388\n",
      "Epoch 206, Loss: 0.4370735508315267\n",
      "Epoch 207, Loss: 0.438056659783102\n",
      "Epoch 208, Loss: 0.43828697608838324\n",
      "Epoch 209, Loss: 0.4380426277456835\n",
      "Epoch 210, Loss: 0.4367571723427673\n",
      "Epoch 211, Loss: 0.4358287121793394\n",
      "Epoch 212, Loss: 0.43549599799409766\n",
      "Epoch 213, Loss: 0.435693177425488\n",
      "Epoch 214, Loss: 0.43638716241086417\n",
      "Epoch 215, Loss: 0.43723040175969713\n",
      "Epoch 216, Loss: 0.4381875017781245\n",
      "Epoch 217, Loss: 0.43727582910411245\n",
      "Epoch 218, Loss: 0.4357251884259994\n",
      "Epoch 219, Loss: 0.43449740709117174\n",
      "Epoch 220, Loss: 0.4346007775761442\n",
      "Epoch 221, Loss: 0.4356339371912412\n",
      "Epoch 222, Loss: 0.43683657413065485\n",
      "Epoch 223, Loss: 0.43732786198111706\n",
      "Epoch 224, Loss: 0.43504045750484316\n",
      "Epoch 225, Loss: 0.4336674601818588\n",
      "Epoch 226, Loss: 0.4339570078903568\n",
      "Epoch 227, Loss: 0.43524205442250136\n",
      "Epoch 228, Loss: 0.43692856322479845\n",
      "Epoch 229, Loss: 0.4361014833656456\n",
      "Epoch 230, Loss: 0.43400818547427195\n",
      "Epoch 231, Loss: 0.43282550764678196\n",
      "Epoch 232, Loss: 0.43422302771098475\n",
      "Epoch 233, Loss: 0.43631150394157153\n",
      "Epoch 234, Loss: 0.4363944185143908\n",
      "Epoch 235, Loss: 0.4344230831071679\n",
      "Epoch 236, Loss: 0.43231983169663213\n",
      "Epoch 237, Loss: 0.4338866438813009\n",
      "Epoch 238, Loss: 0.4371328345881963\n",
      "Epoch 239, Loss: 0.4361934054316967\n",
      "Epoch 240, Loss: 0.4336558976182621\n",
      "Epoch 241, Loss: 0.432399290161847\n",
      "Epoch 242, Loss: 0.43439426928256275\n",
      "Epoch 243, Loss: 0.43607225078754297\n",
      "Epoch 244, Loss: 0.432937520696398\n",
      "Epoch 245, Loss: 0.4313183612820463\n",
      "Epoch 246, Loss: 0.432574819035821\n",
      "Epoch 247, Loss: 0.43256944517797463\n",
      "Epoch 248, Loss: 0.4313844637013701\n",
      "Epoch 249, Loss: 0.43068049739004677\n",
      "Epoch 250, Loss: 0.43099675551916994\n",
      "Epoch 251, Loss: 0.43165141303618687\n",
      "Epoch 252, Loss: 0.43069838475760797\n",
      "Epoch 253, Loss: 0.4299371687594886\n",
      "Epoch 254, Loss: 0.43062274760638575\n",
      "Epoch 255, Loss: 0.4311277872870893\n",
      "Epoch 256, Loss: 0.4311714384142778\n",
      "Epoch 257, Loss: 0.43017855241729436\n",
      "Epoch 258, Loss: 0.42926238444708237\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20541330588086965\n",
      "Test R^2 score: 0.541812597359989\n",
      "Num of epochs: 259\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Epoch 179, Loss: 0.44257338842027333\n",
      "Epoch 180, Loss: 0.44223043415311275\n",
      "Epoch 181, Loss: 0.4412573335324542\n",
      "Epoch 182, Loss: 0.4403093939212056\n",
      "Epoch 183, Loss: 0.440210765892682\n",
      "Epoch 184, Loss: 0.4406913267766654\n",
      "Epoch 185, Loss: 0.44119678016972247\n",
      "Epoch 186, Loss: 0.4414768331353019\n",
      "Epoch 187, Loss: 0.44098509893198107\n",
      "Epoch 188, Loss: 0.4399157822542188\n",
      "Epoch 189, Loss: 0.43913002852403843\n",
      "Epoch 190, Loss: 0.43912120575952834\n",
      "Epoch 191, Loss: 0.43958194116248417\n",
      "Epoch 192, Loss: 0.43991779767875194\n",
      "Epoch 193, Loss: 0.4402464762584031\n",
      "Epoch 194, Loss: 0.4397939928277301\n",
      "Epoch 195, Loss: 0.4389848715145781\n",
      "Epoch 196, Loss: 0.43812834372448495\n",
      "Epoch 197, Loss: 0.4378789384628316\n",
      "Epoch 198, Loss: 0.4380569659316353\n",
      "Epoch 199, Loss: 0.4385928231376636\n",
      "Epoch 200, Loss: 0.4396870477941122\n",
      "Epoch 201, Loss: 0.44003322037003134\n",
      "Epoch 202, Loss: 0.4396387344028484\n",
      "Epoch 203, Loss: 0.43797246081508234\n",
      "Epoch 204, Loss: 0.4368868004619995\n",
      "Epoch 205, Loss: 0.4366217722212388\n",
      "Epoch 206, Loss: 0.4370735508315267\n",
      "Epoch 207, Loss: 0.438056659783102\n",
      "Epoch 208, Loss: 0.43828697608838324\n",
      "Epoch 209, Loss: 0.4380426277456835\n",
      "Epoch 210, Loss: 0.4367571723427673\n",
      "Epoch 211, Loss: 0.4358287121793394\n",
      "Epoch 212, Loss: 0.43549599799409766\n",
      "Epoch 213, Loss: 0.435693177425488\n",
      "Epoch 214, Loss: 0.43638716241086417\n",
      "Epoch 215, Loss: 0.43723040175969713\n",
      "Epoch 216, Loss: 0.4381875017781245\n",
      "Epoch 217, Loss: 0.43727582910411245\n",
      "Epoch 218, Loss: 0.4357251884259994\n",
      "Epoch 219, Loss: 0.43449740709117174\n",
      "Epoch 220, Loss: 0.4346007775761442\n",
      "Epoch 221, Loss: 0.4356339371912412\n",
      "Epoch 222, Loss: 0.43683657413065485\n",
      "Epoch 223, Loss: 0.43732786198111706\n",
      "Epoch 224, Loss: 0.43504045750484316\n",
      "Epoch 225, Loss: 0.4336674601818588\n",
      "Epoch 226, Loss: 0.4339570078903568\n",
      "Epoch 227, Loss: 0.43524205442250136\n",
      "Epoch 228, Loss: 0.43692856322479845\n",
      "Epoch 229, Loss: 0.4361014833656456\n",
      "Epoch 230, Loss: 0.43400818547427195\n",
      "Epoch 231, Loss: 0.43282550764678196\n",
      "Epoch 232, Loss: 0.43422302771098475\n",
      "Epoch 233, Loss: 0.43631150394157153\n",
      "Epoch 234, Loss: 0.4363944185143908\n",
      "Epoch 235, Loss: 0.4344230831071679\n",
      "Epoch 236, Loss: 0.43231983169663213\n",
      "Epoch 237, Loss: 0.4338866438813009\n",
      "Epoch 238, Loss: 0.4371328345881963\n",
      "Epoch 239, Loss: 0.4361934054316967\n",
      "Epoch 240, Loss: 0.4336558976182621\n",
      "Epoch 241, Loss: 0.432399290161847\n",
      "Epoch 242, Loss: 0.43439426928256275\n",
      "Epoch 243, Loss: 0.43607225078754297\n",
      "Epoch 244, Loss: 0.432937520696398\n",
      "Epoch 245, Loss: 0.4313183612820463\n",
      "Epoch 246, Loss: 0.432574819035821\n",
      "Epoch 247, Loss: 0.43256944517797463\n",
      "Epoch 248, Loss: 0.4313844637013701\n",
      "Epoch 249, Loss: 0.43068049739004677\n",
      "Epoch 250, Loss: 0.43099675551916994\n",
      "Epoch 251, Loss: 0.43165141303618687\n",
      "Epoch 252, Loss: 0.43069838475760797\n",
      "Epoch 253, Loss: 0.4299371687594886\n",
      "Epoch 254, Loss: 0.43062274760638575\n",
      "Epoch 255, Loss: 0.4311277872870893\n",
      "Epoch 256, Loss: 0.4311714384142778\n",
      "Epoch 257, Loss: 0.43017855241729436\n",
      "Epoch 258, Loss: 0.42926238444708237\n",
      "Epoch 259, Loss: 0.429571014567453\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20970805296457914\n",
      "Test R^2 score: 0.5227568829770504\n",
      "Num of epochs: 260\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Epoch 179, Loss: 0.44257338842027333\n",
      "Epoch 180, Loss: 0.44223043415311275\n",
      "Epoch 181, Loss: 0.4412573335324542\n",
      "Epoch 182, Loss: 0.4403093939212056\n",
      "Epoch 183, Loss: 0.440210765892682\n",
      "Epoch 184, Loss: 0.4406913267766654\n",
      "Epoch 185, Loss: 0.44119678016972247\n",
      "Epoch 186, Loss: 0.4414768331353019\n",
      "Epoch 187, Loss: 0.44098509893198107\n",
      "Epoch 188, Loss: 0.4399157822542188\n",
      "Epoch 189, Loss: 0.43913002852403843\n",
      "Epoch 190, Loss: 0.43912120575952834\n",
      "Epoch 191, Loss: 0.43958194116248417\n",
      "Epoch 192, Loss: 0.43991779767875194\n",
      "Epoch 193, Loss: 0.4402464762584031\n",
      "Epoch 194, Loss: 0.4397939928277301\n",
      "Epoch 195, Loss: 0.4389848715145781\n",
      "Epoch 196, Loss: 0.43812834372448495\n",
      "Epoch 197, Loss: 0.4378789384628316\n",
      "Epoch 198, Loss: 0.4380569659316353\n",
      "Epoch 199, Loss: 0.4385928231376636\n",
      "Epoch 200, Loss: 0.4396870477941122\n",
      "Epoch 201, Loss: 0.44003322037003134\n",
      "Epoch 202, Loss: 0.4396387344028484\n",
      "Epoch 203, Loss: 0.43797246081508234\n",
      "Epoch 204, Loss: 0.4368868004619995\n",
      "Epoch 205, Loss: 0.4366217722212388\n",
      "Epoch 206, Loss: 0.4370735508315267\n",
      "Epoch 207, Loss: 0.438056659783102\n",
      "Epoch 208, Loss: 0.43828697608838324\n",
      "Epoch 209, Loss: 0.4380426277456835\n",
      "Epoch 210, Loss: 0.4367571723427673\n",
      "Epoch 211, Loss: 0.4358287121793394\n",
      "Epoch 212, Loss: 0.43549599799409766\n",
      "Epoch 213, Loss: 0.435693177425488\n",
      "Epoch 214, Loss: 0.43638716241086417\n",
      "Epoch 215, Loss: 0.43723040175969713\n",
      "Epoch 216, Loss: 0.4381875017781245\n",
      "Epoch 217, Loss: 0.43727582910411245\n",
      "Epoch 218, Loss: 0.4357251884259994\n",
      "Epoch 219, Loss: 0.43449740709117174\n",
      "Epoch 220, Loss: 0.4346007775761442\n",
      "Epoch 221, Loss: 0.4356339371912412\n",
      "Epoch 222, Loss: 0.43683657413065485\n",
      "Epoch 223, Loss: 0.43732786198111706\n",
      "Epoch 224, Loss: 0.43504045750484316\n",
      "Epoch 225, Loss: 0.4336674601818588\n",
      "Epoch 226, Loss: 0.4339570078903568\n",
      "Epoch 227, Loss: 0.43524205442250136\n",
      "Epoch 228, Loss: 0.43692856322479845\n",
      "Epoch 229, Loss: 0.4361014833656456\n",
      "Epoch 230, Loss: 0.43400818547427195\n",
      "Epoch 231, Loss: 0.43282550764678196\n",
      "Epoch 232, Loss: 0.43422302771098475\n",
      "Epoch 233, Loss: 0.43631150394157153\n",
      "Epoch 234, Loss: 0.4363944185143908\n",
      "Epoch 235, Loss: 0.4344230831071679\n",
      "Epoch 236, Loss: 0.43231983169663213\n",
      "Epoch 237, Loss: 0.4338866438813009\n",
      "Epoch 238, Loss: 0.4371328345881963\n",
      "Epoch 239, Loss: 0.4361934054316967\n",
      "Epoch 240, Loss: 0.4336558976182621\n",
      "Epoch 241, Loss: 0.432399290161847\n",
      "Epoch 242, Loss: 0.43439426928256275\n",
      "Epoch 243, Loss: 0.43607225078754297\n",
      "Epoch 244, Loss: 0.432937520696398\n",
      "Epoch 245, Loss: 0.4313183612820463\n",
      "Epoch 246, Loss: 0.432574819035821\n",
      "Epoch 247, Loss: 0.43256944517797463\n",
      "Epoch 248, Loss: 0.4313844637013701\n",
      "Epoch 249, Loss: 0.43068049739004677\n",
      "Epoch 250, Loss: 0.43099675551916994\n",
      "Epoch 251, Loss: 0.43165141303618687\n",
      "Epoch 252, Loss: 0.43069838475760797\n",
      "Epoch 253, Loss: 0.4299371687594886\n",
      "Epoch 254, Loss: 0.43062274760638575\n",
      "Epoch 255, Loss: 0.4311277872870893\n",
      "Epoch 256, Loss: 0.4311714384142778\n",
      "Epoch 257, Loss: 0.43017855241729436\n",
      "Epoch 258, Loss: 0.42926238444708237\n",
      "Epoch 259, Loss: 0.429571014567453\n",
      "Epoch 260, Loss: 0.43070712058104565\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20589365224366166\n",
      "Test R^2 score: 0.5390808672691116\n",
      "Num of epochs: 261\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Epoch 179, Loss: 0.44257338842027333\n",
      "Epoch 180, Loss: 0.44223043415311275\n",
      "Epoch 181, Loss: 0.4412573335324542\n",
      "Epoch 182, Loss: 0.4403093939212056\n",
      "Epoch 183, Loss: 0.440210765892682\n",
      "Epoch 184, Loss: 0.4406913267766654\n",
      "Epoch 185, Loss: 0.44119678016972247\n",
      "Epoch 186, Loss: 0.4414768331353019\n",
      "Epoch 187, Loss: 0.44098509893198107\n",
      "Epoch 188, Loss: 0.4399157822542188\n",
      "Epoch 189, Loss: 0.43913002852403843\n",
      "Epoch 190, Loss: 0.43912120575952834\n",
      "Epoch 191, Loss: 0.43958194116248417\n",
      "Epoch 192, Loss: 0.43991779767875194\n",
      "Epoch 193, Loss: 0.4402464762584031\n",
      "Epoch 194, Loss: 0.4397939928277301\n",
      "Epoch 195, Loss: 0.4389848715145781\n",
      "Epoch 196, Loss: 0.43812834372448495\n",
      "Epoch 197, Loss: 0.4378789384628316\n",
      "Epoch 198, Loss: 0.4380569659316353\n",
      "Epoch 199, Loss: 0.4385928231376636\n",
      "Epoch 200, Loss: 0.4396870477941122\n",
      "Epoch 201, Loss: 0.44003322037003134\n",
      "Epoch 202, Loss: 0.4396387344028484\n",
      "Epoch 203, Loss: 0.43797246081508234\n",
      "Epoch 204, Loss: 0.4368868004619995\n",
      "Epoch 205, Loss: 0.4366217722212388\n",
      "Epoch 206, Loss: 0.4370735508315267\n",
      "Epoch 207, Loss: 0.438056659783102\n",
      "Epoch 208, Loss: 0.43828697608838324\n",
      "Epoch 209, Loss: 0.4380426277456835\n",
      "Epoch 210, Loss: 0.4367571723427673\n",
      "Epoch 211, Loss: 0.4358287121793394\n",
      "Epoch 212, Loss: 0.43549599799409766\n",
      "Epoch 213, Loss: 0.435693177425488\n",
      "Epoch 214, Loss: 0.43638716241086417\n",
      "Epoch 215, Loss: 0.43723040175969713\n",
      "Epoch 216, Loss: 0.4381875017781245\n",
      "Epoch 217, Loss: 0.43727582910411245\n",
      "Epoch 218, Loss: 0.4357251884259994\n",
      "Epoch 219, Loss: 0.43449740709117174\n",
      "Epoch 220, Loss: 0.4346007775761442\n",
      "Epoch 221, Loss: 0.4356339371912412\n",
      "Epoch 222, Loss: 0.43683657413065485\n",
      "Epoch 223, Loss: 0.43732786198111706\n",
      "Epoch 224, Loss: 0.43504045750484316\n",
      "Epoch 225, Loss: 0.4336674601818588\n",
      "Epoch 226, Loss: 0.4339570078903568\n",
      "Epoch 227, Loss: 0.43524205442250136\n",
      "Epoch 228, Loss: 0.43692856322479845\n",
      "Epoch 229, Loss: 0.4361014833656456\n",
      "Epoch 230, Loss: 0.43400818547427195\n",
      "Epoch 231, Loss: 0.43282550764678196\n",
      "Epoch 232, Loss: 0.43422302771098475\n",
      "Epoch 233, Loss: 0.43631150394157153\n",
      "Epoch 234, Loss: 0.4363944185143908\n",
      "Epoch 235, Loss: 0.4344230831071679\n",
      "Epoch 236, Loss: 0.43231983169663213\n",
      "Epoch 237, Loss: 0.4338866438813009\n",
      "Epoch 238, Loss: 0.4371328345881963\n",
      "Epoch 239, Loss: 0.4361934054316967\n",
      "Epoch 240, Loss: 0.4336558976182621\n",
      "Epoch 241, Loss: 0.432399290161847\n",
      "Epoch 242, Loss: 0.43439426928256275\n",
      "Epoch 243, Loss: 0.43607225078754297\n",
      "Epoch 244, Loss: 0.432937520696398\n",
      "Epoch 245, Loss: 0.4313183612820463\n",
      "Epoch 246, Loss: 0.432574819035821\n",
      "Epoch 247, Loss: 0.43256944517797463\n",
      "Epoch 248, Loss: 0.4313844637013701\n",
      "Epoch 249, Loss: 0.43068049739004677\n",
      "Epoch 250, Loss: 0.43099675551916994\n",
      "Epoch 251, Loss: 0.43165141303618687\n",
      "Epoch 252, Loss: 0.43069838475760797\n",
      "Epoch 253, Loss: 0.4299371687594886\n",
      "Epoch 254, Loss: 0.43062274760638575\n",
      "Epoch 255, Loss: 0.4311277872870893\n",
      "Epoch 256, Loss: 0.4311714384142778\n",
      "Epoch 257, Loss: 0.43017855241729436\n",
      "Epoch 258, Loss: 0.42926238444708237\n",
      "Epoch 259, Loss: 0.429571014567453\n",
      "Epoch 260, Loss: 0.43070712058104565\n",
      "Epoch 261, Loss: 0.4319815519144537\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21160302309947193\n",
      "Test R^2 score: 0.5138728914852325\n",
      "Num of epochs: 262\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Epoch 179, Loss: 0.44257338842027333\n",
      "Epoch 180, Loss: 0.44223043415311275\n",
      "Epoch 181, Loss: 0.4412573335324542\n",
      "Epoch 182, Loss: 0.4403093939212056\n",
      "Epoch 183, Loss: 0.440210765892682\n",
      "Epoch 184, Loss: 0.4406913267766654\n",
      "Epoch 185, Loss: 0.44119678016972247\n",
      "Epoch 186, Loss: 0.4414768331353019\n",
      "Epoch 187, Loss: 0.44098509893198107\n",
      "Epoch 188, Loss: 0.4399157822542188\n",
      "Epoch 189, Loss: 0.43913002852403843\n",
      "Epoch 190, Loss: 0.43912120575952834\n",
      "Epoch 191, Loss: 0.43958194116248417\n",
      "Epoch 192, Loss: 0.43991779767875194\n",
      "Epoch 193, Loss: 0.4402464762584031\n",
      "Epoch 194, Loss: 0.4397939928277301\n",
      "Epoch 195, Loss: 0.4389848715145781\n",
      "Epoch 196, Loss: 0.43812834372448495\n",
      "Epoch 197, Loss: 0.4378789384628316\n",
      "Epoch 198, Loss: 0.4380569659316353\n",
      "Epoch 199, Loss: 0.4385928231376636\n",
      "Epoch 200, Loss: 0.4396870477941122\n",
      "Epoch 201, Loss: 0.44003322037003134\n",
      "Epoch 202, Loss: 0.4396387344028484\n",
      "Epoch 203, Loss: 0.43797246081508234\n",
      "Epoch 204, Loss: 0.4368868004619995\n",
      "Epoch 205, Loss: 0.4366217722212388\n",
      "Epoch 206, Loss: 0.4370735508315267\n",
      "Epoch 207, Loss: 0.438056659783102\n",
      "Epoch 208, Loss: 0.43828697608838324\n",
      "Epoch 209, Loss: 0.4380426277456835\n",
      "Epoch 210, Loss: 0.4367571723427673\n",
      "Epoch 211, Loss: 0.4358287121793394\n",
      "Epoch 212, Loss: 0.43549599799409766\n",
      "Epoch 213, Loss: 0.435693177425488\n",
      "Epoch 214, Loss: 0.43638716241086417\n",
      "Epoch 215, Loss: 0.43723040175969713\n",
      "Epoch 216, Loss: 0.4381875017781245\n",
      "Epoch 217, Loss: 0.43727582910411245\n",
      "Epoch 218, Loss: 0.4357251884259994\n",
      "Epoch 219, Loss: 0.43449740709117174\n",
      "Epoch 220, Loss: 0.4346007775761442\n",
      "Epoch 221, Loss: 0.4356339371912412\n",
      "Epoch 222, Loss: 0.43683657413065485\n",
      "Epoch 223, Loss: 0.43732786198111706\n",
      "Epoch 224, Loss: 0.43504045750484316\n",
      "Epoch 225, Loss: 0.4336674601818588\n",
      "Epoch 226, Loss: 0.4339570078903568\n",
      "Epoch 227, Loss: 0.43524205442250136\n",
      "Epoch 228, Loss: 0.43692856322479845\n",
      "Epoch 229, Loss: 0.4361014833656456\n",
      "Epoch 230, Loss: 0.43400818547427195\n",
      "Epoch 231, Loss: 0.43282550764678196\n",
      "Epoch 232, Loss: 0.43422302771098475\n",
      "Epoch 233, Loss: 0.43631150394157153\n",
      "Epoch 234, Loss: 0.4363944185143908\n",
      "Epoch 235, Loss: 0.4344230831071679\n",
      "Epoch 236, Loss: 0.43231983169663213\n",
      "Epoch 237, Loss: 0.4338866438813009\n",
      "Epoch 238, Loss: 0.4371328345881963\n",
      "Epoch 239, Loss: 0.4361934054316967\n",
      "Epoch 240, Loss: 0.4336558976182621\n",
      "Epoch 241, Loss: 0.432399290161847\n",
      "Epoch 242, Loss: 0.43439426928256275\n",
      "Epoch 243, Loss: 0.43607225078754297\n",
      "Epoch 244, Loss: 0.432937520696398\n",
      "Epoch 245, Loss: 0.4313183612820463\n",
      "Epoch 246, Loss: 0.432574819035821\n",
      "Epoch 247, Loss: 0.43256944517797463\n",
      "Epoch 248, Loss: 0.4313844637013701\n",
      "Epoch 249, Loss: 0.43068049739004677\n",
      "Epoch 250, Loss: 0.43099675551916994\n",
      "Epoch 251, Loss: 0.43165141303618687\n",
      "Epoch 252, Loss: 0.43069838475760797\n",
      "Epoch 253, Loss: 0.4299371687594886\n",
      "Epoch 254, Loss: 0.43062274760638575\n",
      "Epoch 255, Loss: 0.4311277872870893\n",
      "Epoch 256, Loss: 0.4311714384142778\n",
      "Epoch 257, Loss: 0.43017855241729436\n",
      "Epoch 258, Loss: 0.42926238444708237\n",
      "Epoch 259, Loss: 0.429571014567453\n",
      "Epoch 260, Loss: 0.43070712058104565\n",
      "Epoch 261, Loss: 0.4319815519144537\n",
      "Epoch 262, Loss: 0.4316843105666133\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20552381817179605\n",
      "Test R^2 score: 0.5406661561738085\n",
      "Num of epochs: 263\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Epoch 179, Loss: 0.44257338842027333\n",
      "Epoch 180, Loss: 0.44223043415311275\n",
      "Epoch 181, Loss: 0.4412573335324542\n",
      "Epoch 182, Loss: 0.4403093939212056\n",
      "Epoch 183, Loss: 0.440210765892682\n",
      "Epoch 184, Loss: 0.4406913267766654\n",
      "Epoch 185, Loss: 0.44119678016972247\n",
      "Epoch 186, Loss: 0.4414768331353019\n",
      "Epoch 187, Loss: 0.44098509893198107\n",
      "Epoch 188, Loss: 0.4399157822542188\n",
      "Epoch 189, Loss: 0.43913002852403843\n",
      "Epoch 190, Loss: 0.43912120575952834\n",
      "Epoch 191, Loss: 0.43958194116248417\n",
      "Epoch 192, Loss: 0.43991779767875194\n",
      "Epoch 193, Loss: 0.4402464762584031\n",
      "Epoch 194, Loss: 0.4397939928277301\n",
      "Epoch 195, Loss: 0.4389848715145781\n",
      "Epoch 196, Loss: 0.43812834372448495\n",
      "Epoch 197, Loss: 0.4378789384628316\n",
      "Epoch 198, Loss: 0.4380569659316353\n",
      "Epoch 199, Loss: 0.4385928231376636\n",
      "Epoch 200, Loss: 0.4396870477941122\n",
      "Epoch 201, Loss: 0.44003322037003134\n",
      "Epoch 202, Loss: 0.4396387344028484\n",
      "Epoch 203, Loss: 0.43797246081508234\n",
      "Epoch 204, Loss: 0.4368868004619995\n",
      "Epoch 205, Loss: 0.4366217722212388\n",
      "Epoch 206, Loss: 0.4370735508315267\n",
      "Epoch 207, Loss: 0.438056659783102\n",
      "Epoch 208, Loss: 0.43828697608838324\n",
      "Epoch 209, Loss: 0.4380426277456835\n",
      "Epoch 210, Loss: 0.4367571723427673\n",
      "Epoch 211, Loss: 0.4358287121793394\n",
      "Epoch 212, Loss: 0.43549599799409766\n",
      "Epoch 213, Loss: 0.435693177425488\n",
      "Epoch 214, Loss: 0.43638716241086417\n",
      "Epoch 215, Loss: 0.43723040175969713\n",
      "Epoch 216, Loss: 0.4381875017781245\n",
      "Epoch 217, Loss: 0.43727582910411245\n",
      "Epoch 218, Loss: 0.4357251884259994\n",
      "Epoch 219, Loss: 0.43449740709117174\n",
      "Epoch 220, Loss: 0.4346007775761442\n",
      "Epoch 221, Loss: 0.4356339371912412\n",
      "Epoch 222, Loss: 0.43683657413065485\n",
      "Epoch 223, Loss: 0.43732786198111706\n",
      "Epoch 224, Loss: 0.43504045750484316\n",
      "Epoch 225, Loss: 0.4336674601818588\n",
      "Epoch 226, Loss: 0.4339570078903568\n",
      "Epoch 227, Loss: 0.43524205442250136\n",
      "Epoch 228, Loss: 0.43692856322479845\n",
      "Epoch 229, Loss: 0.4361014833656456\n",
      "Epoch 230, Loss: 0.43400818547427195\n",
      "Epoch 231, Loss: 0.43282550764678196\n",
      "Epoch 232, Loss: 0.43422302771098475\n",
      "Epoch 233, Loss: 0.43631150394157153\n",
      "Epoch 234, Loss: 0.4363944185143908\n",
      "Epoch 235, Loss: 0.4344230831071679\n",
      "Epoch 236, Loss: 0.43231983169663213\n",
      "Epoch 237, Loss: 0.4338866438813009\n",
      "Epoch 238, Loss: 0.4371328345881963\n",
      "Epoch 239, Loss: 0.4361934054316967\n",
      "Epoch 240, Loss: 0.4336558976182621\n",
      "Epoch 241, Loss: 0.432399290161847\n",
      "Epoch 242, Loss: 0.43439426928256275\n",
      "Epoch 243, Loss: 0.43607225078754297\n",
      "Epoch 244, Loss: 0.432937520696398\n",
      "Epoch 245, Loss: 0.4313183612820463\n",
      "Epoch 246, Loss: 0.432574819035821\n",
      "Epoch 247, Loss: 0.43256944517797463\n",
      "Epoch 248, Loss: 0.4313844637013701\n",
      "Epoch 249, Loss: 0.43068049739004677\n",
      "Epoch 250, Loss: 0.43099675551916994\n",
      "Epoch 251, Loss: 0.43165141303618687\n",
      "Epoch 252, Loss: 0.43069838475760797\n",
      "Epoch 253, Loss: 0.4299371687594886\n",
      "Epoch 254, Loss: 0.43062274760638575\n",
      "Epoch 255, Loss: 0.4311277872870893\n",
      "Epoch 256, Loss: 0.4311714384142778\n",
      "Epoch 257, Loss: 0.43017855241729436\n",
      "Epoch 258, Loss: 0.42926238444708237\n",
      "Epoch 259, Loss: 0.429571014567453\n",
      "Epoch 260, Loss: 0.43070712058104565\n",
      "Epoch 261, Loss: 0.4319815519144537\n",
      "Epoch 262, Loss: 0.4316843105666133\n",
      "Epoch 263, Loss: 0.4304818873122946\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20689471703892787\n",
      "Test R^2 score: 0.5352887317703006\n",
      "Num of epochs: 264\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Epoch 179, Loss: 0.44257338842027333\n",
      "Epoch 180, Loss: 0.44223043415311275\n",
      "Epoch 181, Loss: 0.4412573335324542\n",
      "Epoch 182, Loss: 0.4403093939212056\n",
      "Epoch 183, Loss: 0.440210765892682\n",
      "Epoch 184, Loss: 0.4406913267766654\n",
      "Epoch 185, Loss: 0.44119678016972247\n",
      "Epoch 186, Loss: 0.4414768331353019\n",
      "Epoch 187, Loss: 0.44098509893198107\n",
      "Epoch 188, Loss: 0.4399157822542188\n",
      "Epoch 189, Loss: 0.43913002852403843\n",
      "Epoch 190, Loss: 0.43912120575952834\n",
      "Epoch 191, Loss: 0.43958194116248417\n",
      "Epoch 192, Loss: 0.43991779767875194\n",
      "Epoch 193, Loss: 0.4402464762584031\n",
      "Epoch 194, Loss: 0.4397939928277301\n",
      "Epoch 195, Loss: 0.4389848715145781\n",
      "Epoch 196, Loss: 0.43812834372448495\n",
      "Epoch 197, Loss: 0.4378789384628316\n",
      "Epoch 198, Loss: 0.4380569659316353\n",
      "Epoch 199, Loss: 0.4385928231376636\n",
      "Epoch 200, Loss: 0.4396870477941122\n",
      "Epoch 201, Loss: 0.44003322037003134\n",
      "Epoch 202, Loss: 0.4396387344028484\n",
      "Epoch 203, Loss: 0.43797246081508234\n",
      "Epoch 204, Loss: 0.4368868004619995\n",
      "Epoch 205, Loss: 0.4366217722212388\n",
      "Epoch 206, Loss: 0.4370735508315267\n",
      "Epoch 207, Loss: 0.438056659783102\n",
      "Epoch 208, Loss: 0.43828697608838324\n",
      "Epoch 209, Loss: 0.4380426277456835\n",
      "Epoch 210, Loss: 0.4367571723427673\n",
      "Epoch 211, Loss: 0.4358287121793394\n",
      "Epoch 212, Loss: 0.43549599799409766\n",
      "Epoch 213, Loss: 0.435693177425488\n",
      "Epoch 214, Loss: 0.43638716241086417\n",
      "Epoch 215, Loss: 0.43723040175969713\n",
      "Epoch 216, Loss: 0.4381875017781245\n",
      "Epoch 217, Loss: 0.43727582910411245\n",
      "Epoch 218, Loss: 0.4357251884259994\n",
      "Epoch 219, Loss: 0.43449740709117174\n",
      "Epoch 220, Loss: 0.4346007775761442\n",
      "Epoch 221, Loss: 0.4356339371912412\n",
      "Epoch 222, Loss: 0.43683657413065485\n",
      "Epoch 223, Loss: 0.43732786198111706\n",
      "Epoch 224, Loss: 0.43504045750484316\n",
      "Epoch 225, Loss: 0.4336674601818588\n",
      "Epoch 226, Loss: 0.4339570078903568\n",
      "Epoch 227, Loss: 0.43524205442250136\n",
      "Epoch 228, Loss: 0.43692856322479845\n",
      "Epoch 229, Loss: 0.4361014833656456\n",
      "Epoch 230, Loss: 0.43400818547427195\n",
      "Epoch 231, Loss: 0.43282550764678196\n",
      "Epoch 232, Loss: 0.43422302771098475\n",
      "Epoch 233, Loss: 0.43631150394157153\n",
      "Epoch 234, Loss: 0.4363944185143908\n",
      "Epoch 235, Loss: 0.4344230831071679\n",
      "Epoch 236, Loss: 0.43231983169663213\n",
      "Epoch 237, Loss: 0.4338866438813009\n",
      "Epoch 238, Loss: 0.4371328345881963\n",
      "Epoch 239, Loss: 0.4361934054316967\n",
      "Epoch 240, Loss: 0.4336558976182621\n",
      "Epoch 241, Loss: 0.432399290161847\n",
      "Epoch 242, Loss: 0.43439426928256275\n",
      "Epoch 243, Loss: 0.43607225078754297\n",
      "Epoch 244, Loss: 0.432937520696398\n",
      "Epoch 245, Loss: 0.4313183612820463\n",
      "Epoch 246, Loss: 0.432574819035821\n",
      "Epoch 247, Loss: 0.43256944517797463\n",
      "Epoch 248, Loss: 0.4313844637013701\n",
      "Epoch 249, Loss: 0.43068049739004677\n",
      "Epoch 250, Loss: 0.43099675551916994\n",
      "Epoch 251, Loss: 0.43165141303618687\n",
      "Epoch 252, Loss: 0.43069838475760797\n",
      "Epoch 253, Loss: 0.4299371687594886\n",
      "Epoch 254, Loss: 0.43062274760638575\n",
      "Epoch 255, Loss: 0.4311277872870893\n",
      "Epoch 256, Loss: 0.4311714384142778\n",
      "Epoch 257, Loss: 0.43017855241729436\n",
      "Epoch 258, Loss: 0.42926238444708237\n",
      "Epoch 259, Loss: 0.429571014567453\n",
      "Epoch 260, Loss: 0.43070712058104565\n",
      "Epoch 261, Loss: 0.4319815519144537\n",
      "Epoch 262, Loss: 0.4316843105666133\n",
      "Epoch 263, Loss: 0.4304818873122946\n",
      "Epoch 264, Loss: 0.42840412257514504\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20816948243600172\n",
      "Test R^2 score: 0.5298640499629582\n",
      "Num of epochs: 265\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Epoch 179, Loss: 0.44257338842027333\n",
      "Epoch 180, Loss: 0.44223043415311275\n",
      "Epoch 181, Loss: 0.4412573335324542\n",
      "Epoch 182, Loss: 0.4403093939212056\n",
      "Epoch 183, Loss: 0.440210765892682\n",
      "Epoch 184, Loss: 0.4406913267766654\n",
      "Epoch 185, Loss: 0.44119678016972247\n",
      "Epoch 186, Loss: 0.4414768331353019\n",
      "Epoch 187, Loss: 0.44098509893198107\n",
      "Epoch 188, Loss: 0.4399157822542188\n",
      "Epoch 189, Loss: 0.43913002852403843\n",
      "Epoch 190, Loss: 0.43912120575952834\n",
      "Epoch 191, Loss: 0.43958194116248417\n",
      "Epoch 192, Loss: 0.43991779767875194\n",
      "Epoch 193, Loss: 0.4402464762584031\n",
      "Epoch 194, Loss: 0.4397939928277301\n",
      "Epoch 195, Loss: 0.4389848715145781\n",
      "Epoch 196, Loss: 0.43812834372448495\n",
      "Epoch 197, Loss: 0.4378789384628316\n",
      "Epoch 198, Loss: 0.4380569659316353\n",
      "Epoch 199, Loss: 0.4385928231376636\n",
      "Epoch 200, Loss: 0.4396870477941122\n",
      "Epoch 201, Loss: 0.44003322037003134\n",
      "Epoch 202, Loss: 0.4396387344028484\n",
      "Epoch 203, Loss: 0.43797246081508234\n",
      "Epoch 204, Loss: 0.4368868004619995\n",
      "Epoch 205, Loss: 0.4366217722212388\n",
      "Epoch 206, Loss: 0.4370735508315267\n",
      "Epoch 207, Loss: 0.438056659783102\n",
      "Epoch 208, Loss: 0.43828697608838324\n",
      "Epoch 209, Loss: 0.4380426277456835\n",
      "Epoch 210, Loss: 0.4367571723427673\n",
      "Epoch 211, Loss: 0.4358287121793394\n",
      "Epoch 212, Loss: 0.43549599799409766\n",
      "Epoch 213, Loss: 0.435693177425488\n",
      "Epoch 214, Loss: 0.43638716241086417\n",
      "Epoch 215, Loss: 0.43723040175969713\n",
      "Epoch 216, Loss: 0.4381875017781245\n",
      "Epoch 217, Loss: 0.43727582910411245\n",
      "Epoch 218, Loss: 0.4357251884259994\n",
      "Epoch 219, Loss: 0.43449740709117174\n",
      "Epoch 220, Loss: 0.4346007775761442\n",
      "Epoch 221, Loss: 0.4356339371912412\n",
      "Epoch 222, Loss: 0.43683657413065485\n",
      "Epoch 223, Loss: 0.43732786198111706\n",
      "Epoch 224, Loss: 0.43504045750484316\n",
      "Epoch 225, Loss: 0.4336674601818588\n",
      "Epoch 226, Loss: 0.4339570078903568\n",
      "Epoch 227, Loss: 0.43524205442250136\n",
      "Epoch 228, Loss: 0.43692856322479845\n",
      "Epoch 229, Loss: 0.4361014833656456\n",
      "Epoch 230, Loss: 0.43400818547427195\n",
      "Epoch 231, Loss: 0.43282550764678196\n",
      "Epoch 232, Loss: 0.43422302771098475\n",
      "Epoch 233, Loss: 0.43631150394157153\n",
      "Epoch 234, Loss: 0.4363944185143908\n",
      "Epoch 235, Loss: 0.4344230831071679\n",
      "Epoch 236, Loss: 0.43231983169663213\n",
      "Epoch 237, Loss: 0.4338866438813009\n",
      "Epoch 238, Loss: 0.4371328345881963\n",
      "Epoch 239, Loss: 0.4361934054316967\n",
      "Epoch 240, Loss: 0.4336558976182621\n",
      "Epoch 241, Loss: 0.432399290161847\n",
      "Epoch 242, Loss: 0.43439426928256275\n",
      "Epoch 243, Loss: 0.43607225078754297\n",
      "Epoch 244, Loss: 0.432937520696398\n",
      "Epoch 245, Loss: 0.4313183612820463\n",
      "Epoch 246, Loss: 0.432574819035821\n",
      "Epoch 247, Loss: 0.43256944517797463\n",
      "Epoch 248, Loss: 0.4313844637013701\n",
      "Epoch 249, Loss: 0.43068049739004677\n",
      "Epoch 250, Loss: 0.43099675551916994\n",
      "Epoch 251, Loss: 0.43165141303618687\n",
      "Epoch 252, Loss: 0.43069838475760797\n",
      "Epoch 253, Loss: 0.4299371687594886\n",
      "Epoch 254, Loss: 0.43062274760638575\n",
      "Epoch 255, Loss: 0.4311277872870893\n",
      "Epoch 256, Loss: 0.4311714384142778\n",
      "Epoch 257, Loss: 0.43017855241729436\n",
      "Epoch 258, Loss: 0.42926238444708237\n",
      "Epoch 259, Loss: 0.429571014567453\n",
      "Epoch 260, Loss: 0.43070712058104565\n",
      "Epoch 261, Loss: 0.4319815519144537\n",
      "Epoch 262, Loss: 0.4316843105666133\n",
      "Epoch 263, Loss: 0.4304818873122946\n",
      "Epoch 264, Loss: 0.42840412257514504\n",
      "Epoch 265, Loss: 0.42906400353820484\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20573948890630753\n",
      "Test R^2 score: 0.5400401004195\n",
      "Num of epochs: 266\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Epoch 179, Loss: 0.44257338842027333\n",
      "Epoch 180, Loss: 0.44223043415311275\n",
      "Epoch 181, Loss: 0.4412573335324542\n",
      "Epoch 182, Loss: 0.4403093939212056\n",
      "Epoch 183, Loss: 0.440210765892682\n",
      "Epoch 184, Loss: 0.4406913267766654\n",
      "Epoch 185, Loss: 0.44119678016972247\n",
      "Epoch 186, Loss: 0.4414768331353019\n",
      "Epoch 187, Loss: 0.44098509893198107\n",
      "Epoch 188, Loss: 0.4399157822542188\n",
      "Epoch 189, Loss: 0.43913002852403843\n",
      "Epoch 190, Loss: 0.43912120575952834\n",
      "Epoch 191, Loss: 0.43958194116248417\n",
      "Epoch 192, Loss: 0.43991779767875194\n",
      "Epoch 193, Loss: 0.4402464762584031\n",
      "Epoch 194, Loss: 0.4397939928277301\n",
      "Epoch 195, Loss: 0.4389848715145781\n",
      "Epoch 196, Loss: 0.43812834372448495\n",
      "Epoch 197, Loss: 0.4378789384628316\n",
      "Epoch 198, Loss: 0.4380569659316353\n",
      "Epoch 199, Loss: 0.4385928231376636\n",
      "Epoch 200, Loss: 0.4396870477941122\n",
      "Epoch 201, Loss: 0.44003322037003134\n",
      "Epoch 202, Loss: 0.4396387344028484\n",
      "Epoch 203, Loss: 0.43797246081508234\n",
      "Epoch 204, Loss: 0.4368868004619995\n",
      "Epoch 205, Loss: 0.4366217722212388\n",
      "Epoch 206, Loss: 0.4370735508315267\n",
      "Epoch 207, Loss: 0.438056659783102\n",
      "Epoch 208, Loss: 0.43828697608838324\n",
      "Epoch 209, Loss: 0.4380426277456835\n",
      "Epoch 210, Loss: 0.4367571723427673\n",
      "Epoch 211, Loss: 0.4358287121793394\n",
      "Epoch 212, Loss: 0.43549599799409766\n",
      "Epoch 213, Loss: 0.435693177425488\n",
      "Epoch 214, Loss: 0.43638716241086417\n",
      "Epoch 215, Loss: 0.43723040175969713\n",
      "Epoch 216, Loss: 0.4381875017781245\n",
      "Epoch 217, Loss: 0.43727582910411245\n",
      "Epoch 218, Loss: 0.4357251884259994\n",
      "Epoch 219, Loss: 0.43449740709117174\n",
      "Epoch 220, Loss: 0.4346007775761442\n",
      "Epoch 221, Loss: 0.4356339371912412\n",
      "Epoch 222, Loss: 0.43683657413065485\n",
      "Epoch 223, Loss: 0.43732786198111706\n",
      "Epoch 224, Loss: 0.43504045750484316\n",
      "Epoch 225, Loss: 0.4336674601818588\n",
      "Epoch 226, Loss: 0.4339570078903568\n",
      "Epoch 227, Loss: 0.43524205442250136\n",
      "Epoch 228, Loss: 0.43692856322479845\n",
      "Epoch 229, Loss: 0.4361014833656456\n",
      "Epoch 230, Loss: 0.43400818547427195\n",
      "Epoch 231, Loss: 0.43282550764678196\n",
      "Epoch 232, Loss: 0.43422302771098475\n",
      "Epoch 233, Loss: 0.43631150394157153\n",
      "Epoch 234, Loss: 0.4363944185143908\n",
      "Epoch 235, Loss: 0.4344230831071679\n",
      "Epoch 236, Loss: 0.43231983169663213\n",
      "Epoch 237, Loss: 0.4338866438813009\n",
      "Epoch 238, Loss: 0.4371328345881963\n",
      "Epoch 239, Loss: 0.4361934054316967\n",
      "Epoch 240, Loss: 0.4336558976182621\n",
      "Epoch 241, Loss: 0.432399290161847\n",
      "Epoch 242, Loss: 0.43439426928256275\n",
      "Epoch 243, Loss: 0.43607225078754297\n",
      "Epoch 244, Loss: 0.432937520696398\n",
      "Epoch 245, Loss: 0.4313183612820463\n",
      "Epoch 246, Loss: 0.432574819035821\n",
      "Epoch 247, Loss: 0.43256944517797463\n",
      "Epoch 248, Loss: 0.4313844637013701\n",
      "Epoch 249, Loss: 0.43068049739004677\n",
      "Epoch 250, Loss: 0.43099675551916994\n",
      "Epoch 251, Loss: 0.43165141303618687\n",
      "Epoch 252, Loss: 0.43069838475760797\n",
      "Epoch 253, Loss: 0.4299371687594886\n",
      "Epoch 254, Loss: 0.43062274760638575\n",
      "Epoch 255, Loss: 0.4311277872870893\n",
      "Epoch 256, Loss: 0.4311714384142778\n",
      "Epoch 257, Loss: 0.43017855241729436\n",
      "Epoch 258, Loss: 0.42926238444708237\n",
      "Epoch 259, Loss: 0.429571014567453\n",
      "Epoch 260, Loss: 0.43070712058104565\n",
      "Epoch 261, Loss: 0.4319815519144537\n",
      "Epoch 262, Loss: 0.4316843105666133\n",
      "Epoch 263, Loss: 0.4304818873122946\n",
      "Epoch 264, Loss: 0.42840412257514504\n",
      "Epoch 265, Loss: 0.42906400353820484\n",
      "Epoch 266, Loss: 0.43117263072273004\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21327130593633306\n",
      "Test R^2 score: 0.5061464085292953\n",
      "Num of epochs: 267\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Epoch 179, Loss: 0.44257338842027333\n",
      "Epoch 180, Loss: 0.44223043415311275\n",
      "Epoch 181, Loss: 0.4412573335324542\n",
      "Epoch 182, Loss: 0.4403093939212056\n",
      "Epoch 183, Loss: 0.440210765892682\n",
      "Epoch 184, Loss: 0.4406913267766654\n",
      "Epoch 185, Loss: 0.44119678016972247\n",
      "Epoch 186, Loss: 0.4414768331353019\n",
      "Epoch 187, Loss: 0.44098509893198107\n",
      "Epoch 188, Loss: 0.4399157822542188\n",
      "Epoch 189, Loss: 0.43913002852403843\n",
      "Epoch 190, Loss: 0.43912120575952834\n",
      "Epoch 191, Loss: 0.43958194116248417\n",
      "Epoch 192, Loss: 0.43991779767875194\n",
      "Epoch 193, Loss: 0.4402464762584031\n",
      "Epoch 194, Loss: 0.4397939928277301\n",
      "Epoch 195, Loss: 0.4389848715145781\n",
      "Epoch 196, Loss: 0.43812834372448495\n",
      "Epoch 197, Loss: 0.4378789384628316\n",
      "Epoch 198, Loss: 0.4380569659316353\n",
      "Epoch 199, Loss: 0.4385928231376636\n",
      "Epoch 200, Loss: 0.4396870477941122\n",
      "Epoch 201, Loss: 0.44003322037003134\n",
      "Epoch 202, Loss: 0.4396387344028484\n",
      "Epoch 203, Loss: 0.43797246081508234\n",
      "Epoch 204, Loss: 0.4368868004619995\n",
      "Epoch 205, Loss: 0.4366217722212388\n",
      "Epoch 206, Loss: 0.4370735508315267\n",
      "Epoch 207, Loss: 0.438056659783102\n",
      "Epoch 208, Loss: 0.43828697608838324\n",
      "Epoch 209, Loss: 0.4380426277456835\n",
      "Epoch 210, Loss: 0.4367571723427673\n",
      "Epoch 211, Loss: 0.4358287121793394\n",
      "Epoch 212, Loss: 0.43549599799409766\n",
      "Epoch 213, Loss: 0.435693177425488\n",
      "Epoch 214, Loss: 0.43638716241086417\n",
      "Epoch 215, Loss: 0.43723040175969713\n",
      "Epoch 216, Loss: 0.4381875017781245\n",
      "Epoch 217, Loss: 0.43727582910411245\n",
      "Epoch 218, Loss: 0.4357251884259994\n",
      "Epoch 219, Loss: 0.43449740709117174\n",
      "Epoch 220, Loss: 0.4346007775761442\n",
      "Epoch 221, Loss: 0.4356339371912412\n",
      "Epoch 222, Loss: 0.43683657413065485\n",
      "Epoch 223, Loss: 0.43732786198111706\n",
      "Epoch 224, Loss: 0.43504045750484316\n",
      "Epoch 225, Loss: 0.4336674601818588\n",
      "Epoch 226, Loss: 0.4339570078903568\n",
      "Epoch 227, Loss: 0.43524205442250136\n",
      "Epoch 228, Loss: 0.43692856322479845\n",
      "Epoch 229, Loss: 0.4361014833656456\n",
      "Epoch 230, Loss: 0.43400818547427195\n",
      "Epoch 231, Loss: 0.43282550764678196\n",
      "Epoch 232, Loss: 0.43422302771098475\n",
      "Epoch 233, Loss: 0.43631150394157153\n",
      "Epoch 234, Loss: 0.4363944185143908\n",
      "Epoch 235, Loss: 0.4344230831071679\n",
      "Epoch 236, Loss: 0.43231983169663213\n",
      "Epoch 237, Loss: 0.4338866438813009\n",
      "Epoch 238, Loss: 0.4371328345881963\n",
      "Epoch 239, Loss: 0.4361934054316967\n",
      "Epoch 240, Loss: 0.4336558976182621\n",
      "Epoch 241, Loss: 0.432399290161847\n",
      "Epoch 242, Loss: 0.43439426928256275\n",
      "Epoch 243, Loss: 0.43607225078754297\n",
      "Epoch 244, Loss: 0.432937520696398\n",
      "Epoch 245, Loss: 0.4313183612820463\n",
      "Epoch 246, Loss: 0.432574819035821\n",
      "Epoch 247, Loss: 0.43256944517797463\n",
      "Epoch 248, Loss: 0.4313844637013701\n",
      "Epoch 249, Loss: 0.43068049739004677\n",
      "Epoch 250, Loss: 0.43099675551916994\n",
      "Epoch 251, Loss: 0.43165141303618687\n",
      "Epoch 252, Loss: 0.43069838475760797\n",
      "Epoch 253, Loss: 0.4299371687594886\n",
      "Epoch 254, Loss: 0.43062274760638575\n",
      "Epoch 255, Loss: 0.4311277872870893\n",
      "Epoch 256, Loss: 0.4311714384142778\n",
      "Epoch 257, Loss: 0.43017855241729436\n",
      "Epoch 258, Loss: 0.42926238444708237\n",
      "Epoch 259, Loss: 0.429571014567453\n",
      "Epoch 260, Loss: 0.43070712058104565\n",
      "Epoch 261, Loss: 0.4319815519144537\n",
      "Epoch 262, Loss: 0.4316843105666133\n",
      "Epoch 263, Loss: 0.4304818873122946\n",
      "Epoch 264, Loss: 0.42840412257514504\n",
      "Epoch 265, Loss: 0.42906400353820484\n",
      "Epoch 266, Loss: 0.43117263072273004\n",
      "Epoch 267, Loss: 0.4324830925949777\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20630846897915664\n",
      "Test R^2 score: 0.5367811648403282\n",
      "Num of epochs: 268\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Epoch 179, Loss: 0.44257338842027333\n",
      "Epoch 180, Loss: 0.44223043415311275\n",
      "Epoch 181, Loss: 0.4412573335324542\n",
      "Epoch 182, Loss: 0.4403093939212056\n",
      "Epoch 183, Loss: 0.440210765892682\n",
      "Epoch 184, Loss: 0.4406913267766654\n",
      "Epoch 185, Loss: 0.44119678016972247\n",
      "Epoch 186, Loss: 0.4414768331353019\n",
      "Epoch 187, Loss: 0.44098509893198107\n",
      "Epoch 188, Loss: 0.4399157822542188\n",
      "Epoch 189, Loss: 0.43913002852403843\n",
      "Epoch 190, Loss: 0.43912120575952834\n",
      "Epoch 191, Loss: 0.43958194116248417\n",
      "Epoch 192, Loss: 0.43991779767875194\n",
      "Epoch 193, Loss: 0.4402464762584031\n",
      "Epoch 194, Loss: 0.4397939928277301\n",
      "Epoch 195, Loss: 0.4389848715145781\n",
      "Epoch 196, Loss: 0.43812834372448495\n",
      "Epoch 197, Loss: 0.4378789384628316\n",
      "Epoch 198, Loss: 0.4380569659316353\n",
      "Epoch 199, Loss: 0.4385928231376636\n",
      "Epoch 200, Loss: 0.4396870477941122\n",
      "Epoch 201, Loss: 0.44003322037003134\n",
      "Epoch 202, Loss: 0.4396387344028484\n",
      "Epoch 203, Loss: 0.43797246081508234\n",
      "Epoch 204, Loss: 0.4368868004619995\n",
      "Epoch 205, Loss: 0.4366217722212388\n",
      "Epoch 206, Loss: 0.4370735508315267\n",
      "Epoch 207, Loss: 0.438056659783102\n",
      "Epoch 208, Loss: 0.43828697608838324\n",
      "Epoch 209, Loss: 0.4380426277456835\n",
      "Epoch 210, Loss: 0.4367571723427673\n",
      "Epoch 211, Loss: 0.4358287121793394\n",
      "Epoch 212, Loss: 0.43549599799409766\n",
      "Epoch 213, Loss: 0.435693177425488\n",
      "Epoch 214, Loss: 0.43638716241086417\n",
      "Epoch 215, Loss: 0.43723040175969713\n",
      "Epoch 216, Loss: 0.4381875017781245\n",
      "Epoch 217, Loss: 0.43727582910411245\n",
      "Epoch 218, Loss: 0.4357251884259994\n",
      "Epoch 219, Loss: 0.43449740709117174\n",
      "Epoch 220, Loss: 0.4346007775761442\n",
      "Epoch 221, Loss: 0.4356339371912412\n",
      "Epoch 222, Loss: 0.43683657413065485\n",
      "Epoch 223, Loss: 0.43732786198111706\n",
      "Epoch 224, Loss: 0.43504045750484316\n",
      "Epoch 225, Loss: 0.4336674601818588\n",
      "Epoch 226, Loss: 0.4339570078903568\n",
      "Epoch 227, Loss: 0.43524205442250136\n",
      "Epoch 228, Loss: 0.43692856322479845\n",
      "Epoch 229, Loss: 0.4361014833656456\n",
      "Epoch 230, Loss: 0.43400818547427195\n",
      "Epoch 231, Loss: 0.43282550764678196\n",
      "Epoch 232, Loss: 0.43422302771098475\n",
      "Epoch 233, Loss: 0.43631150394157153\n",
      "Epoch 234, Loss: 0.4363944185143908\n",
      "Epoch 235, Loss: 0.4344230831071679\n",
      "Epoch 236, Loss: 0.43231983169663213\n",
      "Epoch 237, Loss: 0.4338866438813009\n",
      "Epoch 238, Loss: 0.4371328345881963\n",
      "Epoch 239, Loss: 0.4361934054316967\n",
      "Epoch 240, Loss: 0.4336558976182621\n",
      "Epoch 241, Loss: 0.432399290161847\n",
      "Epoch 242, Loss: 0.43439426928256275\n",
      "Epoch 243, Loss: 0.43607225078754297\n",
      "Epoch 244, Loss: 0.432937520696398\n",
      "Epoch 245, Loss: 0.4313183612820463\n",
      "Epoch 246, Loss: 0.432574819035821\n",
      "Epoch 247, Loss: 0.43256944517797463\n",
      "Epoch 248, Loss: 0.4313844637013701\n",
      "Epoch 249, Loss: 0.43068049739004677\n",
      "Epoch 250, Loss: 0.43099675551916994\n",
      "Epoch 251, Loss: 0.43165141303618687\n",
      "Epoch 252, Loss: 0.43069838475760797\n",
      "Epoch 253, Loss: 0.4299371687594886\n",
      "Epoch 254, Loss: 0.43062274760638575\n",
      "Epoch 255, Loss: 0.4311277872870893\n",
      "Epoch 256, Loss: 0.4311714384142778\n",
      "Epoch 257, Loss: 0.43017855241729436\n",
      "Epoch 258, Loss: 0.42926238444708237\n",
      "Epoch 259, Loss: 0.429571014567453\n",
      "Epoch 260, Loss: 0.43070712058104565\n",
      "Epoch 261, Loss: 0.4319815519144537\n",
      "Epoch 262, Loss: 0.4316843105666133\n",
      "Epoch 263, Loss: 0.4304818873122946\n",
      "Epoch 264, Loss: 0.42840412257514504\n",
      "Epoch 265, Loss: 0.42906400353820484\n",
      "Epoch 266, Loss: 0.43117263072273004\n",
      "Epoch 267, Loss: 0.4324830925949777\n",
      "Epoch 268, Loss: 0.432065642300335\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20807977277897763\n",
      "Test R^2 score: 0.5297211072020084\n",
      "Num of epochs: 269\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Epoch 179, Loss: 0.44257338842027333\n",
      "Epoch 180, Loss: 0.44223043415311275\n",
      "Epoch 181, Loss: 0.4412573335324542\n",
      "Epoch 182, Loss: 0.4403093939212056\n",
      "Epoch 183, Loss: 0.440210765892682\n",
      "Epoch 184, Loss: 0.4406913267766654\n",
      "Epoch 185, Loss: 0.44119678016972247\n",
      "Epoch 186, Loss: 0.4414768331353019\n",
      "Epoch 187, Loss: 0.44098509893198107\n",
      "Epoch 188, Loss: 0.4399157822542188\n",
      "Epoch 189, Loss: 0.43913002852403843\n",
      "Epoch 190, Loss: 0.43912120575952834\n",
      "Epoch 191, Loss: 0.43958194116248417\n",
      "Epoch 192, Loss: 0.43991779767875194\n",
      "Epoch 193, Loss: 0.4402464762584031\n",
      "Epoch 194, Loss: 0.4397939928277301\n",
      "Epoch 195, Loss: 0.4389848715145781\n",
      "Epoch 196, Loss: 0.43812834372448495\n",
      "Epoch 197, Loss: 0.4378789384628316\n",
      "Epoch 198, Loss: 0.4380569659316353\n",
      "Epoch 199, Loss: 0.4385928231376636\n",
      "Epoch 200, Loss: 0.4396870477941122\n",
      "Epoch 201, Loss: 0.44003322037003134\n",
      "Epoch 202, Loss: 0.4396387344028484\n",
      "Epoch 203, Loss: 0.43797246081508234\n",
      "Epoch 204, Loss: 0.4368868004619995\n",
      "Epoch 205, Loss: 0.4366217722212388\n",
      "Epoch 206, Loss: 0.4370735508315267\n",
      "Epoch 207, Loss: 0.438056659783102\n",
      "Epoch 208, Loss: 0.43828697608838324\n",
      "Epoch 209, Loss: 0.4380426277456835\n",
      "Epoch 210, Loss: 0.4367571723427673\n",
      "Epoch 211, Loss: 0.4358287121793394\n",
      "Epoch 212, Loss: 0.43549599799409766\n",
      "Epoch 213, Loss: 0.435693177425488\n",
      "Epoch 214, Loss: 0.43638716241086417\n",
      "Epoch 215, Loss: 0.43723040175969713\n",
      "Epoch 216, Loss: 0.4381875017781245\n",
      "Epoch 217, Loss: 0.43727582910411245\n",
      "Epoch 218, Loss: 0.4357251884259994\n",
      "Epoch 219, Loss: 0.43449740709117174\n",
      "Epoch 220, Loss: 0.4346007775761442\n",
      "Epoch 221, Loss: 0.4356339371912412\n",
      "Epoch 222, Loss: 0.43683657413065485\n",
      "Epoch 223, Loss: 0.43732786198111706\n",
      "Epoch 224, Loss: 0.43504045750484316\n",
      "Epoch 225, Loss: 0.4336674601818588\n",
      "Epoch 226, Loss: 0.4339570078903568\n",
      "Epoch 227, Loss: 0.43524205442250136\n",
      "Epoch 228, Loss: 0.43692856322479845\n",
      "Epoch 229, Loss: 0.4361014833656456\n",
      "Epoch 230, Loss: 0.43400818547427195\n",
      "Epoch 231, Loss: 0.43282550764678196\n",
      "Epoch 232, Loss: 0.43422302771098475\n",
      "Epoch 233, Loss: 0.43631150394157153\n",
      "Epoch 234, Loss: 0.4363944185143908\n",
      "Epoch 235, Loss: 0.4344230831071679\n",
      "Epoch 236, Loss: 0.43231983169663213\n",
      "Epoch 237, Loss: 0.4338866438813009\n",
      "Epoch 238, Loss: 0.4371328345881963\n",
      "Epoch 239, Loss: 0.4361934054316967\n",
      "Epoch 240, Loss: 0.4336558976182621\n",
      "Epoch 241, Loss: 0.432399290161847\n",
      "Epoch 242, Loss: 0.43439426928256275\n",
      "Epoch 243, Loss: 0.43607225078754297\n",
      "Epoch 244, Loss: 0.432937520696398\n",
      "Epoch 245, Loss: 0.4313183612820463\n",
      "Epoch 246, Loss: 0.432574819035821\n",
      "Epoch 247, Loss: 0.43256944517797463\n",
      "Epoch 248, Loss: 0.4313844637013701\n",
      "Epoch 249, Loss: 0.43068049739004677\n",
      "Epoch 250, Loss: 0.43099675551916994\n",
      "Epoch 251, Loss: 0.43165141303618687\n",
      "Epoch 252, Loss: 0.43069838475760797\n",
      "Epoch 253, Loss: 0.4299371687594886\n",
      "Epoch 254, Loss: 0.43062274760638575\n",
      "Epoch 255, Loss: 0.4311277872870893\n",
      "Epoch 256, Loss: 0.4311714384142778\n",
      "Epoch 257, Loss: 0.43017855241729436\n",
      "Epoch 258, Loss: 0.42926238444708237\n",
      "Epoch 259, Loss: 0.429571014567453\n",
      "Epoch 260, Loss: 0.43070712058104565\n",
      "Epoch 261, Loss: 0.4319815519144537\n",
      "Epoch 262, Loss: 0.4316843105666133\n",
      "Epoch 263, Loss: 0.4304818873122946\n",
      "Epoch 264, Loss: 0.42840412257514504\n",
      "Epoch 265, Loss: 0.42906400353820484\n",
      "Epoch 266, Loss: 0.43117263072273004\n",
      "Epoch 267, Loss: 0.4324830925949777\n",
      "Epoch 268, Loss: 0.432065642300335\n",
      "Epoch 269, Loss: 0.42821550526406094\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20890396954407559\n",
      "Test R^2 score: 0.5263867947858911\n",
      "Num of epochs: 270\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Epoch 179, Loss: 0.44257338842027333\n",
      "Epoch 180, Loss: 0.44223043415311275\n",
      "Epoch 181, Loss: 0.4412573335324542\n",
      "Epoch 182, Loss: 0.4403093939212056\n",
      "Epoch 183, Loss: 0.440210765892682\n",
      "Epoch 184, Loss: 0.4406913267766654\n",
      "Epoch 185, Loss: 0.44119678016972247\n",
      "Epoch 186, Loss: 0.4414768331353019\n",
      "Epoch 187, Loss: 0.44098509893198107\n",
      "Epoch 188, Loss: 0.4399157822542188\n",
      "Epoch 189, Loss: 0.43913002852403843\n",
      "Epoch 190, Loss: 0.43912120575952834\n",
      "Epoch 191, Loss: 0.43958194116248417\n",
      "Epoch 192, Loss: 0.43991779767875194\n",
      "Epoch 193, Loss: 0.4402464762584031\n",
      "Epoch 194, Loss: 0.4397939928277301\n",
      "Epoch 195, Loss: 0.4389848715145781\n",
      "Epoch 196, Loss: 0.43812834372448495\n",
      "Epoch 197, Loss: 0.4378789384628316\n",
      "Epoch 198, Loss: 0.4380569659316353\n",
      "Epoch 199, Loss: 0.4385928231376636\n",
      "Epoch 200, Loss: 0.4396870477941122\n",
      "Epoch 201, Loss: 0.44003322037003134\n",
      "Epoch 202, Loss: 0.4396387344028484\n",
      "Epoch 203, Loss: 0.43797246081508234\n",
      "Epoch 204, Loss: 0.4368868004619995\n",
      "Epoch 205, Loss: 0.4366217722212388\n",
      "Epoch 206, Loss: 0.4370735508315267\n",
      "Epoch 207, Loss: 0.438056659783102\n",
      "Epoch 208, Loss: 0.43828697608838324\n",
      "Epoch 209, Loss: 0.4380426277456835\n",
      "Epoch 210, Loss: 0.4367571723427673\n",
      "Epoch 211, Loss: 0.4358287121793394\n",
      "Epoch 212, Loss: 0.43549599799409766\n",
      "Epoch 213, Loss: 0.435693177425488\n",
      "Epoch 214, Loss: 0.43638716241086417\n",
      "Epoch 215, Loss: 0.43723040175969713\n",
      "Epoch 216, Loss: 0.4381875017781245\n",
      "Epoch 217, Loss: 0.43727582910411245\n",
      "Epoch 218, Loss: 0.4357251884259994\n",
      "Epoch 219, Loss: 0.43449740709117174\n",
      "Epoch 220, Loss: 0.4346007775761442\n",
      "Epoch 221, Loss: 0.4356339371912412\n",
      "Epoch 222, Loss: 0.43683657413065485\n",
      "Epoch 223, Loss: 0.43732786198111706\n",
      "Epoch 224, Loss: 0.43504045750484316\n",
      "Epoch 225, Loss: 0.4336674601818588\n",
      "Epoch 226, Loss: 0.4339570078903568\n",
      "Epoch 227, Loss: 0.43524205442250136\n",
      "Epoch 228, Loss: 0.43692856322479845\n",
      "Epoch 229, Loss: 0.4361014833656456\n",
      "Epoch 230, Loss: 0.43400818547427195\n",
      "Epoch 231, Loss: 0.43282550764678196\n",
      "Epoch 232, Loss: 0.43422302771098475\n",
      "Epoch 233, Loss: 0.43631150394157153\n",
      "Epoch 234, Loss: 0.4363944185143908\n",
      "Epoch 235, Loss: 0.4344230831071679\n",
      "Epoch 236, Loss: 0.43231983169663213\n",
      "Epoch 237, Loss: 0.4338866438813009\n",
      "Epoch 238, Loss: 0.4371328345881963\n",
      "Epoch 239, Loss: 0.4361934054316967\n",
      "Epoch 240, Loss: 0.4336558976182621\n",
      "Epoch 241, Loss: 0.432399290161847\n",
      "Epoch 242, Loss: 0.43439426928256275\n",
      "Epoch 243, Loss: 0.43607225078754297\n",
      "Epoch 244, Loss: 0.432937520696398\n",
      "Epoch 245, Loss: 0.4313183612820463\n",
      "Epoch 246, Loss: 0.432574819035821\n",
      "Epoch 247, Loss: 0.43256944517797463\n",
      "Epoch 248, Loss: 0.4313844637013701\n",
      "Epoch 249, Loss: 0.43068049739004677\n",
      "Epoch 250, Loss: 0.43099675551916994\n",
      "Epoch 251, Loss: 0.43165141303618687\n",
      "Epoch 252, Loss: 0.43069838475760797\n",
      "Epoch 253, Loss: 0.4299371687594886\n",
      "Epoch 254, Loss: 0.43062274760638575\n",
      "Epoch 255, Loss: 0.4311277872870893\n",
      "Epoch 256, Loss: 0.4311714384142778\n",
      "Epoch 257, Loss: 0.43017855241729436\n",
      "Epoch 258, Loss: 0.42926238444708237\n",
      "Epoch 259, Loss: 0.429571014567453\n",
      "Epoch 260, Loss: 0.43070712058104565\n",
      "Epoch 261, Loss: 0.4319815519144537\n",
      "Epoch 262, Loss: 0.4316843105666133\n",
      "Epoch 263, Loss: 0.4304818873122946\n",
      "Epoch 264, Loss: 0.42840412257514504\n",
      "Epoch 265, Loss: 0.42906400353820484\n",
      "Epoch 266, Loss: 0.43117263072273004\n",
      "Epoch 267, Loss: 0.4324830925949777\n",
      "Epoch 268, Loss: 0.432065642300335\n",
      "Epoch 269, Loss: 0.42821550526406094\n",
      "Epoch 270, Loss: 0.42857532485258004\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20635753670797338\n",
      "Test R^2 score: 0.5371482744459108\n",
      "Num of epochs: 271\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Epoch 179, Loss: 0.44257338842027333\n",
      "Epoch 180, Loss: 0.44223043415311275\n",
      "Epoch 181, Loss: 0.4412573335324542\n",
      "Epoch 182, Loss: 0.4403093939212056\n",
      "Epoch 183, Loss: 0.440210765892682\n",
      "Epoch 184, Loss: 0.4406913267766654\n",
      "Epoch 185, Loss: 0.44119678016972247\n",
      "Epoch 186, Loss: 0.4414768331353019\n",
      "Epoch 187, Loss: 0.44098509893198107\n",
      "Epoch 188, Loss: 0.4399157822542188\n",
      "Epoch 189, Loss: 0.43913002852403843\n",
      "Epoch 190, Loss: 0.43912120575952834\n",
      "Epoch 191, Loss: 0.43958194116248417\n",
      "Epoch 192, Loss: 0.43991779767875194\n",
      "Epoch 193, Loss: 0.4402464762584031\n",
      "Epoch 194, Loss: 0.4397939928277301\n",
      "Epoch 195, Loss: 0.4389848715145781\n",
      "Epoch 196, Loss: 0.43812834372448495\n",
      "Epoch 197, Loss: 0.4378789384628316\n",
      "Epoch 198, Loss: 0.4380569659316353\n",
      "Epoch 199, Loss: 0.4385928231376636\n",
      "Epoch 200, Loss: 0.4396870477941122\n",
      "Epoch 201, Loss: 0.44003322037003134\n",
      "Epoch 202, Loss: 0.4396387344028484\n",
      "Epoch 203, Loss: 0.43797246081508234\n",
      "Epoch 204, Loss: 0.4368868004619995\n",
      "Epoch 205, Loss: 0.4366217722212388\n",
      "Epoch 206, Loss: 0.4370735508315267\n",
      "Epoch 207, Loss: 0.438056659783102\n",
      "Epoch 208, Loss: 0.43828697608838324\n",
      "Epoch 209, Loss: 0.4380426277456835\n",
      "Epoch 210, Loss: 0.4367571723427673\n",
      "Epoch 211, Loss: 0.4358287121793394\n",
      "Epoch 212, Loss: 0.43549599799409766\n",
      "Epoch 213, Loss: 0.435693177425488\n",
      "Epoch 214, Loss: 0.43638716241086417\n",
      "Epoch 215, Loss: 0.43723040175969713\n",
      "Epoch 216, Loss: 0.4381875017781245\n",
      "Epoch 217, Loss: 0.43727582910411245\n",
      "Epoch 218, Loss: 0.4357251884259994\n",
      "Epoch 219, Loss: 0.43449740709117174\n",
      "Epoch 220, Loss: 0.4346007775761442\n",
      "Epoch 221, Loss: 0.4356339371912412\n",
      "Epoch 222, Loss: 0.43683657413065485\n",
      "Epoch 223, Loss: 0.43732786198111706\n",
      "Epoch 224, Loss: 0.43504045750484316\n",
      "Epoch 225, Loss: 0.4336674601818588\n",
      "Epoch 226, Loss: 0.4339570078903568\n",
      "Epoch 227, Loss: 0.43524205442250136\n",
      "Epoch 228, Loss: 0.43692856322479845\n",
      "Epoch 229, Loss: 0.4361014833656456\n",
      "Epoch 230, Loss: 0.43400818547427195\n",
      "Epoch 231, Loss: 0.43282550764678196\n",
      "Epoch 232, Loss: 0.43422302771098475\n",
      "Epoch 233, Loss: 0.43631150394157153\n",
      "Epoch 234, Loss: 0.4363944185143908\n",
      "Epoch 235, Loss: 0.4344230831071679\n",
      "Epoch 236, Loss: 0.43231983169663213\n",
      "Epoch 237, Loss: 0.4338866438813009\n",
      "Epoch 238, Loss: 0.4371328345881963\n",
      "Epoch 239, Loss: 0.4361934054316967\n",
      "Epoch 240, Loss: 0.4336558976182621\n",
      "Epoch 241, Loss: 0.432399290161847\n",
      "Epoch 242, Loss: 0.43439426928256275\n",
      "Epoch 243, Loss: 0.43607225078754297\n",
      "Epoch 244, Loss: 0.432937520696398\n",
      "Epoch 245, Loss: 0.4313183612820463\n",
      "Epoch 246, Loss: 0.432574819035821\n",
      "Epoch 247, Loss: 0.43256944517797463\n",
      "Epoch 248, Loss: 0.4313844637013701\n",
      "Epoch 249, Loss: 0.43068049739004677\n",
      "Epoch 250, Loss: 0.43099675551916994\n",
      "Epoch 251, Loss: 0.43165141303618687\n",
      "Epoch 252, Loss: 0.43069838475760797\n",
      "Epoch 253, Loss: 0.4299371687594886\n",
      "Epoch 254, Loss: 0.43062274760638575\n",
      "Epoch 255, Loss: 0.4311277872870893\n",
      "Epoch 256, Loss: 0.4311714384142778\n",
      "Epoch 257, Loss: 0.43017855241729436\n",
      "Epoch 258, Loss: 0.42926238444708237\n",
      "Epoch 259, Loss: 0.429571014567453\n",
      "Epoch 260, Loss: 0.43070712058104565\n",
      "Epoch 261, Loss: 0.4319815519144537\n",
      "Epoch 262, Loss: 0.4316843105666133\n",
      "Epoch 263, Loss: 0.4304818873122946\n",
      "Epoch 264, Loss: 0.42840412257514504\n",
      "Epoch 265, Loss: 0.42906400353820484\n",
      "Epoch 266, Loss: 0.43117263072273004\n",
      "Epoch 267, Loss: 0.4324830925949777\n",
      "Epoch 268, Loss: 0.432065642300335\n",
      "Epoch 269, Loss: 0.42821550526406094\n",
      "Epoch 270, Loss: 0.42857532485258004\n",
      "Epoch 271, Loss: 0.43234967987659256\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21483537210921505\n",
      "Test R^2 score: 0.4988607472108424\n",
      "Num of epochs: 272\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Epoch 179, Loss: 0.44257338842027333\n",
      "Epoch 180, Loss: 0.44223043415311275\n",
      "Epoch 181, Loss: 0.4412573335324542\n",
      "Epoch 182, Loss: 0.4403093939212056\n",
      "Epoch 183, Loss: 0.440210765892682\n",
      "Epoch 184, Loss: 0.4406913267766654\n",
      "Epoch 185, Loss: 0.44119678016972247\n",
      "Epoch 186, Loss: 0.4414768331353019\n",
      "Epoch 187, Loss: 0.44098509893198107\n",
      "Epoch 188, Loss: 0.4399157822542188\n",
      "Epoch 189, Loss: 0.43913002852403843\n",
      "Epoch 190, Loss: 0.43912120575952834\n",
      "Epoch 191, Loss: 0.43958194116248417\n",
      "Epoch 192, Loss: 0.43991779767875194\n",
      "Epoch 193, Loss: 0.4402464762584031\n",
      "Epoch 194, Loss: 0.4397939928277301\n",
      "Epoch 195, Loss: 0.4389848715145781\n",
      "Epoch 196, Loss: 0.43812834372448495\n",
      "Epoch 197, Loss: 0.4378789384628316\n",
      "Epoch 198, Loss: 0.4380569659316353\n",
      "Epoch 199, Loss: 0.4385928231376636\n",
      "Epoch 200, Loss: 0.4396870477941122\n",
      "Epoch 201, Loss: 0.44003322037003134\n",
      "Epoch 202, Loss: 0.4396387344028484\n",
      "Epoch 203, Loss: 0.43797246081508234\n",
      "Epoch 204, Loss: 0.4368868004619995\n",
      "Epoch 205, Loss: 0.4366217722212388\n",
      "Epoch 206, Loss: 0.4370735508315267\n",
      "Epoch 207, Loss: 0.438056659783102\n",
      "Epoch 208, Loss: 0.43828697608838324\n",
      "Epoch 209, Loss: 0.4380426277456835\n",
      "Epoch 210, Loss: 0.4367571723427673\n",
      "Epoch 211, Loss: 0.4358287121793394\n",
      "Epoch 212, Loss: 0.43549599799409766\n",
      "Epoch 213, Loss: 0.435693177425488\n",
      "Epoch 214, Loss: 0.43638716241086417\n",
      "Epoch 215, Loss: 0.43723040175969713\n",
      "Epoch 216, Loss: 0.4381875017781245\n",
      "Epoch 217, Loss: 0.43727582910411245\n",
      "Epoch 218, Loss: 0.4357251884259994\n",
      "Epoch 219, Loss: 0.43449740709117174\n",
      "Epoch 220, Loss: 0.4346007775761442\n",
      "Epoch 221, Loss: 0.4356339371912412\n",
      "Epoch 222, Loss: 0.43683657413065485\n",
      "Epoch 223, Loss: 0.43732786198111706\n",
      "Epoch 224, Loss: 0.43504045750484316\n",
      "Epoch 225, Loss: 0.4336674601818588\n",
      "Epoch 226, Loss: 0.4339570078903568\n",
      "Epoch 227, Loss: 0.43524205442250136\n",
      "Epoch 228, Loss: 0.43692856322479845\n",
      "Epoch 229, Loss: 0.4361014833656456\n",
      "Epoch 230, Loss: 0.43400818547427195\n",
      "Epoch 231, Loss: 0.43282550764678196\n",
      "Epoch 232, Loss: 0.43422302771098475\n",
      "Epoch 233, Loss: 0.43631150394157153\n",
      "Epoch 234, Loss: 0.4363944185143908\n",
      "Epoch 235, Loss: 0.4344230831071679\n",
      "Epoch 236, Loss: 0.43231983169663213\n",
      "Epoch 237, Loss: 0.4338866438813009\n",
      "Epoch 238, Loss: 0.4371328345881963\n",
      "Epoch 239, Loss: 0.4361934054316967\n",
      "Epoch 240, Loss: 0.4336558976182621\n",
      "Epoch 241, Loss: 0.432399290161847\n",
      "Epoch 242, Loss: 0.43439426928256275\n",
      "Epoch 243, Loss: 0.43607225078754297\n",
      "Epoch 244, Loss: 0.432937520696398\n",
      "Epoch 245, Loss: 0.4313183612820463\n",
      "Epoch 246, Loss: 0.432574819035821\n",
      "Epoch 247, Loss: 0.43256944517797463\n",
      "Epoch 248, Loss: 0.4313844637013701\n",
      "Epoch 249, Loss: 0.43068049739004677\n",
      "Epoch 250, Loss: 0.43099675551916994\n",
      "Epoch 251, Loss: 0.43165141303618687\n",
      "Epoch 252, Loss: 0.43069838475760797\n",
      "Epoch 253, Loss: 0.4299371687594886\n",
      "Epoch 254, Loss: 0.43062274760638575\n",
      "Epoch 255, Loss: 0.4311277872870893\n",
      "Epoch 256, Loss: 0.4311714384142778\n",
      "Epoch 257, Loss: 0.43017855241729436\n",
      "Epoch 258, Loss: 0.42926238444708237\n",
      "Epoch 259, Loss: 0.429571014567453\n",
      "Epoch 260, Loss: 0.43070712058104565\n",
      "Epoch 261, Loss: 0.4319815519144537\n",
      "Epoch 262, Loss: 0.4316843105666133\n",
      "Epoch 263, Loss: 0.4304818873122946\n",
      "Epoch 264, Loss: 0.42840412257514504\n",
      "Epoch 265, Loss: 0.42906400353820484\n",
      "Epoch 266, Loss: 0.43117263072273004\n",
      "Epoch 267, Loss: 0.4324830925949777\n",
      "Epoch 268, Loss: 0.432065642300335\n",
      "Epoch 269, Loss: 0.42821550526406094\n",
      "Epoch 270, Loss: 0.42857532485258004\n",
      "Epoch 271, Loss: 0.43234967987659256\n",
      "Epoch 272, Loss: 0.4333620913145171\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2063933484837769\n",
      "Test R^2 score: 0.5363429376843987\n",
      "Num of epochs: 273\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Epoch 179, Loss: 0.44257338842027333\n",
      "Epoch 180, Loss: 0.44223043415311275\n",
      "Epoch 181, Loss: 0.4412573335324542\n",
      "Epoch 182, Loss: 0.4403093939212056\n",
      "Epoch 183, Loss: 0.440210765892682\n",
      "Epoch 184, Loss: 0.4406913267766654\n",
      "Epoch 185, Loss: 0.44119678016972247\n",
      "Epoch 186, Loss: 0.4414768331353019\n",
      "Epoch 187, Loss: 0.44098509893198107\n",
      "Epoch 188, Loss: 0.4399157822542188\n",
      "Epoch 189, Loss: 0.43913002852403843\n",
      "Epoch 190, Loss: 0.43912120575952834\n",
      "Epoch 191, Loss: 0.43958194116248417\n",
      "Epoch 192, Loss: 0.43991779767875194\n",
      "Epoch 193, Loss: 0.4402464762584031\n",
      "Epoch 194, Loss: 0.4397939928277301\n",
      "Epoch 195, Loss: 0.4389848715145781\n",
      "Epoch 196, Loss: 0.43812834372448495\n",
      "Epoch 197, Loss: 0.4378789384628316\n",
      "Epoch 198, Loss: 0.4380569659316353\n",
      "Epoch 199, Loss: 0.4385928231376636\n",
      "Epoch 200, Loss: 0.4396870477941122\n",
      "Epoch 201, Loss: 0.44003322037003134\n",
      "Epoch 202, Loss: 0.4396387344028484\n",
      "Epoch 203, Loss: 0.43797246081508234\n",
      "Epoch 204, Loss: 0.4368868004619995\n",
      "Epoch 205, Loss: 0.4366217722212388\n",
      "Epoch 206, Loss: 0.4370735508315267\n",
      "Epoch 207, Loss: 0.438056659783102\n",
      "Epoch 208, Loss: 0.43828697608838324\n",
      "Epoch 209, Loss: 0.4380426277456835\n",
      "Epoch 210, Loss: 0.4367571723427673\n",
      "Epoch 211, Loss: 0.4358287121793394\n",
      "Epoch 212, Loss: 0.43549599799409766\n",
      "Epoch 213, Loss: 0.435693177425488\n",
      "Epoch 214, Loss: 0.43638716241086417\n",
      "Epoch 215, Loss: 0.43723040175969713\n",
      "Epoch 216, Loss: 0.4381875017781245\n",
      "Epoch 217, Loss: 0.43727582910411245\n",
      "Epoch 218, Loss: 0.4357251884259994\n",
      "Epoch 219, Loss: 0.43449740709117174\n",
      "Epoch 220, Loss: 0.4346007775761442\n",
      "Epoch 221, Loss: 0.4356339371912412\n",
      "Epoch 222, Loss: 0.43683657413065485\n",
      "Epoch 223, Loss: 0.43732786198111706\n",
      "Epoch 224, Loss: 0.43504045750484316\n",
      "Epoch 225, Loss: 0.4336674601818588\n",
      "Epoch 226, Loss: 0.4339570078903568\n",
      "Epoch 227, Loss: 0.43524205442250136\n",
      "Epoch 228, Loss: 0.43692856322479845\n",
      "Epoch 229, Loss: 0.4361014833656456\n",
      "Epoch 230, Loss: 0.43400818547427195\n",
      "Epoch 231, Loss: 0.43282550764678196\n",
      "Epoch 232, Loss: 0.43422302771098475\n",
      "Epoch 233, Loss: 0.43631150394157153\n",
      "Epoch 234, Loss: 0.4363944185143908\n",
      "Epoch 235, Loss: 0.4344230831071679\n",
      "Epoch 236, Loss: 0.43231983169663213\n",
      "Epoch 237, Loss: 0.4338866438813009\n",
      "Epoch 238, Loss: 0.4371328345881963\n",
      "Epoch 239, Loss: 0.4361934054316967\n",
      "Epoch 240, Loss: 0.4336558976182621\n",
      "Epoch 241, Loss: 0.432399290161847\n",
      "Epoch 242, Loss: 0.43439426928256275\n",
      "Epoch 243, Loss: 0.43607225078754297\n",
      "Epoch 244, Loss: 0.432937520696398\n",
      "Epoch 245, Loss: 0.4313183612820463\n",
      "Epoch 246, Loss: 0.432574819035821\n",
      "Epoch 247, Loss: 0.43256944517797463\n",
      "Epoch 248, Loss: 0.4313844637013701\n",
      "Epoch 249, Loss: 0.43068049739004677\n",
      "Epoch 250, Loss: 0.43099675551916994\n",
      "Epoch 251, Loss: 0.43165141303618687\n",
      "Epoch 252, Loss: 0.43069838475760797\n",
      "Epoch 253, Loss: 0.4299371687594886\n",
      "Epoch 254, Loss: 0.43062274760638575\n",
      "Epoch 255, Loss: 0.4311277872870893\n",
      "Epoch 256, Loss: 0.4311714384142778\n",
      "Epoch 257, Loss: 0.43017855241729436\n",
      "Epoch 258, Loss: 0.42926238444708237\n",
      "Epoch 259, Loss: 0.429571014567453\n",
      "Epoch 260, Loss: 0.43070712058104565\n",
      "Epoch 261, Loss: 0.4319815519144537\n",
      "Epoch 262, Loss: 0.4316843105666133\n",
      "Epoch 263, Loss: 0.4304818873122946\n",
      "Epoch 264, Loss: 0.42840412257514504\n",
      "Epoch 265, Loss: 0.42906400353820484\n",
      "Epoch 266, Loss: 0.43117263072273004\n",
      "Epoch 267, Loss: 0.4324830925949777\n",
      "Epoch 268, Loss: 0.432065642300335\n",
      "Epoch 269, Loss: 0.42821550526406094\n",
      "Epoch 270, Loss: 0.42857532485258004\n",
      "Epoch 271, Loss: 0.43234967987659256\n",
      "Epoch 272, Loss: 0.4333620913145171\n",
      "Epoch 273, Loss: 0.43177123704376796\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20686558807902897\n",
      "Test R^2 score: 0.5348881880816052\n",
      "Num of epochs: 274\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Epoch 179, Loss: 0.44257338842027333\n",
      "Epoch 180, Loss: 0.44223043415311275\n",
      "Epoch 181, Loss: 0.4412573335324542\n",
      "Epoch 182, Loss: 0.4403093939212056\n",
      "Epoch 183, Loss: 0.440210765892682\n",
      "Epoch 184, Loss: 0.4406913267766654\n",
      "Epoch 185, Loss: 0.44119678016972247\n",
      "Epoch 186, Loss: 0.4414768331353019\n",
      "Epoch 187, Loss: 0.44098509893198107\n",
      "Epoch 188, Loss: 0.4399157822542188\n",
      "Epoch 189, Loss: 0.43913002852403843\n",
      "Epoch 190, Loss: 0.43912120575952834\n",
      "Epoch 191, Loss: 0.43958194116248417\n",
      "Epoch 192, Loss: 0.43991779767875194\n",
      "Epoch 193, Loss: 0.4402464762584031\n",
      "Epoch 194, Loss: 0.4397939928277301\n",
      "Epoch 195, Loss: 0.4389848715145781\n",
      "Epoch 196, Loss: 0.43812834372448495\n",
      "Epoch 197, Loss: 0.4378789384628316\n",
      "Epoch 198, Loss: 0.4380569659316353\n",
      "Epoch 199, Loss: 0.4385928231376636\n",
      "Epoch 200, Loss: 0.4396870477941122\n",
      "Epoch 201, Loss: 0.44003322037003134\n",
      "Epoch 202, Loss: 0.4396387344028484\n",
      "Epoch 203, Loss: 0.43797246081508234\n",
      "Epoch 204, Loss: 0.4368868004619995\n",
      "Epoch 205, Loss: 0.4366217722212388\n",
      "Epoch 206, Loss: 0.4370735508315267\n",
      "Epoch 207, Loss: 0.438056659783102\n",
      "Epoch 208, Loss: 0.43828697608838324\n",
      "Epoch 209, Loss: 0.4380426277456835\n",
      "Epoch 210, Loss: 0.4367571723427673\n",
      "Epoch 211, Loss: 0.4358287121793394\n",
      "Epoch 212, Loss: 0.43549599799409766\n",
      "Epoch 213, Loss: 0.435693177425488\n",
      "Epoch 214, Loss: 0.43638716241086417\n",
      "Epoch 215, Loss: 0.43723040175969713\n",
      "Epoch 216, Loss: 0.4381875017781245\n",
      "Epoch 217, Loss: 0.43727582910411245\n",
      "Epoch 218, Loss: 0.4357251884259994\n",
      "Epoch 219, Loss: 0.43449740709117174\n",
      "Epoch 220, Loss: 0.4346007775761442\n",
      "Epoch 221, Loss: 0.4356339371912412\n",
      "Epoch 222, Loss: 0.43683657413065485\n",
      "Epoch 223, Loss: 0.43732786198111706\n",
      "Epoch 224, Loss: 0.43504045750484316\n",
      "Epoch 225, Loss: 0.4336674601818588\n",
      "Epoch 226, Loss: 0.4339570078903568\n",
      "Epoch 227, Loss: 0.43524205442250136\n",
      "Epoch 228, Loss: 0.43692856322479845\n",
      "Epoch 229, Loss: 0.4361014833656456\n",
      "Epoch 230, Loss: 0.43400818547427195\n",
      "Epoch 231, Loss: 0.43282550764678196\n",
      "Epoch 232, Loss: 0.43422302771098475\n",
      "Epoch 233, Loss: 0.43631150394157153\n",
      "Epoch 234, Loss: 0.4363944185143908\n",
      "Epoch 235, Loss: 0.4344230831071679\n",
      "Epoch 236, Loss: 0.43231983169663213\n",
      "Epoch 237, Loss: 0.4338866438813009\n",
      "Epoch 238, Loss: 0.4371328345881963\n",
      "Epoch 239, Loss: 0.4361934054316967\n",
      "Epoch 240, Loss: 0.4336558976182621\n",
      "Epoch 241, Loss: 0.432399290161847\n",
      "Epoch 242, Loss: 0.43439426928256275\n",
      "Epoch 243, Loss: 0.43607225078754297\n",
      "Epoch 244, Loss: 0.432937520696398\n",
      "Epoch 245, Loss: 0.4313183612820463\n",
      "Epoch 246, Loss: 0.432574819035821\n",
      "Epoch 247, Loss: 0.43256944517797463\n",
      "Epoch 248, Loss: 0.4313844637013701\n",
      "Epoch 249, Loss: 0.43068049739004677\n",
      "Epoch 250, Loss: 0.43099675551916994\n",
      "Epoch 251, Loss: 0.43165141303618687\n",
      "Epoch 252, Loss: 0.43069838475760797\n",
      "Epoch 253, Loss: 0.4299371687594886\n",
      "Epoch 254, Loss: 0.43062274760638575\n",
      "Epoch 255, Loss: 0.4311277872870893\n",
      "Epoch 256, Loss: 0.4311714384142778\n",
      "Epoch 257, Loss: 0.43017855241729436\n",
      "Epoch 258, Loss: 0.42926238444708237\n",
      "Epoch 259, Loss: 0.429571014567453\n",
      "Epoch 260, Loss: 0.43070712058104565\n",
      "Epoch 261, Loss: 0.4319815519144537\n",
      "Epoch 262, Loss: 0.4316843105666133\n",
      "Epoch 263, Loss: 0.4304818873122946\n",
      "Epoch 264, Loss: 0.42840412257514504\n",
      "Epoch 265, Loss: 0.42906400353820484\n",
      "Epoch 266, Loss: 0.43117263072273004\n",
      "Epoch 267, Loss: 0.4324830925949777\n",
      "Epoch 268, Loss: 0.432065642300335\n",
      "Epoch 269, Loss: 0.42821550526406094\n",
      "Epoch 270, Loss: 0.42857532485258004\n",
      "Epoch 271, Loss: 0.43234967987659256\n",
      "Epoch 272, Loss: 0.4333620913145171\n",
      "Epoch 273, Loss: 0.43177123704376796\n",
      "Epoch 274, Loss: 0.42781134135031557\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2123710348217455\n",
      "Test R^2 score: 0.5104976286195115\n",
      "Num of epochs: 275\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Epoch 179, Loss: 0.44257338842027333\n",
      "Epoch 180, Loss: 0.44223043415311275\n",
      "Epoch 181, Loss: 0.4412573335324542\n",
      "Epoch 182, Loss: 0.4403093939212056\n",
      "Epoch 183, Loss: 0.440210765892682\n",
      "Epoch 184, Loss: 0.4406913267766654\n",
      "Epoch 185, Loss: 0.44119678016972247\n",
      "Epoch 186, Loss: 0.4414768331353019\n",
      "Epoch 187, Loss: 0.44098509893198107\n",
      "Epoch 188, Loss: 0.4399157822542188\n",
      "Epoch 189, Loss: 0.43913002852403843\n",
      "Epoch 190, Loss: 0.43912120575952834\n",
      "Epoch 191, Loss: 0.43958194116248417\n",
      "Epoch 192, Loss: 0.43991779767875194\n",
      "Epoch 193, Loss: 0.4402464762584031\n",
      "Epoch 194, Loss: 0.4397939928277301\n",
      "Epoch 195, Loss: 0.4389848715145781\n",
      "Epoch 196, Loss: 0.43812834372448495\n",
      "Epoch 197, Loss: 0.4378789384628316\n",
      "Epoch 198, Loss: 0.4380569659316353\n",
      "Epoch 199, Loss: 0.4385928231376636\n",
      "Epoch 200, Loss: 0.4396870477941122\n",
      "Epoch 201, Loss: 0.44003322037003134\n",
      "Epoch 202, Loss: 0.4396387344028484\n",
      "Epoch 203, Loss: 0.43797246081508234\n",
      "Epoch 204, Loss: 0.4368868004619995\n",
      "Epoch 205, Loss: 0.4366217722212388\n",
      "Epoch 206, Loss: 0.4370735508315267\n",
      "Epoch 207, Loss: 0.438056659783102\n",
      "Epoch 208, Loss: 0.43828697608838324\n",
      "Epoch 209, Loss: 0.4380426277456835\n",
      "Epoch 210, Loss: 0.4367571723427673\n",
      "Epoch 211, Loss: 0.4358287121793394\n",
      "Epoch 212, Loss: 0.43549599799409766\n",
      "Epoch 213, Loss: 0.435693177425488\n",
      "Epoch 214, Loss: 0.43638716241086417\n",
      "Epoch 215, Loss: 0.43723040175969713\n",
      "Epoch 216, Loss: 0.4381875017781245\n",
      "Epoch 217, Loss: 0.43727582910411245\n",
      "Epoch 218, Loss: 0.4357251884259994\n",
      "Epoch 219, Loss: 0.43449740709117174\n",
      "Epoch 220, Loss: 0.4346007775761442\n",
      "Epoch 221, Loss: 0.4356339371912412\n",
      "Epoch 222, Loss: 0.43683657413065485\n",
      "Epoch 223, Loss: 0.43732786198111706\n",
      "Epoch 224, Loss: 0.43504045750484316\n",
      "Epoch 225, Loss: 0.4336674601818588\n",
      "Epoch 226, Loss: 0.4339570078903568\n",
      "Epoch 227, Loss: 0.43524205442250136\n",
      "Epoch 228, Loss: 0.43692856322479845\n",
      "Epoch 229, Loss: 0.4361014833656456\n",
      "Epoch 230, Loss: 0.43400818547427195\n",
      "Epoch 231, Loss: 0.43282550764678196\n",
      "Epoch 232, Loss: 0.43422302771098475\n",
      "Epoch 233, Loss: 0.43631150394157153\n",
      "Epoch 234, Loss: 0.4363944185143908\n",
      "Epoch 235, Loss: 0.4344230831071679\n",
      "Epoch 236, Loss: 0.43231983169663213\n",
      "Epoch 237, Loss: 0.4338866438813009\n",
      "Epoch 238, Loss: 0.4371328345881963\n",
      "Epoch 239, Loss: 0.4361934054316967\n",
      "Epoch 240, Loss: 0.4336558976182621\n",
      "Epoch 241, Loss: 0.432399290161847\n",
      "Epoch 242, Loss: 0.43439426928256275\n",
      "Epoch 243, Loss: 0.43607225078754297\n",
      "Epoch 244, Loss: 0.432937520696398\n",
      "Epoch 245, Loss: 0.4313183612820463\n",
      "Epoch 246, Loss: 0.432574819035821\n",
      "Epoch 247, Loss: 0.43256944517797463\n",
      "Epoch 248, Loss: 0.4313844637013701\n",
      "Epoch 249, Loss: 0.43068049739004677\n",
      "Epoch 250, Loss: 0.43099675551916994\n",
      "Epoch 251, Loss: 0.43165141303618687\n",
      "Epoch 252, Loss: 0.43069838475760797\n",
      "Epoch 253, Loss: 0.4299371687594886\n",
      "Epoch 254, Loss: 0.43062274760638575\n",
      "Epoch 255, Loss: 0.4311277872870893\n",
      "Epoch 256, Loss: 0.4311714384142778\n",
      "Epoch 257, Loss: 0.43017855241729436\n",
      "Epoch 258, Loss: 0.42926238444708237\n",
      "Epoch 259, Loss: 0.429571014567453\n",
      "Epoch 260, Loss: 0.43070712058104565\n",
      "Epoch 261, Loss: 0.4319815519144537\n",
      "Epoch 262, Loss: 0.4316843105666133\n",
      "Epoch 263, Loss: 0.4304818873122946\n",
      "Epoch 264, Loss: 0.42840412257514504\n",
      "Epoch 265, Loss: 0.42906400353820484\n",
      "Epoch 266, Loss: 0.43117263072273004\n",
      "Epoch 267, Loss: 0.4324830925949777\n",
      "Epoch 268, Loss: 0.432065642300335\n",
      "Epoch 269, Loss: 0.42821550526406094\n",
      "Epoch 270, Loss: 0.42857532485258004\n",
      "Epoch 271, Loss: 0.43234967987659256\n",
      "Epoch 272, Loss: 0.4333620913145171\n",
      "Epoch 273, Loss: 0.43177123704376796\n",
      "Epoch 274, Loss: 0.42781134135031557\n",
      "Epoch 275, Loss: 0.43068236573784513\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20814857949388527\n",
      "Test R^2 score: 0.528797958884145\n",
      "Num of epochs: 276\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Epoch 179, Loss: 0.44257338842027333\n",
      "Epoch 180, Loss: 0.44223043415311275\n",
      "Epoch 181, Loss: 0.4412573335324542\n",
      "Epoch 182, Loss: 0.4403093939212056\n",
      "Epoch 183, Loss: 0.440210765892682\n",
      "Epoch 184, Loss: 0.4406913267766654\n",
      "Epoch 185, Loss: 0.44119678016972247\n",
      "Epoch 186, Loss: 0.4414768331353019\n",
      "Epoch 187, Loss: 0.44098509893198107\n",
      "Epoch 188, Loss: 0.4399157822542188\n",
      "Epoch 189, Loss: 0.43913002852403843\n",
      "Epoch 190, Loss: 0.43912120575952834\n",
      "Epoch 191, Loss: 0.43958194116248417\n",
      "Epoch 192, Loss: 0.43991779767875194\n",
      "Epoch 193, Loss: 0.4402464762584031\n",
      "Epoch 194, Loss: 0.4397939928277301\n",
      "Epoch 195, Loss: 0.4389848715145781\n",
      "Epoch 196, Loss: 0.43812834372448495\n",
      "Epoch 197, Loss: 0.4378789384628316\n",
      "Epoch 198, Loss: 0.4380569659316353\n",
      "Epoch 199, Loss: 0.4385928231376636\n",
      "Epoch 200, Loss: 0.4396870477941122\n",
      "Epoch 201, Loss: 0.44003322037003134\n",
      "Epoch 202, Loss: 0.4396387344028484\n",
      "Epoch 203, Loss: 0.43797246081508234\n",
      "Epoch 204, Loss: 0.4368868004619995\n",
      "Epoch 205, Loss: 0.4366217722212388\n",
      "Epoch 206, Loss: 0.4370735508315267\n",
      "Epoch 207, Loss: 0.438056659783102\n",
      "Epoch 208, Loss: 0.43828697608838324\n",
      "Epoch 209, Loss: 0.4380426277456835\n",
      "Epoch 210, Loss: 0.4367571723427673\n",
      "Epoch 211, Loss: 0.4358287121793394\n",
      "Epoch 212, Loss: 0.43549599799409766\n",
      "Epoch 213, Loss: 0.435693177425488\n",
      "Epoch 214, Loss: 0.43638716241086417\n",
      "Epoch 215, Loss: 0.43723040175969713\n",
      "Epoch 216, Loss: 0.4381875017781245\n",
      "Epoch 217, Loss: 0.43727582910411245\n",
      "Epoch 218, Loss: 0.4357251884259994\n",
      "Epoch 219, Loss: 0.43449740709117174\n",
      "Epoch 220, Loss: 0.4346007775761442\n",
      "Epoch 221, Loss: 0.4356339371912412\n",
      "Epoch 222, Loss: 0.43683657413065485\n",
      "Epoch 223, Loss: 0.43732786198111706\n",
      "Epoch 224, Loss: 0.43504045750484316\n",
      "Epoch 225, Loss: 0.4336674601818588\n",
      "Epoch 226, Loss: 0.4339570078903568\n",
      "Epoch 227, Loss: 0.43524205442250136\n",
      "Epoch 228, Loss: 0.43692856322479845\n",
      "Epoch 229, Loss: 0.4361014833656456\n",
      "Epoch 230, Loss: 0.43400818547427195\n",
      "Epoch 231, Loss: 0.43282550764678196\n",
      "Epoch 232, Loss: 0.43422302771098475\n",
      "Epoch 233, Loss: 0.43631150394157153\n",
      "Epoch 234, Loss: 0.4363944185143908\n",
      "Epoch 235, Loss: 0.4344230831071679\n",
      "Epoch 236, Loss: 0.43231983169663213\n",
      "Epoch 237, Loss: 0.4338866438813009\n",
      "Epoch 238, Loss: 0.4371328345881963\n",
      "Epoch 239, Loss: 0.4361934054316967\n",
      "Epoch 240, Loss: 0.4336558976182621\n",
      "Epoch 241, Loss: 0.432399290161847\n",
      "Epoch 242, Loss: 0.43439426928256275\n",
      "Epoch 243, Loss: 0.43607225078754297\n",
      "Epoch 244, Loss: 0.432937520696398\n",
      "Epoch 245, Loss: 0.4313183612820463\n",
      "Epoch 246, Loss: 0.432574819035821\n",
      "Epoch 247, Loss: 0.43256944517797463\n",
      "Epoch 248, Loss: 0.4313844637013701\n",
      "Epoch 249, Loss: 0.43068049739004677\n",
      "Epoch 250, Loss: 0.43099675551916994\n",
      "Epoch 251, Loss: 0.43165141303618687\n",
      "Epoch 252, Loss: 0.43069838475760797\n",
      "Epoch 253, Loss: 0.4299371687594886\n",
      "Epoch 254, Loss: 0.43062274760638575\n",
      "Epoch 255, Loss: 0.4311277872870893\n",
      "Epoch 256, Loss: 0.4311714384142778\n",
      "Epoch 257, Loss: 0.43017855241729436\n",
      "Epoch 258, Loss: 0.42926238444708237\n",
      "Epoch 259, Loss: 0.429571014567453\n",
      "Epoch 260, Loss: 0.43070712058104565\n",
      "Epoch 261, Loss: 0.4319815519144537\n",
      "Epoch 262, Loss: 0.4316843105666133\n",
      "Epoch 263, Loss: 0.4304818873122946\n",
      "Epoch 264, Loss: 0.42840412257514504\n",
      "Epoch 265, Loss: 0.42906400353820484\n",
      "Epoch 266, Loss: 0.43117263072273004\n",
      "Epoch 267, Loss: 0.4324830925949777\n",
      "Epoch 268, Loss: 0.432065642300335\n",
      "Epoch 269, Loss: 0.42821550526406094\n",
      "Epoch 270, Loss: 0.42857532485258004\n",
      "Epoch 271, Loss: 0.43234967987659256\n",
      "Epoch 272, Loss: 0.4333620913145171\n",
      "Epoch 273, Loss: 0.43177123704376796\n",
      "Epoch 274, Loss: 0.42781134135031557\n",
      "Epoch 275, Loss: 0.43068236573784513\n",
      "Epoch 276, Loss: 0.4364270609514446\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21287156959833173\n",
      "Test R^2 score: 0.5080465104734228\n",
      "Num of epochs: 277\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Epoch 179, Loss: 0.44257338842027333\n",
      "Epoch 180, Loss: 0.44223043415311275\n",
      "Epoch 181, Loss: 0.4412573335324542\n",
      "Epoch 182, Loss: 0.4403093939212056\n",
      "Epoch 183, Loss: 0.440210765892682\n",
      "Epoch 184, Loss: 0.4406913267766654\n",
      "Epoch 185, Loss: 0.44119678016972247\n",
      "Epoch 186, Loss: 0.4414768331353019\n",
      "Epoch 187, Loss: 0.44098509893198107\n",
      "Epoch 188, Loss: 0.4399157822542188\n",
      "Epoch 189, Loss: 0.43913002852403843\n",
      "Epoch 190, Loss: 0.43912120575952834\n",
      "Epoch 191, Loss: 0.43958194116248417\n",
      "Epoch 192, Loss: 0.43991779767875194\n",
      "Epoch 193, Loss: 0.4402464762584031\n",
      "Epoch 194, Loss: 0.4397939928277301\n",
      "Epoch 195, Loss: 0.4389848715145781\n",
      "Epoch 196, Loss: 0.43812834372448495\n",
      "Epoch 197, Loss: 0.4378789384628316\n",
      "Epoch 198, Loss: 0.4380569659316353\n",
      "Epoch 199, Loss: 0.4385928231376636\n",
      "Epoch 200, Loss: 0.4396870477941122\n",
      "Epoch 201, Loss: 0.44003322037003134\n",
      "Epoch 202, Loss: 0.4396387344028484\n",
      "Epoch 203, Loss: 0.43797246081508234\n",
      "Epoch 204, Loss: 0.4368868004619995\n",
      "Epoch 205, Loss: 0.4366217722212388\n",
      "Epoch 206, Loss: 0.4370735508315267\n",
      "Epoch 207, Loss: 0.438056659783102\n",
      "Epoch 208, Loss: 0.43828697608838324\n",
      "Epoch 209, Loss: 0.4380426277456835\n",
      "Epoch 210, Loss: 0.4367571723427673\n",
      "Epoch 211, Loss: 0.4358287121793394\n",
      "Epoch 212, Loss: 0.43549599799409766\n",
      "Epoch 213, Loss: 0.435693177425488\n",
      "Epoch 214, Loss: 0.43638716241086417\n",
      "Epoch 215, Loss: 0.43723040175969713\n",
      "Epoch 216, Loss: 0.4381875017781245\n",
      "Epoch 217, Loss: 0.43727582910411245\n",
      "Epoch 218, Loss: 0.4357251884259994\n",
      "Epoch 219, Loss: 0.43449740709117174\n",
      "Epoch 220, Loss: 0.4346007775761442\n",
      "Epoch 221, Loss: 0.4356339371912412\n",
      "Epoch 222, Loss: 0.43683657413065485\n",
      "Epoch 223, Loss: 0.43732786198111706\n",
      "Epoch 224, Loss: 0.43504045750484316\n",
      "Epoch 225, Loss: 0.4336674601818588\n",
      "Epoch 226, Loss: 0.4339570078903568\n",
      "Epoch 227, Loss: 0.43524205442250136\n",
      "Epoch 228, Loss: 0.43692856322479845\n",
      "Epoch 229, Loss: 0.4361014833656456\n",
      "Epoch 230, Loss: 0.43400818547427195\n",
      "Epoch 231, Loss: 0.43282550764678196\n",
      "Epoch 232, Loss: 0.43422302771098475\n",
      "Epoch 233, Loss: 0.43631150394157153\n",
      "Epoch 234, Loss: 0.4363944185143908\n",
      "Epoch 235, Loss: 0.4344230831071679\n",
      "Epoch 236, Loss: 0.43231983169663213\n",
      "Epoch 237, Loss: 0.4338866438813009\n",
      "Epoch 238, Loss: 0.4371328345881963\n",
      "Epoch 239, Loss: 0.4361934054316967\n",
      "Epoch 240, Loss: 0.4336558976182621\n",
      "Epoch 241, Loss: 0.432399290161847\n",
      "Epoch 242, Loss: 0.43439426928256275\n",
      "Epoch 243, Loss: 0.43607225078754297\n",
      "Epoch 244, Loss: 0.432937520696398\n",
      "Epoch 245, Loss: 0.4313183612820463\n",
      "Epoch 246, Loss: 0.432574819035821\n",
      "Epoch 247, Loss: 0.43256944517797463\n",
      "Epoch 248, Loss: 0.4313844637013701\n",
      "Epoch 249, Loss: 0.43068049739004677\n",
      "Epoch 250, Loss: 0.43099675551916994\n",
      "Epoch 251, Loss: 0.43165141303618687\n",
      "Epoch 252, Loss: 0.43069838475760797\n",
      "Epoch 253, Loss: 0.4299371687594886\n",
      "Epoch 254, Loss: 0.43062274760638575\n",
      "Epoch 255, Loss: 0.4311277872870893\n",
      "Epoch 256, Loss: 0.4311714384142778\n",
      "Epoch 257, Loss: 0.43017855241729436\n",
      "Epoch 258, Loss: 0.42926238444708237\n",
      "Epoch 259, Loss: 0.429571014567453\n",
      "Epoch 260, Loss: 0.43070712058104565\n",
      "Epoch 261, Loss: 0.4319815519144537\n",
      "Epoch 262, Loss: 0.4316843105666133\n",
      "Epoch 263, Loss: 0.4304818873122946\n",
      "Epoch 264, Loss: 0.42840412257514504\n",
      "Epoch 265, Loss: 0.42906400353820484\n",
      "Epoch 266, Loss: 0.43117263072273004\n",
      "Epoch 267, Loss: 0.4324830925949777\n",
      "Epoch 268, Loss: 0.432065642300335\n",
      "Epoch 269, Loss: 0.42821550526406094\n",
      "Epoch 270, Loss: 0.42857532485258004\n",
      "Epoch 271, Loss: 0.43234967987659256\n",
      "Epoch 272, Loss: 0.4333620913145171\n",
      "Epoch 273, Loss: 0.43177123704376796\n",
      "Epoch 274, Loss: 0.42781134135031557\n",
      "Epoch 275, Loss: 0.43068236573784513\n",
      "Epoch 276, Loss: 0.4364270609514446\n",
      "Epoch 277, Loss: 0.43077905897178964\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20677957036495348\n",
      "Test R^2 score: 0.5351296188896608\n",
      "Num of epochs: 278\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Epoch 179, Loss: 0.44257338842027333\n",
      "Epoch 180, Loss: 0.44223043415311275\n",
      "Epoch 181, Loss: 0.4412573335324542\n",
      "Epoch 182, Loss: 0.4403093939212056\n",
      "Epoch 183, Loss: 0.440210765892682\n",
      "Epoch 184, Loss: 0.4406913267766654\n",
      "Epoch 185, Loss: 0.44119678016972247\n",
      "Epoch 186, Loss: 0.4414768331353019\n",
      "Epoch 187, Loss: 0.44098509893198107\n",
      "Epoch 188, Loss: 0.4399157822542188\n",
      "Epoch 189, Loss: 0.43913002852403843\n",
      "Epoch 190, Loss: 0.43912120575952834\n",
      "Epoch 191, Loss: 0.43958194116248417\n",
      "Epoch 192, Loss: 0.43991779767875194\n",
      "Epoch 193, Loss: 0.4402464762584031\n",
      "Epoch 194, Loss: 0.4397939928277301\n",
      "Epoch 195, Loss: 0.4389848715145781\n",
      "Epoch 196, Loss: 0.43812834372448495\n",
      "Epoch 197, Loss: 0.4378789384628316\n",
      "Epoch 198, Loss: 0.4380569659316353\n",
      "Epoch 199, Loss: 0.4385928231376636\n",
      "Epoch 200, Loss: 0.4396870477941122\n",
      "Epoch 201, Loss: 0.44003322037003134\n",
      "Epoch 202, Loss: 0.4396387344028484\n",
      "Epoch 203, Loss: 0.43797246081508234\n",
      "Epoch 204, Loss: 0.4368868004619995\n",
      "Epoch 205, Loss: 0.4366217722212388\n",
      "Epoch 206, Loss: 0.4370735508315267\n",
      "Epoch 207, Loss: 0.438056659783102\n",
      "Epoch 208, Loss: 0.43828697608838324\n",
      "Epoch 209, Loss: 0.4380426277456835\n",
      "Epoch 210, Loss: 0.4367571723427673\n",
      "Epoch 211, Loss: 0.4358287121793394\n",
      "Epoch 212, Loss: 0.43549599799409766\n",
      "Epoch 213, Loss: 0.435693177425488\n",
      "Epoch 214, Loss: 0.43638716241086417\n",
      "Epoch 215, Loss: 0.43723040175969713\n",
      "Epoch 216, Loss: 0.4381875017781245\n",
      "Epoch 217, Loss: 0.43727582910411245\n",
      "Epoch 218, Loss: 0.4357251884259994\n",
      "Epoch 219, Loss: 0.43449740709117174\n",
      "Epoch 220, Loss: 0.4346007775761442\n",
      "Epoch 221, Loss: 0.4356339371912412\n",
      "Epoch 222, Loss: 0.43683657413065485\n",
      "Epoch 223, Loss: 0.43732786198111706\n",
      "Epoch 224, Loss: 0.43504045750484316\n",
      "Epoch 225, Loss: 0.4336674601818588\n",
      "Epoch 226, Loss: 0.4339570078903568\n",
      "Epoch 227, Loss: 0.43524205442250136\n",
      "Epoch 228, Loss: 0.43692856322479845\n",
      "Epoch 229, Loss: 0.4361014833656456\n",
      "Epoch 230, Loss: 0.43400818547427195\n",
      "Epoch 231, Loss: 0.43282550764678196\n",
      "Epoch 232, Loss: 0.43422302771098475\n",
      "Epoch 233, Loss: 0.43631150394157153\n",
      "Epoch 234, Loss: 0.4363944185143908\n",
      "Epoch 235, Loss: 0.4344230831071679\n",
      "Epoch 236, Loss: 0.43231983169663213\n",
      "Epoch 237, Loss: 0.4338866438813009\n",
      "Epoch 238, Loss: 0.4371328345881963\n",
      "Epoch 239, Loss: 0.4361934054316967\n",
      "Epoch 240, Loss: 0.4336558976182621\n",
      "Epoch 241, Loss: 0.432399290161847\n",
      "Epoch 242, Loss: 0.43439426928256275\n",
      "Epoch 243, Loss: 0.43607225078754297\n",
      "Epoch 244, Loss: 0.432937520696398\n",
      "Epoch 245, Loss: 0.4313183612820463\n",
      "Epoch 246, Loss: 0.432574819035821\n",
      "Epoch 247, Loss: 0.43256944517797463\n",
      "Epoch 248, Loss: 0.4313844637013701\n",
      "Epoch 249, Loss: 0.43068049739004677\n",
      "Epoch 250, Loss: 0.43099675551916994\n",
      "Epoch 251, Loss: 0.43165141303618687\n",
      "Epoch 252, Loss: 0.43069838475760797\n",
      "Epoch 253, Loss: 0.4299371687594886\n",
      "Epoch 254, Loss: 0.43062274760638575\n",
      "Epoch 255, Loss: 0.4311277872870893\n",
      "Epoch 256, Loss: 0.4311714384142778\n",
      "Epoch 257, Loss: 0.43017855241729436\n",
      "Epoch 258, Loss: 0.42926238444708237\n",
      "Epoch 259, Loss: 0.429571014567453\n",
      "Epoch 260, Loss: 0.43070712058104565\n",
      "Epoch 261, Loss: 0.4319815519144537\n",
      "Epoch 262, Loss: 0.4316843105666133\n",
      "Epoch 263, Loss: 0.4304818873122946\n",
      "Epoch 264, Loss: 0.42840412257514504\n",
      "Epoch 265, Loss: 0.42906400353820484\n",
      "Epoch 266, Loss: 0.43117263072273004\n",
      "Epoch 267, Loss: 0.4324830925949777\n",
      "Epoch 268, Loss: 0.432065642300335\n",
      "Epoch 269, Loss: 0.42821550526406094\n",
      "Epoch 270, Loss: 0.42857532485258004\n",
      "Epoch 271, Loss: 0.43234967987659256\n",
      "Epoch 272, Loss: 0.4333620913145171\n",
      "Epoch 273, Loss: 0.43177123704376796\n",
      "Epoch 274, Loss: 0.42781134135031557\n",
      "Epoch 275, Loss: 0.43068236573784513\n",
      "Epoch 276, Loss: 0.4364270609514446\n",
      "Epoch 277, Loss: 0.43077905897178964\n",
      "Epoch 278, Loss: 0.4276025647386226\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20589671228741316\n",
      "Test R^2 score: 0.5387503854451559\n",
      "Num of epochs: 279\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Epoch 179, Loss: 0.44257338842027333\n",
      "Epoch 180, Loss: 0.44223043415311275\n",
      "Epoch 181, Loss: 0.4412573335324542\n",
      "Epoch 182, Loss: 0.4403093939212056\n",
      "Epoch 183, Loss: 0.440210765892682\n",
      "Epoch 184, Loss: 0.4406913267766654\n",
      "Epoch 185, Loss: 0.44119678016972247\n",
      "Epoch 186, Loss: 0.4414768331353019\n",
      "Epoch 187, Loss: 0.44098509893198107\n",
      "Epoch 188, Loss: 0.4399157822542188\n",
      "Epoch 189, Loss: 0.43913002852403843\n",
      "Epoch 190, Loss: 0.43912120575952834\n",
      "Epoch 191, Loss: 0.43958194116248417\n",
      "Epoch 192, Loss: 0.43991779767875194\n",
      "Epoch 193, Loss: 0.4402464762584031\n",
      "Epoch 194, Loss: 0.4397939928277301\n",
      "Epoch 195, Loss: 0.4389848715145781\n",
      "Epoch 196, Loss: 0.43812834372448495\n",
      "Epoch 197, Loss: 0.4378789384628316\n",
      "Epoch 198, Loss: 0.4380569659316353\n",
      "Epoch 199, Loss: 0.4385928231376636\n",
      "Epoch 200, Loss: 0.4396870477941122\n",
      "Epoch 201, Loss: 0.44003322037003134\n",
      "Epoch 202, Loss: 0.4396387344028484\n",
      "Epoch 203, Loss: 0.43797246081508234\n",
      "Epoch 204, Loss: 0.4368868004619995\n",
      "Epoch 205, Loss: 0.4366217722212388\n",
      "Epoch 206, Loss: 0.4370735508315267\n",
      "Epoch 207, Loss: 0.438056659783102\n",
      "Epoch 208, Loss: 0.43828697608838324\n",
      "Epoch 209, Loss: 0.4380426277456835\n",
      "Epoch 210, Loss: 0.4367571723427673\n",
      "Epoch 211, Loss: 0.4358287121793394\n",
      "Epoch 212, Loss: 0.43549599799409766\n",
      "Epoch 213, Loss: 0.435693177425488\n",
      "Epoch 214, Loss: 0.43638716241086417\n",
      "Epoch 215, Loss: 0.43723040175969713\n",
      "Epoch 216, Loss: 0.4381875017781245\n",
      "Epoch 217, Loss: 0.43727582910411245\n",
      "Epoch 218, Loss: 0.4357251884259994\n",
      "Epoch 219, Loss: 0.43449740709117174\n",
      "Epoch 220, Loss: 0.4346007775761442\n",
      "Epoch 221, Loss: 0.4356339371912412\n",
      "Epoch 222, Loss: 0.43683657413065485\n",
      "Epoch 223, Loss: 0.43732786198111706\n",
      "Epoch 224, Loss: 0.43504045750484316\n",
      "Epoch 225, Loss: 0.4336674601818588\n",
      "Epoch 226, Loss: 0.4339570078903568\n",
      "Epoch 227, Loss: 0.43524205442250136\n",
      "Epoch 228, Loss: 0.43692856322479845\n",
      "Epoch 229, Loss: 0.4361014833656456\n",
      "Epoch 230, Loss: 0.43400818547427195\n",
      "Epoch 231, Loss: 0.43282550764678196\n",
      "Epoch 232, Loss: 0.43422302771098475\n",
      "Epoch 233, Loss: 0.43631150394157153\n",
      "Epoch 234, Loss: 0.4363944185143908\n",
      "Epoch 235, Loss: 0.4344230831071679\n",
      "Epoch 236, Loss: 0.43231983169663213\n",
      "Epoch 237, Loss: 0.4338866438813009\n",
      "Epoch 238, Loss: 0.4371328345881963\n",
      "Epoch 239, Loss: 0.4361934054316967\n",
      "Epoch 240, Loss: 0.4336558976182621\n",
      "Epoch 241, Loss: 0.432399290161847\n",
      "Epoch 242, Loss: 0.43439426928256275\n",
      "Epoch 243, Loss: 0.43607225078754297\n",
      "Epoch 244, Loss: 0.432937520696398\n",
      "Epoch 245, Loss: 0.4313183612820463\n",
      "Epoch 246, Loss: 0.432574819035821\n",
      "Epoch 247, Loss: 0.43256944517797463\n",
      "Epoch 248, Loss: 0.4313844637013701\n",
      "Epoch 249, Loss: 0.43068049739004677\n",
      "Epoch 250, Loss: 0.43099675551916994\n",
      "Epoch 251, Loss: 0.43165141303618687\n",
      "Epoch 252, Loss: 0.43069838475760797\n",
      "Epoch 253, Loss: 0.4299371687594886\n",
      "Epoch 254, Loss: 0.43062274760638575\n",
      "Epoch 255, Loss: 0.4311277872870893\n",
      "Epoch 256, Loss: 0.4311714384142778\n",
      "Epoch 257, Loss: 0.43017855241729436\n",
      "Epoch 258, Loss: 0.42926238444708237\n",
      "Epoch 259, Loss: 0.429571014567453\n",
      "Epoch 260, Loss: 0.43070712058104565\n",
      "Epoch 261, Loss: 0.4319815519144537\n",
      "Epoch 262, Loss: 0.4316843105666133\n",
      "Epoch 263, Loss: 0.4304818873122946\n",
      "Epoch 264, Loss: 0.42840412257514504\n",
      "Epoch 265, Loss: 0.42906400353820484\n",
      "Epoch 266, Loss: 0.43117263072273004\n",
      "Epoch 267, Loss: 0.4324830925949777\n",
      "Epoch 268, Loss: 0.432065642300335\n",
      "Epoch 269, Loss: 0.42821550526406094\n",
      "Epoch 270, Loss: 0.42857532485258004\n",
      "Epoch 271, Loss: 0.43234967987659256\n",
      "Epoch 272, Loss: 0.4333620913145171\n",
      "Epoch 273, Loss: 0.43177123704376796\n",
      "Epoch 274, Loss: 0.42781134135031557\n",
      "Epoch 275, Loss: 0.43068236573784513\n",
      "Epoch 276, Loss: 0.4364270609514446\n",
      "Epoch 277, Loss: 0.43077905897178964\n",
      "Epoch 278, Loss: 0.4276025647386226\n",
      "Epoch 279, Loss: 0.42963899858880455\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21164716472483833\n",
      "Test R^2 score: 0.5137515442456269\n",
      "Num of epochs: 280\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Epoch 179, Loss: 0.44257338842027333\n",
      "Epoch 180, Loss: 0.44223043415311275\n",
      "Epoch 181, Loss: 0.4412573335324542\n",
      "Epoch 182, Loss: 0.4403093939212056\n",
      "Epoch 183, Loss: 0.440210765892682\n",
      "Epoch 184, Loss: 0.4406913267766654\n",
      "Epoch 185, Loss: 0.44119678016972247\n",
      "Epoch 186, Loss: 0.4414768331353019\n",
      "Epoch 187, Loss: 0.44098509893198107\n",
      "Epoch 188, Loss: 0.4399157822542188\n",
      "Epoch 189, Loss: 0.43913002852403843\n",
      "Epoch 190, Loss: 0.43912120575952834\n",
      "Epoch 191, Loss: 0.43958194116248417\n",
      "Epoch 192, Loss: 0.43991779767875194\n",
      "Epoch 193, Loss: 0.4402464762584031\n",
      "Epoch 194, Loss: 0.4397939928277301\n",
      "Epoch 195, Loss: 0.4389848715145781\n",
      "Epoch 196, Loss: 0.43812834372448495\n",
      "Epoch 197, Loss: 0.4378789384628316\n",
      "Epoch 198, Loss: 0.4380569659316353\n",
      "Epoch 199, Loss: 0.4385928231376636\n",
      "Epoch 200, Loss: 0.4396870477941122\n",
      "Epoch 201, Loss: 0.44003322037003134\n",
      "Epoch 202, Loss: 0.4396387344028484\n",
      "Epoch 203, Loss: 0.43797246081508234\n",
      "Epoch 204, Loss: 0.4368868004619995\n",
      "Epoch 205, Loss: 0.4366217722212388\n",
      "Epoch 206, Loss: 0.4370735508315267\n",
      "Epoch 207, Loss: 0.438056659783102\n",
      "Epoch 208, Loss: 0.43828697608838324\n",
      "Epoch 209, Loss: 0.4380426277456835\n",
      "Epoch 210, Loss: 0.4367571723427673\n",
      "Epoch 211, Loss: 0.4358287121793394\n",
      "Epoch 212, Loss: 0.43549599799409766\n",
      "Epoch 213, Loss: 0.435693177425488\n",
      "Epoch 214, Loss: 0.43638716241086417\n",
      "Epoch 215, Loss: 0.43723040175969713\n",
      "Epoch 216, Loss: 0.4381875017781245\n",
      "Epoch 217, Loss: 0.43727582910411245\n",
      "Epoch 218, Loss: 0.4357251884259994\n",
      "Epoch 219, Loss: 0.43449740709117174\n",
      "Epoch 220, Loss: 0.4346007775761442\n",
      "Epoch 221, Loss: 0.4356339371912412\n",
      "Epoch 222, Loss: 0.43683657413065485\n",
      "Epoch 223, Loss: 0.43732786198111706\n",
      "Epoch 224, Loss: 0.43504045750484316\n",
      "Epoch 225, Loss: 0.4336674601818588\n",
      "Epoch 226, Loss: 0.4339570078903568\n",
      "Epoch 227, Loss: 0.43524205442250136\n",
      "Epoch 228, Loss: 0.43692856322479845\n",
      "Epoch 229, Loss: 0.4361014833656456\n",
      "Epoch 230, Loss: 0.43400818547427195\n",
      "Epoch 231, Loss: 0.43282550764678196\n",
      "Epoch 232, Loss: 0.43422302771098475\n",
      "Epoch 233, Loss: 0.43631150394157153\n",
      "Epoch 234, Loss: 0.4363944185143908\n",
      "Epoch 235, Loss: 0.4344230831071679\n",
      "Epoch 236, Loss: 0.43231983169663213\n",
      "Epoch 237, Loss: 0.4338866438813009\n",
      "Epoch 238, Loss: 0.4371328345881963\n",
      "Epoch 239, Loss: 0.4361934054316967\n",
      "Epoch 240, Loss: 0.4336558976182621\n",
      "Epoch 241, Loss: 0.432399290161847\n",
      "Epoch 242, Loss: 0.43439426928256275\n",
      "Epoch 243, Loss: 0.43607225078754297\n",
      "Epoch 244, Loss: 0.432937520696398\n",
      "Epoch 245, Loss: 0.4313183612820463\n",
      "Epoch 246, Loss: 0.432574819035821\n",
      "Epoch 247, Loss: 0.43256944517797463\n",
      "Epoch 248, Loss: 0.4313844637013701\n",
      "Epoch 249, Loss: 0.43068049739004677\n",
      "Epoch 250, Loss: 0.43099675551916994\n",
      "Epoch 251, Loss: 0.43165141303618687\n",
      "Epoch 252, Loss: 0.43069838475760797\n",
      "Epoch 253, Loss: 0.4299371687594886\n",
      "Epoch 254, Loss: 0.43062274760638575\n",
      "Epoch 255, Loss: 0.4311277872870893\n",
      "Epoch 256, Loss: 0.4311714384142778\n",
      "Epoch 257, Loss: 0.43017855241729436\n",
      "Epoch 258, Loss: 0.42926238444708237\n",
      "Epoch 259, Loss: 0.429571014567453\n",
      "Epoch 260, Loss: 0.43070712058104565\n",
      "Epoch 261, Loss: 0.4319815519144537\n",
      "Epoch 262, Loss: 0.4316843105666133\n",
      "Epoch 263, Loss: 0.4304818873122946\n",
      "Epoch 264, Loss: 0.42840412257514504\n",
      "Epoch 265, Loss: 0.42906400353820484\n",
      "Epoch 266, Loss: 0.43117263072273004\n",
      "Epoch 267, Loss: 0.4324830925949777\n",
      "Epoch 268, Loss: 0.432065642300335\n",
      "Epoch 269, Loss: 0.42821550526406094\n",
      "Epoch 270, Loss: 0.42857532485258004\n",
      "Epoch 271, Loss: 0.43234967987659256\n",
      "Epoch 272, Loss: 0.4333620913145171\n",
      "Epoch 273, Loss: 0.43177123704376796\n",
      "Epoch 274, Loss: 0.42781134135031557\n",
      "Epoch 275, Loss: 0.43068236573784513\n",
      "Epoch 276, Loss: 0.4364270609514446\n",
      "Epoch 277, Loss: 0.43077905897178964\n",
      "Epoch 278, Loss: 0.4276025647386226\n",
      "Epoch 279, Loss: 0.42963899858880455\n",
      "Epoch 280, Loss: 0.4293283522141213\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20604969468613424\n",
      "Test R^2 score: 0.5389193744426208\n",
      "Num of epochs: 281\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Epoch 179, Loss: 0.44257338842027333\n",
      "Epoch 180, Loss: 0.44223043415311275\n",
      "Epoch 181, Loss: 0.4412573335324542\n",
      "Epoch 182, Loss: 0.4403093939212056\n",
      "Epoch 183, Loss: 0.440210765892682\n",
      "Epoch 184, Loss: 0.4406913267766654\n",
      "Epoch 185, Loss: 0.44119678016972247\n",
      "Epoch 186, Loss: 0.4414768331353019\n",
      "Epoch 187, Loss: 0.44098509893198107\n",
      "Epoch 188, Loss: 0.4399157822542188\n",
      "Epoch 189, Loss: 0.43913002852403843\n",
      "Epoch 190, Loss: 0.43912120575952834\n",
      "Epoch 191, Loss: 0.43958194116248417\n",
      "Epoch 192, Loss: 0.43991779767875194\n",
      "Epoch 193, Loss: 0.4402464762584031\n",
      "Epoch 194, Loss: 0.4397939928277301\n",
      "Epoch 195, Loss: 0.4389848715145781\n",
      "Epoch 196, Loss: 0.43812834372448495\n",
      "Epoch 197, Loss: 0.4378789384628316\n",
      "Epoch 198, Loss: 0.4380569659316353\n",
      "Epoch 199, Loss: 0.4385928231376636\n",
      "Epoch 200, Loss: 0.4396870477941122\n",
      "Epoch 201, Loss: 0.44003322037003134\n",
      "Epoch 202, Loss: 0.4396387344028484\n",
      "Epoch 203, Loss: 0.43797246081508234\n",
      "Epoch 204, Loss: 0.4368868004619995\n",
      "Epoch 205, Loss: 0.4366217722212388\n",
      "Epoch 206, Loss: 0.4370735508315267\n",
      "Epoch 207, Loss: 0.438056659783102\n",
      "Epoch 208, Loss: 0.43828697608838324\n",
      "Epoch 209, Loss: 0.4380426277456835\n",
      "Epoch 210, Loss: 0.4367571723427673\n",
      "Epoch 211, Loss: 0.4358287121793394\n",
      "Epoch 212, Loss: 0.43549599799409766\n",
      "Epoch 213, Loss: 0.435693177425488\n",
      "Epoch 214, Loss: 0.43638716241086417\n",
      "Epoch 215, Loss: 0.43723040175969713\n",
      "Epoch 216, Loss: 0.4381875017781245\n",
      "Epoch 217, Loss: 0.43727582910411245\n",
      "Epoch 218, Loss: 0.4357251884259994\n",
      "Epoch 219, Loss: 0.43449740709117174\n",
      "Epoch 220, Loss: 0.4346007775761442\n",
      "Epoch 221, Loss: 0.4356339371912412\n",
      "Epoch 222, Loss: 0.43683657413065485\n",
      "Epoch 223, Loss: 0.43732786198111706\n",
      "Epoch 224, Loss: 0.43504045750484316\n",
      "Epoch 225, Loss: 0.4336674601818588\n",
      "Epoch 226, Loss: 0.4339570078903568\n",
      "Epoch 227, Loss: 0.43524205442250136\n",
      "Epoch 228, Loss: 0.43692856322479845\n",
      "Epoch 229, Loss: 0.4361014833656456\n",
      "Epoch 230, Loss: 0.43400818547427195\n",
      "Epoch 231, Loss: 0.43282550764678196\n",
      "Epoch 232, Loss: 0.43422302771098475\n",
      "Epoch 233, Loss: 0.43631150394157153\n",
      "Epoch 234, Loss: 0.4363944185143908\n",
      "Epoch 235, Loss: 0.4344230831071679\n",
      "Epoch 236, Loss: 0.43231983169663213\n",
      "Epoch 237, Loss: 0.4338866438813009\n",
      "Epoch 238, Loss: 0.4371328345881963\n",
      "Epoch 239, Loss: 0.4361934054316967\n",
      "Epoch 240, Loss: 0.4336558976182621\n",
      "Epoch 241, Loss: 0.432399290161847\n",
      "Epoch 242, Loss: 0.43439426928256275\n",
      "Epoch 243, Loss: 0.43607225078754297\n",
      "Epoch 244, Loss: 0.432937520696398\n",
      "Epoch 245, Loss: 0.4313183612820463\n",
      "Epoch 246, Loss: 0.432574819035821\n",
      "Epoch 247, Loss: 0.43256944517797463\n",
      "Epoch 248, Loss: 0.4313844637013701\n",
      "Epoch 249, Loss: 0.43068049739004677\n",
      "Epoch 250, Loss: 0.43099675551916994\n",
      "Epoch 251, Loss: 0.43165141303618687\n",
      "Epoch 252, Loss: 0.43069838475760797\n",
      "Epoch 253, Loss: 0.4299371687594886\n",
      "Epoch 254, Loss: 0.43062274760638575\n",
      "Epoch 255, Loss: 0.4311277872870893\n",
      "Epoch 256, Loss: 0.4311714384142778\n",
      "Epoch 257, Loss: 0.43017855241729436\n",
      "Epoch 258, Loss: 0.42926238444708237\n",
      "Epoch 259, Loss: 0.429571014567453\n",
      "Epoch 260, Loss: 0.43070712058104565\n",
      "Epoch 261, Loss: 0.4319815519144537\n",
      "Epoch 262, Loss: 0.4316843105666133\n",
      "Epoch 263, Loss: 0.4304818873122946\n",
      "Epoch 264, Loss: 0.42840412257514504\n",
      "Epoch 265, Loss: 0.42906400353820484\n",
      "Epoch 266, Loss: 0.43117263072273004\n",
      "Epoch 267, Loss: 0.4324830925949777\n",
      "Epoch 268, Loss: 0.432065642300335\n",
      "Epoch 269, Loss: 0.42821550526406094\n",
      "Epoch 270, Loss: 0.42857532485258004\n",
      "Epoch 271, Loss: 0.43234967987659256\n",
      "Epoch 272, Loss: 0.4333620913145171\n",
      "Epoch 273, Loss: 0.43177123704376796\n",
      "Epoch 274, Loss: 0.42781134135031557\n",
      "Epoch 275, Loss: 0.43068236573784513\n",
      "Epoch 276, Loss: 0.4364270609514446\n",
      "Epoch 277, Loss: 0.43077905897178964\n",
      "Epoch 278, Loss: 0.4276025647386226\n",
      "Epoch 279, Loss: 0.42963899858880455\n",
      "Epoch 280, Loss: 0.4293283522141213\n",
      "Epoch 281, Loss: 0.427636522918956\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20649345816617626\n",
      "Test R^2 score: 0.5371248076747945\n",
      "Num of epochs: 282\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Epoch 179, Loss: 0.44257338842027333\n",
      "Epoch 180, Loss: 0.44223043415311275\n",
      "Epoch 181, Loss: 0.4412573335324542\n",
      "Epoch 182, Loss: 0.4403093939212056\n",
      "Epoch 183, Loss: 0.440210765892682\n",
      "Epoch 184, Loss: 0.4406913267766654\n",
      "Epoch 185, Loss: 0.44119678016972247\n",
      "Epoch 186, Loss: 0.4414768331353019\n",
      "Epoch 187, Loss: 0.44098509893198107\n",
      "Epoch 188, Loss: 0.4399157822542188\n",
      "Epoch 189, Loss: 0.43913002852403843\n",
      "Epoch 190, Loss: 0.43912120575952834\n",
      "Epoch 191, Loss: 0.43958194116248417\n",
      "Epoch 192, Loss: 0.43991779767875194\n",
      "Epoch 193, Loss: 0.4402464762584031\n",
      "Epoch 194, Loss: 0.4397939928277301\n",
      "Epoch 195, Loss: 0.4389848715145781\n",
      "Epoch 196, Loss: 0.43812834372448495\n",
      "Epoch 197, Loss: 0.4378789384628316\n",
      "Epoch 198, Loss: 0.4380569659316353\n",
      "Epoch 199, Loss: 0.4385928231376636\n",
      "Epoch 200, Loss: 0.4396870477941122\n",
      "Epoch 201, Loss: 0.44003322037003134\n",
      "Epoch 202, Loss: 0.4396387344028484\n",
      "Epoch 203, Loss: 0.43797246081508234\n",
      "Epoch 204, Loss: 0.4368868004619995\n",
      "Epoch 205, Loss: 0.4366217722212388\n",
      "Epoch 206, Loss: 0.4370735508315267\n",
      "Epoch 207, Loss: 0.438056659783102\n",
      "Epoch 208, Loss: 0.43828697608838324\n",
      "Epoch 209, Loss: 0.4380426277456835\n",
      "Epoch 210, Loss: 0.4367571723427673\n",
      "Epoch 211, Loss: 0.4358287121793394\n",
      "Epoch 212, Loss: 0.43549599799409766\n",
      "Epoch 213, Loss: 0.435693177425488\n",
      "Epoch 214, Loss: 0.43638716241086417\n",
      "Epoch 215, Loss: 0.43723040175969713\n",
      "Epoch 216, Loss: 0.4381875017781245\n",
      "Epoch 217, Loss: 0.43727582910411245\n",
      "Epoch 218, Loss: 0.4357251884259994\n",
      "Epoch 219, Loss: 0.43449740709117174\n",
      "Epoch 220, Loss: 0.4346007775761442\n",
      "Epoch 221, Loss: 0.4356339371912412\n",
      "Epoch 222, Loss: 0.43683657413065485\n",
      "Epoch 223, Loss: 0.43732786198111706\n",
      "Epoch 224, Loss: 0.43504045750484316\n",
      "Epoch 225, Loss: 0.4336674601818588\n",
      "Epoch 226, Loss: 0.4339570078903568\n",
      "Epoch 227, Loss: 0.43524205442250136\n",
      "Epoch 228, Loss: 0.43692856322479845\n",
      "Epoch 229, Loss: 0.4361014833656456\n",
      "Epoch 230, Loss: 0.43400818547427195\n",
      "Epoch 231, Loss: 0.43282550764678196\n",
      "Epoch 232, Loss: 0.43422302771098475\n",
      "Epoch 233, Loss: 0.43631150394157153\n",
      "Epoch 234, Loss: 0.4363944185143908\n",
      "Epoch 235, Loss: 0.4344230831071679\n",
      "Epoch 236, Loss: 0.43231983169663213\n",
      "Epoch 237, Loss: 0.4338866438813009\n",
      "Epoch 238, Loss: 0.4371328345881963\n",
      "Epoch 239, Loss: 0.4361934054316967\n",
      "Epoch 240, Loss: 0.4336558976182621\n",
      "Epoch 241, Loss: 0.432399290161847\n",
      "Epoch 242, Loss: 0.43439426928256275\n",
      "Epoch 243, Loss: 0.43607225078754297\n",
      "Epoch 244, Loss: 0.432937520696398\n",
      "Epoch 245, Loss: 0.4313183612820463\n",
      "Epoch 246, Loss: 0.432574819035821\n",
      "Epoch 247, Loss: 0.43256944517797463\n",
      "Epoch 248, Loss: 0.4313844637013701\n",
      "Epoch 249, Loss: 0.43068049739004677\n",
      "Epoch 250, Loss: 0.43099675551916994\n",
      "Epoch 251, Loss: 0.43165141303618687\n",
      "Epoch 252, Loss: 0.43069838475760797\n",
      "Epoch 253, Loss: 0.4299371687594886\n",
      "Epoch 254, Loss: 0.43062274760638575\n",
      "Epoch 255, Loss: 0.4311277872870893\n",
      "Epoch 256, Loss: 0.4311714384142778\n",
      "Epoch 257, Loss: 0.43017855241729436\n",
      "Epoch 258, Loss: 0.42926238444708237\n",
      "Epoch 259, Loss: 0.429571014567453\n",
      "Epoch 260, Loss: 0.43070712058104565\n",
      "Epoch 261, Loss: 0.4319815519144537\n",
      "Epoch 262, Loss: 0.4316843105666133\n",
      "Epoch 263, Loss: 0.4304818873122946\n",
      "Epoch 264, Loss: 0.42840412257514504\n",
      "Epoch 265, Loss: 0.42906400353820484\n",
      "Epoch 266, Loss: 0.43117263072273004\n",
      "Epoch 267, Loss: 0.4324830925949777\n",
      "Epoch 268, Loss: 0.432065642300335\n",
      "Epoch 269, Loss: 0.42821550526406094\n",
      "Epoch 270, Loss: 0.42857532485258004\n",
      "Epoch 271, Loss: 0.43234967987659256\n",
      "Epoch 272, Loss: 0.4333620913145171\n",
      "Epoch 273, Loss: 0.43177123704376796\n",
      "Epoch 274, Loss: 0.42781134135031557\n",
      "Epoch 275, Loss: 0.43068236573784513\n",
      "Epoch 276, Loss: 0.4364270609514446\n",
      "Epoch 277, Loss: 0.43077905897178964\n",
      "Epoch 278, Loss: 0.4276025647386226\n",
      "Epoch 279, Loss: 0.42963899858880455\n",
      "Epoch 280, Loss: 0.4293283522141213\n",
      "Epoch 281, Loss: 0.427636522918956\n",
      "Epoch 282, Loss: 0.4263990277621903\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2099005135660066\n",
      "Test R^2 score: 0.521732197412552\n",
      "Num of epochs: 283\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Epoch 179, Loss: 0.44257338842027333\n",
      "Epoch 180, Loss: 0.44223043415311275\n",
      "Epoch 181, Loss: 0.4412573335324542\n",
      "Epoch 182, Loss: 0.4403093939212056\n",
      "Epoch 183, Loss: 0.440210765892682\n",
      "Epoch 184, Loss: 0.4406913267766654\n",
      "Epoch 185, Loss: 0.44119678016972247\n",
      "Epoch 186, Loss: 0.4414768331353019\n",
      "Epoch 187, Loss: 0.44098509893198107\n",
      "Epoch 188, Loss: 0.4399157822542188\n",
      "Epoch 189, Loss: 0.43913002852403843\n",
      "Epoch 190, Loss: 0.43912120575952834\n",
      "Epoch 191, Loss: 0.43958194116248417\n",
      "Epoch 192, Loss: 0.43991779767875194\n",
      "Epoch 193, Loss: 0.4402464762584031\n",
      "Epoch 194, Loss: 0.4397939928277301\n",
      "Epoch 195, Loss: 0.4389848715145781\n",
      "Epoch 196, Loss: 0.43812834372448495\n",
      "Epoch 197, Loss: 0.4378789384628316\n",
      "Epoch 198, Loss: 0.4380569659316353\n",
      "Epoch 199, Loss: 0.4385928231376636\n",
      "Epoch 200, Loss: 0.4396870477941122\n",
      "Epoch 201, Loss: 0.44003322037003134\n",
      "Epoch 202, Loss: 0.4396387344028484\n",
      "Epoch 203, Loss: 0.43797246081508234\n",
      "Epoch 204, Loss: 0.4368868004619995\n",
      "Epoch 205, Loss: 0.4366217722212388\n",
      "Epoch 206, Loss: 0.4370735508315267\n",
      "Epoch 207, Loss: 0.438056659783102\n",
      "Epoch 208, Loss: 0.43828697608838324\n",
      "Epoch 209, Loss: 0.4380426277456835\n",
      "Epoch 210, Loss: 0.4367571723427673\n",
      "Epoch 211, Loss: 0.4358287121793394\n",
      "Epoch 212, Loss: 0.43549599799409766\n",
      "Epoch 213, Loss: 0.435693177425488\n",
      "Epoch 214, Loss: 0.43638716241086417\n",
      "Epoch 215, Loss: 0.43723040175969713\n",
      "Epoch 216, Loss: 0.4381875017781245\n",
      "Epoch 217, Loss: 0.43727582910411245\n",
      "Epoch 218, Loss: 0.4357251884259994\n",
      "Epoch 219, Loss: 0.43449740709117174\n",
      "Epoch 220, Loss: 0.4346007775761442\n",
      "Epoch 221, Loss: 0.4356339371912412\n",
      "Epoch 222, Loss: 0.43683657413065485\n",
      "Epoch 223, Loss: 0.43732786198111706\n",
      "Epoch 224, Loss: 0.43504045750484316\n",
      "Epoch 225, Loss: 0.4336674601818588\n",
      "Epoch 226, Loss: 0.4339570078903568\n",
      "Epoch 227, Loss: 0.43524205442250136\n",
      "Epoch 228, Loss: 0.43692856322479845\n",
      "Epoch 229, Loss: 0.4361014833656456\n",
      "Epoch 230, Loss: 0.43400818547427195\n",
      "Epoch 231, Loss: 0.43282550764678196\n",
      "Epoch 232, Loss: 0.43422302771098475\n",
      "Epoch 233, Loss: 0.43631150394157153\n",
      "Epoch 234, Loss: 0.4363944185143908\n",
      "Epoch 235, Loss: 0.4344230831071679\n",
      "Epoch 236, Loss: 0.43231983169663213\n",
      "Epoch 237, Loss: 0.4338866438813009\n",
      "Epoch 238, Loss: 0.4371328345881963\n",
      "Epoch 239, Loss: 0.4361934054316967\n",
      "Epoch 240, Loss: 0.4336558976182621\n",
      "Epoch 241, Loss: 0.432399290161847\n",
      "Epoch 242, Loss: 0.43439426928256275\n",
      "Epoch 243, Loss: 0.43607225078754297\n",
      "Epoch 244, Loss: 0.432937520696398\n",
      "Epoch 245, Loss: 0.4313183612820463\n",
      "Epoch 246, Loss: 0.432574819035821\n",
      "Epoch 247, Loss: 0.43256944517797463\n",
      "Epoch 248, Loss: 0.4313844637013701\n",
      "Epoch 249, Loss: 0.43068049739004677\n",
      "Epoch 250, Loss: 0.43099675551916994\n",
      "Epoch 251, Loss: 0.43165141303618687\n",
      "Epoch 252, Loss: 0.43069838475760797\n",
      "Epoch 253, Loss: 0.4299371687594886\n",
      "Epoch 254, Loss: 0.43062274760638575\n",
      "Epoch 255, Loss: 0.4311277872870893\n",
      "Epoch 256, Loss: 0.4311714384142778\n",
      "Epoch 257, Loss: 0.43017855241729436\n",
      "Epoch 258, Loss: 0.42926238444708237\n",
      "Epoch 259, Loss: 0.429571014567453\n",
      "Epoch 260, Loss: 0.43070712058104565\n",
      "Epoch 261, Loss: 0.4319815519144537\n",
      "Epoch 262, Loss: 0.4316843105666133\n",
      "Epoch 263, Loss: 0.4304818873122946\n",
      "Epoch 264, Loss: 0.42840412257514504\n",
      "Epoch 265, Loss: 0.42906400353820484\n",
      "Epoch 266, Loss: 0.43117263072273004\n",
      "Epoch 267, Loss: 0.4324830925949777\n",
      "Epoch 268, Loss: 0.432065642300335\n",
      "Epoch 269, Loss: 0.42821550526406094\n",
      "Epoch 270, Loss: 0.42857532485258004\n",
      "Epoch 271, Loss: 0.43234967987659256\n",
      "Epoch 272, Loss: 0.4333620913145171\n",
      "Epoch 273, Loss: 0.43177123704376796\n",
      "Epoch 274, Loss: 0.42781134135031557\n",
      "Epoch 275, Loss: 0.43068236573784513\n",
      "Epoch 276, Loss: 0.4364270609514446\n",
      "Epoch 277, Loss: 0.43077905897178964\n",
      "Epoch 278, Loss: 0.4276025647386226\n",
      "Epoch 279, Loss: 0.42963899858880455\n",
      "Epoch 280, Loss: 0.4293283522141213\n",
      "Epoch 281, Loss: 0.427636522918956\n",
      "Epoch 282, Loss: 0.4263990277621903\n",
      "Epoch 283, Loss: 0.4275561270482115\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2057025877675872\n",
      "Test R^2 score: 0.5397860710239639\n",
      "Num of epochs: 284\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Epoch 179, Loss: 0.44257338842027333\n",
      "Epoch 180, Loss: 0.44223043415311275\n",
      "Epoch 181, Loss: 0.4412573335324542\n",
      "Epoch 182, Loss: 0.4403093939212056\n",
      "Epoch 183, Loss: 0.440210765892682\n",
      "Epoch 184, Loss: 0.4406913267766654\n",
      "Epoch 185, Loss: 0.44119678016972247\n",
      "Epoch 186, Loss: 0.4414768331353019\n",
      "Epoch 187, Loss: 0.44098509893198107\n",
      "Epoch 188, Loss: 0.4399157822542188\n",
      "Epoch 189, Loss: 0.43913002852403843\n",
      "Epoch 190, Loss: 0.43912120575952834\n",
      "Epoch 191, Loss: 0.43958194116248417\n",
      "Epoch 192, Loss: 0.43991779767875194\n",
      "Epoch 193, Loss: 0.4402464762584031\n",
      "Epoch 194, Loss: 0.4397939928277301\n",
      "Epoch 195, Loss: 0.4389848715145781\n",
      "Epoch 196, Loss: 0.43812834372448495\n",
      "Epoch 197, Loss: 0.4378789384628316\n",
      "Epoch 198, Loss: 0.4380569659316353\n",
      "Epoch 199, Loss: 0.4385928231376636\n",
      "Epoch 200, Loss: 0.4396870477941122\n",
      "Epoch 201, Loss: 0.44003322037003134\n",
      "Epoch 202, Loss: 0.4396387344028484\n",
      "Epoch 203, Loss: 0.43797246081508234\n",
      "Epoch 204, Loss: 0.4368868004619995\n",
      "Epoch 205, Loss: 0.4366217722212388\n",
      "Epoch 206, Loss: 0.4370735508315267\n",
      "Epoch 207, Loss: 0.438056659783102\n",
      "Epoch 208, Loss: 0.43828697608838324\n",
      "Epoch 209, Loss: 0.4380426277456835\n",
      "Epoch 210, Loss: 0.4367571723427673\n",
      "Epoch 211, Loss: 0.4358287121793394\n",
      "Epoch 212, Loss: 0.43549599799409766\n",
      "Epoch 213, Loss: 0.435693177425488\n",
      "Epoch 214, Loss: 0.43638716241086417\n",
      "Epoch 215, Loss: 0.43723040175969713\n",
      "Epoch 216, Loss: 0.4381875017781245\n",
      "Epoch 217, Loss: 0.43727582910411245\n",
      "Epoch 218, Loss: 0.4357251884259994\n",
      "Epoch 219, Loss: 0.43449740709117174\n",
      "Epoch 220, Loss: 0.4346007775761442\n",
      "Epoch 221, Loss: 0.4356339371912412\n",
      "Epoch 222, Loss: 0.43683657413065485\n",
      "Epoch 223, Loss: 0.43732786198111706\n",
      "Epoch 224, Loss: 0.43504045750484316\n",
      "Epoch 225, Loss: 0.4336674601818588\n",
      "Epoch 226, Loss: 0.4339570078903568\n",
      "Epoch 227, Loss: 0.43524205442250136\n",
      "Epoch 228, Loss: 0.43692856322479845\n",
      "Epoch 229, Loss: 0.4361014833656456\n",
      "Epoch 230, Loss: 0.43400818547427195\n",
      "Epoch 231, Loss: 0.43282550764678196\n",
      "Epoch 232, Loss: 0.43422302771098475\n",
      "Epoch 233, Loss: 0.43631150394157153\n",
      "Epoch 234, Loss: 0.4363944185143908\n",
      "Epoch 235, Loss: 0.4344230831071679\n",
      "Epoch 236, Loss: 0.43231983169663213\n",
      "Epoch 237, Loss: 0.4338866438813009\n",
      "Epoch 238, Loss: 0.4371328345881963\n",
      "Epoch 239, Loss: 0.4361934054316967\n",
      "Epoch 240, Loss: 0.4336558976182621\n",
      "Epoch 241, Loss: 0.432399290161847\n",
      "Epoch 242, Loss: 0.43439426928256275\n",
      "Epoch 243, Loss: 0.43607225078754297\n",
      "Epoch 244, Loss: 0.432937520696398\n",
      "Epoch 245, Loss: 0.4313183612820463\n",
      "Epoch 246, Loss: 0.432574819035821\n",
      "Epoch 247, Loss: 0.43256944517797463\n",
      "Epoch 248, Loss: 0.4313844637013701\n",
      "Epoch 249, Loss: 0.43068049739004677\n",
      "Epoch 250, Loss: 0.43099675551916994\n",
      "Epoch 251, Loss: 0.43165141303618687\n",
      "Epoch 252, Loss: 0.43069838475760797\n",
      "Epoch 253, Loss: 0.4299371687594886\n",
      "Epoch 254, Loss: 0.43062274760638575\n",
      "Epoch 255, Loss: 0.4311277872870893\n",
      "Epoch 256, Loss: 0.4311714384142778\n",
      "Epoch 257, Loss: 0.43017855241729436\n",
      "Epoch 258, Loss: 0.42926238444708237\n",
      "Epoch 259, Loss: 0.429571014567453\n",
      "Epoch 260, Loss: 0.43070712058104565\n",
      "Epoch 261, Loss: 0.4319815519144537\n",
      "Epoch 262, Loss: 0.4316843105666133\n",
      "Epoch 263, Loss: 0.4304818873122946\n",
      "Epoch 264, Loss: 0.42840412257514504\n",
      "Epoch 265, Loss: 0.42906400353820484\n",
      "Epoch 266, Loss: 0.43117263072273004\n",
      "Epoch 267, Loss: 0.4324830925949777\n",
      "Epoch 268, Loss: 0.432065642300335\n",
      "Epoch 269, Loss: 0.42821550526406094\n",
      "Epoch 270, Loss: 0.42857532485258004\n",
      "Epoch 271, Loss: 0.43234967987659256\n",
      "Epoch 272, Loss: 0.4333620913145171\n",
      "Epoch 273, Loss: 0.43177123704376796\n",
      "Epoch 274, Loss: 0.42781134135031557\n",
      "Epoch 275, Loss: 0.43068236573784513\n",
      "Epoch 276, Loss: 0.4364270609514446\n",
      "Epoch 277, Loss: 0.43077905897178964\n",
      "Epoch 278, Loss: 0.4276025647386226\n",
      "Epoch 279, Loss: 0.42963899858880455\n",
      "Epoch 280, Loss: 0.4293283522141213\n",
      "Epoch 281, Loss: 0.427636522918956\n",
      "Epoch 282, Loss: 0.4263990277621903\n",
      "Epoch 283, Loss: 0.4275561270482115\n",
      "Epoch 284, Loss: 0.428346900793098\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20765602050447163\n",
      "Test R^2 score: 0.5315664781974305\n",
      "Num of epochs: 285\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Epoch 179, Loss: 0.44257338842027333\n",
      "Epoch 180, Loss: 0.44223043415311275\n",
      "Epoch 181, Loss: 0.4412573335324542\n",
      "Epoch 182, Loss: 0.4403093939212056\n",
      "Epoch 183, Loss: 0.440210765892682\n",
      "Epoch 184, Loss: 0.4406913267766654\n",
      "Epoch 185, Loss: 0.44119678016972247\n",
      "Epoch 186, Loss: 0.4414768331353019\n",
      "Epoch 187, Loss: 0.44098509893198107\n",
      "Epoch 188, Loss: 0.4399157822542188\n",
      "Epoch 189, Loss: 0.43913002852403843\n",
      "Epoch 190, Loss: 0.43912120575952834\n",
      "Epoch 191, Loss: 0.43958194116248417\n",
      "Epoch 192, Loss: 0.43991779767875194\n",
      "Epoch 193, Loss: 0.4402464762584031\n",
      "Epoch 194, Loss: 0.4397939928277301\n",
      "Epoch 195, Loss: 0.4389848715145781\n",
      "Epoch 196, Loss: 0.43812834372448495\n",
      "Epoch 197, Loss: 0.4378789384628316\n",
      "Epoch 198, Loss: 0.4380569659316353\n",
      "Epoch 199, Loss: 0.4385928231376636\n",
      "Epoch 200, Loss: 0.4396870477941122\n",
      "Epoch 201, Loss: 0.44003322037003134\n",
      "Epoch 202, Loss: 0.4396387344028484\n",
      "Epoch 203, Loss: 0.43797246081508234\n",
      "Epoch 204, Loss: 0.4368868004619995\n",
      "Epoch 205, Loss: 0.4366217722212388\n",
      "Epoch 206, Loss: 0.4370735508315267\n",
      "Epoch 207, Loss: 0.438056659783102\n",
      "Epoch 208, Loss: 0.43828697608838324\n",
      "Epoch 209, Loss: 0.4380426277456835\n",
      "Epoch 210, Loss: 0.4367571723427673\n",
      "Epoch 211, Loss: 0.4358287121793394\n",
      "Epoch 212, Loss: 0.43549599799409766\n",
      "Epoch 213, Loss: 0.435693177425488\n",
      "Epoch 214, Loss: 0.43638716241086417\n",
      "Epoch 215, Loss: 0.43723040175969713\n",
      "Epoch 216, Loss: 0.4381875017781245\n",
      "Epoch 217, Loss: 0.43727582910411245\n",
      "Epoch 218, Loss: 0.4357251884259994\n",
      "Epoch 219, Loss: 0.43449740709117174\n",
      "Epoch 220, Loss: 0.4346007775761442\n",
      "Epoch 221, Loss: 0.4356339371912412\n",
      "Epoch 222, Loss: 0.43683657413065485\n",
      "Epoch 223, Loss: 0.43732786198111706\n",
      "Epoch 224, Loss: 0.43504045750484316\n",
      "Epoch 225, Loss: 0.4336674601818588\n",
      "Epoch 226, Loss: 0.4339570078903568\n",
      "Epoch 227, Loss: 0.43524205442250136\n",
      "Epoch 228, Loss: 0.43692856322479845\n",
      "Epoch 229, Loss: 0.4361014833656456\n",
      "Epoch 230, Loss: 0.43400818547427195\n",
      "Epoch 231, Loss: 0.43282550764678196\n",
      "Epoch 232, Loss: 0.43422302771098475\n",
      "Epoch 233, Loss: 0.43631150394157153\n",
      "Epoch 234, Loss: 0.4363944185143908\n",
      "Epoch 235, Loss: 0.4344230831071679\n",
      "Epoch 236, Loss: 0.43231983169663213\n",
      "Epoch 237, Loss: 0.4338866438813009\n",
      "Epoch 238, Loss: 0.4371328345881963\n",
      "Epoch 239, Loss: 0.4361934054316967\n",
      "Epoch 240, Loss: 0.4336558976182621\n",
      "Epoch 241, Loss: 0.432399290161847\n",
      "Epoch 242, Loss: 0.43439426928256275\n",
      "Epoch 243, Loss: 0.43607225078754297\n",
      "Epoch 244, Loss: 0.432937520696398\n",
      "Epoch 245, Loss: 0.4313183612820463\n",
      "Epoch 246, Loss: 0.432574819035821\n",
      "Epoch 247, Loss: 0.43256944517797463\n",
      "Epoch 248, Loss: 0.4313844637013701\n",
      "Epoch 249, Loss: 0.43068049739004677\n",
      "Epoch 250, Loss: 0.43099675551916994\n",
      "Epoch 251, Loss: 0.43165141303618687\n",
      "Epoch 252, Loss: 0.43069838475760797\n",
      "Epoch 253, Loss: 0.4299371687594886\n",
      "Epoch 254, Loss: 0.43062274760638575\n",
      "Epoch 255, Loss: 0.4311277872870893\n",
      "Epoch 256, Loss: 0.4311714384142778\n",
      "Epoch 257, Loss: 0.43017855241729436\n",
      "Epoch 258, Loss: 0.42926238444708237\n",
      "Epoch 259, Loss: 0.429571014567453\n",
      "Epoch 260, Loss: 0.43070712058104565\n",
      "Epoch 261, Loss: 0.4319815519144537\n",
      "Epoch 262, Loss: 0.4316843105666133\n",
      "Epoch 263, Loss: 0.4304818873122946\n",
      "Epoch 264, Loss: 0.42840412257514504\n",
      "Epoch 265, Loss: 0.42906400353820484\n",
      "Epoch 266, Loss: 0.43117263072273004\n",
      "Epoch 267, Loss: 0.4324830925949777\n",
      "Epoch 268, Loss: 0.432065642300335\n",
      "Epoch 269, Loss: 0.42821550526406094\n",
      "Epoch 270, Loss: 0.42857532485258004\n",
      "Epoch 271, Loss: 0.43234967987659256\n",
      "Epoch 272, Loss: 0.4333620913145171\n",
      "Epoch 273, Loss: 0.43177123704376796\n",
      "Epoch 274, Loss: 0.42781134135031557\n",
      "Epoch 275, Loss: 0.43068236573784513\n",
      "Epoch 276, Loss: 0.4364270609514446\n",
      "Epoch 277, Loss: 0.43077905897178964\n",
      "Epoch 278, Loss: 0.4276025647386226\n",
      "Epoch 279, Loss: 0.42963899858880455\n",
      "Epoch 280, Loss: 0.4293283522141213\n",
      "Epoch 281, Loss: 0.427636522918956\n",
      "Epoch 282, Loss: 0.4263990277621903\n",
      "Epoch 283, Loss: 0.4275561270482115\n",
      "Epoch 284, Loss: 0.428346900793098\n",
      "Epoch 285, Loss: 0.4260589848692751\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20891596243093105\n",
      "Test R^2 score: 0.5261677194170747\n",
      "Num of epochs: 286\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Epoch 179, Loss: 0.44257338842027333\n",
      "Epoch 180, Loss: 0.44223043415311275\n",
      "Epoch 181, Loss: 0.4412573335324542\n",
      "Epoch 182, Loss: 0.4403093939212056\n",
      "Epoch 183, Loss: 0.440210765892682\n",
      "Epoch 184, Loss: 0.4406913267766654\n",
      "Epoch 185, Loss: 0.44119678016972247\n",
      "Epoch 186, Loss: 0.4414768331353019\n",
      "Epoch 187, Loss: 0.44098509893198107\n",
      "Epoch 188, Loss: 0.4399157822542188\n",
      "Epoch 189, Loss: 0.43913002852403843\n",
      "Epoch 190, Loss: 0.43912120575952834\n",
      "Epoch 191, Loss: 0.43958194116248417\n",
      "Epoch 192, Loss: 0.43991779767875194\n",
      "Epoch 193, Loss: 0.4402464762584031\n",
      "Epoch 194, Loss: 0.4397939928277301\n",
      "Epoch 195, Loss: 0.4389848715145781\n",
      "Epoch 196, Loss: 0.43812834372448495\n",
      "Epoch 197, Loss: 0.4378789384628316\n",
      "Epoch 198, Loss: 0.4380569659316353\n",
      "Epoch 199, Loss: 0.4385928231376636\n",
      "Epoch 200, Loss: 0.4396870477941122\n",
      "Epoch 201, Loss: 0.44003322037003134\n",
      "Epoch 202, Loss: 0.4396387344028484\n",
      "Epoch 203, Loss: 0.43797246081508234\n",
      "Epoch 204, Loss: 0.4368868004619995\n",
      "Epoch 205, Loss: 0.4366217722212388\n",
      "Epoch 206, Loss: 0.4370735508315267\n",
      "Epoch 207, Loss: 0.438056659783102\n",
      "Epoch 208, Loss: 0.43828697608838324\n",
      "Epoch 209, Loss: 0.4380426277456835\n",
      "Epoch 210, Loss: 0.4367571723427673\n",
      "Epoch 211, Loss: 0.4358287121793394\n",
      "Epoch 212, Loss: 0.43549599799409766\n",
      "Epoch 213, Loss: 0.435693177425488\n",
      "Epoch 214, Loss: 0.43638716241086417\n",
      "Epoch 215, Loss: 0.43723040175969713\n",
      "Epoch 216, Loss: 0.4381875017781245\n",
      "Epoch 217, Loss: 0.43727582910411245\n",
      "Epoch 218, Loss: 0.4357251884259994\n",
      "Epoch 219, Loss: 0.43449740709117174\n",
      "Epoch 220, Loss: 0.4346007775761442\n",
      "Epoch 221, Loss: 0.4356339371912412\n",
      "Epoch 222, Loss: 0.43683657413065485\n",
      "Epoch 223, Loss: 0.43732786198111706\n",
      "Epoch 224, Loss: 0.43504045750484316\n",
      "Epoch 225, Loss: 0.4336674601818588\n",
      "Epoch 226, Loss: 0.4339570078903568\n",
      "Epoch 227, Loss: 0.43524205442250136\n",
      "Epoch 228, Loss: 0.43692856322479845\n",
      "Epoch 229, Loss: 0.4361014833656456\n",
      "Epoch 230, Loss: 0.43400818547427195\n",
      "Epoch 231, Loss: 0.43282550764678196\n",
      "Epoch 232, Loss: 0.43422302771098475\n",
      "Epoch 233, Loss: 0.43631150394157153\n",
      "Epoch 234, Loss: 0.4363944185143908\n",
      "Epoch 235, Loss: 0.4344230831071679\n",
      "Epoch 236, Loss: 0.43231983169663213\n",
      "Epoch 237, Loss: 0.4338866438813009\n",
      "Epoch 238, Loss: 0.4371328345881963\n",
      "Epoch 239, Loss: 0.4361934054316967\n",
      "Epoch 240, Loss: 0.4336558976182621\n",
      "Epoch 241, Loss: 0.432399290161847\n",
      "Epoch 242, Loss: 0.43439426928256275\n",
      "Epoch 243, Loss: 0.43607225078754297\n",
      "Epoch 244, Loss: 0.432937520696398\n",
      "Epoch 245, Loss: 0.4313183612820463\n",
      "Epoch 246, Loss: 0.432574819035821\n",
      "Epoch 247, Loss: 0.43256944517797463\n",
      "Epoch 248, Loss: 0.4313844637013701\n",
      "Epoch 249, Loss: 0.43068049739004677\n",
      "Epoch 250, Loss: 0.43099675551916994\n",
      "Epoch 251, Loss: 0.43165141303618687\n",
      "Epoch 252, Loss: 0.43069838475760797\n",
      "Epoch 253, Loss: 0.4299371687594886\n",
      "Epoch 254, Loss: 0.43062274760638575\n",
      "Epoch 255, Loss: 0.4311277872870893\n",
      "Epoch 256, Loss: 0.4311714384142778\n",
      "Epoch 257, Loss: 0.43017855241729436\n",
      "Epoch 258, Loss: 0.42926238444708237\n",
      "Epoch 259, Loss: 0.429571014567453\n",
      "Epoch 260, Loss: 0.43070712058104565\n",
      "Epoch 261, Loss: 0.4319815519144537\n",
      "Epoch 262, Loss: 0.4316843105666133\n",
      "Epoch 263, Loss: 0.4304818873122946\n",
      "Epoch 264, Loss: 0.42840412257514504\n",
      "Epoch 265, Loss: 0.42906400353820484\n",
      "Epoch 266, Loss: 0.43117263072273004\n",
      "Epoch 267, Loss: 0.4324830925949777\n",
      "Epoch 268, Loss: 0.432065642300335\n",
      "Epoch 269, Loss: 0.42821550526406094\n",
      "Epoch 270, Loss: 0.42857532485258004\n",
      "Epoch 271, Loss: 0.43234967987659256\n",
      "Epoch 272, Loss: 0.4333620913145171\n",
      "Epoch 273, Loss: 0.43177123704376796\n",
      "Epoch 274, Loss: 0.42781134135031557\n",
      "Epoch 275, Loss: 0.43068236573784513\n",
      "Epoch 276, Loss: 0.4364270609514446\n",
      "Epoch 277, Loss: 0.43077905897178964\n",
      "Epoch 278, Loss: 0.4276025647386226\n",
      "Epoch 279, Loss: 0.42963899858880455\n",
      "Epoch 280, Loss: 0.4293283522141213\n",
      "Epoch 281, Loss: 0.427636522918956\n",
      "Epoch 282, Loss: 0.4263990277621903\n",
      "Epoch 283, Loss: 0.4275561270482115\n",
      "Epoch 284, Loss: 0.428346900793098\n",
      "Epoch 285, Loss: 0.4260589848692751\n",
      "Epoch 286, Loss: 0.42638137940549814\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.206409568785495\n",
      "Test R^2 score: 0.536828197676629\n",
      "Num of epochs: 287\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Epoch 179, Loss: 0.44257338842027333\n",
      "Epoch 180, Loss: 0.44223043415311275\n",
      "Epoch 181, Loss: 0.4412573335324542\n",
      "Epoch 182, Loss: 0.4403093939212056\n",
      "Epoch 183, Loss: 0.440210765892682\n",
      "Epoch 184, Loss: 0.4406913267766654\n",
      "Epoch 185, Loss: 0.44119678016972247\n",
      "Epoch 186, Loss: 0.4414768331353019\n",
      "Epoch 187, Loss: 0.44098509893198107\n",
      "Epoch 188, Loss: 0.4399157822542188\n",
      "Epoch 189, Loss: 0.43913002852403843\n",
      "Epoch 190, Loss: 0.43912120575952834\n",
      "Epoch 191, Loss: 0.43958194116248417\n",
      "Epoch 192, Loss: 0.43991779767875194\n",
      "Epoch 193, Loss: 0.4402464762584031\n",
      "Epoch 194, Loss: 0.4397939928277301\n",
      "Epoch 195, Loss: 0.4389848715145781\n",
      "Epoch 196, Loss: 0.43812834372448495\n",
      "Epoch 197, Loss: 0.4378789384628316\n",
      "Epoch 198, Loss: 0.4380569659316353\n",
      "Epoch 199, Loss: 0.4385928231376636\n",
      "Epoch 200, Loss: 0.4396870477941122\n",
      "Epoch 201, Loss: 0.44003322037003134\n",
      "Epoch 202, Loss: 0.4396387344028484\n",
      "Epoch 203, Loss: 0.43797246081508234\n",
      "Epoch 204, Loss: 0.4368868004619995\n",
      "Epoch 205, Loss: 0.4366217722212388\n",
      "Epoch 206, Loss: 0.4370735508315267\n",
      "Epoch 207, Loss: 0.438056659783102\n",
      "Epoch 208, Loss: 0.43828697608838324\n",
      "Epoch 209, Loss: 0.4380426277456835\n",
      "Epoch 210, Loss: 0.4367571723427673\n",
      "Epoch 211, Loss: 0.4358287121793394\n",
      "Epoch 212, Loss: 0.43549599799409766\n",
      "Epoch 213, Loss: 0.435693177425488\n",
      "Epoch 214, Loss: 0.43638716241086417\n",
      "Epoch 215, Loss: 0.43723040175969713\n",
      "Epoch 216, Loss: 0.4381875017781245\n",
      "Epoch 217, Loss: 0.43727582910411245\n",
      "Epoch 218, Loss: 0.4357251884259994\n",
      "Epoch 219, Loss: 0.43449740709117174\n",
      "Epoch 220, Loss: 0.4346007775761442\n",
      "Epoch 221, Loss: 0.4356339371912412\n",
      "Epoch 222, Loss: 0.43683657413065485\n",
      "Epoch 223, Loss: 0.43732786198111706\n",
      "Epoch 224, Loss: 0.43504045750484316\n",
      "Epoch 225, Loss: 0.4336674601818588\n",
      "Epoch 226, Loss: 0.4339570078903568\n",
      "Epoch 227, Loss: 0.43524205442250136\n",
      "Epoch 228, Loss: 0.43692856322479845\n",
      "Epoch 229, Loss: 0.4361014833656456\n",
      "Epoch 230, Loss: 0.43400818547427195\n",
      "Epoch 231, Loss: 0.43282550764678196\n",
      "Epoch 232, Loss: 0.43422302771098475\n",
      "Epoch 233, Loss: 0.43631150394157153\n",
      "Epoch 234, Loss: 0.4363944185143908\n",
      "Epoch 235, Loss: 0.4344230831071679\n",
      "Epoch 236, Loss: 0.43231983169663213\n",
      "Epoch 237, Loss: 0.4338866438813009\n",
      "Epoch 238, Loss: 0.4371328345881963\n",
      "Epoch 239, Loss: 0.4361934054316967\n",
      "Epoch 240, Loss: 0.4336558976182621\n",
      "Epoch 241, Loss: 0.432399290161847\n",
      "Epoch 242, Loss: 0.43439426928256275\n",
      "Epoch 243, Loss: 0.43607225078754297\n",
      "Epoch 244, Loss: 0.432937520696398\n",
      "Epoch 245, Loss: 0.4313183612820463\n",
      "Epoch 246, Loss: 0.432574819035821\n",
      "Epoch 247, Loss: 0.43256944517797463\n",
      "Epoch 248, Loss: 0.4313844637013701\n",
      "Epoch 249, Loss: 0.43068049739004677\n",
      "Epoch 250, Loss: 0.43099675551916994\n",
      "Epoch 251, Loss: 0.43165141303618687\n",
      "Epoch 252, Loss: 0.43069838475760797\n",
      "Epoch 253, Loss: 0.4299371687594886\n",
      "Epoch 254, Loss: 0.43062274760638575\n",
      "Epoch 255, Loss: 0.4311277872870893\n",
      "Epoch 256, Loss: 0.4311714384142778\n",
      "Epoch 257, Loss: 0.43017855241729436\n",
      "Epoch 258, Loss: 0.42926238444708237\n",
      "Epoch 259, Loss: 0.429571014567453\n",
      "Epoch 260, Loss: 0.43070712058104565\n",
      "Epoch 261, Loss: 0.4319815519144537\n",
      "Epoch 262, Loss: 0.4316843105666133\n",
      "Epoch 263, Loss: 0.4304818873122946\n",
      "Epoch 264, Loss: 0.42840412257514504\n",
      "Epoch 265, Loss: 0.42906400353820484\n",
      "Epoch 266, Loss: 0.43117263072273004\n",
      "Epoch 267, Loss: 0.4324830925949777\n",
      "Epoch 268, Loss: 0.432065642300335\n",
      "Epoch 269, Loss: 0.42821550526406094\n",
      "Epoch 270, Loss: 0.42857532485258004\n",
      "Epoch 271, Loss: 0.43234967987659256\n",
      "Epoch 272, Loss: 0.4333620913145171\n",
      "Epoch 273, Loss: 0.43177123704376796\n",
      "Epoch 274, Loss: 0.42781134135031557\n",
      "Epoch 275, Loss: 0.43068236573784513\n",
      "Epoch 276, Loss: 0.4364270609514446\n",
      "Epoch 277, Loss: 0.43077905897178964\n",
      "Epoch 278, Loss: 0.4276025647386226\n",
      "Epoch 279, Loss: 0.42963899858880455\n",
      "Epoch 280, Loss: 0.4293283522141213\n",
      "Epoch 281, Loss: 0.427636522918956\n",
      "Epoch 282, Loss: 0.4263990277621903\n",
      "Epoch 283, Loss: 0.4275561270482115\n",
      "Epoch 284, Loss: 0.428346900793098\n",
      "Epoch 285, Loss: 0.4260589848692751\n",
      "Epoch 286, Loss: 0.42638137940549814\n",
      "Epoch 287, Loss: 0.42902310764995066\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21197903898037251\n",
      "Test R^2 score: 0.5121088103690525\n",
      "Num of epochs: 288\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Epoch 179, Loss: 0.44257338842027333\n",
      "Epoch 180, Loss: 0.44223043415311275\n",
      "Epoch 181, Loss: 0.4412573335324542\n",
      "Epoch 182, Loss: 0.4403093939212056\n",
      "Epoch 183, Loss: 0.440210765892682\n",
      "Epoch 184, Loss: 0.4406913267766654\n",
      "Epoch 185, Loss: 0.44119678016972247\n",
      "Epoch 186, Loss: 0.4414768331353019\n",
      "Epoch 187, Loss: 0.44098509893198107\n",
      "Epoch 188, Loss: 0.4399157822542188\n",
      "Epoch 189, Loss: 0.43913002852403843\n",
      "Epoch 190, Loss: 0.43912120575952834\n",
      "Epoch 191, Loss: 0.43958194116248417\n",
      "Epoch 192, Loss: 0.43991779767875194\n",
      "Epoch 193, Loss: 0.4402464762584031\n",
      "Epoch 194, Loss: 0.4397939928277301\n",
      "Epoch 195, Loss: 0.4389848715145781\n",
      "Epoch 196, Loss: 0.43812834372448495\n",
      "Epoch 197, Loss: 0.4378789384628316\n",
      "Epoch 198, Loss: 0.4380569659316353\n",
      "Epoch 199, Loss: 0.4385928231376636\n",
      "Epoch 200, Loss: 0.4396870477941122\n",
      "Epoch 201, Loss: 0.44003322037003134\n",
      "Epoch 202, Loss: 0.4396387344028484\n",
      "Epoch 203, Loss: 0.43797246081508234\n",
      "Epoch 204, Loss: 0.4368868004619995\n",
      "Epoch 205, Loss: 0.4366217722212388\n",
      "Epoch 206, Loss: 0.4370735508315267\n",
      "Epoch 207, Loss: 0.438056659783102\n",
      "Epoch 208, Loss: 0.43828697608838324\n",
      "Epoch 209, Loss: 0.4380426277456835\n",
      "Epoch 210, Loss: 0.4367571723427673\n",
      "Epoch 211, Loss: 0.4358287121793394\n",
      "Epoch 212, Loss: 0.43549599799409766\n",
      "Epoch 213, Loss: 0.435693177425488\n",
      "Epoch 214, Loss: 0.43638716241086417\n",
      "Epoch 215, Loss: 0.43723040175969713\n",
      "Epoch 216, Loss: 0.4381875017781245\n",
      "Epoch 217, Loss: 0.43727582910411245\n",
      "Epoch 218, Loss: 0.4357251884259994\n",
      "Epoch 219, Loss: 0.43449740709117174\n",
      "Epoch 220, Loss: 0.4346007775761442\n",
      "Epoch 221, Loss: 0.4356339371912412\n",
      "Epoch 222, Loss: 0.43683657413065485\n",
      "Epoch 223, Loss: 0.43732786198111706\n",
      "Epoch 224, Loss: 0.43504045750484316\n",
      "Epoch 225, Loss: 0.4336674601818588\n",
      "Epoch 226, Loss: 0.4339570078903568\n",
      "Epoch 227, Loss: 0.43524205442250136\n",
      "Epoch 228, Loss: 0.43692856322479845\n",
      "Epoch 229, Loss: 0.4361014833656456\n",
      "Epoch 230, Loss: 0.43400818547427195\n",
      "Epoch 231, Loss: 0.43282550764678196\n",
      "Epoch 232, Loss: 0.43422302771098475\n",
      "Epoch 233, Loss: 0.43631150394157153\n",
      "Epoch 234, Loss: 0.4363944185143908\n",
      "Epoch 235, Loss: 0.4344230831071679\n",
      "Epoch 236, Loss: 0.43231983169663213\n",
      "Epoch 237, Loss: 0.4338866438813009\n",
      "Epoch 238, Loss: 0.4371328345881963\n",
      "Epoch 239, Loss: 0.4361934054316967\n",
      "Epoch 240, Loss: 0.4336558976182621\n",
      "Epoch 241, Loss: 0.432399290161847\n",
      "Epoch 242, Loss: 0.43439426928256275\n",
      "Epoch 243, Loss: 0.43607225078754297\n",
      "Epoch 244, Loss: 0.432937520696398\n",
      "Epoch 245, Loss: 0.4313183612820463\n",
      "Epoch 246, Loss: 0.432574819035821\n",
      "Epoch 247, Loss: 0.43256944517797463\n",
      "Epoch 248, Loss: 0.4313844637013701\n",
      "Epoch 249, Loss: 0.43068049739004677\n",
      "Epoch 250, Loss: 0.43099675551916994\n",
      "Epoch 251, Loss: 0.43165141303618687\n",
      "Epoch 252, Loss: 0.43069838475760797\n",
      "Epoch 253, Loss: 0.4299371687594886\n",
      "Epoch 254, Loss: 0.43062274760638575\n",
      "Epoch 255, Loss: 0.4311277872870893\n",
      "Epoch 256, Loss: 0.4311714384142778\n",
      "Epoch 257, Loss: 0.43017855241729436\n",
      "Epoch 258, Loss: 0.42926238444708237\n",
      "Epoch 259, Loss: 0.429571014567453\n",
      "Epoch 260, Loss: 0.43070712058104565\n",
      "Epoch 261, Loss: 0.4319815519144537\n",
      "Epoch 262, Loss: 0.4316843105666133\n",
      "Epoch 263, Loss: 0.4304818873122946\n",
      "Epoch 264, Loss: 0.42840412257514504\n",
      "Epoch 265, Loss: 0.42906400353820484\n",
      "Epoch 266, Loss: 0.43117263072273004\n",
      "Epoch 267, Loss: 0.4324830925949777\n",
      "Epoch 268, Loss: 0.432065642300335\n",
      "Epoch 269, Loss: 0.42821550526406094\n",
      "Epoch 270, Loss: 0.42857532485258004\n",
      "Epoch 271, Loss: 0.43234967987659256\n",
      "Epoch 272, Loss: 0.4333620913145171\n",
      "Epoch 273, Loss: 0.43177123704376796\n",
      "Epoch 274, Loss: 0.42781134135031557\n",
      "Epoch 275, Loss: 0.43068236573784513\n",
      "Epoch 276, Loss: 0.4364270609514446\n",
      "Epoch 277, Loss: 0.43077905897178964\n",
      "Epoch 278, Loss: 0.4276025647386226\n",
      "Epoch 279, Loss: 0.42963899858880455\n",
      "Epoch 280, Loss: 0.4293283522141213\n",
      "Epoch 281, Loss: 0.427636522918956\n",
      "Epoch 282, Loss: 0.4263990277621903\n",
      "Epoch 283, Loss: 0.4275561270482115\n",
      "Epoch 284, Loss: 0.428346900793098\n",
      "Epoch 285, Loss: 0.4260589848692751\n",
      "Epoch 286, Loss: 0.42638137940549814\n",
      "Epoch 287, Loss: 0.42902310764995066\n",
      "Epoch 288, Loss: 0.42836672926689007\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20585722315786498\n",
      "Test R^2 score: 0.5391117681170967\n",
      "Num of epochs: 289\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Epoch 179, Loss: 0.44257338842027333\n",
      "Epoch 180, Loss: 0.44223043415311275\n",
      "Epoch 181, Loss: 0.4412573335324542\n",
      "Epoch 182, Loss: 0.4403093939212056\n",
      "Epoch 183, Loss: 0.440210765892682\n",
      "Epoch 184, Loss: 0.4406913267766654\n",
      "Epoch 185, Loss: 0.44119678016972247\n",
      "Epoch 186, Loss: 0.4414768331353019\n",
      "Epoch 187, Loss: 0.44098509893198107\n",
      "Epoch 188, Loss: 0.4399157822542188\n",
      "Epoch 189, Loss: 0.43913002852403843\n",
      "Epoch 190, Loss: 0.43912120575952834\n",
      "Epoch 191, Loss: 0.43958194116248417\n",
      "Epoch 192, Loss: 0.43991779767875194\n",
      "Epoch 193, Loss: 0.4402464762584031\n",
      "Epoch 194, Loss: 0.4397939928277301\n",
      "Epoch 195, Loss: 0.4389848715145781\n",
      "Epoch 196, Loss: 0.43812834372448495\n",
      "Epoch 197, Loss: 0.4378789384628316\n",
      "Epoch 198, Loss: 0.4380569659316353\n",
      "Epoch 199, Loss: 0.4385928231376636\n",
      "Epoch 200, Loss: 0.4396870477941122\n",
      "Epoch 201, Loss: 0.44003322037003134\n",
      "Epoch 202, Loss: 0.4396387344028484\n",
      "Epoch 203, Loss: 0.43797246081508234\n",
      "Epoch 204, Loss: 0.4368868004619995\n",
      "Epoch 205, Loss: 0.4366217722212388\n",
      "Epoch 206, Loss: 0.4370735508315267\n",
      "Epoch 207, Loss: 0.438056659783102\n",
      "Epoch 208, Loss: 0.43828697608838324\n",
      "Epoch 209, Loss: 0.4380426277456835\n",
      "Epoch 210, Loss: 0.4367571723427673\n",
      "Epoch 211, Loss: 0.4358287121793394\n",
      "Epoch 212, Loss: 0.43549599799409766\n",
      "Epoch 213, Loss: 0.435693177425488\n",
      "Epoch 214, Loss: 0.43638716241086417\n",
      "Epoch 215, Loss: 0.43723040175969713\n",
      "Epoch 216, Loss: 0.4381875017781245\n",
      "Epoch 217, Loss: 0.43727582910411245\n",
      "Epoch 218, Loss: 0.4357251884259994\n",
      "Epoch 219, Loss: 0.43449740709117174\n",
      "Epoch 220, Loss: 0.4346007775761442\n",
      "Epoch 221, Loss: 0.4356339371912412\n",
      "Epoch 222, Loss: 0.43683657413065485\n",
      "Epoch 223, Loss: 0.43732786198111706\n",
      "Epoch 224, Loss: 0.43504045750484316\n",
      "Epoch 225, Loss: 0.4336674601818588\n",
      "Epoch 226, Loss: 0.4339570078903568\n",
      "Epoch 227, Loss: 0.43524205442250136\n",
      "Epoch 228, Loss: 0.43692856322479845\n",
      "Epoch 229, Loss: 0.4361014833656456\n",
      "Epoch 230, Loss: 0.43400818547427195\n",
      "Epoch 231, Loss: 0.43282550764678196\n",
      "Epoch 232, Loss: 0.43422302771098475\n",
      "Epoch 233, Loss: 0.43631150394157153\n",
      "Epoch 234, Loss: 0.4363944185143908\n",
      "Epoch 235, Loss: 0.4344230831071679\n",
      "Epoch 236, Loss: 0.43231983169663213\n",
      "Epoch 237, Loss: 0.4338866438813009\n",
      "Epoch 238, Loss: 0.4371328345881963\n",
      "Epoch 239, Loss: 0.4361934054316967\n",
      "Epoch 240, Loss: 0.4336558976182621\n",
      "Epoch 241, Loss: 0.432399290161847\n",
      "Epoch 242, Loss: 0.43439426928256275\n",
      "Epoch 243, Loss: 0.43607225078754297\n",
      "Epoch 244, Loss: 0.432937520696398\n",
      "Epoch 245, Loss: 0.4313183612820463\n",
      "Epoch 246, Loss: 0.432574819035821\n",
      "Epoch 247, Loss: 0.43256944517797463\n",
      "Epoch 248, Loss: 0.4313844637013701\n",
      "Epoch 249, Loss: 0.43068049739004677\n",
      "Epoch 250, Loss: 0.43099675551916994\n",
      "Epoch 251, Loss: 0.43165141303618687\n",
      "Epoch 252, Loss: 0.43069838475760797\n",
      "Epoch 253, Loss: 0.4299371687594886\n",
      "Epoch 254, Loss: 0.43062274760638575\n",
      "Epoch 255, Loss: 0.4311277872870893\n",
      "Epoch 256, Loss: 0.4311714384142778\n",
      "Epoch 257, Loss: 0.43017855241729436\n",
      "Epoch 258, Loss: 0.42926238444708237\n",
      "Epoch 259, Loss: 0.429571014567453\n",
      "Epoch 260, Loss: 0.43070712058104565\n",
      "Epoch 261, Loss: 0.4319815519144537\n",
      "Epoch 262, Loss: 0.4316843105666133\n",
      "Epoch 263, Loss: 0.4304818873122946\n",
      "Epoch 264, Loss: 0.42840412257514504\n",
      "Epoch 265, Loss: 0.42906400353820484\n",
      "Epoch 266, Loss: 0.43117263072273004\n",
      "Epoch 267, Loss: 0.4324830925949777\n",
      "Epoch 268, Loss: 0.432065642300335\n",
      "Epoch 269, Loss: 0.42821550526406094\n",
      "Epoch 270, Loss: 0.42857532485258004\n",
      "Epoch 271, Loss: 0.43234967987659256\n",
      "Epoch 272, Loss: 0.4333620913145171\n",
      "Epoch 273, Loss: 0.43177123704376796\n",
      "Epoch 274, Loss: 0.42781134135031557\n",
      "Epoch 275, Loss: 0.43068236573784513\n",
      "Epoch 276, Loss: 0.4364270609514446\n",
      "Epoch 277, Loss: 0.43077905897178964\n",
      "Epoch 278, Loss: 0.4276025647386226\n",
      "Epoch 279, Loss: 0.42963899858880455\n",
      "Epoch 280, Loss: 0.4293283522141213\n",
      "Epoch 281, Loss: 0.427636522918956\n",
      "Epoch 282, Loss: 0.4263990277621903\n",
      "Epoch 283, Loss: 0.4275561270482115\n",
      "Epoch 284, Loss: 0.428346900793098\n",
      "Epoch 285, Loss: 0.4260589848692751\n",
      "Epoch 286, Loss: 0.42638137940549814\n",
      "Epoch 287, Loss: 0.42902310764995066\n",
      "Epoch 288, Loss: 0.42836672926689007\n",
      "Epoch 289, Loss: 0.42654270363727864\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20666115726658477\n",
      "Test R^2 score: 0.5357052247487282\n",
      "Num of epochs: 290\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Epoch 179, Loss: 0.44257338842027333\n",
      "Epoch 180, Loss: 0.44223043415311275\n",
      "Epoch 181, Loss: 0.4412573335324542\n",
      "Epoch 182, Loss: 0.4403093939212056\n",
      "Epoch 183, Loss: 0.440210765892682\n",
      "Epoch 184, Loss: 0.4406913267766654\n",
      "Epoch 185, Loss: 0.44119678016972247\n",
      "Epoch 186, Loss: 0.4414768331353019\n",
      "Epoch 187, Loss: 0.44098509893198107\n",
      "Epoch 188, Loss: 0.4399157822542188\n",
      "Epoch 189, Loss: 0.43913002852403843\n",
      "Epoch 190, Loss: 0.43912120575952834\n",
      "Epoch 191, Loss: 0.43958194116248417\n",
      "Epoch 192, Loss: 0.43991779767875194\n",
      "Epoch 193, Loss: 0.4402464762584031\n",
      "Epoch 194, Loss: 0.4397939928277301\n",
      "Epoch 195, Loss: 0.4389848715145781\n",
      "Epoch 196, Loss: 0.43812834372448495\n",
      "Epoch 197, Loss: 0.4378789384628316\n",
      "Epoch 198, Loss: 0.4380569659316353\n",
      "Epoch 199, Loss: 0.4385928231376636\n",
      "Epoch 200, Loss: 0.4396870477941122\n",
      "Epoch 201, Loss: 0.44003322037003134\n",
      "Epoch 202, Loss: 0.4396387344028484\n",
      "Epoch 203, Loss: 0.43797246081508234\n",
      "Epoch 204, Loss: 0.4368868004619995\n",
      "Epoch 205, Loss: 0.4366217722212388\n",
      "Epoch 206, Loss: 0.4370735508315267\n",
      "Epoch 207, Loss: 0.438056659783102\n",
      "Epoch 208, Loss: 0.43828697608838324\n",
      "Epoch 209, Loss: 0.4380426277456835\n",
      "Epoch 210, Loss: 0.4367571723427673\n",
      "Epoch 211, Loss: 0.4358287121793394\n",
      "Epoch 212, Loss: 0.43549599799409766\n",
      "Epoch 213, Loss: 0.435693177425488\n",
      "Epoch 214, Loss: 0.43638716241086417\n",
      "Epoch 215, Loss: 0.43723040175969713\n",
      "Epoch 216, Loss: 0.4381875017781245\n",
      "Epoch 217, Loss: 0.43727582910411245\n",
      "Epoch 218, Loss: 0.4357251884259994\n",
      "Epoch 219, Loss: 0.43449740709117174\n",
      "Epoch 220, Loss: 0.4346007775761442\n",
      "Epoch 221, Loss: 0.4356339371912412\n",
      "Epoch 222, Loss: 0.43683657413065485\n",
      "Epoch 223, Loss: 0.43732786198111706\n",
      "Epoch 224, Loss: 0.43504045750484316\n",
      "Epoch 225, Loss: 0.4336674601818588\n",
      "Epoch 226, Loss: 0.4339570078903568\n",
      "Epoch 227, Loss: 0.43524205442250136\n",
      "Epoch 228, Loss: 0.43692856322479845\n",
      "Epoch 229, Loss: 0.4361014833656456\n",
      "Epoch 230, Loss: 0.43400818547427195\n",
      "Epoch 231, Loss: 0.43282550764678196\n",
      "Epoch 232, Loss: 0.43422302771098475\n",
      "Epoch 233, Loss: 0.43631150394157153\n",
      "Epoch 234, Loss: 0.4363944185143908\n",
      "Epoch 235, Loss: 0.4344230831071679\n",
      "Epoch 236, Loss: 0.43231983169663213\n",
      "Epoch 237, Loss: 0.4338866438813009\n",
      "Epoch 238, Loss: 0.4371328345881963\n",
      "Epoch 239, Loss: 0.4361934054316967\n",
      "Epoch 240, Loss: 0.4336558976182621\n",
      "Epoch 241, Loss: 0.432399290161847\n",
      "Epoch 242, Loss: 0.43439426928256275\n",
      "Epoch 243, Loss: 0.43607225078754297\n",
      "Epoch 244, Loss: 0.432937520696398\n",
      "Epoch 245, Loss: 0.4313183612820463\n",
      "Epoch 246, Loss: 0.432574819035821\n",
      "Epoch 247, Loss: 0.43256944517797463\n",
      "Epoch 248, Loss: 0.4313844637013701\n",
      "Epoch 249, Loss: 0.43068049739004677\n",
      "Epoch 250, Loss: 0.43099675551916994\n",
      "Epoch 251, Loss: 0.43165141303618687\n",
      "Epoch 252, Loss: 0.43069838475760797\n",
      "Epoch 253, Loss: 0.4299371687594886\n",
      "Epoch 254, Loss: 0.43062274760638575\n",
      "Epoch 255, Loss: 0.4311277872870893\n",
      "Epoch 256, Loss: 0.4311714384142778\n",
      "Epoch 257, Loss: 0.43017855241729436\n",
      "Epoch 258, Loss: 0.42926238444708237\n",
      "Epoch 259, Loss: 0.429571014567453\n",
      "Epoch 260, Loss: 0.43070712058104565\n",
      "Epoch 261, Loss: 0.4319815519144537\n",
      "Epoch 262, Loss: 0.4316843105666133\n",
      "Epoch 263, Loss: 0.4304818873122946\n",
      "Epoch 264, Loss: 0.42840412257514504\n",
      "Epoch 265, Loss: 0.42906400353820484\n",
      "Epoch 266, Loss: 0.43117263072273004\n",
      "Epoch 267, Loss: 0.4324830925949777\n",
      "Epoch 268, Loss: 0.432065642300335\n",
      "Epoch 269, Loss: 0.42821550526406094\n",
      "Epoch 270, Loss: 0.42857532485258004\n",
      "Epoch 271, Loss: 0.43234967987659256\n",
      "Epoch 272, Loss: 0.4333620913145171\n",
      "Epoch 273, Loss: 0.43177123704376796\n",
      "Epoch 274, Loss: 0.42781134135031557\n",
      "Epoch 275, Loss: 0.43068236573784513\n",
      "Epoch 276, Loss: 0.4364270609514446\n",
      "Epoch 277, Loss: 0.43077905897178964\n",
      "Epoch 278, Loss: 0.4276025647386226\n",
      "Epoch 279, Loss: 0.42963899858880455\n",
      "Epoch 280, Loss: 0.4293283522141213\n",
      "Epoch 281, Loss: 0.427636522918956\n",
      "Epoch 282, Loss: 0.4263990277621903\n",
      "Epoch 283, Loss: 0.4275561270482115\n",
      "Epoch 284, Loss: 0.428346900793098\n",
      "Epoch 285, Loss: 0.4260589848692751\n",
      "Epoch 286, Loss: 0.42638137940549814\n",
      "Epoch 287, Loss: 0.42902310764995066\n",
      "Epoch 288, Loss: 0.42836672926689007\n",
      "Epoch 289, Loss: 0.42654270363727864\n",
      "Epoch 290, Loss: 0.42543817399768613\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2106599808773052\n",
      "Test R^2 score: 0.5181532757630111\n",
      "Num of epochs: 291\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Epoch 179, Loss: 0.44257338842027333\n",
      "Epoch 180, Loss: 0.44223043415311275\n",
      "Epoch 181, Loss: 0.4412573335324542\n",
      "Epoch 182, Loss: 0.4403093939212056\n",
      "Epoch 183, Loss: 0.440210765892682\n",
      "Epoch 184, Loss: 0.4406913267766654\n",
      "Epoch 185, Loss: 0.44119678016972247\n",
      "Epoch 186, Loss: 0.4414768331353019\n",
      "Epoch 187, Loss: 0.44098509893198107\n",
      "Epoch 188, Loss: 0.4399157822542188\n",
      "Epoch 189, Loss: 0.43913002852403843\n",
      "Epoch 190, Loss: 0.43912120575952834\n",
      "Epoch 191, Loss: 0.43958194116248417\n",
      "Epoch 192, Loss: 0.43991779767875194\n",
      "Epoch 193, Loss: 0.4402464762584031\n",
      "Epoch 194, Loss: 0.4397939928277301\n",
      "Epoch 195, Loss: 0.4389848715145781\n",
      "Epoch 196, Loss: 0.43812834372448495\n",
      "Epoch 197, Loss: 0.4378789384628316\n",
      "Epoch 198, Loss: 0.4380569659316353\n",
      "Epoch 199, Loss: 0.4385928231376636\n",
      "Epoch 200, Loss: 0.4396870477941122\n",
      "Epoch 201, Loss: 0.44003322037003134\n",
      "Epoch 202, Loss: 0.4396387344028484\n",
      "Epoch 203, Loss: 0.43797246081508234\n",
      "Epoch 204, Loss: 0.4368868004619995\n",
      "Epoch 205, Loss: 0.4366217722212388\n",
      "Epoch 206, Loss: 0.4370735508315267\n",
      "Epoch 207, Loss: 0.438056659783102\n",
      "Epoch 208, Loss: 0.43828697608838324\n",
      "Epoch 209, Loss: 0.4380426277456835\n",
      "Epoch 210, Loss: 0.4367571723427673\n",
      "Epoch 211, Loss: 0.4358287121793394\n",
      "Epoch 212, Loss: 0.43549599799409766\n",
      "Epoch 213, Loss: 0.435693177425488\n",
      "Epoch 214, Loss: 0.43638716241086417\n",
      "Epoch 215, Loss: 0.43723040175969713\n",
      "Epoch 216, Loss: 0.4381875017781245\n",
      "Epoch 217, Loss: 0.43727582910411245\n",
      "Epoch 218, Loss: 0.4357251884259994\n",
      "Epoch 219, Loss: 0.43449740709117174\n",
      "Epoch 220, Loss: 0.4346007775761442\n",
      "Epoch 221, Loss: 0.4356339371912412\n",
      "Epoch 222, Loss: 0.43683657413065485\n",
      "Epoch 223, Loss: 0.43732786198111706\n",
      "Epoch 224, Loss: 0.43504045750484316\n",
      "Epoch 225, Loss: 0.4336674601818588\n",
      "Epoch 226, Loss: 0.4339570078903568\n",
      "Epoch 227, Loss: 0.43524205442250136\n",
      "Epoch 228, Loss: 0.43692856322479845\n",
      "Epoch 229, Loss: 0.4361014833656456\n",
      "Epoch 230, Loss: 0.43400818547427195\n",
      "Epoch 231, Loss: 0.43282550764678196\n",
      "Epoch 232, Loss: 0.43422302771098475\n",
      "Epoch 233, Loss: 0.43631150394157153\n",
      "Epoch 234, Loss: 0.4363944185143908\n",
      "Epoch 235, Loss: 0.4344230831071679\n",
      "Epoch 236, Loss: 0.43231983169663213\n",
      "Epoch 237, Loss: 0.4338866438813009\n",
      "Epoch 238, Loss: 0.4371328345881963\n",
      "Epoch 239, Loss: 0.4361934054316967\n",
      "Epoch 240, Loss: 0.4336558976182621\n",
      "Epoch 241, Loss: 0.432399290161847\n",
      "Epoch 242, Loss: 0.43439426928256275\n",
      "Epoch 243, Loss: 0.43607225078754297\n",
      "Epoch 244, Loss: 0.432937520696398\n",
      "Epoch 245, Loss: 0.4313183612820463\n",
      "Epoch 246, Loss: 0.432574819035821\n",
      "Epoch 247, Loss: 0.43256944517797463\n",
      "Epoch 248, Loss: 0.4313844637013701\n",
      "Epoch 249, Loss: 0.43068049739004677\n",
      "Epoch 250, Loss: 0.43099675551916994\n",
      "Epoch 251, Loss: 0.43165141303618687\n",
      "Epoch 252, Loss: 0.43069838475760797\n",
      "Epoch 253, Loss: 0.4299371687594886\n",
      "Epoch 254, Loss: 0.43062274760638575\n",
      "Epoch 255, Loss: 0.4311277872870893\n",
      "Epoch 256, Loss: 0.4311714384142778\n",
      "Epoch 257, Loss: 0.43017855241729436\n",
      "Epoch 258, Loss: 0.42926238444708237\n",
      "Epoch 259, Loss: 0.429571014567453\n",
      "Epoch 260, Loss: 0.43070712058104565\n",
      "Epoch 261, Loss: 0.4319815519144537\n",
      "Epoch 262, Loss: 0.4316843105666133\n",
      "Epoch 263, Loss: 0.4304818873122946\n",
      "Epoch 264, Loss: 0.42840412257514504\n",
      "Epoch 265, Loss: 0.42906400353820484\n",
      "Epoch 266, Loss: 0.43117263072273004\n",
      "Epoch 267, Loss: 0.4324830925949777\n",
      "Epoch 268, Loss: 0.432065642300335\n",
      "Epoch 269, Loss: 0.42821550526406094\n",
      "Epoch 270, Loss: 0.42857532485258004\n",
      "Epoch 271, Loss: 0.43234967987659256\n",
      "Epoch 272, Loss: 0.4333620913145171\n",
      "Epoch 273, Loss: 0.43177123704376796\n",
      "Epoch 274, Loss: 0.42781134135031557\n",
      "Epoch 275, Loss: 0.43068236573784513\n",
      "Epoch 276, Loss: 0.4364270609514446\n",
      "Epoch 277, Loss: 0.43077905897178964\n",
      "Epoch 278, Loss: 0.4276025647386226\n",
      "Epoch 279, Loss: 0.42963899858880455\n",
      "Epoch 280, Loss: 0.4293283522141213\n",
      "Epoch 281, Loss: 0.427636522918956\n",
      "Epoch 282, Loss: 0.4263990277621903\n",
      "Epoch 283, Loss: 0.4275561270482115\n",
      "Epoch 284, Loss: 0.428346900793098\n",
      "Epoch 285, Loss: 0.4260589848692751\n",
      "Epoch 286, Loss: 0.42638137940549814\n",
      "Epoch 287, Loss: 0.42902310764995066\n",
      "Epoch 288, Loss: 0.42836672926689007\n",
      "Epoch 289, Loss: 0.42654270363727864\n",
      "Epoch 290, Loss: 0.42543817399768613\n",
      "Epoch 291, Loss: 0.42668757089737486\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.206651267304519\n",
      "Test R^2 score: 0.5355468784031774\n",
      "Num of epochs: 292\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Epoch 179, Loss: 0.44257338842027333\n",
      "Epoch 180, Loss: 0.44223043415311275\n",
      "Epoch 181, Loss: 0.4412573335324542\n",
      "Epoch 182, Loss: 0.4403093939212056\n",
      "Epoch 183, Loss: 0.440210765892682\n",
      "Epoch 184, Loss: 0.4406913267766654\n",
      "Epoch 185, Loss: 0.44119678016972247\n",
      "Epoch 186, Loss: 0.4414768331353019\n",
      "Epoch 187, Loss: 0.44098509893198107\n",
      "Epoch 188, Loss: 0.4399157822542188\n",
      "Epoch 189, Loss: 0.43913002852403843\n",
      "Epoch 190, Loss: 0.43912120575952834\n",
      "Epoch 191, Loss: 0.43958194116248417\n",
      "Epoch 192, Loss: 0.43991779767875194\n",
      "Epoch 193, Loss: 0.4402464762584031\n",
      "Epoch 194, Loss: 0.4397939928277301\n",
      "Epoch 195, Loss: 0.4389848715145781\n",
      "Epoch 196, Loss: 0.43812834372448495\n",
      "Epoch 197, Loss: 0.4378789384628316\n",
      "Epoch 198, Loss: 0.4380569659316353\n",
      "Epoch 199, Loss: 0.4385928231376636\n",
      "Epoch 200, Loss: 0.4396870477941122\n",
      "Epoch 201, Loss: 0.44003322037003134\n",
      "Epoch 202, Loss: 0.4396387344028484\n",
      "Epoch 203, Loss: 0.43797246081508234\n",
      "Epoch 204, Loss: 0.4368868004619995\n",
      "Epoch 205, Loss: 0.4366217722212388\n",
      "Epoch 206, Loss: 0.4370735508315267\n",
      "Epoch 207, Loss: 0.438056659783102\n",
      "Epoch 208, Loss: 0.43828697608838324\n",
      "Epoch 209, Loss: 0.4380426277456835\n",
      "Epoch 210, Loss: 0.4367571723427673\n",
      "Epoch 211, Loss: 0.4358287121793394\n",
      "Epoch 212, Loss: 0.43549599799409766\n",
      "Epoch 213, Loss: 0.435693177425488\n",
      "Epoch 214, Loss: 0.43638716241086417\n",
      "Epoch 215, Loss: 0.43723040175969713\n",
      "Epoch 216, Loss: 0.4381875017781245\n",
      "Epoch 217, Loss: 0.43727582910411245\n",
      "Epoch 218, Loss: 0.4357251884259994\n",
      "Epoch 219, Loss: 0.43449740709117174\n",
      "Epoch 220, Loss: 0.4346007775761442\n",
      "Epoch 221, Loss: 0.4356339371912412\n",
      "Epoch 222, Loss: 0.43683657413065485\n",
      "Epoch 223, Loss: 0.43732786198111706\n",
      "Epoch 224, Loss: 0.43504045750484316\n",
      "Epoch 225, Loss: 0.4336674601818588\n",
      "Epoch 226, Loss: 0.4339570078903568\n",
      "Epoch 227, Loss: 0.43524205442250136\n",
      "Epoch 228, Loss: 0.43692856322479845\n",
      "Epoch 229, Loss: 0.4361014833656456\n",
      "Epoch 230, Loss: 0.43400818547427195\n",
      "Epoch 231, Loss: 0.43282550764678196\n",
      "Epoch 232, Loss: 0.43422302771098475\n",
      "Epoch 233, Loss: 0.43631150394157153\n",
      "Epoch 234, Loss: 0.4363944185143908\n",
      "Epoch 235, Loss: 0.4344230831071679\n",
      "Epoch 236, Loss: 0.43231983169663213\n",
      "Epoch 237, Loss: 0.4338866438813009\n",
      "Epoch 238, Loss: 0.4371328345881963\n",
      "Epoch 239, Loss: 0.4361934054316967\n",
      "Epoch 240, Loss: 0.4336558976182621\n",
      "Epoch 241, Loss: 0.432399290161847\n",
      "Epoch 242, Loss: 0.43439426928256275\n",
      "Epoch 243, Loss: 0.43607225078754297\n",
      "Epoch 244, Loss: 0.432937520696398\n",
      "Epoch 245, Loss: 0.4313183612820463\n",
      "Epoch 246, Loss: 0.432574819035821\n",
      "Epoch 247, Loss: 0.43256944517797463\n",
      "Epoch 248, Loss: 0.4313844637013701\n",
      "Epoch 249, Loss: 0.43068049739004677\n",
      "Epoch 250, Loss: 0.43099675551916994\n",
      "Epoch 251, Loss: 0.43165141303618687\n",
      "Epoch 252, Loss: 0.43069838475760797\n",
      "Epoch 253, Loss: 0.4299371687594886\n",
      "Epoch 254, Loss: 0.43062274760638575\n",
      "Epoch 255, Loss: 0.4311277872870893\n",
      "Epoch 256, Loss: 0.4311714384142778\n",
      "Epoch 257, Loss: 0.43017855241729436\n",
      "Epoch 258, Loss: 0.42926238444708237\n",
      "Epoch 259, Loss: 0.429571014567453\n",
      "Epoch 260, Loss: 0.43070712058104565\n",
      "Epoch 261, Loss: 0.4319815519144537\n",
      "Epoch 262, Loss: 0.4316843105666133\n",
      "Epoch 263, Loss: 0.4304818873122946\n",
      "Epoch 264, Loss: 0.42840412257514504\n",
      "Epoch 265, Loss: 0.42906400353820484\n",
      "Epoch 266, Loss: 0.43117263072273004\n",
      "Epoch 267, Loss: 0.4324830925949777\n",
      "Epoch 268, Loss: 0.432065642300335\n",
      "Epoch 269, Loss: 0.42821550526406094\n",
      "Epoch 270, Loss: 0.42857532485258004\n",
      "Epoch 271, Loss: 0.43234967987659256\n",
      "Epoch 272, Loss: 0.4333620913145171\n",
      "Epoch 273, Loss: 0.43177123704376796\n",
      "Epoch 274, Loss: 0.42781134135031557\n",
      "Epoch 275, Loss: 0.43068236573784513\n",
      "Epoch 276, Loss: 0.4364270609514446\n",
      "Epoch 277, Loss: 0.43077905897178964\n",
      "Epoch 278, Loss: 0.4276025647386226\n",
      "Epoch 279, Loss: 0.42963899858880455\n",
      "Epoch 280, Loss: 0.4293283522141213\n",
      "Epoch 281, Loss: 0.427636522918956\n",
      "Epoch 282, Loss: 0.4263990277621903\n",
      "Epoch 283, Loss: 0.4275561270482115\n",
      "Epoch 284, Loss: 0.428346900793098\n",
      "Epoch 285, Loss: 0.4260589848692751\n",
      "Epoch 286, Loss: 0.42638137940549814\n",
      "Epoch 287, Loss: 0.42902310764995066\n",
      "Epoch 288, Loss: 0.42836672926689007\n",
      "Epoch 289, Loss: 0.42654270363727864\n",
      "Epoch 290, Loss: 0.42543817399768613\n",
      "Epoch 291, Loss: 0.42668757089737486\n",
      "Epoch 292, Loss: 0.42858132247346753\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2110917205521473\n",
      "Test R^2 score: 0.5161616581966346\n",
      "Num of epochs: 293\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Epoch 179, Loss: 0.44257338842027333\n",
      "Epoch 180, Loss: 0.44223043415311275\n",
      "Epoch 181, Loss: 0.4412573335324542\n",
      "Epoch 182, Loss: 0.4403093939212056\n",
      "Epoch 183, Loss: 0.440210765892682\n",
      "Epoch 184, Loss: 0.4406913267766654\n",
      "Epoch 185, Loss: 0.44119678016972247\n",
      "Epoch 186, Loss: 0.4414768331353019\n",
      "Epoch 187, Loss: 0.44098509893198107\n",
      "Epoch 188, Loss: 0.4399157822542188\n",
      "Epoch 189, Loss: 0.43913002852403843\n",
      "Epoch 190, Loss: 0.43912120575952834\n",
      "Epoch 191, Loss: 0.43958194116248417\n",
      "Epoch 192, Loss: 0.43991779767875194\n",
      "Epoch 193, Loss: 0.4402464762584031\n",
      "Epoch 194, Loss: 0.4397939928277301\n",
      "Epoch 195, Loss: 0.4389848715145781\n",
      "Epoch 196, Loss: 0.43812834372448495\n",
      "Epoch 197, Loss: 0.4378789384628316\n",
      "Epoch 198, Loss: 0.4380569659316353\n",
      "Epoch 199, Loss: 0.4385928231376636\n",
      "Epoch 200, Loss: 0.4396870477941122\n",
      "Epoch 201, Loss: 0.44003322037003134\n",
      "Epoch 202, Loss: 0.4396387344028484\n",
      "Epoch 203, Loss: 0.43797246081508234\n",
      "Epoch 204, Loss: 0.4368868004619995\n",
      "Epoch 205, Loss: 0.4366217722212388\n",
      "Epoch 206, Loss: 0.4370735508315267\n",
      "Epoch 207, Loss: 0.438056659783102\n",
      "Epoch 208, Loss: 0.43828697608838324\n",
      "Epoch 209, Loss: 0.4380426277456835\n",
      "Epoch 210, Loss: 0.4367571723427673\n",
      "Epoch 211, Loss: 0.4358287121793394\n",
      "Epoch 212, Loss: 0.43549599799409766\n",
      "Epoch 213, Loss: 0.435693177425488\n",
      "Epoch 214, Loss: 0.43638716241086417\n",
      "Epoch 215, Loss: 0.43723040175969713\n",
      "Epoch 216, Loss: 0.4381875017781245\n",
      "Epoch 217, Loss: 0.43727582910411245\n",
      "Epoch 218, Loss: 0.4357251884259994\n",
      "Epoch 219, Loss: 0.43449740709117174\n",
      "Epoch 220, Loss: 0.4346007775761442\n",
      "Epoch 221, Loss: 0.4356339371912412\n",
      "Epoch 222, Loss: 0.43683657413065485\n",
      "Epoch 223, Loss: 0.43732786198111706\n",
      "Epoch 224, Loss: 0.43504045750484316\n",
      "Epoch 225, Loss: 0.4336674601818588\n",
      "Epoch 226, Loss: 0.4339570078903568\n",
      "Epoch 227, Loss: 0.43524205442250136\n",
      "Epoch 228, Loss: 0.43692856322479845\n",
      "Epoch 229, Loss: 0.4361014833656456\n",
      "Epoch 230, Loss: 0.43400818547427195\n",
      "Epoch 231, Loss: 0.43282550764678196\n",
      "Epoch 232, Loss: 0.43422302771098475\n",
      "Epoch 233, Loss: 0.43631150394157153\n",
      "Epoch 234, Loss: 0.4363944185143908\n",
      "Epoch 235, Loss: 0.4344230831071679\n",
      "Epoch 236, Loss: 0.43231983169663213\n",
      "Epoch 237, Loss: 0.4338866438813009\n",
      "Epoch 238, Loss: 0.4371328345881963\n",
      "Epoch 239, Loss: 0.4361934054316967\n",
      "Epoch 240, Loss: 0.4336558976182621\n",
      "Epoch 241, Loss: 0.432399290161847\n",
      "Epoch 242, Loss: 0.43439426928256275\n",
      "Epoch 243, Loss: 0.43607225078754297\n",
      "Epoch 244, Loss: 0.432937520696398\n",
      "Epoch 245, Loss: 0.4313183612820463\n",
      "Epoch 246, Loss: 0.432574819035821\n",
      "Epoch 247, Loss: 0.43256944517797463\n",
      "Epoch 248, Loss: 0.4313844637013701\n",
      "Epoch 249, Loss: 0.43068049739004677\n",
      "Epoch 250, Loss: 0.43099675551916994\n",
      "Epoch 251, Loss: 0.43165141303618687\n",
      "Epoch 252, Loss: 0.43069838475760797\n",
      "Epoch 253, Loss: 0.4299371687594886\n",
      "Epoch 254, Loss: 0.43062274760638575\n",
      "Epoch 255, Loss: 0.4311277872870893\n",
      "Epoch 256, Loss: 0.4311714384142778\n",
      "Epoch 257, Loss: 0.43017855241729436\n",
      "Epoch 258, Loss: 0.42926238444708237\n",
      "Epoch 259, Loss: 0.429571014567453\n",
      "Epoch 260, Loss: 0.43070712058104565\n",
      "Epoch 261, Loss: 0.4319815519144537\n",
      "Epoch 262, Loss: 0.4316843105666133\n",
      "Epoch 263, Loss: 0.4304818873122946\n",
      "Epoch 264, Loss: 0.42840412257514504\n",
      "Epoch 265, Loss: 0.42906400353820484\n",
      "Epoch 266, Loss: 0.43117263072273004\n",
      "Epoch 267, Loss: 0.4324830925949777\n",
      "Epoch 268, Loss: 0.432065642300335\n",
      "Epoch 269, Loss: 0.42821550526406094\n",
      "Epoch 270, Loss: 0.42857532485258004\n",
      "Epoch 271, Loss: 0.43234967987659256\n",
      "Epoch 272, Loss: 0.4333620913145171\n",
      "Epoch 273, Loss: 0.43177123704376796\n",
      "Epoch 274, Loss: 0.42781134135031557\n",
      "Epoch 275, Loss: 0.43068236573784513\n",
      "Epoch 276, Loss: 0.4364270609514446\n",
      "Epoch 277, Loss: 0.43077905897178964\n",
      "Epoch 278, Loss: 0.4276025647386226\n",
      "Epoch 279, Loss: 0.42963899858880455\n",
      "Epoch 280, Loss: 0.4293283522141213\n",
      "Epoch 281, Loss: 0.427636522918956\n",
      "Epoch 282, Loss: 0.4263990277621903\n",
      "Epoch 283, Loss: 0.4275561270482115\n",
      "Epoch 284, Loss: 0.428346900793098\n",
      "Epoch 285, Loss: 0.4260589848692751\n",
      "Epoch 286, Loss: 0.42638137940549814\n",
      "Epoch 287, Loss: 0.42902310764995066\n",
      "Epoch 288, Loss: 0.42836672926689007\n",
      "Epoch 289, Loss: 0.42654270363727864\n",
      "Epoch 290, Loss: 0.42543817399768613\n",
      "Epoch 291, Loss: 0.42668757089737486\n",
      "Epoch 292, Loss: 0.42858132247346753\n",
      "Epoch 293, Loss: 0.4268823786666117\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20609689809280565\n",
      "Test R^2 score: 0.5381840533485858\n",
      "Num of epochs: 294\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Epoch 179, Loss: 0.44257338842027333\n",
      "Epoch 180, Loss: 0.44223043415311275\n",
      "Epoch 181, Loss: 0.4412573335324542\n",
      "Epoch 182, Loss: 0.4403093939212056\n",
      "Epoch 183, Loss: 0.440210765892682\n",
      "Epoch 184, Loss: 0.4406913267766654\n",
      "Epoch 185, Loss: 0.44119678016972247\n",
      "Epoch 186, Loss: 0.4414768331353019\n",
      "Epoch 187, Loss: 0.44098509893198107\n",
      "Epoch 188, Loss: 0.4399157822542188\n",
      "Epoch 189, Loss: 0.43913002852403843\n",
      "Epoch 190, Loss: 0.43912120575952834\n",
      "Epoch 191, Loss: 0.43958194116248417\n",
      "Epoch 192, Loss: 0.43991779767875194\n",
      "Epoch 193, Loss: 0.4402464762584031\n",
      "Epoch 194, Loss: 0.4397939928277301\n",
      "Epoch 195, Loss: 0.4389848715145781\n",
      "Epoch 196, Loss: 0.43812834372448495\n",
      "Epoch 197, Loss: 0.4378789384628316\n",
      "Epoch 198, Loss: 0.4380569659316353\n",
      "Epoch 199, Loss: 0.4385928231376636\n",
      "Epoch 200, Loss: 0.4396870477941122\n",
      "Epoch 201, Loss: 0.44003322037003134\n",
      "Epoch 202, Loss: 0.4396387344028484\n",
      "Epoch 203, Loss: 0.43797246081508234\n",
      "Epoch 204, Loss: 0.4368868004619995\n",
      "Epoch 205, Loss: 0.4366217722212388\n",
      "Epoch 206, Loss: 0.4370735508315267\n",
      "Epoch 207, Loss: 0.438056659783102\n",
      "Epoch 208, Loss: 0.43828697608838324\n",
      "Epoch 209, Loss: 0.4380426277456835\n",
      "Epoch 210, Loss: 0.4367571723427673\n",
      "Epoch 211, Loss: 0.4358287121793394\n",
      "Epoch 212, Loss: 0.43549599799409766\n",
      "Epoch 213, Loss: 0.435693177425488\n",
      "Epoch 214, Loss: 0.43638716241086417\n",
      "Epoch 215, Loss: 0.43723040175969713\n",
      "Epoch 216, Loss: 0.4381875017781245\n",
      "Epoch 217, Loss: 0.43727582910411245\n",
      "Epoch 218, Loss: 0.4357251884259994\n",
      "Epoch 219, Loss: 0.43449740709117174\n",
      "Epoch 220, Loss: 0.4346007775761442\n",
      "Epoch 221, Loss: 0.4356339371912412\n",
      "Epoch 222, Loss: 0.43683657413065485\n",
      "Epoch 223, Loss: 0.43732786198111706\n",
      "Epoch 224, Loss: 0.43504045750484316\n",
      "Epoch 225, Loss: 0.4336674601818588\n",
      "Epoch 226, Loss: 0.4339570078903568\n",
      "Epoch 227, Loss: 0.43524205442250136\n",
      "Epoch 228, Loss: 0.43692856322479845\n",
      "Epoch 229, Loss: 0.4361014833656456\n",
      "Epoch 230, Loss: 0.43400818547427195\n",
      "Epoch 231, Loss: 0.43282550764678196\n",
      "Epoch 232, Loss: 0.43422302771098475\n",
      "Epoch 233, Loss: 0.43631150394157153\n",
      "Epoch 234, Loss: 0.4363944185143908\n",
      "Epoch 235, Loss: 0.4344230831071679\n",
      "Epoch 236, Loss: 0.43231983169663213\n",
      "Epoch 237, Loss: 0.4338866438813009\n",
      "Epoch 238, Loss: 0.4371328345881963\n",
      "Epoch 239, Loss: 0.4361934054316967\n",
      "Epoch 240, Loss: 0.4336558976182621\n",
      "Epoch 241, Loss: 0.432399290161847\n",
      "Epoch 242, Loss: 0.43439426928256275\n",
      "Epoch 243, Loss: 0.43607225078754297\n",
      "Epoch 244, Loss: 0.432937520696398\n",
      "Epoch 245, Loss: 0.4313183612820463\n",
      "Epoch 246, Loss: 0.432574819035821\n",
      "Epoch 247, Loss: 0.43256944517797463\n",
      "Epoch 248, Loss: 0.4313844637013701\n",
      "Epoch 249, Loss: 0.43068049739004677\n",
      "Epoch 250, Loss: 0.43099675551916994\n",
      "Epoch 251, Loss: 0.43165141303618687\n",
      "Epoch 252, Loss: 0.43069838475760797\n",
      "Epoch 253, Loss: 0.4299371687594886\n",
      "Epoch 254, Loss: 0.43062274760638575\n",
      "Epoch 255, Loss: 0.4311277872870893\n",
      "Epoch 256, Loss: 0.4311714384142778\n",
      "Epoch 257, Loss: 0.43017855241729436\n",
      "Epoch 258, Loss: 0.42926238444708237\n",
      "Epoch 259, Loss: 0.429571014567453\n",
      "Epoch 260, Loss: 0.43070712058104565\n",
      "Epoch 261, Loss: 0.4319815519144537\n",
      "Epoch 262, Loss: 0.4316843105666133\n",
      "Epoch 263, Loss: 0.4304818873122946\n",
      "Epoch 264, Loss: 0.42840412257514504\n",
      "Epoch 265, Loss: 0.42906400353820484\n",
      "Epoch 266, Loss: 0.43117263072273004\n",
      "Epoch 267, Loss: 0.4324830925949777\n",
      "Epoch 268, Loss: 0.432065642300335\n",
      "Epoch 269, Loss: 0.42821550526406094\n",
      "Epoch 270, Loss: 0.42857532485258004\n",
      "Epoch 271, Loss: 0.43234967987659256\n",
      "Epoch 272, Loss: 0.4333620913145171\n",
      "Epoch 273, Loss: 0.43177123704376796\n",
      "Epoch 274, Loss: 0.42781134135031557\n",
      "Epoch 275, Loss: 0.43068236573784513\n",
      "Epoch 276, Loss: 0.4364270609514446\n",
      "Epoch 277, Loss: 0.43077905897178964\n",
      "Epoch 278, Loss: 0.4276025647386226\n",
      "Epoch 279, Loss: 0.42963899858880455\n",
      "Epoch 280, Loss: 0.4293283522141213\n",
      "Epoch 281, Loss: 0.427636522918956\n",
      "Epoch 282, Loss: 0.4263990277621903\n",
      "Epoch 283, Loss: 0.4275561270482115\n",
      "Epoch 284, Loss: 0.428346900793098\n",
      "Epoch 285, Loss: 0.4260589848692751\n",
      "Epoch 286, Loss: 0.42638137940549814\n",
      "Epoch 287, Loss: 0.42902310764995066\n",
      "Epoch 288, Loss: 0.42836672926689007\n",
      "Epoch 289, Loss: 0.42654270363727864\n",
      "Epoch 290, Loss: 0.42543817399768613\n",
      "Epoch 291, Loss: 0.42668757089737486\n",
      "Epoch 292, Loss: 0.42858132247346753\n",
      "Epoch 293, Loss: 0.4268823786666117\n",
      "Epoch 294, Loss: 0.42500616097192045\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20674274847601679\n",
      "Test R^2 score: 0.5353808142595287\n",
      "Num of epochs: 295\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Epoch 179, Loss: 0.44257338842027333\n",
      "Epoch 180, Loss: 0.44223043415311275\n",
      "Epoch 181, Loss: 0.4412573335324542\n",
      "Epoch 182, Loss: 0.4403093939212056\n",
      "Epoch 183, Loss: 0.440210765892682\n",
      "Epoch 184, Loss: 0.4406913267766654\n",
      "Epoch 185, Loss: 0.44119678016972247\n",
      "Epoch 186, Loss: 0.4414768331353019\n",
      "Epoch 187, Loss: 0.44098509893198107\n",
      "Epoch 188, Loss: 0.4399157822542188\n",
      "Epoch 189, Loss: 0.43913002852403843\n",
      "Epoch 190, Loss: 0.43912120575952834\n",
      "Epoch 191, Loss: 0.43958194116248417\n",
      "Epoch 192, Loss: 0.43991779767875194\n",
      "Epoch 193, Loss: 0.4402464762584031\n",
      "Epoch 194, Loss: 0.4397939928277301\n",
      "Epoch 195, Loss: 0.4389848715145781\n",
      "Epoch 196, Loss: 0.43812834372448495\n",
      "Epoch 197, Loss: 0.4378789384628316\n",
      "Epoch 198, Loss: 0.4380569659316353\n",
      "Epoch 199, Loss: 0.4385928231376636\n",
      "Epoch 200, Loss: 0.4396870477941122\n",
      "Epoch 201, Loss: 0.44003322037003134\n",
      "Epoch 202, Loss: 0.4396387344028484\n",
      "Epoch 203, Loss: 0.43797246081508234\n",
      "Epoch 204, Loss: 0.4368868004619995\n",
      "Epoch 205, Loss: 0.4366217722212388\n",
      "Epoch 206, Loss: 0.4370735508315267\n",
      "Epoch 207, Loss: 0.438056659783102\n",
      "Epoch 208, Loss: 0.43828697608838324\n",
      "Epoch 209, Loss: 0.4380426277456835\n",
      "Epoch 210, Loss: 0.4367571723427673\n",
      "Epoch 211, Loss: 0.4358287121793394\n",
      "Epoch 212, Loss: 0.43549599799409766\n",
      "Epoch 213, Loss: 0.435693177425488\n",
      "Epoch 214, Loss: 0.43638716241086417\n",
      "Epoch 215, Loss: 0.43723040175969713\n",
      "Epoch 216, Loss: 0.4381875017781245\n",
      "Epoch 217, Loss: 0.43727582910411245\n",
      "Epoch 218, Loss: 0.4357251884259994\n",
      "Epoch 219, Loss: 0.43449740709117174\n",
      "Epoch 220, Loss: 0.4346007775761442\n",
      "Epoch 221, Loss: 0.4356339371912412\n",
      "Epoch 222, Loss: 0.43683657413065485\n",
      "Epoch 223, Loss: 0.43732786198111706\n",
      "Epoch 224, Loss: 0.43504045750484316\n",
      "Epoch 225, Loss: 0.4336674601818588\n",
      "Epoch 226, Loss: 0.4339570078903568\n",
      "Epoch 227, Loss: 0.43524205442250136\n",
      "Epoch 228, Loss: 0.43692856322479845\n",
      "Epoch 229, Loss: 0.4361014833656456\n",
      "Epoch 230, Loss: 0.43400818547427195\n",
      "Epoch 231, Loss: 0.43282550764678196\n",
      "Epoch 232, Loss: 0.43422302771098475\n",
      "Epoch 233, Loss: 0.43631150394157153\n",
      "Epoch 234, Loss: 0.4363944185143908\n",
      "Epoch 235, Loss: 0.4344230831071679\n",
      "Epoch 236, Loss: 0.43231983169663213\n",
      "Epoch 237, Loss: 0.4338866438813009\n",
      "Epoch 238, Loss: 0.4371328345881963\n",
      "Epoch 239, Loss: 0.4361934054316967\n",
      "Epoch 240, Loss: 0.4336558976182621\n",
      "Epoch 241, Loss: 0.432399290161847\n",
      "Epoch 242, Loss: 0.43439426928256275\n",
      "Epoch 243, Loss: 0.43607225078754297\n",
      "Epoch 244, Loss: 0.432937520696398\n",
      "Epoch 245, Loss: 0.4313183612820463\n",
      "Epoch 246, Loss: 0.432574819035821\n",
      "Epoch 247, Loss: 0.43256944517797463\n",
      "Epoch 248, Loss: 0.4313844637013701\n",
      "Epoch 249, Loss: 0.43068049739004677\n",
      "Epoch 250, Loss: 0.43099675551916994\n",
      "Epoch 251, Loss: 0.43165141303618687\n",
      "Epoch 252, Loss: 0.43069838475760797\n",
      "Epoch 253, Loss: 0.4299371687594886\n",
      "Epoch 254, Loss: 0.43062274760638575\n",
      "Epoch 255, Loss: 0.4311277872870893\n",
      "Epoch 256, Loss: 0.4311714384142778\n",
      "Epoch 257, Loss: 0.43017855241729436\n",
      "Epoch 258, Loss: 0.42926238444708237\n",
      "Epoch 259, Loss: 0.429571014567453\n",
      "Epoch 260, Loss: 0.43070712058104565\n",
      "Epoch 261, Loss: 0.4319815519144537\n",
      "Epoch 262, Loss: 0.4316843105666133\n",
      "Epoch 263, Loss: 0.4304818873122946\n",
      "Epoch 264, Loss: 0.42840412257514504\n",
      "Epoch 265, Loss: 0.42906400353820484\n",
      "Epoch 266, Loss: 0.43117263072273004\n",
      "Epoch 267, Loss: 0.4324830925949777\n",
      "Epoch 268, Loss: 0.432065642300335\n",
      "Epoch 269, Loss: 0.42821550526406094\n",
      "Epoch 270, Loss: 0.42857532485258004\n",
      "Epoch 271, Loss: 0.43234967987659256\n",
      "Epoch 272, Loss: 0.4333620913145171\n",
      "Epoch 273, Loss: 0.43177123704376796\n",
      "Epoch 274, Loss: 0.42781134135031557\n",
      "Epoch 275, Loss: 0.43068236573784513\n",
      "Epoch 276, Loss: 0.4364270609514446\n",
      "Epoch 277, Loss: 0.43077905897178964\n",
      "Epoch 278, Loss: 0.4276025647386226\n",
      "Epoch 279, Loss: 0.42963899858880455\n",
      "Epoch 280, Loss: 0.4293283522141213\n",
      "Epoch 281, Loss: 0.427636522918956\n",
      "Epoch 282, Loss: 0.4263990277621903\n",
      "Epoch 283, Loss: 0.4275561270482115\n",
      "Epoch 284, Loss: 0.428346900793098\n",
      "Epoch 285, Loss: 0.4260589848692751\n",
      "Epoch 286, Loss: 0.42638137940549814\n",
      "Epoch 287, Loss: 0.42902310764995066\n",
      "Epoch 288, Loss: 0.42836672926689007\n",
      "Epoch 289, Loss: 0.42654270363727864\n",
      "Epoch 290, Loss: 0.42543817399768613\n",
      "Epoch 291, Loss: 0.42668757089737486\n",
      "Epoch 292, Loss: 0.42858132247346753\n",
      "Epoch 293, Loss: 0.4268823786666117\n",
      "Epoch 294, Loss: 0.42500616097192045\n",
      "Epoch 295, Loss: 0.42444140806548936\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20986126543532319\n",
      "Test R^2 score: 0.5216990820790464\n",
      "Num of epochs: 296\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Epoch 179, Loss: 0.44257338842027333\n",
      "Epoch 180, Loss: 0.44223043415311275\n",
      "Epoch 181, Loss: 0.4412573335324542\n",
      "Epoch 182, Loss: 0.4403093939212056\n",
      "Epoch 183, Loss: 0.440210765892682\n",
      "Epoch 184, Loss: 0.4406913267766654\n",
      "Epoch 185, Loss: 0.44119678016972247\n",
      "Epoch 186, Loss: 0.4414768331353019\n",
      "Epoch 187, Loss: 0.44098509893198107\n",
      "Epoch 188, Loss: 0.4399157822542188\n",
      "Epoch 189, Loss: 0.43913002852403843\n",
      "Epoch 190, Loss: 0.43912120575952834\n",
      "Epoch 191, Loss: 0.43958194116248417\n",
      "Epoch 192, Loss: 0.43991779767875194\n",
      "Epoch 193, Loss: 0.4402464762584031\n",
      "Epoch 194, Loss: 0.4397939928277301\n",
      "Epoch 195, Loss: 0.4389848715145781\n",
      "Epoch 196, Loss: 0.43812834372448495\n",
      "Epoch 197, Loss: 0.4378789384628316\n",
      "Epoch 198, Loss: 0.4380569659316353\n",
      "Epoch 199, Loss: 0.4385928231376636\n",
      "Epoch 200, Loss: 0.4396870477941122\n",
      "Epoch 201, Loss: 0.44003322037003134\n",
      "Epoch 202, Loss: 0.4396387344028484\n",
      "Epoch 203, Loss: 0.43797246081508234\n",
      "Epoch 204, Loss: 0.4368868004619995\n",
      "Epoch 205, Loss: 0.4366217722212388\n",
      "Epoch 206, Loss: 0.4370735508315267\n",
      "Epoch 207, Loss: 0.438056659783102\n",
      "Epoch 208, Loss: 0.43828697608838324\n",
      "Epoch 209, Loss: 0.4380426277456835\n",
      "Epoch 210, Loss: 0.4367571723427673\n",
      "Epoch 211, Loss: 0.4358287121793394\n",
      "Epoch 212, Loss: 0.43549599799409766\n",
      "Epoch 213, Loss: 0.435693177425488\n",
      "Epoch 214, Loss: 0.43638716241086417\n",
      "Epoch 215, Loss: 0.43723040175969713\n",
      "Epoch 216, Loss: 0.4381875017781245\n",
      "Epoch 217, Loss: 0.43727582910411245\n",
      "Epoch 218, Loss: 0.4357251884259994\n",
      "Epoch 219, Loss: 0.43449740709117174\n",
      "Epoch 220, Loss: 0.4346007775761442\n",
      "Epoch 221, Loss: 0.4356339371912412\n",
      "Epoch 222, Loss: 0.43683657413065485\n",
      "Epoch 223, Loss: 0.43732786198111706\n",
      "Epoch 224, Loss: 0.43504045750484316\n",
      "Epoch 225, Loss: 0.4336674601818588\n",
      "Epoch 226, Loss: 0.4339570078903568\n",
      "Epoch 227, Loss: 0.43524205442250136\n",
      "Epoch 228, Loss: 0.43692856322479845\n",
      "Epoch 229, Loss: 0.4361014833656456\n",
      "Epoch 230, Loss: 0.43400818547427195\n",
      "Epoch 231, Loss: 0.43282550764678196\n",
      "Epoch 232, Loss: 0.43422302771098475\n",
      "Epoch 233, Loss: 0.43631150394157153\n",
      "Epoch 234, Loss: 0.4363944185143908\n",
      "Epoch 235, Loss: 0.4344230831071679\n",
      "Epoch 236, Loss: 0.43231983169663213\n",
      "Epoch 237, Loss: 0.4338866438813009\n",
      "Epoch 238, Loss: 0.4371328345881963\n",
      "Epoch 239, Loss: 0.4361934054316967\n",
      "Epoch 240, Loss: 0.4336558976182621\n",
      "Epoch 241, Loss: 0.432399290161847\n",
      "Epoch 242, Loss: 0.43439426928256275\n",
      "Epoch 243, Loss: 0.43607225078754297\n",
      "Epoch 244, Loss: 0.432937520696398\n",
      "Epoch 245, Loss: 0.4313183612820463\n",
      "Epoch 246, Loss: 0.432574819035821\n",
      "Epoch 247, Loss: 0.43256944517797463\n",
      "Epoch 248, Loss: 0.4313844637013701\n",
      "Epoch 249, Loss: 0.43068049739004677\n",
      "Epoch 250, Loss: 0.43099675551916994\n",
      "Epoch 251, Loss: 0.43165141303618687\n",
      "Epoch 252, Loss: 0.43069838475760797\n",
      "Epoch 253, Loss: 0.4299371687594886\n",
      "Epoch 254, Loss: 0.43062274760638575\n",
      "Epoch 255, Loss: 0.4311277872870893\n",
      "Epoch 256, Loss: 0.4311714384142778\n",
      "Epoch 257, Loss: 0.43017855241729436\n",
      "Epoch 258, Loss: 0.42926238444708237\n",
      "Epoch 259, Loss: 0.429571014567453\n",
      "Epoch 260, Loss: 0.43070712058104565\n",
      "Epoch 261, Loss: 0.4319815519144537\n",
      "Epoch 262, Loss: 0.4316843105666133\n",
      "Epoch 263, Loss: 0.4304818873122946\n",
      "Epoch 264, Loss: 0.42840412257514504\n",
      "Epoch 265, Loss: 0.42906400353820484\n",
      "Epoch 266, Loss: 0.43117263072273004\n",
      "Epoch 267, Loss: 0.4324830925949777\n",
      "Epoch 268, Loss: 0.432065642300335\n",
      "Epoch 269, Loss: 0.42821550526406094\n",
      "Epoch 270, Loss: 0.42857532485258004\n",
      "Epoch 271, Loss: 0.43234967987659256\n",
      "Epoch 272, Loss: 0.4333620913145171\n",
      "Epoch 273, Loss: 0.43177123704376796\n",
      "Epoch 274, Loss: 0.42781134135031557\n",
      "Epoch 275, Loss: 0.43068236573784513\n",
      "Epoch 276, Loss: 0.4364270609514446\n",
      "Epoch 277, Loss: 0.43077905897178964\n",
      "Epoch 278, Loss: 0.4276025647386226\n",
      "Epoch 279, Loss: 0.42963899858880455\n",
      "Epoch 280, Loss: 0.4293283522141213\n",
      "Epoch 281, Loss: 0.427636522918956\n",
      "Epoch 282, Loss: 0.4263990277621903\n",
      "Epoch 283, Loss: 0.4275561270482115\n",
      "Epoch 284, Loss: 0.428346900793098\n",
      "Epoch 285, Loss: 0.4260589848692751\n",
      "Epoch 286, Loss: 0.42638137940549814\n",
      "Epoch 287, Loss: 0.42902310764995066\n",
      "Epoch 288, Loss: 0.42836672926689007\n",
      "Epoch 289, Loss: 0.42654270363727864\n",
      "Epoch 290, Loss: 0.42543817399768613\n",
      "Epoch 291, Loss: 0.42668757089737486\n",
      "Epoch 292, Loss: 0.42858132247346753\n",
      "Epoch 293, Loss: 0.4268823786666117\n",
      "Epoch 294, Loss: 0.42500616097192045\n",
      "Epoch 295, Loss: 0.42444140806548936\n",
      "Epoch 296, Loss: 0.4252063474681982\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2065415280034721\n",
      "Test R^2 score: 0.5360268948412917\n",
      "Num of epochs: 297\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Epoch 179, Loss: 0.44257338842027333\n",
      "Epoch 180, Loss: 0.44223043415311275\n",
      "Epoch 181, Loss: 0.4412573335324542\n",
      "Epoch 182, Loss: 0.4403093939212056\n",
      "Epoch 183, Loss: 0.440210765892682\n",
      "Epoch 184, Loss: 0.4406913267766654\n",
      "Epoch 185, Loss: 0.44119678016972247\n",
      "Epoch 186, Loss: 0.4414768331353019\n",
      "Epoch 187, Loss: 0.44098509893198107\n",
      "Epoch 188, Loss: 0.4399157822542188\n",
      "Epoch 189, Loss: 0.43913002852403843\n",
      "Epoch 190, Loss: 0.43912120575952834\n",
      "Epoch 191, Loss: 0.43958194116248417\n",
      "Epoch 192, Loss: 0.43991779767875194\n",
      "Epoch 193, Loss: 0.4402464762584031\n",
      "Epoch 194, Loss: 0.4397939928277301\n",
      "Epoch 195, Loss: 0.4389848715145781\n",
      "Epoch 196, Loss: 0.43812834372448495\n",
      "Epoch 197, Loss: 0.4378789384628316\n",
      "Epoch 198, Loss: 0.4380569659316353\n",
      "Epoch 199, Loss: 0.4385928231376636\n",
      "Epoch 200, Loss: 0.4396870477941122\n",
      "Epoch 201, Loss: 0.44003322037003134\n",
      "Epoch 202, Loss: 0.4396387344028484\n",
      "Epoch 203, Loss: 0.43797246081508234\n",
      "Epoch 204, Loss: 0.4368868004619995\n",
      "Epoch 205, Loss: 0.4366217722212388\n",
      "Epoch 206, Loss: 0.4370735508315267\n",
      "Epoch 207, Loss: 0.438056659783102\n",
      "Epoch 208, Loss: 0.43828697608838324\n",
      "Epoch 209, Loss: 0.4380426277456835\n",
      "Epoch 210, Loss: 0.4367571723427673\n",
      "Epoch 211, Loss: 0.4358287121793394\n",
      "Epoch 212, Loss: 0.43549599799409766\n",
      "Epoch 213, Loss: 0.435693177425488\n",
      "Epoch 214, Loss: 0.43638716241086417\n",
      "Epoch 215, Loss: 0.43723040175969713\n",
      "Epoch 216, Loss: 0.4381875017781245\n",
      "Epoch 217, Loss: 0.43727582910411245\n",
      "Epoch 218, Loss: 0.4357251884259994\n",
      "Epoch 219, Loss: 0.43449740709117174\n",
      "Epoch 220, Loss: 0.4346007775761442\n",
      "Epoch 221, Loss: 0.4356339371912412\n",
      "Epoch 222, Loss: 0.43683657413065485\n",
      "Epoch 223, Loss: 0.43732786198111706\n",
      "Epoch 224, Loss: 0.43504045750484316\n",
      "Epoch 225, Loss: 0.4336674601818588\n",
      "Epoch 226, Loss: 0.4339570078903568\n",
      "Epoch 227, Loss: 0.43524205442250136\n",
      "Epoch 228, Loss: 0.43692856322479845\n",
      "Epoch 229, Loss: 0.4361014833656456\n",
      "Epoch 230, Loss: 0.43400818547427195\n",
      "Epoch 231, Loss: 0.43282550764678196\n",
      "Epoch 232, Loss: 0.43422302771098475\n",
      "Epoch 233, Loss: 0.43631150394157153\n",
      "Epoch 234, Loss: 0.4363944185143908\n",
      "Epoch 235, Loss: 0.4344230831071679\n",
      "Epoch 236, Loss: 0.43231983169663213\n",
      "Epoch 237, Loss: 0.4338866438813009\n",
      "Epoch 238, Loss: 0.4371328345881963\n",
      "Epoch 239, Loss: 0.4361934054316967\n",
      "Epoch 240, Loss: 0.4336558976182621\n",
      "Epoch 241, Loss: 0.432399290161847\n",
      "Epoch 242, Loss: 0.43439426928256275\n",
      "Epoch 243, Loss: 0.43607225078754297\n",
      "Epoch 244, Loss: 0.432937520696398\n",
      "Epoch 245, Loss: 0.4313183612820463\n",
      "Epoch 246, Loss: 0.432574819035821\n",
      "Epoch 247, Loss: 0.43256944517797463\n",
      "Epoch 248, Loss: 0.4313844637013701\n",
      "Epoch 249, Loss: 0.43068049739004677\n",
      "Epoch 250, Loss: 0.43099675551916994\n",
      "Epoch 251, Loss: 0.43165141303618687\n",
      "Epoch 252, Loss: 0.43069838475760797\n",
      "Epoch 253, Loss: 0.4299371687594886\n",
      "Epoch 254, Loss: 0.43062274760638575\n",
      "Epoch 255, Loss: 0.4311277872870893\n",
      "Epoch 256, Loss: 0.4311714384142778\n",
      "Epoch 257, Loss: 0.43017855241729436\n",
      "Epoch 258, Loss: 0.42926238444708237\n",
      "Epoch 259, Loss: 0.429571014567453\n",
      "Epoch 260, Loss: 0.43070712058104565\n",
      "Epoch 261, Loss: 0.4319815519144537\n",
      "Epoch 262, Loss: 0.4316843105666133\n",
      "Epoch 263, Loss: 0.4304818873122946\n",
      "Epoch 264, Loss: 0.42840412257514504\n",
      "Epoch 265, Loss: 0.42906400353820484\n",
      "Epoch 266, Loss: 0.43117263072273004\n",
      "Epoch 267, Loss: 0.4324830925949777\n",
      "Epoch 268, Loss: 0.432065642300335\n",
      "Epoch 269, Loss: 0.42821550526406094\n",
      "Epoch 270, Loss: 0.42857532485258004\n",
      "Epoch 271, Loss: 0.43234967987659256\n",
      "Epoch 272, Loss: 0.4333620913145171\n",
      "Epoch 273, Loss: 0.43177123704376796\n",
      "Epoch 274, Loss: 0.42781134135031557\n",
      "Epoch 275, Loss: 0.43068236573784513\n",
      "Epoch 276, Loss: 0.4364270609514446\n",
      "Epoch 277, Loss: 0.43077905897178964\n",
      "Epoch 278, Loss: 0.4276025647386226\n",
      "Epoch 279, Loss: 0.42963899858880455\n",
      "Epoch 280, Loss: 0.4293283522141213\n",
      "Epoch 281, Loss: 0.427636522918956\n",
      "Epoch 282, Loss: 0.4263990277621903\n",
      "Epoch 283, Loss: 0.4275561270482115\n",
      "Epoch 284, Loss: 0.428346900793098\n",
      "Epoch 285, Loss: 0.4260589848692751\n",
      "Epoch 286, Loss: 0.42638137940549814\n",
      "Epoch 287, Loss: 0.42902310764995066\n",
      "Epoch 288, Loss: 0.42836672926689007\n",
      "Epoch 289, Loss: 0.42654270363727864\n",
      "Epoch 290, Loss: 0.42543817399768613\n",
      "Epoch 291, Loss: 0.42668757089737486\n",
      "Epoch 292, Loss: 0.42858132247346753\n",
      "Epoch 293, Loss: 0.4268823786666117\n",
      "Epoch 294, Loss: 0.42500616097192045\n",
      "Epoch 295, Loss: 0.42444140806548936\n",
      "Epoch 296, Loss: 0.4252063474681982\n",
      "Epoch 297, Loss: 0.42659538198199004\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21088186813509288\n",
      "Test R^2 score: 0.5169722648652546\n",
      "Num of epochs: 298\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Epoch 179, Loss: 0.44257338842027333\n",
      "Epoch 180, Loss: 0.44223043415311275\n",
      "Epoch 181, Loss: 0.4412573335324542\n",
      "Epoch 182, Loss: 0.4403093939212056\n",
      "Epoch 183, Loss: 0.440210765892682\n",
      "Epoch 184, Loss: 0.4406913267766654\n",
      "Epoch 185, Loss: 0.44119678016972247\n",
      "Epoch 186, Loss: 0.4414768331353019\n",
      "Epoch 187, Loss: 0.44098509893198107\n",
      "Epoch 188, Loss: 0.4399157822542188\n",
      "Epoch 189, Loss: 0.43913002852403843\n",
      "Epoch 190, Loss: 0.43912120575952834\n",
      "Epoch 191, Loss: 0.43958194116248417\n",
      "Epoch 192, Loss: 0.43991779767875194\n",
      "Epoch 193, Loss: 0.4402464762584031\n",
      "Epoch 194, Loss: 0.4397939928277301\n",
      "Epoch 195, Loss: 0.4389848715145781\n",
      "Epoch 196, Loss: 0.43812834372448495\n",
      "Epoch 197, Loss: 0.4378789384628316\n",
      "Epoch 198, Loss: 0.4380569659316353\n",
      "Epoch 199, Loss: 0.4385928231376636\n",
      "Epoch 200, Loss: 0.4396870477941122\n",
      "Epoch 201, Loss: 0.44003322037003134\n",
      "Epoch 202, Loss: 0.4396387344028484\n",
      "Epoch 203, Loss: 0.43797246081508234\n",
      "Epoch 204, Loss: 0.4368868004619995\n",
      "Epoch 205, Loss: 0.4366217722212388\n",
      "Epoch 206, Loss: 0.4370735508315267\n",
      "Epoch 207, Loss: 0.438056659783102\n",
      "Epoch 208, Loss: 0.43828697608838324\n",
      "Epoch 209, Loss: 0.4380426277456835\n",
      "Epoch 210, Loss: 0.4367571723427673\n",
      "Epoch 211, Loss: 0.4358287121793394\n",
      "Epoch 212, Loss: 0.43549599799409766\n",
      "Epoch 213, Loss: 0.435693177425488\n",
      "Epoch 214, Loss: 0.43638716241086417\n",
      "Epoch 215, Loss: 0.43723040175969713\n",
      "Epoch 216, Loss: 0.4381875017781245\n",
      "Epoch 217, Loss: 0.43727582910411245\n",
      "Epoch 218, Loss: 0.4357251884259994\n",
      "Epoch 219, Loss: 0.43449740709117174\n",
      "Epoch 220, Loss: 0.4346007775761442\n",
      "Epoch 221, Loss: 0.4356339371912412\n",
      "Epoch 222, Loss: 0.43683657413065485\n",
      "Epoch 223, Loss: 0.43732786198111706\n",
      "Epoch 224, Loss: 0.43504045750484316\n",
      "Epoch 225, Loss: 0.4336674601818588\n",
      "Epoch 226, Loss: 0.4339570078903568\n",
      "Epoch 227, Loss: 0.43524205442250136\n",
      "Epoch 228, Loss: 0.43692856322479845\n",
      "Epoch 229, Loss: 0.4361014833656456\n",
      "Epoch 230, Loss: 0.43400818547427195\n",
      "Epoch 231, Loss: 0.43282550764678196\n",
      "Epoch 232, Loss: 0.43422302771098475\n",
      "Epoch 233, Loss: 0.43631150394157153\n",
      "Epoch 234, Loss: 0.4363944185143908\n",
      "Epoch 235, Loss: 0.4344230831071679\n",
      "Epoch 236, Loss: 0.43231983169663213\n",
      "Epoch 237, Loss: 0.4338866438813009\n",
      "Epoch 238, Loss: 0.4371328345881963\n",
      "Epoch 239, Loss: 0.4361934054316967\n",
      "Epoch 240, Loss: 0.4336558976182621\n",
      "Epoch 241, Loss: 0.432399290161847\n",
      "Epoch 242, Loss: 0.43439426928256275\n",
      "Epoch 243, Loss: 0.43607225078754297\n",
      "Epoch 244, Loss: 0.432937520696398\n",
      "Epoch 245, Loss: 0.4313183612820463\n",
      "Epoch 246, Loss: 0.432574819035821\n",
      "Epoch 247, Loss: 0.43256944517797463\n",
      "Epoch 248, Loss: 0.4313844637013701\n",
      "Epoch 249, Loss: 0.43068049739004677\n",
      "Epoch 250, Loss: 0.43099675551916994\n",
      "Epoch 251, Loss: 0.43165141303618687\n",
      "Epoch 252, Loss: 0.43069838475760797\n",
      "Epoch 253, Loss: 0.4299371687594886\n",
      "Epoch 254, Loss: 0.43062274760638575\n",
      "Epoch 255, Loss: 0.4311277872870893\n",
      "Epoch 256, Loss: 0.4311714384142778\n",
      "Epoch 257, Loss: 0.43017855241729436\n",
      "Epoch 258, Loss: 0.42926238444708237\n",
      "Epoch 259, Loss: 0.429571014567453\n",
      "Epoch 260, Loss: 0.43070712058104565\n",
      "Epoch 261, Loss: 0.4319815519144537\n",
      "Epoch 262, Loss: 0.4316843105666133\n",
      "Epoch 263, Loss: 0.4304818873122946\n",
      "Epoch 264, Loss: 0.42840412257514504\n",
      "Epoch 265, Loss: 0.42906400353820484\n",
      "Epoch 266, Loss: 0.43117263072273004\n",
      "Epoch 267, Loss: 0.4324830925949777\n",
      "Epoch 268, Loss: 0.432065642300335\n",
      "Epoch 269, Loss: 0.42821550526406094\n",
      "Epoch 270, Loss: 0.42857532485258004\n",
      "Epoch 271, Loss: 0.43234967987659256\n",
      "Epoch 272, Loss: 0.4333620913145171\n",
      "Epoch 273, Loss: 0.43177123704376796\n",
      "Epoch 274, Loss: 0.42781134135031557\n",
      "Epoch 275, Loss: 0.43068236573784513\n",
      "Epoch 276, Loss: 0.4364270609514446\n",
      "Epoch 277, Loss: 0.43077905897178964\n",
      "Epoch 278, Loss: 0.4276025647386226\n",
      "Epoch 279, Loss: 0.42963899858880455\n",
      "Epoch 280, Loss: 0.4293283522141213\n",
      "Epoch 281, Loss: 0.427636522918956\n",
      "Epoch 282, Loss: 0.4263990277621903\n",
      "Epoch 283, Loss: 0.4275561270482115\n",
      "Epoch 284, Loss: 0.428346900793098\n",
      "Epoch 285, Loss: 0.4260589848692751\n",
      "Epoch 286, Loss: 0.42638137940549814\n",
      "Epoch 287, Loss: 0.42902310764995066\n",
      "Epoch 288, Loss: 0.42836672926689007\n",
      "Epoch 289, Loss: 0.42654270363727864\n",
      "Epoch 290, Loss: 0.42543817399768613\n",
      "Epoch 291, Loss: 0.42668757089737486\n",
      "Epoch 292, Loss: 0.42858132247346753\n",
      "Epoch 293, Loss: 0.4268823786666117\n",
      "Epoch 294, Loss: 0.42500616097192045\n",
      "Epoch 295, Loss: 0.42444140806548936\n",
      "Epoch 296, Loss: 0.4252063474681982\n",
      "Epoch 297, Loss: 0.42659538198199004\n",
      "Epoch 298, Loss: 0.42576453849824364\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20612703970119337\n",
      "Test R^2 score: 0.5379052765409771\n",
      "Num of epochs: 299\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Epoch 179, Loss: 0.44257338842027333\n",
      "Epoch 180, Loss: 0.44223043415311275\n",
      "Epoch 181, Loss: 0.4412573335324542\n",
      "Epoch 182, Loss: 0.4403093939212056\n",
      "Epoch 183, Loss: 0.440210765892682\n",
      "Epoch 184, Loss: 0.4406913267766654\n",
      "Epoch 185, Loss: 0.44119678016972247\n",
      "Epoch 186, Loss: 0.4414768331353019\n",
      "Epoch 187, Loss: 0.44098509893198107\n",
      "Epoch 188, Loss: 0.4399157822542188\n",
      "Epoch 189, Loss: 0.43913002852403843\n",
      "Epoch 190, Loss: 0.43912120575952834\n",
      "Epoch 191, Loss: 0.43958194116248417\n",
      "Epoch 192, Loss: 0.43991779767875194\n",
      "Epoch 193, Loss: 0.4402464762584031\n",
      "Epoch 194, Loss: 0.4397939928277301\n",
      "Epoch 195, Loss: 0.4389848715145781\n",
      "Epoch 196, Loss: 0.43812834372448495\n",
      "Epoch 197, Loss: 0.4378789384628316\n",
      "Epoch 198, Loss: 0.4380569659316353\n",
      "Epoch 199, Loss: 0.4385928231376636\n",
      "Epoch 200, Loss: 0.4396870477941122\n",
      "Epoch 201, Loss: 0.44003322037003134\n",
      "Epoch 202, Loss: 0.4396387344028484\n",
      "Epoch 203, Loss: 0.43797246081508234\n",
      "Epoch 204, Loss: 0.4368868004619995\n",
      "Epoch 205, Loss: 0.4366217722212388\n",
      "Epoch 206, Loss: 0.4370735508315267\n",
      "Epoch 207, Loss: 0.438056659783102\n",
      "Epoch 208, Loss: 0.43828697608838324\n",
      "Epoch 209, Loss: 0.4380426277456835\n",
      "Epoch 210, Loss: 0.4367571723427673\n",
      "Epoch 211, Loss: 0.4358287121793394\n",
      "Epoch 212, Loss: 0.43549599799409766\n",
      "Epoch 213, Loss: 0.435693177425488\n",
      "Epoch 214, Loss: 0.43638716241086417\n",
      "Epoch 215, Loss: 0.43723040175969713\n",
      "Epoch 216, Loss: 0.4381875017781245\n",
      "Epoch 217, Loss: 0.43727582910411245\n",
      "Epoch 218, Loss: 0.4357251884259994\n",
      "Epoch 219, Loss: 0.43449740709117174\n",
      "Epoch 220, Loss: 0.4346007775761442\n",
      "Epoch 221, Loss: 0.4356339371912412\n",
      "Epoch 222, Loss: 0.43683657413065485\n",
      "Epoch 223, Loss: 0.43732786198111706\n",
      "Epoch 224, Loss: 0.43504045750484316\n",
      "Epoch 225, Loss: 0.4336674601818588\n",
      "Epoch 226, Loss: 0.4339570078903568\n",
      "Epoch 227, Loss: 0.43524205442250136\n",
      "Epoch 228, Loss: 0.43692856322479845\n",
      "Epoch 229, Loss: 0.4361014833656456\n",
      "Epoch 230, Loss: 0.43400818547427195\n",
      "Epoch 231, Loss: 0.43282550764678196\n",
      "Epoch 232, Loss: 0.43422302771098475\n",
      "Epoch 233, Loss: 0.43631150394157153\n",
      "Epoch 234, Loss: 0.4363944185143908\n",
      "Epoch 235, Loss: 0.4344230831071679\n",
      "Epoch 236, Loss: 0.43231983169663213\n",
      "Epoch 237, Loss: 0.4338866438813009\n",
      "Epoch 238, Loss: 0.4371328345881963\n",
      "Epoch 239, Loss: 0.4361934054316967\n",
      "Epoch 240, Loss: 0.4336558976182621\n",
      "Epoch 241, Loss: 0.432399290161847\n",
      "Epoch 242, Loss: 0.43439426928256275\n",
      "Epoch 243, Loss: 0.43607225078754297\n",
      "Epoch 244, Loss: 0.432937520696398\n",
      "Epoch 245, Loss: 0.4313183612820463\n",
      "Epoch 246, Loss: 0.432574819035821\n",
      "Epoch 247, Loss: 0.43256944517797463\n",
      "Epoch 248, Loss: 0.4313844637013701\n",
      "Epoch 249, Loss: 0.43068049739004677\n",
      "Epoch 250, Loss: 0.43099675551916994\n",
      "Epoch 251, Loss: 0.43165141303618687\n",
      "Epoch 252, Loss: 0.43069838475760797\n",
      "Epoch 253, Loss: 0.4299371687594886\n",
      "Epoch 254, Loss: 0.43062274760638575\n",
      "Epoch 255, Loss: 0.4311277872870893\n",
      "Epoch 256, Loss: 0.4311714384142778\n",
      "Epoch 257, Loss: 0.43017855241729436\n",
      "Epoch 258, Loss: 0.42926238444708237\n",
      "Epoch 259, Loss: 0.429571014567453\n",
      "Epoch 260, Loss: 0.43070712058104565\n",
      "Epoch 261, Loss: 0.4319815519144537\n",
      "Epoch 262, Loss: 0.4316843105666133\n",
      "Epoch 263, Loss: 0.4304818873122946\n",
      "Epoch 264, Loss: 0.42840412257514504\n",
      "Epoch 265, Loss: 0.42906400353820484\n",
      "Epoch 266, Loss: 0.43117263072273004\n",
      "Epoch 267, Loss: 0.4324830925949777\n",
      "Epoch 268, Loss: 0.432065642300335\n",
      "Epoch 269, Loss: 0.42821550526406094\n",
      "Epoch 270, Loss: 0.42857532485258004\n",
      "Epoch 271, Loss: 0.43234967987659256\n",
      "Epoch 272, Loss: 0.4333620913145171\n",
      "Epoch 273, Loss: 0.43177123704376796\n",
      "Epoch 274, Loss: 0.42781134135031557\n",
      "Epoch 275, Loss: 0.43068236573784513\n",
      "Epoch 276, Loss: 0.4364270609514446\n",
      "Epoch 277, Loss: 0.43077905897178964\n",
      "Epoch 278, Loss: 0.4276025647386226\n",
      "Epoch 279, Loss: 0.42963899858880455\n",
      "Epoch 280, Loss: 0.4293283522141213\n",
      "Epoch 281, Loss: 0.427636522918956\n",
      "Epoch 282, Loss: 0.4263990277621903\n",
      "Epoch 283, Loss: 0.4275561270482115\n",
      "Epoch 284, Loss: 0.428346900793098\n",
      "Epoch 285, Loss: 0.4260589848692751\n",
      "Epoch 286, Loss: 0.42638137940549814\n",
      "Epoch 287, Loss: 0.42902310764995066\n",
      "Epoch 288, Loss: 0.42836672926689007\n",
      "Epoch 289, Loss: 0.42654270363727864\n",
      "Epoch 290, Loss: 0.42543817399768613\n",
      "Epoch 291, Loss: 0.42668757089737486\n",
      "Epoch 292, Loss: 0.42858132247346753\n",
      "Epoch 293, Loss: 0.4268823786666117\n",
      "Epoch 294, Loss: 0.42500616097192045\n",
      "Epoch 295, Loss: 0.42444140806548936\n",
      "Epoch 296, Loss: 0.4252063474681982\n",
      "Epoch 297, Loss: 0.42659538198199004\n",
      "Epoch 298, Loss: 0.42576453849824364\n",
      "Epoch 299, Loss: 0.42449864730911496\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20736294462726748\n",
      "Test R^2 score: 0.532630048929307\n",
      "Num of epochs: 300\n",
      "Epoch 1, Loss: 0.5746450334035433\n",
      "Epoch 2, Loss: 0.5715367228690077\n",
      "Epoch 3, Loss: 0.568723843570422\n",
      "Epoch 4, Loss: 0.5662034033240844\n",
      "Epoch 5, Loss: 0.5639657421022336\n",
      "Epoch 6, Loss: 0.5620144761959939\n",
      "Epoch 7, Loss: 0.5603495127446635\n",
      "Epoch 8, Loss: 0.5589520832280581\n",
      "Epoch 9, Loss: 0.557849468213647\n",
      "Epoch 10, Loss: 0.5570423216073913\n",
      "Epoch 11, Loss: 0.5565358916684618\n",
      "Epoch 12, Loss: 0.5563135089408692\n",
      "Epoch 13, Loss: 0.5563421687370618\n",
      "Epoch 14, Loss: 0.5565110172833165\n",
      "Epoch 15, Loss: 0.5566788242015659\n",
      "Epoch 16, Loss: 0.5567680882195035\n",
      "Epoch 17, Loss: 0.556777482190829\n",
      "Epoch 18, Loss: 0.5567465430427734\n",
      "Epoch 19, Loss: 0.5567011750065124\n",
      "Epoch 20, Loss: 0.5566445066082453\n",
      "Epoch 21, Loss: 0.5565730271369262\n",
      "Epoch 22, Loss: 0.5564914168769578\n",
      "Epoch 23, Loss: 0.5564502323531654\n",
      "Epoch 24, Loss: 0.556406500585168\n",
      "Epoch 25, Loss: 0.5563592835561056\n",
      "Epoch 26, Loss: 0.5563191070918575\n",
      "Epoch 27, Loss: 0.5562729273582215\n",
      "Epoch 28, Loss: 0.5562343520203035\n",
      "Epoch 29, Loss: 0.5561994979735423\n",
      "Epoch 30, Loss: 0.5561694912029482\n",
      "Epoch 31, Loss: 0.5561461276677419\n",
      "Epoch 32, Loss: 0.5561277469490856\n",
      "Epoch 33, Loss: 0.5561070612155388\n",
      "Epoch 34, Loss: 0.5560814709338037\n",
      "Epoch 35, Loss: 0.5560675900579946\n",
      "Epoch 36, Loss: 0.5560241497887618\n",
      "Epoch 37, Loss: 0.5559664206999307\n",
      "Epoch 38, Loss: 0.5558908063589797\n",
      "Epoch 39, Loss: 0.5557741079657121\n",
      "Epoch 40, Loss: 0.5556088170375676\n",
      "Epoch 41, Loss: 0.5553692134304155\n",
      "Epoch 42, Loss: 0.5550226891235807\n",
      "Epoch 43, Loss: 0.5545056273258259\n",
      "Epoch 44, Loss: 0.5537124714502148\n",
      "Epoch 45, Loss: 0.5525529381690897\n",
      "Epoch 46, Loss: 0.550848882323938\n",
      "Epoch 47, Loss: 0.5483697898344198\n",
      "Epoch 48, Loss: 0.5448011038882461\n",
      "Epoch 49, Loss: 0.5400353098733769\n",
      "Epoch 50, Loss: 0.5336340256510972\n",
      "Epoch 51, Loss: 0.52589993093925\n",
      "Epoch 52, Loss: 0.5187376744747868\n",
      "Epoch 53, Loss: 0.5151239908824535\n",
      "Epoch 54, Loss: 0.5147143616699151\n",
      "Epoch 55, Loss: 0.512489960734965\n",
      "Epoch 56, Loss: 0.5067746634369639\n",
      "Epoch 57, Loss: 0.5015278064458155\n",
      "Epoch 58, Loss: 0.49911122007237646\n",
      "Epoch 59, Loss: 0.49757202549587576\n",
      "Epoch 60, Loss: 0.4946854644704594\n",
      "Epoch 61, Loss: 0.4910206511489863\n",
      "Epoch 62, Loss: 0.4873650767609312\n",
      "Epoch 63, Loss: 0.4851739508552587\n",
      "Epoch 64, Loss: 0.48385790942181356\n",
      "Epoch 65, Loss: 0.4817848633106549\n",
      "Epoch 66, Loss: 0.47921724847210706\n",
      "Epoch 67, Loss: 0.4775466294264445\n",
      "Epoch 68, Loss: 0.47631626333990706\n",
      "Epoch 69, Loss: 0.4752886271704639\n",
      "Epoch 70, Loss: 0.47492148101735077\n",
      "Epoch 71, Loss: 0.4743722707999104\n",
      "Epoch 72, Loss: 0.47297657602550575\n",
      "Epoch 73, Loss: 0.4714483005531081\n",
      "Epoch 74, Loss: 0.47152151294954175\n",
      "Epoch 75, Loss: 0.47185189398979355\n",
      "Epoch 76, Loss: 0.4708703246678204\n",
      "Epoch 77, Loss: 0.46978887830641225\n",
      "Epoch 78, Loss: 0.4699105994694321\n",
      "Epoch 79, Loss: 0.4700158352669895\n",
      "Epoch 80, Loss: 0.46908940107858094\n",
      "Epoch 81, Loss: 0.4679695626126018\n",
      "Epoch 82, Loss: 0.46778533538149547\n",
      "Epoch 83, Loss: 0.4678917657516925\n",
      "Epoch 84, Loss: 0.46715040665667723\n",
      "Epoch 85, Loss: 0.466339813305786\n",
      "Epoch 86, Loss: 0.46623526590808634\n",
      "Epoch 87, Loss: 0.46611929841056937\n",
      "Epoch 88, Loss: 0.46544963555403174\n",
      "Epoch 89, Loss: 0.4648119651121463\n",
      "Epoch 90, Loss: 0.46462719144347975\n",
      "Epoch 91, Loss: 0.46446866842814705\n",
      "Epoch 92, Loss: 0.46390305229875994\n",
      "Epoch 93, Loss: 0.4632553080456935\n",
      "Epoch 94, Loss: 0.4628486614279642\n",
      "Epoch 95, Loss: 0.4626228105028892\n",
      "Epoch 96, Loss: 0.46229942006122837\n",
      "Epoch 97, Loss: 0.4617790686230633\n",
      "Epoch 98, Loss: 0.4612109940791263\n",
      "Epoch 99, Loss: 0.46072981083228576\n",
      "Epoch 100, Loss: 0.4603641144146304\n",
      "Epoch 101, Loss: 0.46010724958003446\n",
      "Epoch 102, Loss: 0.46001618654859433\n",
      "Epoch 103, Loss: 0.4604582477222354\n",
      "Epoch 104, Loss: 0.4615539049963798\n",
      "Epoch 105, Loss: 0.4617234011962844\n",
      "Epoch 106, Loss: 0.45888721168103547\n",
      "Epoch 107, Loss: 0.45790191597417934\n",
      "Epoch 108, Loss: 0.4593611286949523\n",
      "Epoch 109, Loss: 0.45820182481404037\n",
      "Epoch 110, Loss: 0.45664565619576014\n",
      "Epoch 111, Loss: 0.45730830215168616\n",
      "Epoch 112, Loss: 0.4571509571294477\n",
      "Epoch 113, Loss: 0.45581174011564657\n",
      "Epoch 114, Loss: 0.4557780666455928\n",
      "Epoch 115, Loss: 0.4560219795865245\n",
      "Epoch 116, Loss: 0.455091271599395\n",
      "Epoch 117, Loss: 0.4545006095915715\n",
      "Epoch 118, Loss: 0.4548476458231629\n",
      "Epoch 119, Loss: 0.454618377281746\n",
      "Epoch 120, Loss: 0.4536306256775575\n",
      "Epoch 121, Loss: 0.45334614914713994\n",
      "Epoch 122, Loss: 0.4535784425691982\n",
      "Epoch 123, Loss: 0.4532190258207036\n",
      "Epoch 124, Loss: 0.45248254086338646\n",
      "Epoch 125, Loss: 0.4520451240243248\n",
      "Epoch 126, Loss: 0.45201562038897525\n",
      "Epoch 127, Loss: 0.45202002133276015\n",
      "Epoch 128, Loss: 0.45174505312226626\n",
      "Epoch 129, Loss: 0.451254321074997\n",
      "Epoch 130, Loss: 0.450701117045743\n",
      "Epoch 131, Loss: 0.4503451613071291\n",
      "Epoch 132, Loss: 0.4501975301493475\n",
      "Epoch 133, Loss: 0.45017161275911555\n",
      "Epoch 134, Loss: 0.45030717432286493\n",
      "Epoch 135, Loss: 0.45063688918578604\n",
      "Epoch 136, Loss: 0.45118492074576116\n",
      "Epoch 137, Loss: 0.45122144682729737\n",
      "Epoch 138, Loss: 0.45025497008148224\n",
      "Epoch 139, Loss: 0.4487822858677476\n",
      "Epoch 140, Loss: 0.44816424122183957\n",
      "Epoch 141, Loss: 0.44852883807681776\n",
      "Epoch 142, Loss: 0.44905737590587325\n",
      "Epoch 143, Loss: 0.44893013348563976\n",
      "Epoch 144, Loss: 0.44800152270556426\n",
      "Epoch 145, Loss: 0.44715268570691546\n",
      "Epoch 146, Loss: 0.4469859985733856\n",
      "Epoch 147, Loss: 0.44728956200125686\n",
      "Epoch 148, Loss: 0.4475838640950054\n",
      "Epoch 149, Loss: 0.4473542537915037\n",
      "Epoch 150, Loss: 0.4467132188815497\n",
      "Epoch 151, Loss: 0.44602101830385354\n",
      "Epoch 152, Loss: 0.44562273763266913\n",
      "Epoch 153, Loss: 0.4455197838993956\n",
      "Epoch 154, Loss: 0.44559570141282134\n",
      "Epoch 155, Loss: 0.4459112224842973\n",
      "Epoch 156, Loss: 0.4462447029622165\n",
      "Epoch 157, Loss: 0.4462571247451015\n",
      "Epoch 158, Loss: 0.44600314407673075\n",
      "Epoch 159, Loss: 0.44519938320552466\n",
      "Epoch 160, Loss: 0.4444029202120226\n",
      "Epoch 161, Loss: 0.44389745854631824\n",
      "Epoch 162, Loss: 0.44382591739878385\n",
      "Epoch 163, Loss: 0.4441270106501204\n",
      "Epoch 164, Loss: 0.4445980095638177\n",
      "Epoch 165, Loss: 0.44504527389409254\n",
      "Epoch 166, Loss: 0.44485602490205184\n",
      "Epoch 167, Loss: 0.44396994472495155\n",
      "Epoch 168, Loss: 0.4428634895252279\n",
      "Epoch 169, Loss: 0.4424317692831299\n",
      "Epoch 170, Loss: 0.44267913123663494\n",
      "Epoch 171, Loss: 0.44321793976433804\n",
      "Epoch 172, Loss: 0.44371724074962915\n",
      "Epoch 173, Loss: 0.44345821001593017\n",
      "Epoch 174, Loss: 0.4425378994956313\n",
      "Epoch 175, Loss: 0.4415629623529453\n",
      "Epoch 176, Loss: 0.44126667077665377\n",
      "Epoch 177, Loss: 0.4416504581044379\n",
      "Epoch 178, Loss: 0.442165228616442\n",
      "Epoch 179, Loss: 0.44257338842027333\n",
      "Epoch 180, Loss: 0.44223043415311275\n",
      "Epoch 181, Loss: 0.4412573335324542\n",
      "Epoch 182, Loss: 0.4403093939212056\n",
      "Epoch 183, Loss: 0.440210765892682\n",
      "Epoch 184, Loss: 0.4406913267766654\n",
      "Epoch 185, Loss: 0.44119678016972247\n",
      "Epoch 186, Loss: 0.4414768331353019\n",
      "Epoch 187, Loss: 0.44098509893198107\n",
      "Epoch 188, Loss: 0.4399157822542188\n",
      "Epoch 189, Loss: 0.43913002852403843\n",
      "Epoch 190, Loss: 0.43912120575952834\n",
      "Epoch 191, Loss: 0.43958194116248417\n",
      "Epoch 192, Loss: 0.43991779767875194\n",
      "Epoch 193, Loss: 0.4402464762584031\n",
      "Epoch 194, Loss: 0.4397939928277301\n",
      "Epoch 195, Loss: 0.4389848715145781\n",
      "Epoch 196, Loss: 0.43812834372448495\n",
      "Epoch 197, Loss: 0.4378789384628316\n",
      "Epoch 198, Loss: 0.4380569659316353\n",
      "Epoch 199, Loss: 0.4385928231376636\n",
      "Epoch 200, Loss: 0.4396870477941122\n",
      "Epoch 201, Loss: 0.44003322037003134\n",
      "Epoch 202, Loss: 0.4396387344028484\n",
      "Epoch 203, Loss: 0.43797246081508234\n",
      "Epoch 204, Loss: 0.4368868004619995\n",
      "Epoch 205, Loss: 0.4366217722212388\n",
      "Epoch 206, Loss: 0.4370735508315267\n",
      "Epoch 207, Loss: 0.438056659783102\n",
      "Epoch 208, Loss: 0.43828697608838324\n",
      "Epoch 209, Loss: 0.4380426277456835\n",
      "Epoch 210, Loss: 0.4367571723427673\n",
      "Epoch 211, Loss: 0.4358287121793394\n",
      "Epoch 212, Loss: 0.43549599799409766\n",
      "Epoch 213, Loss: 0.435693177425488\n",
      "Epoch 214, Loss: 0.43638716241086417\n",
      "Epoch 215, Loss: 0.43723040175969713\n",
      "Epoch 216, Loss: 0.4381875017781245\n",
      "Epoch 217, Loss: 0.43727582910411245\n",
      "Epoch 218, Loss: 0.4357251884259994\n",
      "Epoch 219, Loss: 0.43449740709117174\n",
      "Epoch 220, Loss: 0.4346007775761442\n",
      "Epoch 221, Loss: 0.4356339371912412\n",
      "Epoch 222, Loss: 0.43683657413065485\n",
      "Epoch 223, Loss: 0.43732786198111706\n",
      "Epoch 224, Loss: 0.43504045750484316\n",
      "Epoch 225, Loss: 0.4336674601818588\n",
      "Epoch 226, Loss: 0.4339570078903568\n",
      "Epoch 227, Loss: 0.43524205442250136\n",
      "Epoch 228, Loss: 0.43692856322479845\n",
      "Epoch 229, Loss: 0.4361014833656456\n",
      "Epoch 230, Loss: 0.43400818547427195\n",
      "Epoch 231, Loss: 0.43282550764678196\n",
      "Epoch 232, Loss: 0.43422302771098475\n",
      "Epoch 233, Loss: 0.43631150394157153\n",
      "Epoch 234, Loss: 0.4363944185143908\n",
      "Epoch 235, Loss: 0.4344230831071679\n",
      "Epoch 236, Loss: 0.43231983169663213\n",
      "Epoch 237, Loss: 0.4338866438813009\n",
      "Epoch 238, Loss: 0.4371328345881963\n",
      "Epoch 239, Loss: 0.4361934054316967\n",
      "Epoch 240, Loss: 0.4336558976182621\n",
      "Epoch 241, Loss: 0.432399290161847\n",
      "Epoch 242, Loss: 0.43439426928256275\n",
      "Epoch 243, Loss: 0.43607225078754297\n",
      "Epoch 244, Loss: 0.432937520696398\n",
      "Epoch 245, Loss: 0.4313183612820463\n",
      "Epoch 246, Loss: 0.432574819035821\n",
      "Epoch 247, Loss: 0.43256944517797463\n",
      "Epoch 248, Loss: 0.4313844637013701\n",
      "Epoch 249, Loss: 0.43068049739004677\n",
      "Epoch 250, Loss: 0.43099675551916994\n",
      "Epoch 251, Loss: 0.43165141303618687\n",
      "Epoch 252, Loss: 0.43069838475760797\n",
      "Epoch 253, Loss: 0.4299371687594886\n",
      "Epoch 254, Loss: 0.43062274760638575\n",
      "Epoch 255, Loss: 0.4311277872870893\n",
      "Epoch 256, Loss: 0.4311714384142778\n",
      "Epoch 257, Loss: 0.43017855241729436\n",
      "Epoch 258, Loss: 0.42926238444708237\n",
      "Epoch 259, Loss: 0.429571014567453\n",
      "Epoch 260, Loss: 0.43070712058104565\n",
      "Epoch 261, Loss: 0.4319815519144537\n",
      "Epoch 262, Loss: 0.4316843105666133\n",
      "Epoch 263, Loss: 0.4304818873122946\n",
      "Epoch 264, Loss: 0.42840412257514504\n",
      "Epoch 265, Loss: 0.42906400353820484\n",
      "Epoch 266, Loss: 0.43117263072273004\n",
      "Epoch 267, Loss: 0.4324830925949777\n",
      "Epoch 268, Loss: 0.432065642300335\n",
      "Epoch 269, Loss: 0.42821550526406094\n",
      "Epoch 270, Loss: 0.42857532485258004\n",
      "Epoch 271, Loss: 0.43234967987659256\n",
      "Epoch 272, Loss: 0.4333620913145171\n",
      "Epoch 273, Loss: 0.43177123704376796\n",
      "Epoch 274, Loss: 0.42781134135031557\n",
      "Epoch 275, Loss: 0.43068236573784513\n",
      "Epoch 276, Loss: 0.4364270609514446\n",
      "Epoch 277, Loss: 0.43077905897178964\n",
      "Epoch 278, Loss: 0.4276025647386226\n",
      "Epoch 279, Loss: 0.42963899858880455\n",
      "Epoch 280, Loss: 0.4293283522141213\n",
      "Epoch 281, Loss: 0.427636522918956\n",
      "Epoch 282, Loss: 0.4263990277621903\n",
      "Epoch 283, Loss: 0.4275561270482115\n",
      "Epoch 284, Loss: 0.428346900793098\n",
      "Epoch 285, Loss: 0.4260589848692751\n",
      "Epoch 286, Loss: 0.42638137940549814\n",
      "Epoch 287, Loss: 0.42902310764995066\n",
      "Epoch 288, Loss: 0.42836672926689007\n",
      "Epoch 289, Loss: 0.42654270363727864\n",
      "Epoch 290, Loss: 0.42543817399768613\n",
      "Epoch 291, Loss: 0.42668757089737486\n",
      "Epoch 292, Loss: 0.42858132247346753\n",
      "Epoch 293, Loss: 0.4268823786666117\n",
      "Epoch 294, Loss: 0.42500616097192045\n",
      "Epoch 295, Loss: 0.42444140806548936\n",
      "Epoch 296, Loss: 0.4252063474681982\n",
      "Epoch 297, Loss: 0.42659538198199004\n",
      "Epoch 298, Loss: 0.42576453849824364\n",
      "Epoch 299, Loss: 0.42449864730911496\n",
      "Epoch 300, Loss: 0.42349863209328986\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20909630443049038\n",
      "Test R^2 score: 0.5249973421357244\n",
      "Completed.\n"
     ]
    }
   ],
   "source": [
    "for num_epochs in num_epochs_list:\n",
    "  # Set the seed\n",
    "  torch.manual_seed(seed)\n",
    "\n",
    "  print(f'Num of epochs: {num_epochs}')\n",
    "  \n",
    "  model = train_model(num_epochs)\n",
    "\n",
    "  print(\"Training completed.\")\n",
    "  print(\"Testing model...\")\n",
    "\n",
    "  test_pred, rmse, r2_score = test_model(model)\n",
    "  r2_scores_list.append(r2_score)\n",
    "  rmse_list.append(rmse)\n",
    "\n",
    "print(\"Completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the graph to visualise the relationship between epochs and r^2 score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.1700001869073665,\n",
       " -0.1424245115660614,\n",
       " -0.11759274216462934,\n",
       " -0.09534284228933132,\n",
       " -0.07559009845094455,\n",
       " -0.05822318435063145,\n",
       " -0.043030230212775744,\n",
       " -0.030212756981492728,\n",
       " -0.019711210909134858,\n",
       " -0.011503706030553396,\n",
       " -0.00541616228436459,\n",
       " -0.001969448724638667,\n",
       " -0.00031094223058325543,\n",
       " 0.00023350835347557553,\n",
       " 0.00027466840693546324,\n",
       " 0.00011411099107933032,\n",
       " -0.0002637878606110422,\n",
       " -0.000830523693997054,\n",
       " -0.0015289259106820996,\n",
       " -0.0022553741143767625,\n",
       " -0.0028761027503560466,\n",
       " -0.0036976516001974713,\n",
       " -0.004375219054210733,\n",
       " -0.004860354954552171,\n",
       " -0.005213458525565762,\n",
       " -0.005367820905556209,\n",
       " -0.005438372187367202,\n",
       " -0.005442241328407538,\n",
       " -0.005356349345031708,\n",
       " -0.005206739435550278,\n",
       " -0.004995800282604934,\n",
       " -0.004687301425359447,\n",
       " -0.004234593881606075,\n",
       " -0.0038650727279878616,\n",
       " -0.003319320682360405,\n",
       " -0.0027266724092485095,\n",
       " -0.0019773434627214925,\n",
       " -0.000853282106687836,\n",
       " 0.0007275035228641036,\n",
       " 0.002986904738824292,\n",
       " 0.006105249414737723,\n",
       " 0.010477104936065462,\n",
       " 0.01696256292044651,\n",
       " 0.026257457616739144,\n",
       " 0.03977492167327046,\n",
       " 0.05969367676305187,\n",
       " 0.08853041671364853,\n",
       " 0.12686948424435746,\n",
       " 0.1769468123455391,\n",
       " 0.23450257939340918,\n",
       " 0.2858599614026012,\n",
       " 0.3102261200308776,\n",
       " 0.29451001815486866,\n",
       " 0.31328760064624667,\n",
       " 0.3375468452192559,\n",
       " 0.36469494200463004,\n",
       " 0.383428544275905,\n",
       " 0.37985506597718194,\n",
       " 0.3951892808794154,\n",
       " 0.41995507652347946,\n",
       " 0.4290722645615866,\n",
       " 0.43658157699086164,\n",
       " 0.4461672682054492,\n",
       " 0.43714464116474944,\n",
       " 0.4579117568399104,\n",
       " 0.45960296499978515,\n",
       " 0.4560812664886876,\n",
       " 0.47457720799843855,\n",
       " 0.45126713903916604,\n",
       " 0.4808031610335267,\n",
       " 0.4554716375820421,\n",
       " 0.4738342659236635,\n",
       " 0.4759414846414184,\n",
       " 0.45217972684567503,\n",
       " 0.480425365145275,\n",
       " 0.47568287612396215,\n",
       " 0.4687618891482298,\n",
       " 0.4895893467894558,\n",
       " 0.4706086646369991,\n",
       " 0.4881401379070297,\n",
       " 0.49100089241303185,\n",
       " 0.47502497242367814,\n",
       " 0.4971346203696733,\n",
       " 0.49353623486849013,\n",
       " 0.48999107440903944,\n",
       " 0.5042375384782498,\n",
       " 0.4942534898677726,\n",
       " 0.5008740189473404,\n",
       " 0.506608799798111,\n",
       " 0.49392755072363,\n",
       " 0.50884664189765,\n",
       " 0.5044562046015815,\n",
       " 0.5057132398306081,\n",
       " 0.5141417806455351,\n",
       " 0.5043739596819248,\n",
       " 0.5165746882628248,\n",
       " 0.5112658099695704,\n",
       " 0.514922990142427,\n",
       " 0.5187637914035317,\n",
       " 0.5115314773616685,\n",
       " 0.5257217305655595,\n",
       " 0.5013291136092914,\n",
       " 0.5294196176855203,\n",
       " 0.4882134708682091,\n",
       " 0.5310765719568207,\n",
       " 0.5296865871364764,\n",
       " 0.5011990830756129,\n",
       " 0.534541543888686,\n",
       " 0.5281593990271027,\n",
       " 0.5138060536521887,\n",
       " 0.5368238687603456,\n",
       " 0.5267318858596638,\n",
       " 0.5230792697249089,\n",
       " 0.539121596179186,\n",
       " 0.5255374385511594,\n",
       " 0.5314496155737622,\n",
       " 0.541463636037949,\n",
       " 0.522627267313359,\n",
       " 0.5395962906965568,\n",
       " 0.5402989851206323,\n",
       " 0.5263920827802626,\n",
       " 0.5446227716725349,\n",
       " 0.5340059151527008,\n",
       " 0.5386111920896326,\n",
       " 0.5448012231786101,\n",
       " 0.5304351440863062,\n",
       " 0.5468418305920868,\n",
       " 0.5339478000398814,\n",
       " 0.5449831845135983,\n",
       " 0.5431157558049928,\n",
       " 0.5388444518246017,\n",
       " 0.5483664316717107,\n",
       " 0.531966727630623,\n",
       " 0.5503715542362535,\n",
       " 0.5215079819717598,\n",
       " 0.5506446270309779,\n",
       " 0.5254560751978181,\n",
       " 0.5499310358551571,\n",
       " 0.5466013103080379,\n",
       " 0.5355741644186687,\n",
       " 0.5519906691319802,\n",
       " 0.5289684181477528,\n",
       " 0.551549324148531,\n",
       " 0.5429782481785494,\n",
       " 0.5422392386734898,\n",
       " 0.551423309155511,\n",
       " 0.5324445404160782,\n",
       " 0.5523960267470325,\n",
       " 0.5367775266610864,\n",
       " 0.5499170462333689,\n",
       " 0.5465476724009815,\n",
       " 0.5438919066768444,\n",
       " 0.551257079346312,\n",
       " 0.5357928225188815,\n",
       " 0.5520316784258512,\n",
       " 0.5303062880743801,\n",
       " 0.5527237125409493,\n",
       " 0.5353573420970423,\n",
       " 0.5507523821078032,\n",
       " 0.5461866664269545,\n",
       " 0.5438312279379878,\n",
       " 0.5521321143951737,\n",
       " 0.5332653932098674,\n",
       " 0.5513201674084693,\n",
       " 0.5287178684997795,\n",
       " 0.5514351038494107,\n",
       " 0.5419452665983886,\n",
       " 0.5466585842705404,\n",
       " 0.5513001103630368,\n",
       " 0.5344885132643893,\n",
       " 0.5508942768925387,\n",
       " 0.529917748628723,\n",
       " 0.5512710429239333,\n",
       " 0.5427225436055102,\n",
       " 0.5448961930730208,\n",
       " 0.5508750130990571,\n",
       " 0.5332997048938268,\n",
       " 0.5506893685690909,\n",
       " 0.5299192125364447,\n",
       " 0.5502022313320087,\n",
       " 0.5433272204691257,\n",
       " 0.5427715707837119,\n",
       " 0.550714199976328,\n",
       " 0.5314269387467603,\n",
       " 0.5493601317145367,\n",
       " 0.5303910672257844,\n",
       " 0.5497886980934209,\n",
       " 0.5436575171943688,\n",
       " 0.5414953952172291,\n",
       " 0.5492079972939848,\n",
       " 0.5322734893271467,\n",
       " 0.549501432447857,\n",
       " 0.5308177591076586,\n",
       " 0.5491861649964376,\n",
       " 0.5411288815725317,\n",
       " 0.5432790044821327,\n",
       " 0.547898797350175,\n",
       " 0.5331070695942057,\n",
       " 0.5483095919762253,\n",
       " 0.5221805620989538,\n",
       " 0.5475769598729048,\n",
       " 0.5328331138601292,\n",
       " 0.5469304825166121,\n",
       " 0.5460209936310225,\n",
       " 0.5358321122034021,\n",
       " 0.5477450354324802,\n",
       " 0.5251227071317075,\n",
       " 0.5477157778766886,\n",
       " 0.5329909865443361,\n",
       " 0.5462363593225891,\n",
       " 0.5446388959088131,\n",
       " 0.5379356787358491,\n",
       " 0.5472019216428925,\n",
       " 0.5244167809739486,\n",
       " 0.5458246510467608,\n",
       " 0.5221334340312765,\n",
       " 0.5470556398497604,\n",
       " 0.541157139120488,\n",
       " 0.5386439763356874,\n",
       " 0.5472598843244323,\n",
       " 0.5205084621351009,\n",
       " 0.5441598848374121,\n",
       " 0.5291940166165449,\n",
       " 0.5438724428491786,\n",
       " 0.5460532609969689,\n",
       " 0.5246048754302343,\n",
       " 0.5424777567759411,\n",
       " 0.5178540930638673,\n",
       " 0.5451630235916567,\n",
       " 0.543254370671176,\n",
       " 0.5281880629049286,\n",
       " 0.5440732252517186,\n",
       " 0.512125635783895,\n",
       " 0.5422117834262584,\n",
       " 0.5398717126391724,\n",
       " 0.5242974696336593,\n",
       " 0.5416993398044203,\n",
       " 0.5093837651543531,\n",
       " 0.5423703449781547,\n",
       " 0.5425963931694955,\n",
       " 0.5179100961601562,\n",
       " 0.5422504605966845,\n",
       " 0.5239201445888451,\n",
       " 0.5382432762728899,\n",
       " 0.541837533531951,\n",
       " 0.5228773711337935,\n",
       " 0.5431930984889478,\n",
       " 0.5400672472650885,\n",
       " 0.5320936664045076,\n",
       " 0.543645996795602,\n",
       " 0.5316117783473724,\n",
       " 0.5368936124857355,\n",
       " 0.5416449572547799,\n",
       " 0.5250652060699486,\n",
       " 0.5424864264337638,\n",
       " 0.5296560567824288,\n",
       " 0.5386605691953488,\n",
       " 0.541812597359989,\n",
       " 0.5227568829770504,\n",
       " 0.5390808672691116,\n",
       " 0.5138728914852325,\n",
       " 0.5406661561738085,\n",
       " 0.5352887317703006,\n",
       " 0.5298640499629582,\n",
       " 0.5400401004195,\n",
       " 0.5061464085292953,\n",
       " 0.5367811648403282,\n",
       " 0.5297211072020084,\n",
       " 0.5263867947858911,\n",
       " 0.5371482744459108,\n",
       " 0.4988607472108424,\n",
       " 0.5363429376843987,\n",
       " 0.5348881880816052,\n",
       " 0.5104976286195115,\n",
       " 0.528797958884145,\n",
       " 0.5080465104734228,\n",
       " 0.5351296188896608,\n",
       " 0.5387503854451559,\n",
       " 0.5137515442456269,\n",
       " 0.5389193744426208,\n",
       " 0.5371248076747945,\n",
       " 0.521732197412552,\n",
       " 0.5397860710239639,\n",
       " 0.5315664781974305,\n",
       " 0.5261677194170747,\n",
       " 0.536828197676629,\n",
       " 0.5121088103690525,\n",
       " 0.5391117681170967,\n",
       " 0.5357052247487282,\n",
       " 0.5181532757630111,\n",
       " 0.5355468784031774,\n",
       " 0.5161616581966346,\n",
       " 0.5381840533485858,\n",
       " 0.5353808142595287,\n",
       " 0.5216990820790464,\n",
       " 0.5360268948412917,\n",
       " 0.5169722648652546,\n",
       " 0.5379052765409771,\n",
       " 0.532630048929307,\n",
       " 0.5249973421357244]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_scores_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the line graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(num_epochs_list, r2_scores_list, color='b', linestyle='-')\n",
    "plt.title('num_epochs vs. R^2 score')\n",
    "plt.xlabel('num_epochs')\n",
    "plt.ylabel('r^2 score') \n",
    "plt.grid(True)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max R^2 score: 0.5527237125409493\n",
      "Corresponding RMSE: 0.2029850378970027\n",
      "Corresponding num_epochs: 157\n"
     ]
    }
   ],
   "source": [
    "max_r2_score = max(r2_scores_list)\n",
    "corresponding_rmse = rmse_list[r2_scores_list.index(max_r2_score)]\n",
    "corresponding_num_epochs = num_epochs_list[r2_scores_list.index(max_r2_score)]\n",
    "\n",
    "print(f'Max R^2 score: {max_r2_score}')\n",
    "print(f'Corresponding RMSE: {corresponding_rmse}')\n",
    "print(f'Corresponding num_epochs: {corresponding_num_epochs}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
