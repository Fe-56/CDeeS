{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEAM Dataset - Feed Forward Neural Network\n",
    "## Essentia Best Overall & openSMILE GeMAPS Featureset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torcheval.metrics import R2Score\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import math\n",
    "\n",
    "import sys\n",
    "sys.path.insert(1, '../../utils')\n",
    "from paths import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import annotations dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song_id</th>\n",
       "      <th>valence_mean_mapped</th>\n",
       "      <th>arousal_mean_mapped</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.475</td>\n",
       "      <td>-0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.375</td>\n",
       "      <td>-0.425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>-0.150</td>\n",
       "      <td>0.075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1739</th>\n",
       "      <td>1996</td>\n",
       "      <td>-0.275</td>\n",
       "      <td>0.225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1740</th>\n",
       "      <td>1997</td>\n",
       "      <td>0.075</td>\n",
       "      <td>-0.275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1741</th>\n",
       "      <td>1998</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1742</th>\n",
       "      <td>1999</td>\n",
       "      <td>-0.100</td>\n",
       "      <td>0.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1743</th>\n",
       "      <td>2000</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1744 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      song_id  valence_mean_mapped  arousal_mean_mapped\n",
       "0           2               -0.475               -0.500\n",
       "1           3               -0.375               -0.425\n",
       "2           4                0.175                0.125\n",
       "3           5               -0.150                0.075\n",
       "4           7                0.200                0.350\n",
       "...       ...                  ...                  ...\n",
       "1739     1996               -0.275                0.225\n",
       "1740     1997                0.075               -0.275\n",
       "1741     1998                0.350                0.300\n",
       "1742     1999               -0.100                0.100\n",
       "1743     2000                0.200                0.250\n",
       "\n",
       "[1744 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_annotations = pd.read_csv(get_deam_path('processed/annotations/deam_static_annotations.csv'))\n",
    "df_annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the featureset\n",
    "\n",
    "This is where you should change between normalised and standardised, and untouched featuresets!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song_id</th>\n",
       "      <th>lowlevel.melbands_kurtosis.dmean</th>\n",
       "      <th>lowlevel.melbands_kurtosis.dmean2</th>\n",
       "      <th>lowlevel.melbands_kurtosis.dvar</th>\n",
       "      <th>lowlevel.melbands_kurtosis.dvar2</th>\n",
       "      <th>lowlevel.melbands_kurtosis.max</th>\n",
       "      <th>lowlevel.melbands_kurtosis.mean</th>\n",
       "      <th>lowlevel.melbands_kurtosis.median</th>\n",
       "      <th>lowlevel.melbands_kurtosis.min</th>\n",
       "      <th>lowlevel.melbands_kurtosis.stdev</th>\n",
       "      <th>...</th>\n",
       "      <th>alphaRatioUV_sma3nz_amean</th>\n",
       "      <th>hammarbergIndexUV_sma3nz_amean</th>\n",
       "      <th>slopeUV0-500_sma3nz_amean</th>\n",
       "      <th>slopeUV500-1500_sma3nz_amean</th>\n",
       "      <th>loudnessPeaksPerSec</th>\n",
       "      <th>VoicedSegmentsPerSec</th>\n",
       "      <th>MeanVoicedSegmentLengthSec</th>\n",
       "      <th>StddevVoicedSegmentLengthSec</th>\n",
       "      <th>MeanUnvoicedSegmentLength</th>\n",
       "      <th>StddevUnvoicedSegmentLength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.092381</td>\n",
       "      <td>-0.078572</td>\n",
       "      <td>-0.025137</td>\n",
       "      <td>-0.024931</td>\n",
       "      <td>-0.051278</td>\n",
       "      <td>-0.058571</td>\n",
       "      <td>-0.055109</td>\n",
       "      <td>0.361562</td>\n",
       "      <td>-0.018698</td>\n",
       "      <td>...</td>\n",
       "      <td>0.287564</td>\n",
       "      <td>-0.262130</td>\n",
       "      <td>-0.181091</td>\n",
       "      <td>0.668531</td>\n",
       "      <td>-0.555169</td>\n",
       "      <td>-0.967327</td>\n",
       "      <td>-0.075432</td>\n",
       "      <td>0.439999</td>\n",
       "      <td>-0.440097</td>\n",
       "      <td>-0.377481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0.073364</td>\n",
       "      <td>0.050761</td>\n",
       "      <td>-0.025077</td>\n",
       "      <td>-0.024890</td>\n",
       "      <td>-0.020349</td>\n",
       "      <td>1.479718</td>\n",
       "      <td>3.014248</td>\n",
       "      <td>0.583826</td>\n",
       "      <td>0.056605</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.745983</td>\n",
       "      <td>1.481523</td>\n",
       "      <td>-1.835793</td>\n",
       "      <td>0.496337</td>\n",
       "      <td>-0.932362</td>\n",
       "      <td>0.263018</td>\n",
       "      <td>-0.389877</td>\n",
       "      <td>-0.474327</td>\n",
       "      <td>0.570241</td>\n",
       "      <td>0.450156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>-0.119333</td>\n",
       "      <td>-0.107505</td>\n",
       "      <td>-0.025174</td>\n",
       "      <td>-0.024965</td>\n",
       "      <td>-0.083147</td>\n",
       "      <td>-0.208423</td>\n",
       "      <td>-0.075820</td>\n",
       "      <td>0.053745</td>\n",
       "      <td>-0.094185</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025746</td>\n",
       "      <td>-0.164946</td>\n",
       "      <td>-0.758607</td>\n",
       "      <td>0.719491</td>\n",
       "      <td>0.005327</td>\n",
       "      <td>0.196521</td>\n",
       "      <td>-0.381856</td>\n",
       "      <td>-0.512572</td>\n",
       "      <td>-0.174826</td>\n",
       "      <td>-0.303339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>-0.163481</td>\n",
       "      <td>-0.139436</td>\n",
       "      <td>-0.025195</td>\n",
       "      <td>-0.024978</td>\n",
       "      <td>-0.094325</td>\n",
       "      <td>-0.262338</td>\n",
       "      <td>-0.148097</td>\n",
       "      <td>-0.493194</td>\n",
       "      <td>-0.110313</td>\n",
       "      <td>...</td>\n",
       "      <td>0.296808</td>\n",
       "      <td>-0.540060</td>\n",
       "      <td>1.453477</td>\n",
       "      <td>-1.260938</td>\n",
       "      <td>-0.603349</td>\n",
       "      <td>-1.000287</td>\n",
       "      <td>-0.015498</td>\n",
       "      <td>0.340968</td>\n",
       "      <td>-0.418676</td>\n",
       "      <td>-0.300240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>0.721637</td>\n",
       "      <td>0.521923</td>\n",
       "      <td>-0.024526</td>\n",
       "      <td>-0.024479</td>\n",
       "      <td>0.015265</td>\n",
       "      <td>2.154544</td>\n",
       "      <td>4.094221</td>\n",
       "      <td>0.492728</td>\n",
       "      <td>0.184390</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.342634</td>\n",
       "      <td>1.977728</td>\n",
       "      <td>-0.823529</td>\n",
       "      <td>0.440421</td>\n",
       "      <td>1.121683</td>\n",
       "      <td>-0.917488</td>\n",
       "      <td>-0.139595</td>\n",
       "      <td>0.293586</td>\n",
       "      <td>-0.372262</td>\n",
       "      <td>-0.240131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1739</th>\n",
       "      <td>1996</td>\n",
       "      <td>-0.154993</td>\n",
       "      <td>-0.129360</td>\n",
       "      <td>-0.025193</td>\n",
       "      <td>-0.024975</td>\n",
       "      <td>-0.100449</td>\n",
       "      <td>-0.321333</td>\n",
       "      <td>-0.138527</td>\n",
       "      <td>0.145668</td>\n",
       "      <td>-0.130138</td>\n",
       "      <td>...</td>\n",
       "      <td>0.343948</td>\n",
       "      <td>-0.753080</td>\n",
       "      <td>0.230580</td>\n",
       "      <td>-0.884061</td>\n",
       "      <td>1.768270</td>\n",
       "      <td>-0.434687</td>\n",
       "      <td>-0.329498</td>\n",
       "      <td>-0.316919</td>\n",
       "      <td>-0.508329</td>\n",
       "      <td>-0.462869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1740</th>\n",
       "      <td>1997</td>\n",
       "      <td>-0.169892</td>\n",
       "      <td>-0.137550</td>\n",
       "      <td>-0.025197</td>\n",
       "      <td>-0.024978</td>\n",
       "      <td>-0.102115</td>\n",
       "      <td>-0.346532</td>\n",
       "      <td>-0.290196</td>\n",
       "      <td>-0.205395</td>\n",
       "      <td>-0.126981</td>\n",
       "      <td>...</td>\n",
       "      <td>0.222617</td>\n",
       "      <td>-0.444289</td>\n",
       "      <td>0.247618</td>\n",
       "      <td>-0.770541</td>\n",
       "      <td>1.076880</td>\n",
       "      <td>-0.550845</td>\n",
       "      <td>-0.310073</td>\n",
       "      <td>-0.300887</td>\n",
       "      <td>-0.344771</td>\n",
       "      <td>-0.226950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1741</th>\n",
       "      <td>1998</td>\n",
       "      <td>-0.106021</td>\n",
       "      <td>-0.088136</td>\n",
       "      <td>-0.025128</td>\n",
       "      <td>-0.024919</td>\n",
       "      <td>-0.035307</td>\n",
       "      <td>-0.242062</td>\n",
       "      <td>-0.115127</td>\n",
       "      <td>-0.427167</td>\n",
       "      <td>-0.093478</td>\n",
       "      <td>...</td>\n",
       "      <td>0.374784</td>\n",
       "      <td>-0.346391</td>\n",
       "      <td>-0.400532</td>\n",
       "      <td>-0.131125</td>\n",
       "      <td>1.027496</td>\n",
       "      <td>0.996925</td>\n",
       "      <td>-0.404940</td>\n",
       "      <td>-0.493444</td>\n",
       "      <td>-0.080049</td>\n",
       "      <td>-0.197836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1742</th>\n",
       "      <td>1999</td>\n",
       "      <td>-0.124002</td>\n",
       "      <td>-0.105158</td>\n",
       "      <td>-0.025185</td>\n",
       "      <td>-0.024971</td>\n",
       "      <td>-0.068508</td>\n",
       "      <td>-0.098127</td>\n",
       "      <td>0.316466</td>\n",
       "      <td>1.586562</td>\n",
       "      <td>-0.104839</td>\n",
       "      <td>...</td>\n",
       "      <td>0.146768</td>\n",
       "      <td>-0.269664</td>\n",
       "      <td>0.058214</td>\n",
       "      <td>-0.166695</td>\n",
       "      <td>0.138567</td>\n",
       "      <td>0.629971</td>\n",
       "      <td>-0.396049</td>\n",
       "      <td>-0.541690</td>\n",
       "      <td>-0.219187</td>\n",
       "      <td>-0.239845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1743</th>\n",
       "      <td>2000</td>\n",
       "      <td>-0.045190</td>\n",
       "      <td>-0.042233</td>\n",
       "      <td>-0.025147</td>\n",
       "      <td>-0.024939</td>\n",
       "      <td>-0.053395</td>\n",
       "      <td>0.026676</td>\n",
       "      <td>0.151622</td>\n",
       "      <td>-0.962203</td>\n",
       "      <td>-0.044583</td>\n",
       "      <td>...</td>\n",
       "      <td>0.702241</td>\n",
       "      <td>-0.498246</td>\n",
       "      <td>-0.321659</td>\n",
       "      <td>0.703128</td>\n",
       "      <td>0.994572</td>\n",
       "      <td>0.979312</td>\n",
       "      <td>-0.406345</td>\n",
       "      <td>-0.541945</td>\n",
       "      <td>0.126237</td>\n",
       "      <td>-0.018917</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1744 rows × 199 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      song_id  lowlevel.melbands_kurtosis.dmean  \\\n",
       "0           2                         -0.092381   \n",
       "1           3                          0.073364   \n",
       "2           4                         -0.119333   \n",
       "3           5                         -0.163481   \n",
       "4           7                          0.721637   \n",
       "...       ...                               ...   \n",
       "1739     1996                         -0.154993   \n",
       "1740     1997                         -0.169892   \n",
       "1741     1998                         -0.106021   \n",
       "1742     1999                         -0.124002   \n",
       "1743     2000                         -0.045190   \n",
       "\n",
       "      lowlevel.melbands_kurtosis.dmean2  lowlevel.melbands_kurtosis.dvar  \\\n",
       "0                             -0.078572                        -0.025137   \n",
       "1                              0.050761                        -0.025077   \n",
       "2                             -0.107505                        -0.025174   \n",
       "3                             -0.139436                        -0.025195   \n",
       "4                              0.521923                        -0.024526   \n",
       "...                                 ...                              ...   \n",
       "1739                          -0.129360                        -0.025193   \n",
       "1740                          -0.137550                        -0.025197   \n",
       "1741                          -0.088136                        -0.025128   \n",
       "1742                          -0.105158                        -0.025185   \n",
       "1743                          -0.042233                        -0.025147   \n",
       "\n",
       "      lowlevel.melbands_kurtosis.dvar2  lowlevel.melbands_kurtosis.max  \\\n",
       "0                            -0.024931                       -0.051278   \n",
       "1                            -0.024890                       -0.020349   \n",
       "2                            -0.024965                       -0.083147   \n",
       "3                            -0.024978                       -0.094325   \n",
       "4                            -0.024479                        0.015265   \n",
       "...                                ...                             ...   \n",
       "1739                         -0.024975                       -0.100449   \n",
       "1740                         -0.024978                       -0.102115   \n",
       "1741                         -0.024919                       -0.035307   \n",
       "1742                         -0.024971                       -0.068508   \n",
       "1743                         -0.024939                       -0.053395   \n",
       "\n",
       "      lowlevel.melbands_kurtosis.mean  lowlevel.melbands_kurtosis.median  \\\n",
       "0                           -0.058571                          -0.055109   \n",
       "1                            1.479718                           3.014248   \n",
       "2                           -0.208423                          -0.075820   \n",
       "3                           -0.262338                          -0.148097   \n",
       "4                            2.154544                           4.094221   \n",
       "...                               ...                                ...   \n",
       "1739                        -0.321333                          -0.138527   \n",
       "1740                        -0.346532                          -0.290196   \n",
       "1741                        -0.242062                          -0.115127   \n",
       "1742                        -0.098127                           0.316466   \n",
       "1743                         0.026676                           0.151622   \n",
       "\n",
       "      lowlevel.melbands_kurtosis.min  lowlevel.melbands_kurtosis.stdev  ...  \\\n",
       "0                           0.361562                         -0.018698  ...   \n",
       "1                           0.583826                          0.056605  ...   \n",
       "2                           0.053745                         -0.094185  ...   \n",
       "3                          -0.493194                         -0.110313  ...   \n",
       "4                           0.492728                          0.184390  ...   \n",
       "...                              ...                               ...  ...   \n",
       "1739                        0.145668                         -0.130138  ...   \n",
       "1740                       -0.205395                         -0.126981  ...   \n",
       "1741                       -0.427167                         -0.093478  ...   \n",
       "1742                        1.586562                         -0.104839  ...   \n",
       "1743                       -0.962203                         -0.044583  ...   \n",
       "\n",
       "      alphaRatioUV_sma3nz_amean  hammarbergIndexUV_sma3nz_amean  \\\n",
       "0                      0.287564                       -0.262130   \n",
       "1                     -1.745983                        1.481523   \n",
       "2                      0.025746                       -0.164946   \n",
       "3                      0.296808                       -0.540060   \n",
       "4                     -2.342634                        1.977728   \n",
       "...                         ...                             ...   \n",
       "1739                   0.343948                       -0.753080   \n",
       "1740                   0.222617                       -0.444289   \n",
       "1741                   0.374784                       -0.346391   \n",
       "1742                   0.146768                       -0.269664   \n",
       "1743                   0.702241                       -0.498246   \n",
       "\n",
       "      slopeUV0-500_sma3nz_amean  slopeUV500-1500_sma3nz_amean  \\\n",
       "0                     -0.181091                      0.668531   \n",
       "1                     -1.835793                      0.496337   \n",
       "2                     -0.758607                      0.719491   \n",
       "3                      1.453477                     -1.260938   \n",
       "4                     -0.823529                      0.440421   \n",
       "...                         ...                           ...   \n",
       "1739                   0.230580                     -0.884061   \n",
       "1740                   0.247618                     -0.770541   \n",
       "1741                  -0.400532                     -0.131125   \n",
       "1742                   0.058214                     -0.166695   \n",
       "1743                  -0.321659                      0.703128   \n",
       "\n",
       "      loudnessPeaksPerSec  VoicedSegmentsPerSec  MeanVoicedSegmentLengthSec  \\\n",
       "0               -0.555169             -0.967327                   -0.075432   \n",
       "1               -0.932362              0.263018                   -0.389877   \n",
       "2                0.005327              0.196521                   -0.381856   \n",
       "3               -0.603349             -1.000287                   -0.015498   \n",
       "4                1.121683             -0.917488                   -0.139595   \n",
       "...                   ...                   ...                         ...   \n",
       "1739             1.768270             -0.434687                   -0.329498   \n",
       "1740             1.076880             -0.550845                   -0.310073   \n",
       "1741             1.027496              0.996925                   -0.404940   \n",
       "1742             0.138567              0.629971                   -0.396049   \n",
       "1743             0.994572              0.979312                   -0.406345   \n",
       "\n",
       "      StddevVoicedSegmentLengthSec  MeanUnvoicedSegmentLength  \\\n",
       "0                         0.439999                  -0.440097   \n",
       "1                        -0.474327                   0.570241   \n",
       "2                        -0.512572                  -0.174826   \n",
       "3                         0.340968                  -0.418676   \n",
       "4                         0.293586                  -0.372262   \n",
       "...                            ...                        ...   \n",
       "1739                     -0.316919                  -0.508329   \n",
       "1740                     -0.300887                  -0.344771   \n",
       "1741                     -0.493444                  -0.080049   \n",
       "1742                     -0.541690                  -0.219187   \n",
       "1743                     -0.541945                   0.126237   \n",
       "\n",
       "      StddevUnvoicedSegmentLength  \n",
       "0                       -0.377481  \n",
       "1                        0.450156  \n",
       "2                       -0.303339  \n",
       "3                       -0.300240  \n",
       "4                       -0.240131  \n",
       "...                           ...  \n",
       "1739                    -0.462869  \n",
       "1740                    -0.226950  \n",
       "1741                    -0.197836  \n",
       "1742                    -0.239845  \n",
       "1743                    -0.018917  \n",
       "\n",
       "[1744 rows x 199 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_essentia_best_overall_opensmile_gemaps_features = pd.read_csv(get_deam_path('processed/features/integrated/standardised_essentia_best_overall_opensmile_gemaps_features.csv'))\n",
    "\n",
    "# drop Unnamed:0 column\n",
    "df_essentia_best_overall_opensmile_gemaps_features = df_essentia_best_overall_opensmile_gemaps_features[df_essentia_best_overall_opensmile_gemaps_features.columns[1:]]\n",
    "\n",
    "df_essentia_best_overall_opensmile_gemaps_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1744 entries, 0 to 1743\n",
      "Data columns (total 199 columns):\n",
      " #    Column                                          Dtype  \n",
      "---   ------                                          -----  \n",
      " 0    song_id                                         int64  \n",
      " 1    lowlevel.melbands_kurtosis.dmean                float64\n",
      " 2    lowlevel.melbands_kurtosis.dmean2               float64\n",
      " 3    lowlevel.melbands_kurtosis.dvar                 float64\n",
      " 4    lowlevel.melbands_kurtosis.dvar2                float64\n",
      " 5    lowlevel.melbands_kurtosis.max                  float64\n",
      " 6    lowlevel.melbands_kurtosis.mean                 float64\n",
      " 7    lowlevel.melbands_kurtosis.median               float64\n",
      " 8    lowlevel.melbands_kurtosis.min                  float64\n",
      " 9    lowlevel.melbands_kurtosis.stdev                float64\n",
      " 10   lowlevel.melbands_kurtosis.var                  float64\n",
      " 11   lowlevel.melbands_skewness.dmean                float64\n",
      " 12   lowlevel.melbands_skewness.dmean2               float64\n",
      " 13   lowlevel.melbands_skewness.dvar                 float64\n",
      " 14   lowlevel.melbands_skewness.dvar2                float64\n",
      " 15   lowlevel.melbands_skewness.max                  float64\n",
      " 16   lowlevel.melbands_skewness.mean                 float64\n",
      " 17   lowlevel.melbands_skewness.median               float64\n",
      " 18   lowlevel.melbands_skewness.min                  float64\n",
      " 19   lowlevel.melbands_skewness.stdev                float64\n",
      " 20   lowlevel.melbands_skewness.var                  float64\n",
      " 21   lowlevel.spectral_energy.dmean                  float64\n",
      " 22   lowlevel.spectral_energy.dmean2                 float64\n",
      " 23   lowlevel.spectral_energy.dvar                   float64\n",
      " 24   lowlevel.spectral_energy.dvar2                  float64\n",
      " 25   lowlevel.spectral_energy.max                    float64\n",
      " 26   lowlevel.spectral_energy.mean                   float64\n",
      " 27   lowlevel.spectral_energy.median                 float64\n",
      " 28   lowlevel.spectral_energy.min                    float64\n",
      " 29   lowlevel.spectral_energy.stdev                  float64\n",
      " 30   lowlevel.spectral_energy.var                    float64\n",
      " 31   tonal.chords_strength.dmean                     float64\n",
      " 32   tonal.chords_strength.dmean2                    float64\n",
      " 33   tonal.chords_strength.dvar                      float64\n",
      " 34   tonal.chords_strength.dvar2                     float64\n",
      " 35   tonal.chords_strength.max                       float64\n",
      " 36   tonal.chords_strength.mean                      float64\n",
      " 37   tonal.chords_strength.median                    float64\n",
      " 38   tonal.chords_strength.min                       float64\n",
      " 39   tonal.chords_strength.stdev                     float64\n",
      " 40   tonal.chords_strength.var                       float64\n",
      " 41   tonal.hpcp_entropy.dmean                        float64\n",
      " 42   tonal.hpcp_entropy.dmean2                       float64\n",
      " 43   tonal.hpcp_entropy.dvar                         float64\n",
      " 44   tonal.hpcp_entropy.dvar2                        float64\n",
      " 45   tonal.hpcp_entropy.max                          float64\n",
      " 46   tonal.hpcp_entropy.mean                         float64\n",
      " 47   tonal.hpcp_entropy.median                       float64\n",
      " 48   tonal.hpcp_entropy.min                          float64\n",
      " 49   tonal.hpcp_entropy.stdev                        float64\n",
      " 50   tonal.hpcp_entropy.var                          float64\n",
      " 51   tonal.key_edma.strength                         float64\n",
      " 52   tonal.key_temperley.strength                    float64\n",
      " 53   rhythm.beats_loudness_band_ratio.dmean_0        float64\n",
      " 54   rhythm.beats_loudness_band_ratio.dmean_1        float64\n",
      " 55   rhythm.beats_loudness_band_ratio.dmean_2        float64\n",
      " 56   rhythm.beats_loudness_band_ratio.dmean_3        float64\n",
      " 57   rhythm.beats_loudness_band_ratio.dmean_4        float64\n",
      " 58   rhythm.beats_loudness_band_ratio.dmean_5        float64\n",
      " 59   rhythm.beats_loudness_band_ratio.dmean2_0       float64\n",
      " 60   rhythm.beats_loudness_band_ratio.dmean2_1       float64\n",
      " 61   rhythm.beats_loudness_band_ratio.dmean2_2       float64\n",
      " 62   rhythm.beats_loudness_band_ratio.dmean2_3       float64\n",
      " 63   rhythm.beats_loudness_band_ratio.dmean2_4       float64\n",
      " 64   rhythm.beats_loudness_band_ratio.dmean2_5       float64\n",
      " 65   rhythm.beats_loudness_band_ratio.dvar_0         float64\n",
      " 66   rhythm.beats_loudness_band_ratio.dvar_1         float64\n",
      " 67   rhythm.beats_loudness_band_ratio.dvar_2         float64\n",
      " 68   rhythm.beats_loudness_band_ratio.dvar_3         float64\n",
      " 69   rhythm.beats_loudness_band_ratio.dvar_4         float64\n",
      " 70   rhythm.beats_loudness_band_ratio.dvar_5         float64\n",
      " 71   rhythm.beats_loudness_band_ratio.dvar2_0        float64\n",
      " 72   rhythm.beats_loudness_band_ratio.dvar2_1        float64\n",
      " 73   rhythm.beats_loudness_band_ratio.dvar2_2        float64\n",
      " 74   rhythm.beats_loudness_band_ratio.dvar2_3        float64\n",
      " 75   rhythm.beats_loudness_band_ratio.dvar2_4        float64\n",
      " 76   rhythm.beats_loudness_band_ratio.dvar2_5        float64\n",
      " 77   rhythm.beats_loudness_band_ratio.max_0          float64\n",
      " 78   rhythm.beats_loudness_band_ratio.max_1          float64\n",
      " 79   rhythm.beats_loudness_band_ratio.max_2          float64\n",
      " 80   rhythm.beats_loudness_band_ratio.max_3          float64\n",
      " 81   rhythm.beats_loudness_band_ratio.max_4          float64\n",
      " 82   rhythm.beats_loudness_band_ratio.max_5          float64\n",
      " 83   rhythm.beats_loudness_band_ratio.mean_0         float64\n",
      " 84   rhythm.beats_loudness_band_ratio.mean_1         float64\n",
      " 85   rhythm.beats_loudness_band_ratio.mean_2         float64\n",
      " 86   rhythm.beats_loudness_band_ratio.mean_3         float64\n",
      " 87   rhythm.beats_loudness_band_ratio.mean_4         float64\n",
      " 88   rhythm.beats_loudness_band_ratio.mean_5         float64\n",
      " 89   rhythm.beats_loudness_band_ratio.median_0       float64\n",
      " 90   rhythm.beats_loudness_band_ratio.median_1       float64\n",
      " 91   rhythm.beats_loudness_band_ratio.median_2       float64\n",
      " 92   rhythm.beats_loudness_band_ratio.median_3       float64\n",
      " 93   rhythm.beats_loudness_band_ratio.median_4       float64\n",
      " 94   rhythm.beats_loudness_band_ratio.median_5       float64\n",
      " 95   rhythm.beats_loudness_band_ratio.min_0          float64\n",
      " 96   rhythm.beats_loudness_band_ratio.min_1          float64\n",
      " 97   rhythm.beats_loudness_band_ratio.min_2          float64\n",
      " 98   rhythm.beats_loudness_band_ratio.min_3          float64\n",
      " 99   rhythm.beats_loudness_band_ratio.min_4          float64\n",
      " 100  rhythm.beats_loudness_band_ratio.min_5          float64\n",
      " 101  rhythm.beats_loudness_band_ratio.stdev_0        float64\n",
      " 102  rhythm.beats_loudness_band_ratio.stdev_1        float64\n",
      " 103  rhythm.beats_loudness_band_ratio.stdev_2        float64\n",
      " 104  rhythm.beats_loudness_band_ratio.stdev_3        float64\n",
      " 105  rhythm.beats_loudness_band_ratio.stdev_4        float64\n",
      " 106  rhythm.beats_loudness_band_ratio.stdev_5        float64\n",
      " 107  rhythm.beats_loudness_band_ratio.var_0          float64\n",
      " 108  rhythm.beats_loudness_band_ratio.var_1          float64\n",
      " 109  rhythm.beats_loudness_band_ratio.var_2          float64\n",
      " 110  rhythm.beats_loudness_band_ratio.var_3          float64\n",
      " 111  rhythm.beats_loudness_band_ratio.var_4          float64\n",
      " 112  rhythm.beats_loudness_band_ratio.var_5          float64\n",
      " 113  tonal.chords_histogram_0                        float64\n",
      " 114  tonal.chords_histogram_1                        float64\n",
      " 115  tonal.chords_histogram_2                        float64\n",
      " 116  tonal.chords_histogram_3                        float64\n",
      " 117  tonal.chords_histogram_4                        float64\n",
      " 118  tonal.chords_histogram_5                        float64\n",
      " 119  tonal.chords_histogram_6                        float64\n",
      " 120  tonal.chords_histogram_7                        float64\n",
      " 121  tonal.chords_histogram_8                        float64\n",
      " 122  tonal.chords_histogram_9                        float64\n",
      " 123  tonal.chords_histogram_10                       float64\n",
      " 124  tonal.chords_histogram_11                       float64\n",
      " 125  tonal.chords_histogram_12                       float64\n",
      " 126  tonal.chords_histogram_13                       float64\n",
      " 127  tonal.chords_histogram_14                       float64\n",
      " 128  tonal.chords_histogram_15                       float64\n",
      " 129  tonal.chords_histogram_16                       float64\n",
      " 130  tonal.chords_histogram_17                       float64\n",
      " 131  tonal.chords_histogram_18                       float64\n",
      " 132  tonal.chords_histogram_19                       float64\n",
      " 133  tonal.chords_histogram_20                       float64\n",
      " 134  tonal.chords_histogram_21                       float64\n",
      " 135  tonal.chords_histogram_22                       float64\n",
      " 136  tonal.chords_histogram_23                       float64\n",
      " 137  F0semitoneFrom27.5Hz_sma3nz_amean               float64\n",
      " 138  F0semitoneFrom27.5Hz_sma3nz_stddevNorm          float64\n",
      " 139  F0semitoneFrom27.5Hz_sma3nz_percentile20.0      float64\n",
      " 140  F0semitoneFrom27.5Hz_sma3nz_percentile50.0      float64\n",
      " 141  F0semitoneFrom27.5Hz_sma3nz_percentile80.0      float64\n",
      " 142  F0semitoneFrom27.5Hz_sma3nz_pctlrange0-2        float64\n",
      " 143  F0semitoneFrom27.5Hz_sma3nz_meanRisingSlope     float64\n",
      " 144  F0semitoneFrom27.5Hz_sma3nz_stddevRisingSlope   float64\n",
      " 145  F0semitoneFrom27.5Hz_sma3nz_meanFallingSlope    float64\n",
      " 146  F0semitoneFrom27.5Hz_sma3nz_stddevFallingSlope  float64\n",
      " 147  loudness_sma3_amean                             float64\n",
      " 148  loudness_sma3_stddevNorm                        float64\n",
      " 149  loudness_sma3_percentile20.0                    float64\n",
      " 150  loudness_sma3_percentile50.0                    float64\n",
      " 151  loudness_sma3_percentile80.0                    float64\n",
      " 152  loudness_sma3_pctlrange0-2                      float64\n",
      " 153  loudness_sma3_meanRisingSlope                   float64\n",
      " 154  loudness_sma3_stddevRisingSlope                 float64\n",
      " 155  loudness_sma3_meanFallingSlope                  float64\n",
      " 156  loudness_sma3_stddevFallingSlope                float64\n",
      " 157  jitterLocal_sma3nz_amean                        float64\n",
      " 158  jitterLocal_sma3nz_stddevNorm                   float64\n",
      " 159  shimmerLocaldB_sma3nz_amean                     float64\n",
      " 160  shimmerLocaldB_sma3nz_stddevNorm                float64\n",
      " 161  HNRdBACF_sma3nz_amean                           float64\n",
      " 162  HNRdBACF_sma3nz_stddevNorm                      float64\n",
      " 163  logRelF0-H1-H2_sma3nz_amean                     float64\n",
      " 164  logRelF0-H1-H2_sma3nz_stddevNorm                float64\n",
      " 165  logRelF0-H1-A3_sma3nz_amean                     float64\n",
      " 166  logRelF0-H1-A3_sma3nz_stddevNorm                float64\n",
      " 167  F1frequency_sma3nz_amean                        float64\n",
      " 168  F1frequency_sma3nz_stddevNorm                   float64\n",
      " 169  F1bandwidth_sma3nz_amean                        float64\n",
      " 170  F1bandwidth_sma3nz_stddevNorm                   float64\n",
      " 171  F1amplitudeLogRelF0_sma3nz_amean                float64\n",
      " 172  F1amplitudeLogRelF0_sma3nz_stddevNorm           float64\n",
      " 173  F2frequency_sma3nz_amean                        float64\n",
      " 174  F2frequency_sma3nz_stddevNorm                   float64\n",
      " 175  F2amplitudeLogRelF0_sma3nz_amean                float64\n",
      " 176  F2amplitudeLogRelF0_sma3nz_stddevNorm           float64\n",
      " 177  F3frequency_sma3nz_amean                        float64\n",
      " 178  F3frequency_sma3nz_stddevNorm                   float64\n",
      " 179  F3amplitudeLogRelF0_sma3nz_amean                float64\n",
      " 180  F3amplitudeLogRelF0_sma3nz_stddevNorm           float64\n",
      " 181  alphaRatioV_sma3nz_amean                        float64\n",
      " 182  alphaRatioV_sma3nz_stddevNorm                   float64\n",
      " 183  hammarbergIndexV_sma3nz_amean                   float64\n",
      " 184  hammarbergIndexV_sma3nz_stddevNorm              float64\n",
      " 185  slopeV0-500_sma3nz_amean                        float64\n",
      " 186  slopeV0-500_sma3nz_stddevNorm                   float64\n",
      " 187  slopeV500-1500_sma3nz_amean                     float64\n",
      " 188  slopeV500-1500_sma3nz_stddevNorm                float64\n",
      " 189  alphaRatioUV_sma3nz_amean                       float64\n",
      " 190  hammarbergIndexUV_sma3nz_amean                  float64\n",
      " 191  slopeUV0-500_sma3nz_amean                       float64\n",
      " 192  slopeUV500-1500_sma3nz_amean                    float64\n",
      " 193  loudnessPeaksPerSec                             float64\n",
      " 194  VoicedSegmentsPerSec                            float64\n",
      " 195  MeanVoicedSegmentLengthSec                      float64\n",
      " 196  StddevVoicedSegmentLengthSec                    float64\n",
      " 197  MeanUnvoicedSegmentLength                       float64\n",
      " 198  StddevUnvoicedSegmentLength                     float64\n",
      "dtypes: float64(198), int64(1)\n",
      "memory usage: 2.6 MB\n"
     ]
    }
   ],
   "source": [
    "df_essentia_best_overall_opensmile_gemaps_features.info(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join both the featureset and annotation set together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lowlevel.melbands_kurtosis.dmean</th>\n",
       "      <th>lowlevel.melbands_kurtosis.dmean2</th>\n",
       "      <th>lowlevel.melbands_kurtosis.dvar</th>\n",
       "      <th>lowlevel.melbands_kurtosis.dvar2</th>\n",
       "      <th>lowlevel.melbands_kurtosis.max</th>\n",
       "      <th>lowlevel.melbands_kurtosis.mean</th>\n",
       "      <th>lowlevel.melbands_kurtosis.median</th>\n",
       "      <th>lowlevel.melbands_kurtosis.min</th>\n",
       "      <th>lowlevel.melbands_kurtosis.stdev</th>\n",
       "      <th>lowlevel.melbands_kurtosis.var</th>\n",
       "      <th>...</th>\n",
       "      <th>slopeUV0-500_sma3nz_amean</th>\n",
       "      <th>slopeUV500-1500_sma3nz_amean</th>\n",
       "      <th>loudnessPeaksPerSec</th>\n",
       "      <th>VoicedSegmentsPerSec</th>\n",
       "      <th>MeanVoicedSegmentLengthSec</th>\n",
       "      <th>StddevVoicedSegmentLengthSec</th>\n",
       "      <th>MeanUnvoicedSegmentLength</th>\n",
       "      <th>StddevUnvoicedSegmentLength</th>\n",
       "      <th>valence_mean_mapped</th>\n",
       "      <th>arousal_mean_mapped</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.092381</td>\n",
       "      <td>-0.078572</td>\n",
       "      <td>-0.025137</td>\n",
       "      <td>-0.024931</td>\n",
       "      <td>-0.051278</td>\n",
       "      <td>-0.058571</td>\n",
       "      <td>-0.055109</td>\n",
       "      <td>0.361562</td>\n",
       "      <td>-0.018698</td>\n",
       "      <td>-0.026304</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.181091</td>\n",
       "      <td>0.668531</td>\n",
       "      <td>-0.555169</td>\n",
       "      <td>-0.967327</td>\n",
       "      <td>-0.075432</td>\n",
       "      <td>0.439999</td>\n",
       "      <td>-0.440097</td>\n",
       "      <td>-0.377481</td>\n",
       "      <td>-0.475</td>\n",
       "      <td>-0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.073364</td>\n",
       "      <td>0.050761</td>\n",
       "      <td>-0.025077</td>\n",
       "      <td>-0.024890</td>\n",
       "      <td>-0.020349</td>\n",
       "      <td>1.479718</td>\n",
       "      <td>3.014248</td>\n",
       "      <td>0.583826</td>\n",
       "      <td>0.056605</td>\n",
       "      <td>-0.025526</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.835793</td>\n",
       "      <td>0.496337</td>\n",
       "      <td>-0.932362</td>\n",
       "      <td>0.263018</td>\n",
       "      <td>-0.389877</td>\n",
       "      <td>-0.474327</td>\n",
       "      <td>0.570241</td>\n",
       "      <td>0.450156</td>\n",
       "      <td>-0.375</td>\n",
       "      <td>-0.425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.119333</td>\n",
       "      <td>-0.107505</td>\n",
       "      <td>-0.025174</td>\n",
       "      <td>-0.024965</td>\n",
       "      <td>-0.083147</td>\n",
       "      <td>-0.208423</td>\n",
       "      <td>-0.075820</td>\n",
       "      <td>0.053745</td>\n",
       "      <td>-0.094185</td>\n",
       "      <td>-0.026786</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.758607</td>\n",
       "      <td>0.719491</td>\n",
       "      <td>0.005327</td>\n",
       "      <td>0.196521</td>\n",
       "      <td>-0.381856</td>\n",
       "      <td>-0.512572</td>\n",
       "      <td>-0.174826</td>\n",
       "      <td>-0.303339</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.163481</td>\n",
       "      <td>-0.139436</td>\n",
       "      <td>-0.025195</td>\n",
       "      <td>-0.024978</td>\n",
       "      <td>-0.094325</td>\n",
       "      <td>-0.262338</td>\n",
       "      <td>-0.148097</td>\n",
       "      <td>-0.493194</td>\n",
       "      <td>-0.110313</td>\n",
       "      <td>-0.026850</td>\n",
       "      <td>...</td>\n",
       "      <td>1.453477</td>\n",
       "      <td>-1.260938</td>\n",
       "      <td>-0.603349</td>\n",
       "      <td>-1.000287</td>\n",
       "      <td>-0.015498</td>\n",
       "      <td>0.340968</td>\n",
       "      <td>-0.418676</td>\n",
       "      <td>-0.300240</td>\n",
       "      <td>-0.150</td>\n",
       "      <td>0.075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.721637</td>\n",
       "      <td>0.521923</td>\n",
       "      <td>-0.024526</td>\n",
       "      <td>-0.024479</td>\n",
       "      <td>0.015265</td>\n",
       "      <td>2.154544</td>\n",
       "      <td>4.094221</td>\n",
       "      <td>0.492728</td>\n",
       "      <td>0.184390</td>\n",
       "      <td>-0.023528</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.823529</td>\n",
       "      <td>0.440421</td>\n",
       "      <td>1.121683</td>\n",
       "      <td>-0.917488</td>\n",
       "      <td>-0.139595</td>\n",
       "      <td>0.293586</td>\n",
       "      <td>-0.372262</td>\n",
       "      <td>-0.240131</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1739</th>\n",
       "      <td>-0.154993</td>\n",
       "      <td>-0.129360</td>\n",
       "      <td>-0.025193</td>\n",
       "      <td>-0.024975</td>\n",
       "      <td>-0.100449</td>\n",
       "      <td>-0.321333</td>\n",
       "      <td>-0.138527</td>\n",
       "      <td>0.145668</td>\n",
       "      <td>-0.130138</td>\n",
       "      <td>-0.026911</td>\n",
       "      <td>...</td>\n",
       "      <td>0.230580</td>\n",
       "      <td>-0.884061</td>\n",
       "      <td>1.768270</td>\n",
       "      <td>-0.434687</td>\n",
       "      <td>-0.329498</td>\n",
       "      <td>-0.316919</td>\n",
       "      <td>-0.508329</td>\n",
       "      <td>-0.462869</td>\n",
       "      <td>-0.275</td>\n",
       "      <td>0.225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1740</th>\n",
       "      <td>-0.169892</td>\n",
       "      <td>-0.137550</td>\n",
       "      <td>-0.025197</td>\n",
       "      <td>-0.024978</td>\n",
       "      <td>-0.102115</td>\n",
       "      <td>-0.346532</td>\n",
       "      <td>-0.290196</td>\n",
       "      <td>-0.205395</td>\n",
       "      <td>-0.126981</td>\n",
       "      <td>-0.026903</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247618</td>\n",
       "      <td>-0.770541</td>\n",
       "      <td>1.076880</td>\n",
       "      <td>-0.550845</td>\n",
       "      <td>-0.310073</td>\n",
       "      <td>-0.300887</td>\n",
       "      <td>-0.344771</td>\n",
       "      <td>-0.226950</td>\n",
       "      <td>0.075</td>\n",
       "      <td>-0.275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1741</th>\n",
       "      <td>-0.106021</td>\n",
       "      <td>-0.088136</td>\n",
       "      <td>-0.025128</td>\n",
       "      <td>-0.024919</td>\n",
       "      <td>-0.035307</td>\n",
       "      <td>-0.242062</td>\n",
       "      <td>-0.115127</td>\n",
       "      <td>-0.427167</td>\n",
       "      <td>-0.093478</td>\n",
       "      <td>-0.026783</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.400532</td>\n",
       "      <td>-0.131125</td>\n",
       "      <td>1.027496</td>\n",
       "      <td>0.996925</td>\n",
       "      <td>-0.404940</td>\n",
       "      <td>-0.493444</td>\n",
       "      <td>-0.080049</td>\n",
       "      <td>-0.197836</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1742</th>\n",
       "      <td>-0.124002</td>\n",
       "      <td>-0.105158</td>\n",
       "      <td>-0.025185</td>\n",
       "      <td>-0.024971</td>\n",
       "      <td>-0.068508</td>\n",
       "      <td>-0.098127</td>\n",
       "      <td>0.316466</td>\n",
       "      <td>1.586562</td>\n",
       "      <td>-0.104839</td>\n",
       "      <td>-0.026830</td>\n",
       "      <td>...</td>\n",
       "      <td>0.058214</td>\n",
       "      <td>-0.166695</td>\n",
       "      <td>0.138567</td>\n",
       "      <td>0.629971</td>\n",
       "      <td>-0.396049</td>\n",
       "      <td>-0.541690</td>\n",
       "      <td>-0.219187</td>\n",
       "      <td>-0.239845</td>\n",
       "      <td>-0.100</td>\n",
       "      <td>0.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1743</th>\n",
       "      <td>-0.045190</td>\n",
       "      <td>-0.042233</td>\n",
       "      <td>-0.025147</td>\n",
       "      <td>-0.024939</td>\n",
       "      <td>-0.053395</td>\n",
       "      <td>0.026676</td>\n",
       "      <td>0.151622</td>\n",
       "      <td>-0.962203</td>\n",
       "      <td>-0.044583</td>\n",
       "      <td>-0.026503</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.321659</td>\n",
       "      <td>0.703128</td>\n",
       "      <td>0.994572</td>\n",
       "      <td>0.979312</td>\n",
       "      <td>-0.406345</td>\n",
       "      <td>-0.541945</td>\n",
       "      <td>0.126237</td>\n",
       "      <td>-0.018917</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1744 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      lowlevel.melbands_kurtosis.dmean  lowlevel.melbands_kurtosis.dmean2  \\\n",
       "0                            -0.092381                          -0.078572   \n",
       "1                             0.073364                           0.050761   \n",
       "2                            -0.119333                          -0.107505   \n",
       "3                            -0.163481                          -0.139436   \n",
       "4                             0.721637                           0.521923   \n",
       "...                                ...                                ...   \n",
       "1739                         -0.154993                          -0.129360   \n",
       "1740                         -0.169892                          -0.137550   \n",
       "1741                         -0.106021                          -0.088136   \n",
       "1742                         -0.124002                          -0.105158   \n",
       "1743                         -0.045190                          -0.042233   \n",
       "\n",
       "      lowlevel.melbands_kurtosis.dvar  lowlevel.melbands_kurtosis.dvar2  \\\n",
       "0                           -0.025137                         -0.024931   \n",
       "1                           -0.025077                         -0.024890   \n",
       "2                           -0.025174                         -0.024965   \n",
       "3                           -0.025195                         -0.024978   \n",
       "4                           -0.024526                         -0.024479   \n",
       "...                               ...                               ...   \n",
       "1739                        -0.025193                         -0.024975   \n",
       "1740                        -0.025197                         -0.024978   \n",
       "1741                        -0.025128                         -0.024919   \n",
       "1742                        -0.025185                         -0.024971   \n",
       "1743                        -0.025147                         -0.024939   \n",
       "\n",
       "      lowlevel.melbands_kurtosis.max  lowlevel.melbands_kurtosis.mean  \\\n",
       "0                          -0.051278                        -0.058571   \n",
       "1                          -0.020349                         1.479718   \n",
       "2                          -0.083147                        -0.208423   \n",
       "3                          -0.094325                        -0.262338   \n",
       "4                           0.015265                         2.154544   \n",
       "...                              ...                              ...   \n",
       "1739                       -0.100449                        -0.321333   \n",
       "1740                       -0.102115                        -0.346532   \n",
       "1741                       -0.035307                        -0.242062   \n",
       "1742                       -0.068508                        -0.098127   \n",
       "1743                       -0.053395                         0.026676   \n",
       "\n",
       "      lowlevel.melbands_kurtosis.median  lowlevel.melbands_kurtosis.min  \\\n",
       "0                             -0.055109                        0.361562   \n",
       "1                              3.014248                        0.583826   \n",
       "2                             -0.075820                        0.053745   \n",
       "3                             -0.148097                       -0.493194   \n",
       "4                              4.094221                        0.492728   \n",
       "...                                 ...                             ...   \n",
       "1739                          -0.138527                        0.145668   \n",
       "1740                          -0.290196                       -0.205395   \n",
       "1741                          -0.115127                       -0.427167   \n",
       "1742                           0.316466                        1.586562   \n",
       "1743                           0.151622                       -0.962203   \n",
       "\n",
       "      lowlevel.melbands_kurtosis.stdev  lowlevel.melbands_kurtosis.var  ...  \\\n",
       "0                            -0.018698                       -0.026304  ...   \n",
       "1                             0.056605                       -0.025526  ...   \n",
       "2                            -0.094185                       -0.026786  ...   \n",
       "3                            -0.110313                       -0.026850  ...   \n",
       "4                             0.184390                       -0.023528  ...   \n",
       "...                                ...                             ...  ...   \n",
       "1739                         -0.130138                       -0.026911  ...   \n",
       "1740                         -0.126981                       -0.026903  ...   \n",
       "1741                         -0.093478                       -0.026783  ...   \n",
       "1742                         -0.104839                       -0.026830  ...   \n",
       "1743                         -0.044583                       -0.026503  ...   \n",
       "\n",
       "      slopeUV0-500_sma3nz_amean  slopeUV500-1500_sma3nz_amean  \\\n",
       "0                     -0.181091                      0.668531   \n",
       "1                     -1.835793                      0.496337   \n",
       "2                     -0.758607                      0.719491   \n",
       "3                      1.453477                     -1.260938   \n",
       "4                     -0.823529                      0.440421   \n",
       "...                         ...                           ...   \n",
       "1739                   0.230580                     -0.884061   \n",
       "1740                   0.247618                     -0.770541   \n",
       "1741                  -0.400532                     -0.131125   \n",
       "1742                   0.058214                     -0.166695   \n",
       "1743                  -0.321659                      0.703128   \n",
       "\n",
       "      loudnessPeaksPerSec  VoicedSegmentsPerSec  MeanVoicedSegmentLengthSec  \\\n",
       "0               -0.555169             -0.967327                   -0.075432   \n",
       "1               -0.932362              0.263018                   -0.389877   \n",
       "2                0.005327              0.196521                   -0.381856   \n",
       "3               -0.603349             -1.000287                   -0.015498   \n",
       "4                1.121683             -0.917488                   -0.139595   \n",
       "...                   ...                   ...                         ...   \n",
       "1739             1.768270             -0.434687                   -0.329498   \n",
       "1740             1.076880             -0.550845                   -0.310073   \n",
       "1741             1.027496              0.996925                   -0.404940   \n",
       "1742             0.138567              0.629971                   -0.396049   \n",
       "1743             0.994572              0.979312                   -0.406345   \n",
       "\n",
       "      StddevVoicedSegmentLengthSec  MeanUnvoicedSegmentLength  \\\n",
       "0                         0.439999                  -0.440097   \n",
       "1                        -0.474327                   0.570241   \n",
       "2                        -0.512572                  -0.174826   \n",
       "3                         0.340968                  -0.418676   \n",
       "4                         0.293586                  -0.372262   \n",
       "...                            ...                        ...   \n",
       "1739                     -0.316919                  -0.508329   \n",
       "1740                     -0.300887                  -0.344771   \n",
       "1741                     -0.493444                  -0.080049   \n",
       "1742                     -0.541690                  -0.219187   \n",
       "1743                     -0.541945                   0.126237   \n",
       "\n",
       "      StddevUnvoicedSegmentLength  valence_mean_mapped  arousal_mean_mapped  \n",
       "0                       -0.377481               -0.475               -0.500  \n",
       "1                        0.450156               -0.375               -0.425  \n",
       "2                       -0.303339                0.175                0.125  \n",
       "3                       -0.300240               -0.150                0.075  \n",
       "4                       -0.240131                0.200                0.350  \n",
       "...                           ...                  ...                  ...  \n",
       "1739                    -0.462869               -0.275                0.225  \n",
       "1740                    -0.226950                0.075               -0.275  \n",
       "1741                    -0.197836                0.350                0.300  \n",
       "1742                    -0.239845               -0.100                0.100  \n",
       "1743                    -0.018917                0.200                0.250  \n",
       "\n",
       "[1744 rows x 200 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_essentia_best_overall_opensmile_gemaps_whole = pd.merge(df_essentia_best_overall_opensmile_gemaps_features, df_annotations, how='inner', on='song_id')\n",
    "df_essentia_best_overall_opensmile_gemaps_whole = df_essentia_best_overall_opensmile_gemaps_whole.drop('song_id', axis=1)\n",
    "df_essentia_best_overall_opensmile_gemaps_whole"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare dataframes for the neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform splitting of the dataframe into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lowlevel.melbands_kurtosis.dmean</th>\n",
       "      <th>lowlevel.melbands_kurtosis.dmean2</th>\n",
       "      <th>lowlevel.melbands_kurtosis.dvar</th>\n",
       "      <th>lowlevel.melbands_kurtosis.dvar2</th>\n",
       "      <th>lowlevel.melbands_kurtosis.max</th>\n",
       "      <th>lowlevel.melbands_kurtosis.mean</th>\n",
       "      <th>lowlevel.melbands_kurtosis.median</th>\n",
       "      <th>lowlevel.melbands_kurtosis.min</th>\n",
       "      <th>lowlevel.melbands_kurtosis.stdev</th>\n",
       "      <th>lowlevel.melbands_kurtosis.var</th>\n",
       "      <th>...</th>\n",
       "      <th>alphaRatioUV_sma3nz_amean</th>\n",
       "      <th>hammarbergIndexUV_sma3nz_amean</th>\n",
       "      <th>slopeUV0-500_sma3nz_amean</th>\n",
       "      <th>slopeUV500-1500_sma3nz_amean</th>\n",
       "      <th>loudnessPeaksPerSec</th>\n",
       "      <th>VoicedSegmentsPerSec</th>\n",
       "      <th>MeanVoicedSegmentLengthSec</th>\n",
       "      <th>StddevVoicedSegmentLengthSec</th>\n",
       "      <th>MeanUnvoicedSegmentLength</th>\n",
       "      <th>StddevUnvoicedSegmentLength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.092381</td>\n",
       "      <td>-0.078572</td>\n",
       "      <td>-0.025137</td>\n",
       "      <td>-0.024931</td>\n",
       "      <td>-0.051278</td>\n",
       "      <td>-0.058571</td>\n",
       "      <td>-0.055109</td>\n",
       "      <td>0.361562</td>\n",
       "      <td>-0.018698</td>\n",
       "      <td>-0.026304</td>\n",
       "      <td>...</td>\n",
       "      <td>0.287564</td>\n",
       "      <td>-0.262130</td>\n",
       "      <td>-0.181091</td>\n",
       "      <td>0.668531</td>\n",
       "      <td>-0.555169</td>\n",
       "      <td>-0.967327</td>\n",
       "      <td>-0.075432</td>\n",
       "      <td>0.439999</td>\n",
       "      <td>-0.440097</td>\n",
       "      <td>-0.377481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.073364</td>\n",
       "      <td>0.050761</td>\n",
       "      <td>-0.025077</td>\n",
       "      <td>-0.024890</td>\n",
       "      <td>-0.020349</td>\n",
       "      <td>1.479718</td>\n",
       "      <td>3.014248</td>\n",
       "      <td>0.583826</td>\n",
       "      <td>0.056605</td>\n",
       "      <td>-0.025526</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.745983</td>\n",
       "      <td>1.481523</td>\n",
       "      <td>-1.835793</td>\n",
       "      <td>0.496337</td>\n",
       "      <td>-0.932362</td>\n",
       "      <td>0.263018</td>\n",
       "      <td>-0.389877</td>\n",
       "      <td>-0.474327</td>\n",
       "      <td>0.570241</td>\n",
       "      <td>0.450156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.119333</td>\n",
       "      <td>-0.107505</td>\n",
       "      <td>-0.025174</td>\n",
       "      <td>-0.024965</td>\n",
       "      <td>-0.083147</td>\n",
       "      <td>-0.208423</td>\n",
       "      <td>-0.075820</td>\n",
       "      <td>0.053745</td>\n",
       "      <td>-0.094185</td>\n",
       "      <td>-0.026786</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025746</td>\n",
       "      <td>-0.164946</td>\n",
       "      <td>-0.758607</td>\n",
       "      <td>0.719491</td>\n",
       "      <td>0.005327</td>\n",
       "      <td>0.196521</td>\n",
       "      <td>-0.381856</td>\n",
       "      <td>-0.512572</td>\n",
       "      <td>-0.174826</td>\n",
       "      <td>-0.303339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.163481</td>\n",
       "      <td>-0.139436</td>\n",
       "      <td>-0.025195</td>\n",
       "      <td>-0.024978</td>\n",
       "      <td>-0.094325</td>\n",
       "      <td>-0.262338</td>\n",
       "      <td>-0.148097</td>\n",
       "      <td>-0.493194</td>\n",
       "      <td>-0.110313</td>\n",
       "      <td>-0.026850</td>\n",
       "      <td>...</td>\n",
       "      <td>0.296808</td>\n",
       "      <td>-0.540060</td>\n",
       "      <td>1.453477</td>\n",
       "      <td>-1.260938</td>\n",
       "      <td>-0.603349</td>\n",
       "      <td>-1.000287</td>\n",
       "      <td>-0.015498</td>\n",
       "      <td>0.340968</td>\n",
       "      <td>-0.418676</td>\n",
       "      <td>-0.300240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.721637</td>\n",
       "      <td>0.521923</td>\n",
       "      <td>-0.024526</td>\n",
       "      <td>-0.024479</td>\n",
       "      <td>0.015265</td>\n",
       "      <td>2.154544</td>\n",
       "      <td>4.094221</td>\n",
       "      <td>0.492728</td>\n",
       "      <td>0.184390</td>\n",
       "      <td>-0.023528</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.342634</td>\n",
       "      <td>1.977728</td>\n",
       "      <td>-0.823529</td>\n",
       "      <td>0.440421</td>\n",
       "      <td>1.121683</td>\n",
       "      <td>-0.917488</td>\n",
       "      <td>-0.139595</td>\n",
       "      <td>0.293586</td>\n",
       "      <td>-0.372262</td>\n",
       "      <td>-0.240131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1739</th>\n",
       "      <td>-0.154993</td>\n",
       "      <td>-0.129360</td>\n",
       "      <td>-0.025193</td>\n",
       "      <td>-0.024975</td>\n",
       "      <td>-0.100449</td>\n",
       "      <td>-0.321333</td>\n",
       "      <td>-0.138527</td>\n",
       "      <td>0.145668</td>\n",
       "      <td>-0.130138</td>\n",
       "      <td>-0.026911</td>\n",
       "      <td>...</td>\n",
       "      <td>0.343948</td>\n",
       "      <td>-0.753080</td>\n",
       "      <td>0.230580</td>\n",
       "      <td>-0.884061</td>\n",
       "      <td>1.768270</td>\n",
       "      <td>-0.434687</td>\n",
       "      <td>-0.329498</td>\n",
       "      <td>-0.316919</td>\n",
       "      <td>-0.508329</td>\n",
       "      <td>-0.462869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1740</th>\n",
       "      <td>-0.169892</td>\n",
       "      <td>-0.137550</td>\n",
       "      <td>-0.025197</td>\n",
       "      <td>-0.024978</td>\n",
       "      <td>-0.102115</td>\n",
       "      <td>-0.346532</td>\n",
       "      <td>-0.290196</td>\n",
       "      <td>-0.205395</td>\n",
       "      <td>-0.126981</td>\n",
       "      <td>-0.026903</td>\n",
       "      <td>...</td>\n",
       "      <td>0.222617</td>\n",
       "      <td>-0.444289</td>\n",
       "      <td>0.247618</td>\n",
       "      <td>-0.770541</td>\n",
       "      <td>1.076880</td>\n",
       "      <td>-0.550845</td>\n",
       "      <td>-0.310073</td>\n",
       "      <td>-0.300887</td>\n",
       "      <td>-0.344771</td>\n",
       "      <td>-0.226950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1741</th>\n",
       "      <td>-0.106021</td>\n",
       "      <td>-0.088136</td>\n",
       "      <td>-0.025128</td>\n",
       "      <td>-0.024919</td>\n",
       "      <td>-0.035307</td>\n",
       "      <td>-0.242062</td>\n",
       "      <td>-0.115127</td>\n",
       "      <td>-0.427167</td>\n",
       "      <td>-0.093478</td>\n",
       "      <td>-0.026783</td>\n",
       "      <td>...</td>\n",
       "      <td>0.374784</td>\n",
       "      <td>-0.346391</td>\n",
       "      <td>-0.400532</td>\n",
       "      <td>-0.131125</td>\n",
       "      <td>1.027496</td>\n",
       "      <td>0.996925</td>\n",
       "      <td>-0.404940</td>\n",
       "      <td>-0.493444</td>\n",
       "      <td>-0.080049</td>\n",
       "      <td>-0.197836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1742</th>\n",
       "      <td>-0.124002</td>\n",
       "      <td>-0.105158</td>\n",
       "      <td>-0.025185</td>\n",
       "      <td>-0.024971</td>\n",
       "      <td>-0.068508</td>\n",
       "      <td>-0.098127</td>\n",
       "      <td>0.316466</td>\n",
       "      <td>1.586562</td>\n",
       "      <td>-0.104839</td>\n",
       "      <td>-0.026830</td>\n",
       "      <td>...</td>\n",
       "      <td>0.146768</td>\n",
       "      <td>-0.269664</td>\n",
       "      <td>0.058214</td>\n",
       "      <td>-0.166695</td>\n",
       "      <td>0.138567</td>\n",
       "      <td>0.629971</td>\n",
       "      <td>-0.396049</td>\n",
       "      <td>-0.541690</td>\n",
       "      <td>-0.219187</td>\n",
       "      <td>-0.239845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1743</th>\n",
       "      <td>-0.045190</td>\n",
       "      <td>-0.042233</td>\n",
       "      <td>-0.025147</td>\n",
       "      <td>-0.024939</td>\n",
       "      <td>-0.053395</td>\n",
       "      <td>0.026676</td>\n",
       "      <td>0.151622</td>\n",
       "      <td>-0.962203</td>\n",
       "      <td>-0.044583</td>\n",
       "      <td>-0.026503</td>\n",
       "      <td>...</td>\n",
       "      <td>0.702241</td>\n",
       "      <td>-0.498246</td>\n",
       "      <td>-0.321659</td>\n",
       "      <td>0.703128</td>\n",
       "      <td>0.994572</td>\n",
       "      <td>0.979312</td>\n",
       "      <td>-0.406345</td>\n",
       "      <td>-0.541945</td>\n",
       "      <td>0.126237</td>\n",
       "      <td>-0.018917</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1744 rows × 198 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      lowlevel.melbands_kurtosis.dmean  lowlevel.melbands_kurtosis.dmean2  \\\n",
       "0                            -0.092381                          -0.078572   \n",
       "1                             0.073364                           0.050761   \n",
       "2                            -0.119333                          -0.107505   \n",
       "3                            -0.163481                          -0.139436   \n",
       "4                             0.721637                           0.521923   \n",
       "...                                ...                                ...   \n",
       "1739                         -0.154993                          -0.129360   \n",
       "1740                         -0.169892                          -0.137550   \n",
       "1741                         -0.106021                          -0.088136   \n",
       "1742                         -0.124002                          -0.105158   \n",
       "1743                         -0.045190                          -0.042233   \n",
       "\n",
       "      lowlevel.melbands_kurtosis.dvar  lowlevel.melbands_kurtosis.dvar2  \\\n",
       "0                           -0.025137                         -0.024931   \n",
       "1                           -0.025077                         -0.024890   \n",
       "2                           -0.025174                         -0.024965   \n",
       "3                           -0.025195                         -0.024978   \n",
       "4                           -0.024526                         -0.024479   \n",
       "...                               ...                               ...   \n",
       "1739                        -0.025193                         -0.024975   \n",
       "1740                        -0.025197                         -0.024978   \n",
       "1741                        -0.025128                         -0.024919   \n",
       "1742                        -0.025185                         -0.024971   \n",
       "1743                        -0.025147                         -0.024939   \n",
       "\n",
       "      lowlevel.melbands_kurtosis.max  lowlevel.melbands_kurtosis.mean  \\\n",
       "0                          -0.051278                        -0.058571   \n",
       "1                          -0.020349                         1.479718   \n",
       "2                          -0.083147                        -0.208423   \n",
       "3                          -0.094325                        -0.262338   \n",
       "4                           0.015265                         2.154544   \n",
       "...                              ...                              ...   \n",
       "1739                       -0.100449                        -0.321333   \n",
       "1740                       -0.102115                        -0.346532   \n",
       "1741                       -0.035307                        -0.242062   \n",
       "1742                       -0.068508                        -0.098127   \n",
       "1743                       -0.053395                         0.026676   \n",
       "\n",
       "      lowlevel.melbands_kurtosis.median  lowlevel.melbands_kurtosis.min  \\\n",
       "0                             -0.055109                        0.361562   \n",
       "1                              3.014248                        0.583826   \n",
       "2                             -0.075820                        0.053745   \n",
       "3                             -0.148097                       -0.493194   \n",
       "4                              4.094221                        0.492728   \n",
       "...                                 ...                             ...   \n",
       "1739                          -0.138527                        0.145668   \n",
       "1740                          -0.290196                       -0.205395   \n",
       "1741                          -0.115127                       -0.427167   \n",
       "1742                           0.316466                        1.586562   \n",
       "1743                           0.151622                       -0.962203   \n",
       "\n",
       "      lowlevel.melbands_kurtosis.stdev  lowlevel.melbands_kurtosis.var  ...  \\\n",
       "0                            -0.018698                       -0.026304  ...   \n",
       "1                             0.056605                       -0.025526  ...   \n",
       "2                            -0.094185                       -0.026786  ...   \n",
       "3                            -0.110313                       -0.026850  ...   \n",
       "4                             0.184390                       -0.023528  ...   \n",
       "...                                ...                             ...  ...   \n",
       "1739                         -0.130138                       -0.026911  ...   \n",
       "1740                         -0.126981                       -0.026903  ...   \n",
       "1741                         -0.093478                       -0.026783  ...   \n",
       "1742                         -0.104839                       -0.026830  ...   \n",
       "1743                         -0.044583                       -0.026503  ...   \n",
       "\n",
       "      alphaRatioUV_sma3nz_amean  hammarbergIndexUV_sma3nz_amean  \\\n",
       "0                      0.287564                       -0.262130   \n",
       "1                     -1.745983                        1.481523   \n",
       "2                      0.025746                       -0.164946   \n",
       "3                      0.296808                       -0.540060   \n",
       "4                     -2.342634                        1.977728   \n",
       "...                         ...                             ...   \n",
       "1739                   0.343948                       -0.753080   \n",
       "1740                   0.222617                       -0.444289   \n",
       "1741                   0.374784                       -0.346391   \n",
       "1742                   0.146768                       -0.269664   \n",
       "1743                   0.702241                       -0.498246   \n",
       "\n",
       "      slopeUV0-500_sma3nz_amean  slopeUV500-1500_sma3nz_amean  \\\n",
       "0                     -0.181091                      0.668531   \n",
       "1                     -1.835793                      0.496337   \n",
       "2                     -0.758607                      0.719491   \n",
       "3                      1.453477                     -1.260938   \n",
       "4                     -0.823529                      0.440421   \n",
       "...                         ...                           ...   \n",
       "1739                   0.230580                     -0.884061   \n",
       "1740                   0.247618                     -0.770541   \n",
       "1741                  -0.400532                     -0.131125   \n",
       "1742                   0.058214                     -0.166695   \n",
       "1743                  -0.321659                      0.703128   \n",
       "\n",
       "      loudnessPeaksPerSec  VoicedSegmentsPerSec  MeanVoicedSegmentLengthSec  \\\n",
       "0               -0.555169             -0.967327                   -0.075432   \n",
       "1               -0.932362              0.263018                   -0.389877   \n",
       "2                0.005327              0.196521                   -0.381856   \n",
       "3               -0.603349             -1.000287                   -0.015498   \n",
       "4                1.121683             -0.917488                   -0.139595   \n",
       "...                   ...                   ...                         ...   \n",
       "1739             1.768270             -0.434687                   -0.329498   \n",
       "1740             1.076880             -0.550845                   -0.310073   \n",
       "1741             1.027496              0.996925                   -0.404940   \n",
       "1742             0.138567              0.629971                   -0.396049   \n",
       "1743             0.994572              0.979312                   -0.406345   \n",
       "\n",
       "      StddevVoicedSegmentLengthSec  MeanUnvoicedSegmentLength  \\\n",
       "0                         0.439999                  -0.440097   \n",
       "1                        -0.474327                   0.570241   \n",
       "2                        -0.512572                  -0.174826   \n",
       "3                         0.340968                  -0.418676   \n",
       "4                         0.293586                  -0.372262   \n",
       "...                            ...                        ...   \n",
       "1739                     -0.316919                  -0.508329   \n",
       "1740                     -0.300887                  -0.344771   \n",
       "1741                     -0.493444                  -0.080049   \n",
       "1742                     -0.541690                  -0.219187   \n",
       "1743                     -0.541945                   0.126237   \n",
       "\n",
       "      StddevUnvoicedSegmentLength  \n",
       "0                       -0.377481  \n",
       "1                        0.450156  \n",
       "2                       -0.303339  \n",
       "3                       -0.300240  \n",
       "4                       -0.240131  \n",
       "...                           ...  \n",
       "1739                    -0.462869  \n",
       "1740                    -0.226950  \n",
       "1741                    -0.197836  \n",
       "1742                    -0.239845  \n",
       "1743                    -0.018917  \n",
       "\n",
       "[1744 rows x 198 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = df_essentia_best_overall_opensmile_gemaps_features.drop('song_id', axis=1)\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>valence_mean_mapped</th>\n",
       "      <th>arousal_mean_mapped</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.475</td>\n",
       "      <td>-0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.375</td>\n",
       "      <td>-0.425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.175</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.150</td>\n",
       "      <td>0.075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.200</td>\n",
       "      <td>0.350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1739</th>\n",
       "      <td>-0.275</td>\n",
       "      <td>0.225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1740</th>\n",
       "      <td>0.075</td>\n",
       "      <td>-0.275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1741</th>\n",
       "      <td>0.350</td>\n",
       "      <td>0.300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1742</th>\n",
       "      <td>-0.100</td>\n",
       "      <td>0.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1743</th>\n",
       "      <td>0.200</td>\n",
       "      <td>0.250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1744 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      valence_mean_mapped  arousal_mean_mapped\n",
       "0                  -0.475               -0.500\n",
       "1                  -0.375               -0.425\n",
       "2                   0.175                0.125\n",
       "3                  -0.150                0.075\n",
       "4                   0.200                0.350\n",
       "...                   ...                  ...\n",
       "1739               -0.275                0.225\n",
       "1740                0.075               -0.275\n",
       "1741                0.350                0.300\n",
       "1742               -0.100                0.100\n",
       "1743                0.200                0.250\n",
       "\n",
       "[1744 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets = df_annotations.drop('song_id', axis=1)\n",
    "targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform 80-20 train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, targets, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create tensors for X_train and X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float64)\n",
    "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create tensors for Y_train and Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float64)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define neural network parameters and instantitate neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 1\n",
    "hidden_size = 20 \n",
    "output_size = 2  # Output size for valence and arousal\n",
    "learning_rate = 0.001\n",
    "criterion = nn.MSELoss()\n",
    "num_epochs = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_size, math.ceil((input_size**0.5) * 2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(math.ceil((input_size**0.5) * 2), math.ceil((input_size**0.5) * 2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(math.ceil((input_size**0.5) * 2), math.ceil((input_size**0.5) * 2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(math.ceil((input_size**0.5) * 2), math.ceil((input_size**0.5) * 2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(math.ceil((input_size**0.5) * 2), math.ceil((input_size**0.5) * 2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(math.ceil((input_size**0.5) * 2), math.ceil((input_size**0.5) * 2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(math.ceil((input_size**0.5) * 2), math.ceil((input_size**0.5) * 2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(math.ceil((input_size**0.5) * 2), math.ceil((input_size**0.5) * 2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(math.ceil((input_size**0.5) * 2), math.ceil((input_size**0.5) * 2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(math.ceil((input_size**0.5) * 2), math.ceil((input_size**0.5) * 2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(math.ceil((input_size**0.5) * 2), math.ceil((input_size**0.5) * 2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(math.ceil((input_size**0.5) * 2), 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare input_train_data and target_train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1395, 198])\n"
     ]
    }
   ],
   "source": [
    "input_train_data = X_train_tensor.float()\n",
    "\n",
    "# input_train_data = input_train_data.view(input_train_data.shape[1], -1)\n",
    "print(input_train_data.shape)\n",
    "\n",
    "target_train_labels = y_train_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(num_epochs):\n",
    "  model = NeuralNetwork(input_size=input_train_data.shape[1])\n",
    "  optimiser = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "  \n",
    "  for epoch in range(num_epochs):\n",
    "    optimiser.zero_grad()\n",
    "    \n",
    "    # forward pass\n",
    "    output = model(input_train_data)\n",
    "\n",
    "    # calculate loss\n",
    "    loss = torch.sqrt(criterion(output.float(), target_train_labels.float()))\n",
    "\n",
    "    # backward pass\n",
    "    loss.backward()\n",
    "    # update weights\n",
    "    optimiser.step()\n",
    "\n",
    "    print(f'Epoch {epoch + 1}, Loss: {math.sqrt(loss.item())}')\n",
    "\n",
    "  print(\"Training completed.\")\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.5919856661063264\n",
      "Epoch 2, Loss: 0.5890659989877897\n",
      "Epoch 3, Loss: 0.5862917020236218\n",
      "Epoch 4, Loss: 0.5837528190708093\n",
      "Epoch 5, Loss: 0.5814122229999482\n",
      "Epoch 6, Loss: 0.5792679700373092\n",
      "Epoch 7, Loss: 0.5773848615779948\n",
      "Epoch 8, Loss: 0.5758207641459014\n",
      "Epoch 9, Loss: 0.574334995674005\n",
      "Epoch 10, Loss: 0.57293724254304\n",
      "Epoch 11, Loss: 0.5716229628612757\n",
      "Epoch 12, Loss: 0.5704399384552743\n",
      "Epoch 13, Loss: 0.5693331893409633\n",
      "Epoch 14, Loss: 0.5682908898480724\n",
      "Epoch 15, Loss: 0.5673503242685392\n",
      "Epoch 16, Loss: 0.566478145903395\n",
      "Epoch 17, Loss: 0.5656564419263835\n",
      "Epoch 18, Loss: 0.5648823198628004\n",
      "Epoch 19, Loss: 0.5642465655670637\n",
      "Epoch 20, Loss: 0.5636292090496735\n",
      "Epoch 21, Loss: 0.5630369802224562\n",
      "Epoch 22, Loss: 0.5624857741782257\n",
      "Epoch 23, Loss: 0.5620770983942835\n",
      "Epoch 24, Loss: 0.5616586804270246\n",
      "Epoch 25, Loss: 0.5612376140765565\n",
      "Epoch 26, Loss: 0.5608030258971846\n",
      "Epoch 27, Loss: 0.56034307729387\n",
      "Epoch 28, Loss: 0.5598339904224068\n",
      "Epoch 29, Loss: 0.5592543157463001\n",
      "Epoch 30, Loss: 0.558576490228937\n",
      "Epoch 31, Loss: 0.5577839937593015\n",
      "Epoch 32, Loss: 0.5568675064027988\n",
      "Epoch 33, Loss: 0.555834001724703\n",
      "Epoch 34, Loss: 0.5546372081899484\n",
      "Epoch 35, Loss: 0.5531833025275593\n",
      "Epoch 36, Loss: 0.5514118561604278\n",
      "Epoch 37, Loss: 0.5492750364196191\n",
      "Epoch 38, Loss: 0.5467637630138024\n",
      "Epoch 39, Loss: 0.5438942739762154\n",
      "Epoch 40, Loss: 0.5408306425299025\n",
      "Epoch 41, Loss: 0.5378785607807186\n",
      "Epoch 42, Loss: 0.5355738938386466\n",
      "Epoch 43, Loss: 0.5344906029388151\n",
      "Epoch 44, Loss: 0.5338750385453218\n",
      "Epoch 45, Loss: 0.5320326985746989\n",
      "Epoch 46, Loss: 0.5289975548148657\n",
      "Epoch 47, Loss: 0.5260190644145403\n",
      "Epoch 48, Loss: 0.5238091871463841\n",
      "Epoch 49, Loss: 0.5222651034390364\n",
      "Epoch 50, Loss: 0.5207885214283372\n",
      "Epoch 51, Loss: 0.5189566912855431\n",
      "Epoch 52, Loss: 0.5166718231477093\n",
      "Epoch 53, Loss: 0.514106682499089\n",
      "Epoch 54, Loss: 0.5117273402767013\n",
      "Epoch 55, Loss: 0.5099446650947411\n",
      "Epoch 56, Loss: 0.5085116342096977\n",
      "Epoch 57, Loss: 0.506633034372048\n",
      "Epoch 58, Loss: 0.50424738729062\n",
      "Epoch 59, Loss: 0.5020918301962135\n",
      "Epoch 60, Loss: 0.5004690175884959\n",
      "Epoch 61, Loss: 0.498898275845076\n",
      "Epoch 62, Loss: 0.496849610621678\n",
      "Epoch 63, Loss: 0.4945231076936718\n",
      "Epoch 64, Loss: 0.49236769632199057\n",
      "Epoch 65, Loss: 0.49052402404840495\n",
      "Epoch 66, Loss: 0.4884959244885082\n",
      "Epoch 67, Loss: 0.4862863147335298\n",
      "Epoch 68, Loss: 0.48437318493902937\n",
      "Epoch 69, Loss: 0.4825954202322824\n",
      "Epoch 70, Loss: 0.4807051100520192\n",
      "Epoch 71, Loss: 0.4789130603996791\n",
      "Epoch 72, Loss: 0.47735351827213346\n",
      "Epoch 73, Loss: 0.47573413145769655\n",
      "Epoch 74, Loss: 0.47411518505747885\n",
      "Epoch 75, Loss: 0.4726167299757273\n",
      "Epoch 76, Loss: 0.47108978598778906\n",
      "Epoch 77, Loss: 0.46953594757624506\n",
      "Epoch 78, Loss: 0.46802354787920464\n",
      "Epoch 79, Loss: 0.4665085608442005\n",
      "Epoch 80, Loss: 0.46508902802415875\n",
      "Epoch 81, Loss: 0.463703439822384\n",
      "Epoch 82, Loss: 0.4623559366562247\n",
      "Epoch 83, Loss: 0.46120197984344097\n",
      "Epoch 84, Loss: 0.46019531563439176\n",
      "Epoch 85, Loss: 0.4593040813796257\n",
      "Epoch 86, Loss: 0.4583787696887263\n",
      "Epoch 87, Loss: 0.4575305884459206\n",
      "Epoch 88, Loss: 0.4567590701836976\n",
      "Epoch 89, Loss: 0.45608936970284364\n",
      "Epoch 90, Loss: 0.4554174083477983\n",
      "Epoch 91, Loss: 0.4547646388266179\n",
      "Epoch 92, Loss: 0.4540616253754501\n",
      "Epoch 93, Loss: 0.45329659600039063\n",
      "Epoch 94, Loss: 0.45246900560335057\n",
      "Epoch 95, Loss: 0.4516085373533132\n",
      "Epoch 96, Loss: 0.4507929048403379\n",
      "Epoch 97, Loss: 0.4500125836891162\n",
      "Epoch 98, Loss: 0.4492323168488873\n",
      "Epoch 99, Loss: 0.44846413297351906\n",
      "Epoch 100, Loss: 0.4476865095793023\n",
      "Epoch 101, Loss: 0.44678568180829453\n",
      "Epoch 102, Loss: 0.445825348393365\n",
      "Epoch 103, Loss: 0.44481145545244016\n",
      "Epoch 104, Loss: 0.4437875738489141\n",
      "Epoch 105, Loss: 0.44283924598118146\n",
      "Epoch 106, Loss: 0.4419422608622047\n",
      "Epoch 107, Loss: 0.44110487042529184\n",
      "Epoch 108, Loss: 0.44028979869013196\n",
      "Epoch 109, Loss: 0.4394630770086224\n",
      "Epoch 110, Loss: 0.4385817641579831\n",
      "Epoch 111, Loss: 0.4377232560953723\n",
      "Epoch 112, Loss: 0.43686514159773243\n",
      "Epoch 113, Loss: 0.43599209460694743\n",
      "Epoch 114, Loss: 0.4350953263211274\n",
      "Epoch 115, Loss: 0.43425615935385414\n",
      "Epoch 116, Loss: 0.4334364081481075\n",
      "Epoch 117, Loss: 0.4326901858636395\n",
      "Epoch 118, Loss: 0.4319383621383848\n",
      "Epoch 119, Loss: 0.4311246938685002\n",
      "Epoch 120, Loss: 0.4302303526402684\n",
      "Epoch 121, Loss: 0.42928289958222876\n",
      "Epoch 122, Loss: 0.4285396329262482\n",
      "Epoch 123, Loss: 0.4277305777045877\n",
      "Epoch 124, Loss: 0.42700816477668163\n",
      "Epoch 125, Loss: 0.4262184033750804\n",
      "Epoch 126, Loss: 0.42526520070151075\n",
      "Epoch 127, Loss: 0.42451539109324093\n",
      "Epoch 128, Loss: 0.42371445990654766\n",
      "Epoch 129, Loss: 0.4231099843357119\n",
      "Epoch 130, Loss: 0.42260213283356257\n",
      "Epoch 131, Loss: 0.422034639601246\n",
      "Epoch 132, Loss: 0.42132109907967014\n",
      "Epoch 133, Loss: 0.42043181218495856\n",
      "Epoch 134, Loss: 0.4197833697758853\n",
      "Epoch 135, Loss: 0.4193022658923931\n",
      "Epoch 136, Loss: 0.4187123110877033\n",
      "Epoch 137, Loss: 0.41792248977922264\n",
      "Epoch 138, Loss: 0.41708916065871976\n",
      "Epoch 139, Loss: 0.41652349356670876\n",
      "Epoch 140, Loss: 0.4159927361867451\n",
      "Epoch 141, Loss: 0.4154389732338161\n",
      "Epoch 142, Loss: 0.41473957700664293\n",
      "Epoch 143, Loss: 0.41408882417311943\n",
      "Epoch 144, Loss: 0.41352791735311495\n",
      "Epoch 145, Loss: 0.4130207488295223\n",
      "Epoch 146, Loss: 0.4125867131153277\n",
      "Epoch 147, Loss: 0.4122734827822056\n",
      "Epoch 148, Loss: 0.4119551311221977\n",
      "Epoch 149, Loss: 0.4113054252946999\n",
      "Epoch 150, Loss: 0.41038906211126974\n",
      "Epoch 151, Loss: 0.40974043704168184\n",
      "Epoch 152, Loss: 0.4095332364030887\n",
      "Epoch 153, Loss: 0.4092786755696033\n",
      "Epoch 154, Loss: 0.40874643992118975\n",
      "Epoch 155, Loss: 0.4080086386212522\n",
      "Epoch 156, Loss: 0.407516266667819\n",
      "Epoch 157, Loss: 0.40726267702523766\n",
      "Epoch 158, Loss: 0.40704140238630154\n",
      "Epoch 159, Loss: 0.40659442386303085\n",
      "Epoch 160, Loss: 0.4059435532245575\n",
      "Epoch 161, Loss: 0.40530058988132467\n",
      "Epoch 162, Loss: 0.40481061130640833\n",
      "Epoch 163, Loss: 0.40454696439099885\n",
      "Epoch 164, Loss: 0.40434073242552127\n",
      "Epoch 165, Loss: 0.4041328097284099\n",
      "Epoch 166, Loss: 0.40376133855600277\n",
      "Epoch 167, Loss: 0.40325718494194035\n",
      "Epoch 168, Loss: 0.40266396455550235\n",
      "Epoch 169, Loss: 0.40223925816932243\n",
      "Epoch 170, Loss: 0.4020172942816074\n",
      "Epoch 171, Loss: 0.40185691490237585\n",
      "Epoch 172, Loss: 0.40171943299492513\n",
      "Epoch 173, Loss: 0.40148523084523674\n",
      "Epoch 174, Loss: 0.4011580021882279\n",
      "Epoch 175, Loss: 0.40059065125517707\n",
      "Epoch 176, Loss: 0.40004175385466695\n",
      "Epoch 177, Loss: 0.3996592843816505\n",
      "Epoch 178, Loss: 0.39942426598533914\n",
      "Epoch 179, Loss: 0.3993039713934098\n",
      "Epoch 180, Loss: 0.3993113042813817\n",
      "Epoch 181, Loss: 0.399507376442797\n",
      "Epoch 182, Loss: 0.3992982617232683\n",
      "Epoch 183, Loss: 0.398582955531641\n",
      "Epoch 184, Loss: 0.39751846309584515\n",
      "Epoch 185, Loss: 0.3971466208790008\n",
      "Epoch 186, Loss: 0.39735836795704627\n",
      "Epoch 187, Loss: 0.397288910850058\n",
      "Epoch 188, Loss: 0.39669531111046064\n",
      "Epoch 189, Loss: 0.39598742004001647\n",
      "Epoch 190, Loss: 0.3957618180303878\n",
      "Epoch 191, Loss: 0.3958990728432479\n",
      "Epoch 192, Loss: 0.3958333877094968\n",
      "Epoch 193, Loss: 0.395458981360546\n",
      "Epoch 194, Loss: 0.3948262877201329\n",
      "Epoch 195, Loss: 0.39436680605396907\n",
      "Epoch 196, Loss: 0.3942003845642146\n",
      "Epoch 197, Loss: 0.39422380157633025\n",
      "Epoch 198, Loss: 0.3943568873591307\n",
      "Epoch 199, Loss: 0.39444663774002947\n",
      "Epoch 200, Loss: 0.3943060619416986\n",
      "Epoch 201, Loss: 0.3935800738228291\n",
      "Epoch 202, Loss: 0.39273453438708\n",
      "Epoch 203, Loss: 0.39240185020673585\n",
      "Epoch 204, Loss: 0.39253137794129933\n",
      "Epoch 205, Loss: 0.39258034548914356\n",
      "Epoch 206, Loss: 0.39228390348508385\n",
      "Epoch 207, Loss: 0.3917927643854107\n",
      "Epoch 208, Loss: 0.39142795053351764\n",
      "Epoch 209, Loss: 0.39120425191452535\n",
      "Epoch 210, Loss: 0.3906381414110283\n",
      "Epoch 211, Loss: 0.3905363363731613\n",
      "Epoch 212, Loss: 0.39051634230956306\n",
      "Epoch 213, Loss: 0.39024406932745104\n",
      "Epoch 214, Loss: 0.3900667779556787\n",
      "Epoch 215, Loss: 0.38991002454044343\n",
      "Epoch 216, Loss: 0.3897366531440683\n",
      "Epoch 217, Loss: 0.38943309139351506\n",
      "Epoch 218, Loss: 0.389380073391849\n",
      "Epoch 219, Loss: 0.3889742303013059\n",
      "Epoch 220, Loss: 0.38861520632050234\n",
      "Epoch 221, Loss: 0.38821867778267366\n",
      "Epoch 222, Loss: 0.3878534220423185\n",
      "Epoch 223, Loss: 0.3875100103746534\n",
      "Epoch 224, Loss: 0.38710239916077444\n",
      "Epoch 225, Loss: 0.3868839797178003\n",
      "Epoch 226, Loss: 0.3866570356042401\n",
      "Epoch 227, Loss: 0.38647663359313744\n",
      "Epoch 228, Loss: 0.38674774446550975\n",
      "Epoch 229, Loss: 0.3877638556859717\n",
      "Epoch 230, Loss: 0.3906666924161436\n",
      "Epoch 231, Loss: 0.39133446162617336\n",
      "Epoch 232, Loss: 0.38662955671598126\n",
      "Epoch 233, Loss: 0.3858441954347779\n",
      "Epoch 234, Loss: 0.38821840909862926\n",
      "Epoch 235, Loss: 0.38585989399620385\n",
      "Epoch 236, Loss: 0.3847077611798252\n",
      "Epoch 237, Loss: 0.38646637744534657\n",
      "Epoch 238, Loss: 0.3846694322583883\n",
      "Epoch 239, Loss: 0.3836330067422692\n",
      "Epoch 240, Loss: 0.3851046351577073\n",
      "Epoch 241, Loss: 0.38351675375708005\n",
      "Epoch 242, Loss: 0.38268449161187507\n",
      "Epoch 243, Loss: 0.3836076807728401\n",
      "Epoch 244, Loss: 0.38249968379138516\n",
      "Epoch 245, Loss: 0.38185570316913336\n",
      "Epoch 246, Loss: 0.38216294435107123\n",
      "Epoch 247, Loss: 0.3815248202403041\n",
      "Epoch 248, Loss: 0.38109839348585794\n",
      "Epoch 249, Loss: 0.38098989353267254\n",
      "Epoch 250, Loss: 0.3804740913219844\n",
      "Epoch 251, Loss: 0.3804246426498621\n",
      "Epoch 252, Loss: 0.37996678539727946\n",
      "Epoch 253, Loss: 0.37927743093858024\n",
      "Epoch 254, Loss: 0.379287311814474\n",
      "Epoch 255, Loss: 0.3792039940175036\n",
      "Epoch 256, Loss: 0.37861576940443586\n",
      "Epoch 257, Loss: 0.3783952669286701\n",
      "Epoch 258, Loss: 0.3781817086311745\n",
      "Epoch 259, Loss: 0.37741023597466516\n",
      "Epoch 260, Loss: 0.37699000519118986\n",
      "Epoch 261, Loss: 0.3768171153998342\n",
      "Epoch 262, Loss: 0.37658873423131844\n",
      "Epoch 263, Loss: 0.3760942547378354\n",
      "Epoch 264, Loss: 0.3759542285181149\n",
      "Epoch 265, Loss: 0.37682536040249437\n",
      "Epoch 266, Loss: 0.37783485030963626\n",
      "Epoch 267, Loss: 0.3796447164661476\n",
      "Epoch 268, Loss: 0.3785852468608639\n",
      "Epoch 269, Loss: 0.3747535730348111\n",
      "Epoch 270, Loss: 0.3750963286019059\n",
      "Epoch 271, Loss: 0.37751414004110745\n",
      "Epoch 272, Loss: 0.3753577949386819\n",
      "Epoch 273, Loss: 0.37341819378095703\n",
      "Epoch 274, Loss: 0.3737364581853954\n",
      "Epoch 275, Loss: 0.3746648124908291\n",
      "Epoch 276, Loss: 0.37318573609157096\n",
      "Epoch 277, Loss: 0.37147217579094144\n",
      "Epoch 278, Loss: 0.3716440637769016\n",
      "Epoch 279, Loss: 0.3717703824384796\n",
      "Epoch 280, Loss: 0.3709061399346061\n",
      "Epoch 281, Loss: 0.37066674008700334\n",
      "Epoch 282, Loss: 0.36974225139429967\n",
      "Epoch 283, Loss: 0.36946420767075494\n",
      "Epoch 284, Loss: 0.3698218382584257\n",
      "Epoch 285, Loss: 0.3697804955241304\n",
      "Epoch 286, Loss: 0.3689328370779478\n",
      "Epoch 287, Loss: 0.3690118312696408\n",
      "Epoch 288, Loss: 0.36789430403798845\n",
      "Epoch 289, Loss: 0.3672292158089611\n",
      "Epoch 290, Loss: 0.3669981975784009\n",
      "Epoch 291, Loss: 0.3670668099278797\n",
      "Epoch 292, Loss: 0.3677028732146569\n",
      "Epoch 293, Loss: 0.3686345784536209\n",
      "Epoch 294, Loss: 0.37157234650471416\n",
      "Epoch 295, Loss: 0.3683240021987995\n",
      "Epoch 296, Loss: 0.36635173888274736\n",
      "Epoch 297, Loss: 0.3647659275938516\n",
      "Epoch 298, Loss: 0.36665740200100067\n",
      "Epoch 299, Loss: 0.3685733129407231\n",
      "Epoch 300, Loss: 0.36525214248932264\n",
      "Training completed.\n"
     ]
    }
   ],
   "source": [
    "model = train_model(num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare input_test_data and target_test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([349, 198])\n"
     ]
    }
   ],
   "source": [
    "input_test_data = X_test_tensor.float()\n",
    "\n",
    "# input_test_data = input_test_data.view(input_test_data.shape[1], -1)\n",
    "print(input_test_data.shape)\n",
    "\n",
    "target_test_labels = y_test_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(trained_model):\n",
    "  with torch.no_grad():\n",
    "    test_pred = trained_model(input_test_data)\n",
    "    test_loss = criterion(test_pred.float(), target_test_labels)\n",
    "\n",
    "  rmse = math.sqrt(test_loss.item())\n",
    "  print(f'Test RMSE: {rmse}')\n",
    "\n",
    "  metric = R2Score()\n",
    "  metric.update(test_pred, target_test_labels)\n",
    "  r2_score = metric.compute().item()\n",
    "  print(f'Test R^2 score: {r2_score}')\n",
    "  return test_pred, rmse, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.2576766538309106\n",
      "Test R^2 score: 0.28601930995132696\n"
     ]
    }
   ],
   "source": [
    "test_pred, rmse, r2_score = test_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "True values (test set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1500, -0.1500],\n",
       "        [-0.3000, -0.1000],\n",
       "        [ 0.2000,  0.3500],\n",
       "        [ 0.2250,  0.4500],\n",
       "        [-0.1750, -0.2000],\n",
       "        [-0.5250, -0.3000],\n",
       "        [-0.2500, -0.7750],\n",
       "        [ 0.3000,  0.3000],\n",
       "        [-0.1750, -0.4000],\n",
       "        [ 0.4500,  0.1500],\n",
       "        [ 0.1750,  0.0250],\n",
       "        [-0.1750, -0.0250],\n",
       "        [-0.0500, -0.3000],\n",
       "        [ 0.1250,  0.3000],\n",
       "        [-0.0750, -0.1500],\n",
       "        [-0.2000, -0.2750],\n",
       "        [-0.6000, -0.2250],\n",
       "        [ 0.1500, -0.2000],\n",
       "        [ 0.2750,  0.6000],\n",
       "        [-0.1500, -0.4500],\n",
       "        [-0.2250, -0.6250],\n",
       "        [-0.0250, -0.4500],\n",
       "        [-0.5250, -0.1250],\n",
       "        [ 0.0000,  0.3250],\n",
       "        [ 0.1250,  0.3750],\n",
       "        [ 0.1500, -0.2500],\n",
       "        [ 0.4500,  0.3250],\n",
       "        [ 0.2500,  0.2250],\n",
       "        [-0.1000,  0.0750],\n",
       "        [ 0.4250,  0.1250],\n",
       "        [-0.4500, -0.3500],\n",
       "        [-0.0500,  0.3750],\n",
       "        [-0.4750, -0.2000],\n",
       "        [-0.2750, -0.4000],\n",
       "        [-0.4000, -0.2250],\n",
       "        [ 0.1000, -0.4500],\n",
       "        [-0.2250, -0.6750],\n",
       "        [ 0.3000,  0.1250],\n",
       "        [-0.2000, -0.2250],\n",
       "        [ 0.2500,  0.3750],\n",
       "        [-0.3250, -0.4750],\n",
       "        [ 0.2250,  0.2000],\n",
       "        [ 0.0500,  0.1250],\n",
       "        [-0.5750, -0.6000],\n",
       "        [-0.1250, -0.3500],\n",
       "        [ 0.5000,  0.6000],\n",
       "        [-0.1500,  0.3250],\n",
       "        [-0.1750,  0.0250],\n",
       "        [-0.2750, -0.3250],\n",
       "        [ 0.2500,  0.3500],\n",
       "        [-0.3250, -0.7500],\n",
       "        [ 0.3000,  0.4000],\n",
       "        [ 0.0250,  0.2000],\n",
       "        [ 0.3750,  0.2250],\n",
       "        [-0.4250, -0.3750],\n",
       "        [-0.4250, -0.2500],\n",
       "        [-0.5250, -0.1750],\n",
       "        [-0.0500, -0.1500],\n",
       "        [ 0.1250, -0.1000],\n",
       "        [-0.3250, -0.5000],\n",
       "        [-0.4000, -0.0750],\n",
       "        [ 0.1500, -0.0500],\n",
       "        [-0.3000, -0.6500],\n",
       "        [-0.7000, -0.3750],\n",
       "        [ 0.5500,  0.2500],\n",
       "        [-0.2000, -0.1500],\n",
       "        [ 0.0750,  0.0750],\n",
       "        [-0.3000, -0.4000],\n",
       "        [-0.4250, -0.3750],\n",
       "        [-0.5750, -0.1000],\n",
       "        [ 0.2750, -0.1250],\n",
       "        [-0.1750, -0.2000],\n",
       "        [-0.2750, -0.6250],\n",
       "        [-0.4750, -0.3750],\n",
       "        [ 0.2750,  0.1250],\n",
       "        [ 0.3250,  0.4250],\n",
       "        [-0.3000, -0.1500],\n",
       "        [ 0.0500,  0.0750],\n",
       "        [ 0.2750, -0.2500],\n",
       "        [-0.3000, -0.6500],\n",
       "        [-0.3000,  0.2250],\n",
       "        [-0.4000, -0.0500],\n",
       "        [-0.0250, -0.3500],\n",
       "        [ 0.0000, -0.0500],\n",
       "        [-0.3000, -0.1000],\n",
       "        [ 0.3500, -0.3750],\n",
       "        [ 0.0250,  0.2000],\n",
       "        [-0.2500, -0.2250],\n",
       "        [ 0.0000, -0.3250],\n",
       "        [ 0.1500,  0.0000],\n",
       "        [-0.3500, -0.4750],\n",
       "        [-0.1750, -0.1250],\n",
       "        [-0.6750, -0.6000],\n",
       "        [ 0.2500,  0.2750],\n",
       "        [-0.3000, -0.5750],\n",
       "        [-0.1750, -0.5250],\n",
       "        [ 0.2750,  0.3250],\n",
       "        [ 0.3250, -0.1000],\n",
       "        [ 0.1000,  0.1750],\n",
       "        [-0.0750,  0.2000],\n",
       "        [ 0.2250, -0.3250],\n",
       "        [ 0.3750,  0.5500],\n",
       "        [-0.5250, -0.2500],\n",
       "        [-0.1000,  0.1500],\n",
       "        [ 0.1250,  0.1000],\n",
       "        [-0.3750, -0.3250],\n",
       "        [-0.4750, -0.3500],\n",
       "        [-0.2750, -0.2750],\n",
       "        [-0.2000, -0.0750],\n",
       "        [ 0.2750,  0.6000],\n",
       "        [-0.0500, -0.2500],\n",
       "        [-0.0500,  0.2500],\n",
       "        [-0.4750, -0.2000],\n",
       "        [-0.0250,  0.2000],\n",
       "        [-0.0750,  0.1500],\n",
       "        [ 0.6000,  0.6500],\n",
       "        [ 0.3250,  0.1500],\n",
       "        [-0.3500,  0.0000],\n",
       "        [ 0.2500,  0.2000],\n",
       "        [-0.1500,  0.3750],\n",
       "        [ 0.2250,  0.1000],\n",
       "        [ 0.2750, -0.4250],\n",
       "        [-0.0750,  0.6250],\n",
       "        [-0.1750, -0.3000],\n",
       "        [-0.0750, -0.6500],\n",
       "        [-0.1250,  0.1000],\n",
       "        [ 0.0000, -0.0250],\n",
       "        [ 0.0500,  0.0500],\n",
       "        [-0.1000,  0.0250],\n",
       "        [ 0.2000, -0.0750],\n",
       "        [-0.2750,  0.2250],\n",
       "        [-0.3750,  0.1250],\n",
       "        [-0.0750,  0.0500],\n",
       "        [ 0.3000,  0.0000],\n",
       "        [ 0.2000,  0.3000],\n",
       "        [ 0.3500,  0.1000],\n",
       "        [ 0.5750,  0.6000],\n",
       "        [-0.2750,  0.1250],\n",
       "        [ 0.0750, -0.3500],\n",
       "        [-0.0750, -0.3750],\n",
       "        [ 0.3750,  0.1000],\n",
       "        [ 0.0500, -0.0750],\n",
       "        [-0.4000, -0.0500],\n",
       "        [-0.1750, -0.2750],\n",
       "        [ 0.2000, -0.1750],\n",
       "        [ 0.2750,  0.1000],\n",
       "        [-0.0500, -0.2750],\n",
       "        [-0.3000, -0.4000],\n",
       "        [-0.1250, -0.0500],\n",
       "        [ 0.0250, -0.3500],\n",
       "        [-0.2000, -0.8500],\n",
       "        [ 0.1500,  0.0250],\n",
       "        [ 0.2250, -0.4000],\n",
       "        [-0.1250, -0.2000],\n",
       "        [ 0.3500,  0.1000],\n",
       "        [-0.2000,  0.0000],\n",
       "        [ 0.0250, -0.3500],\n",
       "        [-0.2250,  0.0000],\n",
       "        [-0.0750,  0.1250],\n",
       "        [-0.1000,  0.2000],\n",
       "        [-0.2500, -0.6000],\n",
       "        [ 0.2250,  0.1000],\n",
       "        [ 0.0250,  0.4250],\n",
       "        [-0.2250, -0.2500],\n",
       "        [ 0.1750,  0.3000],\n",
       "        [-0.1500,  0.0500],\n",
       "        [-0.3500, -0.0500],\n",
       "        [-0.4000,  0.2250],\n",
       "        [-0.1000,  0.1500],\n",
       "        [ 0.0000, -0.4750],\n",
       "        [-0.1500, -0.4500],\n",
       "        [ 0.1500,  0.2250],\n",
       "        [ 0.2250,  0.0750],\n",
       "        [ 0.3500,  0.0750],\n",
       "        [ 0.5250,  0.3750],\n",
       "        [ 0.2500,  0.2000],\n",
       "        [ 0.3500,  0.2000],\n",
       "        [-0.0250, -0.3000],\n",
       "        [-0.4000,  0.0750],\n",
       "        [-0.1500,  0.4750],\n",
       "        [-0.4750, -0.6750],\n",
       "        [-0.0750, -0.1750],\n",
       "        [-0.5250, -0.3750],\n",
       "        [ 0.2750, -0.2750],\n",
       "        [ 0.6000,  0.4000],\n",
       "        [-0.4250, -0.5500],\n",
       "        [-0.1500, -0.5750],\n",
       "        [ 0.2250,  0.4500],\n",
       "        [ 0.6500,  0.7000],\n",
       "        [ 0.1750,  0.3250],\n",
       "        [-0.2750, -0.1250],\n",
       "        [-0.2500, -0.4000],\n",
       "        [-0.0250, -0.1250],\n",
       "        [-0.0250, -0.2500],\n",
       "        [-0.1500, -0.3750],\n",
       "        [ 0.3500,  0.4000],\n",
       "        [ 0.5750, -0.4250],\n",
       "        [-0.0750,  0.0750],\n",
       "        [-0.0500, -0.1250],\n",
       "        [ 0.0750,  0.2000],\n",
       "        [-0.1500, -0.0500],\n",
       "        [-0.1500, -0.3000],\n",
       "        [-0.0500,  0.2500],\n",
       "        [-0.3000, -0.4250],\n",
       "        [-0.3000, -0.3500],\n",
       "        [-0.4000, -0.1000],\n",
       "        [-0.1500, -0.5750],\n",
       "        [-0.0750, -0.3750],\n",
       "        [-0.3500, -0.3500],\n",
       "        [ 0.2250,  0.2250],\n",
       "        [ 0.1250,  0.0000],\n",
       "        [-0.1750, -0.2000],\n",
       "        [-0.0750, -0.3000],\n",
       "        [ 0.5000,  0.4000],\n",
       "        [-0.2000, -0.2250],\n",
       "        [-0.2000, -0.4750],\n",
       "        [ 0.3000,  0.1750],\n",
       "        [ 0.1250,  0.0000],\n",
       "        [ 0.1750,  0.4750],\n",
       "        [ 0.1750, -0.2500],\n",
       "        [-0.1250,  0.4250],\n",
       "        [ 0.2000,  0.4750],\n",
       "        [-0.3000, -0.4000],\n",
       "        [-0.1250, -0.5250],\n",
       "        [-0.5750, -0.0750],\n",
       "        [ 0.1750, -0.0250],\n",
       "        [ 0.4000,  0.3500],\n",
       "        [-0.2500,  0.0000],\n",
       "        [-0.4750, -0.3000],\n",
       "        [ 0.1250,  0.2750],\n",
       "        [ 0.0750,  0.1750],\n",
       "        [ 0.3750,  0.1500],\n",
       "        [-0.1750, -0.2250],\n",
       "        [ 0.1250,  0.2750],\n",
       "        [-0.4500, -0.3250],\n",
       "        [ 0.3000,  0.0750],\n",
       "        [-0.3000,  0.0250],\n",
       "        [-0.3250, -0.5250],\n",
       "        [-0.1250, -0.0250],\n",
       "        [ 0.1250,  0.2000],\n",
       "        [-0.3750,  0.0500],\n",
       "        [-0.3250, -0.0500],\n",
       "        [ 0.0500,  0.3000],\n",
       "        [-0.5500, -0.3250],\n",
       "        [-0.2750, -0.3000],\n",
       "        [-0.2750, -0.5500],\n",
       "        [-0.1750, -0.5750],\n",
       "        [ 0.4500,  0.3000],\n",
       "        [-0.2500,  0.1250],\n",
       "        [-0.1000, -0.3250],\n",
       "        [ 0.1250,  0.2250],\n",
       "        [ 0.4750,  0.2750],\n",
       "        [-0.2250, -0.0250],\n",
       "        [ 0.3750,  0.3500],\n",
       "        [ 0.0000,  0.1750],\n",
       "        [-0.4250, -0.1000],\n",
       "        [ 0.1000, -0.1000],\n",
       "        [ 0.2000,  0.1500],\n",
       "        [ 0.1250,  0.0250],\n",
       "        [-0.2500,  0.1750],\n",
       "        [-0.3250, -0.6500],\n",
       "        [-0.0750, -0.3000],\n",
       "        [ 0.0750, -0.1500],\n",
       "        [ 0.5250,  0.5250],\n",
       "        [-0.0750,  0.2250],\n",
       "        [-0.1750,  0.0000],\n",
       "        [ 0.3000, -0.0500],\n",
       "        [-0.3500, -0.4000],\n",
       "        [-0.2250, -0.2000],\n",
       "        [ 0.4750,  0.5500],\n",
       "        [ 0.1000, -0.4750],\n",
       "        [-0.1250,  0.0000],\n",
       "        [-0.3000,  0.0000],\n",
       "        [-0.2750, -0.4500],\n",
       "        [-0.1500, -0.3000],\n",
       "        [ 0.1500, -0.1250],\n",
       "        [ 0.0500, -0.1250],\n",
       "        [ 0.0750,  0.1750],\n",
       "        [-0.1250, -0.1250],\n",
       "        [ 0.5750,  0.2500],\n",
       "        [-0.3750, -0.0500],\n",
       "        [ 0.2250,  0.1000],\n",
       "        [ 0.3250, -0.2000],\n",
       "        [ 0.4750,  0.4500],\n",
       "        [-0.1750, -0.4000],\n",
       "        [ 0.3500,  0.3750],\n",
       "        [-0.4000,  0.1250],\n",
       "        [-0.1500, -0.2750],\n",
       "        [ 0.5750, -0.3750],\n",
       "        [-0.2500,  0.2000],\n",
       "        [ 0.0000,  0.1500],\n",
       "        [ 0.4500, -0.1250],\n",
       "        [-0.1000, -0.0250],\n",
       "        [ 0.1500,  0.0750],\n",
       "        [ 0.2000, -0.1000],\n",
       "        [ 0.0500,  0.0250],\n",
       "        [ 0.3500,  0.4250],\n",
       "        [-0.3500, -0.5500],\n",
       "        [-0.4250, -0.6000],\n",
       "        [ 0.1750,  0.5500],\n",
       "        [ 0.2000,  0.0250],\n",
       "        [-0.2250, -0.1250],\n",
       "        [ 0.2500,  0.1750],\n",
       "        [-0.3750, -0.0500],\n",
       "        [-0.4750, -0.4500],\n",
       "        [-0.3250, -0.5500],\n",
       "        [-0.1250,  0.1750],\n",
       "        [-0.2500, -0.0500],\n",
       "        [ 0.0000,  0.1250],\n",
       "        [-0.6250, -0.1500],\n",
       "        [-0.4250, -0.5500],\n",
       "        [ 0.0250, -0.2000],\n",
       "        [ 0.3250,  0.3750],\n",
       "        [ 0.1750,  0.1500],\n",
       "        [-0.1750, -0.6500],\n",
       "        [ 0.0750,  0.4250],\n",
       "        [-0.4500, -0.3750],\n",
       "        [-0.1250, -0.1750],\n",
       "        [ 0.0500, -0.3000],\n",
       "        [-0.0500,  0.3750],\n",
       "        [-0.2750,  0.0500],\n",
       "        [-0.4750, -0.3250],\n",
       "        [ 0.0000, -0.3000],\n",
       "        [ 0.3750, -0.1000],\n",
       "        [ 0.1750,  0.1000],\n",
       "        [-0.2250, -0.5500],\n",
       "        [ 0.1500,  0.2250],\n",
       "        [-0.6250, -0.5750],\n",
       "        [ 0.0750, -0.2750],\n",
       "        [ 0.3500,  0.6250],\n",
       "        [-0.0500,  0.2500],\n",
       "        [ 0.0750,  0.3500],\n",
       "        [ 0.2000, -0.3000],\n",
       "        [ 0.2000, -0.1500],\n",
       "        [-0.0250, -0.1500],\n",
       "        [-0.3000, -0.1000],\n",
       "        [-0.1250,  0.1000],\n",
       "        [-0.6750, -0.6250],\n",
       "        [-0.0750, -0.1250],\n",
       "        [ 0.2750,  0.2000],\n",
       "        [ 0.0250,  0.0500],\n",
       "        [-0.4750, -0.1500],\n",
       "        [-0.1500, -0.0500],\n",
       "        [ 0.2000,  0.0250],\n",
       "        [-0.1750,  0.1750],\n",
       "        [ 0.2750,  0.2250],\n",
       "        [ 0.2500,  0.2500],\n",
       "        [-0.1750, -0.2250],\n",
       "        [-0.5750, -0.7000]], dtype=torch.float64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.8438e-02,  1.3422e-01],\n",
       "        [-2.1536e-01, -1.4485e-01],\n",
       "        [ 5.4178e-01,  5.1793e-01],\n",
       "        [ 2.5567e-01,  2.9125e-01],\n",
       "        [-4.1663e-02, -2.9653e-01],\n",
       "        [-2.4227e-01, -3.5063e-01],\n",
       "        [-4.0734e-01, -4.7899e-01],\n",
       "        [ 2.7611e-01,  2.9969e-01],\n",
       "        [-2.4187e-01, -3.1090e-01],\n",
       "        [ 1.1935e-01,  1.5500e-01],\n",
       "        [ 2.8012e-01,  3.0446e-01],\n",
       "        [-5.5996e-02,  3.4543e-02],\n",
       "        [-2.4864e-01, -3.6557e-01],\n",
       "        [ 5.3878e-01,  5.1481e-01],\n",
       "        [-2.4036e-01, -1.6465e-01],\n",
       "        [-1.6931e-02, -2.3520e-01],\n",
       "        [-4.5131e-01, -5.0976e-01],\n",
       "        [-2.5728e-01, -3.7081e-01],\n",
       "        [ 2.9222e-01,  3.1103e-01],\n",
       "        [-3.2280e-01, -4.2002e-01],\n",
       "        [-4.0450e-01, -4.7588e-01],\n",
       "        [-9.4189e-02, -1.2169e-01],\n",
       "        [-2.4000e-01, -1.9356e-01],\n",
       "        [ 3.3593e-01,  3.4089e-01],\n",
       "        [ 2.0441e-02, -1.3836e-01],\n",
       "        [-3.4059e-02, -3.1387e-01],\n",
       "        [ 1.7155e-01,  2.2642e-01],\n",
       "        [-4.8202e-02,  7.8109e-04],\n",
       "        [ 5.9994e-02,  1.4309e-01],\n",
       "        [ 3.7148e-01,  3.4745e-01],\n",
       "        [-3.3306e-01, -4.2504e-01],\n",
       "        [ 2.1989e-01,  2.6400e-01],\n",
       "        [ 1.8604e-01,  2.3698e-01],\n",
       "        [-2.4075e-01, -1.9705e-01],\n",
       "        [-2.3979e-01, -1.1758e-01],\n",
       "        [-2.4005e-01, -1.9658e-01],\n",
       "        [-4.5381e-01, -5.1091e-01],\n",
       "        [ 2.5220e-01,  2.6992e-01],\n",
       "        [-2.2577e-01, -1.6860e-01],\n",
       "        [ 6.1651e-02,  1.4077e-01],\n",
       "        [-2.4151e-01, -2.3219e-01],\n",
       "        [ 1.5109e-01,  2.1096e-01],\n",
       "        [ 1.9690e-01,  2.4535e-01],\n",
       "        [-3.8705e-01, -4.6606e-01],\n",
       "        [-8.1934e-02, -1.9422e-01],\n",
       "        [ 1.3688e-01, -3.0966e-01],\n",
       "        [ 2.4779e-01,  2.6723e-01],\n",
       "        [ 2.8414e-02,  1.1889e-01],\n",
       "        [-2.5314e-01, -3.6586e-01],\n",
       "        [ 4.2412e-01,  4.0659e-01],\n",
       "        [-4.1899e-01, -4.8961e-01],\n",
       "        [ 1.8591e-01,  2.3461e-01],\n",
       "        [ 5.0419e-02,  1.3366e-01],\n",
       "        [ 3.0715e-01,  3.1284e-01],\n",
       "        [-2.9177e-01, -3.9458e-01],\n",
       "        [-9.0293e-02, -1.0338e-01],\n",
       "        [-2.9865e-01, -4.0080e-01],\n",
       "        [-4.1515e-05,  9.7037e-02],\n",
       "        [ 4.2268e-01,  4.0916e-01],\n",
       "        [-2.6703e-01, -3.7591e-01],\n",
       "        [-1.8541e-01, -1.9361e-01],\n",
       "        [ 4.2680e-02, -2.2534e-01],\n",
       "        [-3.9950e-01, -4.7302e-01],\n",
       "        [-3.6645e-01, -4.5462e-01],\n",
       "        [ 3.2237e-01,  3.3201e-01],\n",
       "        [ 8.7380e-03,  1.0394e-01],\n",
       "        [-5.2390e-02,  2.5225e-02],\n",
       "        [-2.8119e-01, -3.8666e-01],\n",
       "        [-5.9574e-03, -6.5864e-02],\n",
       "        [-4.4461e-01, -5.0512e-01],\n",
       "        [-2.4159e-01, -2.7096e-01],\n",
       "        [-2.2228e-01, -1.8939e-01],\n",
       "        [-4.3683e-01, -4.9915e-01],\n",
       "        [-3.9845e-01, -4.7194e-01],\n",
       "        [ 3.0024e-01,  3.1178e-01],\n",
       "        [ 4.5962e-01,  4.2234e-01],\n",
       "        [-3.3320e-01, -4.2582e-01],\n",
       "        [ 2.6116e-02,  1.1378e-01],\n",
       "        [-7.3911e-03,  8.6627e-02],\n",
       "        [-3.8173e-01, -4.6050e-01],\n",
       "        [-2.4015e-01, -2.6893e-01],\n",
       "        [-2.4122e-01, -2.0352e-01],\n",
       "        [-6.3887e-02, -7.8471e-02],\n",
       "        [-4.0632e-02,  1.3450e-03],\n",
       "        [-7.7420e-02, -6.6162e-02],\n",
       "        [-3.1444e-02,  7.2681e-03],\n",
       "        [ 4.1117e-02,  1.1474e-01],\n",
       "        [-7.3144e-02, -1.0384e-01],\n",
       "        [-2.2217e-01, -1.2899e-01],\n",
       "        [ 1.5043e-01,  2.1120e-01],\n",
       "        [-2.8730e-01, -3.9388e-01],\n",
       "        [ 3.1563e-01,  3.3184e-01],\n",
       "        [-5.1277e-01, -5.8291e-01],\n",
       "        [ 1.2600e-01,  1.9267e-01],\n",
       "        [-3.3937e-01, -4.2954e-01],\n",
       "        [-1.8968e-02, -3.6525e-01],\n",
       "        [ 7.5615e-02,  1.5282e-01],\n",
       "        [ 6.5430e-02, -5.2511e-01],\n",
       "        [ 9.6946e-02,  1.6896e-01],\n",
       "        [ 2.9814e-02,  1.1662e-01],\n",
       "        [ 2.5138e-01, -7.8208e-01],\n",
       "        [ 9.7598e-02,  1.6660e-01],\n",
       "        [-2.4109e-01, -2.4326e-01],\n",
       "        [ 1.8042e-01,  2.3162e-01],\n",
       "        [ 1.7451e-01,  2.2638e-01],\n",
       "        [-2.3953e-01, -1.5968e-01],\n",
       "        [-1.4957e-02, -8.8502e-02],\n",
       "        [-3.0149e-01, -4.0530e-01],\n",
       "        [-1.6859e-01, -2.4970e-01],\n",
       "        [ 1.5303e-01,  2.0932e-01],\n",
       "        [-2.3734e-01, -1.2419e-01],\n",
       "        [ 4.0837e-02,  1.1021e-01],\n",
       "        [-3.9202e-01, -4.6721e-01],\n",
       "        [-1.3979e-01, -2.7708e-01],\n",
       "        [ 5.0505e-01,  4.7578e-01],\n",
       "        [ 3.7409e-01,  3.3730e-01],\n",
       "        [-5.5072e-02, -2.4829e-02],\n",
       "        [-2.3057e-01, -1.2080e-01],\n",
       "        [ 2.3055e-01,  2.5971e-01],\n",
       "        [ 2.0540e-01,  2.3601e-01],\n",
       "        [ 2.1914e-01,  2.6324e-01],\n",
       "        [ 2.1513e-01,  2.6002e-01],\n",
       "        [ 1.1890e-01,  1.8732e-01],\n",
       "        [-5.1226e-01, -5.9956e-01],\n",
       "        [-1.7374e-01, -2.3859e-01],\n",
       "        [-3.1216e-02,  6.0617e-02],\n",
       "        [ 4.2927e-01,  4.1260e-01],\n",
       "        [ 2.8566e-01,  2.9723e-01],\n",
       "        [ 4.9169e-02,  8.9058e-02],\n",
       "        [ 6.6531e-01,  6.6145e-01],\n",
       "        [-1.0609e-01, -3.9304e-01],\n",
       "        [-8.5391e-02, -4.0617e-01],\n",
       "        [-2.1664e-02,  7.9947e-02],\n",
       "        [ 4.2244e-01,  3.7950e-01],\n",
       "        [ 4.5941e-01,  4.2938e-01],\n",
       "        [-8.4532e-02, -3.2422e-02],\n",
       "        [ 5.4378e-01,  5.2071e-01],\n",
       "        [ 5.2746e-02, -4.4177e-01],\n",
       "        [ 4.3859e-02,  1.2860e-01],\n",
       "        [ 3.1416e-01,  3.3101e-01],\n",
       "        [ 1.3434e-01,  1.9479e-01],\n",
       "        [-4.3230e-02, -4.6985e-02],\n",
       "        [-3.5878e-01, -4.4392e-01],\n",
       "        [-2.3557e-01, -1.9115e-01],\n",
       "        [ 1.5382e-01,  5.7496e-02],\n",
       "        [ 2.8047e-01,  3.0392e-01],\n",
       "        [-2.1077e-02, -1.4071e-01],\n",
       "        [-5.0459e-01, -5.7483e-01],\n",
       "        [ 4.2151e-02,  1.2956e-01],\n",
       "        [ 1.5977e-01,  2.0535e-01],\n",
       "        [-2.4078e-01, -2.0580e-01],\n",
       "        [-2.4115e-01, -2.6485e-01],\n",
       "        [-2.4109e-01, -1.4309e-01],\n",
       "        [ 2.3460e-01,  2.7420e-01],\n",
       "        [ 2.6332e-01,  2.9127e-01],\n",
       "        [-2.3481e-01, -2.2132e-01],\n",
       "        [-2.4118e-01, -2.6970e-01],\n",
       "        [-2.3437e-01, -2.6639e-01],\n",
       "        [ 2.2758e-01,  2.6913e-01],\n",
       "        [-1.2035e-02,  8.4394e-02],\n",
       "        [-3.0517e-01, -4.0553e-01],\n",
       "        [ 2.7965e-01,  3.0953e-01],\n",
       "        [ 4.0077e-01,  3.8034e-01],\n",
       "        [ 2.1960e-01,  2.6262e-01],\n",
       "        [ 8.7995e-02,  1.6416e-01],\n",
       "        [-5.9911e-02,  2.3998e-02],\n",
       "        [-3.3268e-01, -4.2541e-01],\n",
       "        [-6.6652e-02, -1.5320e-01],\n",
       "        [ 6.3169e-02,  2.5965e-02],\n",
       "        [-8.9560e-02, -4.8571e-02],\n",
       "        [-2.8918e-01, -3.9569e-01],\n",
       "        [ 3.4797e-01,  3.4603e-01],\n",
       "        [ 3.2576e-01,  3.3376e-01],\n",
       "        [ 4.5019e-01,  4.2607e-01],\n",
       "        [ 4.8323e-01,  4.5072e-01],\n",
       "        [ 3.1223e-01,  3.2638e-01],\n",
       "        [ 9.9581e-02,  1.7365e-01],\n",
       "        [ 2.3226e-01,  2.6097e-01],\n",
       "        [-2.4186e-01, -2.8194e-01],\n",
       "        [ 1.0896e-01,  1.7467e-01],\n",
       "        [-3.4977e-01, -4.3749e-01],\n",
       "        [-9.1358e-02, -5.1540e-02],\n",
       "        [-2.9217e-01, -3.9746e-01],\n",
       "        [ 3.5221e-02, -4.6284e-02],\n",
       "        [ 4.5990e-01,  4.2225e-01],\n",
       "        [-3.0448e-01, -4.0457e-01],\n",
       "        [-4.1527e-01, -4.8461e-01],\n",
       "        [ 2.1714e-01,  2.0055e-01],\n",
       "        [ 4.7157e-01,  4.3558e-01],\n",
       "        [ 1.7594e-01,  1.9888e-01],\n",
       "        [ 1.2982e-03, -4.7962e-01],\n",
       "        [-2.4168e-01, -3.4200e-01],\n",
       "        [-2.4076e-01, -2.9588e-01],\n",
       "        [ 4.8105e-02,  1.3175e-01],\n",
       "        [-2.4089e-01, -2.3947e-01],\n",
       "        [ 2.9507e-01,  3.0412e-01],\n",
       "        [ 1.7536e-01,  2.2400e-01],\n",
       "        [ 1.5501e-01,  2.1502e-01],\n",
       "        [-2.7836e-02, -2.6188e-01],\n",
       "        [ 3.5309e-03, -6.2167e-02],\n",
       "        [-1.7771e-02,  8.2452e-02],\n",
       "        [-9.2454e-03, -1.5578e-01],\n",
       "        [ 2.4946e-01,  2.8357e-01],\n",
       "        [-3.8907e-01, -4.6627e-01],\n",
       "        [-2.9905e-01, -4.0161e-01],\n",
       "        [ 1.2231e-02,  1.0584e-01],\n",
       "        [-3.9732e-01, -4.7277e-01],\n",
       "        [-2.4079e-01, -1.5957e-01],\n",
       "        [-2.7535e-02,  7.3943e-02],\n",
       "        [ 4.9133e-02,  1.3544e-01],\n",
       "        [ 7.2322e-02,  1.5306e-01],\n",
       "        [-2.3860e-01, -1.3888e-01],\n",
       "        [-3.3647e-01, -4.3016e-01],\n",
       "        [ 1.7765e-01,  2.1592e-01],\n",
       "        [-4.8183e-02, -1.9745e-01],\n",
       "        [-2.1251e-01, -2.1724e-01],\n",
       "        [ 1.8767e-01,  2.2480e-01],\n",
       "        [ 3.8121e-03,  1.0001e-01],\n",
       "        [ 3.7070e-01,  3.7431e-01],\n",
       "        [-1.2586e-01, -2.8882e-01],\n",
       "        [ 6.9876e-03, -4.9247e-01],\n",
       "        [-2.3272e-01, -1.2248e-01],\n",
       "        [-2.5253e-01, -3.6959e-01],\n",
       "        [ 5.6856e-02,  1.3943e-01],\n",
       "        [-3.0927e-01, -4.1010e-01],\n",
       "        [-6.6754e-02,  1.6740e-02],\n",
       "        [ 4.1515e-01,  3.8323e-01],\n",
       "        [-2.3378e-01, -1.4904e-01],\n",
       "        [-4.8111e-01, -5.3437e-01],\n",
       "        [ 3.8318e-01,  3.4509e-01],\n",
       "        [-2.3384e-01, -2.0528e-01],\n",
       "        [ 3.8694e-01,  3.3892e-01],\n",
       "        [-2.8365e-01, -3.8987e-01],\n",
       "        [-1.3454e+00, -1.7220e+00],\n",
       "        [-2.4365e-01, -3.5960e-01],\n",
       "        [ 2.4770e-02,  1.1163e-01],\n",
       "        [-2.5109e-02,  7.5895e-02],\n",
       "        [-6.5382e-02, -2.0743e-01],\n",
       "        [ 1.4963e-02,  1.0538e-01],\n",
       "        [ 1.7543e-01,  2.3131e-01],\n",
       "        [-4.5349e-01, -5.1216e-01],\n",
       "        [-2.4242e-01, -3.2585e-01],\n",
       "        [ 5.9989e-01,  5.8545e-01],\n",
       "        [-3.0220e-01, -4.0281e-01],\n",
       "        [-2.4059e-01, -2.0261e-01],\n",
       "        [-2.6778e-01, -3.7557e-01],\n",
       "        [ 5.2491e-02, -2.4582e-02],\n",
       "        [ 2.3214e-01,  2.6673e-01],\n",
       "        [-7.4345e-02, -3.6194e-03],\n",
       "        [-7.0840e-02,  9.6786e-03],\n",
       "        [ 4.8633e-01,  4.5537e-01],\n",
       "        [ 6.7400e-01,  6.7224e-01],\n",
       "        [-9.4075e-03, -2.6157e-01],\n",
       "        [ 4.6934e-01,  4.3319e-01],\n",
       "        [ 1.1944e-01,  1.8782e-01],\n",
       "        [-8.2034e-02, -1.4016e-01],\n",
       "        [-1.3555e-02,  8.3127e-02],\n",
       "        [ 3.7702e-01,  3.7989e-01],\n",
       "        [ 5.0608e-02,  1.3704e-01],\n",
       "        [-2.3910e-01, -1.1993e-01],\n",
       "        [-2.9613e-01, -4.0112e-01],\n",
       "        [-1.1742e-01, -3.0088e-01],\n",
       "        [-3.8703e-01, -4.6636e-01],\n",
       "        [ 3.5089e-01,  3.2639e-01],\n",
       "        [-6.1439e-02, -1.3883e-01],\n",
       "        [ 1.3335e-01,  1.9886e-01],\n",
       "        [ 2.6260e-02,  1.1381e-01],\n",
       "        [-3.1883e-01, -4.1797e-01],\n",
       "        [-7.3159e-02, -1.3452e-03],\n",
       "        [ 5.0334e-01,  4.7274e-01],\n",
       "        [ 5.2243e-02,  1.3407e-01],\n",
       "        [ 5.6730e-02, -4.0495e-01],\n",
       "        [-2.4718e-01, -3.6334e-01],\n",
       "        [-4.3423e-01, -4.9840e-01],\n",
       "        [-2.3888e-01, -1.5222e-01],\n",
       "        [ 1.2579e-01, -7.8083e-03],\n",
       "        [ 1.2724e-01, -7.2993e-02],\n",
       "        [ 1.0253e-01,  1.4628e-01],\n",
       "        [-2.5059e-03,  9.0663e-02],\n",
       "        [ 1.8939e-01, -4.0627e-01],\n",
       "        [-2.4152e-01, -2.3009e-01],\n",
       "        [ 2.2971e-01,  2.4832e-01],\n",
       "        [ 1.5918e-01,  2.1734e-01],\n",
       "        [-2.8283e-02,  4.6273e-03],\n",
       "        [-3.2168e-01, -4.1657e-01],\n",
       "        [ 1.9837e-01,  1.9144e-01],\n",
       "        [-2.3778e-01, -1.0362e-01],\n",
       "        [-2.3729e-01, -1.2194e-01],\n",
       "        [ 1.6500e-01,  1.2225e-01],\n",
       "        [ 2.0846e-02,  1.1340e-01],\n",
       "        [ 4.5469e-01,  4.2660e-01],\n",
       "        [ 2.2309e-01,  2.6656e-01],\n",
       "        [ 1.1640e-01,  1.8610e-01],\n",
       "        [ 4.7504e-01,  4.4019e-01],\n",
       "        [ 9.6510e-02,  1.7042e-01],\n",
       "        [-3.0693e-02, -4.5906e-02],\n",
       "        [ 2.0775e-01,  2.1770e-01],\n",
       "        [-4.9942e-01, -5.6934e-01],\n",
       "        [-2.4197e-01, -3.1682e-01],\n",
       "        [ 3.5057e-01,  3.4136e-01],\n",
       "        [-4.7787e-03,  2.5503e-02],\n",
       "        [-3.9576e-01, -4.7264e-01],\n",
       "        [ 3.1230e-01,  3.3254e-01],\n",
       "        [-2.1529e-01, -2.4155e-01],\n",
       "        [-3.9966e-01, -4.7480e-01],\n",
       "        [-3.4293e-01, -4.3283e-01],\n",
       "        [-8.9198e-02, -5.3080e-02],\n",
       "        [ 7.7770e-03,  1.0006e-01],\n",
       "        [ 1.9589e-01,  2.4500e-01],\n",
       "        [-2.3459e-01, -3.2408e-01],\n",
       "        [-4.3902e-01, -5.0161e-01],\n",
       "        [ 7.2268e-03,  1.0191e-01],\n",
       "        [-2.2622e-02,  7.6394e-02],\n",
       "        [ 9.6316e-02,  1.7041e-01],\n",
       "        [-2.4223e-01, -2.8062e-01],\n",
       "        [ 1.6493e-01,  2.2239e-01],\n",
       "        [-3.8359e-01, -4.6188e-01],\n",
       "        [-3.0301e-02,  6.9455e-02],\n",
       "        [-6.7713e-02, -8.5921e-02],\n",
       "        [-7.6559e-02, -3.4602e-02],\n",
       "        [-1.3322e-01, -3.3556e-01],\n",
       "        [-2.4481e-01, -3.6047e-01],\n",
       "        [-4.6519e-02,  5.7037e-02],\n",
       "        [ 7.8361e-02,  1.5595e-01],\n",
       "        [ 9.0588e-02,  1.6711e-01],\n",
       "        [-2.9198e-01, -3.9468e-01],\n",
       "        [ 1.9495e-01,  2.4245e-01],\n",
       "        [-1.4592e-02,  8.2124e-02],\n",
       "        [ 9.2369e-03,  1.0020e-01],\n",
       "        [ 3.4447e-01,  3.5099e-01],\n",
       "        [-1.7438e-02, -3.4260e-01],\n",
       "        [ 2.0716e-01,  2.5121e-01],\n",
       "        [-2.4191e-01, -2.7914e-01],\n",
       "        [ 1.0780e-01, -1.8981e-02],\n",
       "        [-2.3878e-01, -3.0218e-01],\n",
       "        [-2.2786e-01, -1.4916e-01],\n",
       "        [ 1.1194e-02,  1.0571e-01],\n",
       "        [-2.3666e-01, -1.5012e-01],\n",
       "        [-5.3373e-02, -1.2685e-01],\n",
       "        [ 3.3747e-02, -2.6885e-02],\n",
       "        [ 4.3487e-02, -3.3565e-01],\n",
       "        [-3.1472e-01, -4.1109e-01],\n",
       "        [-7.3558e-02, -4.3307e-01],\n",
       "        [ 1.2863e-01,  1.9178e-01],\n",
       "        [ 2.1360e-03,  9.9205e-02],\n",
       "        [ 2.8714e-01,  3.1516e-01],\n",
       "        [ 5.4257e-01,  5.1868e-01],\n",
       "        [-8.4271e-02, -3.5896e-02],\n",
       "        [-3.1311e-01, -4.1077e-01]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse relationship between epochs and r^2 score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create lists to store the epochs and R^2 scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs_list = [i for i in range(1, 301)]\n",
    "r2_scores_list = []\n",
    "rmse_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conduct training and testing for each num_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of epochs: 1\n",
      "Epoch 1, Loss: 0.5937800399810507\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.35452848880056964\n",
      "Test R^2 score: -0.36602040368659494\n",
      "Num of epochs: 2\n",
      "Epoch 1, Loss: 0.5711606133975731\n",
      "Epoch 2, Loss: 0.5689570113084879\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.3104160114164725\n",
      "Test R^2 score: -0.0525073900299845\n",
      "Num of epochs: 3\n",
      "Epoch 1, Loss: 0.5831201084173026\n",
      "Epoch 2, Loss: 0.581164207074593\n",
      "Epoch 3, Loss: 0.5792800859730892\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.33527792232098863\n",
      "Test R^2 score: -0.24252575767042395\n",
      "Num of epochs: 4\n",
      "Epoch 1, Loss: 0.5746265961162448\n",
      "Epoch 2, Loss: 0.572735043838687\n",
      "Epoch 3, Loss: 0.5709697646204642\n",
      "Epoch 4, Loss: 0.5693314095737481\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.31390649661380526\n",
      "Test R^2 score: -0.06905817392914027\n",
      "Num of epochs: 5\n",
      "Epoch 1, Loss: 0.5643863308467213\n",
      "Epoch 2, Loss: 0.5630711463893573\n",
      "Epoch 3, Loss: 0.5619478429691649\n",
      "Epoch 4, Loss: 0.5609487229608535\n",
      "Epoch 5, Loss: 0.560103264168775\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.309439361200018\n",
      "Test R^2 score: -0.04821156181738773\n",
      "Num of epochs: 6\n",
      "Epoch 1, Loss: 0.5710577602500815\n",
      "Epoch 2, Loss: 0.5693992985168708\n",
      "Epoch 3, Loss: 0.5678641400030368\n",
      "Epoch 4, Loss: 0.566546192639369\n",
      "Epoch 5, Loss: 0.5652877023212561\n",
      "Epoch 6, Loss: 0.5641038863619788\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.3104328937547551\n",
      "Test R^2 score: -0.04903012202086254\n",
      "Num of epochs: 7\n",
      "Epoch 1, Loss: 0.5769532417395389\n",
      "Epoch 2, Loss: 0.5748324844737139\n",
      "Epoch 3, Loss: 0.5728331476081204\n",
      "Epoch 4, Loss: 0.5709597690041512\n",
      "Epoch 5, Loss: 0.569214927415476\n",
      "Epoch 6, Loss: 0.5676170299031807\n",
      "Epoch 7, Loss: 0.5661156270503516\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.3182449472223947\n",
      "Test R^2 score: -0.10518717046527304\n",
      "Num of epochs: 8\n",
      "Epoch 1, Loss: 0.5694869611602212\n",
      "Epoch 2, Loss: 0.5683928017765838\n",
      "Epoch 3, Loss: 0.5673461482008642\n",
      "Epoch 4, Loss: 0.5663415806124724\n",
      "Epoch 5, Loss: 0.5653791652106844\n",
      "Epoch 6, Loss: 0.5644585368283087\n",
      "Epoch 7, Loss: 0.5635818039379195\n",
      "Epoch 8, Loss: 0.5627661446264105\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.3143438863985406\n",
      "Test R^2 score: -0.07919195349137242\n",
      "Num of epochs: 9\n",
      "Epoch 1, Loss: 0.5910310479753087\n",
      "Epoch 2, Loss: 0.5890988579010015\n",
      "Epoch 3, Loss: 0.5872169766582269\n",
      "Epoch 4, Loss: 0.585384743952537\n",
      "Epoch 5, Loss: 0.5836015039462503\n",
      "Epoch 6, Loss: 0.5818663241828516\n",
      "Epoch 7, Loss: 0.5801790451474242\n",
      "Epoch 8, Loss: 0.5785396995918517\n",
      "Epoch 9, Loss: 0.5769520020264148\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.32592144475290036\n",
      "Test R^2 score: -0.16257440605503515\n",
      "Num of epochs: 10\n",
      "Epoch 1, Loss: 0.5644789693123059\n",
      "Epoch 2, Loss: 0.5634617530820342\n",
      "Epoch 3, Loss: 0.562489430010349\n",
      "Epoch 4, Loss: 0.5615966483778941\n",
      "Epoch 5, Loss: 0.5607785267948451\n",
      "Epoch 6, Loss: 0.560037946777765\n",
      "Epoch 7, Loss: 0.5593444741300502\n",
      "Epoch 8, Loss: 0.5587503173793088\n",
      "Epoch 9, Loss: 0.5582151663931645\n",
      "Epoch 10, Loss: 0.5577390307173222\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.3039542944601431\n",
      "Test R^2 score: -0.006492499076157787\n",
      "Num of epochs: 11\n",
      "Epoch 1, Loss: 0.593212913734862\n",
      "Epoch 2, Loss: 0.5905248991087825\n",
      "Epoch 3, Loss: 0.5879576888755929\n",
      "Epoch 4, Loss: 0.5855556006414472\n",
      "Epoch 5, Loss: 0.5833069307165015\n",
      "Epoch 6, Loss: 0.5811810267964077\n",
      "Epoch 7, Loss: 0.5791468481977121\n",
      "Epoch 8, Loss: 0.5772069394690451\n",
      "Epoch 9, Loss: 0.5753547952532538\n",
      "Epoch 10, Loss: 0.5736151656494236\n",
      "Epoch 11, Loss: 0.5719337151824976\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.31686062715598096\n",
      "Test R^2 score: -0.09902294404843393\n",
      "Num of epochs: 12\n",
      "Epoch 1, Loss: 0.5886589681707708\n",
      "Epoch 2, Loss: 0.5871257685785621\n",
      "Epoch 3, Loss: 0.5856209980961256\n",
      "Epoch 4, Loss: 0.5841538301418897\n",
      "Epoch 5, Loss: 0.5827216080058341\n",
      "Epoch 6, Loss: 0.5813270507523688\n",
      "Epoch 7, Loss: 0.579971226562198\n",
      "Epoch 8, Loss: 0.5786963294583714\n",
      "Epoch 9, Loss: 0.5774137916458498\n",
      "Epoch 10, Loss: 0.5761418997515875\n",
      "Epoch 11, Loss: 0.5749364506806988\n",
      "Epoch 12, Loss: 0.5737621282405151\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.32609778962921154\n",
      "Test R^2 score: -0.14442986025703008\n",
      "Num of epochs: 13\n",
      "Epoch 1, Loss: 0.573161728783417\n",
      "Epoch 2, Loss: 0.571480612960813\n",
      "Epoch 3, Loss: 0.5700779262613999\n",
      "Epoch 4, Loss: 0.5687492580199379\n",
      "Epoch 5, Loss: 0.5674831282002409\n",
      "Epoch 6, Loss: 0.5662858243056187\n",
      "Epoch 7, Loss: 0.5651315486151369\n",
      "Epoch 8, Loss: 0.5640245017992688\n",
      "Epoch 9, Loss: 0.5629684034479341\n",
      "Epoch 10, Loss: 0.56196677577583\n",
      "Epoch 11, Loss: 0.5610220088364448\n",
      "Epoch 12, Loss: 0.5601426371645443\n",
      "Epoch 13, Loss: 0.559330434462424\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.3087886614211358\n",
      "Test R^2 score: -0.037702182567893705\n",
      "Num of epochs: 14\n",
      "Epoch 1, Loss: 0.5791362732749887\n",
      "Epoch 2, Loss: 0.5772889768147059\n",
      "Epoch 3, Loss: 0.5755871149160448\n",
      "Epoch 4, Loss: 0.5740380554310832\n",
      "Epoch 5, Loss: 0.5726070752439233\n",
      "Epoch 6, Loss: 0.5712423973913152\n",
      "Epoch 7, Loss: 0.5699368114749646\n",
      "Epoch 8, Loss: 0.5688353443041281\n",
      "Epoch 9, Loss: 0.5677874069673674\n",
      "Epoch 10, Loss: 0.5667779426383562\n",
      "Epoch 11, Loss: 0.5658069465488555\n",
      "Epoch 12, Loss: 0.564877597960719\n",
      "Epoch 13, Loss: 0.5639915030647634\n",
      "Epoch 14, Loss: 0.563149554006269\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.30971914460573036\n",
      "Test R^2 score: -0.04599577528197929\n",
      "Num of epochs: 15\n",
      "Epoch 1, Loss: 0.5813085434256778\n",
      "Epoch 2, Loss: 0.5790185209434983\n",
      "Epoch 3, Loss: 0.5767985669601696\n",
      "Epoch 4, Loss: 0.5746449556103249\n",
      "Epoch 5, Loss: 0.5725762627543103\n",
      "Epoch 6, Loss: 0.5706302332559798\n",
      "Epoch 7, Loss: 0.5688115317207849\n",
      "Epoch 8, Loss: 0.5670857792796188\n",
      "Epoch 9, Loss: 0.5654817072998392\n",
      "Epoch 10, Loss: 0.5639928505288812\n",
      "Epoch 11, Loss: 0.5626222424663099\n",
      "Epoch 12, Loss: 0.5613869409932658\n",
      "Epoch 13, Loss: 0.5602927612214943\n",
      "Epoch 14, Loss: 0.5593941562718325\n",
      "Epoch 15, Loss: 0.558618691694518\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.3071879753266775\n",
      "Test R^2 score: -0.026426265948142125\n",
      "Num of epochs: 16\n",
      "Epoch 1, Loss: 0.5967576745446299\n",
      "Epoch 2, Loss: 0.5932393387705814\n",
      "Epoch 3, Loss: 0.5898870237531189\n",
      "Epoch 4, Loss: 0.5866957018677077\n",
      "Epoch 5, Loss: 0.5837489645579138\n",
      "Epoch 6, Loss: 0.5812218690033011\n",
      "Epoch 7, Loss: 0.5788174168516194\n",
      "Epoch 8, Loss: 0.5765580774153138\n",
      "Epoch 9, Loss: 0.5744885699510431\n",
      "Epoch 10, Loss: 0.5725189273320778\n",
      "Epoch 11, Loss: 0.5706339674764159\n",
      "Epoch 12, Loss: 0.5688444866042996\n",
      "Epoch 13, Loss: 0.5671563279174301\n",
      "Epoch 14, Loss: 0.565601856327248\n",
      "Epoch 15, Loss: 0.5642301653687296\n",
      "Epoch 16, Loss: 0.5629738295487681\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.3139451810001507\n",
      "Test R^2 score: -0.07838428787310725\n",
      "Num of epochs: 17\n",
      "Epoch 1, Loss: 0.571591080607477\n",
      "Epoch 2, Loss: 0.569778610535534\n",
      "Epoch 3, Loss: 0.5681061590278836\n",
      "Epoch 4, Loss: 0.5665758865466661\n",
      "Epoch 5, Loss: 0.5651983337933251\n",
      "Epoch 6, Loss: 0.5639679351325582\n",
      "Epoch 7, Loss: 0.5628665418588745\n",
      "Epoch 8, Loss: 0.5618848350860735\n",
      "Epoch 9, Loss: 0.5610123937652142\n",
      "Epoch 10, Loss: 0.5602341154877499\n",
      "Epoch 11, Loss: 0.5595457061630099\n",
      "Epoch 12, Loss: 0.5589316353219905\n",
      "Epoch 13, Loss: 0.5583819274489699\n",
      "Epoch 14, Loss: 0.5578877449041432\n",
      "Epoch 15, Loss: 0.5574409486946449\n",
      "Epoch 16, Loss: 0.5570350454235917\n",
      "Epoch 17, Loss: 0.5566629505699674\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.30343643945289667\n",
      "Test R^2 score: -0.003945783343389131\n",
      "Num of epochs: 18\n",
      "Epoch 1, Loss: 0.5738643668553796\n",
      "Epoch 2, Loss: 0.5720000969229796\n",
      "Epoch 3, Loss: 0.5702277342627455\n",
      "Epoch 4, Loss: 0.5685512310671275\n",
      "Epoch 5, Loss: 0.5669976665509361\n",
      "Epoch 6, Loss: 0.5655471073702943\n",
      "Epoch 7, Loss: 0.5642024344803174\n",
      "Epoch 8, Loss: 0.5629586892733779\n",
      "Epoch 9, Loss: 0.5617963044979682\n",
      "Epoch 10, Loss: 0.5607105773711171\n",
      "Epoch 11, Loss: 0.5597340076405821\n",
      "Epoch 12, Loss: 0.5588729800719138\n",
      "Epoch 13, Loss: 0.5581308327398922\n",
      "Epoch 14, Loss: 0.5575338591997847\n",
      "Epoch 15, Loss: 0.5570444616433623\n",
      "Epoch 16, Loss: 0.556659979232814\n",
      "Epoch 17, Loss: 0.5563940472484608\n",
      "Epoch 18, Loss: 0.5562054723426523\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.3036849285045038\n",
      "Test R^2 score: -0.005236659441914648\n",
      "Num of epochs: 19\n",
      "Epoch 1, Loss: 0.6146555039224175\n",
      "Epoch 2, Loss: 0.6122176551110023\n",
      "Epoch 3, Loss: 0.6098316877747247\n",
      "Epoch 4, Loss: 0.6074846977300338\n",
      "Epoch 5, Loss: 0.6052236737809177\n",
      "Epoch 6, Loss: 0.6030495087414983\n",
      "Epoch 7, Loss: 0.600893069254887\n",
      "Epoch 8, Loss: 0.5987572595080569\n",
      "Epoch 9, Loss: 0.5966496936108406\n",
      "Epoch 10, Loss: 0.5945647572362569\n",
      "Epoch 11, Loss: 0.5925012808999167\n",
      "Epoch 12, Loss: 0.5904598176658593\n",
      "Epoch 13, Loss: 0.5885130669950807\n",
      "Epoch 14, Loss: 0.5865976302571493\n",
      "Epoch 15, Loss: 0.5847042838969693\n",
      "Epoch 16, Loss: 0.5828435209471317\n",
      "Epoch 17, Loss: 0.5810071653278798\n",
      "Epoch 18, Loss: 0.5791899177860581\n",
      "Epoch 19, Loss: 0.5774025656096432\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.3272614914462067\n",
      "Test R^2 score: -0.15624500963519972\n",
      "Num of epochs: 20\n",
      "Epoch 1, Loss: 0.5688333010192439\n",
      "Epoch 2, Loss: 0.5670802348620066\n",
      "Epoch 3, Loss: 0.5654503747716699\n",
      "Epoch 4, Loss: 0.5639458194843213\n",
      "Epoch 5, Loss: 0.5625864068528751\n",
      "Epoch 6, Loss: 0.5613596801807949\n",
      "Epoch 7, Loss: 0.5602599948381329\n",
      "Epoch 8, Loss: 0.5592684372568578\n",
      "Epoch 9, Loss: 0.5584269187791472\n",
      "Epoch 10, Loss: 0.5577118320614216\n",
      "Epoch 11, Loss: 0.5571509180560025\n",
      "Epoch 12, Loss: 0.5567314207748021\n",
      "Epoch 13, Loss: 0.5564047598129238\n",
      "Epoch 14, Loss: 0.5561639987169763\n",
      "Epoch 15, Loss: 0.5560222470220287\n",
      "Epoch 16, Loss: 0.5559216859143267\n",
      "Epoch 17, Loss: 0.5558667877410713\n",
      "Epoch 18, Loss: 0.555842660852357\n",
      "Epoch 19, Loss: 0.555838720027705\n",
      "Epoch 20, Loss: 0.5558432238250265\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.3043019756480518\n",
      "Test R^2 score: -0.009408584576971024\n",
      "Num of epochs: 21\n",
      "Epoch 1, Loss: 0.5915857826161072\n",
      "Epoch 2, Loss: 0.5888861151795873\n",
      "Epoch 3, Loss: 0.5864546972763967\n",
      "Epoch 4, Loss: 0.5841060498912912\n",
      "Epoch 5, Loss: 0.5819079121215152\n",
      "Epoch 6, Loss: 0.5798173054755766\n",
      "Epoch 7, Loss: 0.5778301363409942\n",
      "Epoch 8, Loss: 0.5759434910098861\n",
      "Epoch 9, Loss: 0.5741529102596842\n",
      "Epoch 10, Loss: 0.5724543237580677\n",
      "Epoch 11, Loss: 0.5708477434952212\n",
      "Epoch 12, Loss: 0.5693387641640272\n",
      "Epoch 13, Loss: 0.5679248577720416\n",
      "Epoch 14, Loss: 0.5665978995372108\n",
      "Epoch 15, Loss: 0.5653505945312716\n",
      "Epoch 16, Loss: 0.5641812788575001\n",
      "Epoch 17, Loss: 0.5630963131692621\n",
      "Epoch 18, Loss: 0.5620903271701165\n",
      "Epoch 19, Loss: 0.5611602404722807\n",
      "Epoch 20, Loss: 0.56034650777064\n",
      "Epoch 21, Loss: 0.5596371489282504\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.3065920171503299\n",
      "Test R^2 score: -0.02280430351356888\n",
      "Num of epochs: 22\n",
      "Epoch 1, Loss: 0.5691464666670274\n",
      "Epoch 2, Loss: 0.567586366576541\n",
      "Epoch 3, Loss: 0.5661218915952121\n",
      "Epoch 4, Loss: 0.5647565296837519\n",
      "Epoch 5, Loss: 0.563496316599887\n",
      "Epoch 6, Loss: 0.5623456160293658\n",
      "Epoch 7, Loss: 0.561298570803942\n",
      "Epoch 8, Loss: 0.5603506296335554\n",
      "Epoch 9, Loss: 0.5595087946284956\n",
      "Epoch 10, Loss: 0.5587729053368109\n",
      "Epoch 11, Loss: 0.5581508828256376\n",
      "Epoch 12, Loss: 0.5576433486279808\n",
      "Epoch 13, Loss: 0.5572244092576776\n",
      "Epoch 14, Loss: 0.5568923916225572\n",
      "Epoch 15, Loss: 0.5566445869170956\n",
      "Epoch 16, Loss: 0.5564635948961649\n",
      "Epoch 17, Loss: 0.5563401867052215\n",
      "Epoch 18, Loss: 0.5562628551669322\n",
      "Epoch 19, Loss: 0.5562223770483705\n",
      "Epoch 20, Loss: 0.5562051776443354\n",
      "Epoch 21, Loss: 0.5561999802119949\n",
      "Epoch 22, Loss: 0.5561972743130466\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.3026666289039352\n",
      "Test R^2 score: 0.0016060845340539198\n",
      "Num of epochs: 23\n",
      "Epoch 1, Loss: 0.5663433960865778\n",
      "Epoch 2, Loss: 0.5650789164396925\n",
      "Epoch 3, Loss: 0.5638981767363481\n",
      "Epoch 4, Loss: 0.5628037427340586\n",
      "Epoch 5, Loss: 0.5618002035323277\n",
      "Epoch 6, Loss: 0.5608969203541381\n",
      "Epoch 7, Loss: 0.5600995661573972\n",
      "Epoch 8, Loss: 0.5594072353941874\n",
      "Epoch 9, Loss: 0.5587955457143944\n",
      "Epoch 10, Loss: 0.5582578222492935\n",
      "Epoch 11, Loss: 0.5577906991668075\n",
      "Epoch 12, Loss: 0.5573931776865222\n",
      "Epoch 13, Loss: 0.5570557501970436\n",
      "Epoch 14, Loss: 0.5567752876020299\n",
      "Epoch 15, Loss: 0.5565391581897371\n",
      "Epoch 16, Loss: 0.5563597388727403\n",
      "Epoch 17, Loss: 0.556226824159763\n",
      "Epoch 18, Loss: 0.5561355172978604\n",
      "Epoch 19, Loss: 0.5560781481302126\n",
      "Epoch 20, Loss: 0.5560475184491317\n",
      "Epoch 21, Loss: 0.5560360218341373\n",
      "Epoch 22, Loss: 0.5560353518608988\n",
      "Epoch 23, Loss: 0.5560370133930488\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.30383760964246626\n",
      "Test R^2 score: -0.005777301273682922\n",
      "Num of epochs: 24\n",
      "Epoch 1, Loss: 0.5846806078962851\n",
      "Epoch 2, Loss: 0.5825555219507572\n",
      "Epoch 3, Loss: 0.5805107070730554\n",
      "Epoch 4, Loss: 0.5785570077049231\n",
      "Epoch 5, Loss: 0.5769089203405903\n",
      "Epoch 6, Loss: 0.5755053528189601\n",
      "Epoch 7, Loss: 0.5741569849129067\n",
      "Epoch 8, Loss: 0.5729149269308783\n",
      "Epoch 9, Loss: 0.5717456264803954\n",
      "Epoch 10, Loss: 0.5706124757894365\n",
      "Epoch 11, Loss: 0.5695189612047903\n",
      "Epoch 12, Loss: 0.5684743548625417\n",
      "Epoch 13, Loss: 0.5674762747338323\n",
      "Epoch 14, Loss: 0.566524098731342\n",
      "Epoch 15, Loss: 0.5656107347491501\n",
      "Epoch 16, Loss: 0.5647366877350887\n",
      "Epoch 17, Loss: 0.5638970932992649\n",
      "Epoch 18, Loss: 0.5630913381221618\n",
      "Epoch 19, Loss: 0.5624638916717993\n",
      "Epoch 20, Loss: 0.5618294586888075\n",
      "Epoch 21, Loss: 0.5612141429092419\n",
      "Epoch 22, Loss: 0.5606170769836498\n",
      "Epoch 23, Loss: 0.5600339822591295\n",
      "Epoch 24, Loss: 0.5594301963724035\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.3044476720482535\n",
      "Test R^2 score: -0.008927439518905567\n",
      "Num of epochs: 25\n",
      "Epoch 1, Loss: 0.5707223020826442\n",
      "Epoch 2, Loss: 0.5691278250674638\n",
      "Epoch 3, Loss: 0.5676349598309632\n",
      "Epoch 4, Loss: 0.5662772722392433\n",
      "Epoch 5, Loss: 0.5650169961617887\n",
      "Epoch 6, Loss: 0.5638407517021355\n",
      "Epoch 7, Loss: 0.5627519520116071\n",
      "Epoch 8, Loss: 0.5617485590255448\n",
      "Epoch 9, Loss: 0.5608498156772123\n",
      "Epoch 10, Loss: 0.5600340354743305\n",
      "Epoch 11, Loss: 0.5593062971322966\n",
      "Epoch 12, Loss: 0.5586966573184721\n",
      "Epoch 13, Loss: 0.5581811568233259\n",
      "Epoch 14, Loss: 0.5577301872920164\n",
      "Epoch 15, Loss: 0.5573351626193144\n",
      "Epoch 16, Loss: 0.5569981547792509\n",
      "Epoch 17, Loss: 0.5567409759547272\n",
      "Epoch 18, Loss: 0.556522852167103\n",
      "Epoch 19, Loss: 0.556343186534452\n",
      "Epoch 20, Loss: 0.5561902817805424\n",
      "Epoch 21, Loss: 0.5560882772598152\n",
      "Epoch 22, Loss: 0.5560105622835458\n",
      "Epoch 23, Loss: 0.5559320859339868\n",
      "Epoch 24, Loss: 0.5558609169612254\n",
      "Epoch 25, Loss: 0.5558119109551807\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.3032602479448956\n",
      "Test R^2 score: -0.00272775384404611\n",
      "Num of epochs: 26\n",
      "Epoch 1, Loss: 0.5639100151327403\n",
      "Epoch 2, Loss: 0.5628898382346845\n",
      "Epoch 3, Loss: 0.5618790537058874\n",
      "Epoch 4, Loss: 0.5609391066334277\n",
      "Epoch 5, Loss: 0.5601053659053671\n",
      "Epoch 6, Loss: 0.5593837407031258\n",
      "Epoch 7, Loss: 0.5587230879427845\n",
      "Epoch 8, Loss: 0.5581344903991265\n",
      "Epoch 9, Loss: 0.5576224518909909\n",
      "Epoch 10, Loss: 0.5571902054973992\n",
      "Epoch 11, Loss: 0.5568525479775202\n",
      "Epoch 12, Loss: 0.5565854764690433\n",
      "Epoch 13, Loss: 0.556389440782328\n",
      "Epoch 14, Loss: 0.5562591584126754\n",
      "Epoch 15, Loss: 0.5561889689964393\n",
      "Epoch 16, Loss: 0.5561664368515904\n",
      "Epoch 17, Loss: 0.5561804492202175\n",
      "Epoch 18, Loss: 0.556207454854544\n",
      "Epoch 19, Loss: 0.5562380489394234\n",
      "Epoch 20, Loss: 0.5562681859504663\n",
      "Epoch 21, Loss: 0.5562859191441423\n",
      "Epoch 22, Loss: 0.5562847673073392\n",
      "Epoch 23, Loss: 0.5562594798705426\n",
      "Epoch 24, Loss: 0.5562063296459592\n",
      "Epoch 25, Loss: 0.5561218253345381\n",
      "Epoch 26, Loss: 0.5560102138816101\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.30242195220531287\n",
      "Test R^2 score: 0.00317436608412508\n",
      "Num of epochs: 27\n",
      "Epoch 1, Loss: 0.5578031747503334\n",
      "Epoch 2, Loss: 0.5572625951819639\n",
      "Epoch 3, Loss: 0.5568446538343993\n",
      "Epoch 4, Loss: 0.5565451824614768\n",
      "Epoch 5, Loss: 0.5563574890692702\n",
      "Epoch 6, Loss: 0.5562651053531472\n",
      "Epoch 7, Loss: 0.5562452016044848\n",
      "Epoch 8, Loss: 0.5562553544804749\n",
      "Epoch 9, Loss: 0.5562720701575523\n",
      "Epoch 10, Loss: 0.5562764365096889\n",
      "Epoch 11, Loss: 0.5562705164779725\n",
      "Epoch 12, Loss: 0.5562577118499742\n",
      "Epoch 13, Loss: 0.5562347270711892\n",
      "Epoch 14, Loss: 0.5562048829458623\n",
      "Epoch 15, Loss: 0.5561795650850219\n",
      "Epoch 16, Loss: 0.5561527992360541\n",
      "Epoch 17, Loss: 0.5561224684088532\n",
      "Epoch 18, Loss: 0.5560842845826102\n",
      "Epoch 19, Loss: 0.5560343602990243\n",
      "Epoch 20, Loss: 0.5559695565564824\n",
      "Epoch 21, Loss: 0.555888929941827\n",
      "Epoch 22, Loss: 0.5557896048213057\n",
      "Epoch 23, Loss: 0.5556661542105567\n",
      "Epoch 24, Loss: 0.5555123924998446\n",
      "Epoch 25, Loss: 0.5553202713662478\n",
      "Epoch 26, Loss: 0.5550754963156881\n",
      "Epoch 27, Loss: 0.5547541994638153\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.30163685204733126\n",
      "Test R^2 score: 0.007713634862911822\n",
      "Num of epochs: 28\n",
      "Epoch 1, Loss: 0.5584216352876556\n",
      "Epoch 2, Loss: 0.5576881056280716\n",
      "Epoch 3, Loss: 0.5571038978573825\n",
      "Epoch 4, Loss: 0.556657302338915\n",
      "Epoch 5, Loss: 0.5563443650343671\n",
      "Epoch 6, Loss: 0.5561571397315022\n",
      "Epoch 7, Loss: 0.5560784696927181\n",
      "Epoch 8, Loss: 0.556081363746901\n",
      "Epoch 9, Loss: 0.5561142959507763\n",
      "Epoch 10, Loss: 0.5561371249426728\n",
      "Epoch 11, Loss: 0.5561219593084151\n",
      "Epoch 12, Loss: 0.5560536284414858\n",
      "Epoch 13, Loss: 0.5559269931651638\n",
      "Epoch 14, Loss: 0.5557462500747281\n",
      "Epoch 15, Loss: 0.5555196618034942\n",
      "Epoch 16, Loss: 0.5552576922244977\n",
      "Epoch 17, Loss: 0.5549638623853083\n",
      "Epoch 18, Loss: 0.5546401634972019\n",
      "Epoch 19, Loss: 0.5542806557129905\n",
      "Epoch 20, Loss: 0.5538845698279532\n",
      "Epoch 21, Loss: 0.5534396036583042\n",
      "Epoch 22, Loss: 0.5529107934438141\n",
      "Epoch 23, Loss: 0.5522822225744831\n",
      "Epoch 24, Loss: 0.5515390958494347\n",
      "Epoch 25, Loss: 0.5506696114453664\n",
      "Epoch 26, Loss: 0.549657771535736\n",
      "Epoch 27, Loss: 0.5485082488330812\n",
      "Epoch 28, Loss: 0.547220720277243\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.29264017547939203\n",
      "Test R^2 score: 0.06423003630458013\n",
      "Num of epochs: 29\n",
      "Epoch 1, Loss: 0.5819537476008682\n",
      "Epoch 2, Loss: 0.5797713524972832\n",
      "Epoch 3, Loss: 0.5777513482190738\n",
      "Epoch 4, Loss: 0.5758670323729246\n",
      "Epoch 5, Loss: 0.5741110460648302\n",
      "Epoch 6, Loss: 0.572478895839524\n",
      "Epoch 7, Loss: 0.5709654323382738\n",
      "Epoch 8, Loss: 0.5695714447112786\n",
      "Epoch 9, Loss: 0.5682775169755497\n",
      "Epoch 10, Loss: 0.5670904827951884\n",
      "Epoch 11, Loss: 0.5659856089339551\n",
      "Epoch 12, Loss: 0.5649586034480086\n",
      "Epoch 13, Loss: 0.5640054002851631\n",
      "Epoch 14, Loss: 0.5632323689619883\n",
      "Epoch 15, Loss: 0.5625349404821263\n",
      "Epoch 16, Loss: 0.5618847290062388\n",
      "Epoch 17, Loss: 0.5612785004174156\n",
      "Epoch 18, Loss: 0.5607130754620904\n",
      "Epoch 19, Loss: 0.5601856516592969\n",
      "Epoch 20, Loss: 0.5596944461563997\n",
      "Epoch 21, Loss: 0.5592462157000766\n",
      "Epoch 22, Loss: 0.5588504228232467\n",
      "Epoch 23, Loss: 0.5584977074066345\n",
      "Epoch 24, Loss: 0.558179234713559\n",
      "Epoch 25, Loss: 0.5578785833115046\n",
      "Epoch 26, Loss: 0.5575949268607644\n",
      "Epoch 27, Loss: 0.5573324889683525\n",
      "Epoch 28, Loss: 0.5571224068505781\n",
      "Epoch 29, Loss: 0.5569282993022854\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.30542881225613877\n",
      "Test R^2 score: -0.015954426310469283\n",
      "Num of epochs: 30\n",
      "Epoch 1, Loss: 0.5785230864070076\n",
      "Epoch 2, Loss: 0.5771024011108203\n",
      "Epoch 3, Loss: 0.5757189764873302\n",
      "Epoch 4, Loss: 0.5744089084200749\n",
      "Epoch 5, Loss: 0.5731508614415904\n",
      "Epoch 6, Loss: 0.5719217302167805\n",
      "Epoch 7, Loss: 0.5707213099282891\n",
      "Epoch 8, Loss: 0.5695653489191357\n",
      "Epoch 9, Loss: 0.5684976835514003\n",
      "Epoch 10, Loss: 0.567458471089479\n",
      "Epoch 11, Loss: 0.5664439484777325\n",
      "Epoch 12, Loss: 0.5654582014783861\n",
      "Epoch 13, Loss: 0.5645015128227756\n",
      "Epoch 14, Loss: 0.5635778379084484\n",
      "Epoch 15, Loss: 0.5626816721106679\n",
      "Epoch 16, Loss: 0.5620032872446653\n",
      "Epoch 17, Loss: 0.5612884029597203\n",
      "Epoch 18, Loss: 0.5606252103824284\n",
      "Epoch 19, Loss: 0.5599752828132968\n",
      "Epoch 20, Loss: 0.5593266514177069\n",
      "Epoch 21, Loss: 0.5586890292771385\n",
      "Epoch 22, Loss: 0.5580684085532732\n",
      "Epoch 23, Loss: 0.5574617185835103\n",
      "Epoch 24, Loss: 0.556880698383602\n",
      "Epoch 25, Loss: 0.5562880353032158\n",
      "Epoch 26, Loss: 0.5556894574789998\n",
      "Epoch 27, Loss: 0.5551033610245446\n",
      "Epoch 28, Loss: 0.5545092820249743\n",
      "Epoch 29, Loss: 0.5538976176333085\n",
      "Epoch 30, Loss: 0.553260283440517\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2997471910651127\n",
      "Test R^2 score: 0.021369056041318113\n",
      "Num of epochs: 31\n",
      "Epoch 1, Loss: 0.5593046186699431\n",
      "Epoch 2, Loss: 0.5587282085649684\n",
      "Epoch 3, Loss: 0.5582199179577286\n",
      "Epoch 4, Loss: 0.5577729336680008\n",
      "Epoch 5, Loss: 0.5573889804856784\n",
      "Epoch 6, Loss: 0.5570729233399914\n",
      "Epoch 7, Loss: 0.55681061407796\n",
      "Epoch 8, Loss: 0.5565933742880671\n",
      "Epoch 9, Loss: 0.5564330399921619\n",
      "Epoch 10, Loss: 0.5563136160830436\n",
      "Epoch 11, Loss: 0.5562324231831824\n",
      "Epoch 12, Loss: 0.5561796990449903\n",
      "Epoch 13, Loss: 0.5561521829901271\n",
      "Epoch 14, Loss: 0.5561440913498252\n",
      "Epoch 15, Loss: 0.5561490749567843\n",
      "Epoch 16, Loss: 0.5561605692348129\n",
      "Epoch 17, Loss: 0.5561721704447149\n",
      "Epoch 18, Loss: 0.5561799133808727\n",
      "Epoch 19, Loss: 0.5561780111470298\n",
      "Epoch 20, Loss: 0.5561620696358616\n",
      "Epoch 21, Loss: 0.5561274522095812\n",
      "Epoch 22, Loss: 0.5560800775024569\n",
      "Epoch 23, Loss: 0.55601680668122\n",
      "Epoch 24, Loss: 0.5559343106551995\n",
      "Epoch 25, Loss: 0.5558331170384312\n",
      "Epoch 26, Loss: 0.5557116603745526\n",
      "Epoch 27, Loss: 0.5555664942247305\n",
      "Epoch 28, Loss: 0.5553943535924682\n",
      "Epoch 29, Loss: 0.5551858463230518\n",
      "Epoch 30, Loss: 0.5549321508174486\n",
      "Epoch 31, Loss: 0.5546231030974879\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.30186367487040905\n",
      "Test R^2 score: 0.006400275807526334\n",
      "Num of epochs: 32\n",
      "Epoch 1, Loss: 0.5751495602194581\n",
      "Epoch 2, Loss: 0.5727237781298319\n",
      "Epoch 3, Loss: 0.5704434388228662\n",
      "Epoch 4, Loss: 0.568308929616733\n",
      "Epoch 5, Loss: 0.5663283985172537\n",
      "Epoch 6, Loss: 0.5645075841061407\n",
      "Epoch 7, Loss: 0.5628652181722092\n",
      "Epoch 8, Loss: 0.5613911083036419\n",
      "Epoch 9, Loss: 0.5600976240265355\n",
      "Epoch 10, Loss: 0.5589898312433661\n",
      "Epoch 11, Loss: 0.5580743362140506\n",
      "Epoch 12, Loss: 0.5573485306817373\n",
      "Epoch 13, Loss: 0.5568194453467504\n",
      "Epoch 14, Loss: 0.556476234120497\n",
      "Epoch 15, Loss: 0.5562943033727297\n",
      "Epoch 16, Loss: 0.5562421744578382\n",
      "Epoch 17, Loss: 0.5563001160065569\n",
      "Epoch 18, Loss: 0.556424818535214\n",
      "Epoch 19, Loss: 0.556581005450629\n",
      "Epoch 20, Loss: 0.5567323843297923\n",
      "Epoch 21, Loss: 0.5568466073107443\n",
      "Epoch 22, Loss: 0.5569208878471291\n",
      "Epoch 23, Loss: 0.5569151887188623\n",
      "Epoch 24, Loss: 0.5568460453524979\n",
      "Epoch 25, Loss: 0.5567245152485686\n",
      "Epoch 26, Loss: 0.5565629336030397\n",
      "Epoch 27, Loss: 0.5563746837648492\n",
      "Epoch 28, Loss: 0.5561725455375324\n",
      "Epoch 29, Loss: 0.5559681360424581\n",
      "Epoch 30, Loss: 0.5557686115722923\n",
      "Epoch 31, Loss: 0.5555768204301514\n",
      "Epoch 32, Loss: 0.5553802677293659\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.3021068746861973\n",
      "Test R^2 score: 0.005779184060019593\n",
      "Num of epochs: 33\n",
      "Epoch 1, Loss: 0.5670757152018573\n",
      "Epoch 2, Loss: 0.5657970440800497\n",
      "Epoch 3, Loss: 0.5646135306875099\n",
      "Epoch 4, Loss: 0.5635123679488582\n",
      "Epoch 5, Loss: 0.5624966886210989\n",
      "Epoch 6, Loss: 0.5615972321160215\n",
      "Epoch 7, Loss: 0.5608136276715028\n",
      "Epoch 8, Loss: 0.5601044081529614\n",
      "Epoch 9, Loss: 0.5594741978410179\n",
      "Epoch 10, Loss: 0.5588988424636231\n",
      "Epoch 11, Loss: 0.5583772840092361\n",
      "Epoch 12, Loss: 0.5579510439261577\n",
      "Epoch 13, Loss: 0.5576373094979998\n",
      "Epoch 14, Loss: 0.5573500011490291\n",
      "Epoch 15, Loss: 0.5570861639532486\n",
      "Epoch 16, Loss: 0.5568411750239395\n",
      "Epoch 17, Loss: 0.5566118199441165\n",
      "Epoch 18, Loss: 0.5564005283746055\n",
      "Epoch 19, Loss: 0.5561990961078458\n",
      "Epoch 20, Loss: 0.5559978588718243\n",
      "Epoch 21, Loss: 0.5557280438264934\n",
      "Epoch 22, Loss: 0.5554264143679601\n",
      "Epoch 23, Loss: 0.5551246478606398\n",
      "Epoch 24, Loss: 0.5547797166705061\n",
      "Epoch 25, Loss: 0.5543965127118979\n",
      "Epoch 26, Loss: 0.5538916452739513\n",
      "Epoch 27, Loss: 0.553192407196867\n",
      "Epoch 28, Loss: 0.552357143903364\n",
      "Epoch 29, Loss: 0.5514278809522277\n",
      "Epoch 30, Loss: 0.5503045311891844\n",
      "Epoch 31, Loss: 0.5488768043514471\n",
      "Epoch 32, Loss: 0.5470390618689114\n",
      "Epoch 33, Loss: 0.5446885679391009\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2876741343590825\n",
      "Test R^2 score: 0.09822127901911942\n",
      "Num of epochs: 34\n",
      "Epoch 1, Loss: 0.5655132752402559\n",
      "Epoch 2, Loss: 0.5646550698354296\n",
      "Epoch 3, Loss: 0.5638605723242405\n",
      "Epoch 4, Loss: 0.5631011029337164\n",
      "Epoch 5, Loss: 0.562391456091909\n",
      "Epoch 6, Loss: 0.5617246582399643\n",
      "Epoch 7, Loss: 0.5610910890750364\n",
      "Epoch 8, Loss: 0.5604921639887499\n",
      "Epoch 9, Loss: 0.5599293513947903\n",
      "Epoch 10, Loss: 0.5594052642222015\n",
      "Epoch 11, Loss: 0.5589204912981421\n",
      "Epoch 12, Loss: 0.5584749482272863\n",
      "Epoch 13, Loss: 0.5580680080333823\n",
      "Epoch 14, Loss: 0.5576995414674545\n",
      "Epoch 15, Loss: 0.5573702129972034\n",
      "Epoch 16, Loss: 0.5570815632101775\n",
      "Epoch 17, Loss: 0.5568347793080017\n",
      "Epoch 18, Loss: 0.5566231708132476\n",
      "Epoch 19, Loss: 0.5564475008920502\n",
      "Epoch 20, Loss: 0.5563062500104915\n",
      "Epoch 21, Loss: 0.556197140357311\n",
      "Epoch 22, Loss: 0.5561160912223523\n",
      "Epoch 23, Loss: 0.556058184093848\n",
      "Epoch 24, Loss: 0.5560126258905356\n",
      "Epoch 25, Loss: 0.555965375410483\n",
      "Epoch 26, Loss: 0.5559028956947728\n",
      "Epoch 27, Loss: 0.5558138680612278\n",
      "Epoch 28, Loss: 0.555735498003182\n",
      "Epoch 29, Loss: 0.5556184451614457\n",
      "Epoch 30, Loss: 0.5554458913915039\n",
      "Epoch 31, Loss: 0.5552084719411404\n",
      "Epoch 32, Loss: 0.5549053247994781\n",
      "Epoch 33, Loss: 0.5545442154336807\n",
      "Epoch 34, Loss: 0.5541278810002397\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.3004960821849241\n",
      "Test R^2 score: 0.016312948959951\n",
      "Num of epochs: 35\n",
      "Epoch 1, Loss: 0.5803265280561017\n",
      "Epoch 2, Loss: 0.5783767925125023\n",
      "Epoch 3, Loss: 0.5765042397028052\n",
      "Epoch 4, Loss: 0.5748930105932736\n",
      "Epoch 5, Loss: 0.5734210019765691\n",
      "Epoch 6, Loss: 0.5720142684787478\n",
      "Epoch 7, Loss: 0.5709423871762926\n",
      "Epoch 8, Loss: 0.5698997101058932\n",
      "Epoch 9, Loss: 0.569030496576156\n",
      "Epoch 10, Loss: 0.5681828490161215\n",
      "Epoch 11, Loss: 0.5673474089037788\n",
      "Epoch 12, Loss: 0.56652814934565\n",
      "Epoch 13, Loss: 0.5657267210314062\n",
      "Epoch 14, Loss: 0.5649457319748501\n",
      "Epoch 15, Loss: 0.5641865876463957\n",
      "Epoch 16, Loss: 0.5634852628515514\n",
      "Epoch 17, Loss: 0.5628343489163972\n",
      "Epoch 18, Loss: 0.5621902354641958\n",
      "Epoch 19, Loss: 0.561562021007981\n",
      "Epoch 20, Loss: 0.5609481385478695\n",
      "Epoch 21, Loss: 0.5603690845705704\n",
      "Epoch 22, Loss: 0.5598120574966459\n",
      "Epoch 23, Loss: 0.5592553015991809\n",
      "Epoch 24, Loss: 0.5586730793996105\n",
      "Epoch 25, Loss: 0.5580768194045828\n",
      "Epoch 26, Loss: 0.5574708870269908\n",
      "Epoch 27, Loss: 0.5568262694130653\n",
      "Epoch 28, Loss: 0.5561519954368833\n",
      "Epoch 29, Loss: 0.5554705988642616\n",
      "Epoch 30, Loss: 0.5546900252163856\n",
      "Epoch 31, Loss: 0.5537704085987312\n",
      "Epoch 32, Loss: 0.5526858466853867\n",
      "Epoch 33, Loss: 0.5514002899167776\n",
      "Epoch 34, Loss: 0.5498614104096868\n",
      "Epoch 35, Loss: 0.5479871340741442\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.29067760601321196\n",
      "Test R^2 score: 0.07569099231327808\n",
      "Num of epochs: 36\n",
      "Epoch 1, Loss: 0.5638292025650551\n",
      "Epoch 2, Loss: 0.5630082642184143\n",
      "Epoch 3, Loss: 0.5622509829019425\n",
      "Epoch 4, Loss: 0.5615479306393892\n",
      "Epoch 5, Loss: 0.5608979033199221\n",
      "Epoch 6, Loss: 0.5603001546696469\n",
      "Epoch 7, Loss: 0.5597533880201936\n",
      "Epoch 8, Loss: 0.5592565006070991\n",
      "Epoch 9, Loss: 0.5588071722184754\n",
      "Epoch 10, Loss: 0.5584104010310108\n",
      "Epoch 11, Loss: 0.5580560457068068\n",
      "Epoch 12, Loss: 0.5577477671357536\n",
      "Epoch 13, Loss: 0.5574717958440777\n",
      "Epoch 14, Loss: 0.5572214409144561\n",
      "Epoch 15, Loss: 0.5569941953770945\n",
      "Epoch 16, Loss: 0.5567905960167869\n",
      "Epoch 17, Loss: 0.5566082861357224\n",
      "Epoch 18, Loss: 0.5564418504740494\n",
      "Epoch 19, Loss: 0.5562945712373746\n",
      "Epoch 20, Loss: 0.5561358120330905\n",
      "Epoch 21, Loss: 0.5559729604149423\n",
      "Epoch 22, Loss: 0.5557920177876234\n",
      "Epoch 23, Loss: 0.5555851348976293\n",
      "Epoch 24, Loss: 0.5553451185891655\n",
      "Epoch 25, Loss: 0.5550768117332091\n",
      "Epoch 26, Loss: 0.5547802001430926\n",
      "Epoch 27, Loss: 0.5544523089756147\n",
      "Epoch 28, Loss: 0.5540861711862086\n",
      "Epoch 29, Loss: 0.5536601532752591\n",
      "Epoch 30, Loss: 0.5531263545391502\n",
      "Epoch 31, Loss: 0.5524401741088268\n",
      "Epoch 32, Loss: 0.5515538471613045\n",
      "Epoch 33, Loss: 0.5503955329150965\n",
      "Epoch 34, Loss: 0.5489496116982875\n",
      "Epoch 35, Loss: 0.5471883965729449\n",
      "Epoch 36, Loss: 0.5451389003626774\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.28940205584246576\n",
      "Test R^2 score: 0.08405374365024093\n",
      "Num of epochs: 37\n",
      "Epoch 1, Loss: 0.5802350843370528\n",
      "Epoch 2, Loss: 0.5780040511349007\n",
      "Epoch 3, Loss: 0.5758606150780299\n",
      "Epoch 4, Loss: 0.5738121461558687\n",
      "Epoch 5, Loss: 0.5718581275327015\n",
      "Epoch 6, Loss: 0.570002092516555\n",
      "Epoch 7, Loss: 0.568247282635107\n",
      "Epoch 8, Loss: 0.5665935075273458\n",
      "Epoch 9, Loss: 0.565048748293318\n",
      "Epoch 10, Loss: 0.5636145358354727\n",
      "Epoch 11, Loss: 0.5623313863019961\n",
      "Epoch 12, Loss: 0.5611592048575296\n",
      "Epoch 13, Loss: 0.5600849334988323\n",
      "Epoch 14, Loss: 0.5591264065785138\n",
      "Epoch 15, Loss: 0.5582796827796613\n",
      "Epoch 16, Loss: 0.5575586612271225\n",
      "Epoch 17, Loss: 0.5569461452535321\n",
      "Epoch 18, Loss: 0.5564498842265139\n",
      "Epoch 19, Loss: 0.5560475988442038\n",
      "Epoch 20, Loss: 0.5557283655915807\n",
      "Epoch 21, Loss: 0.5555284063010342\n",
      "Epoch 22, Loss: 0.5554462938021445\n",
      "Epoch 23, Loss: 0.5553472383331737\n",
      "Epoch 24, Loss: 0.5552065663789708\n",
      "Epoch 25, Loss: 0.5550069292168606\n",
      "Epoch 26, Loss: 0.5547157065513443\n",
      "Epoch 27, Loss: 0.5543039634633085\n",
      "Epoch 28, Loss: 0.5537421808056715\n",
      "Epoch 29, Loss: 0.5529928782368368\n",
      "Epoch 30, Loss: 0.5520025200147051\n",
      "Epoch 31, Loss: 0.5507078189463105\n",
      "Epoch 32, Loss: 0.5490441491105946\n",
      "Epoch 33, Loss: 0.5469578543977415\n",
      "Epoch 34, Loss: 0.5443772906968002\n",
      "Epoch 35, Loss: 0.5412868274467216\n",
      "Epoch 36, Loss: 0.5377115930987809\n",
      "Epoch 37, Loss: 0.5337713937246387\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.27265613429012264\n",
      "Test R^2 score: 0.19314726837438823\n",
      "Num of epochs: 38\n",
      "Epoch 1, Loss: 0.5704604701556927\n",
      "Epoch 2, Loss: 0.569231629017827\n",
      "Epoch 3, Loss: 0.5680794567322641\n",
      "Epoch 4, Loss: 0.5670011093273446\n",
      "Epoch 5, Loss: 0.5659929543450927\n",
      "Epoch 6, Loss: 0.5650675244617988\n",
      "Epoch 7, Loss: 0.5642556765823897\n",
      "Epoch 8, Loss: 0.5634946770623942\n",
      "Epoch 9, Loss: 0.562782799309339\n",
      "Epoch 10, Loss: 0.5621370893251045\n",
      "Epoch 11, Loss: 0.5615298063497516\n",
      "Epoch 12, Loss: 0.5609535044987616\n",
      "Epoch 13, Loss: 0.5604060989811074\n",
      "Epoch 14, Loss: 0.5598852792380922\n",
      "Epoch 15, Loss: 0.5593895478727703\n",
      "Epoch 16, Loss: 0.558917478641102\n",
      "Epoch 17, Loss: 0.5584841800812412\n",
      "Epoch 18, Loss: 0.5580712922880023\n",
      "Epoch 19, Loss: 0.55767536026908\n",
      "Epoch 20, Loss: 0.5572923024491816\n",
      "Epoch 21, Loss: 0.5569168743825926\n",
      "Epoch 22, Loss: 0.5565393456125074\n",
      "Epoch 23, Loss: 0.5561488070220622\n",
      "Epoch 24, Loss: 0.5557313150962003\n",
      "Epoch 25, Loss: 0.55526928546224\n",
      "Epoch 26, Loss: 0.5547423805703762\n",
      "Epoch 27, Loss: 0.5541244389165219\n",
      "Epoch 28, Loss: 0.5533807432687927\n",
      "Epoch 29, Loss: 0.5524770993885082\n",
      "Epoch 30, Loss: 0.5513630492879045\n",
      "Epoch 31, Loss: 0.5499638112040038\n",
      "Epoch 32, Loss: 0.5482158028043308\n",
      "Epoch 33, Loss: 0.5460853597845072\n",
      "Epoch 34, Loss: 0.5435728102310735\n",
      "Epoch 35, Loss: 0.5407935833344325\n",
      "Epoch 36, Loss: 0.5380337615427823\n",
      "Epoch 37, Loss: 0.5358613652460557\n",
      "Epoch 38, Loss: 0.534703250922784\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2822350920486493\n",
      "Test R^2 score: 0.1286870043479032\n",
      "Num of epochs: 39\n",
      "Epoch 1, Loss: 0.5745365534940416\n",
      "Epoch 2, Loss: 0.5726571420035499\n",
      "Epoch 3, Loss: 0.5708595421846823\n",
      "Epoch 4, Loss: 0.5692433041416244\n",
      "Epoch 5, Loss: 0.567734942264675\n",
      "Epoch 6, Loss: 0.5662836928796208\n",
      "Epoch 7, Loss: 0.5648925021541893\n",
      "Epoch 8, Loss: 0.5635671559302553\n",
      "Epoch 9, Loss: 0.5623350961352661\n",
      "Epoch 10, Loss: 0.5611932994773553\n",
      "Epoch 11, Loss: 0.560131570439961\n",
      "Epoch 12, Loss: 0.5591850885416199\n",
      "Epoch 13, Loss: 0.5583138731748818\n",
      "Epoch 14, Loss: 0.5575092431657849\n",
      "Epoch 15, Loss: 0.5567818713424769\n",
      "Epoch 16, Loss: 0.5561253086448493\n",
      "Epoch 17, Loss: 0.5555335027238417\n",
      "Epoch 18, Loss: 0.555000485514523\n",
      "Epoch 19, Loss: 0.5545331982115926\n",
      "Epoch 20, Loss: 0.554122072471563\n",
      "Epoch 21, Loss: 0.5537522450265949\n",
      "Epoch 22, Loss: 0.553356642629493\n",
      "Epoch 23, Loss: 0.5528581837807661\n",
      "Epoch 24, Loss: 0.5521771753076684\n",
      "Epoch 25, Loss: 0.5512606651329764\n",
      "Epoch 26, Loss: 0.5500456585138787\n",
      "Epoch 27, Loss: 0.5484737188655247\n",
      "Epoch 28, Loss: 0.546510438658828\n",
      "Epoch 29, Loss: 0.5441219789441732\n",
      "Epoch 30, Loss: 0.5413190355830197\n",
      "Epoch 31, Loss: 0.5381935690459102\n",
      "Epoch 32, Loss: 0.5349244499785271\n",
      "Epoch 33, Loss: 0.5317634737686772\n",
      "Epoch 34, Loss: 0.5289158875166304\n",
      "Epoch 35, Loss: 0.5262885096814719\n",
      "Epoch 36, Loss: 0.5234413716187274\n",
      "Epoch 37, Loss: 0.5201887115222408\n",
      "Epoch 38, Loss: 0.5168356410197176\n",
      "Epoch 39, Loss: 0.5139332095642888\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2570054003014634\n",
      "Test R^2 score: 0.28225364998932306\n",
      "Num of epochs: 40\n",
      "Epoch 1, Loss: 0.5584297206104122\n",
      "Epoch 2, Loss: 0.5579407082473237\n",
      "Epoch 3, Loss: 0.557518544465991\n",
      "Epoch 4, Loss: 0.557154314697095\n",
      "Epoch 5, Loss: 0.5568473298276564\n",
      "Epoch 6, Loss: 0.5565980058382795\n",
      "Epoch 7, Loss: 0.5564072504546104\n",
      "Epoch 8, Loss: 0.5562739988572005\n",
      "Epoch 9, Loss: 0.5561953185561058\n",
      "Epoch 10, Loss: 0.5561656330721294\n",
      "Epoch 11, Loss: 0.5561758409849822\n",
      "Epoch 12, Loss: 0.5562130808633244\n",
      "Epoch 13, Loss: 0.5562621051028378\n",
      "Epoch 14, Loss: 0.5563080714484178\n",
      "Epoch 15, Loss: 0.5563384189411361\n",
      "Epoch 16, Loss: 0.5563446596589559\n",
      "Epoch 17, Loss: 0.5563256426609726\n",
      "Epoch 18, Loss: 0.5562836690421198\n",
      "Epoch 19, Loss: 0.5562242523406425\n",
      "Epoch 20, Loss: 0.5561533083082615\n",
      "Epoch 21, Loss: 0.5560749324949292\n",
      "Epoch 22, Loss: 0.5559908102291486\n",
      "Epoch 23, Loss: 0.5558996522402443\n",
      "Epoch 24, Loss: 0.5557996587785193\n",
      "Epoch 25, Loss: 0.55568798261756\n",
      "Epoch 26, Loss: 0.5555593059996004\n",
      "Epoch 27, Loss: 0.555407419587998\n",
      "Epoch 28, Loss: 0.5552217301785617\n",
      "Epoch 29, Loss: 0.5549874367881454\n",
      "Epoch 30, Loss: 0.554687446271867\n",
      "Epoch 31, Loss: 0.5542995278077899\n",
      "Epoch 32, Loss: 0.5538073259048869\n",
      "Epoch 33, Loss: 0.5531929998032846\n",
      "Epoch 34, Loss: 0.5524063215195807\n",
      "Epoch 35, Loss: 0.5513459955913614\n",
      "Epoch 36, Loss: 0.5498545541051434\n",
      "Epoch 37, Loss: 0.5477880213263099\n",
      "Epoch 38, Loss: 0.5451331600636011\n",
      "Epoch 39, Loss: 0.5419566924698251\n",
      "Epoch 40, Loss: 0.5383565952404744\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.28389668452575356\n",
      "Test R^2 score: 0.11915902827526781\n",
      "Num of epochs: 41\n",
      "Epoch 1, Loss: 0.5781001523838394\n",
      "Epoch 2, Loss: 0.575367382069573\n",
      "Epoch 3, Loss: 0.5728438128764294\n",
      "Epoch 4, Loss: 0.570496934305792\n",
      "Epoch 5, Loss: 0.5683336284875337\n",
      "Epoch 6, Loss: 0.5663617346798621\n",
      "Epoch 7, Loss: 0.5645741527650847\n",
      "Epoch 8, Loss: 0.5629666564970242\n",
      "Epoch 9, Loss: 0.5615372100467926\n",
      "Epoch 10, Loss: 0.5603312965044396\n",
      "Epoch 11, Loss: 0.5593109595012945\n",
      "Epoch 12, Loss: 0.5584368452037352\n",
      "Epoch 13, Loss: 0.5577075571029366\n",
      "Epoch 14, Loss: 0.557118822787187\n",
      "Epoch 15, Loss: 0.5566721589375234\n",
      "Epoch 16, Loss: 0.556361211953417\n",
      "Epoch 17, Loss: 0.5561671066669206\n",
      "Epoch 18, Loss: 0.5560702161962101\n",
      "Epoch 19, Loss: 0.5560684207765263\n",
      "Epoch 20, Loss: 0.5561076507160061\n",
      "Epoch 21, Loss: 0.5561769930473706\n",
      "Epoch 22, Loss: 0.5562653732318522\n",
      "Epoch 23, Loss: 0.5563478737352431\n",
      "Epoch 24, Loss: 0.5563885837611653\n",
      "Epoch 25, Loss: 0.5563832005667994\n",
      "Epoch 26, Loss: 0.5563281604417024\n",
      "Epoch 27, Loss: 0.5562297978107978\n",
      "Epoch 28, Loss: 0.556092537870316\n",
      "Epoch 29, Loss: 0.5559187642243127\n",
      "Epoch 30, Loss: 0.5557063242523761\n",
      "Epoch 31, Loss: 0.55545436878071\n",
      "Epoch 32, Loss: 0.5551624950741593\n",
      "Epoch 33, Loss: 0.5548330304145082\n",
      "Epoch 34, Loss: 0.5544698046244402\n",
      "Epoch 35, Loss: 0.5540592235246699\n",
      "Epoch 36, Loss: 0.5535918953843239\n",
      "Epoch 37, Loss: 0.553052291832812\n",
      "Epoch 38, Loss: 0.5524182982902851\n",
      "Epoch 39, Loss: 0.5516472899884262\n",
      "Epoch 40, Loss: 0.550709225970808\n",
      "Epoch 41, Loss: 0.5495640446582519\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.29494512250107985\n",
      "Test R^2 score: 0.05539345631621556\n",
      "Num of epochs: 42\n",
      "Epoch 1, Loss: 0.5628587850106885\n",
      "Epoch 2, Loss: 0.561620926065143\n",
      "Epoch 3, Loss: 0.5605090457499396\n",
      "Epoch 4, Loss: 0.5595267979610683\n",
      "Epoch 5, Loss: 0.5586762267359201\n",
      "Epoch 6, Loss: 0.5579564387005598\n",
      "Epoch 7, Loss: 0.5573673791049982\n",
      "Epoch 8, Loss: 0.5569044057015924\n",
      "Epoch 9, Loss: 0.556563870676228\n",
      "Epoch 10, Loss: 0.5563344548436756\n",
      "Epoch 11, Loss: 0.5562059813666501\n",
      "Epoch 12, Loss: 0.5561621232215385\n",
      "Epoch 13, Loss: 0.5561837982044257\n",
      "Epoch 14, Loss: 0.5562508540200525\n",
      "Epoch 15, Loss: 0.5563421151687266\n",
      "Epoch 16, Loss: 0.5564368159300528\n",
      "Epoch 17, Loss: 0.5565174434957856\n",
      "Epoch 18, Loss: 0.5565721168522553\n",
      "Epoch 19, Loss: 0.5565950073824252\n",
      "Epoch 20, Loss: 0.5565843252521664\n",
      "Epoch 21, Loss: 0.5565387565693026\n",
      "Epoch 22, Loss: 0.556471467667072\n",
      "Epoch 23, Loss: 0.5563925474729767\n",
      "Epoch 24, Loss: 0.5563010803085993\n",
      "Epoch 25, Loss: 0.5562081782017181\n",
      "Epoch 26, Loss: 0.5561171630235153\n",
      "Epoch 27, Loss: 0.5560306352264534\n",
      "Epoch 28, Loss: 0.5559480340398142\n",
      "Epoch 29, Loss: 0.5558695756696039\n",
      "Epoch 30, Loss: 0.5557903555230604\n",
      "Epoch 31, Loss: 0.5557031869103933\n",
      "Epoch 32, Loss: 0.5556024071355654\n",
      "Epoch 33, Loss: 0.5554793977857007\n",
      "Epoch 34, Loss: 0.5553290190034927\n",
      "Epoch 35, Loss: 0.5551449675719368\n",
      "Epoch 36, Loss: 0.5549145354803685\n",
      "Epoch 37, Loss: 0.5546221896124653\n",
      "Epoch 38, Loss: 0.5542535561966706\n",
      "Epoch 39, Loss: 0.5537930113231941\n",
      "Epoch 40, Loss: 0.5532260500744036\n",
      "Epoch 41, Loss: 0.5525240548537381\n",
      "Epoch 42, Loss: 0.5516501262534301\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2978660017150303\n",
      "Test R^2 score: 0.029990506413105744\n",
      "Num of epochs: 43\n",
      "Epoch 1, Loss: 0.5572194352681927\n",
      "Epoch 2, Loss: 0.5569613152002232\n",
      "Epoch 3, Loss: 0.5567424747916004\n",
      "Epoch 4, Loss: 0.5565672173533073\n",
      "Epoch 5, Loss: 0.5564233456229298\n",
      "Epoch 6, Loss: 0.5563102143089311\n",
      "Epoch 7, Loss: 0.5562263955240687\n",
      "Epoch 8, Loss: 0.5561691429005705\n",
      "Epoch 9, Loss: 0.5561355172978604\n",
      "Epoch 10, Loss: 0.5561178061032216\n",
      "Epoch 11, Loss: 0.5561105714136495\n",
      "Epoch 12, Loss: 0.5561079990568977\n",
      "Epoch 13, Loss: 0.5561030418775147\n",
      "Epoch 14, Loss: 0.5560889739656517\n",
      "Epoch 15, Loss: 0.5560598991533022\n",
      "Epoch 16, Loss: 0.5560111518863244\n",
      "Epoch 17, Loss: 0.555919246706291\n",
      "Epoch 18, Loss: 0.5558124471493036\n",
      "Epoch 19, Loss: 0.5556887870879215\n",
      "Epoch 20, Loss: 0.5555351389338808\n",
      "Epoch 21, Loss: 0.5553425426868223\n",
      "Epoch 22, Loss: 0.5551036831517284\n",
      "Epoch 23, Loss: 0.5548161370924287\n",
      "Epoch 24, Loss: 0.5544721158363063\n",
      "Epoch 25, Loss: 0.5540614557659811\n",
      "Epoch 26, Loss: 0.5535843315906053\n",
      "Epoch 27, Loss: 0.5530605364805705\n",
      "Epoch 28, Loss: 0.5524768836161026\n",
      "Epoch 29, Loss: 0.5518039380263821\n",
      "Epoch 30, Loss: 0.5510200902492085\n",
      "Epoch 31, Loss: 0.5501036026218641\n",
      "Epoch 32, Loss: 0.5490315016375147\n",
      "Epoch 33, Loss: 0.5478557239721209\n",
      "Epoch 34, Loss: 0.5465459923844087\n",
      "Epoch 35, Loss: 0.5450264615013188\n",
      "Epoch 36, Loss: 0.5432645965999156\n",
      "Epoch 37, Loss: 0.541262683851938\n",
      "Epoch 38, Loss: 0.5390481532302386\n",
      "Epoch 39, Loss: 0.5365905753040601\n",
      "Epoch 40, Loss: 0.5338733359516123\n",
      "Epoch 41, Loss: 0.5308432705017464\n",
      "Epoch 42, Loss: 0.5274674164620535\n",
      "Epoch 43, Loss: 0.5236845145335622\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2672047216061869\n",
      "Test R^2 score: 0.22213012326574005\n",
      "Num of epochs: 44\n",
      "Epoch 1, Loss: 0.5630013827464467\n",
      "Epoch 2, Loss: 0.5620417582738798\n",
      "Epoch 3, Loss: 0.561152938019798\n",
      "Epoch 4, Loss: 0.5603459759151521\n",
      "Epoch 5, Loss: 0.5596137704001612\n",
      "Epoch 6, Loss: 0.5589501371101466\n",
      "Epoch 7, Loss: 0.5583561478646045\n",
      "Epoch 8, Loss: 0.5578325593905195\n",
      "Epoch 9, Loss: 0.5573829118655164\n",
      "Epoch 10, Loss: 0.5570050569130107\n",
      "Epoch 11, Loss: 0.5566978023676856\n",
      "Epoch 12, Loss: 0.5564584802132025\n",
      "Epoch 13, Loss: 0.5562829725801254\n",
      "Epoch 14, Loss: 0.5561649632550245\n",
      "Epoch 15, Loss: 0.5560963965082607\n",
      "Epoch 16, Loss: 0.5560665717561658\n",
      "Epoch 17, Loss: 0.5560640527909988\n",
      "Epoch 18, Loss: 0.556073297873198\n",
      "Epoch 19, Loss: 0.5560833199046231\n",
      "Epoch 20, Loss: 0.556075227262271\n",
      "Epoch 21, Loss: 0.555990167002554\n",
      "Epoch 22, Loss: 0.5558722563569298\n",
      "Epoch 23, Loss: 0.5557280974540209\n",
      "Epoch 24, Loss: 0.5555443391727299\n",
      "Epoch 25, Loss: 0.5553109869134025\n",
      "Epoch 26, Loss: 0.555023199232335\n",
      "Epoch 27, Loss: 0.5546999916496848\n",
      "Epoch 28, Loss: 0.554334985176985\n",
      "Epoch 29, Loss: 0.5539313790844957\n",
      "Epoch 30, Loss: 0.5534939887556902\n",
      "Epoch 31, Loss: 0.5530169947290933\n",
      "Epoch 32, Loss: 0.5524893982763366\n",
      "Epoch 33, Loss: 0.5519095153210889\n",
      "Epoch 34, Loss: 0.5512507716755213\n",
      "Epoch 35, Loss: 0.5504778303555482\n",
      "Epoch 36, Loss: 0.5495622822121091\n",
      "Epoch 37, Loss: 0.5484838797583312\n",
      "Epoch 38, Loss: 0.5472380114497355\n",
      "Epoch 39, Loss: 0.5457986593759776\n",
      "Epoch 40, Loss: 0.5441252652182306\n",
      "Epoch 41, Loss: 0.5421882893229519\n",
      "Epoch 42, Loss: 0.5399434727646293\n",
      "Epoch 43, Loss: 0.537336266885106\n",
      "Epoch 44, Loss: 0.5344052300630552\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2776609029149043\n",
      "Test R^2 score: 0.16073319864186214\n",
      "Num of epochs: 45\n",
      "Epoch 1, Loss: 0.5740441816020635\n",
      "Epoch 2, Loss: 0.5724367530318917\n",
      "Epoch 3, Loss: 0.5709706780492602\n",
      "Epoch 4, Loss: 0.5695724388686165\n",
      "Epoch 5, Loss: 0.5682855669580825\n",
      "Epoch 6, Loss: 0.5670626552837625\n",
      "Epoch 7, Loss: 0.5659053034183877\n",
      "Epoch 8, Loss: 0.5648141781992124\n",
      "Epoch 9, Loss: 0.5637894526969042\n",
      "Epoch 10, Loss: 0.5628309071277396\n",
      "Epoch 11, Loss: 0.5619381111522699\n",
      "Epoch 12, Loss: 0.5611101570163248\n",
      "Epoch 13, Loss: 0.560345789765612\n",
      "Epoch 14, Loss: 0.5596410363792217\n",
      "Epoch 15, Loss: 0.5589855927161516\n",
      "Epoch 16, Loss: 0.5583985527815004\n",
      "Epoch 17, Loss: 0.557873721997171\n",
      "Epoch 18, Loss: 0.5574086562622986\n",
      "Epoch 19, Loss: 0.5569790530794722\n",
      "Epoch 20, Loss: 0.5565851016545076\n",
      "Epoch 21, Loss: 0.5562284851199586\n",
      "Epoch 22, Loss: 0.5558934065265645\n",
      "Epoch 23, Loss: 0.5555743797080095\n",
      "Epoch 24, Loss: 0.5552604027022242\n",
      "Epoch 25, Loss: 0.5549407166100909\n",
      "Epoch 26, Loss: 0.5546050211876195\n",
      "Epoch 27, Loss: 0.5542265629009301\n",
      "Epoch 28, Loss: 0.5537881679598993\n",
      "Epoch 29, Loss: 0.553273211304711\n",
      "Epoch 30, Loss: 0.5526690495038556\n",
      "Epoch 31, Loss: 0.5519352990340801\n",
      "Epoch 32, Loss: 0.5510042429031982\n",
      "Epoch 33, Loss: 0.5498189162044411\n",
      "Epoch 34, Loss: 0.5483198697264394\n",
      "Epoch 35, Loss: 0.5464556584915081\n",
      "Epoch 36, Loss: 0.5441915889405429\n",
      "Epoch 37, Loss: 0.5414285839588021\n",
      "Epoch 38, Loss: 0.5380518464575645\n",
      "Epoch 39, Loss: 0.5340071265195154\n",
      "Epoch 40, Loss: 0.5293733323396359\n",
      "Epoch 41, Loss: 0.5244231267674945\n",
      "Epoch 42, Loss: 0.5196652920692343\n",
      "Epoch 43, Loss: 0.5163622988928221\n",
      "Epoch 44, Loss: 0.5156707165420753\n",
      "Epoch 45, Loss: 0.5160115844660778\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.25591348870964226\n",
      "Test R^2 score: 0.2871962573865998\n",
      "Num of epochs: 46\n",
      "Epoch 1, Loss: 0.5692421523463357\n",
      "Epoch 2, Loss: 0.5678594428955823\n",
      "Epoch 3, Loss: 0.5665485071893979\n",
      "Epoch 4, Loss: 0.5653580536209756\n",
      "Epoch 5, Loss: 0.5643613272074227\n",
      "Epoch 6, Loss: 0.5634161587871641\n",
      "Epoch 7, Loss: 0.5625136161851616\n",
      "Epoch 8, Loss: 0.5616605640989191\n",
      "Epoch 9, Loss: 0.5608608682296138\n",
      "Epoch 10, Loss: 0.5601165129587464\n",
      "Epoch 11, Loss: 0.5594489746621664\n",
      "Epoch 12, Loss: 0.5588481830467387\n",
      "Epoch 13, Loss: 0.5582990602630572\n",
      "Epoch 14, Loss: 0.5577969503506044\n",
      "Epoch 15, Loss: 0.5573492258122132\n",
      "Epoch 16, Loss: 0.556939028346024\n",
      "Epoch 17, Loss: 0.5565554369607335\n",
      "Epoch 18, Loss: 0.5562137506224839\n",
      "Epoch 19, Loss: 0.5559095701821547\n",
      "Epoch 20, Loss: 0.5556329540803301\n",
      "Epoch 21, Loss: 0.5553774236831823\n",
      "Epoch 22, Loss: 0.5551765596221594\n",
      "Epoch 23, Loss: 0.5549468119368767\n",
      "Epoch 24, Loss: 0.5546351394655016\n",
      "Epoch 25, Loss: 0.5542715420354298\n",
      "Epoch 26, Loss: 0.5538586078164648\n",
      "Epoch 27, Loss: 0.5533705107233435\n",
      "Epoch 28, Loss: 0.5527889912179855\n",
      "Epoch 29, Loss: 0.5520886265003125\n",
      "Epoch 30, Loss: 0.5512437704603647\n",
      "Epoch 31, Loss: 0.5502215307757683\n",
      "Epoch 32, Loss: 0.5489939917529193\n",
      "Epoch 33, Loss: 0.5475510641784191\n",
      "Epoch 34, Loss: 0.5458626232102439\n",
      "Epoch 35, Loss: 0.5438923561712807\n",
      "Epoch 36, Loss: 0.5416566927309471\n",
      "Epoch 37, Loss: 0.5390636333508948\n",
      "Epoch 38, Loss: 0.5360063914515767\n",
      "Epoch 39, Loss: 0.5323883650625427\n",
      "Epoch 40, Loss: 0.5281849968141881\n",
      "Epoch 41, Loss: 0.5233082967689836\n",
      "Epoch 42, Loss: 0.5178004812849836\n",
      "Epoch 43, Loss: 0.5121823896766425\n",
      "Epoch 44, Loss: 0.5076296844059625\n",
      "Epoch 45, Loss: 0.5057717324705754\n",
      "Epoch 46, Loss: 0.5055298781540527\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.24752812970129173\n",
      "Test R^2 score: 0.33707324776576764\n",
      "Num of epochs: 47\n",
      "Epoch 1, Loss: 0.5629885723976779\n",
      "Epoch 2, Loss: 0.5618615766031434\n",
      "Epoch 3, Loss: 0.56102833025758\n",
      "Epoch 4, Loss: 0.5602848623579414\n",
      "Epoch 5, Loss: 0.5596049566013279\n",
      "Epoch 6, Loss: 0.5590101703953773\n",
      "Epoch 7, Loss: 0.5584752684097468\n",
      "Epoch 8, Loss: 0.5580866719549001\n",
      "Epoch 9, Loss: 0.5577410344951115\n",
      "Epoch 10, Loss: 0.5574155533130712\n",
      "Epoch 11, Loss: 0.5571262048627403\n",
      "Epoch 12, Loss: 0.5568694597989778\n",
      "Epoch 13, Loss: 0.5566431948953835\n",
      "Epoch 14, Loss: 0.556451972983156\n",
      "Epoch 15, Loss: 0.5562884906781664\n",
      "Epoch 16, Loss: 0.5561500931075509\n",
      "Epoch 17, Loss: 0.5560357806438644\n",
      "Epoch 18, Loss: 0.5559402878741244\n",
      "Epoch 19, Loss: 0.5558576732617492\n",
      "Epoch 20, Loss: 0.555789175848419\n",
      "Epoch 21, Loss: 0.5557361147111637\n",
      "Epoch 22, Loss: 0.5556844697500021\n",
      "Epoch 23, Loss: 0.5556494471231863\n",
      "Epoch 24, Loss: 0.5556088706766029\n",
      "Epoch 25, Loss: 0.5554873649815212\n",
      "Epoch 26, Loss: 0.5553021048204543\n",
      "Epoch 27, Loss: 0.555085992723795\n",
      "Epoch 28, Loss: 0.5548483655603843\n",
      "Epoch 29, Loss: 0.554572912926034\n",
      "Epoch 30, Loss: 0.5542465929125387\n",
      "Epoch 31, Loss: 0.5538628317706537\n",
      "Epoch 32, Loss: 0.5534210791970777\n",
      "Epoch 33, Loss: 0.5529437258389193\n",
      "Epoch 34, Loss: 0.5524004679133031\n",
      "Epoch 35, Loss: 0.5517656984018872\n",
      "Epoch 36, Loss: 0.551018684018502\n",
      "Epoch 37, Loss: 0.5501334797839043\n",
      "Epoch 38, Loss: 0.5491128094920185\n",
      "Epoch 39, Loss: 0.5479598048915582\n",
      "Epoch 40, Loss: 0.5466439712812349\n",
      "Epoch 41, Loss: 0.545150599451758\n",
      "Epoch 42, Loss: 0.5433844477602421\n",
      "Epoch 43, Loss: 0.5412907090416329\n",
      "Epoch 44, Loss: 0.5387164401070085\n",
      "Epoch 45, Loss: 0.5355636271298946\n",
      "Epoch 46, Loss: 0.5317728891311148\n",
      "Epoch 47, Loss: 0.5272536871967923\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.267439351865595\n",
      "Test R^2 score: 0.22204741580577708\n",
      "Num of epochs: 48\n",
      "Epoch 1, Loss: 0.5627489598661595\n",
      "Epoch 2, Loss: 0.561787020973908\n",
      "Epoch 3, Loss: 0.5609244693103274\n",
      "Epoch 4, Loss: 0.5601502454108658\n",
      "Epoch 5, Loss: 0.5594468438241101\n",
      "Epoch 6, Loss: 0.5588125587278181\n",
      "Epoch 7, Loss: 0.558247305401023\n",
      "Epoch 8, Loss: 0.5577590681712749\n",
      "Epoch 9, Loss: 0.5573354032472718\n",
      "Epoch 10, Loss: 0.5569767522703081\n",
      "Epoch 11, Loss: 0.5566820095806959\n",
      "Epoch 12, Loss: 0.556451303510727\n",
      "Epoch 13, Loss: 0.5562868566839655\n",
      "Epoch 14, Loss: 0.5561755194787734\n",
      "Epoch 15, Loss: 0.5561100623023202\n",
      "Epoch 16, Loss: 0.5560874197745106\n",
      "Epoch 17, Loss: 0.5561047835942252\n",
      "Epoch 18, Loss: 0.5561436626503664\n",
      "Epoch 19, Loss: 0.556180020548783\n",
      "Epoch 20, Loss: 0.5562027128886617\n",
      "Epoch 21, Loss: 0.5562035969870618\n",
      "Epoch 22, Loss: 0.5561772073842958\n",
      "Epoch 23, Loss: 0.5561195477736919\n",
      "Epoch 24, Loss: 0.5560242301872128\n",
      "Epoch 25, Loss: 0.5558845069334776\n",
      "Epoch 26, Loss: 0.5556898597132585\n",
      "Epoch 27, Loss: 0.5554359651700805\n",
      "Epoch 28, Loss: 0.5551133200368658\n",
      "Epoch 29, Loss: 0.554705525494899\n",
      "Epoch 30, Loss: 0.5541890282051111\n",
      "Epoch 31, Loss: 0.5535428500159836\n",
      "Epoch 32, Loss: 0.552686763370812\n",
      "Epoch 33, Loss: 0.5515785668818364\n",
      "Epoch 34, Loss: 0.5501708848951976\n",
      "Epoch 35, Loss: 0.5484078858468696\n",
      "Epoch 36, Loss: 0.5462082749586749\n",
      "Epoch 37, Loss: 0.54346928749762\n",
      "Epoch 38, Loss: 0.5401890634330733\n",
      "Epoch 39, Loss: 0.5364600122913148\n",
      "Epoch 40, Loss: 0.5326492450999887\n",
      "Epoch 41, Loss: 0.5296578671878976\n",
      "Epoch 42, Loss: 0.5284212759855962\n",
      "Epoch 43, Loss: 0.527852667617742\n",
      "Epoch 44, Loss: 0.5256193152538702\n",
      "Epoch 45, Loss: 0.5222865303780105\n",
      "Epoch 46, Loss: 0.5194917821592148\n",
      "Epoch 47, Loss: 0.5177516142664803\n",
      "Epoch 48, Loss: 0.5164609259719475\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2621943275498127\n",
      "Test R^2 score: 0.2506487875001098\n",
      "Num of epochs: 49\n",
      "Epoch 1, Loss: 0.6366544819792647\n",
      "Epoch 2, Loss: 0.6320663102920703\n",
      "Epoch 3, Loss: 0.6275398147535758\n",
      "Epoch 4, Loss: 0.6230822466433119\n",
      "Epoch 5, Loss: 0.6186972152466637\n",
      "Epoch 6, Loss: 0.6143670401925847\n",
      "Epoch 7, Loss: 0.6101095711684331\n",
      "Epoch 8, Loss: 0.6059965970680324\n",
      "Epoch 9, Loss: 0.6019701134068649\n",
      "Epoch 10, Loss: 0.5980300731528752\n",
      "Epoch 11, Loss: 0.594244851144223\n",
      "Epoch 12, Loss: 0.5905471043965409\n",
      "Epoch 13, Loss: 0.5868731340047566\n",
      "Epoch 14, Loss: 0.5832940042952416\n",
      "Epoch 15, Loss: 0.5798416940276924\n",
      "Epoch 16, Loss: 0.5765230304885359\n",
      "Epoch 17, Loss: 0.5732895995618796\n",
      "Epoch 18, Loss: 0.5702711900355436\n",
      "Epoch 19, Loss: 0.567497570099859\n",
      "Epoch 20, Loss: 0.5649496620254187\n",
      "Epoch 21, Loss: 0.562724333640037\n",
      "Epoch 22, Loss: 0.560704996489375\n",
      "Epoch 23, Loss: 0.5587798922178627\n",
      "Epoch 24, Loss: 0.556857043575115\n",
      "Epoch 25, Loss: 0.5551481080686181\n",
      "Epoch 26, Loss: 0.5536130788402016\n",
      "Epoch 27, Loss: 0.5518482235453324\n",
      "Epoch 28, Loss: 0.5497590989612783\n",
      "Epoch 29, Loss: 0.5473230433923622\n",
      "Epoch 30, Loss: 0.5446277220988281\n",
      "Epoch 31, Loss: 0.541687310876898\n",
      "Epoch 32, Loss: 0.5385026374068709\n",
      "Epoch 33, Loss: 0.5351946740382957\n",
      "Epoch 34, Loss: 0.5318403049812206\n",
      "Epoch 35, Loss: 0.5285411380268481\n",
      "Epoch 36, Loss: 0.525058513741107\n",
      "Epoch 37, Loss: 0.5214575428435364\n",
      "Epoch 38, Loss: 0.5177629536675707\n",
      "Epoch 39, Loss: 0.5144213296598685\n",
      "Epoch 40, Loss: 0.5116225290469465\n",
      "Epoch 41, Loss: 0.509228127022457\n",
      "Epoch 42, Loss: 0.5069398571341026\n",
      "Epoch 43, Loss: 0.5046101171260987\n",
      "Epoch 44, Loss: 0.5022778481167887\n",
      "Epoch 45, Loss: 0.5001459206798877\n",
      "Epoch 46, Loss: 0.4983636185470919\n",
      "Epoch 47, Loss: 0.49669627148073814\n",
      "Epoch 48, Loss: 0.49480437379548375\n",
      "Epoch 49, Loss: 0.492792302880694\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.23955087340772052\n",
      "Test R^2 score: 0.37804733635588106\n",
      "Num of epochs: 50\n",
      "Epoch 1, Loss: 0.5771430155697892\n",
      "Epoch 2, Loss: 0.5751779809487627\n",
      "Epoch 3, Loss: 0.5733179825383709\n",
      "Epoch 4, Loss: 0.5715642804117562\n",
      "Epoch 5, Loss: 0.5699137770121246\n",
      "Epoch 6, Loss: 0.5683703077385608\n",
      "Epoch 7, Loss: 0.5669267827601082\n",
      "Epoch 8, Loss: 0.5655861277421533\n",
      "Epoch 9, Loss: 0.5643623305426881\n",
      "Epoch 10, Loss: 0.5632323954184947\n",
      "Epoch 11, Loss: 0.5622423694630496\n",
      "Epoch 12, Loss: 0.5613609277833973\n",
      "Epoch 13, Loss: 0.5605422229108595\n",
      "Epoch 14, Loss: 0.5597977101300621\n",
      "Epoch 15, Loss: 0.5591382394046589\n",
      "Epoch 16, Loss: 0.5585326047923701\n",
      "Epoch 17, Loss: 0.5579834652009572\n",
      "Epoch 18, Loss: 0.5575182504617503\n",
      "Epoch 19, Loss: 0.5570972376790377\n",
      "Epoch 20, Loss: 0.5567012820740771\n",
      "Epoch 21, Loss: 0.5563249730365198\n",
      "Epoch 22, Loss: 0.5559615694681964\n",
      "Epoch 23, Loss: 0.5556053573088521\n",
      "Epoch 24, Loss: 0.5552342634843699\n",
      "Epoch 25, Loss: 0.5548409800351568\n",
      "Epoch 26, Loss: 0.5544682996440925\n",
      "Epoch 27, Loss: 0.5540592504191969\n",
      "Epoch 28, Loss: 0.5536095528065736\n",
      "Epoch 29, Loss: 0.5530782108668383\n",
      "Epoch 30, Loss: 0.5524353728319774\n",
      "Epoch 31, Loss: 0.5516567981717031\n",
      "Epoch 32, Loss: 0.5506857390141259\n",
      "Epoch 33, Loss: 0.5493941459747985\n",
      "Epoch 34, Loss: 0.5478697313094112\n",
      "Epoch 35, Loss: 0.5460478931214151\n",
      "Epoch 36, Loss: 0.5438272289810724\n",
      "Epoch 37, Loss: 0.5412159352672358\n",
      "Epoch 38, Loss: 0.5382926253181238\n",
      "Epoch 39, Loss: 0.5350674465036797\n",
      "Epoch 40, Loss: 0.531542865585662\n",
      "Epoch 41, Loss: 0.5278228279038361\n",
      "Epoch 42, Loss: 0.5242055695151643\n",
      "Epoch 43, Loss: 0.5211795101484262\n",
      "Epoch 44, Loss: 0.518804256635202\n",
      "Epoch 45, Loss: 0.5165368888769206\n",
      "Epoch 46, Loss: 0.5134870247339105\n",
      "Epoch 47, Loss: 0.509576725946833\n",
      "Epoch 48, Loss: 0.5056629167634398\n",
      "Epoch 49, Loss: 0.5024592300975598\n",
      "Epoch 50, Loss: 0.4999094970572871\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.24532368331534932\n",
      "Test R^2 score: 0.347391311214101\n",
      "Num of epochs: 51\n",
      "Epoch 1, Loss: 0.5645708799455008\n",
      "Epoch 2, Loss: 0.5629386516045529\n",
      "Epoch 3, Loss: 0.5615042509035262\n",
      "Epoch 4, Loss: 0.5602640907408509\n",
      "Epoch 5, Loss: 0.5593035529769455\n",
      "Epoch 6, Loss: 0.5585359930309712\n",
      "Epoch 7, Loss: 0.5578909500905324\n",
      "Epoch 8, Loss: 0.5573611765736656\n",
      "Epoch 9, Loss: 0.5569368076382232\n",
      "Epoch 10, Loss: 0.5566190213478369\n",
      "Epoch 11, Loss: 0.556392360000757\n",
      "Epoch 12, Loss: 0.556245549859237\n",
      "Epoch 13, Loss: 0.5561605692348129\n",
      "Epoch 14, Loss: 0.5561327842910136\n",
      "Epoch 15, Loss: 0.5561473333787834\n",
      "Epoch 16, Loss: 0.5561882188327035\n",
      "Epoch 17, Loss: 0.5562381828853071\n",
      "Epoch 18, Loss: 0.556281472505176\n",
      "Epoch 19, Loss: 0.5563049910719687\n",
      "Epoch 20, Loss: 0.5562973838083595\n",
      "Epoch 21, Loss: 0.5562522202351011\n",
      "Epoch 22, Loss: 0.5561684730876927\n",
      "Epoch 23, Loss: 0.5560301528411299\n",
      "Epoch 24, Loss: 0.5558194980538964\n",
      "Epoch 25, Loss: 0.5555099783189197\n",
      "Epoch 26, Loss: 0.5550987438477006\n",
      "Epoch 27, Loss: 0.5546586203780512\n",
      "Epoch 28, Loss: 0.5542063977284888\n",
      "Epoch 29, Loss: 0.5536548781231818\n",
      "Epoch 30, Loss: 0.5529782731011471\n",
      "Epoch 31, Loss: 0.5521412555131681\n",
      "Epoch 32, Loss: 0.551118436368055\n",
      "Epoch 33, Loss: 0.5498711120700422\n",
      "Epoch 34, Loss: 0.5483463657225672\n",
      "Epoch 35, Loss: 0.5464790818433206\n",
      "Epoch 36, Loss: 0.5442103728033771\n",
      "Epoch 37, Loss: 0.5414844781195516\n",
      "Epoch 38, Loss: 0.5382609281870124\n",
      "Epoch 39, Loss: 0.5345541915720654\n",
      "Epoch 40, Loss: 0.5304837591326059\n",
      "Epoch 41, Loss: 0.5263396983143317\n",
      "Epoch 42, Loss: 0.5228986101211924\n",
      "Epoch 43, Loss: 0.5209916891324765\n",
      "Epoch 44, Loss: 0.5196931629709626\n",
      "Epoch 45, Loss: 0.5168713908778693\n",
      "Epoch 46, Loss: 0.513028659534949\n",
      "Epoch 47, Loss: 0.5096801452293183\n",
      "Epoch 48, Loss: 0.507385749500023\n",
      "Epoch 49, Loss: 0.5055351249120444\n",
      "Epoch 50, Loss: 0.5032689403981496\n",
      "Epoch 51, Loss: 0.5003859401367434\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.24377074079998043\n",
      "Test R^2 score: 0.3586790290017078\n",
      "Num of epochs: 52\n",
      "Epoch 1, Loss: 0.5702925900681075\n",
      "Epoch 2, Loss: 0.5690074516120202\n",
      "Epoch 3, Loss: 0.5677792186987315\n",
      "Epoch 4, Loss: 0.5666066834548078\n",
      "Epoch 5, Loss: 0.565483630939283\n",
      "Epoch 6, Loss: 0.5644306851582718\n",
      "Epoch 7, Loss: 0.5634328207032203\n",
      "Epoch 8, Loss: 0.56251011945311\n",
      "Epoch 9, Loss: 0.5616496599388401\n",
      "Epoch 10, Loss: 0.5608420309362552\n",
      "Epoch 11, Loss: 0.5601005239180825\n",
      "Epoch 12, Loss: 0.55940997904093\n",
      "Epoch 13, Loss: 0.5587738653714458\n",
      "Epoch 14, Loss: 0.5581902333633563\n",
      "Epoch 15, Loss: 0.5577433588683283\n",
      "Epoch 16, Loss: 0.5573713625908767\n",
      "Epoch 17, Loss: 0.5570368912292144\n",
      "Epoch 18, Loss: 0.5567446695097418\n",
      "Epoch 19, Loss: 0.5565178986830212\n",
      "Epoch 20, Loss: 0.5563255623060808\n",
      "Epoch 21, Loss: 0.5561643470225756\n",
      "Epoch 22, Loss: 0.556080693828291\n",
      "Epoch 23, Loss: 0.5559869508584183\n",
      "Epoch 24, Loss: 0.5558776176927993\n",
      "Epoch 25, Loss: 0.5557413164816908\n",
      "Epoch 26, Loss: 0.5556123572027898\n",
      "Epoch 27, Loss: 0.555522719710923\n",
      "Epoch 28, Loss: 0.5554052464149803\n",
      "Epoch 29, Loss: 0.55523796706234\n",
      "Epoch 30, Loss: 0.5550159771226175\n",
      "Epoch 31, Loss: 0.5547355040074115\n",
      "Epoch 32, Loss: 0.5543879116322339\n",
      "Epoch 33, Loss: 0.5539608615053849\n",
      "Epoch 34, Loss: 0.5534495118365357\n",
      "Epoch 35, Loss: 0.5528590193217086\n",
      "Epoch 36, Loss: 0.5521670014182444\n",
      "Epoch 37, Loss: 0.551347779362452\n",
      "Epoch 38, Loss: 0.5503695146182049\n",
      "Epoch 39, Loss: 0.5492276132663398\n",
      "Epoch 40, Loss: 0.5478701392847416\n",
      "Epoch 41, Loss: 0.5462150406289481\n",
      "Epoch 42, Loss: 0.5441558813844055\n",
      "Epoch 43, Loss: 0.5415898659863827\n",
      "Epoch 44, Loss: 0.5384994828497087\n",
      "Epoch 45, Loss: 0.5349011335200097\n",
      "Epoch 46, Loss: 0.5307009889449327\n",
      "Epoch 47, Loss: 0.5258126814857894\n",
      "Epoch 48, Loss: 0.520276302647959\n",
      "Epoch 49, Loss: 0.5143976052694954\n",
      "Epoch 50, Loss: 0.5086490782660853\n",
      "Epoch 51, Loss: 0.5035034758268845\n",
      "Epoch 52, Loss: 0.4992632205838263\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.24774243162353535\n",
      "Test R^2 score: 0.3333546977324073\n",
      "Num of epochs: 53\n",
      "Epoch 1, Loss: 0.5809020282654134\n",
      "Epoch 2, Loss: 0.5791074035247031\n",
      "Epoch 3, Loss: 0.5773457094812242\n",
      "Epoch 4, Loss: 0.5756774073714066\n",
      "Epoch 5, Loss: 0.574095810166223\n",
      "Epoch 6, Loss: 0.572558773846885\n",
      "Epoch 7, Loss: 0.5710780609939916\n",
      "Epoch 8, Loss: 0.5697870577452027\n",
      "Epoch 9, Loss: 0.5686443964412509\n",
      "Epoch 10, Loss: 0.5675438342201345\n",
      "Epoch 11, Loss: 0.5664785667819271\n",
      "Epoch 12, Loss: 0.5654676618984575\n",
      "Epoch 13, Loss: 0.5644983979650966\n",
      "Epoch 14, Loss: 0.5635644589631545\n",
      "Epoch 15, Loss: 0.5627114110601442\n",
      "Epoch 16, Loss: 0.561962957446003\n",
      "Epoch 17, Loss: 0.5612447826763206\n",
      "Epoch 18, Loss: 0.560557189208516\n",
      "Epoch 19, Loss: 0.559896829885143\n",
      "Epoch 20, Loss: 0.5592664389515509\n",
      "Epoch 21, Loss: 0.5586653443452091\n",
      "Epoch 22, Loss: 0.5580998885175289\n",
      "Epoch 23, Loss: 0.5575709816516654\n",
      "Epoch 24, Loss: 0.5570594684146414\n",
      "Epoch 25, Loss: 0.5565597475423977\n",
      "Epoch 26, Loss: 0.5560670541098961\n",
      "Epoch 27, Loss: 0.555576015797663\n",
      "Epoch 28, Loss: 0.5550754426251108\n",
      "Epoch 29, Loss: 0.5545766746595107\n",
      "Epoch 30, Loss: 0.5541070937161968\n",
      "Epoch 31, Loss: 0.5536393753445469\n",
      "Epoch 32, Loss: 0.5530615333740947\n",
      "Epoch 33, Loss: 0.5522351386132943\n",
      "Epoch 34, Loss: 0.5510507019206025\n",
      "Epoch 35, Loss: 0.5494964440207275\n",
      "Epoch 36, Loss: 0.5475765632849863\n",
      "Epoch 37, Loss: 0.545485365829536\n",
      "Epoch 38, Loss: 0.5433427359736684\n",
      "Epoch 39, Loss: 0.541375106202007\n",
      "Epoch 40, Loss: 0.5396637811181104\n",
      "Epoch 41, Loss: 0.5377790957355681\n",
      "Epoch 42, Loss: 0.5352642757787285\n",
      "Epoch 43, Loss: 0.5323305920765394\n",
      "Epoch 44, Loss: 0.5295985583236036\n",
      "Epoch 45, Loss: 0.5273958816191759\n",
      "Epoch 46, Loss: 0.525423694122938\n",
      "Epoch 47, Loss: 0.5233714503278819\n",
      "Epoch 48, Loss: 0.5211523191831374\n",
      "Epoch 49, Loss: 0.5188811400695119\n",
      "Epoch 50, Loss: 0.5167638743641426\n",
      "Epoch 51, Loss: 0.5148436377008573\n",
      "Epoch 52, Loss: 0.5128710055175947\n",
      "Epoch 53, Loss: 0.5107535074704544\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2581011274503299\n",
      "Test R^2 score: 0.27648488133934757\n",
      "Num of epochs: 54\n",
      "Epoch 1, Loss: 0.5683714088660394\n",
      "Epoch 2, Loss: 0.5669118269089898\n",
      "Epoch 3, Loss: 0.5655718478103637\n",
      "Epoch 4, Loss: 0.5643390157386835\n",
      "Epoch 5, Loss: 0.563204430197501\n",
      "Epoch 6, Loss: 0.562166061883204\n",
      "Epoch 7, Loss: 0.5612216038731456\n",
      "Epoch 8, Loss: 0.5603568788517574\n",
      "Epoch 9, Loss: 0.5595705521667926\n",
      "Epoch 10, Loss: 0.5588672475240862\n",
      "Epoch 11, Loss: 0.5582427409204483\n",
      "Epoch 12, Loss: 0.5576964153383897\n",
      "Epoch 13, Loss: 0.5572306400528277\n",
      "Epoch 14, Loss: 0.5568475706664188\n",
      "Epoch 15, Loss: 0.556548663122093\n",
      "Epoch 16, Loss: 0.5563338120143988\n",
      "Epoch 17, Loss: 0.5561988817793556\n",
      "Epoch 18, Loss: 0.5561364818853054\n",
      "Epoch 19, Loss: 0.5561346330912326\n",
      "Epoch 20, Loss: 0.5561739119449421\n",
      "Epoch 21, Loss: 0.5562368970034923\n",
      "Epoch 22, Loss: 0.556273463107969\n",
      "Epoch 23, Loss: 0.5563030089076695\n",
      "Epoch 24, Loss: 0.5563054196471049\n",
      "Epoch 25, Loss: 0.5562610603690208\n",
      "Epoch 26, Loss: 0.5561538441732394\n",
      "Epoch 27, Loss: 0.5559713790974622\n",
      "Epoch 28, Loss: 0.5556967512816631\n",
      "Epoch 29, Loss: 0.5553189296919058\n",
      "Epoch 30, Loss: 0.5548254298260947\n",
      "Epoch 31, Loss: 0.5542200025786835\n",
      "Epoch 32, Loss: 0.5535258903978327\n",
      "Epoch 33, Loss: 0.5527190890405784\n",
      "Epoch 34, Loss: 0.5517598650058616\n",
      "Epoch 35, Loss: 0.5505504259753101\n",
      "Epoch 36, Loss: 0.5489908974801424\n",
      "Epoch 37, Loss: 0.5469920441852674\n",
      "Epoch 38, Loss: 0.5445218822926795\n",
      "Epoch 39, Loss: 0.5415678270345419\n",
      "Epoch 40, Loss: 0.5380743894359016\n",
      "Epoch 41, Loss: 0.5338927061234684\n",
      "Epoch 42, Loss: 0.5290183428899502\n",
      "Epoch 43, Loss: 0.5237224145056933\n",
      "Epoch 44, Loss: 0.5189758142502873\n",
      "Epoch 45, Loss: 0.5166928764073692\n",
      "Epoch 46, Loss: 0.5168075871817084\n",
      "Epoch 47, Loss: 0.5146778829355888\n",
      "Epoch 48, Loss: 0.5102480071242429\n",
      "Epoch 49, Loss: 0.5062211263923341\n",
      "Epoch 50, Loss: 0.5039385703907097\n",
      "Epoch 51, Loss: 0.5027456298611632\n",
      "Epoch 52, Loss: 0.5015168130572174\n",
      "Epoch 53, Loss: 0.49960117527225634\n",
      "Epoch 54, Loss: 0.4969629947550028\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.24324911285160028\n",
      "Test R^2 score: 0.3568222059490627\n",
      "Num of epochs: 55\n",
      "Epoch 1, Loss: 0.5952738982173243\n",
      "Epoch 2, Loss: 0.5926158513310628\n",
      "Epoch 3, Loss: 0.5900199828966486\n",
      "Epoch 4, Loss: 0.5874829320254494\n",
      "Epoch 5, Loss: 0.5850192949992924\n",
      "Epoch 6, Loss: 0.5827147547595694\n",
      "Epoch 7, Loss: 0.5804826244477664\n",
      "Epoch 8, Loss: 0.5783021500816792\n",
      "Epoch 9, Loss: 0.5761949437582609\n",
      "Epoch 10, Loss: 0.5741673660643165\n",
      "Epoch 11, Loss: 0.5721627360995182\n",
      "Epoch 12, Loss: 0.5703484772086078\n",
      "Epoch 13, Loss: 0.5686876587708727\n",
      "Epoch 14, Loss: 0.5673590965370117\n",
      "Epoch 15, Loss: 0.5660935953062658\n",
      "Epoch 16, Loss: 0.5648760679504604\n",
      "Epoch 17, Loss: 0.5637386776787344\n",
      "Epoch 18, Loss: 0.5626809306029753\n",
      "Epoch 19, Loss: 0.5616879164253916\n",
      "Epoch 20, Loss: 0.5607630880905853\n",
      "Epoch 21, Loss: 0.5599108021235939\n",
      "Epoch 22, Loss: 0.5591353611726982\n",
      "Epoch 23, Loss: 0.5584408477443772\n",
      "Epoch 24, Loss: 0.557827377120946\n",
      "Epoch 25, Loss: 0.557292061802614\n",
      "Epoch 26, Loss: 0.5568343511402944\n",
      "Epoch 27, Loss: 0.556451357068551\n",
      "Epoch 28, Loss: 0.5561389737284618\n",
      "Epoch 29, Loss: 0.5558907527471489\n",
      "Epoch 30, Loss: 0.555698789238825\n",
      "Epoch 31, Loss: 0.5555519567479025\n",
      "Epoch 32, Loss: 0.5554432086464498\n",
      "Epoch 33, Loss: 0.5553598761326995\n",
      "Epoch 34, Loss: 0.5552714323315558\n",
      "Epoch 35, Loss: 0.555194112966572\n",
      "Epoch 36, Loss: 0.5550571875277709\n",
      "Epoch 37, Loss: 0.5548402011922208\n",
      "Epoch 38, Loss: 0.5545272595693829\n",
      "Epoch 39, Loss: 0.5541108586120149\n",
      "Epoch 40, Loss: 0.5535749372687531\n",
      "Epoch 41, Loss: 0.5528819827269068\n",
      "Epoch 42, Loss: 0.5519852431145752\n",
      "Epoch 43, Loss: 0.5509049297015948\n",
      "Epoch 44, Loss: 0.5496227173314291\n",
      "Epoch 45, Loss: 0.548102662991724\n",
      "Epoch 46, Loss: 0.5463006136685311\n",
      "Epoch 47, Loss: 0.5441609200159072\n",
      "Epoch 48, Loss: 0.5416379303523334\n",
      "Epoch 49, Loss: 0.5387058183737866\n",
      "Epoch 50, Loss: 0.5353642915522717\n",
      "Epoch 51, Loss: 0.5316413952263404\n",
      "Epoch 52, Loss: 0.5275134343429777\n",
      "Epoch 53, Loss: 0.522976515740509\n",
      "Epoch 54, Loss: 0.5181742851551651\n",
      "Epoch 55, Loss: 0.513451271406452\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2528360041758681\n",
      "Test R^2 score: 0.3064139523305293\n",
      "Num of epochs: 56\n",
      "Epoch 1, Loss: 0.559409606118862\n",
      "Epoch 2, Loss: 0.5587114063477804\n",
      "Epoch 3, Loss: 0.5581032526834968\n",
      "Epoch 4, Loss: 0.5575825267915713\n",
      "Epoch 5, Loss: 0.5571471737032434\n",
      "Epoch 6, Loss: 0.5567978486327834\n",
      "Epoch 7, Loss: 0.556539827556484\n",
      "Epoch 8, Loss: 0.5563444721705992\n",
      "Epoch 9, Loss: 0.5562108572571313\n",
      "Epoch 10, Loss: 0.5561315785484292\n",
      "Epoch 11, Loss: 0.55609224311215\n",
      "Epoch 12, Loss: 0.5560875537566766\n",
      "Epoch 13, Loss: 0.556099665611124\n",
      "Epoch 14, Loss: 0.5561138672283487\n",
      "Epoch 15, Loss: 0.5561097675534428\n",
      "Epoch 16, Loss: 0.5560786572707606\n",
      "Epoch 17, Loss: 0.556030528029751\n",
      "Epoch 18, Loss: 0.5559498030452138\n",
      "Epoch 19, Loss: 0.5558174605393248\n",
      "Epoch 20, Loss: 0.5556376472724396\n",
      "Epoch 21, Loss: 0.5554215852481961\n",
      "Epoch 22, Loss: 0.5551720235759485\n",
      "Epoch 23, Loss: 0.5548620889480286\n",
      "Epoch 24, Loss: 0.5544778132011563\n",
      "Epoch 25, Loss: 0.5540081753592343\n",
      "Epoch 26, Loss: 0.5534319570081789\n",
      "Epoch 27, Loss: 0.5527291988494386\n",
      "Epoch 28, Loss: 0.551867907857632\n",
      "Epoch 29, Loss: 0.5508020816407659\n",
      "Epoch 30, Loss: 0.5494606744146437\n",
      "Epoch 31, Loss: 0.5477934073794851\n",
      "Epoch 32, Loss: 0.545724585185583\n",
      "Epoch 33, Loss: 0.543220489105915\n",
      "Epoch 34, Loss: 0.5402617452422412\n",
      "Epoch 35, Loss: 0.5367948131163583\n",
      "Epoch 36, Loss: 0.5329350506750965\n",
      "Epoch 37, Loss: 0.5289443696793065\n",
      "Epoch 38, Loss: 0.5255215563231965\n",
      "Epoch 39, Loss: 0.523617841484511\n",
      "Epoch 40, Loss: 0.5233624817339875\n",
      "Epoch 41, Loss: 0.5223526031264231\n",
      "Epoch 42, Loss: 0.519393529779472\n",
      "Epoch 43, Loss: 0.5157113436451581\n",
      "Epoch 44, Loss: 0.5126050015790073\n",
      "Epoch 45, Loss: 0.5105401071509958\n",
      "Epoch 46, Loss: 0.5091288597921556\n",
      "Epoch 47, Loss: 0.5076877147237833\n",
      "Epoch 48, Loss: 0.5058083526920203\n",
      "Epoch 49, Loss: 0.5033703697338339\n",
      "Epoch 50, Loss: 0.500552855256903\n",
      "Epoch 51, Loss: 0.49777859212527525\n",
      "Epoch 52, Loss: 0.4954184193282036\n",
      "Epoch 53, Loss: 0.49365782239460315\n",
      "Epoch 54, Loss: 0.49213406106185714\n",
      "Epoch 55, Loss: 0.49017111685487125\n",
      "Epoch 56, Loss: 0.4877069529166628\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2367198392854758\n",
      "Test R^2 score: 0.3917816857335793\n",
      "Num of epochs: 57\n",
      "Epoch 1, Loss: 0.5760320461451669\n",
      "Epoch 2, Loss: 0.573856836565387\n",
      "Epoch 3, Loss: 0.571796498356505\n",
      "Epoch 4, Loss: 0.5698609851001601\n",
      "Epoch 5, Loss: 0.5680559797085912\n",
      "Epoch 6, Loss: 0.5663845452721081\n",
      "Epoch 7, Loss: 0.564848579818738\n",
      "Epoch 8, Loss: 0.5634482920412343\n",
      "Epoch 9, Loss: 0.5621820451896966\n",
      "Epoch 10, Loss: 0.5610631764771067\n",
      "Epoch 11, Loss: 0.5600921700613933\n",
      "Epoch 12, Loss: 0.5592423787951274\n",
      "Epoch 13, Loss: 0.5585037639135916\n",
      "Epoch 14, Loss: 0.5578697688092298\n",
      "Epoch 15, Loss: 0.5573392800167105\n",
      "Epoch 16, Loss: 0.55690745600557\n",
      "Epoch 17, Loss: 0.556573000363869\n",
      "Epoch 18, Loss: 0.5563273836807778\n",
      "Epoch 19, Loss: 0.556157220110728\n",
      "Epoch 20, Loss: 0.5560670809073133\n",
      "Epoch 21, Loss: 0.5560741553802792\n",
      "Epoch 22, Loss: 0.5560704037770366\n",
      "Epoch 23, Loss: 0.5560808814055831\n",
      "Epoch 24, Loss: 0.5560964233042639\n",
      "Epoch 25, Loss: 0.5560830519382186\n",
      "Epoch 26, Loss: 0.555976310648982\n",
      "Epoch 27, Loss: 0.5557745369502288\n",
      "Epoch 28, Loss: 0.5555795829928262\n",
      "Epoch 29, Loss: 0.5553404497573707\n",
      "Epoch 30, Loss: 0.554997746918375\n",
      "Epoch 31, Loss: 0.5545344074295886\n",
      "Epoch 32, Loss: 0.553928150986899\n",
      "Epoch 33, Loss: 0.5531496031725868\n",
      "Epoch 34, Loss: 0.5521792802269041\n",
      "Epoch 35, Loss: 0.5509865831223184\n",
      "Epoch 36, Loss: 0.5495620381806593\n",
      "Epoch 37, Loss: 0.5478718255795513\n",
      "Epoch 38, Loss: 0.5458421490469364\n",
      "Epoch 39, Loss: 0.5433646480872116\n",
      "Epoch 40, Loss: 0.540450561914391\n",
      "Epoch 41, Loss: 0.5370315772847213\n",
      "Epoch 42, Loss: 0.5330050872699517\n",
      "Epoch 43, Loss: 0.5283133740771573\n",
      "Epoch 44, Loss: 0.5231488698893731\n",
      "Epoch 45, Loss: 0.518009567378588\n",
      "Epoch 46, Loss: 0.5140268238059577\n",
      "Epoch 47, Loss: 0.5126891508186285\n",
      "Epoch 48, Loss: 0.5127325425935546\n",
      "Epoch 49, Loss: 0.5102222487562803\n",
      "Epoch 50, Loss: 0.5057035817498275\n",
      "Epoch 51, Loss: 0.5014649626110497\n",
      "Epoch 52, Loss: 0.4988297088287231\n",
      "Epoch 53, Loss: 0.4973565946616734\n",
      "Epoch 54, Loss: 0.4959194297599237\n",
      "Epoch 55, Loss: 0.4938166917353345\n",
      "Epoch 56, Loss: 0.491001091911205\n",
      "Epoch 57, Loss: 0.4878856276904471\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2371805010130831\n",
      "Test R^2 score: 0.3906646731649457\n",
      "Num of epochs: 58\n",
      "Epoch 1, Loss: 0.5593568084998053\n",
      "Epoch 2, Loss: 0.558613543393171\n",
      "Epoch 3, Loss: 0.5580224002884733\n",
      "Epoch 4, Loss: 0.5575671866692146\n",
      "Epoch 5, Loss: 0.5572194887521867\n",
      "Epoch 6, Loss: 0.5569459579676577\n",
      "Epoch 7, Loss: 0.5567245152485686\n",
      "Epoch 8, Loss: 0.5565411930621512\n",
      "Epoch 9, Loss: 0.5563920654014268\n",
      "Epoch 10, Loss: 0.5562772401290471\n",
      "Epoch 11, Loss: 0.556197247521902\n",
      "Epoch 12, Loss: 0.5561507093557937\n",
      "Epoch 13, Loss: 0.5561342043844828\n",
      "Epoch 14, Loss: 0.5561456721762237\n",
      "Epoch 15, Loss: 0.5561656598647968\n",
      "Epoch 16, Loss: 0.5561865041689366\n",
      "Epoch 17, Loss: 0.5561977029711832\n",
      "Epoch 18, Loss: 0.5561912998558768\n",
      "Epoch 19, Loss: 0.5561633556906815\n",
      "Epoch 20, Loss: 0.5561125006734048\n",
      "Epoch 21, Loss: 0.5560371473873607\n",
      "Epoch 22, Loss: 0.5559345786932989\n",
      "Epoch 23, Loss: 0.5557967900679375\n",
      "Epoch 24, Loss: 0.5556162459946493\n",
      "Epoch 25, Loss: 0.5553846679230654\n",
      "Epoch 26, Loss: 0.5550821807519873\n",
      "Epoch 27, Loss: 0.5547155722378317\n",
      "Epoch 28, Loss: 0.5542354084583953\n",
      "Epoch 29, Loss: 0.553604869337869\n",
      "Epoch 30, Loss: 0.5528007979634291\n",
      "Epoch 31, Loss: 0.5517842784374389\n",
      "Epoch 32, Loss: 0.5505013803192768\n",
      "Epoch 33, Loss: 0.5489256151162103\n",
      "Epoch 34, Loss: 0.5469959670202345\n",
      "Epoch 35, Loss: 0.5446756551814865\n",
      "Epoch 36, Loss: 0.5418778032452541\n",
      "Epoch 37, Loss: 0.5385424828538545\n",
      "Epoch 38, Loss: 0.5346135081246128\n",
      "Epoch 39, Loss: 0.5302075367929687\n",
      "Epoch 40, Loss: 0.5255979391292046\n",
      "Epoch 41, Loss: 0.5215002907599483\n",
      "Epoch 42, Loss: 0.5188337534200109\n",
      "Epoch 43, Loss: 0.5176097644276233\n",
      "Epoch 44, Loss: 0.5159206409807552\n",
      "Epoch 45, Loss: 0.5131435796089773\n",
      "Epoch 46, Loss: 0.5103275227715268\n",
      "Epoch 47, Loss: 0.5078714189828016\n",
      "Epoch 48, Loss: 0.5055181759189906\n",
      "Epoch 49, Loss: 0.5032659795150448\n",
      "Epoch 50, Loss: 0.5010829165708753\n",
      "Epoch 51, Loss: 0.4989773603991189\n",
      "Epoch 52, Loss: 0.4969710155301812\n",
      "Epoch 53, Loss: 0.494961655846322\n",
      "Epoch 54, Loss: 0.49282807339460916\n",
      "Epoch 55, Loss: 0.4905065107924498\n",
      "Epoch 56, Loss: 0.4880819753277665\n",
      "Epoch 57, Loss: 0.48587129577351346\n",
      "Epoch 58, Loss: 0.4840872740639595\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.23200386392844247\n",
      "Test R^2 score: 0.421310139366671\n",
      "Num of epochs: 59\n",
      "Epoch 1, Loss: 0.5589908975344612\n",
      "Epoch 2, Loss: 0.5582231479307734\n",
      "Epoch 3, Loss: 0.5575834621512342\n",
      "Epoch 4, Loss: 0.5570707299150872\n",
      "Epoch 5, Loss: 0.5566844454465557\n",
      "Epoch 6, Loss: 0.5564111604717576\n",
      "Epoch 7, Loss: 0.5562407814290677\n",
      "Epoch 8, Loss: 0.5561574076622098\n",
      "Epoch 9, Loss: 0.5561385182310843\n",
      "Epoch 10, Loss: 0.5561653651453843\n",
      "Epoch 11, Loss: 0.5562146079130313\n",
      "Epoch 12, Loss: 0.556261221097428\n",
      "Epoch 13, Loss: 0.5562859459310163\n",
      "Epoch 14, Loss: 0.5562880888767587\n",
      "Epoch 15, Loss: 0.5562613818257889\n",
      "Epoch 16, Loss: 0.5562041863852144\n",
      "Epoch 17, Loss: 0.5561189314909183\n",
      "Epoch 18, Loss: 0.5560081770659244\n",
      "Epoch 19, Loss: 0.5558740524102059\n",
      "Epoch 20, Loss: 0.5557185248583795\n",
      "Epoch 21, Loss: 0.5555482552631534\n",
      "Epoch 22, Loss: 0.5553625056174764\n",
      "Epoch 23, Loss: 0.5551584957387666\n",
      "Epoch 24, Loss: 0.5549247664073238\n",
      "Epoch 25, Loss: 0.554679682501924\n",
      "Epoch 26, Loss: 0.5543350658204255\n",
      "Epoch 27, Loss: 0.5539689043386661\n",
      "Epoch 28, Loss: 0.5535365238699761\n",
      "Epoch 29, Loss: 0.5530490586040622\n",
      "Epoch 30, Loss: 0.5524615905321987\n",
      "Epoch 31, Loss: 0.5517390425198544\n",
      "Epoch 32, Loss: 0.5508607577029425\n",
      "Epoch 33, Loss: 0.5498520337819839\n",
      "Epoch 34, Loss: 0.5485845276337986\n",
      "Epoch 35, Loss: 0.5470315164294625\n",
      "Epoch 36, Loss: 0.5451786981073505\n",
      "Epoch 37, Loss: 0.5430005839504524\n",
      "Epoch 38, Loss: 0.5404226861685647\n",
      "Epoch 39, Loss: 0.537396108212308\n",
      "Epoch 40, Loss: 0.5339218996080398\n",
      "Epoch 41, Loss: 0.5300223808241493\n",
      "Epoch 42, Loss: 0.5255558080411622\n",
      "Epoch 43, Loss: 0.520411842187408\n",
      "Epoch 44, Loss: 0.5145712981058608\n",
      "Epoch 45, Loss: 0.5080346135245583\n",
      "Epoch 46, Loss: 0.5013135999537425\n",
      "Epoch 47, Loss: 0.49545422581148535\n",
      "Epoch 48, Loss: 0.4922955560900513\n",
      "Epoch 49, Loss: 0.49165136413144445\n",
      "Epoch 50, Loss: 0.4892561373805686\n",
      "Epoch 51, Loss: 0.48456538980882635\n",
      "Epoch 52, Loss: 0.47975129936483607\n",
      "Epoch 53, Loss: 0.4766171377160315\n",
      "Epoch 54, Loss: 0.4752213257342089\n",
      "Epoch 55, Loss: 0.4745833621333479\n",
      "Epoch 56, Loss: 0.4736164050848904\n",
      "Epoch 57, Loss: 0.4720789481254237\n",
      "Epoch 58, Loss: 0.4701820116474505\n",
      "Epoch 59, Loss: 0.4685303809351835\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22515999688125612\n",
      "Test R^2 score: 0.4535322032253295\n",
      "Num of epochs: 60\n",
      "Epoch 1, Loss: 0.5581709855839845\n",
      "Epoch 2, Loss: 0.557506597077891\n",
      "Epoch 3, Loss: 0.5569853133725737\n",
      "Epoch 4, Loss: 0.556603734985798\n",
      "Epoch 5, Loss: 0.5563518377370918\n",
      "Epoch 6, Loss: 0.5562131344440868\n",
      "Epoch 7, Loss: 0.556171018372337\n",
      "Epoch 8, Loss: 0.5561922375551941\n",
      "Epoch 9, Loss: 0.556250505768621\n",
      "Epoch 10, Loss: 0.5563182767476613\n",
      "Epoch 11, Loss: 0.5563739606341508\n",
      "Epoch 12, Loss: 0.5564044384389909\n",
      "Epoch 13, Loss: 0.5564051883112123\n",
      "Epoch 14, Loss: 0.5563783261866702\n",
      "Epoch 15, Loss: 0.5563299282383847\n",
      "Epoch 16, Loss: 0.5562673287424906\n",
      "Epoch 17, Loss: 0.5561975422244206\n",
      "Epoch 18, Loss: 0.5561243440380245\n",
      "Epoch 19, Loss: 0.5560474916507718\n",
      "Epoch 20, Loss: 0.5559584871718981\n",
      "Epoch 21, Loss: 0.5558375136472258\n",
      "Epoch 22, Loss: 0.5556795624245542\n",
      "Epoch 23, Loss: 0.5554953857130658\n",
      "Epoch 24, Loss: 0.5552959060551007\n",
      "Epoch 25, Loss: 0.5550344483535924\n",
      "Epoch 26, Loss: 0.5546716768398794\n",
      "Epoch 27, Loss: 0.5541925774399009\n",
      "Epoch 28, Loss: 0.5535880192894209\n",
      "Epoch 29, Loss: 0.5528470790521947\n",
      "Epoch 30, Loss: 0.5519609195620514\n",
      "Epoch 31, Loss: 0.5508823707767818\n",
      "Epoch 32, Loss: 0.5495444405160067\n",
      "Epoch 33, Loss: 0.5478727231214464\n",
      "Epoch 34, Loss: 0.5457558215289948\n",
      "Epoch 35, Loss: 0.5431405762961871\n",
      "Epoch 36, Loss: 0.5399993826721337\n",
      "Epoch 37, Loss: 0.5363068011685378\n",
      "Epoch 38, Loss: 0.5321290653065405\n",
      "Epoch 39, Loss: 0.5274439681156394\n",
      "Epoch 40, Loss: 0.5221682860824908\n",
      "Epoch 41, Loss: 0.5164138366326609\n",
      "Epoch 42, Loss: 0.5106572505426851\n",
      "Epoch 43, Loss: 0.5054530570234086\n",
      "Epoch 44, Loss: 0.5016657975443835\n",
      "Epoch 45, Loss: 0.4997816801272657\n",
      "Epoch 46, Loss: 0.49833593021256284\n",
      "Epoch 47, Loss: 0.4954333678345479\n",
      "Epoch 48, Loss: 0.4913674744073643\n",
      "Epoch 49, Loss: 0.4872485875803566\n",
      "Epoch 50, Loss: 0.4838840396010121\n",
      "Epoch 51, Loss: 0.4814977404540414\n",
      "Epoch 52, Loss: 0.4797782899010786\n",
      "Epoch 53, Loss: 0.4782145273001869\n",
      "Epoch 54, Loss: 0.4766489794701908\n",
      "Epoch 55, Loss: 0.4745210165026325\n",
      "Epoch 56, Loss: 0.4723115089409135\n",
      "Epoch 57, Loss: 0.4707809004100232\n",
      "Epoch 58, Loss: 0.46950833650303275\n",
      "Epoch 59, Loss: 0.4682612414153752\n",
      "Epoch 60, Loss: 0.4672278007297646\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2232610788011299\n",
      "Test R^2 score: 0.46165690480032934\n",
      "Num of epochs: 61\n",
      "Epoch 1, Loss: 0.5933826966816151\n",
      "Epoch 2, Loss: 0.5911767814254166\n",
      "Epoch 3, Loss: 0.5890986555422488\n",
      "Epoch 4, Loss: 0.5871437118550239\n",
      "Epoch 5, Loss: 0.5852483129464806\n",
      "Epoch 6, Loss: 0.5834078797890732\n",
      "Epoch 7, Loss: 0.5816200391048314\n",
      "Epoch 8, Loss: 0.5798869476222316\n",
      "Epoch 9, Loss: 0.5782102573523393\n",
      "Epoch 10, Loss: 0.5765867905294186\n",
      "Epoch 11, Loss: 0.5750167128995072\n",
      "Epoch 12, Loss: 0.5735177412722835\n",
      "Epoch 13, Loss: 0.5720784528940417\n",
      "Epoch 14, Loss: 0.5706961660724582\n",
      "Epoch 15, Loss: 0.5693711389354182\n",
      "Epoch 16, Loss: 0.5681098311511158\n",
      "Epoch 17, Loss: 0.5669068853459794\n",
      "Epoch 18, Loss: 0.5657615149131484\n",
      "Epoch 19, Loss: 0.5646702437938684\n",
      "Epoch 20, Loss: 0.5636299493098175\n",
      "Epoch 21, Loss: 0.5626493096870372\n",
      "Epoch 22, Loss: 0.5617180793768815\n",
      "Epoch 23, Loss: 0.5608412338577039\n",
      "Epoch 24, Loss: 0.5600389844659279\n",
      "Epoch 25, Loss: 0.5593394124309217\n",
      "Epoch 26, Loss: 0.5586717457771818\n",
      "Epoch 27, Loss: 0.5580310521612241\n",
      "Epoch 28, Loss: 0.5574204988201986\n",
      "Epoch 29, Loss: 0.556806680104041\n",
      "Epoch 30, Loss: 0.5561727866684957\n",
      "Epoch 31, Loss: 0.5555051767501175\n",
      "Epoch 32, Loss: 0.5547774335998212\n",
      "Epoch 33, Loss: 0.5539251111777972\n",
      "Epoch 34, Loss: 0.5528759185400449\n",
      "Epoch 35, Loss: 0.5515454989398588\n",
      "Epoch 36, Loss: 0.5498723857389978\n",
      "Epoch 37, Loss: 0.5477855186977236\n",
      "Epoch 38, Loss: 0.5452433905762796\n",
      "Epoch 39, Loss: 0.5422452868357466\n",
      "Epoch 40, Loss: 0.5388755474154161\n",
      "Epoch 41, Loss: 0.5352184510106847\n",
      "Epoch 42, Loss: 0.531831451184154\n",
      "Epoch 43, Loss: 0.5298617681141196\n",
      "Epoch 44, Loss: 0.5303935833403306\n",
      "Epoch 45, Loss: 0.5308658950326672\n",
      "Epoch 46, Loss: 0.5285475377994847\n",
      "Epoch 47, Loss: 0.5248768786973392\n",
      "Epoch 48, Loss: 0.521756847506647\n",
      "Epoch 49, Loss: 0.5198403493014965\n",
      "Epoch 50, Loss: 0.5187667729067549\n",
      "Epoch 51, Loss: 0.5178475596335149\n",
      "Epoch 52, Loss: 0.5165942070767272\n",
      "Epoch 53, Loss: 0.5148101784117827\n",
      "Epoch 54, Loss: 0.5125472663389711\n",
      "Epoch 55, Loss: 0.5100516908760265\n",
      "Epoch 56, Loss: 0.5077245489397317\n",
      "Epoch 57, Loss: 0.5060014562020438\n",
      "Epoch 58, Loss: 0.5049387681305103\n",
      "Epoch 59, Loss: 0.5038960773712782\n",
      "Epoch 60, Loss: 0.5022028142449158\n",
      "Epoch 61, Loss: 0.5000506315821795\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2444977773643687\n",
      "Test R^2 score: 0.351312374241081\n",
      "Num of epochs: 62\n",
      "Epoch 1, Loss: 0.5652777116740587\n",
      "Epoch 2, Loss: 0.5640474069113548\n",
      "Epoch 3, Loss: 0.5628916913140897\n",
      "Epoch 4, Loss: 0.5618391393434868\n",
      "Epoch 5, Loss: 0.560896628120735\n",
      "Epoch 6, Loss: 0.5600366164055126\n",
      "Epoch 7, Loss: 0.5592624156752073\n",
      "Epoch 8, Loss: 0.5585761701044979\n",
      "Epoch 9, Loss: 0.557979245734759\n",
      "Epoch 10, Loss: 0.5574718760337496\n",
      "Epoch 11, Loss: 0.5570530217050325\n",
      "Epoch 12, Loss: 0.5567201524107103\n",
      "Epoch 13, Loss: 0.5564694057616477\n",
      "Epoch 14, Loss: 0.5562952676848478\n",
      "Epoch 15, Loss: 0.5561904157379297\n",
      "Epoch 16, Loss: 0.5561449755414154\n",
      "Epoch 17, Loss: 0.5561470386496591\n",
      "Epoch 18, Loss: 0.5561758945693323\n",
      "Epoch 19, Loss: 0.5562293155981964\n",
      "Epoch 20, Loss: 0.5562853030456838\n",
      "Epoch 21, Loss: 0.5563289104167385\n",
      "Epoch 22, Loss: 0.5563509806580041\n",
      "Epoch 23, Loss: 0.5563411777220243\n",
      "Epoch 24, Loss: 0.5562917854387625\n",
      "Epoch 25, Loss: 0.5561918624756569\n",
      "Epoch 26, Loss: 0.5560167262816956\n",
      "Epoch 27, Loss: 0.5558143238246605\n",
      "Epoch 28, Loss: 0.5555947634319046\n",
      "Epoch 29, Loss: 0.5553270065224656\n",
      "Epoch 30, Loss: 0.5550085401307555\n",
      "Epoch 31, Loss: 0.5546368857918409\n",
      "Epoch 32, Loss: 0.5542108072422076\n",
      "Epoch 33, Loss: 0.5537103454479033\n",
      "Epoch 34, Loss: 0.553111079412604\n",
      "Epoch 35, Loss: 0.5523892730557367\n",
      "Epoch 36, Loss: 0.5515240469434148\n",
      "Epoch 37, Loss: 0.5504854639024223\n",
      "Epoch 38, Loss: 0.5492422367462348\n",
      "Epoch 39, Loss: 0.5477405782469924\n",
      "Epoch 40, Loss: 0.5458930054532539\n",
      "Epoch 41, Loss: 0.5436282372342102\n",
      "Epoch 42, Loss: 0.5409028799965921\n",
      "Epoch 43, Loss: 0.5376593253843979\n",
      "Epoch 44, Loss: 0.5338662184928864\n",
      "Epoch 45, Loss: 0.5296614682712895\n",
      "Epoch 46, Loss: 0.5254764415893788\n",
      "Epoch 47, Loss: 0.522102190008504\n",
      "Epoch 48, Loss: 0.5201969614136714\n",
      "Epoch 49, Loss: 0.5186443359124557\n",
      "Epoch 50, Loss: 0.5157474314671443\n",
      "Epoch 51, Loss: 0.5120029679357665\n",
      "Epoch 52, Loss: 0.5089589602257949\n",
      "Epoch 53, Loss: 0.506920838641064\n",
      "Epoch 54, Loss: 0.5053756050240223\n",
      "Epoch 55, Loss: 0.5035152840742639\n",
      "Epoch 56, Loss: 0.5010261436748952\n",
      "Epoch 57, Loss: 0.49818286909009635\n",
      "Epoch 58, Loss: 0.4954890072042968\n",
      "Epoch 59, Loss: 0.49332491829123853\n",
      "Epoch 60, Loss: 0.49154819870289795\n",
      "Epoch 61, Loss: 0.4895708982092357\n",
      "Epoch 62, Loss: 0.4872389693658149\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2384783086975038\n",
      "Test R^2 score: 0.3800394943913229\n",
      "Num of epochs: 63\n",
      "Epoch 1, Loss: 0.5615763498338027\n",
      "Epoch 2, Loss: 0.5606852769289902\n",
      "Epoch 3, Loss: 0.5598771084751933\n",
      "Epoch 4, Loss: 0.559151670957912\n",
      "Epoch 5, Loss: 0.5585208124946236\n",
      "Epoch 6, Loss: 0.5579695248177821\n",
      "Epoch 7, Loss: 0.5575117823292285\n",
      "Epoch 8, Loss: 0.5571520948473867\n",
      "Epoch 9, Loss: 0.5568626897802018\n",
      "Epoch 10, Loss: 0.5566211630112664\n",
      "Epoch 11, Loss: 0.5564201855434189\n",
      "Epoch 12, Loss: 0.5562593727179408\n",
      "Epoch 13, Loss: 0.5561357048566612\n",
      "Epoch 14, Loss: 0.5560439274573885\n",
      "Epoch 15, Loss: 0.5559771147021476\n",
      "Epoch 16, Loss: 0.5559279045061699\n",
      "Epoch 17, Loss: 0.5558896805094482\n",
      "Epoch 18, Loss: 0.5558452344370486\n",
      "Epoch 19, Loss: 0.5557788267771842\n",
      "Epoch 20, Loss: 0.5556591818114134\n",
      "Epoch 21, Loss: 0.5554979609066598\n",
      "Epoch 22, Loss: 0.5553115235912045\n",
      "Epoch 23, Loss: 0.5550783150637018\n",
      "Epoch 24, Loss: 0.554783772455258\n",
      "Epoch 25, Loss: 0.5544199230997325\n",
      "Epoch 26, Loss: 0.5539794755104926\n",
      "Epoch 27, Loss: 0.5534653160906663\n",
      "Epoch 28, Loss: 0.5528906880877692\n",
      "Epoch 29, Loss: 0.5522716458966863\n",
      "Epoch 30, Loss: 0.5516006380895613\n",
      "Epoch 31, Loss: 0.5508529399993158\n",
      "Epoch 32, Loss: 0.5500061587509045\n",
      "Epoch 33, Loss: 0.5490285161399922\n",
      "Epoch 34, Loss: 0.547885016577592\n",
      "Epoch 35, Loss: 0.5465427206657972\n",
      "Epoch 36, Loss: 0.5449802545155313\n",
      "Epoch 37, Loss: 0.5431838398569674\n",
      "Epoch 38, Loss: 0.5411264189051449\n",
      "Epoch 39, Loss: 0.5387614141879227\n",
      "Epoch 40, Loss: 0.5360297432304915\n",
      "Epoch 41, Loss: 0.5328282026734548\n",
      "Epoch 42, Loss: 0.5290338066598578\n",
      "Epoch 43, Loss: 0.5245553222441514\n",
      "Epoch 44, Loss: 0.5193656141073415\n",
      "Epoch 45, Loss: 0.513530784347194\n",
      "Epoch 46, Loss: 0.5074040751165386\n",
      "Epoch 47, Loss: 0.5018337419494077\n",
      "Epoch 48, Loss: 0.498489392727304\n",
      "Epoch 49, Loss: 0.4981774102977817\n",
      "Epoch 50, Loss: 0.4974424097379873\n",
      "Epoch 51, Loss: 0.49388038808905016\n",
      "Epoch 52, Loss: 0.4890427564103053\n",
      "Epoch 53, Loss: 0.48458010422616643\n",
      "Epoch 54, Loss: 0.4817713935092728\n",
      "Epoch 55, Loss: 0.4801319461509739\n",
      "Epoch 56, Loss: 0.4785834128184748\n",
      "Epoch 57, Loss: 0.47689243527258146\n",
      "Epoch 58, Loss: 0.4751530425826818\n",
      "Epoch 59, Loss: 0.47372012562529703\n",
      "Epoch 60, Loss: 0.47281084606236873\n",
      "Epoch 61, Loss: 0.4723857704725485\n",
      "Epoch 62, Loss: 0.4720465613479635\n",
      "Epoch 63, Loss: 0.4714866227267841\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22741310354324304\n",
      "Test R^2 score: 0.4408104430522945\n",
      "Num of epochs: 64\n",
      "Epoch 1, Loss: 0.5679929673018075\n",
      "Epoch 2, Loss: 0.5668697433900892\n",
      "Epoch 3, Loss: 0.5657898278101042\n",
      "Epoch 4, Loss: 0.564756397758204\n",
      "Epoch 5, Loss: 0.5637964567002063\n",
      "Epoch 6, Loss: 0.5628943120874049\n",
      "Epoch 7, Loss: 0.5620428187749488\n",
      "Epoch 8, Loss: 0.5612407470314209\n",
      "Epoch 9, Loss: 0.5604905422494889\n",
      "Epoch 10, Loss: 0.5598178336053489\n",
      "Epoch 11, Loss: 0.55924205905186\n",
      "Epoch 12, Loss: 0.5587114863595358\n",
      "Epoch 13, Loss: 0.5582354269965679\n",
      "Epoch 14, Loss: 0.5578128718527188\n",
      "Epoch 15, Loss: 0.5574357895160347\n",
      "Epoch 16, Loss: 0.5571084181740322\n",
      "Epoch 17, Loss: 0.5568309525474401\n",
      "Epoch 18, Loss: 0.5565934010601444\n",
      "Epoch 19, Loss: 0.5564082949139351\n",
      "Epoch 20, Loss: 0.5562650517773907\n",
      "Epoch 21, Loss: 0.5561609443354546\n",
      "Epoch 22, Loss: 0.5560854904277407\n",
      "Epoch 23, Loss: 0.5560300456443346\n",
      "Epoch 24, Loss: 0.5559874332812247\n",
      "Epoch 25, Loss: 0.5559469887157958\n",
      "Epoch 26, Loss: 0.5559056834422201\n",
      "Epoch 27, Loss: 0.5558460386798211\n",
      "Epoch 28, Loss: 0.5557920177876234\n",
      "Epoch 29, Loss: 0.55571273295574\n",
      "Epoch 30, Loss: 0.5555935297014575\n",
      "Epoch 31, Loss: 0.5554289898813332\n",
      "Epoch 32, Loss: 0.5552108337555979\n",
      "Epoch 33, Loss: 0.5549253034586463\n",
      "Epoch 34, Loss: 0.5545558773278602\n",
      "Epoch 35, Loss: 0.5540831322440367\n",
      "Epoch 36, Loss: 0.5534900042864105\n",
      "Epoch 37, Loss: 0.5527551330334972\n",
      "Epoch 38, Loss: 0.5518689069055152\n",
      "Epoch 39, Loss: 0.5508152565704801\n",
      "Epoch 40, Loss: 0.5495767612175181\n",
      "Epoch 41, Loss: 0.5481762799206522\n",
      "Epoch 42, Loss: 0.5466351936989702\n",
      "Epoch 43, Loss: 0.5449356022681526\n",
      "Epoch 44, Loss: 0.5430067035391227\n",
      "Epoch 45, Loss: 0.5407781527347039\n",
      "Epoch 46, Loss: 0.5381506242311269\n",
      "Epoch 47, Loss: 0.5348987656029768\n",
      "Epoch 48, Loss: 0.530852281131462\n",
      "Epoch 49, Loss: 0.5259121430076102\n",
      "Epoch 50, Loss: 0.5198898511922169\n",
      "Epoch 51, Loss: 0.5125833152876836\n",
      "Epoch 52, Loss: 0.5040660575178297\n",
      "Epoch 53, Loss: 0.4950250393140939\n",
      "Epoch 54, Loss: 0.48743490493656877\n",
      "Epoch 55, Loss: 0.484047594475086\n",
      "Epoch 56, Loss: 0.4848682752891806\n",
      "Epoch 57, Loss: 0.48438419825526297\n",
      "Epoch 58, Loss: 0.48167655297245465\n",
      "Epoch 59, Loss: 0.478726134415038\n",
      "Epoch 60, Loss: 0.4766092590155806\n",
      "Epoch 61, Loss: 0.47537768933290053\n",
      "Epoch 62, Loss: 0.47466073719796636\n",
      "Epoch 63, Loss: 0.47399327041077993\n",
      "Epoch 64, Loss: 0.4728854860902248\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2228942198931484\n",
      "Test R^2 score: 0.462692737932308\n",
      "Num of epochs: 65\n",
      "Epoch 1, Loss: 0.6185541594406394\n",
      "Epoch 2, Loss: 0.6158280671874874\n",
      "Epoch 3, Loss: 0.613315046800585\n",
      "Epoch 4, Loss: 0.6108515530202657\n",
      "Epoch 5, Loss: 0.6084469795762107\n",
      "Epoch 6, Loss: 0.6061540970209233\n",
      "Epoch 7, Loss: 0.6038857963621838\n",
      "Epoch 8, Loss: 0.6016150117223737\n",
      "Epoch 9, Loss: 0.5993861425913405\n",
      "Epoch 10, Loss: 0.5972087156877904\n",
      "Epoch 11, Loss: 0.5950787633567172\n",
      "Epoch 12, Loss: 0.5929975510188027\n",
      "Epoch 13, Loss: 0.5910174584722727\n",
      "Epoch 14, Loss: 0.5891219769308617\n",
      "Epoch 15, Loss: 0.5872541511798164\n",
      "Epoch 16, Loss: 0.5854222893586297\n",
      "Epoch 17, Loss: 0.5837591751325126\n",
      "Epoch 18, Loss: 0.5821266352176123\n",
      "Epoch 19, Loss: 0.5805417657985925\n",
      "Epoch 20, Loss: 0.5789976235787306\n",
      "Epoch 21, Loss: 0.5775137840624146\n",
      "Epoch 22, Loss: 0.576073253402509\n",
      "Epoch 23, Loss: 0.5746633404480967\n",
      "Epoch 24, Loss: 0.573273614025233\n",
      "Epoch 25, Loss: 0.571950363446392\n",
      "Epoch 26, Loss: 0.5706462145034129\n",
      "Epoch 27, Loss: 0.5693476628295172\n",
      "Epoch 28, Loss: 0.5680435194415594\n",
      "Epoch 29, Loss: 0.5667418176475132\n",
      "Epoch 30, Loss: 0.5655318251945883\n",
      "Epoch 31, Loss: 0.5645249792912665\n",
      "Epoch 32, Loss: 0.5637019349646133\n",
      "Epoch 33, Loss: 0.5629274545516342\n",
      "Epoch 34, Loss: 0.5621365326556622\n",
      "Epoch 35, Loss: 0.5613311172862192\n",
      "Epoch 36, Loss: 0.5605174997321914\n",
      "Epoch 37, Loss: 0.5596943396614169\n",
      "Epoch 38, Loss: 0.5588660476810529\n",
      "Epoch 39, Loss: 0.5580373807609743\n",
      "Epoch 40, Loss: 0.5572115463228479\n",
      "Epoch 41, Loss: 0.556377094193723\n",
      "Epoch 42, Loss: 0.5555197690987767\n",
      "Epoch 43, Loss: 0.5546084602886846\n",
      "Epoch 44, Loss: 0.553562258719161\n",
      "Epoch 45, Loss: 0.5523331334929641\n",
      "Epoch 46, Loss: 0.5509033338367977\n",
      "Epoch 47, Loss: 0.5492264194956895\n",
      "Epoch 48, Loss: 0.5471899760401034\n",
      "Epoch 49, Loss: 0.544750555856604\n",
      "Epoch 50, Loss: 0.541870460931231\n",
      "Epoch 51, Loss: 0.5385338775937235\n",
      "Epoch 52, Loss: 0.5348425175270638\n",
      "Epoch 53, Loss: 0.5310146708141047\n",
      "Epoch 54, Loss: 0.5275420204709568\n",
      "Epoch 55, Loss: 0.5250221293190594\n",
      "Epoch 56, Loss: 0.5230587970038726\n",
      "Epoch 57, Loss: 0.5202302747485518\n",
      "Epoch 58, Loss: 0.5162751405057863\n",
      "Epoch 59, Loss: 0.5124104898487544\n",
      "Epoch 60, Loss: 0.5097480273954605\n",
      "Epoch 61, Loss: 0.5081238599062958\n",
      "Epoch 62, Loss: 0.5067655187356233\n",
      "Epoch 63, Loss: 0.5051233836324913\n",
      "Epoch 64, Loss: 0.5030505285176302\n",
      "Epoch 65, Loss: 0.5006045025118938\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.24280722053165715\n",
      "Test R^2 score: 0.35735648970028727\n",
      "Num of epochs: 66\n",
      "Epoch 1, Loss: 0.5695834529693337\n",
      "Epoch 2, Loss: 0.5677389842400481\n",
      "Epoch 3, Loss: 0.5660171224443993\n",
      "Epoch 4, Loss: 0.5644195441054363\n",
      "Epoch 5, Loss: 0.5629550894277047\n",
      "Epoch 6, Loss: 0.5615816301792755\n",
      "Epoch 7, Loss: 0.560363207776181\n",
      "Epoch 8, Loss: 0.559260177548686\n",
      "Epoch 9, Loss: 0.5582958040387564\n",
      "Epoch 10, Loss: 0.5574853477348725\n",
      "Epoch 11, Loss: 0.5568272595647594\n",
      "Epoch 12, Loss: 0.5563462934833889\n",
      "Epoch 13, Loss: 0.5559775703317587\n",
      "Epoch 14, Loss: 0.5557300548552327\n",
      "Epoch 15, Loss: 0.5555565433360962\n",
      "Epoch 16, Loss: 0.5554528932950531\n",
      "Epoch 17, Loss: 0.5553698037140756\n",
      "Epoch 18, Loss: 0.5552697416726642\n",
      "Epoch 19, Loss: 0.5550706372974121\n",
      "Epoch 20, Loss: 0.5547186614403915\n",
      "Epoch 21, Loss: 0.5542111836624852\n",
      "Epoch 22, Loss: 0.5535185141477919\n",
      "Epoch 23, Loss: 0.5526147450097639\n",
      "Epoch 24, Loss: 0.5515070252442282\n",
      "Epoch 25, Loss: 0.5501659554749732\n",
      "Epoch 26, Loss: 0.5485563589558341\n",
      "Epoch 27, Loss: 0.5466244804960827\n",
      "Epoch 28, Loss: 0.5443188465119417\n",
      "Epoch 29, Loss: 0.5416096480020871\n",
      "Epoch 30, Loss: 0.5384284727520982\n",
      "Epoch 31, Loss: 0.5348316795509394\n",
      "Epoch 32, Loss: 0.5309105798588648\n",
      "Epoch 33, Loss: 0.5267194372561352\n",
      "Epoch 34, Loss: 0.5225617783816013\n",
      "Epoch 35, Loss: 0.5189464978257304\n",
      "Epoch 36, Loss: 0.5162855598819818\n",
      "Epoch 37, Loss: 0.5141820078786351\n",
      "Epoch 38, Loss: 0.5114238267693314\n",
      "Epoch 39, Loss: 0.5078818053855934\n",
      "Epoch 40, Loss: 0.5045953814167778\n",
      "Epoch 41, Loss: 0.5022690368906714\n",
      "Epoch 42, Loss: 0.5006698948783185\n",
      "Epoch 43, Loss: 0.49914458235806236\n",
      "Epoch 44, Loss: 0.49723739663766026\n",
      "Epoch 45, Loss: 0.4949264911535693\n",
      "Epoch 46, Loss: 0.4925829948408426\n",
      "Epoch 47, Loss: 0.4906109886841469\n",
      "Epoch 48, Loss: 0.4889870387350807\n",
      "Epoch 49, Loss: 0.48722230142201023\n",
      "Epoch 50, Loss: 0.4851586401691623\n",
      "Epoch 51, Loss: 0.4832010656141774\n",
      "Epoch 52, Loss: 0.4816147078744304\n",
      "Epoch 53, Loss: 0.4802494634141759\n",
      "Epoch 54, Loss: 0.4787419465137121\n",
      "Epoch 55, Loss: 0.47697056044093933\n",
      "Epoch 56, Loss: 0.4751855469000869\n",
      "Epoch 57, Loss: 0.47360230967036604\n",
      "Epoch 58, Loss: 0.4720544688509948\n",
      "Epoch 59, Loss: 0.4704033146115789\n",
      "Epoch 60, Loss: 0.4689197074131019\n",
      "Epoch 61, Loss: 0.4677550087247224\n",
      "Epoch 62, Loss: 0.4667182760424613\n",
      "Epoch 63, Loss: 0.4656370590235727\n",
      "Epoch 64, Loss: 0.4645574152634974\n",
      "Epoch 65, Loss: 0.46348978852419204\n",
      "Epoch 66, Loss: 0.4623007577165834\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21453224012076938\n",
      "Test R^2 score: 0.5013785804480692\n",
      "Num of epochs: 67\n",
      "Epoch 1, Loss: 0.5660106461268468\n",
      "Epoch 2, Loss: 0.5645419252232537\n",
      "Epoch 3, Loss: 0.5631607731031629\n",
      "Epoch 4, Loss: 0.561866536018347\n",
      "Epoch 5, Loss: 0.5606649453892332\n",
      "Epoch 6, Loss: 0.5595859438858246\n",
      "Epoch 7, Loss: 0.5586415783873445\n",
      "Epoch 8, Loss: 0.5578491476720029\n",
      "Epoch 9, Loss: 0.5572086848811707\n",
      "Epoch 10, Loss: 0.5567246758431748\n",
      "Epoch 11, Loss: 0.5564080806660283\n",
      "Epoch 12, Loss: 0.5562281368545221\n",
      "Epoch 13, Loss: 0.5561699198824982\n",
      "Epoch 14, Loss: 0.556203409451155\n",
      "Epoch 15, Loss: 0.5562879817296676\n",
      "Epoch 16, Loss: 0.5563886373250266\n",
      "Epoch 17, Loss: 0.5564731278970559\n",
      "Epoch 18, Loss: 0.5565177112530281\n",
      "Epoch 19, Loss: 0.5565105353143899\n",
      "Epoch 20, Loss: 0.556450687595381\n",
      "Epoch 21, Loss: 0.5563432668867982\n",
      "Epoch 22, Loss: 0.5561975154332891\n",
      "Epoch 23, Loss: 0.5560302600379046\n",
      "Epoch 24, Loss: 0.5558389344950716\n",
      "Epoch 25, Loss: 0.5556286363085777\n",
      "Epoch 26, Loss: 0.5553979756138097\n",
      "Epoch 27, Loss: 0.5551396796869562\n",
      "Epoch 28, Loss: 0.5548443639607364\n",
      "Epoch 29, Loss: 0.5544998496272964\n",
      "Epoch 30, Loss: 0.5540864939047523\n",
      "Epoch 31, Loss: 0.5535830933796546\n",
      "Epoch 32, Loss: 0.5529585474716338\n",
      "Epoch 33, Loss: 0.5521750703804088\n",
      "Epoch 34, Loss: 0.5511972466137055\n",
      "Epoch 35, Loss: 0.5499800407516108\n",
      "Epoch 36, Loss: 0.5484837167508414\n",
      "Epoch 37, Loss: 0.5466494231247272\n",
      "Epoch 38, Loss: 0.5443893072479628\n",
      "Epoch 39, Loss: 0.5415906363704738\n",
      "Epoch 40, Loss: 0.5381602324273135\n",
      "Epoch 41, Loss: 0.5340538085801696\n",
      "Epoch 42, Loss: 0.5293166941630753\n",
      "Epoch 43, Loss: 0.5241206252108606\n",
      "Epoch 44, Loss: 0.5189167202907176\n",
      "Epoch 45, Loss: 0.5146628853726125\n",
      "Epoch 46, Loss: 0.5125542437527224\n",
      "Epoch 47, Loss: 0.5121226282099745\n",
      "Epoch 48, Loss: 0.5103354940939685\n",
      "Epoch 49, Loss: 0.5064626800348488\n",
      "Epoch 50, Loss: 0.5022711432921189\n",
      "Epoch 51, Loss: 0.4992871865896537\n",
      "Epoch 52, Loss: 0.4978045753044599\n",
      "Epoch 53, Loss: 0.496948107253459\n",
      "Epoch 54, Loss: 0.4958510668839746\n",
      "Epoch 55, Loss: 0.4940972441075096\n",
      "Epoch 56, Loss: 0.49180080724330366\n",
      "Epoch 57, Loss: 0.4893128750514972\n",
      "Epoch 58, Loss: 0.487165901434488\n",
      "Epoch 59, Loss: 0.4857367938225011\n",
      "Epoch 60, Loss: 0.48476652503410356\n",
      "Epoch 61, Loss: 0.4836688277675863\n",
      "Epoch 62, Loss: 0.4819871588624812\n",
      "Epoch 63, Loss: 0.48016710814672314\n",
      "Epoch 64, Loss: 0.4786871466450446\n",
      "Epoch 65, Loss: 0.47766894736991106\n",
      "Epoch 66, Loss: 0.4768305009300904\n",
      "Epoch 67, Loss: 0.47580294191618305\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.226659077595938\n",
      "Test R^2 score: 0.4423195790845283\n",
      "Num of epochs: 68\n",
      "Epoch 1, Loss: 0.5579178729292364\n",
      "Epoch 2, Loss: 0.5572988266054153\n",
      "Epoch 3, Loss: 0.5568188565998554\n",
      "Epoch 4, Loss: 0.5564752968997335\n",
      "Epoch 5, Loss: 0.556261837222559\n",
      "Epoch 6, Loss: 0.5561650436331197\n",
      "Epoch 7, Loss: 0.5561622036000441\n",
      "Epoch 8, Loss: 0.5562157331048695\n",
      "Epoch 9, Loss: 0.5562837226160833\n",
      "Epoch 10, Loss: 0.5563346959044629\n",
      "Epoch 11, Loss: 0.5563528823004447\n",
      "Epoch 12, Loss: 0.5563322852918895\n",
      "Epoch 13, Loss: 0.556277775874641\n",
      "Epoch 14, Loss: 0.5561964705781498\n",
      "Epoch 15, Loss: 0.5560962357322142\n",
      "Epoch 16, Loss: 0.5559841099156236\n",
      "Epoch 17, Loss: 0.5558644823280688\n",
      "Epoch 18, Loss: 0.5557433006493732\n",
      "Epoch 19, Loss: 0.5556143954695035\n",
      "Epoch 20, Loss: 0.5554663603096809\n",
      "Epoch 21, Loss: 0.55528332047015\n",
      "Epoch 22, Loss: 0.5550526236596248\n",
      "Epoch 23, Loss: 0.5547634932349864\n",
      "Epoch 24, Loss: 0.5544152195994402\n",
      "Epoch 25, Loss: 0.5540025538564683\n",
      "Epoch 26, Loss: 0.55350906486635\n",
      "Epoch 27, Loss: 0.5528806081837143\n",
      "Epoch 28, Loss: 0.5520785049611208\n",
      "Epoch 29, Loss: 0.5510781752589505\n",
      "Epoch 30, Loss: 0.5498758544394933\n",
      "Epoch 31, Loss: 0.5484348394867359\n",
      "Epoch 32, Loss: 0.5467246802685145\n",
      "Epoch 33, Loss: 0.5447053923652831\n",
      "Epoch 34, Loss: 0.5423594012649335\n",
      "Epoch 35, Loss: 0.5396046331121902\n",
      "Epoch 36, Loss: 0.5363856763308358\n",
      "Epoch 37, Loss: 0.532708438097014\n",
      "Epoch 38, Loss: 0.5285188086978406\n",
      "Epoch 39, Loss: 0.5238547299176541\n",
      "Epoch 40, Loss: 0.5188135337989322\n",
      "Epoch 41, Loss: 0.5138889042822804\n",
      "Epoch 42, Loss: 0.5097041769006624\n",
      "Epoch 43, Loss: 0.507348215161627\n",
      "Epoch 44, Loss: 0.5067791916202713\n",
      "Epoch 45, Loss: 0.5053176925382953\n",
      "Epoch 46, Loss: 0.5019532437454262\n",
      "Epoch 47, Loss: 0.49776564493121506\n",
      "Epoch 48, Loss: 0.49435228782692353\n",
      "Epoch 49, Loss: 0.4922046355640319\n",
      "Epoch 50, Loss: 0.49090680515093515\n",
      "Epoch 51, Loss: 0.48965873205305827\n",
      "Epoch 52, Loss: 0.4879059379135382\n",
      "Epoch 53, Loss: 0.48560713365698466\n",
      "Epoch 54, Loss: 0.4831356528811471\n",
      "Epoch 55, Loss: 0.48090527251140097\n",
      "Epoch 56, Loss: 0.4791030236838912\n",
      "Epoch 57, Loss: 0.4777155357008655\n",
      "Epoch 58, Loss: 0.47637582468458434\n",
      "Epoch 59, Loss: 0.4747383193687846\n",
      "Epoch 60, Loss: 0.47296072870868466\n",
      "Epoch 61, Loss: 0.4713570417312979\n",
      "Epoch 62, Loss: 0.46996761172380175\n",
      "Epoch 63, Loss: 0.46872644365248983\n",
      "Epoch 64, Loss: 0.4675012963577901\n",
      "Epoch 65, Loss: 0.4663070439018338\n",
      "Epoch 66, Loss: 0.46521891352843514\n",
      "Epoch 67, Loss: 0.46423070216192086\n",
      "Epoch 68, Loss: 0.4631862903301733\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21698939686826255\n",
      "Test R^2 score: 0.49077371772419087\n",
      "Num of epochs: 69\n",
      "Epoch 1, Loss: 0.572901219824426\n",
      "Epoch 2, Loss: 0.5714192559981579\n",
      "Epoch 3, Loss: 0.5700173332690888\n",
      "Epoch 4, Loss: 0.5686713866514596\n",
      "Epoch 5, Loss: 0.5674098101970256\n",
      "Epoch 6, Loss: 0.5663018755276645\n",
      "Epoch 7, Loss: 0.5652535119603489\n",
      "Epoch 8, Loss: 0.5642752977767009\n",
      "Epoch 9, Loss: 0.5634680735776695\n",
      "Epoch 10, Loss: 0.5627277231200623\n",
      "Epoch 11, Loss: 0.562023702936138\n",
      "Epoch 12, Loss: 0.5613583794857678\n",
      "Epoch 13, Loss: 0.5607330863636583\n",
      "Epoch 14, Loss: 0.5601508040542504\n",
      "Epoch 15, Loss: 0.5596147822473376\n",
      "Epoch 16, Loss: 0.5591190242605774\n",
      "Epoch 17, Loss: 0.5586627570789728\n",
      "Epoch 18, Loss: 0.5582612121556244\n",
      "Epoch 19, Loss: 0.5579122641116453\n",
      "Epoch 20, Loss: 0.5575885397905973\n",
      "Epoch 21, Loss: 0.5573396008515938\n",
      "Epoch 22, Loss: 0.5570921288135726\n",
      "Epoch 23, Loss: 0.5568605490456747\n",
      "Epoch 24, Loss: 0.556647130024696\n",
      "Epoch 25, Loss: 0.5564501252372958\n",
      "Epoch 26, Loss: 0.5562671948036251\n",
      "Epoch 27, Loss: 0.5560965304882639\n",
      "Epoch 28, Loss: 0.5559336137555363\n",
      "Epoch 29, Loss: 0.5557760652048784\n",
      "Epoch 30, Loss: 0.5556130813247154\n",
      "Epoch 31, Loss: 0.555431297101922\n",
      "Epoch 32, Loss: 0.5552295937204133\n",
      "Epoch 33, Loss: 0.5550208366194247\n",
      "Epoch 34, Loss: 0.5547774604595309\n",
      "Epoch 35, Loss: 0.5544570659117378\n",
      "Epoch 36, Loss: 0.5540204402581884\n",
      "Epoch 37, Loss: 0.5534341648546272\n",
      "Epoch 38, Loss: 0.5526687798820116\n",
      "Epoch 39, Loss: 0.5517141679364476\n",
      "Epoch 40, Loss: 0.5505575984009559\n",
      "Epoch 41, Loss: 0.5491956247423545\n",
      "Epoch 42, Loss: 0.5476438567191833\n",
      "Epoch 43, Loss: 0.5458325668746964\n",
      "Epoch 44, Loss: 0.5436738191052659\n",
      "Epoch 45, Loss: 0.5411079410605468\n",
      "Epoch 46, Loss: 0.5381055160256044\n",
      "Epoch 47, Loss: 0.534660025759707\n",
      "Epoch 48, Loss: 0.5308799576856816\n",
      "Epoch 49, Loss: 0.5271378291710298\n",
      "Epoch 50, Loss: 0.5239286253781726\n",
      "Epoch 51, Loss: 0.521703238403743\n",
      "Epoch 52, Loss: 0.5196503237458014\n",
      "Epoch 53, Loss: 0.516492229927607\n",
      "Epoch 54, Loss: 0.5123987411858032\n",
      "Epoch 55, Loss: 0.5084214594021681\n",
      "Epoch 56, Loss: 0.5053085214697696\n",
      "Epoch 57, Loss: 0.5025106517649679\n",
      "Epoch 58, Loss: 0.49893138357449146\n",
      "Epoch 59, Loss: 0.49443545988161314\n",
      "Epoch 60, Loss: 0.48986897015784503\n",
      "Epoch 61, Loss: 0.4860329402407822\n",
      "Epoch 62, Loss: 0.4827336373472466\n",
      "Epoch 63, Loss: 0.47938317265811525\n",
      "Epoch 64, Loss: 0.4761143124643508\n",
      "Epoch 65, Loss: 0.473921304520868\n",
      "Epoch 66, Loss: 0.4727775796322545\n",
      "Epoch 67, Loss: 0.47111311346085644\n",
      "Epoch 68, Loss: 0.46907731390528074\n",
      "Epoch 69, Loss: 0.46832247947467076\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22258403088583056\n",
      "Test R^2 score: 0.4633074607894256\n",
      "Num of epochs: 70\n",
      "Epoch 1, Loss: 0.5638079800785624\n",
      "Epoch 2, Loss: 0.5629105129606784\n",
      "Epoch 3, Loss: 0.562077814187717\n",
      "Epoch 4, Loss: 0.5613095879729285\n",
      "Epoch 5, Loss: 0.5606053019521612\n",
      "Epoch 6, Loss: 0.5599768262138445\n",
      "Epoch 7, Loss: 0.5594113641778632\n",
      "Epoch 8, Loss: 0.5589114799393455\n",
      "Epoch 9, Loss: 0.5584580583422525\n",
      "Epoch 10, Loss: 0.5580508121082969\n",
      "Epoch 11, Loss: 0.5576889606522112\n",
      "Epoch 12, Loss: 0.557371389325585\n",
      "Epoch 13, Loss: 0.5570966224778242\n",
      "Epoch 14, Loss: 0.5568627432984596\n",
      "Epoch 15, Loss: 0.5566751569778112\n",
      "Epoch 16, Loss: 0.556521807922775\n",
      "Epoch 17, Loss: 0.5564040367213137\n",
      "Epoch 18, Loss: 0.556313562511959\n",
      "Epoch 19, Loss: 0.5562472643409923\n",
      "Epoch 20, Loss: 0.556201721625148\n",
      "Epoch 21, Loss: 0.5561735368530463\n",
      "Epoch 22, Loss: 0.5561594171384033\n",
      "Epoch 23, Loss: 0.5561562019730086\n",
      "Epoch 24, Loss: 0.5561605424419003\n",
      "Epoch 25, Loss: 0.5561690625230677\n",
      "Epoch 26, Loss: 0.5561786809484208\n",
      "Epoch 27, Loss: 0.5561866113355769\n",
      "Epoch 28, Loss: 0.5561903621549786\n",
      "Epoch 29, Loss: 0.5561877097924494\n",
      "Epoch 30, Loss: 0.5561766447496909\n",
      "Epoch 31, Loss: 0.5561558000760274\n",
      "Epoch 32, Loss: 0.5561238617339846\n",
      "Epoch 33, Loss: 0.556079300394997\n",
      "Epoch 34, Loss: 0.5560195938575452\n",
      "Epoch 35, Loss: 0.555942968220485\n",
      "Epoch 36, Loss: 0.5558463335685462\n",
      "Epoch 37, Loss: 0.5557262204874794\n",
      "Epoch 38, Loss: 0.5555776787035213\n",
      "Epoch 39, Loss: 0.5553883973282351\n",
      "Epoch 40, Loss: 0.5551377202040968\n",
      "Epoch 41, Loss: 0.5548126724206799\n",
      "Epoch 42, Loss: 0.5544131769240284\n",
      "Epoch 43, Loss: 0.5539354410805756\n",
      "Epoch 44, Loss: 0.5533645596033111\n",
      "Epoch 45, Loss: 0.5527108123393949\n",
      "Epoch 46, Loss: 0.5519701523796753\n",
      "Epoch 47, Loss: 0.5511069450821275\n",
      "Epoch 48, Loss: 0.5500247169489393\n",
      "Epoch 49, Loss: 0.5486301866131061\n",
      "Epoch 50, Loss: 0.5468093015171955\n",
      "Epoch 51, Loss: 0.5444642746837819\n",
      "Epoch 52, Loss: 0.5414954306074183\n",
      "Epoch 53, Loss: 0.5377854409911003\n",
      "Epoch 54, Loss: 0.5332560251005567\n",
      "Epoch 55, Loss: 0.5280039575222562\n",
      "Epoch 56, Loss: 0.5225494594984004\n",
      "Epoch 57, Loss: 0.5181706042403416\n",
      "Epoch 58, Loss: 0.5171576753527883\n",
      "Epoch 59, Loss: 0.5189483355346884\n",
      "Epoch 60, Loss: 0.5176251659968796\n",
      "Epoch 61, Loss: 0.5132702029358879\n",
      "Epoch 62, Loss: 0.5088272812559728\n",
      "Epoch 63, Loss: 0.5058473563515544\n",
      "Epoch 64, Loss: 0.5041649915599056\n",
      "Epoch 65, Loss: 0.5029104877251422\n",
      "Epoch 66, Loss: 0.5012917224424353\n",
      "Epoch 67, Loss: 0.49900107137645305\n",
      "Epoch 68, Loss: 0.4961720802764396\n",
      "Epoch 69, Loss: 0.4930799506947507\n",
      "Epoch 70, Loss: 0.4901266093559666\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.23943485996490935\n",
      "Test R^2 score: 0.3816918160528826\n",
      "Num of epochs: 71\n",
      "Epoch 1, Loss: 0.5564017067530663\n",
      "Epoch 2, Loss: 0.5562205553298235\n",
      "Epoch 3, Loss: 0.5561666779852021\n",
      "Epoch 4, Loss: 0.556191246273011\n",
      "Epoch 5, Loss: 0.5562234486447286\n",
      "Epoch 6, Loss: 0.5562192426171718\n",
      "Epoch 7, Loss: 0.5561858611686611\n",
      "Epoch 8, Loss: 0.5561429124255183\n",
      "Epoch 9, Loss: 0.5561052391192342\n",
      "Epoch 10, Loss: 0.5560783357083634\n",
      "Epoch 11, Loss: 0.5560572729663614\n",
      "Epoch 12, Loss: 0.5560317071923405\n",
      "Epoch 13, Loss: 0.5559903546103876\n",
      "Epoch 14, Loss: 0.5559261622352972\n",
      "Epoch 15, Loss: 0.5558368970517475\n",
      "Epoch 16, Loss: 0.5557213403448027\n",
      "Epoch 17, Loss: 0.5555761499031586\n",
      "Epoch 18, Loss: 0.5553946218911554\n",
      "Epoch 19, Loss: 0.5551666554260406\n",
      "Epoch 20, Loss: 0.5548665201063802\n",
      "Epoch 21, Loss: 0.5544807962320439\n",
      "Epoch 22, Loss: 0.5539994606607614\n",
      "Epoch 23, Loss: 0.5533971957280777\n",
      "Epoch 24, Loss: 0.5526452953146997\n",
      "Epoch 25, Loss: 0.5517172199272345\n",
      "Epoch 26, Loss: 0.5506009286907996\n",
      "Epoch 27, Loss: 0.5492967390142454\n",
      "Epoch 28, Loss: 0.5478205544575426\n",
      "Epoch 29, Loss: 0.5461866679021012\n",
      "Epoch 30, Loss: 0.5443581841080025\n",
      "Epoch 31, Loss: 0.5423308268254479\n",
      "Epoch 32, Loss: 0.5400692481215451\n",
      "Epoch 33, Loss: 0.5375342613212599\n",
      "Epoch 34, Loss: 0.5346785313507884\n",
      "Epoch 35, Loss: 0.5314436447414599\n",
      "Epoch 36, Loss: 0.5277759899839717\n",
      "Epoch 37, Loss: 0.5236824373537062\n",
      "Epoch 38, Loss: 0.5190793990864244\n",
      "Epoch 39, Loss: 0.5139247141484748\n",
      "Epoch 40, Loss: 0.508221622866357\n",
      "Epoch 41, Loss: 0.5021200533322425\n",
      "Epoch 42, Loss: 0.4960049527213256\n",
      "Epoch 43, Loss: 0.4906105027213318\n",
      "Epoch 44, Loss: 0.4868675518812841\n",
      "Epoch 45, Loss: 0.48478884091910945\n",
      "Epoch 46, Loss: 0.4823712774144462\n",
      "Epoch 47, Loss: 0.47894019151299966\n",
      "Epoch 48, Loss: 0.475255879071317\n",
      "Epoch 49, Loss: 0.47210225828552205\n",
      "Epoch 50, Loss: 0.4700887160322986\n",
      "Epoch 51, Loss: 0.4692386940786588\n",
      "Epoch 52, Loss: 0.46887032236152315\n",
      "Epoch 53, Loss: 0.46892364782378504\n",
      "Epoch 54, Loss: 0.4684224891929604\n",
      "Epoch 55, Loss: 0.4679921222384427\n",
      "Epoch 56, Loss: 0.46670168939652096\n",
      "Epoch 57, Loss: 0.46548211318314187\n",
      "Epoch 58, Loss: 0.4640960289501879\n",
      "Epoch 59, Loss: 0.46277241867492946\n",
      "Epoch 60, Loss: 0.4614045476316883\n",
      "Epoch 61, Loss: 0.46002261645239256\n",
      "Epoch 62, Loss: 0.4586799748478243\n",
      "Epoch 63, Loss: 0.4576260860943924\n",
      "Epoch 64, Loss: 0.45659321391187946\n",
      "Epoch 65, Loss: 0.4557399603155856\n",
      "Epoch 66, Loss: 0.45488189592346906\n",
      "Epoch 67, Loss: 0.45420394891717114\n",
      "Epoch 68, Loss: 0.45335357754340094\n",
      "Epoch 69, Loss: 0.4525059055238067\n",
      "Epoch 70, Loss: 0.45172959902180476\n",
      "Epoch 71, Loss: 0.45103174981307803\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2153522982678325\n",
      "Test R^2 score: 0.4981562017447203\n",
      "Num of epochs: 72\n",
      "Epoch 1, Loss: 0.576846513344457\n",
      "Epoch 2, Loss: 0.5742911468332279\n",
      "Epoch 3, Loss: 0.5719002869231933\n",
      "Epoch 4, Loss: 0.5696797714922838\n",
      "Epoch 5, Loss: 0.5676467202959328\n",
      "Epoch 6, Loss: 0.5658112393205782\n",
      "Epoch 7, Loss: 0.5641549190564072\n",
      "Epoch 8, Loss: 0.5626729063679421\n",
      "Epoch 9, Loss: 0.5613682540746453\n",
      "Epoch 10, Loss: 0.5602417756872378\n",
      "Epoch 11, Loss: 0.5592975584159988\n",
      "Epoch 12, Loss: 0.5585411420471316\n",
      "Epoch 13, Loss: 0.5579345655051101\n",
      "Epoch 14, Loss: 0.5574592593835188\n",
      "Epoch 15, Loss: 0.5571023999928874\n",
      "Epoch 16, Loss: 0.5568614053404731\n",
      "Epoch 17, Loss: 0.556703343120683\n",
      "Epoch 18, Loss: 0.5566035743562971\n",
      "Epoch 19, Loss: 0.5565474850547829\n",
      "Epoch 20, Loss: 0.5565174167200542\n",
      "Epoch 21, Loss: 0.5565028505312292\n",
      "Epoch 22, Loss: 0.5564944158909696\n",
      "Epoch 23, Loss: 0.5564850171412284\n",
      "Epoch 24, Loss: 0.5564692718714209\n",
      "Epoch 25, Loss: 0.5564429484270622\n",
      "Epoch 26, Loss: 0.556403849252965\n",
      "Epoch 27, Loss: 0.5563507931717777\n",
      "Epoch 28, Loss: 0.5562820618208171\n",
      "Epoch 29, Loss: 0.5561945148183829\n",
      "Epoch 30, Loss: 0.5561014877256906\n",
      "Epoch 31, Loss: 0.5559972424541674\n",
      "Epoch 32, Loss: 0.555880888082288\n",
      "Epoch 33, Loss: 0.5557505937453859\n",
      "Epoch 34, Loss: 0.555602997171476\n",
      "Epoch 35, Loss: 0.5554340335604283\n",
      "Epoch 36, Loss: 0.5552383159488465\n",
      "Epoch 37, Loss: 0.5550020695982827\n",
      "Epoch 38, Loss: 0.5547130471377437\n",
      "Epoch 39, Loss: 0.5543606023198291\n",
      "Epoch 40, Loss: 0.5539351989756838\n",
      "Epoch 41, Loss: 0.5534209714949088\n",
      "Epoch 42, Loss: 0.5528016335911082\n",
      "Epoch 43, Loss: 0.5520515132826994\n",
      "Epoch 44, Loss: 0.5511390119308439\n",
      "Epoch 45, Loss: 0.5500454417876648\n",
      "Epoch 46, Loss: 0.5487840845215017\n",
      "Epoch 47, Loss: 0.547328706273784\n",
      "Epoch 48, Loss: 0.5456423901105829\n",
      "Epoch 49, Loss: 0.5436295255295898\n",
      "Epoch 50, Loss: 0.5413226141465374\n",
      "Epoch 51, Loss: 0.5386343651783125\n",
      "Epoch 52, Loss: 0.5354359863249167\n",
      "Epoch 53, Loss: 0.531580541664484\n",
      "Epoch 54, Loss: 0.5269823036570498\n",
      "Epoch 55, Loss: 0.5216198577334868\n",
      "Epoch 56, Loss: 0.5155004293068135\n",
      "Epoch 57, Loss: 0.5085404094142393\n",
      "Epoch 58, Loss: 0.5010611479442275\n",
      "Epoch 59, Loss: 0.4937379425121789\n",
      "Epoch 60, Loss: 0.4877007505138896\n",
      "Epoch 61, Loss: 0.48466313928691784\n",
      "Epoch 62, Loss: 0.48443069445451425\n",
      "Epoch 63, Loss: 0.48413222904752196\n",
      "Epoch 64, Loss: 0.4822158991521919\n",
      "Epoch 65, Loss: 0.4801772248900247\n",
      "Epoch 66, Loss: 0.4790818115094527\n",
      "Epoch 67, Loss: 0.4785126355136209\n",
      "Epoch 68, Loss: 0.4775910456472952\n",
      "Epoch 69, Loss: 0.47637110134141986\n",
      "Epoch 70, Loss: 0.4750861924171344\n",
      "Epoch 71, Loss: 0.4737073544706244\n",
      "Epoch 72, Loss: 0.47226006478569565\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22469374881254253\n",
      "Test R^2 score: 0.45464782472622184\n",
      "Num of epochs: 73\n",
      "Epoch 1, Loss: 0.5590559640995978\n",
      "Epoch 2, Loss: 0.5583073608800759\n",
      "Epoch 3, Loss: 0.5576740777011009\n",
      "Epoch 4, Loss: 0.557154314697095\n",
      "Epoch 5, Loss: 0.5567461683366715\n",
      "Epoch 6, Loss: 0.5564590961199233\n",
      "Epoch 7, Loss: 0.5562688288555812\n",
      "Epoch 8, Loss: 0.5561659277914\n",
      "Epoch 9, Loss: 0.5561421621996582\n",
      "Epoch 10, Loss: 0.5561671066669206\n",
      "Epoch 11, Loss: 0.5562178763211215\n",
      "Epoch 12, Loss: 0.55627156119403\n",
      "Epoch 13, Loss: 0.5563018838923578\n",
      "Epoch 14, Loss: 0.5562995802824777\n",
      "Epoch 15, Loss: 0.5562555955755415\n",
      "Epoch 16, Loss: 0.5561684462951608\n",
      "Epoch 17, Loss: 0.5560407116242039\n",
      "Epoch 18, Loss: 0.5558780197909049\n",
      "Epoch 19, Loss: 0.5556826998999189\n",
      "Epoch 20, Loss: 0.5554539127219253\n",
      "Epoch 21, Loss: 0.5551886645108075\n",
      "Epoch 22, Loss: 0.5548818543267092\n",
      "Epoch 23, Loss: 0.5545231212924148\n",
      "Epoch 24, Loss: 0.5541031405480564\n",
      "Epoch 25, Loss: 0.5536085838162993\n",
      "Epoch 26, Loss: 0.5530209017713021\n",
      "Epoch 27, Loss: 0.5523150575515362\n",
      "Epoch 28, Loss: 0.5514641174235965\n",
      "Epoch 29, Loss: 0.5504511662494683\n",
      "Epoch 30, Loss: 0.5492755789949354\n",
      "Epoch 31, Loss: 0.5478945900515069\n",
      "Epoch 32, Loss: 0.5462332365924981\n",
      "Epoch 33, Loss: 0.5442166978357631\n",
      "Epoch 34, Loss: 0.5417900189527681\n",
      "Epoch 35, Loss: 0.538899936213218\n",
      "Epoch 36, Loss: 0.5354684350731054\n",
      "Epoch 37, Loss: 0.5314354853227927\n",
      "Epoch 38, Loss: 0.5267972869848807\n",
      "Epoch 39, Loss: 0.5216799879912293\n",
      "Epoch 40, Loss: 0.5162447470520113\n",
      "Epoch 41, Loss: 0.5106138283244018\n",
      "Epoch 42, Loss: 0.5048361190365571\n",
      "Epoch 43, Loss: 0.49904822121905035\n",
      "Epoch 44, Loss: 0.49397466533867135\n",
      "Epoch 45, Loss: 0.49068826583376907\n",
      "Epoch 46, Loss: 0.48948027831532664\n",
      "Epoch 47, Loss: 0.48815687502874794\n",
      "Epoch 48, Loss: 0.4853045097277917\n",
      "Epoch 49, Loss: 0.482014750688252\n",
      "Epoch 50, Loss: 0.4798689719514854\n",
      "Epoch 51, Loss: 0.47905403520405354\n",
      "Epoch 52, Loss: 0.4782958635442442\n",
      "Epoch 53, Loss: 0.4767773097207302\n",
      "Epoch 54, Loss: 0.47519962671017196\n",
      "Epoch 55, Loss: 0.4753160278670929\n",
      "Epoch 56, Loss: 0.4744126339887374\n",
      "Epoch 57, Loss: 0.47237488750326206\n",
      "Epoch 58, Loss: 0.4708665746021644\n",
      "Epoch 59, Loss: 0.4705287246205636\n",
      "Epoch 60, Loss: 0.470188080688548\n",
      "Epoch 61, Loss: 0.4692278969019567\n",
      "Epoch 62, Loss: 0.4682208412315679\n",
      "Epoch 63, Loss: 0.46758216977262196\n",
      "Epoch 64, Loss: 0.4669843161704133\n",
      "Epoch 65, Loss: 0.46605873004482806\n",
      "Epoch 66, Loss: 0.46514618275505215\n",
      "Epoch 67, Loss: 0.46460799642139927\n",
      "Epoch 68, Loss: 0.46413975788594725\n",
      "Epoch 69, Loss: 0.46338918049459155\n",
      "Epoch 70, Loss: 0.46239523796575444\n",
      "Epoch 71, Loss: 0.46153364585922546\n",
      "Epoch 72, Loss: 0.4609250859027453\n",
      "Epoch 73, Loss: 0.4602553120119548\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22061729375599276\n",
      "Test R^2 score: 0.47311858059328016\n",
      "Num of epochs: 74\n",
      "Epoch 1, Loss: 0.5798945023928153\n",
      "Epoch 2, Loss: 0.5783649410612229\n",
      "Epoch 3, Loss: 0.5769019463838728\n",
      "Epoch 4, Loss: 0.5754776214901832\n",
      "Epoch 5, Loss: 0.5741130705660688\n",
      "Epoch 6, Loss: 0.5728083045668476\n",
      "Epoch 7, Loss: 0.5715768724890135\n",
      "Epoch 8, Loss: 0.5704049858455854\n",
      "Epoch 9, Loss: 0.5692926459104971\n",
      "Epoch 10, Loss: 0.5682601579932167\n",
      "Epoch 11, Loss: 0.5673003932950845\n",
      "Epoch 12, Loss: 0.5663793360136472\n",
      "Epoch 13, Loss: 0.5655019183628048\n",
      "Epoch 14, Loss: 0.5646689771138063\n",
      "Epoch 15, Loss: 0.5638799694318398\n",
      "Epoch 16, Loss: 0.5631206585106006\n",
      "Epoch 17, Loss: 0.5623968877592292\n",
      "Epoch 18, Loss: 0.56171049236653\n",
      "Epoch 19, Loss: 0.5610487283072675\n",
      "Epoch 20, Loss: 0.5604152990227594\n",
      "Epoch 21, Loss: 0.5598084374165713\n",
      "Epoch 22, Loss: 0.559224952520532\n",
      "Epoch 23, Loss: 0.5586613967589292\n",
      "Epoch 24, Loss: 0.5581077916054433\n",
      "Epoch 25, Loss: 0.5575531556999469\n",
      "Epoch 26, Loss: 0.5569913060658658\n",
      "Epoch 27, Loss: 0.5564076789509808\n",
      "Epoch 28, Loss: 0.5558001145536038\n",
      "Epoch 29, Loss: 0.5551532885072257\n",
      "Epoch 30, Loss: 0.5544280399035337\n",
      "Epoch 31, Loss: 0.5535839816617043\n",
      "Epoch 32, Loss: 0.552592660374865\n",
      "Epoch 33, Loss: 0.551442743327698\n",
      "Epoch 34, Loss: 0.5500933903820455\n",
      "Epoch 35, Loss: 0.5485778998396995\n",
      "Epoch 36, Loss: 0.5468753269739536\n",
      "Epoch 37, Loss: 0.5449068074211223\n",
      "Epoch 38, Loss: 0.5426249616386085\n",
      "Epoch 39, Loss: 0.5400350615368716\n",
      "Epoch 40, Loss: 0.5372475741062273\n",
      "Epoch 41, Loss: 0.5346184694552653\n",
      "Epoch 42, Loss: 0.5327963482598437\n",
      "Epoch 43, Loss: 0.5323882531054548\n",
      "Epoch 44, Loss: 0.5324012119820383\n",
      "Epoch 45, Loss: 0.5309559906091081\n",
      "Epoch 46, Loss: 0.5282787088030103\n",
      "Epoch 47, Loss: 0.5255090516215507\n",
      "Epoch 48, Loss: 0.5233914084567154\n",
      "Epoch 49, Loss: 0.5220117652451445\n",
      "Epoch 50, Loss: 0.5210184880800185\n",
      "Epoch 51, Loss: 0.5199773207175411\n",
      "Epoch 52, Loss: 0.5185913820089105\n",
      "Epoch 53, Loss: 0.5168526513412416\n",
      "Epoch 54, Loss: 0.5148894236193524\n",
      "Epoch 55, Loss: 0.5129444788414699\n",
      "Epoch 56, Loss: 0.5112584205717442\n",
      "Epoch 57, Loss: 0.5099787650175388\n",
      "Epoch 58, Loss: 0.5089417153527858\n",
      "Epoch 59, Loss: 0.5077303012931591\n",
      "Epoch 60, Loss: 0.5061290419858306\n",
      "Epoch 61, Loss: 0.5043757713056715\n",
      "Epoch 62, Loss: 0.5028061798438199\n",
      "Epoch 63, Loss: 0.5015214481369271\n",
      "Epoch 64, Loss: 0.5003626819345621\n",
      "Epoch 65, Loss: 0.4990892908051048\n",
      "Epoch 66, Loss: 0.4975920301888118\n",
      "Epoch 67, Loss: 0.4959873325620364\n",
      "Epoch 68, Loss: 0.4944657775060518\n",
      "Epoch 69, Loss: 0.4931714652232922\n",
      "Epoch 70, Loss: 0.4919908372861258\n",
      "Epoch 71, Loss: 0.4906654590276744\n",
      "Epoch 72, Loss: 0.48920070292039464\n",
      "Epoch 73, Loss: 0.487803095348738\n",
      "Epoch 74, Loss: 0.48653513168069423\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.24027481409828916\n",
      "Test R^2 score: 0.3746258074295084\n",
      "Num of epochs: 75\n",
      "Epoch 1, Loss: 0.5678772339689803\n",
      "Epoch 2, Loss: 0.5667080042524691\n",
      "Epoch 3, Loss: 0.5656114724159159\n",
      "Epoch 4, Loss: 0.5645840766826771\n",
      "Epoch 5, Loss: 0.5636313505138567\n",
      "Epoch 6, Loss: 0.5627537790660485\n",
      "Epoch 7, Loss: 0.5619287238994423\n",
      "Epoch 8, Loss: 0.5611547968349005\n",
      "Epoch 9, Loss: 0.5604321299219382\n",
      "Epoch 10, Loss: 0.5597620397587366\n",
      "Epoch 11, Loss: 0.5591563612655813\n",
      "Epoch 12, Loss: 0.5586518210790157\n",
      "Epoch 13, Loss: 0.558194744882753\n",
      "Epoch 14, Loss: 0.5577869858236063\n",
      "Epoch 15, Loss: 0.5574524430659645\n",
      "Epoch 16, Loss: 0.5571480295575212\n",
      "Epoch 17, Loss: 0.5568970206859296\n",
      "Epoch 18, Loss: 0.5566823040265859\n",
      "Epoch 19, Loss: 0.5565012974959582\n",
      "Epoch 20, Loss: 0.5563607834212588\n",
      "Epoch 21, Loss: 0.5562573903910853\n",
      "Epoch 22, Loss: 0.5561899334911844\n",
      "Epoch 23, Loss: 0.5561520490235309\n",
      "Epoch 24, Loss: 0.5561399115160054\n",
      "Epoch 25, Loss: 0.5561506825624061\n",
      "Epoch 26, Loss: 0.5561675085557314\n",
      "Epoch 27, Loss: 0.5561889957879826\n",
      "Epoch 28, Loss: 0.5562092230348641\n",
      "Epoch 29, Loss: 0.5562214126098829\n",
      "Epoch 30, Loss: 0.5562197784186284\n",
      "Epoch 31, Loss: 0.5561936039142262\n",
      "Epoch 32, Loss: 0.556136240738601\n",
      "Epoch 33, Loss: 0.5560636776249976\n",
      "Epoch 34, Loss: 0.5559839491071068\n",
      "Epoch 35, Loss: 0.5558796817933227\n",
      "Epoch 36, Loss: 0.5557454993133956\n",
      "Epoch 37, Loss: 0.5555760426187647\n",
      "Epoch 38, Loss: 0.5553682475103455\n",
      "Epoch 39, Loss: 0.5551233862424164\n",
      "Epoch 40, Loss: 0.5548236035207843\n",
      "Epoch 41, Loss: 0.5544514489602079\n",
      "Epoch 42, Loss: 0.5539865766424227\n",
      "Epoch 43, Loss: 0.5534041427735036\n",
      "Epoch 44, Loss: 0.5526889202716977\n",
      "Epoch 45, Loss: 0.5518235429079452\n",
      "Epoch 46, Loss: 0.550735715241879\n",
      "Epoch 47, Loss: 0.5493952308896335\n",
      "Epoch 48, Loss: 0.5478188952058004\n",
      "Epoch 49, Loss: 0.5459926025846678\n",
      "Epoch 50, Loss: 0.5438384904875095\n",
      "Epoch 51, Loss: 0.5412598482165448\n",
      "Epoch 52, Loss: 0.5382237751122667\n",
      "Epoch 53, Loss: 0.5346440279403857\n",
      "Epoch 54, Loss: 0.5304450500317732\n",
      "Epoch 55, Loss: 0.5256424481175542\n",
      "Epoch 56, Loss: 0.5202175569257669\n",
      "Epoch 57, Loss: 0.5142233031820973\n",
      "Epoch 58, Loss: 0.5080250515298914\n",
      "Epoch 59, Loss: 0.5018010187312033\n",
      "Epoch 60, Loss: 0.49582615340935426\n",
      "Epoch 61, Loss: 0.49088774224362003\n",
      "Epoch 62, Loss: 0.48753599131823894\n",
      "Epoch 63, Loss: 0.48511829565615694\n",
      "Epoch 64, Loss: 0.483381929982703\n",
      "Epoch 65, Loss: 0.48295853761053165\n",
      "Epoch 66, Loss: 0.48171474198991826\n",
      "Epoch 67, Loss: 0.4785102065421856\n",
      "Epoch 68, Loss: 0.4751688167838256\n",
      "Epoch 69, Loss: 0.4740555754314879\n",
      "Epoch 70, Loss: 0.4753008385456039\n",
      "Epoch 71, Loss: 0.47451629039809823\n",
      "Epoch 72, Loss: 0.47294952814760394\n",
      "Epoch 73, Loss: 0.47233365612494604\n",
      "Epoch 74, Loss: 0.4723538148383736\n",
      "Epoch 75, Loss: 0.4719584965885626\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2234313457877347\n",
      "Test R^2 score: 0.460212280519701\n",
      "Num of epochs: 76\n",
      "Epoch 1, Loss: 0.5910889322284708\n",
      "Epoch 2, Loss: 0.5883805270983898\n",
      "Epoch 3, Loss: 0.5857677468132182\n",
      "Epoch 4, Loss: 0.5832819717365973\n",
      "Epoch 5, Loss: 0.5808947431190207\n",
      "Epoch 6, Loss: 0.5785880167793223\n",
      "Epoch 7, Loss: 0.5764605558669857\n",
      "Epoch 8, Loss: 0.5744248364218664\n",
      "Epoch 9, Loss: 0.5724812644907935\n",
      "Epoch 10, Loss: 0.5705842977340806\n",
      "Epoch 11, Loss: 0.5688429672637351\n",
      "Epoch 12, Loss: 0.5672299413854259\n",
      "Epoch 13, Loss: 0.5657033044134919\n",
      "Epoch 14, Loss: 0.5642683261249688\n",
      "Epoch 15, Loss: 0.5629302075120063\n",
      "Epoch 16, Loss: 0.5616946548153936\n",
      "Epoch 17, Loss: 0.5605628247268082\n",
      "Epoch 18, Loss: 0.5595278099655252\n",
      "Epoch 19, Loss: 0.5585850801662058\n",
      "Epoch 20, Loss: 0.5577494235666289\n",
      "Epoch 21, Loss: 0.557031032781572\n",
      "Epoch 22, Loss: 0.5564383691452935\n",
      "Epoch 23, Loss: 0.5559448176519391\n",
      "Epoch 24, Loss: 0.5555595205748315\n",
      "Epoch 25, Loss: 0.5552462329298737\n",
      "Epoch 26, Loss: 0.554944126779142\n",
      "Epoch 27, Loss: 0.5546402440962701\n",
      "Epoch 28, Loss: 0.5543008988323767\n",
      "Epoch 29, Loss: 0.5538858073649536\n",
      "Epoch 30, Loss: 0.5533453055411777\n",
      "Epoch 31, Loss: 0.5526345098747604\n",
      "Epoch 32, Loss: 0.5517111969557479\n",
      "Epoch 33, Loss: 0.5505328869710585\n",
      "Epoch 34, Loss: 0.5490542994469216\n",
      "Epoch 35, Loss: 0.5471987447231378\n",
      "Epoch 36, Loss: 0.5448645284687458\n",
      "Epoch 37, Loss: 0.5420078034771745\n",
      "Epoch 38, Loss: 0.538613228928458\n",
      "Epoch 39, Loss: 0.5348779831990536\n",
      "Epoch 40, Loss: 0.5313272139590944\n",
      "Epoch 41, Loss: 0.5287315192724207\n",
      "Epoch 42, Loss: 0.5275614536339649\n",
      "Epoch 43, Loss: 0.5263126606910967\n",
      "Epoch 44, Loss: 0.5232978178939942\n",
      "Epoch 45, Loss: 0.5194489836990295\n",
      "Epoch 46, Loss: 0.5162656734110125\n",
      "Epoch 47, Loss: 0.5142026994136549\n",
      "Epoch 48, Loss: 0.5127065602839861\n",
      "Epoch 49, Loss: 0.5110522873287147\n",
      "Epoch 50, Loss: 0.5088955114377687\n",
      "Epoch 51, Loss: 0.5062518272837875\n",
      "Epoch 52, Loss: 0.5035686692855048\n",
      "Epoch 53, Loss: 0.5013914416709906\n",
      "Epoch 54, Loss: 0.49984537654420075\n",
      "Epoch 55, Loss: 0.49827186140209107\n",
      "Epoch 56, Loss: 0.49603889943066215\n",
      "Epoch 57, Loss: 0.4936213271361103\n",
      "Epoch 58, Loss: 0.49170449186829257\n",
      "Epoch 59, Loss: 0.49025028704469986\n",
      "Epoch 60, Loss: 0.4887169686787521\n",
      "Epoch 61, Loss: 0.4868243799350512\n",
      "Epoch 62, Loss: 0.4848258320002011\n",
      "Epoch 63, Loss: 0.48319532963255396\n",
      "Epoch 64, Loss: 0.4818698643807776\n",
      "Epoch 65, Loss: 0.48024330432459955\n",
      "Epoch 66, Loss: 0.4783005834570725\n",
      "Epoch 67, Loss: 0.4765904058822219\n",
      "Epoch 68, Loss: 0.47508255404299315\n",
      "Epoch 69, Loss: 0.47338758589495566\n",
      "Epoch 70, Loss: 0.47149716275373826\n",
      "Epoch 71, Loss: 0.4698444147235315\n",
      "Epoch 72, Loss: 0.46856697005996406\n",
      "Epoch 73, Loss: 0.46724117953045863\n",
      "Epoch 74, Loss: 0.46584481548746104\n",
      "Epoch 75, Loss: 0.4646949209250504\n",
      "Epoch 76, Loss: 0.4635911943643583\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21585585682725017\n",
      "Test R^2 score: 0.495778022274542\n",
      "Num of epochs: 77\n",
      "Epoch 1, Loss: 0.579701927807524\n",
      "Epoch 2, Loss: 0.5776248263169147\n",
      "Epoch 3, Loss: 0.5756476911199795\n",
      "Epoch 4, Loss: 0.5737712699504619\n",
      "Epoch 5, Loss: 0.5719984817601442\n",
      "Epoch 6, Loss: 0.5703236827015269\n",
      "Epoch 7, Loss: 0.5687434678174179\n",
      "Epoch 8, Loss: 0.5672706322395795\n",
      "Epoch 9, Loss: 0.5658935857593678\n",
      "Epoch 10, Loss: 0.5646335617000711\n",
      "Epoch 11, Loss: 0.5634556440837271\n",
      "Epoch 12, Loss: 0.5623613557553054\n",
      "Epoch 13, Loss: 0.561376084606318\n",
      "Epoch 14, Loss: 0.5605134056812375\n",
      "Epoch 15, Loss: 0.5597120974197914\n",
      "Epoch 16, Loss: 0.5589904443609943\n",
      "Epoch 17, Loss: 0.5583558009262634\n",
      "Epoch 18, Loss: 0.5577875468338767\n",
      "Epoch 19, Loss: 0.5573495466413714\n",
      "Epoch 20, Loss: 0.5569241521102903\n",
      "Epoch 21, Loss: 0.5565163724655271\n",
      "Epoch 22, Loss: 0.5561241028860568\n",
      "Epoch 23, Loss: 0.5557643484785021\n",
      "Epoch 24, Loss: 0.555442725750964\n",
      "Epoch 25, Loss: 0.555144511258975\n",
      "Epoch 26, Loss: 0.5548080796829191\n",
      "Epoch 27, Loss: 0.5543633171837444\n",
      "Epoch 28, Loss: 0.5537214059529736\n",
      "Epoch 29, Loss: 0.5527910938075471\n",
      "Epoch 30, Loss: 0.5514387980816265\n",
      "Epoch 31, Loss: 0.549569033705918\n",
      "Epoch 32, Loss: 0.5470540979577584\n",
      "Epoch 33, Loss: 0.5440018246125728\n",
      "Epoch 34, Loss: 0.5405437187877858\n",
      "Epoch 35, Loss: 0.5365615270180343\n",
      "Epoch 36, Loss: 0.5324971482375171\n",
      "Epoch 37, Loss: 0.5292206037121168\n",
      "Epoch 38, Loss: 0.5280373144998625\n",
      "Epoch 39, Loss: 0.5283705146333847\n",
      "Epoch 40, Loss: 0.5267693393508317\n",
      "Epoch 41, Loss: 0.5229714724581257\n",
      "Epoch 42, Loss: 0.5191516780322449\n",
      "Epoch 43, Loss: 0.5168214845456505\n",
      "Epoch 44, Loss: 0.5154994175886385\n",
      "Epoch 45, Loss: 0.5144417798435823\n",
      "Epoch 46, Loss: 0.5130025179412648\n",
      "Epoch 47, Loss: 0.5109561741767304\n",
      "Epoch 48, Loss: 0.5084152459243175\n",
      "Epoch 49, Loss: 0.5058449408044136\n",
      "Epoch 50, Loss: 0.5037384049380317\n",
      "Epoch 51, Loss: 0.5023020856080757\n",
      "Epoch 52, Loss: 0.5011175303084437\n",
      "Epoch 53, Loss: 0.4994220821018683\n",
      "Epoch 54, Loss: 0.4972597821559888\n",
      "Epoch 55, Loss: 0.4952598983077812\n",
      "Epoch 56, Loss: 0.4937618749132147\n",
      "Epoch 57, Loss: 0.4925794705789264\n",
      "Epoch 58, Loss: 0.4912622929265295\n",
      "Epoch 59, Loss: 0.48962018875298097\n",
      "Epoch 60, Loss: 0.4878284796541856\n",
      "Epoch 61, Loss: 0.48623659429237076\n",
      "Epoch 62, Loss: 0.48500181986772123\n",
      "Epoch 63, Loss: 0.48380951020046686\n",
      "Epoch 64, Loss: 0.48232306885567744\n",
      "Epoch 65, Loss: 0.48069923579097923\n",
      "Epoch 66, Loss: 0.47929455943896776\n",
      "Epoch 67, Loss: 0.4780998447757063\n",
      "Epoch 68, Loss: 0.4768493914446408\n",
      "Epoch 69, Loss: 0.4754129365372935\n",
      "Epoch 70, Loss: 0.4739824243508223\n",
      "Epoch 71, Loss: 0.4727044199208115\n",
      "Epoch 72, Loss: 0.47151370711846236\n",
      "Epoch 73, Loss: 0.4702185673234496\n",
      "Epoch 74, Loss: 0.46884459494743647\n",
      "Epoch 75, Loss: 0.4675802417219622\n",
      "Epoch 76, Loss: 0.4664503431324449\n",
      "Epoch 77, Loss: 0.4652898715315299\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21873404722439252\n",
      "Test R^2 score: 0.4804267868347989\n",
      "Num of epochs: 78\n",
      "Epoch 1, Loss: 0.5816840345837507\n",
      "Epoch 2, Loss: 0.5791570627207543\n",
      "Epoch 3, Loss: 0.5767741272372804\n",
      "Epoch 4, Loss: 0.5745267236783915\n",
      "Epoch 5, Loss: 0.5724134026545091\n",
      "Epoch 6, Loss: 0.5704089566534745\n",
      "Epoch 7, Loss: 0.56846423672905\n",
      "Epoch 8, Loss: 0.5666345333590826\n",
      "Epoch 9, Loss: 0.5650106666199477\n",
      "Epoch 10, Loss: 0.5634910541965017\n",
      "Epoch 11, Loss: 0.5620865361900311\n",
      "Epoch 12, Loss: 0.5608340866694084\n",
      "Epoch 13, Loss: 0.5596773800768338\n",
      "Epoch 14, Loss: 0.5586273076574634\n",
      "Epoch 15, Loss: 0.5576689206792438\n",
      "Epoch 16, Loss: 0.5569040846159912\n",
      "Epoch 17, Loss: 0.5563037857026283\n",
      "Epoch 18, Loss: 0.555753087318758\n",
      "Epoch 19, Loss: 0.5552891436867045\n",
      "Epoch 20, Loss: 0.5548744423922122\n",
      "Epoch 21, Loss: 0.5544869234883956\n",
      "Epoch 22, Loss: 0.5541249229608366\n",
      "Epoch 23, Loss: 0.5537707584098286\n",
      "Epoch 24, Loss: 0.5533820088599499\n",
      "Epoch 25, Loss: 0.5529023040059753\n",
      "Epoch 26, Loss: 0.5522787959689088\n",
      "Epoch 27, Loss: 0.551456065080179\n",
      "Epoch 28, Loss: 0.5503707329842185\n",
      "Epoch 29, Loss: 0.5489634282589286\n",
      "Epoch 30, Loss: 0.5471505969297633\n",
      "Epoch 31, Loss: 0.5448991230689302\n",
      "Epoch 32, Loss: 0.5422269295638369\n",
      "Epoch 33, Loss: 0.5391770669571797\n",
      "Epoch 34, Loss: 0.5356784695051177\n",
      "Epoch 35, Loss: 0.5317330408319739\n",
      "Epoch 36, Loss: 0.5273646880337665\n",
      "Epoch 37, Loss: 0.5227007734325461\n",
      "Epoch 38, Loss: 0.5182085624189863\n",
      "Epoch 39, Loss: 0.5148049393469524\n",
      "Epoch 40, Loss: 0.5132503157631878\n",
      "Epoch 41, Loss: 0.5120327401161338\n",
      "Epoch 42, Loss: 0.5089252604470071\n",
      "Epoch 43, Loss: 0.5045945250196382\n",
      "Epoch 44, Loss: 0.5007830686729603\n",
      "Epoch 45, Loss: 0.49839312914961814\n",
      "Epoch 46, Loss: 0.49697133036170676\n",
      "Epoch 47, Loss: 0.49564532039880305\n",
      "Epoch 48, Loss: 0.4936183838525283\n",
      "Epoch 49, Loss: 0.49094107402566545\n",
      "Epoch 50, Loss: 0.4881736026358872\n",
      "Epoch 51, Loss: 0.4860634907225177\n",
      "Epoch 52, Loss: 0.4849067507155721\n",
      "Epoch 53, Loss: 0.4839433623417866\n",
      "Epoch 54, Loss: 0.4822601788693925\n",
      "Epoch 55, Loss: 0.480096129785157\n",
      "Epoch 56, Loss: 0.47833922891217895\n",
      "Epoch 57, Loss: 0.4772371301029738\n",
      "Epoch 58, Loss: 0.47627226011563323\n",
      "Epoch 59, Loss: 0.4749767153453708\n",
      "Epoch 60, Loss: 0.47340382811908704\n",
      "Epoch 61, Loss: 0.47194122582350245\n",
      "Epoch 62, Loss: 0.4708255592762156\n",
      "Epoch 63, Loss: 0.4698298731265213\n",
      "Epoch 64, Loss: 0.4684815909902175\n",
      "Epoch 65, Loss: 0.4668531663224491\n",
      "Epoch 66, Loss: 0.4654071663143292\n",
      "Epoch 67, Loss: 0.464268015298842\n",
      "Epoch 68, Loss: 0.46315915330574386\n",
      "Epoch 69, Loss: 0.4619599817529358\n",
      "Epoch 70, Loss: 0.46086147457251764\n",
      "Epoch 71, Loss: 0.45962220371984064\n",
      "Epoch 72, Loss: 0.45827315397814217\n",
      "Epoch 73, Loss: 0.457314998216884\n",
      "Epoch 74, Loss: 0.4565859687669008\n",
      "Epoch 75, Loss: 0.455633454944251\n",
      "Epoch 76, Loss: 0.4546678191444934\n",
      "Epoch 77, Loss: 0.45392707015330913\n",
      "Epoch 78, Loss: 0.4530371219001596\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21251863544397795\n",
      "Test R^2 score: 0.5114869628339827\n",
      "Num of epochs: 79\n",
      "Epoch 1, Loss: 0.5926027759310605\n",
      "Epoch 2, Loss: 0.58991443134755\n",
      "Epoch 3, Loss: 0.5873409756054292\n",
      "Epoch 4, Loss: 0.5848672884200157\n",
      "Epoch 5, Loss: 0.582478703285527\n",
      "Epoch 6, Loss: 0.580171442713919\n",
      "Epoch 7, Loss: 0.5779484659736446\n",
      "Epoch 8, Loss: 0.5758422167111658\n",
      "Epoch 9, Loss: 0.5738743897777346\n",
      "Epoch 10, Loss: 0.572006010464121\n",
      "Epoch 11, Loss: 0.5702257743633177\n",
      "Epoch 12, Loss: 0.5685370256097768\n",
      "Epoch 13, Loss: 0.5669431575189654\n",
      "Epoch 14, Loss: 0.5654469752592493\n",
      "Epoch 15, Loss: 0.5640506827683125\n",
      "Epoch 16, Loss: 0.5627552618884808\n",
      "Epoch 17, Loss: 0.5615622598247407\n",
      "Epoch 18, Loss: 0.5604741916652877\n",
      "Epoch 19, Loss: 0.5594180500790595\n",
      "Epoch 20, Loss: 0.5584663299137549\n",
      "Epoch 21, Loss: 0.5576122437373201\n",
      "Epoch 22, Loss: 0.5568763635278314\n",
      "Epoch 23, Loss: 0.5563517038185714\n",
      "Epoch 24, Loss: 0.5558328489514042\n",
      "Epoch 25, Loss: 0.5553447697697559\n",
      "Epoch 26, Loss: 0.5549038210003248\n",
      "Epoch 27, Loss: 0.5544631128055232\n",
      "Epoch 28, Loss: 0.5539800672749634\n",
      "Epoch 29, Loss: 0.5534231524597449\n",
      "Epoch 30, Loss: 0.5527576401198461\n",
      "Epoch 31, Loss: 0.5519379448338676\n",
      "Epoch 32, Loss: 0.5509160735777663\n",
      "Epoch 33, Loss: 0.549630064530818\n",
      "Epoch 34, Loss: 0.5480099753303764\n",
      "Epoch 35, Loss: 0.5459940217602599\n",
      "Epoch 36, Loss: 0.5435483021280557\n",
      "Epoch 37, Loss: 0.5406737641849788\n",
      "Epoch 38, Loss: 0.5374427177157286\n",
      "Epoch 39, Loss: 0.5340657504961035\n",
      "Epoch 40, Loss: 0.5309378323882321\n",
      "Epoch 41, Loss: 0.5285111116271566\n",
      "Epoch 42, Loss: 0.5268348498901355\n",
      "Epoch 43, Loss: 0.5249278359543789\n",
      "Epoch 44, Loss: 0.5219695159846196\n",
      "Epoch 45, Loss: 0.5185172144681689\n",
      "Epoch 46, Loss: 0.515536185042624\n",
      "Epoch 47, Loss: 0.5133318627891698\n",
      "Epoch 48, Loss: 0.5116490032624358\n",
      "Epoch 49, Loss: 0.5098991073124027\n",
      "Epoch 50, Loss: 0.5077932794307995\n",
      "Epoch 51, Loss: 0.5054401737490063\n",
      "Epoch 52, Loss: 0.5032173000993032\n",
      "Epoch 53, Loss: 0.5014869811344964\n",
      "Epoch 54, Loss: 0.5001777392617974\n",
      "Epoch 55, Loss: 0.498708786277407\n",
      "Epoch 56, Loss: 0.4968008873806429\n",
      "Epoch 57, Loss: 0.49491331880394923\n",
      "Epoch 58, Loss: 0.4934690684245707\n",
      "Epoch 59, Loss: 0.4922851284021795\n",
      "Epoch 60, Loss: 0.49094277374815043\n",
      "Epoch 61, Loss: 0.48927211169516516\n",
      "Epoch 62, Loss: 0.4875235209537318\n",
      "Epoch 63, Loss: 0.48608499600637134\n",
      "Epoch 64, Loss: 0.48493569746639936\n",
      "Epoch 65, Loss: 0.4835767937123317\n",
      "Epoch 66, Loss: 0.4819492696977978\n",
      "Epoch 67, Loss: 0.4805326806931707\n",
      "Epoch 68, Loss: 0.4794329511486087\n",
      "Epoch 69, Loss: 0.4782739145588144\n",
      "Epoch 70, Loss: 0.4769330069683097\n",
      "Epoch 71, Loss: 0.47567403553095905\n",
      "Epoch 72, Loss: 0.47462954694163817\n",
      "Epoch 73, Loss: 0.47353498884069467\n",
      "Epoch 74, Loss: 0.4723223933705307\n",
      "Epoch 75, Loss: 0.4712437892120041\n",
      "Epoch 76, Loss: 0.47026506989550204\n",
      "Epoch 77, Loss: 0.4692108114500227\n",
      "Epoch 78, Loss: 0.4681089945757577\n",
      "Epoch 79, Loss: 0.4670681344836758\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21930023227301942\n",
      "Test R^2 score: 0.4798571113691376\n",
      "Num of epochs: 80\n",
      "Epoch 1, Loss: 0.561976904830647\n",
      "Epoch 2, Loss: 0.5609826444348358\n",
      "Epoch 3, Loss: 0.5600812885771352\n",
      "Epoch 4, Loss: 0.5592689701370671\n",
      "Epoch 5, Loss: 0.5585560819289779\n",
      "Epoch 6, Loss: 0.5579435926420726\n",
      "Epoch 7, Loss: 0.5574262729784046\n",
      "Epoch 8, Loss: 0.556995800543523\n",
      "Epoch 9, Loss: 0.5566527248205203\n",
      "Epoch 10, Loss: 0.5563759961107534\n",
      "Epoch 11, Loss: 0.5561674817631531\n",
      "Epoch 12, Loss: 0.5560320019825973\n",
      "Epoch 13, Loss: 0.5559346591047035\n",
      "Epoch 14, Loss: 0.5558611850347155\n",
      "Epoch 15, Loss: 0.5557993906753539\n",
      "Epoch 16, Loss: 0.5557309397055726\n",
      "Epoch 17, Loss: 0.5556302454199852\n",
      "Epoch 18, Loss: 0.5554998386444626\n",
      "Epoch 19, Loss: 0.5553204860338418\n",
      "Epoch 20, Loss: 0.5550605164432209\n",
      "Epoch 21, Loss: 0.5547028660324875\n",
      "Epoch 22, Loss: 0.554237156044233\n",
      "Epoch 23, Loss: 0.5536403173660527\n",
      "Epoch 24, Loss: 0.5528889092945248\n",
      "Epoch 25, Loss: 0.5520006573749167\n",
      "Epoch 26, Loss: 0.5509108803431316\n",
      "Epoch 27, Loss: 0.5495660782429317\n",
      "Epoch 28, Loss: 0.5479231190996539\n",
      "Epoch 29, Loss: 0.5459274256998975\n",
      "Epoch 30, Loss: 0.5435382682905576\n",
      "Epoch 31, Loss: 0.5407241697257495\n",
      "Epoch 32, Loss: 0.537361585182977\n",
      "Epoch 33, Loss: 0.5333959209951279\n",
      "Epoch 34, Loss: 0.5288524944085379\n",
      "Epoch 35, Loss: 0.5239109062081205\n",
      "Epoch 36, Loss: 0.519136981936977\n",
      "Epoch 37, Loss: 0.5156831130600669\n",
      "Epoch 38, Loss: 0.5144441550246913\n",
      "Epoch 39, Loss: 0.513193059628892\n",
      "Epoch 40, Loss: 0.5096193300988617\n",
      "Epoch 41, Loss: 0.5050773909726455\n",
      "Epoch 42, Loss: 0.5014751251266188\n",
      "Epoch 43, Loss: 0.4993184182693348\n",
      "Epoch 44, Loss: 0.4980870099819395\n",
      "Epoch 45, Loss: 0.4966634647961698\n",
      "Epoch 46, Loss: 0.49455569479550954\n",
      "Epoch 47, Loss: 0.4919047224523819\n",
      "Epoch 48, Loss: 0.4892737715320701\n",
      "Epoch 49, Loss: 0.4873016449063096\n",
      "Epoch 50, Loss: 0.48611980403968863\n",
      "Epoch 51, Loss: 0.4849646424894421\n",
      "Epoch 52, Loss: 0.4831228992964264\n",
      "Epoch 53, Loss: 0.4809672707953865\n",
      "Epoch 54, Loss: 0.47924453337630507\n",
      "Epoch 55, Loss: 0.4780704685354493\n",
      "Epoch 56, Loss: 0.47698894556799626\n",
      "Epoch 57, Loss: 0.47560884079821236\n",
      "Epoch 58, Loss: 0.4740313554062425\n",
      "Epoch 59, Loss: 0.4726219637706926\n",
      "Epoch 60, Loss: 0.47151253781279956\n",
      "Epoch 61, Loss: 0.4704337397851195\n",
      "Epoch 62, Loss: 0.4691875799536494\n",
      "Epoch 63, Loss: 0.46802894447147486\n",
      "Epoch 64, Loss: 0.4670631734454449\n",
      "Epoch 65, Loss: 0.46614538402287087\n",
      "Epoch 66, Loss: 0.4651106861365269\n",
      "Epoch 67, Loss: 0.46416051324067775\n",
      "Epoch 68, Loss: 0.4633272582394561\n",
      "Epoch 69, Loss: 0.4624216464403493\n",
      "Epoch 70, Loss: 0.46157516402715987\n",
      "Epoch 71, Loss: 0.46093289324511194\n",
      "Epoch 72, Loss: 0.4602372783050629\n",
      "Epoch 73, Loss: 0.4594451863654339\n",
      "Epoch 74, Loss: 0.4587333154892517\n",
      "Epoch 75, Loss: 0.4581056502550652\n",
      "Epoch 76, Loss: 0.45743953367787915\n",
      "Epoch 77, Loss: 0.45675807516041045\n",
      "Epoch 78, Loss: 0.4560298218575027\n",
      "Epoch 79, Loss: 0.45524752824228576\n",
      "Epoch 80, Loss: 0.45449856047512505\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21338436590728843\n",
      "Test R^2 score: 0.5068933431459464\n",
      "Num of epochs: 81\n",
      "Epoch 1, Loss: 0.5632632957697532\n",
      "Epoch 2, Loss: 0.5621324238879664\n",
      "Epoch 3, Loss: 0.5611251081660747\n",
      "Epoch 4, Loss: 0.5602260828049516\n",
      "Epoch 5, Loss: 0.5594379741234976\n",
      "Epoch 6, Loss: 0.5587508507536485\n",
      "Epoch 7, Loss: 0.5581597996763258\n",
      "Epoch 8, Loss: 0.5576480516219599\n",
      "Epoch 9, Loss: 0.5572271636521084\n",
      "Epoch 10, Loss: 0.556887709004853\n",
      "Epoch 11, Loss: 0.5566131317309164\n",
      "Epoch 12, Loss: 0.5564014389399989\n",
      "Epoch 13, Loss: 0.5562452283933196\n",
      "Epoch 14, Loss: 0.5561413047974358\n",
      "Epoch 15, Loss: 0.5560852760554641\n",
      "Epoch 16, Loss: 0.556058157296002\n",
      "Epoch 17, Loss: 0.5560533068646146\n",
      "Epoch 18, Loss: 0.5560600331420993\n",
      "Epoch 19, Loss: 0.5560668129330832\n",
      "Epoch 20, Loss: 0.556063275661144\n",
      "Epoch 21, Loss: 0.5560342263040408\n",
      "Epoch 22, Loss: 0.5559556728864405\n",
      "Epoch 23, Loss: 0.5558206240455869\n",
      "Epoch 24, Loss: 0.5556125449381945\n",
      "Epoch 25, Loss: 0.5553677645496805\n",
      "Epoch 26, Loss: 0.5550812680224588\n",
      "Epoch 27, Loss: 0.5546831748686322\n",
      "Epoch 28, Loss: 0.5541641022567882\n",
      "Epoch 29, Loss: 0.5535123492502697\n",
      "Epoch 30, Loss: 0.5527112437014756\n",
      "Epoch 31, Loss: 0.5517561110748794\n",
      "Epoch 32, Loss: 0.5506345404708793\n",
      "Epoch 33, Loss: 0.5493397347476955\n",
      "Epoch 34, Loss: 0.5478736750582132\n",
      "Epoch 35, Loss: 0.5462036371524135\n",
      "Epoch 36, Loss: 0.544296480027843\n",
      "Epoch 37, Loss: 0.5420907145805697\n",
      "Epoch 38, Loss: 0.5395453129141727\n",
      "Epoch 39, Loss: 0.536695869102452\n",
      "Epoch 40, Loss: 0.5335901553478332\n",
      "Epoch 41, Loss: 0.5301892686225508\n",
      "Epoch 42, Loss: 0.5264720069257831\n",
      "Epoch 43, Loss: 0.5225351726520944\n",
      "Epoch 44, Loss: 0.5186457149977689\n",
      "Epoch 45, Loss: 0.5152982485658688\n",
      "Epoch 46, Loss: 0.5129348921720565\n",
      "Epoch 47, Loss: 0.5111779128552795\n",
      "Epoch 48, Loss: 0.5087487905895658\n",
      "Epoch 49, Loss: 0.505206183465008\n",
      "Epoch 50, Loss: 0.5014024675273548\n",
      "Epoch 51, Loss: 0.4983303385371332\n",
      "Epoch 52, Loss: 0.49600423170407243\n",
      "Epoch 53, Loss: 0.493366736132872\n",
      "Epoch 54, Loss: 0.4898591904587073\n",
      "Epoch 55, Loss: 0.485864456550117\n",
      "Epoch 56, Loss: 0.4820787236408998\n",
      "Epoch 57, Loss: 0.47904355257391984\n",
      "Epoch 58, Loss: 0.4764189894922461\n",
      "Epoch 59, Loss: 0.4737187730316211\n",
      "Epoch 60, Loss: 0.47091412069183397\n",
      "Epoch 61, Loss: 0.4686752895581214\n",
      "Epoch 62, Loss: 0.467256598960238\n",
      "Epoch 63, Loss: 0.4661978065741468\n",
      "Epoch 64, Loss: 0.46526802959795033\n",
      "Epoch 65, Loss: 0.46458647524479746\n",
      "Epoch 66, Loss: 0.4639001453135469\n",
      "Epoch 67, Loss: 0.4630173779227442\n",
      "Epoch 68, Loss: 0.4621457573312635\n",
      "Epoch 69, Loss: 0.4610827104105908\n",
      "Epoch 70, Loss: 0.4599642257410909\n",
      "Epoch 71, Loss: 0.45912978121363063\n",
      "Epoch 72, Loss: 0.4581984263615787\n",
      "Epoch 73, Loss: 0.45752348842151247\n",
      "Epoch 74, Loss: 0.45660323290944005\n",
      "Epoch 75, Loss: 0.45586415789268014\n",
      "Epoch 76, Loss: 0.45517482466925574\n",
      "Epoch 77, Loss: 0.45447019975472047\n",
      "Epoch 78, Loss: 0.4538265585088397\n",
      "Epoch 79, Loss: 0.45300436058219345\n",
      "Epoch 80, Loss: 0.4523586830744462\n",
      "Epoch 81, Loss: 0.4516623007233719\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21200628363342686\n",
      "Test R^2 score: 0.5146582253433278\n",
      "Num of epochs: 82\n",
      "Epoch 1, Loss: 0.5651971210258604\n",
      "Epoch 2, Loss: 0.5641170676088074\n",
      "Epoch 3, Loss: 0.5631055221830156\n",
      "Epoch 4, Loss: 0.5621630931261522\n",
      "Epoch 5, Loss: 0.5612911905071414\n",
      "Epoch 6, Loss: 0.560487431687283\n",
      "Epoch 7, Loss: 0.5597527224963053\n",
      "Epoch 8, Loss: 0.5590999417163899\n",
      "Epoch 9, Loss: 0.5585122749291106\n",
      "Epoch 10, Loss: 0.5579899278658045\n",
      "Epoch 11, Loss: 0.55753393938053\n",
      "Epoch 12, Loss: 0.5571414768897066\n",
      "Epoch 13, Loss: 0.556828410279381\n",
      "Epoch 14, Loss: 0.556576721806483\n",
      "Epoch 15, Loss: 0.5563715769744525\n",
      "Epoch 16, Loss: 0.5562073209012605\n",
      "Epoch 17, Loss: 0.5560678044370893\n",
      "Epoch 18, Loss: 0.555988076510982\n",
      "Epoch 19, Loss: 0.5558979902975334\n",
      "Epoch 20, Loss: 0.5558478080098246\n",
      "Epoch 21, Loss: 0.5558016427379242\n",
      "Epoch 22, Loss: 0.5557533286317163\n",
      "Epoch 23, Loss: 0.5556942306400977\n",
      "Epoch 24, Loss: 0.5556160850796639\n",
      "Epoch 25, Loss: 0.5554871503784176\n",
      "Epoch 26, Loss: 0.5553160316642641\n",
      "Epoch 27, Loss: 0.5550974553263783\n",
      "Epoch 28, Loss: 0.5548328692723713\n",
      "Epoch 29, Loss: 0.5545298392588798\n",
      "Epoch 30, Loss: 0.5541494204292271\n",
      "Epoch 31, Loss: 0.5536839715759311\n",
      "Epoch 32, Loss: 0.5531361066920817\n",
      "Epoch 33, Loss: 0.5524352379640476\n",
      "Epoch 34, Loss: 0.5515264515538076\n",
      "Epoch 35, Loss: 0.5504245279238292\n",
      "Epoch 36, Loss: 0.5491024431388606\n",
      "Epoch 37, Loss: 0.5475194675868861\n",
      "Epoch 38, Loss: 0.545617264892702\n",
      "Epoch 39, Loss: 0.543306341812373\n",
      "Epoch 40, Loss: 0.5404547252307648\n",
      "Epoch 41, Loss: 0.5369526582446956\n",
      "Epoch 42, Loss: 0.5326892206758832\n",
      "Epoch 43, Loss: 0.5275626116922995\n",
      "Epoch 44, Loss: 0.5216172009873917\n",
      "Epoch 45, Loss: 0.5150335561134654\n",
      "Epoch 46, Loss: 0.5083183116986326\n",
      "Epoch 47, Loss: 0.5024877291457446\n",
      "Epoch 48, Loss: 0.4991366263644536\n",
      "Epoch 49, Loss: 0.49876385112640725\n",
      "Epoch 50, Loss: 0.4978367979509992\n",
      "Epoch 51, Loss: 0.49431793891518105\n",
      "Epoch 52, Loss: 0.48965585624634683\n",
      "Epoch 53, Loss: 0.48565842198032927\n",
      "Epoch 54, Loss: 0.4832835976179486\n",
      "Epoch 55, Loss: 0.482524382167907\n",
      "Epoch 56, Loss: 0.482817653517394\n",
      "Epoch 57, Loss: 0.48328023679166415\n",
      "Epoch 58, Loss: 0.4829516725658708\n",
      "Epoch 59, Loss: 0.48139896131010407\n",
      "Epoch 60, Loss: 0.47902913469455616\n",
      "Epoch 61, Loss: 0.4769185721513586\n",
      "Epoch 62, Loss: 0.4755567506454406\n",
      "Epoch 63, Loss: 0.475191614753582\n",
      "Epoch 64, Loss: 0.4751224648564324\n",
      "Epoch 65, Loss: 0.47478525803801963\n",
      "Epoch 66, Loss: 0.4738019818093432\n",
      "Epoch 67, Loss: 0.47239614849087075\n",
      "Epoch 68, Loss: 0.4709711696635243\n",
      "Epoch 69, Loss: 0.46978933822945756\n",
      "Epoch 70, Loss: 0.46889314055429837\n",
      "Epoch 71, Loss: 0.46820597868784425\n",
      "Epoch 72, Loss: 0.46749844362132437\n",
      "Epoch 73, Loss: 0.46669790583455995\n",
      "Epoch 74, Loss: 0.46575540214309163\n",
      "Epoch 75, Loss: 0.464727948294051\n",
      "Epoch 76, Loss: 0.4637401206000154\n",
      "Epoch 77, Loss: 0.46293470921221774\n",
      "Epoch 78, Loss: 0.4623350197140871\n",
      "Epoch 79, Loss: 0.46179062079020033\n",
      "Epoch 80, Loss: 0.4611557266119675\n",
      "Epoch 81, Loss: 0.4603862213695776\n",
      "Epoch 82, Loss: 0.45956126543406056\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21491692937505433\n",
      "Test R^2 score: 0.5008514993567187\n",
      "Num of epochs: 83\n",
      "Epoch 1, Loss: 0.5729552660568161\n",
      "Epoch 2, Loss: 0.571644103751416\n",
      "Epoch 3, Loss: 0.5703848178945676\n",
      "Epoch 4, Loss: 0.5691643222334216\n",
      "Epoch 5, Loss: 0.5679804531817386\n",
      "Epoch 6, Loss: 0.5668351489762111\n",
      "Epoch 7, Loss: 0.5657311197705013\n",
      "Epoch 8, Loss: 0.564671668805542\n",
      "Epoch 9, Loss: 0.5636842235922959\n",
      "Epoch 10, Loss: 0.5627605576509872\n",
      "Epoch 11, Loss: 0.5618860550027326\n",
      "Epoch 12, Loss: 0.5610648762373329\n",
      "Epoch 13, Loss: 0.5602990908701662\n",
      "Epoch 14, Loss: 0.5595823223429637\n",
      "Epoch 15, Loss: 0.5589294225311067\n",
      "Epoch 16, Loss: 0.5583672497777008\n",
      "Epoch 17, Loss: 0.5578780223927818\n",
      "Epoch 18, Loss: 0.5574541805665894\n",
      "Epoch 19, Loss: 0.5570967027214992\n",
      "Epoch 20, Loss: 0.5568051011543115\n",
      "Epoch 21, Loss: 0.556575035112554\n",
      "Epoch 22, Loss: 0.5564023762851709\n",
      "Epoch 23, Loss: 0.5562809635502562\n",
      "Epoch 24, Loss: 0.5562018823707027\n",
      "Epoch 25, Loss: 0.5561555053513899\n",
      "Epoch 26, Loss: 0.5561358656212974\n",
      "Epoch 27, Loss: 0.5561369373843508\n",
      "Epoch 28, Loss: 0.556142617694051\n",
      "Epoch 29, Loss: 0.5561421889934562\n",
      "Epoch 30, Loss: 0.5561263268391272\n",
      "Epoch 31, Loss: 0.5560854100381467\n",
      "Epoch 32, Loss: 0.5560080698648922\n",
      "Epoch 33, Loss: 0.5558816118544107\n",
      "Epoch 34, Loss: 0.5557085498774021\n",
      "Epoch 35, Loss: 0.5554842532284032\n",
      "Epoch 36, Loss: 0.5551939787687964\n",
      "Epoch 37, Loss: 0.5548338361244907\n",
      "Epoch 38, Loss: 0.5543907607546528\n",
      "Epoch 39, Loss: 0.5538491643373984\n",
      "Epoch 40, Loss: 0.5531886899239488\n",
      "Epoch 41, Loss: 0.5523843634321763\n",
      "Epoch 42, Loss: 0.5514069648580222\n",
      "Epoch 43, Loss: 0.5502249701932592\n",
      "Epoch 44, Loss: 0.548798529753509\n",
      "Epoch 45, Loss: 0.5470704410638627\n",
      "Epoch 46, Loss: 0.5450161814693494\n",
      "Epoch 47, Loss: 0.5426087867196909\n",
      "Epoch 48, Loss: 0.5398062675039432\n",
      "Epoch 49, Loss: 0.5366006279774993\n",
      "Epoch 50, Loss: 0.5330549879713263\n",
      "Epoch 51, Loss: 0.5293733604883164\n",
      "Epoch 52, Loss: 0.5257855600801065\n",
      "Epoch 53, Loss: 0.522312292897091\n",
      "Epoch 54, Loss: 0.5184750253296334\n",
      "Epoch 55, Loss: 0.5140100098685396\n",
      "Epoch 56, Loss: 0.5093225475522801\n",
      "Epoch 57, Loss: 0.505237181977048\n",
      "Epoch 58, Loss: 0.5020923644027923\n",
      "Epoch 59, Loss: 0.49969745960055517\n",
      "Epoch 60, Loss: 0.4975927638785776\n",
      "Epoch 61, Loss: 0.49557923496513046\n",
      "Epoch 62, Loss: 0.493479637173257\n",
      "Epoch 63, Loss: 0.4909155774821861\n",
      "Epoch 64, Loss: 0.4878224773474107\n",
      "Epoch 65, Loss: 0.48439771845053453\n",
      "Epoch 66, Loss: 0.4813104096186338\n",
      "Epoch 67, Loss: 0.4792341326473248\n",
      "Epoch 68, Loss: 0.47809211518137623\n",
      "Epoch 69, Loss: 0.47652663424248526\n",
      "Epoch 70, Loss: 0.47414046934473786\n",
      "Epoch 71, Loss: 0.4718952357772141\n",
      "Epoch 72, Loss: 0.4703178570210994\n",
      "Epoch 73, Loss: 0.46931040960728515\n",
      "Epoch 74, Loss: 0.4681852117097293\n",
      "Epoch 75, Loss: 0.46684298427250104\n",
      "Epoch 76, Loss: 0.4657767413412843\n",
      "Epoch 77, Loss: 0.4653197824281036\n",
      "Epoch 78, Loss: 0.464856203697778\n",
      "Epoch 79, Loss: 0.4639519383155761\n",
      "Epoch 80, Loss: 0.4629375900715498\n",
      "Epoch 81, Loss: 0.4620959063104495\n",
      "Epoch 82, Loss: 0.4614081162396548\n",
      "Epoch 83, Loss: 0.4607195904839291\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21379888222870927\n",
      "Test R^2 score: 0.5058474935531625\n",
      "Num of epochs: 84\n",
      "Epoch 1, Loss: 0.5675547039032978\n",
      "Epoch 2, Loss: 0.5660669033708587\n",
      "Epoch 3, Loss: 0.5647039944931864\n",
      "Epoch 4, Loss: 0.5634842050652231\n",
      "Epoch 5, Loss: 0.5624295561443861\n",
      "Epoch 6, Loss: 0.5614982532990379\n",
      "Epoch 7, Loss: 0.5606653174763222\n",
      "Epoch 8, Loss: 0.5599273820608649\n",
      "Epoch 9, Loss: 0.5592772830025913\n",
      "Epoch 10, Loss: 0.5587086592705618\n",
      "Epoch 11, Loss: 0.5582159138329676\n",
      "Epoch 12, Loss: 0.5578130054204452\n",
      "Epoch 13, Loss: 0.557469015928323\n",
      "Epoch 14, Loss: 0.5571551972854856\n",
      "Epoch 15, Loss: 0.5568963785060265\n",
      "Epoch 16, Loss: 0.5566662966513785\n",
      "Epoch 17, Loss: 0.5564563379236471\n",
      "Epoch 18, Loss: 0.5562649178379769\n",
      "Epoch 19, Loss: 0.556097146795863\n",
      "Epoch 20, Loss: 0.5559573078540119\n",
      "Epoch 21, Loss: 0.5558430361675334\n",
      "Epoch 22, Loss: 0.5557498161772073\n",
      "Epoch 23, Loss: 0.5556702035252842\n",
      "Epoch 24, Loss: 0.5555875755725233\n",
      "Epoch 25, Loss: 0.555486935775231\n",
      "Epoch 26, Loss: 0.55535399999417\n",
      "Epoch 27, Loss: 0.5551848264039576\n",
      "Epoch 28, Loss: 0.5549735822490326\n",
      "Epoch 29, Loss: 0.5547045852823722\n",
      "Epoch 30, Loss: 0.5543679136062017\n",
      "Epoch 31, Loss: 0.5539641701098023\n",
      "Epoch 32, Loss: 0.5534880120410143\n",
      "Epoch 33, Loss: 0.5529203337993579\n",
      "Epoch 34, Loss: 0.5522345449789897\n",
      "Epoch 35, Loss: 0.551378156638682\n",
      "Epoch 36, Loss: 0.5502960286228843\n",
      "Epoch 37, Loss: 0.548893690435208\n",
      "Epoch 38, Loss: 0.5470601177253048\n",
      "Epoch 39, Loss: 0.5446834521162379\n",
      "Epoch 40, Loss: 0.5416634052129516\n",
      "Epoch 41, Loss: 0.5379558759129983\n",
      "Epoch 42, Loss: 0.5335243850236854\n",
      "Epoch 43, Loss: 0.5284802658308829\n",
      "Epoch 44, Loss: 0.5231381599475521\n",
      "Epoch 45, Loss: 0.5183225640203402\n",
      "Epoch 46, Loss: 0.5155271668532296\n",
      "Epoch 47, Loss: 0.5155177438329541\n",
      "Epoch 48, Loss: 0.5150985052751003\n",
      "Epoch 49, Loss: 0.5119356176327532\n",
      "Epoch 50, Loss: 0.507407687299398\n",
      "Epoch 51, Loss: 0.5035276543221283\n",
      "Epoch 52, Loss: 0.5012994807452396\n",
      "Epoch 53, Loss: 0.5000415427116116\n",
      "Epoch 54, Loss: 0.4991416865701891\n",
      "Epoch 55, Loss: 0.4979023443207845\n",
      "Epoch 56, Loss: 0.49615299441802446\n",
      "Epoch 57, Loss: 0.4938739916685678\n",
      "Epoch 58, Loss: 0.4913429401412624\n",
      "Epoch 59, Loss: 0.4889235277740757\n",
      "Epoch 60, Loss: 0.48697561034945663\n",
      "Epoch 61, Loss: 0.48554049523751125\n",
      "Epoch 62, Loss: 0.4841895055910297\n",
      "Epoch 63, Loss: 0.4824010713238389\n",
      "Epoch 64, Loss: 0.4801721665450176\n",
      "Epoch 65, Loss: 0.4780019221496641\n",
      "Epoch 66, Loss: 0.47635680590488694\n",
      "Epoch 67, Loss: 0.4751253188608129\n",
      "Epoch 68, Loss: 0.47394375376931186\n",
      "Epoch 69, Loss: 0.4725329813723988\n",
      "Epoch 70, Loss: 0.4710055286048575\n",
      "Epoch 71, Loss: 0.4696212142850641\n",
      "Epoch 72, Loss: 0.4684947749541665\n",
      "Epoch 73, Loss: 0.46749245122435046\n",
      "Epoch 74, Loss: 0.4663813988536238\n",
      "Epoch 75, Loss: 0.4651453978861856\n",
      "Epoch 76, Loss: 0.463945418336398\n",
      "Epoch 77, Loss: 0.46293351823720025\n",
      "Epoch 78, Loss: 0.46201620121928033\n",
      "Epoch 79, Loss: 0.46104421834962095\n",
      "Epoch 80, Loss: 0.45997344240979887\n",
      "Epoch 81, Loss: 0.4589772487655314\n",
      "Epoch 82, Loss: 0.4581711402650147\n",
      "Epoch 83, Loss: 0.45745031592528806\n",
      "Epoch 84, Loss: 0.45671655955198825\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21409254188003315\n",
      "Test R^2 score: 0.5035935125068194\n",
      "Num of epochs: 85\n",
      "Epoch 1, Loss: 0.5914325914853462\n",
      "Epoch 2, Loss: 0.5890614456450641\n",
      "Epoch 3, Loss: 0.586763054689893\n",
      "Epoch 4, Loss: 0.584543171312141\n",
      "Epoch 5, Loss: 0.5824340859968146\n",
      "Epoch 6, Loss: 0.5806574641782121\n",
      "Epoch 7, Loss: 0.5789266132268838\n",
      "Epoch 8, Loss: 0.5772448102652502\n",
      "Epoch 9, Loss: 0.5756137019238408\n",
      "Epoch 10, Loss: 0.5740382111820028\n",
      "Epoch 11, Loss: 0.5725792816187903\n",
      "Epoch 12, Loss: 0.5711368977623854\n",
      "Epoch 13, Loss: 0.5698056777774989\n",
      "Epoch 14, Loss: 0.5685507855138937\n",
      "Epoch 15, Loss: 0.56735431645544\n",
      "Epoch 16, Loss: 0.5662035085948032\n",
      "Epoch 17, Loss: 0.5651032818437203\n",
      "Epoch 18, Loss: 0.5640611178309871\n",
      "Epoch 19, Loss: 0.5631434151605307\n",
      "Epoch 20, Loss: 0.5623178452028573\n",
      "Epoch 21, Loss: 0.5615291960047799\n",
      "Epoch 22, Loss: 0.5607775436198105\n",
      "Epoch 23, Loss: 0.5600673471979001\n",
      "Epoch 24, Loss: 0.5593998301445434\n",
      "Epoch 25, Loss: 0.55877599877584\n",
      "Epoch 26, Loss: 0.5581981618672596\n",
      "Epoch 27, Loss: 0.5576661951872905\n",
      "Epoch 28, Loss: 0.5571789731556918\n",
      "Epoch 29, Loss: 0.5567342311388626\n",
      "Epoch 30, Loss: 0.5563445793068108\n",
      "Epoch 31, Loss: 0.5560123578900606\n",
      "Epoch 32, Loss: 0.5557066728448363\n",
      "Epoch 33, Loss: 0.5554156829336869\n",
      "Epoch 34, Loss: 0.5551309559087481\n",
      "Epoch 35, Loss: 0.5548374080913215\n",
      "Epoch 36, Loss: 0.5545074815511982\n",
      "Epoch 37, Loss: 0.5540990259961606\n",
      "Epoch 38, Loss: 0.5535876155279745\n",
      "Epoch 39, Loss: 0.5529798090837521\n",
      "Epoch 40, Loss: 0.5522716189151065\n",
      "Epoch 41, Loss: 0.5514410139082372\n",
      "Epoch 42, Loss: 0.5504863571829041\n",
      "Epoch 43, Loss: 0.5493183864981668\n",
      "Epoch 44, Loss: 0.5478714176054765\n",
      "Epoch 45, Loss: 0.5460975024704263\n",
      "Epoch 46, Loss: 0.5439742130292958\n",
      "Epoch 47, Loss: 0.5415205269301718\n",
      "Epoch 48, Loss: 0.5387357744432023\n",
      "Epoch 49, Loss: 0.5356575504414268\n",
      "Epoch 50, Loss: 0.53241117582815\n",
      "Epoch 51, Loss: 0.5292389053187316\n",
      "Epoch 52, Loss: 0.5263524663844737\n",
      "Epoch 53, Loss: 0.5239121007777492\n",
      "Epoch 54, Loss: 0.5217108645418747\n",
      "Epoch 55, Loss: 0.5191526252272394\n",
      "Epoch 56, Loss: 0.5162694833602712\n",
      "Epoch 57, Loss: 0.5135563767694743\n",
      "Epoch 58, Loss: 0.5112559722980593\n",
      "Epoch 59, Loss: 0.509246064466308\n",
      "Epoch 60, Loss: 0.5072023687809765\n",
      "Epoch 61, Loss: 0.504879477395824\n",
      "Epoch 62, Loss: 0.5022779074511207\n",
      "Epoch 63, Loss: 0.4996215311798015\n",
      "Epoch 64, Loss: 0.49711749559262736\n",
      "Epoch 65, Loss: 0.4947362483929188\n",
      "Epoch 66, Loss: 0.49225015090137997\n",
      "Epoch 67, Loss: 0.4896824530102237\n",
      "Epoch 68, Loss: 0.4873740198507577\n",
      "Epoch 69, Loss: 0.4853232085697802\n",
      "Epoch 70, Loss: 0.4830543295136864\n",
      "Epoch 71, Loss: 0.4806941984387199\n",
      "Epoch 72, Loss: 0.47862304727350746\n",
      "Epoch 73, Loss: 0.47646369847939735\n",
      "Epoch 74, Loss: 0.4740928853656774\n",
      "Epoch 75, Loss: 0.47201674523997716\n",
      "Epoch 76, Loss: 0.47004731581815967\n",
      "Epoch 77, Loss: 0.46797647231008094\n",
      "Epoch 78, Loss: 0.46612831345636446\n",
      "Epoch 79, Loss: 0.46435956020538294\n",
      "Epoch 80, Loss: 0.46269035030745903\n",
      "Epoch 81, Loss: 0.46142860694302623\n",
      "Epoch 82, Loss: 0.46030329053462177\n",
      "Epoch 83, Loss: 0.4593844678772439\n",
      "Epoch 84, Loss: 0.45846924789533766\n",
      "Epoch 85, Loss: 0.457291309020555\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21584025214844124\n",
      "Test R^2 score: 0.4959575342190069\n",
      "Num of epochs: 86\n",
      "Epoch 1, Loss: 0.5705701690101597\n",
      "Epoch 2, Loss: 0.568835711046792\n",
      "Epoch 3, Loss: 0.5672049317426645\n",
      "Epoch 4, Loss: 0.5657131031611978\n",
      "Epoch 5, Loss: 0.5643567329652657\n",
      "Epoch 6, Loss: 0.5631550577421074\n",
      "Epoch 7, Loss: 0.5620967426166305\n",
      "Epoch 8, Loss: 0.5611453964782152\n",
      "Epoch 9, Loss: 0.5603217759563975\n",
      "Epoch 10, Loss: 0.5596211195643561\n",
      "Epoch 11, Loss: 0.5590030264525129\n",
      "Epoch 12, Loss: 0.5584675306155643\n",
      "Epoch 13, Loss: 0.5580124130833795\n",
      "Epoch 14, Loss: 0.5576226389496549\n",
      "Epoch 15, Loss: 0.5572885590463668\n",
      "Epoch 16, Loss: 0.557000830035045\n",
      "Epoch 17, Loss: 0.556758239099308\n",
      "Epoch 18, Loss: 0.5565505640890848\n",
      "Epoch 19, Loss: 0.5563747105474497\n",
      "Epoch 20, Loss: 0.5562282172234884\n",
      "Epoch 21, Loss: 0.5561098747348707\n",
      "Epoch 22, Loss: 0.5560189506642487\n",
      "Epoch 23, Loss: 0.5559526977691805\n",
      "Epoch 24, Loss: 0.5559038070752841\n",
      "Epoch 25, Loss: 0.5558624717856683\n",
      "Epoch 26, Loss: 0.5558190422947066\n",
      "Epoch 27, Loss: 0.5557602998497224\n",
      "Epoch 28, Loss: 0.555672348845632\n",
      "Epoch 29, Loss: 0.5555439100104572\n",
      "Epoch 30, Loss: 0.5553626934373411\n",
      "Epoch 31, Loss: 0.5551260436902267\n",
      "Epoch 32, Loss: 0.5548363606748593\n",
      "Epoch 33, Loss: 0.554479345029833\n",
      "Epoch 34, Loss: 0.5540412307934155\n",
      "Epoch 35, Loss: 0.5535092802363843\n",
      "Epoch 36, Loss: 0.55287009685808\n",
      "Epoch 37, Loss: 0.5521089230011024\n",
      "Epoch 38, Loss: 0.5512077628063113\n",
      "Epoch 39, Loss: 0.5501359446450347\n",
      "Epoch 40, Loss: 0.5488457456319081\n",
      "Epoch 41, Loss: 0.5472745253433442\n",
      "Epoch 42, Loss: 0.5453510303602648\n",
      "Epoch 43, Loss: 0.5430102709805176\n",
      "Epoch 44, Loss: 0.5402526157303471\n",
      "Epoch 45, Loss: 0.5371128983815543\n",
      "Epoch 46, Loss: 0.5336166008319324\n",
      "Epoch 47, Loss: 0.5297251865179777\n",
      "Epoch 48, Loss: 0.5254463534951808\n",
      "Epoch 49, Loss: 0.5209232983772967\n",
      "Epoch 50, Loss: 0.5165745632565414\n",
      "Epoch 51, Loss: 0.5130177673661326\n",
      "Epoch 52, Loss: 0.5100276463625955\n",
      "Epoch 53, Loss: 0.5067059418185541\n",
      "Epoch 54, Loss: 0.5028661891517174\n",
      "Epoch 55, Loss: 0.49924196956405253\n",
      "Epoch 56, Loss: 0.4966503835202135\n",
      "Epoch 57, Loss: 0.494106985160873\n",
      "Epoch 58, Loss: 0.4905251936017681\n",
      "Epoch 59, Loss: 0.48722604793612245\n",
      "Epoch 60, Loss: 0.4852319182329288\n",
      "Epoch 61, Loss: 0.48315583894318714\n",
      "Epoch 62, Loss: 0.48033082734722077\n",
      "Epoch 63, Loss: 0.4782158671779972\n",
      "Epoch 64, Loss: 0.47673722487978093\n",
      "Epoch 65, Loss: 0.47418108795283515\n",
      "Epoch 66, Loss: 0.47211813441812506\n",
      "Epoch 67, Loss: 0.4703450245557688\n",
      "Epoch 68, Loss: 0.46788627203373345\n",
      "Epoch 69, Loss: 0.46676725030210703\n",
      "Epoch 70, Loss: 0.46540652596443677\n",
      "Epoch 71, Loss: 0.4643506552269245\n",
      "Epoch 72, Loss: 0.46368494569759017\n",
      "Epoch 73, Loss: 0.4622669444694726\n",
      "Epoch 74, Loss: 0.4615232011598296\n",
      "Epoch 75, Loss: 0.46030987828810094\n",
      "Epoch 76, Loss: 0.4592914446921604\n",
      "Epoch 77, Loss: 0.45818367776146746\n",
      "Epoch 78, Loss: 0.4569556181838497\n",
      "Epoch 79, Loss: 0.4562088503635919\n",
      "Epoch 80, Loss: 0.4552219638340465\n",
      "Epoch 81, Loss: 0.45449721624971806\n",
      "Epoch 82, Loss: 0.45356017624153455\n",
      "Epoch 83, Loss: 0.4528805467959248\n",
      "Epoch 84, Loss: 0.45197335596064636\n",
      "Epoch 85, Loss: 0.4511563517224305\n",
      "Epoch 86, Loss: 0.4501979438886882\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.212636356405525\n",
      "Test R^2 score: 0.5090873566375718\n",
      "Num of epochs: 87\n",
      "Epoch 1, Loss: 0.5856105146377399\n",
      "Epoch 2, Loss: 0.5826104373777435\n",
      "Epoch 3, Loss: 0.579774565212055\n",
      "Epoch 4, Loss: 0.5771056803245116\n",
      "Epoch 5, Loss: 0.5746084953628124\n",
      "Epoch 6, Loss: 0.5722862213907035\n",
      "Epoch 7, Loss: 0.5701500386897871\n",
      "Epoch 8, Loss: 0.5683363290420663\n",
      "Epoch 9, Loss: 0.5666889143063971\n",
      "Epoch 10, Loss: 0.5652022884517622\n",
      "Epoch 11, Loss: 0.563903726015602\n",
      "Epoch 12, Loss: 0.5627305035376526\n",
      "Epoch 13, Loss: 0.5616518620125575\n",
      "Epoch 14, Loss: 0.5606677891914313\n",
      "Epoch 15, Loss: 0.5597727677288202\n",
      "Epoch 16, Loss: 0.5589726103604938\n",
      "Epoch 17, Loss: 0.5582667373919041\n",
      "Epoch 18, Loss: 0.5576609044884144\n",
      "Epoch 19, Loss: 0.5571869427929037\n",
      "Epoch 20, Loss: 0.5567721295200411\n",
      "Epoch 21, Loss: 0.5565466282769912\n",
      "Epoch 22, Loss: 0.5563408563113628\n",
      "Epoch 23, Loss: 0.5562110180000458\n",
      "Epoch 24, Loss: 0.5561444128742025\n",
      "Epoch 25, Loss: 0.5561257641530462\n",
      "Epoch 26, Loss: 0.5561376340292278\n",
      "Epoch 27, Loss: 0.5561640255097224\n",
      "Epoch 28, Loss: 0.556176296451793\n",
      "Epoch 29, Loss: 0.5561502002812074\n",
      "Epoch 30, Loss: 0.5560715828550689\n",
      "Epoch 31, Loss: 0.5559284137843168\n",
      "Epoch 32, Loss: 0.5557049030654673\n",
      "Epoch 33, Loss: 0.5553783895872929\n",
      "Epoch 34, Loss: 0.5549373601240258\n",
      "Epoch 35, Loss: 0.5543902769424439\n",
      "Epoch 36, Loss: 0.5537308516108668\n",
      "Epoch 37, Loss: 0.5529311675628289\n",
      "Epoch 38, Loss: 0.5519699364090973\n",
      "Epoch 39, Loss: 0.5508121454758684\n",
      "Epoch 40, Loss: 0.5494128062114869\n",
      "Epoch 41, Loss: 0.5477300771017674\n",
      "Epoch 42, Loss: 0.5456600043832511\n",
      "Epoch 43, Loss: 0.5432416655387847\n",
      "Epoch 44, Loss: 0.5405512445226084\n",
      "Epoch 45, Loss: 0.5378538486205778\n",
      "Epoch 46, Loss: 0.5356027452971147\n",
      "Epoch 47, Loss: 0.5340605329161479\n",
      "Epoch 48, Loss: 0.5327217528177507\n",
      "Epoch 49, Loss: 0.5307231983851264\n",
      "Epoch 50, Loss: 0.5283411554254903\n",
      "Epoch 51, Loss: 0.5264082912044291\n",
      "Epoch 52, Loss: 0.5252163963299179\n",
      "Epoch 53, Loss: 0.5240360083620186\n",
      "Epoch 54, Loss: 0.5223740264763014\n",
      "Epoch 55, Loss: 0.5203492171703823\n",
      "Epoch 56, Loss: 0.5183768389475822\n",
      "Epoch 57, Loss: 0.5167014705051577\n",
      "Epoch 58, Loss: 0.51492331183836\n",
      "Epoch 59, Loss: 0.5129431715789183\n",
      "Epoch 60, Loss: 0.5110504795418189\n",
      "Epoch 61, Loss: 0.5094910682479332\n",
      "Epoch 62, Loss: 0.5079435032813305\n",
      "Epoch 63, Loss: 0.506083317384427\n",
      "Epoch 64, Loss: 0.5039225435210238\n",
      "Epoch 65, Loss: 0.5017498807179946\n",
      "Epoch 66, Loss: 0.49977860913771266\n",
      "Epoch 67, Loss: 0.4979757519969723\n",
      "Epoch 68, Loss: 0.4961944838249926\n",
      "Epoch 69, Loss: 0.4944833012095886\n",
      "Epoch 70, Loss: 0.49283650917295935\n",
      "Epoch 71, Loss: 0.4910228968455862\n",
      "Epoch 72, Loss: 0.4892299590871982\n",
      "Epoch 73, Loss: 0.48763500936170906\n",
      "Epoch 74, Loss: 0.4860947596736613\n",
      "Epoch 75, Loss: 0.4843683549978923\n",
      "Epoch 76, Loss: 0.482694726301348\n",
      "Epoch 77, Loss: 0.48103477508060205\n",
      "Epoch 78, Loss: 0.4792477048541348\n",
      "Epoch 79, Loss: 0.4775472378957337\n",
      "Epoch 80, Loss: 0.47593256481314505\n",
      "Epoch 81, Loss: 0.47421128645778665\n",
      "Epoch 82, Loss: 0.47258370213143025\n",
      "Epoch 83, Loss: 0.4710243205566349\n",
      "Epoch 84, Loss: 0.4694359687441953\n",
      "Epoch 85, Loss: 0.4679233732815732\n",
      "Epoch 86, Loss: 0.4663155759917786\n",
      "Epoch 87, Loss: 0.4647305615244953\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22903841512298365\n",
      "Test R^2 score: 0.42985375603747533\n",
      "Num of epochs: 88\n",
      "Epoch 1, Loss: 0.5688217484627999\n",
      "Epoch 2, Loss: 0.5677108472949254\n",
      "Epoch 3, Loss: 0.566666957443761\n",
      "Epoch 4, Loss: 0.5656847864241227\n",
      "Epoch 5, Loss: 0.5647648937005836\n",
      "Epoch 6, Loss: 0.563904122390602\n",
      "Epoch 7, Loss: 0.563100785381533\n",
      "Epoch 8, Loss: 0.562351525102706\n",
      "Epoch 9, Loss: 0.5617409724268589\n",
      "Epoch 10, Loss: 0.5611874047612888\n",
      "Epoch 11, Loss: 0.5606651048551587\n",
      "Epoch 12, Loss: 0.5601682281277538\n",
      "Epoch 13, Loss: 0.559709701353342\n",
      "Epoch 14, Loss: 0.559286155251599\n",
      "Epoch 15, Loss: 0.5588880977183674\n",
      "Epoch 16, Loss: 0.5585154231715829\n",
      "Epoch 17, Loss: 0.5581674616468085\n",
      "Epoch 18, Loss: 0.5578459956693589\n",
      "Epoch 19, Loss: 0.5575622959143004\n",
      "Epoch 20, Loss: 0.5573123827022178\n",
      "Epoch 21, Loss: 0.5570838635864626\n",
      "Epoch 22, Loss: 0.5568808856914241\n",
      "Epoch 23, Loss: 0.5567002916983184\n",
      "Epoch 24, Loss: 0.5565384084980248\n",
      "Epoch 25, Loss: 0.5563931366709705\n",
      "Epoch 26, Loss: 0.5562629355308824\n",
      "Epoch 27, Loss: 0.5561452166843324\n",
      "Epoch 28, Loss: 0.5560341995050402\n",
      "Epoch 29, Loss: 0.5559236694382458\n",
      "Epoch 30, Loss: 0.5557963611005966\n",
      "Epoch 31, Loss: 0.5556257130775982\n",
      "Epoch 32, Loss: 0.5554073391002601\n",
      "Epoch 33, Loss: 0.5551490743717151\n",
      "Epoch 34, Loss: 0.5548465124742024\n",
      "Epoch 35, Loss: 0.5543430225821934\n",
      "Epoch 36, Loss: 0.5535437114430387\n",
      "Epoch 37, Loss: 0.552500132608182\n",
      "Epoch 38, Loss: 0.5513409145148042\n",
      "Epoch 39, Loss: 0.549961887469617\n",
      "Epoch 40, Loss: 0.5482803271664463\n",
      "Epoch 41, Loss: 0.546318397648121\n",
      "Epoch 42, Loss: 0.5442243370625836\n",
      "Epoch 43, Loss: 0.5422527065148\n",
      "Epoch 44, Loss: 0.5405204241825755\n",
      "Epoch 45, Loss: 0.5386493315761707\n",
      "Epoch 46, Loss: 0.5363198876356108\n",
      "Epoch 47, Loss: 0.5337930845966802\n",
      "Epoch 48, Loss: 0.5314301017202298\n",
      "Epoch 49, Loss: 0.5293464215163526\n",
      "Epoch 50, Loss: 0.5272834460781859\n",
      "Epoch 51, Loss: 0.5250218454993043\n",
      "Epoch 52, Loss: 0.5226490288251268\n",
      "Epoch 53, Loss: 0.5204357505284253\n",
      "Epoch 54, Loss: 0.5186200289319072\n",
      "Epoch 55, Loss: 0.5169387611075833\n",
      "Epoch 56, Loss: 0.5150903762293094\n",
      "Epoch 57, Loss: 0.5132997854941697\n",
      "Epoch 58, Loss: 0.5117059662365041\n",
      "Epoch 59, Loss: 0.5100335188210365\n",
      "Epoch 60, Loss: 0.5080632690994499\n",
      "Epoch 61, Loss: 0.5059740385794966\n",
      "Epoch 62, Loss: 0.5040766701359082\n",
      "Epoch 63, Loss: 0.5023197957404107\n",
      "Epoch 64, Loss: 0.5004920922111005\n",
      "Epoch 65, Loss: 0.4987832403937351\n",
      "Epoch 66, Loss: 0.49732296261742825\n",
      "Epoch 67, Loss: 0.4959318993341715\n",
      "Epoch 68, Loss: 0.4945668429180758\n",
      "Epoch 69, Loss: 0.49326661809294264\n",
      "Epoch 70, Loss: 0.4919687117866327\n",
      "Epoch 71, Loss: 0.4905704698813117\n",
      "Epoch 72, Loss: 0.4892472591518299\n",
      "Epoch 73, Loss: 0.48801715575318183\n",
      "Epoch 74, Loss: 0.48671993114640394\n",
      "Epoch 75, Loss: 0.485467693473813\n",
      "Epoch 76, Loss: 0.4842361897334274\n",
      "Epoch 77, Loss: 0.4828899290594848\n",
      "Epoch 78, Loss: 0.4815603741618076\n",
      "Epoch 79, Loss: 0.4802345542479181\n",
      "Epoch 80, Loss: 0.47891542509913815\n",
      "Epoch 81, Loss: 0.4776653598644184\n",
      "Epoch 82, Loss: 0.4763663153896505\n",
      "Epoch 83, Loss: 0.47501097277465576\n",
      "Epoch 84, Loss: 0.47359725976019124\n",
      "Epoch 85, Loss: 0.47213170603664983\n",
      "Epoch 86, Loss: 0.47081293115326445\n",
      "Epoch 87, Loss: 0.4694848340746663\n",
      "Epoch 88, Loss: 0.46820546947027847\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.23188861824839185\n",
      "Test R^2 score: 0.41786451073616276\n",
      "Num of epochs: 89\n",
      "Epoch 1, Loss: 0.5619908783841001\n",
      "Epoch 2, Loss: 0.5608150359121602\n",
      "Epoch 3, Loss: 0.5597712237656427\n",
      "Epoch 4, Loss: 0.5588635413339614\n",
      "Epoch 5, Loss: 0.5580944150295617\n",
      "Epoch 6, Loss: 0.5574646321868512\n",
      "Epoch 7, Loss: 0.5569721506234665\n",
      "Epoch 8, Loss: 0.5566189410352981\n",
      "Epoch 9, Loss: 0.5563823435360247\n",
      "Epoch 10, Loss: 0.5562499967853675\n",
      "Epoch 11, Loss: 0.5562019091616239\n",
      "Epoch 12, Loss: 0.5562193229874232\n",
      "Epoch 13, Loss: 0.5562746685430142\n",
      "Epoch 14, Loss: 0.5563265801338524\n",
      "Epoch 15, Loss: 0.5563697021787508\n",
      "Epoch 16, Loss: 0.5564117496500416\n",
      "Epoch 17, Loss: 0.5564377264360646\n",
      "Epoch 18, Loss: 0.5564446890798379\n",
      "Epoch 19, Loss: 0.5564346199976594\n",
      "Epoch 20, Loss: 0.5564060720878902\n",
      "Epoch 21, Loss: 0.5563628992955816\n",
      "Epoch 22, Loss: 0.5563086607358817\n",
      "Epoch 23, Loss: 0.5562470232423148\n",
      "Epoch 24, Loss: 0.5561810118509738\n",
      "Epoch 25, Loss: 0.5561123399020141\n",
      "Epoch 26, Loss: 0.5560309300172783\n",
      "Epoch 27, Loss: 0.5559359188818574\n",
      "Epoch 28, Loss: 0.5558603540064755\n",
      "Epoch 29, Loss: 0.5557788267771842\n",
      "Epoch 30, Loss: 0.5556896451883567\n",
      "Epoch 31, Loss: 0.5555889434185997\n",
      "Epoch 32, Loss: 0.555472342564035\n",
      "Epoch 33, Loss: 0.5553317827988846\n",
      "Epoch 34, Loss: 0.5551604551482971\n",
      "Epoch 35, Loss: 0.5549498192981152\n",
      "Epoch 36, Loss: 0.5546910191813842\n",
      "Epoch 37, Loss: 0.5543817295238006\n",
      "Epoch 38, Loss: 0.5540309028630855\n",
      "Epoch 39, Loss: 0.5536224725148362\n",
      "Epoch 40, Loss: 0.5531291024007444\n",
      "Epoch 41, Loss: 0.5525244593923896\n",
      "Epoch 42, Loss: 0.5517904356367819\n",
      "Epoch 43, Loss: 0.5508974372115173\n",
      "Epoch 44, Loss: 0.549758827912288\n",
      "Epoch 45, Loss: 0.5482770929752412\n",
      "Epoch 46, Loss: 0.54636209140942\n",
      "Epoch 47, Loss: 0.5439168213756947\n",
      "Epoch 48, Loss: 0.540884532263493\n",
      "Epoch 49, Loss: 0.5371822515811585\n",
      "Epoch 50, Loss: 0.5328292374205384\n",
      "Epoch 51, Loss: 0.528025377346446\n",
      "Epoch 52, Loss: 0.5229932123622657\n",
      "Epoch 53, Loss: 0.5176856738938755\n",
      "Epoch 54, Loss: 0.5123843167163603\n",
      "Epoch 55, Loss: 0.5076583041322431\n",
      "Epoch 56, Loss: 0.5043247466359623\n",
      "Epoch 57, Loss: 0.5025247072911585\n",
      "Epoch 58, Loss: 0.500043539297338\n",
      "Epoch 59, Loss: 0.49566815360388605\n",
      "Epoch 60, Loss: 0.49052437339580546\n",
      "Epoch 61, Loss: 0.4859682919721669\n",
      "Epoch 62, Loss: 0.48257042454879107\n",
      "Epoch 63, Loss: 0.48034239867652345\n",
      "Epoch 64, Loss: 0.47926217834190443\n",
      "Epoch 65, Loss: 0.4792796205680844\n",
      "Epoch 66, Loss: 0.478894686909363\n",
      "Epoch 67, Loss: 0.4767721840498515\n",
      "Epoch 68, Loss: 0.4741737030101662\n",
      "Epoch 69, Loss: 0.4722809523247895\n",
      "Epoch 70, Loss: 0.47146547875388656\n",
      "Epoch 71, Loss: 0.47061276656787704\n",
      "Epoch 72, Loss: 0.4693523034247817\n",
      "Epoch 73, Loss: 0.46816342528438687\n",
      "Epoch 74, Loss: 0.4676719348340664\n",
      "Epoch 75, Loss: 0.4675438303468892\n",
      "Epoch 76, Loss: 0.46716007164908946\n",
      "Epoch 77, Loss: 0.46620117867671407\n",
      "Epoch 78, Loss: 0.4647583281944074\n",
      "Epoch 79, Loss: 0.4634745492099739\n",
      "Epoch 80, Loss: 0.4627308630178053\n",
      "Epoch 81, Loss: 0.46227005513363384\n",
      "Epoch 82, Loss: 0.46178913644970987\n",
      "Epoch 83, Loss: 0.4611935470118446\n",
      "Epoch 84, Loss: 0.46061624226209247\n",
      "Epoch 85, Loss: 0.4600676880409094\n",
      "Epoch 86, Loss: 0.4595453770297174\n",
      "Epoch 87, Loss: 0.4589970039091208\n",
      "Epoch 88, Loss: 0.4584318203304469\n",
      "Epoch 89, Loss: 0.45793915907115557\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21932746594976305\n",
      "Test R^2 score: 0.48006973980351675\n",
      "Num of epochs: 90\n",
      "Epoch 1, Loss: 0.5980780366021056\n",
      "Epoch 2, Loss: 0.5957263129051956\n",
      "Epoch 3, Loss: 0.5936466428241698\n",
      "Epoch 4, Loss: 0.5918944375976327\n",
      "Epoch 5, Loss: 0.5901688949042314\n",
      "Epoch 6, Loss: 0.5884759466786522\n",
      "Epoch 7, Loss: 0.5868188206328915\n",
      "Epoch 8, Loss: 0.5852002910343419\n",
      "Epoch 9, Loss: 0.5836321173417961\n",
      "Epoch 10, Loss: 0.582133085827477\n",
      "Epoch 11, Loss: 0.580682330673377\n",
      "Epoch 12, Loss: 0.5792730633915043\n",
      "Epoch 13, Loss: 0.577904762382905\n",
      "Epoch 14, Loss: 0.5765780552779031\n",
      "Epoch 15, Loss: 0.5752933334481529\n",
      "Epoch 16, Loss: 0.5740539677649855\n",
      "Epoch 17, Loss: 0.5728528131678781\n",
      "Epoch 18, Loss: 0.5716909706558367\n",
      "Epoch 19, Loss: 0.5705786306169692\n",
      "Epoch 20, Loss: 0.5695020325417625\n",
      "Epoch 21, Loss: 0.5684394648907525\n",
      "Epoch 22, Loss: 0.5674433454306375\n",
      "Epoch 23, Loss: 0.5664830912063986\n",
      "Epoch 24, Loss: 0.5655268188748158\n",
      "Epoch 25, Loss: 0.5645417404572678\n",
      "Epoch 26, Loss: 0.5636246617160305\n",
      "Epoch 27, Loss: 0.562863947430082\n",
      "Epoch 28, Loss: 0.5621105806445141\n",
      "Epoch 29, Loss: 0.5613350460977014\n",
      "Epoch 30, Loss: 0.5605424887455648\n",
      "Epoch 31, Loss: 0.5597853056169197\n",
      "Epoch 32, Loss: 0.5590362929912589\n",
      "Epoch 33, Loss: 0.5582688727342697\n",
      "Epoch 34, Loss: 0.5574694436085721\n",
      "Epoch 35, Loss: 0.5566185394724297\n",
      "Epoch 36, Loss: 0.5557054929925499\n",
      "Epoch 37, Loss: 0.5546869089902496\n",
      "Epoch 38, Loss: 0.5535251904659185\n",
      "Epoch 39, Loss: 0.5521766895559361\n",
      "Epoch 40, Loss: 0.5505954889102987\n",
      "Epoch 41, Loss: 0.5487189404902064\n",
      "Epoch 42, Loss: 0.5464808269655501\n",
      "Epoch 43, Loss: 0.54383766848763\n",
      "Epoch 44, Loss: 0.5407055954586673\n",
      "Epoch 45, Loss: 0.537020034295558\n",
      "Epoch 46, Loss: 0.5328078149494465\n",
      "Epoch 47, Loss: 0.5282167343735809\n",
      "Epoch 48, Loss: 0.5236676407656644\n",
      "Epoch 49, Loss: 0.5199146433613221\n",
      "Epoch 50, Loss: 0.5180314579859885\n",
      "Epoch 51, Loss: 0.5179452421857865\n",
      "Epoch 52, Loss: 0.5167051618858264\n",
      "Epoch 53, Loss: 0.5129700133685456\n",
      "Epoch 54, Loss: 0.5083387142688721\n",
      "Epoch 55, Loss: 0.5044609388006516\n",
      "Epoch 56, Loss: 0.501879586499303\n",
      "Epoch 57, Loss: 0.5002492938839772\n",
      "Epoch 58, Loss: 0.4987193635025711\n",
      "Epoch 59, Loss: 0.4966793208809061\n",
      "Epoch 60, Loss: 0.49404164404765943\n",
      "Epoch 61, Loss: 0.49111943691459375\n",
      "Epoch 62, Loss: 0.4883401453738682\n",
      "Epoch 63, Loss: 0.4861764479809339\n",
      "Epoch 64, Loss: 0.4848556594787406\n",
      "Epoch 65, Loss: 0.48377030066346166\n",
      "Epoch 66, Loss: 0.48209467305249404\n",
      "Epoch 67, Loss: 0.4796969565040321\n",
      "Epoch 68, Loss: 0.477317774388981\n",
      "Epoch 69, Loss: 0.47559449111797514\n",
      "Epoch 70, Loss: 0.47422099607837565\n",
      "Epoch 71, Loss: 0.4724688040057553\n",
      "Epoch 72, Loss: 0.47021004267347927\n",
      "Epoch 73, Loss: 0.4676330769944395\n",
      "Epoch 74, Loss: 0.46530967890881486\n",
      "Epoch 75, Loss: 0.463509062002537\n",
      "Epoch 76, Loss: 0.46242424048005487\n",
      "Epoch 77, Loss: 0.4621299094170746\n",
      "Epoch 78, Loss: 0.46174620144948886\n",
      "Epoch 79, Loss: 0.4605790538724769\n",
      "Epoch 80, Loss: 0.4593167988244691\n",
      "Epoch 81, Loss: 0.45854810718286726\n",
      "Epoch 82, Loss: 0.45791076738215475\n",
      "Epoch 83, Loss: 0.45718936956288037\n",
      "Epoch 84, Loss: 0.4564191680981509\n",
      "Epoch 85, Loss: 0.4556378863517808\n",
      "Epoch 86, Loss: 0.4550019392821097\n",
      "Epoch 87, Loss: 0.45440348770690325\n",
      "Epoch 88, Loss: 0.4535997304545128\n",
      "Epoch 89, Loss: 0.45272288073347516\n",
      "Epoch 90, Loss: 0.451883522681436\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2123097759759002\n",
      "Test R^2 score: 0.5118369095086713\n",
      "Num of epochs: 91\n",
      "Epoch 1, Loss: 0.5808858674298824\n",
      "Epoch 2, Loss: 0.5786236082032681\n",
      "Epoch 3, Loss: 0.5764490527679023\n",
      "Epoch 4, Loss: 0.5743700982798895\n",
      "Epoch 5, Loss: 0.572380236713141\n",
      "Epoch 6, Loss: 0.570486930404924\n",
      "Epoch 7, Loss: 0.5686957815548105\n",
      "Epoch 8, Loss: 0.5670126201378988\n",
      "Epoch 9, Loss: 0.5654459474956566\n",
      "Epoch 10, Loss: 0.5640024940506596\n",
      "Epoch 11, Loss: 0.5626895108465093\n",
      "Epoch 12, Loss: 0.5614946971670085\n",
      "Epoch 13, Loss: 0.5604236746518843\n",
      "Epoch 14, Loss: 0.5594775004750652\n",
      "Epoch 15, Loss: 0.5586581693196913\n",
      "Epoch 16, Loss: 0.557964236995122\n",
      "Epoch 17, Loss: 0.5573930974855283\n",
      "Epoch 18, Loss: 0.5569362190153938\n",
      "Epoch 19, Loss: 0.5565811125413104\n",
      "Epoch 20, Loss: 0.5563122500187735\n",
      "Epoch 21, Loss: 0.5561109197527115\n",
      "Epoch 22, Loss: 0.5559555924780752\n",
      "Epoch 23, Loss: 0.5558292029549993\n",
      "Epoch 24, Loss: 0.5557039109139614\n",
      "Epoch 25, Loss: 0.5555476919915731\n",
      "Epoch 26, Loss: 0.5553304948182775\n",
      "Epoch 27, Loss: 0.5550228770584394\n",
      "Epoch 28, Loss: 0.5546218672056277\n",
      "Epoch 29, Loss: 0.5541251112001782\n",
      "Epoch 30, Loss: 0.5534962501984676\n",
      "Epoch 31, Loss: 0.5526980061242664\n",
      "Epoch 32, Loss: 0.5517054440112725\n",
      "Epoch 33, Loss: 0.5504637811042907\n",
      "Epoch 34, Loss: 0.5489136435784201\n",
      "Epoch 35, Loss: 0.5469862960915508\n",
      "Epoch 36, Loss: 0.544606107057084\n",
      "Epoch 37, Loss: 0.5416938579287875\n",
      "Epoch 38, Loss: 0.5381909941149079\n",
      "Epoch 39, Loss: 0.5340844161802923\n",
      "Epoch 40, Loss: 0.5295531718651376\n",
      "Epoch 41, Loss: 0.5251039197795428\n",
      "Epoch 42, Loss: 0.5217851207338499\n",
      "Epoch 43, Loss: 0.5206495310395244\n",
      "Epoch 44, Loss: 0.5200245458513354\n",
      "Epoch 45, Loss: 0.5171264116794939\n",
      "Epoch 46, Loss: 0.5128289039587072\n",
      "Epoch 47, Loss: 0.5092011172486129\n",
      "Epoch 48, Loss: 0.5070926846519879\n",
      "Epoch 49, Loss: 0.5058438214006077\n",
      "Epoch 50, Loss: 0.5044141767429768\n",
      "Epoch 51, Loss: 0.5022906048369394\n",
      "Epoch 52, Loss: 0.49954177303643454\n",
      "Epoch 53, Loss: 0.4966978915077817\n",
      "Epoch 54, Loss: 0.49446063931186396\n",
      "Epoch 55, Loss: 0.49324879437728\n",
      "Epoch 56, Loss: 0.492332149624397\n",
      "Epoch 57, Loss: 0.4906138437059645\n",
      "Epoch 58, Loss: 0.4882749175614769\n",
      "Epoch 59, Loss: 0.48627745889147234\n",
      "Epoch 60, Loss: 0.48504160572315197\n",
      "Epoch 61, Loss: 0.48401648574231904\n",
      "Epoch 62, Loss: 0.4825906960083752\n",
      "Epoch 63, Loss: 0.4806556958241917\n",
      "Epoch 64, Loss: 0.4786576040963191\n",
      "Epoch 65, Loss: 0.4771255231579098\n",
      "Epoch 66, Loss: 0.47596320007126064\n",
      "Epoch 67, Loss: 0.47464128865765326\n",
      "Epoch 68, Loss: 0.47302455581693376\n",
      "Epoch 69, Loss: 0.4715954565182027\n",
      "Epoch 70, Loss: 0.47052984886774074\n",
      "Epoch 71, Loss: 0.4694937051497329\n",
      "Epoch 72, Loss: 0.46827906157803534\n",
      "Epoch 73, Loss: 0.4671044074836116\n",
      "Epoch 74, Loss: 0.46621447507093855\n",
      "Epoch 75, Loss: 0.46529682102265185\n",
      "Epoch 76, Loss: 0.46415895621997166\n",
      "Epoch 77, Loss: 0.4630623028281471\n",
      "Epoch 78, Loss: 0.46213026410675573\n",
      "Epoch 79, Loss: 0.46112732292245806\n",
      "Epoch 80, Loss: 0.46006670017343654\n",
      "Epoch 81, Loss: 0.4591877425901749\n",
      "Epoch 82, Loss: 0.45838655538482176\n",
      "Epoch 83, Loss: 0.45746375266039474\n",
      "Epoch 84, Loss: 0.4565913210472587\n",
      "Epoch 85, Loss: 0.4557900488013637\n",
      "Epoch 86, Loss: 0.4549372868496133\n",
      "Epoch 87, Loss: 0.4541465326827606\n",
      "Epoch 88, Loss: 0.45348904225381514\n",
      "Epoch 89, Loss: 0.4527744713209426\n",
      "Epoch 90, Loss: 0.45203994866554914\n",
      "Epoch 91, Loss: 0.45138670195351344\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21370660003771336\n",
      "Test R^2 score: 0.5047650588743443\n",
      "Num of epochs: 92\n",
      "Epoch 1, Loss: 0.5803253469036309\n",
      "Epoch 2, Loss: 0.5788252687634754\n",
      "Epoch 3, Loss: 0.5773794418679443\n",
      "Epoch 4, Loss: 0.5759886110739507\n",
      "Epoch 5, Loss: 0.5746602288102759\n",
      "Epoch 6, Loss: 0.5734043704241226\n",
      "Epoch 7, Loss: 0.5721943781640885\n",
      "Epoch 8, Loss: 0.5710302826438939\n",
      "Epoch 9, Loss: 0.5699129926212896\n",
      "Epoch 10, Loss: 0.5688392736775073\n",
      "Epoch 11, Loss: 0.5678101077997751\n",
      "Epoch 12, Loss: 0.566824212916818\n",
      "Epoch 13, Loss: 0.565883289818264\n",
      "Epoch 14, Loss: 0.5649890137760533\n",
      "Epoch 15, Loss: 0.564141342485936\n",
      "Epoch 16, Loss: 0.5633400366551725\n",
      "Epoch 17, Loss: 0.5625850295331938\n",
      "Epoch 18, Loss: 0.5618754469431626\n",
      "Epoch 19, Loss: 0.5612120453250147\n",
      "Epoch 20, Loss: 0.5606137013227096\n",
      "Epoch 21, Loss: 0.5600647930144724\n",
      "Epoch 22, Loss: 0.5595476502095204\n",
      "Epoch 23, Loss: 0.5590672653447196\n",
      "Epoch 24, Loss: 0.5586157841104695\n",
      "Epoch 25, Loss: 0.5581937838520917\n",
      "Epoch 26, Loss: 0.557801091053437\n",
      "Epoch 27, Loss: 0.5574305233621984\n",
      "Epoch 28, Loss: 0.5570864849339054\n",
      "Epoch 29, Loss: 0.5567617719559392\n",
      "Epoch 30, Loss: 0.5564466975185822\n",
      "Epoch 31, Loss: 0.5561374464710775\n",
      "Epoch 32, Loss: 0.5558231977323138\n",
      "Epoch 33, Loss: 0.5554953857130658\n",
      "Epoch 34, Loss: 0.5551532079826431\n",
      "Epoch 35, Loss: 0.5547769769845567\n",
      "Epoch 36, Loss: 0.5543546080682573\n",
      "Epoch 37, Loss: 0.5538751805984661\n",
      "Epoch 38, Loss: 0.5533252698337595\n",
      "Epoch 39, Loss: 0.5527028860012329\n",
      "Epoch 40, Loss: 0.5519819226483808\n",
      "Epoch 41, Loss: 0.5511433919120629\n",
      "Epoch 42, Loss: 0.550183668680316\n",
      "Epoch 43, Loss: 0.5490675705929076\n",
      "Epoch 44, Loss: 0.5477123933711524\n",
      "Epoch 45, Loss: 0.546034630452736\n",
      "Epoch 46, Loss: 0.5440156298786754\n",
      "Epoch 47, Loss: 0.5417619095722406\n",
      "Epoch 48, Loss: 0.5394723964732108\n",
      "Epoch 49, Loss: 0.5370574093735776\n",
      "Epoch 50, Loss: 0.5343627894830186\n",
      "Epoch 51, Loss: 0.5312144043160821\n",
      "Epoch 52, Loss: 0.5276195793750038\n",
      "Epoch 53, Loss: 0.5235142153419378\n",
      "Epoch 54, Loss: 0.5190694376960128\n",
      "Epoch 55, Loss: 0.5145551101059398\n",
      "Epoch 56, Loss: 0.5100737477256563\n",
      "Epoch 57, Loss: 0.5052575615039112\n",
      "Epoch 58, Loss: 0.49963261100654394\n",
      "Epoch 59, Loss: 0.4938356717544939\n",
      "Epoch 60, Loss: 0.48888393591349033\n",
      "Epoch 61, Loss: 0.4854210049785983\n",
      "Epoch 62, Loss: 0.48304017016801115\n",
      "Epoch 63, Loss: 0.4808131588527579\n",
      "Epoch 64, Loss: 0.4785693858561609\n",
      "Epoch 65, Loss: 0.4767487427795428\n",
      "Epoch 66, Loss: 0.4750228619093082\n",
      "Epoch 67, Loss: 0.4732701122123225\n",
      "Epoch 68, Loss: 0.47184823067630377\n",
      "Epoch 69, Loss: 0.4714120140899176\n",
      "Epoch 70, Loss: 0.47053661012861553\n",
      "Epoch 71, Loss: 0.4699319085296992\n",
      "Epoch 72, Loss: 0.469603381590674\n",
      "Epoch 73, Loss: 0.46852791611523337\n",
      "Epoch 74, Loss: 0.46721249197771514\n",
      "Epoch 75, Loss: 0.4663382795381489\n",
      "Epoch 76, Loss: 0.464937072490132\n",
      "Epoch 77, Loss: 0.4636374296073678\n",
      "Epoch 78, Loss: 0.46268642122317344\n",
      "Epoch 79, Loss: 0.4614955788759128\n",
      "Epoch 80, Loss: 0.4605057035490582\n",
      "Epoch 81, Loss: 0.4597377357029467\n",
      "Epoch 82, Loss: 0.4586471617494097\n",
      "Epoch 83, Loss: 0.457927737525954\n",
      "Epoch 84, Loss: 0.45723522557749585\n",
      "Epoch 85, Loss: 0.45637616869072334\n",
      "Epoch 86, Loss: 0.4556534695201344\n",
      "Epoch 87, Loss: 0.45480448145453406\n",
      "Epoch 88, Loss: 0.453985154192769\n",
      "Epoch 89, Loss: 0.45331140498753947\n",
      "Epoch 90, Loss: 0.4525513800013626\n",
      "Epoch 91, Loss: 0.45191240844371106\n",
      "Epoch 92, Loss: 0.4512808366790394\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2159477881205905\n",
      "Test R^2 score: 0.4955013438891375\n",
      "Num of epochs: 93\n",
      "Epoch 1, Loss: 0.5832399707966931\n",
      "Epoch 2, Loss: 0.5808220918717805\n",
      "Epoch 3, Loss: 0.5785366603161707\n",
      "Epoch 4, Loss: 0.5763785815817438\n",
      "Epoch 5, Loss: 0.574363145384216\n",
      "Epoch 6, Loss: 0.5724737940958107\n",
      "Epoch 7, Loss: 0.5707085162044564\n",
      "Epoch 8, Loss: 0.5690713990891444\n",
      "Epoch 9, Loss: 0.5675581170458849\n",
      "Epoch 10, Loss: 0.566163609590307\n",
      "Epoch 11, Loss: 0.5648724539442564\n",
      "Epoch 12, Loss: 0.5636826903428478\n",
      "Epoch 13, Loss: 0.5625920485309913\n",
      "Epoch 14, Loss: 0.5615987179921534\n",
      "Epoch 15, Loss: 0.5607003191361761\n",
      "Epoch 16, Loss: 0.5598937692530237\n",
      "Epoch 17, Loss: 0.5591768542506756\n",
      "Epoch 18, Loss: 0.5585486120380057\n",
      "Epoch 19, Loss: 0.5579914500528317\n",
      "Epoch 20, Loss: 0.557525333248063\n",
      "Epoch 21, Loss: 0.5571255896935136\n",
      "Epoch 22, Loss: 0.5567959217477119\n",
      "Epoch 23, Loss: 0.5565302421478874\n",
      "Epoch 24, Loss: 0.5563079375193616\n",
      "Epoch 25, Loss: 0.5561228167404633\n",
      "Epoch 26, Loss: 0.555965991863472\n",
      "Epoch 27, Loss: 0.5558410791641866\n",
      "Epoch 28, Loss: 0.5557266763227937\n",
      "Epoch 29, Loss: 0.5556061350792002\n",
      "Epoch 30, Loss: 0.5554684527647187\n",
      "Epoch 31, Loss: 0.5553375786746502\n",
      "Epoch 32, Loss: 0.555192234194762\n",
      "Epoch 33, Loss: 0.5550169168076389\n",
      "Epoch 34, Loss: 0.5548042389432032\n",
      "Epoch 35, Loss: 0.5545603378031908\n",
      "Epoch 36, Loss: 0.5542774027656312\n",
      "Epoch 37, Loss: 0.5539617491816804\n",
      "Epoch 38, Loss: 0.553580536196099\n",
      "Epoch 39, Loss: 0.5531100017863357\n",
      "Epoch 40, Loss: 0.5525186879462644\n",
      "Epoch 41, Loss: 0.5517900845702453\n",
      "Epoch 42, Loss: 0.5509094738336601\n",
      "Epoch 43, Loss: 0.549870949473793\n",
      "Epoch 44, Loss: 0.5486880629393535\n",
      "Epoch 45, Loss: 0.5473457490153266\n",
      "Epoch 46, Loss: 0.5458253596599462\n",
      "Epoch 47, Loss: 0.5441252652182306\n",
      "Epoch 48, Loss: 0.5422890889529929\n",
      "Epoch 49, Loss: 0.540355789541978\n",
      "Epoch 50, Loss: 0.538331296058713\n",
      "Epoch 51, Loss: 0.536023766383948\n",
      "Epoch 52, Loss: 0.5332709188994635\n",
      "Epoch 53, Loss: 0.5299762433953632\n",
      "Epoch 54, Loss: 0.526050309465874\n",
      "Epoch 55, Loss: 0.5213671205977454\n",
      "Epoch 56, Loss: 0.515747402574782\n",
      "Epoch 57, Loss: 0.5090257383389258\n",
      "Epoch 58, Loss: 0.5012368461138665\n",
      "Epoch 59, Loss: 0.4928907789180828\n",
      "Epoch 60, Loss: 0.4856031291656603\n",
      "Epoch 61, Loss: 0.482488110277213\n",
      "Epoch 62, Loss: 0.48280793160064195\n",
      "Epoch 63, Loss: 0.48036881314655444\n",
      "Epoch 64, Loss: 0.4757996378635473\n",
      "Epoch 65, Loss: 0.4726715085427703\n",
      "Epoch 66, Loss: 0.4723249330346838\n",
      "Epoch 67, Loss: 0.47264199984168065\n",
      "Epoch 68, Loss: 0.4720866183525505\n",
      "Epoch 69, Loss: 0.47098528054495836\n",
      "Epoch 70, Loss: 0.47007977693789565\n",
      "Epoch 71, Loss: 0.4695583208756987\n",
      "Epoch 72, Loss: 0.46883827014149626\n",
      "Epoch 73, Loss: 0.467277343429576\n",
      "Epoch 74, Loss: 0.4655659458935723\n",
      "Epoch 75, Loss: 0.46433268429988533\n",
      "Epoch 76, Loss: 0.46348157414597424\n",
      "Epoch 77, Loss: 0.46294521862922416\n",
      "Epoch 78, Loss: 0.4625330642531624\n",
      "Epoch 79, Loss: 0.4619483693066934\n",
      "Epoch 80, Loss: 0.4611787487967252\n",
      "Epoch 81, Loss: 0.4603388017804492\n",
      "Epoch 82, Loss: 0.4595681880669993\n",
      "Epoch 83, Loss: 0.45886025881177994\n",
      "Epoch 84, Loss: 0.45824476672366865\n",
      "Epoch 85, Loss: 0.4577738605636958\n",
      "Epoch 86, Loss: 0.45740521447049565\n",
      "Epoch 87, Loss: 0.4569645531396483\n",
      "Epoch 88, Loss: 0.45632242189725175\n",
      "Epoch 89, Loss: 0.45562338191662133\n",
      "Epoch 90, Loss: 0.4550729022729158\n",
      "Epoch 91, Loss: 0.454704589784762\n",
      "Epoch 92, Loss: 0.45437423559069445\n",
      "Epoch 93, Loss: 0.453931107882706\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21362425189447043\n",
      "Test R^2 score: 0.5065686482473732\n",
      "Num of epochs: 94\n",
      "Epoch 1, Loss: 0.5763407055760377\n",
      "Epoch 2, Loss: 0.5742247185429339\n",
      "Epoch 3, Loss: 0.5722094563595138\n",
      "Epoch 4, Loss: 0.5702944452223606\n",
      "Epoch 5, Loss: 0.5685170010781628\n",
      "Epoch 6, Loss: 0.5670782640843939\n",
      "Epoch 7, Loss: 0.5657085725785154\n",
      "Epoch 8, Loss: 0.5644213393610404\n",
      "Epoch 9, Loss: 0.5632211512912497\n",
      "Epoch 10, Loss: 0.5621127809125772\n",
      "Epoch 11, Loss: 0.5611023758873466\n",
      "Epoch 12, Loss: 0.5601924613197525\n",
      "Epoch 13, Loss: 0.5593938099772685\n",
      "Epoch 14, Loss: 0.5587023649456168\n",
      "Epoch 15, Loss: 0.5580977258286982\n",
      "Epoch 16, Loss: 0.5575812974593423\n",
      "Epoch 17, Loss: 0.5571537263040579\n",
      "Epoch 18, Loss: 0.5568112028335703\n",
      "Epoch 19, Loss: 0.5565685024719582\n",
      "Epoch 20, Loss: 0.5564020816911441\n",
      "Epoch 21, Loss: 0.556301910678463\n",
      "Epoch 22, Loss: 0.5562562117069033\n",
      "Epoch 23, Loss: 0.556250130728374\n",
      "Epoch 24, Loss: 0.5562741327944277\n",
      "Epoch 25, Loss: 0.5563127589450702\n",
      "Epoch 26, Loss: 0.5563515431163043\n",
      "Epoch 27, Loss: 0.5563838433390141\n",
      "Epoch 28, Loss: 0.5564056168091708\n",
      "Epoch 29, Loss: 0.556413463619684\n",
      "Epoch 30, Loss: 0.5564039831589348\n",
      "Epoch 31, Loss: 0.5563761032408946\n",
      "Epoch 32, Loss: 0.556321330265378\n",
      "Epoch 33, Loss: 0.5562341109160291\n",
      "Epoch 34, Loss: 0.5560976559190165\n",
      "Epoch 35, Loss: 0.555890189822614\n",
      "Epoch 36, Loss: 0.5556321227107376\n",
      "Epoch 37, Loss: 0.555257611715056\n",
      "Epoch 38, Loss: 0.5548391537810313\n",
      "Epoch 39, Loss: 0.5543256035766839\n",
      "Epoch 40, Loss: 0.5537105607396481\n",
      "Epoch 41, Loss: 0.5530216023414694\n",
      "Epoch 42, Loss: 0.55228308596781\n",
      "Epoch 43, Loss: 0.5514785194761612\n",
      "Epoch 44, Loss: 0.5505217894729593\n",
      "Epoch 45, Loss: 0.5493090006011218\n",
      "Epoch 46, Loss: 0.5476869550034248\n",
      "Epoch 47, Loss: 0.5455208771012222\n",
      "Epoch 48, Loss: 0.5427612072698169\n",
      "Epoch 49, Loss: 0.5395170037238912\n",
      "Epoch 50, Loss: 0.5359655789952148\n",
      "Epoch 51, Loss: 0.532520430043125\n",
      "Epoch 52, Loss: 0.529281813065864\n",
      "Epoch 53, Loss: 0.526563080693952\n",
      "Epoch 54, Loss: 0.5242033806948349\n",
      "Epoch 55, Loss: 0.5214789172397716\n",
      "Epoch 56, Loss: 0.5184573209628476\n",
      "Epoch 57, Loss: 0.5156165613582081\n",
      "Epoch 58, Loss: 0.5132818735894025\n",
      "Epoch 59, Loss: 0.5111790788793837\n",
      "Epoch 60, Loss: 0.508944086923455\n",
      "Epoch 61, Loss: 0.5062573903333215\n",
      "Epoch 62, Loss: 0.5030736032142882\n",
      "Epoch 63, Loss: 0.49977749105430613\n",
      "Epoch 64, Loss: 0.4966619646673347\n",
      "Epoch 65, Loss: 0.49384593092058987\n",
      "Epoch 66, Loss: 0.4911214849424415\n",
      "Epoch 67, Loss: 0.4882833557083502\n",
      "Epoch 68, Loss: 0.4855462648935697\n",
      "Epoch 69, Loss: 0.4830344168512383\n",
      "Epoch 70, Loss: 0.48039763009545283\n",
      "Epoch 71, Loss: 0.47751882623338576\n",
      "Epoch 72, Loss: 0.4746960376376043\n",
      "Epoch 73, Loss: 0.47228566924691573\n",
      "Epoch 74, Loss: 0.47014039778299016\n",
      "Epoch 75, Loss: 0.4680126430706978\n",
      "Epoch 76, Loss: 0.46624603650758106\n",
      "Epoch 77, Loss: 0.4646001706543427\n",
      "Epoch 78, Loss: 0.46284959506626716\n",
      "Epoch 79, Loss: 0.461410199260507\n",
      "Epoch 80, Loss: 0.4601907662106466\n",
      "Epoch 81, Loss: 0.458986176832193\n",
      "Epoch 82, Loss: 0.45801942725186623\n",
      "Epoch 83, Loss: 0.457082843313705\n",
      "Epoch 84, Loss: 0.4559964912743849\n",
      "Epoch 85, Loss: 0.4549112791766231\n",
      "Epoch 86, Loss: 0.4536975170553117\n",
      "Epoch 87, Loss: 0.4524500357984178\n",
      "Epoch 88, Loss: 0.45119811473027305\n",
      "Epoch 89, Loss: 0.44981535394952343\n",
      "Epoch 90, Loss: 0.44842862841506775\n",
      "Epoch 91, Loss: 0.44699581620479384\n",
      "Epoch 92, Loss: 0.4455933605374042\n",
      "Epoch 93, Loss: 0.44416998813966574\n",
      "Epoch 94, Loss: 0.44278740644189857\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2163352726282644\n",
      "Test R^2 score: 0.4940291350065739\n",
      "Num of epochs: 95\n",
      "Epoch 1, Loss: 0.6001135976860682\n",
      "Epoch 2, Loss: 0.5971444375617924\n",
      "Epoch 3, Loss: 0.5942637329167729\n",
      "Epoch 4, Loss: 0.5914673847967357\n",
      "Epoch 5, Loss: 0.5887575316301731\n",
      "Epoch 6, Loss: 0.5861451353298669\n",
      "Epoch 7, Loss: 0.583619402381654\n",
      "Epoch 8, Loss: 0.5811800268570434\n",
      "Epoch 9, Loss: 0.5789166262954135\n",
      "Epoch 10, Loss: 0.5767771241300435\n",
      "Epoch 11, Loss: 0.5748859603410996\n",
      "Epoch 12, Loss: 0.5731697621644158\n",
      "Epoch 13, Loss: 0.5716347716176343\n",
      "Epoch 14, Loss: 0.5703383923231332\n",
      "Epoch 15, Loss: 0.5691275108779693\n",
      "Epoch 16, Loss: 0.5679356152131795\n",
      "Epoch 17, Loss: 0.566766085271491\n",
      "Epoch 18, Loss: 0.5656232486086544\n",
      "Epoch 19, Loss: 0.5645125202753593\n",
      "Epoch 20, Loss: 0.5634947828391507\n",
      "Epoch 21, Loss: 0.5625752557639764\n",
      "Epoch 22, Loss: 0.5616994300034619\n",
      "Epoch 23, Loss: 0.5608767027568708\n",
      "Epoch 24, Loss: 0.5601022532040607\n",
      "Epoch 25, Loss: 0.5593067500498464\n",
      "Epoch 26, Loss: 0.5585946569902219\n",
      "Epoch 27, Loss: 0.5579047856004765\n",
      "Epoch 28, Loss: 0.5572314422960676\n",
      "Epoch 29, Loss: 0.5565468692458785\n",
      "Epoch 30, Loss: 0.5558527406576729\n",
      "Epoch 31, Loss: 0.5551511948642827\n",
      "Epoch 32, Loss: 0.5544037966468851\n",
      "Epoch 33, Loss: 0.5536029044225335\n",
      "Epoch 34, Loss: 0.5527212997345793\n",
      "Epoch 35, Loss: 0.5517296167781937\n",
      "Epoch 36, Loss: 0.550621929528187\n",
      "Epoch 37, Loss: 0.5494196951503171\n",
      "Epoch 38, Loss: 0.5481132113712511\n",
      "Epoch 39, Loss: 0.5466443801713828\n",
      "Epoch 40, Loss: 0.5449375710910068\n",
      "Epoch 41, Loss: 0.5428381014833032\n",
      "Epoch 42, Loss: 0.5402855198634242\n",
      "Epoch 43, Loss: 0.5375709908201485\n",
      "Epoch 44, Loss: 0.5346531974807459\n",
      "Epoch 45, Loss: 0.5315922588291371\n",
      "Epoch 46, Loss: 0.5284628120645034\n",
      "Epoch 47, Loss: 0.5253831089999543\n",
      "Epoch 48, Loss: 0.5223351157727448\n",
      "Epoch 49, Loss: 0.5194776120139323\n",
      "Epoch 50, Loss: 0.5168765801678896\n",
      "Epoch 51, Loss: 0.5143895230844475\n",
      "Epoch 52, Loss: 0.5120394335253735\n",
      "Epoch 53, Loss: 0.5098434330398272\n",
      "Epoch 54, Loss: 0.50769029760852\n",
      "Epoch 55, Loss: 0.5053287801673728\n",
      "Epoch 56, Loss: 0.5027634132849469\n",
      "Epoch 57, Loss: 0.5000574853753175\n",
      "Epoch 58, Loss: 0.4972616700451905\n",
      "Epoch 59, Loss: 0.4944879268815562\n",
      "Epoch 60, Loss: 0.4918728231214657\n",
      "Epoch 61, Loss: 0.4893516861634843\n",
      "Epoch 62, Loss: 0.48674136150612024\n",
      "Epoch 63, Loss: 0.4840131453983099\n",
      "Epoch 64, Loss: 0.48122893262551647\n",
      "Epoch 65, Loss: 0.47855450219242707\n",
      "Epoch 66, Loss: 0.4760085623045185\n",
      "Epoch 67, Loss: 0.4735746210275674\n",
      "Epoch 68, Loss: 0.4712531014803308\n",
      "Epoch 69, Loss: 0.4690028303494077\n",
      "Epoch 70, Loss: 0.46678530307615734\n",
      "Epoch 71, Loss: 0.46469593102016077\n",
      "Epoch 72, Loss: 0.4628065491627956\n",
      "Epoch 73, Loss: 0.4610618649830375\n",
      "Epoch 74, Loss: 0.4594127036211526\n",
      "Epoch 75, Loss: 0.45786847758561744\n",
      "Epoch 76, Loss: 0.4565363103207634\n",
      "Epoch 77, Loss: 0.4553709929627911\n",
      "Epoch 78, Loss: 0.4542844998616783\n",
      "Epoch 79, Loss: 0.45319795021294734\n",
      "Epoch 80, Loss: 0.45214196153126757\n",
      "Epoch 81, Loss: 0.4511956873302948\n",
      "Epoch 82, Loss: 0.45027456185968356\n",
      "Epoch 83, Loss: 0.4492831142588778\n",
      "Epoch 84, Loss: 0.44824318480536524\n",
      "Epoch 85, Loss: 0.44713565653855813\n",
      "Epoch 86, Loss: 0.4459726058892706\n",
      "Epoch 87, Loss: 0.44484604280535467\n",
      "Epoch 88, Loss: 0.4437550027323515\n",
      "Epoch 89, Loss: 0.44269629817386047\n",
      "Epoch 90, Loss: 0.4417229419370357\n",
      "Epoch 91, Loss: 0.440970991121244\n",
      "Epoch 92, Loss: 0.4399730234925506\n",
      "Epoch 93, Loss: 0.43858094873830467\n",
      "Epoch 94, Loss: 0.43787638618125685\n",
      "Epoch 95, Loss: 0.43694832624408847\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22073750226432523\n",
      "Test R^2 score: 0.47393663845030987\n",
      "Num of epochs: 96\n",
      "Epoch 1, Loss: 0.5578896413083145\n",
      "Epoch 2, Loss: 0.5572669537730428\n",
      "Epoch 3, Loss: 0.5567949047779023\n",
      "Epoch 4, Loss: 0.5564649070323844\n",
      "Epoch 5, Loss: 0.5562696324859299\n",
      "Epoch 6, Loss: 0.5561889957879826\n",
      "Epoch 7, Loss: 0.5561881116663729\n",
      "Epoch 8, Loss: 0.5562300924960706\n",
      "Epoch 9, Loss: 0.5562904193208834\n",
      "Epoch 10, Loss: 0.5563400795681641\n",
      "Epoch 11, Loss: 0.5563637563563085\n",
      "Epoch 12, Loss: 0.5563563373806399\n",
      "Epoch 13, Loss: 0.5563215981170097\n",
      "Epoch 14, Loss: 0.5562681591627371\n",
      "Epoch 15, Loss: 0.5562054723426523\n",
      "Epoch 16, Loss: 0.5561420550244526\n",
      "Epoch 17, Loss: 0.5560841505996565\n",
      "Epoch 18, Loss: 0.5560350302734576\n",
      "Epoch 19, Loss: 0.5559954467988368\n",
      "Epoch 20, Loss: 0.5559616498756972\n",
      "Epoch 21, Loss: 0.5559290034742198\n",
      "Epoch 22, Loss: 0.5558908063589797\n",
      "Epoch 23, Loss: 0.5558413204389441\n",
      "Epoch 24, Loss: 0.5557732499956853\n",
      "Epoch 25, Loss: 0.5556808227800346\n",
      "Epoch 26, Loss: 0.5555609957773026\n",
      "Epoch 27, Loss: 0.555410934207845\n",
      "Epoch 28, Loss: 0.5552284128543407\n",
      "Epoch 29, Loss: 0.5550106880086757\n",
      "Epoch 30, Loss: 0.5547525072286094\n",
      "Epoch 31, Loss: 0.5544443537822021\n",
      "Epoch 32, Loss: 0.554071110778441\n",
      "Epoch 33, Loss: 0.553617789155429\n",
      "Epoch 34, Loss: 0.5530650359587155\n",
      "Epoch 35, Loss: 0.5523844983125274\n",
      "Epoch 36, Loss: 0.5515112401901073\n",
      "Epoch 37, Loss: 0.5503990795387705\n",
      "Epoch 38, Loss: 0.5490040615900854\n",
      "Epoch 39, Loss: 0.5472181605926837\n",
      "Epoch 40, Loss: 0.5450384090608037\n",
      "Epoch 41, Loss: 0.5424611305340308\n",
      "Epoch 42, Loss: 0.5395134131838566\n",
      "Epoch 43, Loss: 0.5361968733518163\n",
      "Epoch 44, Loss: 0.5324369522165345\n",
      "Epoch 45, Loss: 0.5281319837842028\n",
      "Epoch 46, Loss: 0.5233809027747796\n",
      "Epoch 47, Loss: 0.518521381465196\n",
      "Epoch 48, Loss: 0.5141060158535438\n",
      "Epoch 49, Loss: 0.5112321884578137\n",
      "Epoch 50, Loss: 0.5101079266548306\n",
      "Epoch 51, Loss: 0.5081633896067795\n",
      "Epoch 52, Loss: 0.5046861807980141\n",
      "Epoch 53, Loss: 0.500951903927969\n",
      "Epoch 54, Loss: 0.4982531400917509\n",
      "Epoch 55, Loss: 0.4963857287138695\n",
      "Epoch 56, Loss: 0.49478529541196775\n",
      "Epoch 57, Loss: 0.4929541112597364\n",
      "Epoch 58, Loss: 0.4907053019173637\n",
      "Epoch 59, Loss: 0.48808838659361264\n",
      "Epoch 60, Loss: 0.4853633978953006\n",
      "Epoch 61, Loss: 0.4829688735611263\n",
      "Epoch 62, Loss: 0.48106256092116245\n",
      "Epoch 63, Loss: 0.47933736815078587\n",
      "Epoch 64, Loss: 0.4772970136123442\n",
      "Epoch 65, Loss: 0.47490594961753424\n",
      "Epoch 66, Loss: 0.47306471900454783\n",
      "Epoch 67, Loss: 0.4716942826376431\n",
      "Epoch 68, Loss: 0.4704831190901709\n",
      "Epoch 69, Loss: 0.4691596784065576\n",
      "Epoch 70, Loss: 0.4676813022927271\n",
      "Epoch 71, Loss: 0.46627369695175297\n",
      "Epoch 72, Loss: 0.465205492585263\n",
      "Epoch 73, Loss: 0.46439787373228525\n",
      "Epoch 74, Loss: 0.46351235722094447\n",
      "Epoch 75, Loss: 0.4625504124720092\n",
      "Epoch 76, Loss: 0.4617453623943069\n",
      "Epoch 77, Loss: 0.4611043143282146\n",
      "Epoch 78, Loss: 0.4605303598796419\n",
      "Epoch 79, Loss: 0.4598863059238216\n",
      "Epoch 80, Loss: 0.45927004750560113\n",
      "Epoch 81, Loss: 0.45869264462397036\n",
      "Epoch 82, Loss: 0.45811685593926654\n",
      "Epoch 83, Loss: 0.45751645342627195\n",
      "Epoch 84, Loss: 0.4568901985500176\n",
      "Epoch 85, Loss: 0.45625353119411205\n",
      "Epoch 86, Loss: 0.45560019348389935\n",
      "Epoch 87, Loss: 0.4549835172224787\n",
      "Epoch 88, Loss: 0.45436938191840626\n",
      "Epoch 89, Loss: 0.45373635321448325\n",
      "Epoch 90, Loss: 0.4530672825852796\n",
      "Epoch 91, Loss: 0.45239335218055576\n",
      "Epoch 92, Loss: 0.45171176924799067\n",
      "Epoch 93, Loss: 0.45099905758376524\n",
      "Epoch 94, Loss: 0.45016505869992873\n",
      "Epoch 95, Loss: 0.4492357831296485\n",
      "Epoch 96, Loss: 0.44849362105252877\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21768238237164692\n",
      "Test R^2 score: 0.4878301843518427\n",
      "Num of epochs: 97\n",
      "Epoch 1, Loss: 0.5597777456500662\n",
      "Epoch 2, Loss: 0.5590005207195825\n",
      "Epoch 3, Loss: 0.5583308474879178\n",
      "Epoch 4, Loss: 0.5577731741071003\n",
      "Epoch 5, Loss: 0.5573287725722107\n",
      "Epoch 6, Loss: 0.5569693949679133\n",
      "Epoch 7, Loss: 0.5566827323112389\n",
      "Epoch 8, Loss: 0.5564736098983816\n",
      "Epoch 9, Loss: 0.5563058750078252\n",
      "Epoch 10, Loss: 0.556197569015551\n",
      "Epoch 11, Loss: 0.5561249335201719\n",
      "Epoch 12, Loss: 0.5560861871370687\n",
      "Epoch 13, Loss: 0.5560558526764197\n",
      "Epoch 14, Loss: 0.5560317875896988\n",
      "Epoch 15, Loss: 0.5560063010448759\n",
      "Epoch 16, Loss: 0.5559738716805999\n",
      "Epoch 17, Loss: 0.555928762237517\n",
      "Epoch 18, Loss: 0.5558672702681642\n",
      "Epoch 19, Loss: 0.5557816955804848\n",
      "Epoch 20, Loss: 0.5556674950465157\n",
      "Epoch 21, Loss: 0.5555229074766201\n",
      "Epoch 22, Loss: 0.5553429183399915\n",
      "Epoch 23, Loss: 0.5551219904061475\n",
      "Epoch 24, Loss: 0.5548554018602464\n",
      "Epoch 25, Loss: 0.5545436242712235\n",
      "Epoch 26, Loss: 0.5541769283702191\n",
      "Epoch 27, Loss: 0.5537394898065174\n",
      "Epoch 28, Loss: 0.5532217943230266\n",
      "Epoch 29, Loss: 0.5526277958320972\n",
      "Epoch 30, Loss: 0.5519312763141836\n",
      "Epoch 31, Loss: 0.5511003205848914\n",
      "Epoch 32, Loss: 0.5501104287348091\n",
      "Epoch 33, Loss: 0.5489316143600744\n",
      "Epoch 34, Loss: 0.5475388448687154\n",
      "Epoch 35, Loss: 0.5459298822562583\n",
      "Epoch 36, Loss: 0.5441168851801598\n",
      "Epoch 37, Loss: 0.542080406363832\n",
      "Epoch 38, Loss: 0.5397525185812937\n",
      "Epoch 39, Loss: 0.5370101559635835\n",
      "Epoch 40, Loss: 0.533691322487199\n",
      "Epoch 41, Loss: 0.52957872157136\n",
      "Epoch 42, Loss: 0.524626307097073\n",
      "Epoch 43, Loss: 0.5189094838331952\n",
      "Epoch 44, Loss: 0.5126263962703164\n",
      "Epoch 45, Loss: 0.5062234812725646\n",
      "Epoch 46, Loss: 0.5007726243060305\n",
      "Epoch 47, Loss: 0.49797738282327664\n",
      "Epoch 48, Loss: 0.4973571189739802\n",
      "Epoch 49, Loss: 0.49465547661621745\n",
      "Epoch 50, Loss: 0.4896996305870546\n",
      "Epoch 51, Loss: 0.4849476966479123\n",
      "Epoch 52, Loss: 0.4819229263933874\n",
      "Epoch 53, Loss: 0.4806543782485877\n",
      "Epoch 54, Loss: 0.4802240353276866\n",
      "Epoch 55, Loss: 0.4797047534287633\n",
      "Epoch 56, Loss: 0.47876490114094505\n",
      "Epoch 57, Loss: 0.47743362791826055\n",
      "Epoch 58, Loss: 0.47588066665946926\n",
      "Epoch 59, Loss: 0.47448195014525196\n",
      "Epoch 60, Loss: 0.47344734257201937\n",
      "Epoch 61, Loss: 0.4725045047272795\n",
      "Epoch 62, Loss: 0.47180433186252063\n",
      "Epoch 63, Loss: 0.47057779313477377\n",
      "Epoch 64, Loss: 0.4686040015147072\n",
      "Epoch 65, Loss: 0.4671016320765408\n",
      "Epoch 66, Loss: 0.4665896063287157\n",
      "Epoch 67, Loss: 0.46649854695685666\n",
      "Epoch 68, Loss: 0.46612311863743333\n",
      "Epoch 69, Loss: 0.4652728656569602\n",
      "Epoch 70, Loss: 0.464191106835412\n",
      "Epoch 71, Loss: 0.46333065123376366\n",
      "Epoch 72, Loss: 0.4627175631311792\n",
      "Epoch 73, Loss: 0.4620393095323009\n",
      "Epoch 74, Loss: 0.46119186688904473\n",
      "Epoch 75, Loss: 0.46033674628166293\n",
      "Epoch 76, Loss: 0.4596660665031445\n",
      "Epoch 77, Loss: 0.4591566695817175\n",
      "Epoch 78, Loss: 0.45861943122662313\n",
      "Epoch 79, Loss: 0.4579898692441115\n",
      "Epoch 80, Loss: 0.45739425197887723\n",
      "Epoch 81, Loss: 0.4569367694194068\n",
      "Epoch 82, Loss: 0.4565042244693791\n",
      "Epoch 83, Loss: 0.45595193232179043\n",
      "Epoch 84, Loss: 0.45532540737019306\n",
      "Epoch 85, Loss: 0.45478211955407616\n",
      "Epoch 86, Loss: 0.4543538530982916\n",
      "Epoch 87, Loss: 0.4538833750280673\n",
      "Epoch 88, Loss: 0.4533296977743525\n",
      "Epoch 89, Loss: 0.45280966803255507\n",
      "Epoch 90, Loss: 0.452368565275665\n",
      "Epoch 91, Loss: 0.45189677870569483\n",
      "Epoch 92, Loss: 0.45136362600138813\n",
      "Epoch 93, Loss: 0.45084081616540767\n",
      "Epoch 94, Loss: 0.45035703985447073\n",
      "Epoch 95, Loss: 0.44983092350377296\n",
      "Epoch 96, Loss: 0.4492776749152847\n",
      "Epoch 97, Loss: 0.44877348684302637\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2128449605689588\n",
      "Test R^2 score: 0.510576108932536\n",
      "Num of epochs: 98\n",
      "Epoch 1, Loss: 0.5922761241856282\n",
      "Epoch 2, Loss: 0.5897191402354568\n",
      "Epoch 3, Loss: 0.5872523749763465\n",
      "Epoch 4, Loss: 0.5848725368336195\n",
      "Epoch 5, Loss: 0.5826282639558347\n",
      "Epoch 6, Loss: 0.5806916970337502\n",
      "Epoch 7, Loss: 0.5788127056533783\n",
      "Epoch 8, Loss: 0.5769959069095267\n",
      "Epoch 9, Loss: 0.5752468636537919\n",
      "Epoch 10, Loss: 0.5735647148778757\n",
      "Epoch 11, Loss: 0.5719789170868074\n",
      "Epoch 12, Loss: 0.5704764300382907\n",
      "Epoch 13, Loss: 0.5690459204682808\n",
      "Epoch 14, Loss: 0.5676823677167817\n",
      "Epoch 15, Loss: 0.5663453957324803\n",
      "Epoch 16, Loss: 0.5650764112790678\n",
      "Epoch 17, Loss: 0.5638790973691203\n",
      "Epoch 18, Loss: 0.5627564534393897\n",
      "Epoch 19, Loss: 0.5617111820989784\n",
      "Epoch 20, Loss: 0.5607463468465802\n",
      "Epoch 21, Loss: 0.5598955524059448\n",
      "Epoch 22, Loss: 0.559114093777342\n",
      "Epoch 23, Loss: 0.5584122422904596\n",
      "Epoch 24, Loss: 0.5577913136025074\n",
      "Epoch 25, Loss: 0.5572469253643471\n",
      "Epoch 26, Loss: 0.5567756087619067\n",
      "Epoch 27, Loss: 0.5563697021787508\n",
      "Epoch 28, Loss: 0.5560165922824625\n",
      "Epoch 29, Loss: 0.5557116335599963\n",
      "Epoch 30, Loss: 0.5554497008672176\n",
      "Epoch 31, Loss: 0.5552212202522074\n",
      "Epoch 32, Loss: 0.5549994652547924\n",
      "Epoch 33, Loss: 0.5547478065481741\n",
      "Epoch 34, Loss: 0.5544456975728851\n",
      "Epoch 35, Loss: 0.5540674800831872\n",
      "Epoch 36, Loss: 0.5535907379421602\n",
      "Epoch 37, Loss: 0.5529988333567338\n",
      "Epoch 38, Loss: 0.5522333577084662\n",
      "Epoch 39, Loss: 0.5512447436075606\n",
      "Epoch 40, Loss: 0.5499971097089944\n",
      "Epoch 41, Loss: 0.5484376108544392\n",
      "Epoch 42, Loss: 0.5465070303964681\n",
      "Epoch 43, Loss: 0.5441572231984395\n",
      "Epoch 44, Loss: 0.5413541320111771\n",
      "Epoch 45, Loss: 0.538057856164514\n",
      "Epoch 46, Loss: 0.5342647617248213\n",
      "Epoch 47, Loss: 0.5300370843526973\n",
      "Epoch 48, Loss: 0.5256713344186925\n",
      "Epoch 49, Loss: 0.5217728977488735\n",
      "Epoch 50, Loss: 0.5191025076277763\n",
      "Epoch 51, Loss: 0.5174170477352663\n",
      "Epoch 52, Loss: 0.5146835575751839\n",
      "Epoch 53, Loss: 0.5104965582104819\n",
      "Epoch 54, Loss: 0.506710147131799\n",
      "Epoch 55, Loss: 0.5044398772101313\n",
      "Epoch 56, Loss: 0.5030652206163445\n",
      "Epoch 57, Loss: 0.5012729652832646\n",
      "Epoch 58, Loss: 0.49865529913278817\n",
      "Epoch 59, Loss: 0.4958375284140363\n",
      "Epoch 60, Loss: 0.4938278414534286\n",
      "Epoch 61, Loss: 0.4927057988650708\n",
      "Epoch 62, Loss: 0.4910745450329665\n",
      "Epoch 63, Loss: 0.48850818700967763\n",
      "Epoch 64, Loss: 0.48619309048197534\n",
      "Epoch 65, Loss: 0.48473271112956023\n",
      "Epoch 66, Loss: 0.48325277889042784\n",
      "Epoch 67, Loss: 0.48114484034378885\n",
      "Epoch 68, Loss: 0.4789512519788602\n",
      "Epoch 69, Loss: 0.4773726222020753\n",
      "Epoch 70, Loss: 0.47593234564732184\n",
      "Epoch 71, Loss: 0.4740476227238304\n",
      "Epoch 72, Loss: 0.4723145850007973\n",
      "Epoch 73, Loss: 0.4713896655489857\n",
      "Epoch 74, Loss: 0.4707283867986198\n",
      "Epoch 75, Loss: 0.46994904703554413\n",
      "Epoch 76, Loss: 0.4694215573409865\n",
      "Epoch 77, Loss: 0.4687819946814118\n",
      "Epoch 78, Loss: 0.46761645906465077\n",
      "Epoch 79, Loss: 0.4664152333019061\n",
      "Epoch 80, Loss: 0.4655949909345498\n",
      "Epoch 81, Loss: 0.46481773560121914\n",
      "Epoch 82, Loss: 0.46398007274148284\n",
      "Epoch 83, Loss: 0.4634103874872291\n",
      "Epoch 84, Loss: 0.46276531857320263\n",
      "Epoch 85, Loss: 0.46189110922692056\n",
      "Epoch 86, Loss: 0.4611610420114046\n",
      "Epoch 87, Loss: 0.46040734012645335\n",
      "Epoch 88, Loss: 0.4595249482740636\n",
      "Epoch 89, Loss: 0.45882573734274706\n",
      "Epoch 90, Loss: 0.4581076832369933\n",
      "Epoch 91, Loss: 0.45737209814776963\n",
      "Epoch 92, Loss: 0.4567601467638292\n",
      "Epoch 93, Loss: 0.4560734747012762\n",
      "Epoch 94, Loss: 0.45538486735574635\n",
      "Epoch 95, Loss: 0.4547183370456599\n",
      "Epoch 96, Loss: 0.45389146764324373\n",
      "Epoch 97, Loss: 0.45294975311983376\n",
      "Epoch 98, Loss: 0.45206402841418\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21551895735553106\n",
      "Test R^2 score: 0.49745017333526037\n",
      "Num of epochs: 99\n",
      "Epoch 1, Loss: 0.6074869544194428\n",
      "Epoch 2, Loss: 0.6053340392842076\n",
      "Epoch 3, Loss: 0.6032329749271118\n",
      "Epoch 4, Loss: 0.6012674822020394\n",
      "Epoch 5, Loss: 0.5993251313197098\n",
      "Epoch 6, Loss: 0.5974088917385637\n",
      "Epoch 7, Loss: 0.595523319311482\n",
      "Epoch 8, Loss: 0.5936868533636841\n",
      "Epoch 9, Loss: 0.591879155951051\n",
      "Epoch 10, Loss: 0.590078420882654\n",
      "Epoch 11, Loss: 0.5882387112945988\n",
      "Epoch 12, Loss: 0.5864164810650183\n",
      "Epoch 13, Loss: 0.5846181129211401\n",
      "Epoch 14, Loss: 0.5828497335286255\n",
      "Epoch 15, Loss: 0.5811177964759975\n",
      "Epoch 16, Loss: 0.5794241201489292\n",
      "Epoch 17, Loss: 0.5777883580530019\n",
      "Epoch 18, Loss: 0.5763050765901986\n",
      "Epoch 19, Loss: 0.5748392243141063\n",
      "Epoch 20, Loss: 0.5734199105457293\n",
      "Epoch 21, Loss: 0.572205003255059\n",
      "Epoch 22, Loss: 0.5710146774887468\n",
      "Epoch 23, Loss: 0.5698812500330006\n",
      "Epoch 24, Loss: 0.5687843385747423\n",
      "Epoch 25, Loss: 0.5677306902854972\n",
      "Epoch 26, Loss: 0.5666927270880661\n",
      "Epoch 27, Loss: 0.5656669263949647\n",
      "Epoch 28, Loss: 0.5646495279402547\n",
      "Epoch 29, Loss: 0.5636311125737937\n",
      "Epoch 30, Loss: 0.5626006831024964\n",
      "Epoch 31, Loss: 0.5615320354300991\n",
      "Epoch 32, Loss: 0.5603889748019719\n",
      "Epoch 33, Loss: 0.559211949075005\n",
      "Epoch 34, Loss: 0.5579445541036753\n",
      "Epoch 35, Loss: 0.5564924076244459\n",
      "Epoch 36, Loss: 0.5547793674955981\n",
      "Epoch 37, Loss: 0.5526956335718326\n",
      "Epoch 38, Loss: 0.5502057145949643\n",
      "Epoch 39, Loss: 0.5473721560491226\n",
      "Epoch 40, Loss: 0.5442016928773686\n",
      "Epoch 41, Loss: 0.5408066438908712\n",
      "Epoch 42, Loss: 0.5374698331041133\n",
      "Epoch 43, Loss: 0.5346916019320256\n",
      "Epoch 44, Loss: 0.5329177707703432\n",
      "Epoch 45, Loss: 0.5321153997120242\n",
      "Epoch 46, Loss: 0.5305650165833856\n",
      "Epoch 47, Loss: 0.5271625631389572\n",
      "Epoch 48, Loss: 0.5230683120767458\n",
      "Epoch 49, Loss: 0.5194463732230857\n",
      "Epoch 50, Loss: 0.5167972359976801\n",
      "Epoch 51, Loss: 0.5146424729292944\n",
      "Epoch 52, Loss: 0.5124327650394629\n",
      "Epoch 53, Loss: 0.5099388500559969\n",
      "Epoch 54, Loss: 0.5073476864891429\n",
      "Epoch 55, Loss: 0.5051748585835439\n",
      "Epoch 56, Loss: 0.5038953380733954\n",
      "Epoch 57, Loss: 0.5031085538841737\n",
      "Epoch 58, Loss: 0.5016614311310481\n",
      "Epoch 59, Loss: 0.4994144885762903\n",
      "Epoch 60, Loss: 0.49725205072542983\n",
      "Epoch 61, Loss: 0.495674617058811\n",
      "Epoch 62, Loss: 0.49438711660320644\n",
      "Epoch 63, Loss: 0.49287779402708826\n",
      "Epoch 64, Loss: 0.4910377667395871\n",
      "Epoch 65, Loss: 0.48922158295582685\n",
      "Epoch 66, Loss: 0.4877741812905538\n",
      "Epoch 67, Loss: 0.48649673909332375\n",
      "Epoch 68, Loss: 0.4849209631101117\n",
      "Epoch 69, Loss: 0.483124163874881\n",
      "Epoch 70, Loss: 0.48150979436239655\n",
      "Epoch 71, Loss: 0.48017632494296936\n",
      "Epoch 72, Loss: 0.4788524609924613\n",
      "Epoch 73, Loss: 0.4773164944273687\n",
      "Epoch 74, Loss: 0.47572987158466745\n",
      "Epoch 75, Loss: 0.4743056090494364\n",
      "Epoch 76, Loss: 0.4729423130184213\n",
      "Epoch 77, Loss: 0.4714596474017166\n",
      "Epoch 78, Loss: 0.4699437359095407\n",
      "Epoch 79, Loss: 0.4686395038070751\n",
      "Epoch 80, Loss: 0.46747389980631227\n",
      "Epoch 81, Loss: 0.4661881695778494\n",
      "Epoch 82, Loss: 0.4648122055506213\n",
      "Epoch 83, Loss: 0.46355606085327206\n",
      "Epoch 84, Loss: 0.4624156527028895\n",
      "Epoch 85, Loss: 0.46118517864721986\n",
      "Epoch 86, Loss: 0.459864531373767\n",
      "Epoch 87, Loss: 0.45865837044799795\n",
      "Epoch 88, Loss: 0.4574444036368054\n",
      "Epoch 89, Loss: 0.45625153894034254\n",
      "Epoch 90, Loss: 0.4551977728863372\n",
      "Epoch 91, Loss: 0.45414669673948493\n",
      "Epoch 92, Loss: 0.4530319414277585\n",
      "Epoch 93, Loss: 0.45203370189562175\n",
      "Epoch 94, Loss: 0.45108105624777756\n",
      "Epoch 95, Loss: 0.4500983872410803\n",
      "Epoch 96, Loss: 0.4491031829786168\n",
      "Epoch 97, Loss: 0.44807143272938427\n",
      "Epoch 98, Loss: 0.4470223343995792\n",
      "Epoch 99, Loss: 0.44600438026129\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.210440424551996\n",
      "Test R^2 score: 0.5187373809098279\n",
      "Num of epochs: 100\n",
      "Epoch 1, Loss: 0.5892816606398696\n",
      "Epoch 2, Loss: 0.5871841139439457\n",
      "Epoch 3, Loss: 0.5851538695018309\n",
      "Epoch 4, Loss: 0.5831776025071428\n",
      "Epoch 5, Loss: 0.5812741161798937\n",
      "Epoch 6, Loss: 0.5793932844155323\n",
      "Epoch 7, Loss: 0.5775924497974756\n",
      "Epoch 8, Loss: 0.5758485307035973\n",
      "Epoch 9, Loss: 0.574159502359363\n",
      "Epoch 10, Loss: 0.5725280108116861\n",
      "Epoch 11, Loss: 0.5710357626139249\n",
      "Epoch 12, Loss: 0.5696213074113047\n",
      "Epoch 13, Loss: 0.5682403072683494\n",
      "Epoch 14, Loss: 0.5669437620355209\n",
      "Epoch 15, Loss: 0.5656885006071468\n",
      "Epoch 16, Loss: 0.5644294707413906\n",
      "Epoch 17, Loss: 0.5632047212334411\n",
      "Epoch 18, Loss: 0.5620133095858784\n",
      "Epoch 19, Loss: 0.5610162451256843\n",
      "Epoch 20, Loss: 0.5601488354988936\n",
      "Epoch 21, Loss: 0.559269289864949\n",
      "Epoch 22, Loss: 0.5584308146549946\n",
      "Epoch 23, Loss: 0.5576277696771168\n",
      "Epoch 24, Loss: 0.5568562140330514\n",
      "Epoch 25, Loss: 0.5561126882399685\n",
      "Epoch 26, Loss: 0.5553796237956563\n",
      "Epoch 27, Loss: 0.554635864863264\n",
      "Epoch 28, Loss: 0.5538844622159094\n",
      "Epoch 29, Loss: 0.5531037515125768\n",
      "Epoch 30, Loss: 0.5522351386132943\n",
      "Epoch 31, Loss: 0.5512279025123072\n",
      "Epoch 32, Loss: 0.5500504806500504\n",
      "Epoch 33, Loss: 0.548684450939939\n",
      "Epoch 34, Loss: 0.5470368009719826\n",
      "Epoch 35, Loss: 0.5449723524552813\n",
      "Epoch 36, Loss: 0.542402369991754\n",
      "Epoch 37, Loss: 0.5392026304468067\n",
      "Epoch 38, Loss: 0.5353291364535374\n",
      "Epoch 39, Loss: 0.5308403511371964\n",
      "Epoch 40, Loss: 0.5259611017707897\n",
      "Epoch 41, Loss: 0.5207809390099458\n",
      "Epoch 42, Loss: 0.5154812063219388\n",
      "Epoch 43, Loss: 0.5103911730828897\n",
      "Epoch 44, Loss: 0.5056626810148543\n",
      "Epoch 45, Loss: 0.5014408332402963\n",
      "Epoch 46, Loss: 0.4973204457404656\n",
      "Epoch 47, Loss: 0.49284307023407214\n",
      "Epoch 48, Loss: 0.488596379633196\n",
      "Epoch 49, Loss: 0.4854532975658773\n",
      "Epoch 50, Loss: 0.4839617135051251\n",
      "Epoch 51, Loss: 0.48360931728863454\n",
      "Epoch 52, Loss: 0.48325828292939477\n",
      "Epoch 53, Loss: 0.4821611232552088\n",
      "Epoch 54, Loss: 0.48044262016389727\n",
      "Epoch 55, Loss: 0.4784644274668026\n",
      "Epoch 56, Loss: 0.47657485070405586\n",
      "Epoch 57, Loss: 0.4752510975659984\n",
      "Epoch 58, Loss: 0.47416968052492314\n",
      "Epoch 59, Loss: 0.47289539624020355\n",
      "Epoch 60, Loss: 0.471442864083192\n",
      "Epoch 61, Loss: 0.47014771930109345\n",
      "Epoch 62, Loss: 0.46917365320784493\n",
      "Epoch 63, Loss: 0.4684213916994043\n",
      "Epoch 64, Loss: 0.4676315952662912\n",
      "Epoch 65, Loss: 0.46668467110859135\n",
      "Epoch 66, Loss: 0.46555455142121277\n",
      "Epoch 67, Loss: 0.4643901727746772\n",
      "Epoch 68, Loss: 0.4633169343788388\n",
      "Epoch 69, Loss: 0.4623785768098823\n",
      "Epoch 70, Loss: 0.46154141062167237\n",
      "Epoch 71, Loss: 0.4606902704099956\n",
      "Epoch 72, Loss: 0.45993450113120515\n",
      "Epoch 73, Loss: 0.4593075527579285\n",
      "Epoch 74, Loss: 0.4586192200328457\n",
      "Epoch 75, Loss: 0.457753352748274\n",
      "Epoch 76, Loss: 0.4568761578713499\n",
      "Epoch 77, Loss: 0.4561601308600182\n",
      "Epoch 78, Loss: 0.4554797352795993\n",
      "Epoch 79, Loss: 0.4546458929891838\n",
      "Epoch 80, Loss: 0.45377942215815575\n",
      "Epoch 81, Loss: 0.4530679732644758\n",
      "Epoch 82, Loss: 0.45241113862420507\n",
      "Epoch 83, Loss: 0.45167986852570824\n",
      "Epoch 84, Loss: 0.4509007188173674\n",
      "Epoch 85, Loss: 0.4500972119604572\n",
      "Epoch 86, Loss: 0.4492602287713751\n",
      "Epoch 87, Loss: 0.44848494926660143\n",
      "Epoch 88, Loss: 0.4477606952780702\n",
      "Epoch 89, Loss: 0.44697483054714254\n",
      "Epoch 90, Loss: 0.446174039145785\n",
      "Epoch 91, Loss: 0.4454101656173775\n",
      "Epoch 92, Loss: 0.44458021219451577\n",
      "Epoch 93, Loss: 0.4437876074261513\n",
      "Epoch 94, Loss: 0.44295977763351746\n",
      "Epoch 95, Loss: 0.4421173545547366\n",
      "Epoch 96, Loss: 0.4412944280719103\n",
      "Epoch 97, Loss: 0.4404181163815711\n",
      "Epoch 98, Loss: 0.43949672906502524\n",
      "Epoch 99, Loss: 0.43856917594774497\n",
      "Epoch 100, Loss: 0.4376943701444982\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21396953657717263\n",
      "Test R^2 score: 0.5050079787065928\n",
      "Num of epochs: 101\n",
      "Epoch 1, Loss: 0.5838074176821534\n",
      "Epoch 2, Loss: 0.5822886211563564\n",
      "Epoch 3, Loss: 0.5808206295182144\n",
      "Epoch 4, Loss: 0.579403726056976\n",
      "Epoch 5, Loss: 0.5782240963109205\n",
      "Epoch 6, Loss: 0.5771201138073704\n",
      "Epoch 7, Loss: 0.5760449803161048\n",
      "Epoch 8, Loss: 0.5749991686441797\n",
      "Epoch 9, Loss: 0.5739885504557612\n",
      "Epoch 10, Loss: 0.5730275624771244\n",
      "Epoch 11, Loss: 0.5720965295099921\n",
      "Epoch 12, Loss: 0.571198676368438\n",
      "Epoch 13, Loss: 0.57032687025386\n",
      "Epoch 14, Loss: 0.5694848155491659\n",
      "Epoch 15, Loss: 0.5686689235203461\n",
      "Epoch 16, Loss: 0.5678831117232443\n",
      "Epoch 17, Loss: 0.5671201482039371\n",
      "Epoch 18, Loss: 0.5663840190865601\n",
      "Epoch 19, Loss: 0.5656746447363414\n",
      "Epoch 20, Loss: 0.5649740066287995\n",
      "Epoch 21, Loss: 0.5642746639937392\n",
      "Epoch 22, Loss: 0.5636001001925139\n",
      "Epoch 23, Loss: 0.5629494513878545\n",
      "Epoch 24, Loss: 0.5623217936196501\n",
      "Epoch 25, Loss: 0.5617186364610157\n",
      "Epoch 26, Loss: 0.5611368722898245\n",
      "Epoch 27, Loss: 0.560567077910646\n",
      "Epoch 28, Loss: 0.560017299044308\n",
      "Epoch 29, Loss: 0.5594834664742484\n",
      "Epoch 30, Loss: 0.5589643196224263\n",
      "Epoch 31, Loss: 0.5584631547120855\n",
      "Epoch 32, Loss: 0.5579799133739406\n",
      "Epoch 33, Loss: 0.5575275783389053\n",
      "Epoch 34, Loss: 0.5570725756024728\n",
      "Epoch 35, Loss: 0.5566229031067352\n",
      "Epoch 36, Loss: 0.5561486194676799\n",
      "Epoch 37, Loss: 0.5556660469435402\n",
      "Epoch 38, Loss: 0.5551669238347687\n",
      "Epoch 39, Loss: 0.5546551547223691\n",
      "Epoch 40, Loss: 0.5541401432497239\n",
      "Epoch 41, Loss: 0.5535508450843218\n",
      "Epoch 42, Loss: 0.5529074785359793\n",
      "Epoch 43, Loss: 0.5522042687832401\n",
      "Epoch 44, Loss: 0.5514215035192052\n",
      "Epoch 45, Loss: 0.5505238736542977\n",
      "Epoch 46, Loss: 0.549476512040751\n",
      "Epoch 47, Loss: 0.5482830449594298\n",
      "Epoch 48, Loss: 0.5469388379575493\n",
      "Epoch 49, Loss: 0.5453859492900545\n",
      "Epoch 50, Loss: 0.5435864619166447\n",
      "Epoch 51, Loss: 0.5414449867823847\n",
      "Epoch 52, Loss: 0.5388176679930855\n",
      "Epoch 53, Loss: 0.5356609720994833\n",
      "Epoch 54, Loss: 0.5319910490781644\n",
      "Epoch 55, Loss: 0.5279288542780085\n",
      "Epoch 56, Loss: 0.524230129158236\n",
      "Epoch 57, Loss: 0.5217228319271745\n",
      "Epoch 58, Loss: 0.5207124347240853\n",
      "Epoch 59, Loss: 0.5196757008216079\n",
      "Epoch 60, Loss: 0.5173206768691636\n",
      "Epoch 61, Loss: 0.5145015036298691\n",
      "Epoch 62, Loss: 0.5123114029520186\n",
      "Epoch 63, Loss: 0.5108365907093302\n",
      "Epoch 64, Loss: 0.5095394992248335\n",
      "Epoch 65, Loss: 0.5078536970593818\n",
      "Epoch 66, Loss: 0.5055596188875656\n",
      "Epoch 67, Loss: 0.5027845747396344\n",
      "Epoch 68, Loss: 0.49987180377713897\n",
      "Epoch 69, Loss: 0.4972926094303003\n",
      "Epoch 70, Loss: 0.49525272237307727\n",
      "Epoch 71, Loss: 0.493128331466851\n",
      "Epoch 72, Loss: 0.4902454846099792\n",
      "Epoch 73, Loss: 0.48685019786180744\n",
      "Epoch 74, Loss: 0.4835728340370995\n",
      "Epoch 75, Loss: 0.4806875645527482\n",
      "Epoch 76, Loss: 0.47793550164318876\n",
      "Epoch 77, Loss: 0.4750049810399347\n",
      "Epoch 78, Loss: 0.472004433116057\n",
      "Epoch 79, Loss: 0.4691984256962693\n",
      "Epoch 80, Loss: 0.46727920895163055\n",
      "Epoch 81, Loss: 0.46652930663498293\n",
      "Epoch 82, Loss: 0.4663161991158261\n",
      "Epoch 83, Loss: 0.4657918413526289\n",
      "Epoch 84, Loss: 0.4649405819349347\n",
      "Epoch 85, Loss: 0.4638617424896296\n",
      "Epoch 86, Loss: 0.46264398820752234\n",
      "Epoch 87, Loss: 0.4614578639588506\n",
      "Epoch 88, Loss: 0.4605834538733569\n",
      "Epoch 89, Loss: 0.4601332874106196\n",
      "Epoch 90, Loss: 0.45981433581200554\n",
      "Epoch 91, Loss: 0.4594254504935435\n",
      "Epoch 92, Loss: 0.45899279972217455\n",
      "Epoch 93, Loss: 0.458601771841773\n",
      "Epoch 94, Loss: 0.4580983314454211\n",
      "Epoch 95, Loss: 0.45746603279445563\n",
      "Epoch 96, Loss: 0.45677849717128527\n",
      "Epoch 97, Loss: 0.4561015560400861\n",
      "Epoch 98, Loss: 0.4554658801346624\n",
      "Epoch 99, Loss: 0.4548915103852242\n",
      "Epoch 100, Loss: 0.4543655448569964\n",
      "Epoch 101, Loss: 0.45384136661985114\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21708115113736398\n",
      "Test R^2 score: 0.49116813945293003\n",
      "Num of epochs: 102\n",
      "Epoch 1, Loss: 0.5567151203834827\n",
      "Epoch 2, Loss: 0.5565475386033512\n",
      "Epoch 3, Loss: 0.5564182573504942\n",
      "Epoch 4, Loss: 0.5563239284207641\n",
      "Epoch 5, Loss: 0.5562576582735057\n",
      "Epoch 6, Loss: 0.5562115538094251\n",
      "Epoch 7, Loss: 0.5561772341764056\n",
      "Epoch 8, Loss: 0.5561517275035682\n",
      "Epoch 9, Loss: 0.5561320876400615\n",
      "Epoch 10, Loss: 0.5561175113584486\n",
      "Epoch 11, Loss: 0.5561063645323625\n",
      "Epoch 12, Loss: 0.5560960213640799\n",
      "Epoch 13, Loss: 0.5560807474218095\n",
      "Epoch 14, Loss: 0.5560566030187277\n",
      "Epoch 15, Loss: 0.556019191861822\n",
      "Epoch 16, Loss: 0.5559656970382146\n",
      "Epoch 17, Loss: 0.5558945591742834\n",
      "Epoch 18, Loss: 0.5558047527140912\n",
      "Epoch 19, Loss: 0.5556941770093018\n",
      "Epoch 20, Loss: 0.555561049420955\n",
      "Epoch 21, Loss: 0.5554021610312752\n",
      "Epoch 22, Loss: 0.5552127393031213\n",
      "Epoch 23, Loss: 0.5549909540676393\n",
      "Epoch 24, Loss: 0.5547332476166146\n",
      "Epoch 25, Loss: 0.5544292762274592\n",
      "Epoch 26, Loss: 0.55406906683441\n",
      "Epoch 27, Loss: 0.5536368722510432\n",
      "Epoch 28, Loss: 0.5531237144239756\n",
      "Epoch 29, Loss: 0.5525228142666933\n",
      "Epoch 30, Loss: 0.5518363154106172\n",
      "Epoch 31, Loss: 0.5510465375352076\n",
      "Epoch 32, Loss: 0.5501005416786316\n",
      "Epoch 33, Loss: 0.5489436126511109\n",
      "Epoch 34, Loss: 0.5475676645854609\n",
      "Epoch 35, Loss: 0.5459578862175194\n",
      "Epoch 36, Loss: 0.5440748461133763\n",
      "Epoch 37, Loss: 0.5417997276269559\n",
      "Epoch 38, Loss: 0.5390735569801259\n",
      "Epoch 39, Loss: 0.5357550174123954\n",
      "Epoch 40, Loss: 0.5319045746466889\n",
      "Epoch 41, Loss: 0.5275688256204353\n",
      "Epoch 42, Loss: 0.522748066089032\n",
      "Epoch 43, Loss: 0.5174989459814865\n",
      "Epoch 44, Loss: 0.5119433892737614\n",
      "Epoch 45, Loss: 0.5062085864706231\n",
      "Epoch 46, Loss: 0.5007350703950099\n",
      "Epoch 47, Loss: 0.49657553459426396\n",
      "Epoch 48, Loss: 0.4948010912215135\n",
      "Epoch 49, Loss: 0.4936615955304605\n",
      "Epoch 50, Loss: 0.4903166196612366\n",
      "Epoch 51, Loss: 0.48594777810858225\n",
      "Epoch 52, Loss: 0.48277742202883717\n",
      "Epoch 53, Loss: 0.48107849756032084\n",
      "Epoch 54, Loss: 0.47936245470404637\n",
      "Epoch 55, Loss: 0.4764906563308081\n",
      "Epoch 56, Loss: 0.47319786314473755\n",
      "Epoch 57, Loss: 0.4711288173396394\n",
      "Epoch 58, Loss: 0.47089715970916984\n",
      "Epoch 59, Loss: 0.4715090772831052\n",
      "Epoch 60, Loss: 0.47155027015960627\n",
      "Epoch 61, Loss: 0.4705343933324764\n",
      "Epoch 62, Loss: 0.46892232906099285\n",
      "Epoch 63, Loss: 0.4672404460185348\n",
      "Epoch 64, Loss: 0.4658434400275311\n",
      "Epoch 65, Loss: 0.46491955691980674\n",
      "Epoch 66, Loss: 0.4642953282188802\n",
      "Epoch 67, Loss: 0.4636252002957329\n",
      "Epoch 68, Loss: 0.4627891300490575\n",
      "Epoch 69, Loss: 0.46203174664570984\n",
      "Epoch 70, Loss: 0.46146968249220766\n",
      "Epoch 71, Loss: 0.46096376570527753\n",
      "Epoch 72, Loss: 0.460405349664281\n",
      "Epoch 73, Loss: 0.45968054062731367\n",
      "Epoch 74, Loss: 0.45882084956832137\n",
      "Epoch 75, Loss: 0.4577669758995345\n",
      "Epoch 76, Loss: 0.4567252218627725\n",
      "Epoch 77, Loss: 0.45591944582296684\n",
      "Epoch 78, Loss: 0.45526767434130483\n",
      "Epoch 79, Loss: 0.45472361299967123\n",
      "Epoch 80, Loss: 0.45418319788719835\n",
      "Epoch 81, Loss: 0.45362755431683055\n",
      "Epoch 82, Loss: 0.45305417592572533\n",
      "Epoch 83, Loss: 0.4524786054706464\n",
      "Epoch 84, Loss: 0.451883819462354\n",
      "Epoch 85, Loss: 0.45127897106171355\n",
      "Epoch 86, Loss: 0.45070911802214336\n",
      "Epoch 87, Loss: 0.45014678627349136\n",
      "Epoch 88, Loss: 0.44955928997461964\n",
      "Epoch 89, Loss: 0.44897555526957356\n",
      "Epoch 90, Loss: 0.44840456944684476\n",
      "Epoch 91, Loss: 0.4477613109446428\n",
      "Epoch 92, Loss: 0.44708059889865825\n",
      "Epoch 93, Loss: 0.44644726509737315\n",
      "Epoch 94, Loss: 0.4458120121120926\n",
      "Epoch 95, Loss: 0.445201391446526\n",
      "Epoch 96, Loss: 0.44461738140838425\n",
      "Epoch 97, Loss: 0.44398821964508994\n",
      "Epoch 98, Loss: 0.4433707517264968\n",
      "Epoch 99, Loss: 0.442779800779895\n",
      "Epoch 100, Loss: 0.44219916365374873\n",
      "Epoch 101, Loss: 0.4416164134184447\n",
      "Epoch 102, Loss: 0.44101040738231734\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21366476392430497\n",
      "Test R^2 score: 0.5052357538650368\n",
      "Num of epochs: 103\n",
      "Epoch 1, Loss: 0.5569394029223708\n",
      "Epoch 2, Loss: 0.5566493251187561\n",
      "Epoch 3, Loss: 0.5564268806058615\n",
      "Epoch 4, Loss: 0.5562759811248705\n",
      "Epoch 5, Loss: 0.5561869060437312\n",
      "Epoch 6, Loss: 0.5561517810902417\n",
      "Epoch 7, Loss: 0.5561549962811937\n",
      "Epoch 8, Loss: 0.5561702681843893\n",
      "Epoch 9, Loss: 0.5561766983339634\n",
      "Epoch 10, Loss: 0.5561639987169763\n",
      "Epoch 11, Loss: 0.5561222272560722\n",
      "Epoch 12, Loss: 0.5560477864326603\n",
      "Epoch 13, Loss: 0.5559442011754713\n",
      "Epoch 14, Loss: 0.5558146723493862\n",
      "Epoch 15, Loss: 0.5556616221610654\n",
      "Epoch 16, Loss: 0.5554844410071028\n",
      "Epoch 17, Loss: 0.5552747867982447\n",
      "Epoch 18, Loss: 0.5550198969410398\n",
      "Epoch 19, Loss: 0.5547068417897594\n",
      "Epoch 20, Loss: 0.554315764822417\n",
      "Epoch 21, Loss: 0.5538423035892307\n",
      "Epoch 22, Loss: 0.553273211304711\n",
      "Epoch 23, Loss: 0.5525976490447753\n",
      "Epoch 24, Loss: 0.5517922179711373\n",
      "Epoch 25, Loss: 0.5508638144219402\n",
      "Epoch 26, Loss: 0.5497909733906555\n",
      "Epoch 27, Loss: 0.548499962925801\n",
      "Epoch 28, Loss: 0.5469221367276431\n",
      "Epoch 29, Loss: 0.5449729266572914\n",
      "Epoch 30, Loss: 0.542555040784345\n",
      "Epoch 31, Loss: 0.5395658879301317\n",
      "Epoch 32, Loss: 0.5359505654569146\n",
      "Epoch 33, Loss: 0.5318575918753354\n",
      "Epoch 34, Loss: 0.5271703364320602\n",
      "Epoch 35, Loss: 0.5219864731932393\n",
      "Epoch 36, Loss: 0.5166069564105075\n",
      "Epoch 37, Loss: 0.5116102671474335\n",
      "Epoch 38, Loss: 0.5079539762171407\n",
      "Epoch 39, Loss: 0.5064141902048034\n",
      "Epoch 40, Loss: 0.5052719829879015\n",
      "Epoch 41, Loss: 0.502092809574507\n",
      "Epoch 42, Loss: 0.49791239998663955\n",
      "Epoch 43, Loss: 0.49415678819600406\n",
      "Epoch 44, Loss: 0.49138739812013954\n",
      "Epoch 45, Loss: 0.4896340512998992\n",
      "Epoch 46, Loss: 0.4881315688547231\n",
      "Epoch 47, Loss: 0.48627945070391654\n",
      "Epoch 48, Loss: 0.4838134833383663\n",
      "Epoch 49, Loss: 0.48084213511026663\n",
      "Epoch 50, Loss: 0.47776400644979045\n",
      "Epoch 51, Loss: 0.47504519636561926\n",
      "Epoch 52, Loss: 0.4729573102814576\n",
      "Epoch 53, Loss: 0.4713683433578607\n",
      "Epoch 54, Loss: 0.4699069844436969\n",
      "Epoch 55, Loss: 0.46859576548886706\n",
      "Epoch 56, Loss: 0.46722714692873285\n",
      "Epoch 57, Loss: 0.46611904266204607\n",
      "Epoch 58, Loss: 0.4652311489912619\n",
      "Epoch 59, Loss: 0.46439254725022366\n",
      "Epoch 60, Loss: 0.4636218094570687\n",
      "Epoch 61, Loss: 0.46280155854102856\n",
      "Epoch 62, Loss: 0.4616469564631503\n",
      "Epoch 63, Loss: 0.46036895343622364\n",
      "Epoch 64, Loss: 0.45920632048636667\n",
      "Epoch 65, Loss: 0.45820988994004563\n",
      "Epoch 66, Loss: 0.4573563454695021\n",
      "Epoch 67, Loss: 0.4566324075003514\n",
      "Epoch 68, Loss: 0.4559779786776084\n",
      "Epoch 69, Loss: 0.4553990030949587\n",
      "Epoch 70, Loss: 0.4547668997270458\n",
      "Epoch 71, Loss: 0.4540228826799558\n",
      "Epoch 72, Loss: 0.4532232506881067\n",
      "Epoch 73, Loss: 0.4524179565755364\n",
      "Epoch 74, Loss: 0.4516297861147076\n",
      "Epoch 75, Loss: 0.4508359740309785\n",
      "Epoch 76, Loss: 0.45002205384042754\n",
      "Epoch 77, Loss: 0.449216975332984\n",
      "Epoch 78, Loss: 0.44837407849921423\n",
      "Epoch 79, Loss: 0.4475631057741551\n",
      "Epoch 80, Loss: 0.44679045110767984\n",
      "Epoch 81, Loss: 0.4459229016871807\n",
      "Epoch 82, Loss: 0.4450728457544384\n",
      "Epoch 83, Loss: 0.4442285261175348\n",
      "Epoch 84, Loss: 0.44342961364142214\n",
      "Epoch 85, Loss: 0.44258998710176356\n",
      "Epoch 86, Loss: 0.44172537079131163\n",
      "Epoch 87, Loss: 0.44085730117345234\n",
      "Epoch 88, Loss: 0.43996735050703084\n",
      "Epoch 89, Loss: 0.43907997395235526\n",
      "Epoch 90, Loss: 0.438166400324708\n",
      "Epoch 91, Loss: 0.43726758232994034\n",
      "Epoch 92, Loss: 0.4363441696563847\n",
      "Epoch 93, Loss: 0.43539850419172615\n",
      "Epoch 94, Loss: 0.4345007165621961\n",
      "Epoch 95, Loss: 0.43359498719734807\n",
      "Epoch 96, Loss: 0.432667214835696\n",
      "Epoch 97, Loss: 0.431773808158072\n",
      "Epoch 98, Loss: 0.43087849717232957\n",
      "Epoch 99, Loss: 0.43001907733249267\n",
      "Epoch 100, Loss: 0.42923430037962146\n",
      "Epoch 101, Loss: 0.4284398431804307\n",
      "Epoch 102, Loss: 0.4276653739282055\n",
      "Epoch 103, Loss: 0.4266812498082733\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21410613081324836\n",
      "Test R^2 score: 0.5033164613646764\n",
      "Num of epochs: 104\n",
      "Epoch 1, Loss: 0.5747157949396863\n",
      "Epoch 2, Loss: 0.5727683453313032\n",
      "Epoch 3, Loss: 0.570912502766781\n",
      "Epoch 4, Loss: 0.5691575151920683\n",
      "Epoch 5, Loss: 0.5675415499848833\n",
      "Epoch 6, Loss: 0.5660348924473205\n",
      "Epoch 7, Loss: 0.5646307906537308\n",
      "Epoch 8, Loss: 0.5633332914948683\n",
      "Epoch 9, Loss: 0.5621597002417527\n",
      "Epoch 10, Loss: 0.5610970910317304\n",
      "Epoch 11, Loss: 0.5601409346057629\n",
      "Epoch 12, Loss: 0.5592902316431434\n",
      "Epoch 13, Loss: 0.5585447970194343\n",
      "Epoch 14, Loss: 0.5579031563401018\n",
      "Epoch 15, Loss: 0.5573622994508339\n",
      "Epoch 16, Loss: 0.5569182657202406\n",
      "Epoch 17, Loss: 0.5565664141526435\n",
      "Epoch 18, Loss: 0.5563010535224541\n",
      "Epoch 19, Loss: 0.5561154749357481\n",
      "Epoch 20, Loss: 0.5559993329112765\n",
      "Epoch 21, Loss: 0.5559386260528911\n",
      "Epoch 22, Loss: 0.5558733286282405\n",
      "Epoch 23, Loss: 0.555847003769612\n",
      "Epoch 24, Loss: 0.5557907576842978\n",
      "Epoch 25, Loss: 0.5556627216557581\n",
      "Epoch 26, Loss: 0.5554713231709859\n",
      "Epoch 27, Loss: 0.5551941934852217\n",
      "Epoch 28, Loss: 0.5547881505207521\n",
      "Epoch 29, Loss: 0.5542339566136626\n",
      "Epoch 30, Loss: 0.5535072611390217\n",
      "Epoch 31, Loss: 0.5525784761267806\n",
      "Epoch 32, Loss: 0.5514430135489988\n",
      "Epoch 33, Loss: 0.5500423534298383\n",
      "Epoch 34, Loss: 0.548310928737294\n",
      "Epoch 35, Loss: 0.5461781012314303\n",
      "Epoch 36, Loss: 0.5436042250424136\n",
      "Epoch 37, Loss: 0.5405736005747943\n",
      "Epoch 38, Loss: 0.5371884929299401\n",
      "Epoch 39, Loss: 0.5337190751758726\n",
      "Epoch 40, Loss: 0.5306243578364392\n",
      "Epoch 41, Loss: 0.5283341326642332\n",
      "Epoch 42, Loss: 0.5264503257644664\n",
      "Epoch 43, Loss: 0.5238101543669393\n",
      "Epoch 44, Loss: 0.5204206898332439\n",
      "Epoch 45, Loss: 0.5172553153394095\n",
      "Epoch 46, Loss: 0.5148988870783173\n",
      "Epoch 47, Loss: 0.5129660917661163\n",
      "Epoch 48, Loss: 0.5108137791714555\n",
      "Epoch 49, Loss: 0.508213090615638\n",
      "Epoch 50, Loss: 0.5054389355222699\n",
      "Epoch 51, Loss: 0.5030302373128592\n",
      "Epoch 52, Loss: 0.5012643742105626\n",
      "Epoch 53, Loss: 0.49949370022639616\n",
      "Epoch 54, Loss: 0.49709754674383266\n",
      "Epoch 55, Loss: 0.49465985968574877\n",
      "Epoch 56, Loss: 0.49281758138278076\n",
      "Epoch 57, Loss: 0.49115743781815846\n",
      "Epoch 58, Loss: 0.4891871631650885\n",
      "Epoch 59, Loss: 0.48697928226353976\n",
      "Epoch 60, Loss: 0.4850029105659535\n",
      "Epoch 61, Loss: 0.48346631122689315\n",
      "Epoch 62, Loss: 0.4818915258906112\n",
      "Epoch 63, Loss: 0.48021879129613787\n",
      "Epoch 64, Loss: 0.4788180893966512\n",
      "Epoch 65, Loss: 0.4775347251149041\n",
      "Epoch 66, Loss: 0.4761858217545514\n",
      "Epoch 67, Loss: 0.4749135898746564\n",
      "Epoch 68, Loss: 0.47363243496280055\n",
      "Epoch 69, Loss: 0.47232816674878\n",
      "Epoch 70, Loss: 0.47123057148293096\n",
      "Epoch 71, Loss: 0.4700802048771401\n",
      "Epoch 72, Loss: 0.46886944838359107\n",
      "Epoch 73, Loss: 0.46791625580241686\n",
      "Epoch 74, Loss: 0.4669406621532571\n",
      "Epoch 75, Loss: 0.4659119042133983\n",
      "Epoch 76, Loss: 0.46503172207373805\n",
      "Epoch 77, Loss: 0.4641563076675966\n",
      "Epoch 78, Loss: 0.4633227717301607\n",
      "Epoch 79, Loss: 0.4624806129413133\n",
      "Epoch 80, Loss: 0.4616507975602922\n",
      "Epoch 81, Loss: 0.4609123320093217\n",
      "Epoch 82, Loss: 0.46008812508554725\n",
      "Epoch 83, Loss: 0.45932469838651085\n",
      "Epoch 84, Loss: 0.45857158522843017\n",
      "Epoch 85, Loss: 0.4577857579307407\n",
      "Epoch 86, Loss: 0.45699246559881307\n",
      "Epoch 87, Loss: 0.45612702214677986\n",
      "Epoch 88, Loss: 0.4552023394762537\n",
      "Epoch 89, Loss: 0.4541787686908313\n",
      "Epoch 90, Loss: 0.45327784163867885\n",
      "Epoch 91, Loss: 0.452486756141494\n",
      "Epoch 92, Loss: 0.4516476356214303\n",
      "Epoch 93, Loss: 0.4508246369530864\n",
      "Epoch 94, Loss: 0.45005667117687853\n",
      "Epoch 95, Loss: 0.44929465606252955\n",
      "Epoch 96, Loss: 0.44847758974586144\n",
      "Epoch 97, Loss: 0.44759847923975843\n",
      "Epoch 98, Loss: 0.44673680189284093\n",
      "Epoch 99, Loss: 0.44591720414573366\n",
      "Epoch 100, Loss: 0.4450826386270897\n",
      "Epoch 101, Loss: 0.44421889891137234\n",
      "Epoch 102, Loss: 0.44336384506324844\n",
      "Epoch 103, Loss: 0.44257049284614175\n",
      "Epoch 104, Loss: 0.44179310345916023\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21554232928868153\n",
      "Test R^2 score: 0.4984371395558849\n",
      "Num of epochs: 105\n",
      "Epoch 1, Loss: 0.5626877100655048\n",
      "Epoch 2, Loss: 0.5616591579782435\n",
      "Epoch 3, Loss: 0.5607660376865512\n",
      "Epoch 4, Loss: 0.5600129618592168\n",
      "Epoch 5, Loss: 0.5593715134837006\n",
      "Epoch 6, Loss: 0.5587948257165087\n",
      "Epoch 7, Loss: 0.558308321715234\n",
      "Epoch 8, Loss: 0.5578972268605374\n",
      "Epoch 9, Loss: 0.5575323090364421\n",
      "Epoch 10, Loss: 0.5572124020782521\n",
      "Epoch 11, Loss: 0.5569360852373912\n",
      "Epoch 12, Loss: 0.5567022456812323\n",
      "Epoch 13, Loss: 0.5565095445991743\n",
      "Epoch 14, Loss: 0.5563547303692646\n",
      "Epoch 15, Loss: 0.5562352360684153\n",
      "Epoch 16, Loss: 0.5561480835976679\n",
      "Epoch 17, Loss: 0.5560938776781922\n",
      "Epoch 18, Loss: 0.5560623109467099\n",
      "Epoch 19, Loss: 0.5560473040622159\n",
      "Epoch 20, Loss: 0.556042480334757\n",
      "Epoch 21, Loss: 0.5560298848491027\n",
      "Epoch 22, Loss: 0.5560218182286264\n",
      "Epoch 23, Loss: 0.5560036746047738\n",
      "Epoch 24, Loss: 0.555968430866422\n",
      "Epoch 25, Loss: 0.5559109104310037\n",
      "Epoch 26, Loss: 0.5558277284643672\n",
      "Epoch 27, Loss: 0.555717559545465\n",
      "Epoch 28, Loss: 0.5555787515433691\n",
      "Epoch 29, Loss: 0.5554074732464834\n",
      "Epoch 30, Loss: 0.5551998297616879\n",
      "Epoch 31, Loss: 0.5549511618648347\n",
      "Epoch 32, Loss: 0.5546542144244571\n",
      "Epoch 33, Loss: 0.5543002805275906\n",
      "Epoch 34, Loss: 0.5538786511344984\n",
      "Epoch 35, Loss: 0.5533756539474701\n",
      "Epoch 36, Loss: 0.5527747850507472\n",
      "Epoch 37, Loss: 0.5520515132826994\n",
      "Epoch 38, Loss: 0.5511817558154496\n",
      "Epoch 39, Loss: 0.5501365676301654\n",
      "Epoch 40, Loss: 0.5488698543011135\n",
      "Epoch 41, Loss: 0.5473391606701745\n",
      "Epoch 42, Loss: 0.5454801482094529\n",
      "Epoch 43, Loss: 0.5432650354624594\n",
      "Epoch 44, Loss: 0.540639863884839\n",
      "Epoch 45, Loss: 0.5375057353223829\n",
      "Epoch 46, Loss: 0.5337277022267127\n",
      "Epoch 47, Loss: 0.5291741992634584\n",
      "Epoch 48, Loss: 0.5238563797376118\n",
      "Epoch 49, Loss: 0.5179690917691445\n",
      "Epoch 50, Loss: 0.5119719715977533\n",
      "Epoch 51, Loss: 0.507012926190842\n",
      "Epoch 52, Loss: 0.5045455012430798\n",
      "Epoch 53, Loss: 0.5034876422786131\n",
      "Epoch 54, Loss: 0.49996417632515433\n",
      "Epoch 55, Loss: 0.49491813616104385\n",
      "Epoch 56, Loss: 0.491985794395352\n",
      "Epoch 57, Loss: 0.491761022810745\n",
      "Epoch 58, Loss: 0.49000992519194286\n",
      "Epoch 59, Loss: 0.4864087172070999\n",
      "Epoch 60, Loss: 0.483238949137722\n",
      "Epoch 61, Loss: 0.4817888222162611\n",
      "Epoch 62, Loss: 0.4809016316840527\n",
      "Epoch 63, Loss: 0.47915206935319876\n",
      "Epoch 64, Loss: 0.4769294764149139\n",
      "Epoch 65, Loss: 0.47538120006537393\n",
      "Epoch 66, Loss: 0.4746747697902472\n",
      "Epoch 67, Loss: 0.4740267187255664\n",
      "Epoch 68, Loss: 0.4728982321749512\n",
      "Epoch 69, Loss: 0.4714000971073007\n",
      "Epoch 70, Loss: 0.4701491930993935\n",
      "Epoch 71, Loss: 0.46946009256998167\n",
      "Epoch 72, Loss: 0.469043306139718\n",
      "Epoch 73, Loss: 0.46825570429816743\n",
      "Epoch 74, Loss: 0.4672992668293451\n",
      "Epoch 75, Loss: 0.46667215444823584\n",
      "Epoch 76, Loss: 0.466066435404539\n",
      "Epoch 77, Loss: 0.4650301038831634\n",
      "Epoch 78, Loss: 0.4637207121224958\n",
      "Epoch 79, Loss: 0.46250954566589975\n",
      "Epoch 80, Loss: 0.46174760524994146\n",
      "Epoch 81, Loss: 0.4609667558599111\n",
      "Epoch 82, Loss: 0.46010171149320434\n",
      "Epoch 83, Loss: 0.45946490517381194\n",
      "Epoch 84, Loss: 0.4587930158669702\n",
      "Epoch 85, Loss: 0.4579322280819822\n",
      "Epoch 86, Loss: 0.45712065841056754\n",
      "Epoch 87, Loss: 0.45654757084286424\n",
      "Epoch 88, Loss: 0.45598873012716346\n",
      "Epoch 89, Loss: 0.4552869685914456\n",
      "Epoch 90, Loss: 0.45458763113825285\n",
      "Epoch 91, Loss: 0.4538914183985573\n",
      "Epoch 92, Loss: 0.45324455525599167\n",
      "Epoch 93, Loss: 0.4526872658102864\n",
      "Epoch 94, Loss: 0.4520895406704125\n",
      "Epoch 95, Loss: 0.45134721791863774\n",
      "Epoch 96, Loss: 0.45071916863419975\n",
      "Epoch 97, Loss: 0.4501828007810939\n",
      "Epoch 98, Loss: 0.44962045703954645\n",
      "Epoch 99, Loss: 0.4490909726401615\n",
      "Epoch 100, Loss: 0.4484871255351512\n",
      "Epoch 101, Loss: 0.4479079652281134\n",
      "Epoch 102, Loss: 0.44742051819931483\n",
      "Epoch 103, Loss: 0.44689959745135033\n",
      "Epoch 104, Loss: 0.44636199488798867\n",
      "Epoch 105, Loss: 0.44586234696478744\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21019361035795464\n",
      "Test R^2 score: 0.5216925184737039\n",
      "Num of epochs: 106\n",
      "Epoch 1, Loss: 0.5642413365700832\n",
      "Epoch 2, Loss: 0.5628820287615913\n",
      "Epoch 3, Loss: 0.5616355717689424\n",
      "Epoch 4, Loss: 0.5605077164958467\n",
      "Epoch 5, Loss: 0.5595038675800109\n",
      "Epoch 6, Loss: 0.558683881623956\n",
      "Epoch 7, Loss: 0.5579858152695621\n",
      "Epoch 8, Loss: 0.5574049671070862\n",
      "Epoch 9, Loss: 0.5569320718823729\n",
      "Epoch 10, Loss: 0.5565710459272069\n",
      "Epoch 11, Loss: 0.5563177142557276\n",
      "Epoch 12, Loss: 0.5561616677431205\n",
      "Epoch 13, Loss: 0.5560904209672921\n",
      "Epoch 14, Loss: 0.5560940652510373\n",
      "Epoch 15, Loss: 0.5561255230016944\n",
      "Epoch 16, Loss: 0.5561667047778193\n",
      "Epoch 17, Loss: 0.5562095713121433\n",
      "Epoch 18, Loss: 0.5562029540065465\n",
      "Epoch 19, Loss: 0.5561672674224798\n",
      "Epoch 20, Loss: 0.55606571423739\n",
      "Epoch 21, Loss: 0.5558938622247855\n",
      "Epoch 22, Loss: 0.5556953300702715\n",
      "Epoch 23, Loss: 0.5553694280790917\n",
      "Epoch 24, Loss: 0.5550047007782647\n",
      "Epoch 25, Loss: 0.5545577045148639\n",
      "Epoch 26, Loss: 0.55403179042716\n",
      "Epoch 27, Loss: 0.5534128129946805\n",
      "Epoch 28, Loss: 0.552677866065682\n",
      "Epoch 29, Loss: 0.5517967277914448\n",
      "Epoch 30, Loss: 0.5507218078569949\n",
      "Epoch 31, Loss: 0.5493846257552354\n",
      "Epoch 32, Loss: 0.5476278028296706\n",
      "Epoch 33, Loss: 0.5454119047924075\n",
      "Epoch 34, Loss: 0.5426659871992611\n",
      "Epoch 35, Loss: 0.5394550221248915\n",
      "Epoch 36, Loss: 0.5358752689988227\n",
      "Epoch 37, Loss: 0.532131249528872\n",
      "Epoch 38, Loss: 0.528701588238343\n",
      "Epoch 39, Loss: 0.5262637629487498\n",
      "Epoch 40, Loss: 0.5250060648794905\n",
      "Epoch 41, Loss: 0.5234634336053906\n",
      "Epoch 42, Loss: 0.520502115472531\n",
      "Epoch 43, Loss: 0.5169679896186458\n",
      "Epoch 44, Loss: 0.5138924708828652\n",
      "Epoch 45, Loss: 0.5116139078846145\n",
      "Epoch 46, Loss: 0.5098117500571837\n",
      "Epoch 47, Loss: 0.5079856283997214\n",
      "Epoch 48, Loss: 0.5057323399400664\n",
      "Epoch 49, Loss: 0.5030457890394124\n",
      "Epoch 50, Loss: 0.5002321062181037\n",
      "Epoch 51, Loss: 0.4978082272094194\n",
      "Epoch 52, Loss: 0.4959414691441716\n",
      "Epoch 53, Loss: 0.4942913202582909\n",
      "Epoch 54, Loss: 0.4922261449992045\n",
      "Epoch 55, Loss: 0.48980709468092754\n",
      "Epoch 56, Loss: 0.4875521442451462\n",
      "Epoch 57, Loss: 0.48571286483013865\n",
      "Epoch 58, Loss: 0.48405572151378157\n",
      "Epoch 59, Loss: 0.482179681315294\n",
      "Epoch 60, Loss: 0.48007218347136527\n",
      "Epoch 61, Loss: 0.47807645301939156\n",
      "Epoch 62, Loss: 0.4763865849736107\n",
      "Epoch 63, Loss: 0.47476196975644247\n",
      "Epoch 64, Loss: 0.47305782062898916\n",
      "Epoch 65, Loss: 0.4714571662896254\n",
      "Epoch 66, Loss: 0.47011396330110944\n",
      "Epoch 67, Loss: 0.4688086790868186\n",
      "Epoch 68, Loss: 0.4674237403532741\n",
      "Epoch 69, Loss: 0.46609645631716123\n",
      "Epoch 70, Loss: 0.46486615679936466\n",
      "Epoch 71, Loss: 0.4636279965136986\n",
      "Epoch 72, Loss: 0.4623892438859738\n",
      "Epoch 73, Loss: 0.4612111556229617\n",
      "Epoch 74, Loss: 0.46005389009329156\n",
      "Epoch 75, Loss: 0.4589611291071511\n",
      "Epoch 76, Loss: 0.45796829736401545\n",
      "Epoch 77, Loss: 0.4569816073330821\n",
      "Epoch 78, Loss: 0.4559769656100224\n",
      "Epoch 79, Loss: 0.4550280563905756\n",
      "Epoch 80, Loss: 0.45411882265164627\n",
      "Epoch 81, Loss: 0.45323840728132825\n",
      "Epoch 82, Loss: 0.4523660618051073\n",
      "Epoch 83, Loss: 0.4514409208467834\n",
      "Epoch 84, Loss: 0.45052687874267805\n",
      "Epoch 85, Loss: 0.4496492893455164\n",
      "Epoch 86, Loss: 0.44866683890711145\n",
      "Epoch 87, Loss: 0.44762356357509103\n",
      "Epoch 88, Loss: 0.4466581925731765\n",
      "Epoch 89, Loss: 0.4457946308961011\n",
      "Epoch 90, Loss: 0.4449538074585561\n",
      "Epoch 91, Loss: 0.4440312273475329\n",
      "Epoch 92, Loss: 0.44307030484168225\n",
      "Epoch 93, Loss: 0.4421690030492163\n",
      "Epoch 94, Loss: 0.44125937659915626\n",
      "Epoch 95, Loss: 0.4402914062764686\n",
      "Epoch 96, Loss: 0.4392985941137373\n",
      "Epoch 97, Loss: 0.4383431212464983\n",
      "Epoch 98, Loss: 0.4374241763212968\n",
      "Epoch 99, Loss: 0.43651800984330164\n",
      "Epoch 100, Loss: 0.43559453044930635\n",
      "Epoch 101, Loss: 0.43466509524758074\n",
      "Epoch 102, Loss: 0.43371961674101\n",
      "Epoch 103, Loss: 0.43277116020341\n",
      "Epoch 104, Loss: 0.4318208792764198\n",
      "Epoch 105, Loss: 0.43088748871289595\n",
      "Epoch 106, Loss: 0.4299914758691229\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21551718096840786\n",
      "Test R^2 score: 0.4975180509207812\n",
      "Num of epochs: 107\n",
      "Epoch 1, Loss: 0.602549424538319\n",
      "Epoch 2, Loss: 0.599587530179299\n",
      "Epoch 3, Loss: 0.5967131010648689\n",
      "Epoch 4, Loss: 0.5939281597878254\n",
      "Epoch 5, Loss: 0.5912449091315111\n",
      "Epoch 6, Loss: 0.5886487160160205\n",
      "Epoch 7, Loss: 0.586158329358363\n",
      "Epoch 8, Loss: 0.5837670116273825\n",
      "Epoch 9, Loss: 0.5814743962444555\n",
      "Epoch 10, Loss: 0.5792733978020818\n",
      "Epoch 11, Loss: 0.5772958428479501\n",
      "Epoch 12, Loss: 0.5755106607173887\n",
      "Epoch 13, Loss: 0.5738225854823108\n",
      "Epoch 14, Loss: 0.5721993782314748\n",
      "Epoch 15, Loss: 0.5706404174359762\n",
      "Epoch 16, Loss: 0.5691482470125724\n",
      "Epoch 17, Loss: 0.5677391942120085\n",
      "Epoch 18, Loss: 0.5664086703544731\n",
      "Epoch 19, Loss: 0.5651577046665395\n",
      "Epoch 20, Loss: 0.5639805118646724\n",
      "Epoch 21, Loss: 0.5628720218885482\n",
      "Epoch 22, Loss: 0.5618348427447368\n",
      "Epoch 23, Loss: 0.5608734083618542\n",
      "Epoch 24, Loss: 0.5599875766789606\n",
      "Epoch 25, Loss: 0.5591685398921299\n",
      "Epoch 26, Loss: 0.558414270337319\n",
      "Epoch 27, Loss: 0.5577217712132417\n",
      "Epoch 28, Loss: 0.557092503286978\n",
      "Epoch 29, Loss: 0.5565272165516763\n",
      "Epoch 30, Loss: 0.556021014240106\n",
      "Epoch 31, Loss: 0.5555675134431531\n",
      "Epoch 32, Loss: 0.5551379081000133\n",
      "Epoch 33, Loss: 0.5547114085028133\n",
      "Epoch 34, Loss: 0.5542561909300155\n",
      "Epoch 35, Loss: 0.5537377406500545\n",
      "Epoch 36, Loss: 0.5531234719637869\n",
      "Epoch 37, Loss: 0.5523805328164558\n",
      "Epoch 38, Loss: 0.551466630379181\n",
      "Epoch 39, Loss: 0.5503095676792401\n",
      "Epoch 40, Loss: 0.548851582850554\n",
      "Epoch 41, Loss: 0.547041758589173\n",
      "Epoch 42, Loss: 0.5448454389663567\n",
      "Epoch 43, Loss: 0.5422500958985613\n",
      "Epoch 44, Loss: 0.5392263135929495\n",
      "Epoch 45, Loss: 0.5358108915916445\n",
      "Epoch 46, Loss: 0.5320769773485519\n",
      "Epoch 47, Loss: 0.5282014441608012\n",
      "Epoch 48, Loss: 0.5246212796744426\n",
      "Epoch 49, Loss: 0.5218143633490394\n",
      "Epoch 50, Loss: 0.5197939961240423\n",
      "Epoch 51, Loss: 0.5174370051479634\n",
      "Epoch 52, Loss: 0.5140624501422522\n",
      "Epoch 53, Loss: 0.510476592172682\n",
      "Epoch 54, Loss: 0.5076167976639158\n",
      "Epoch 55, Loss: 0.5055954881880241\n",
      "Epoch 56, Loss: 0.5038790140997573\n",
      "Epoch 57, Loss: 0.5018365628165923\n",
      "Epoch 58, Loss: 0.49922258318890533\n",
      "Epoch 59, Loss: 0.49620951405702196\n",
      "Epoch 60, Loss: 0.49322231439693337\n",
      "Epoch 61, Loss: 0.49080487981078746\n",
      "Epoch 62, Loss: 0.48896969898907305\n",
      "Epoch 63, Loss: 0.48715556276769567\n",
      "Epoch 64, Loss: 0.4851614965625083\n",
      "Epoch 65, Loss: 0.4834515320875033\n",
      "Epoch 66, Loss: 0.482235134909147\n",
      "Epoch 67, Loss: 0.4810906703809522\n",
      "Epoch 68, Loss: 0.4796893769019371\n",
      "Epoch 69, Loss: 0.4781518760308075\n",
      "Epoch 70, Loss: 0.47683504784689257\n",
      "Epoch 71, Loss: 0.47582065187358663\n",
      "Epoch 72, Loss: 0.4748189800814985\n",
      "Epoch 73, Loss: 0.47358774187033154\n",
      "Epoch 74, Loss: 0.47228601630955935\n",
      "Epoch 75, Loss: 0.47122786781085596\n",
      "Epoch 76, Loss: 0.4703506321197298\n",
      "Epoch 77, Loss: 0.4694614256926292\n",
      "Epoch 78, Loss: 0.4685575726043809\n",
      "Epoch 79, Loss: 0.46785176364027714\n",
      "Epoch 80, Loss: 0.4673438598367402\n",
      "Epoch 81, Loss: 0.46671090072503724\n",
      "Epoch 82, Loss: 0.46594294247432494\n",
      "Epoch 83, Loss: 0.46515419154533405\n",
      "Epoch 84, Loss: 0.4643931248235208\n",
      "Epoch 85, Loss: 0.4635036931574903\n",
      "Epoch 86, Loss: 0.46226973278598826\n",
      "Epoch 87, Loss: 0.4610567908371178\n",
      "Epoch 88, Loss: 0.46014471897774367\n",
      "Epoch 89, Loss: 0.4593566196683016\n",
      "Epoch 90, Loss: 0.45859218642635985\n",
      "Epoch 91, Loss: 0.457928258172388\n",
      "Epoch 92, Loss: 0.45724549121938385\n",
      "Epoch 93, Loss: 0.4564196251695599\n",
      "Epoch 94, Loss: 0.45562724108988606\n",
      "Epoch 95, Loss: 0.45498625192203\n",
      "Epoch 96, Loss: 0.4541945823641124\n",
      "Epoch 97, Loss: 0.4534323406386035\n",
      "Epoch 98, Loss: 0.45279270352619627\n",
      "Epoch 99, Loss: 0.45203717965945206\n",
      "Epoch 100, Loss: 0.45133305432528426\n",
      "Epoch 101, Loss: 0.450707712902272\n",
      "Epoch 102, Loss: 0.44999102676240044\n",
      "Epoch 103, Loss: 0.4493044729955106\n",
      "Epoch 104, Loss: 0.4486692135649053\n",
      "Epoch 105, Loss: 0.4480095885242672\n",
      "Epoch 106, Loss: 0.44741349087362087\n",
      "Epoch 107, Loss: 0.44679885562324995\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.20825765651948547\n",
      "Test R^2 score: 0.5305071515355861\n",
      "Num of epochs: 108\n",
      "Epoch 1, Loss: 0.5723970542202796\n",
      "Epoch 2, Loss: 0.5713678810979704\n",
      "Epoch 3, Loss: 0.5704138678776264\n",
      "Epoch 4, Loss: 0.5695070039169424\n",
      "Epoch 5, Loss: 0.5686344647696352\n",
      "Epoch 6, Loss: 0.5677990330561903\n",
      "Epoch 7, Loss: 0.5669984812556385\n",
      "Epoch 8, Loss: 0.5662269834762691\n",
      "Epoch 9, Loss: 0.5654918260970161\n",
      "Epoch 10, Loss: 0.5647836265380989\n",
      "Epoch 11, Loss: 0.5641012712082574\n",
      "Epoch 12, Loss: 0.5634436639077293\n",
      "Epoch 13, Loss: 0.5628096469974169\n",
      "Epoch 14, Loss: 0.5621937341858614\n",
      "Epoch 15, Loss: 0.561609596608364\n",
      "Epoch 16, Loss: 0.561064849678619\n",
      "Epoch 17, Loss: 0.5605424355786338\n",
      "Epoch 18, Loss: 0.5600367494428801\n",
      "Epoch 19, Loss: 0.5594507592327936\n",
      "Epoch 20, Loss: 0.5589046280101247\n",
      "Epoch 21, Loss: 0.5583702920903525\n",
      "Epoch 22, Loss: 0.55785983229422\n",
      "Epoch 23, Loss: 0.5573431300231206\n",
      "Epoch 24, Loss: 0.5568472495480459\n",
      "Epoch 25, Loss: 0.5563704788805937\n",
      "Epoch 26, Loss: 0.555882335625591\n",
      "Epoch 27, Loss: 0.555378121280764\n",
      "Epoch 28, Loss: 0.5549089500128256\n",
      "Epoch 29, Loss: 0.554420138115935\n",
      "Epoch 30, Loss: 0.5538947928767737\n",
      "Epoch 31, Loss: 0.5533221728518822\n",
      "Epoch 32, Loss: 0.5526808048883698\n",
      "Epoch 33, Loss: 0.551951362623248\n",
      "Epoch 34, Loss: 0.5511071073137139\n",
      "Epoch 35, Loss: 0.5501226180115392\n",
      "Epoch 36, Loss: 0.5489488244967388\n",
      "Epoch 37, Loss: 0.5475334018812822\n",
      "Epoch 38, Loss: 0.5458269157711862\n",
      "Epoch 39, Loss: 0.543776343792701\n",
      "Epoch 40, Loss: 0.5413351939859187\n",
      "Epoch 41, Loss: 0.538420059399862\n",
      "Epoch 42, Loss: 0.5349727510928477\n",
      "Epoch 43, Loss: 0.5309495637363991\n",
      "Epoch 44, Loss: 0.5264162171694899\n",
      "Epoch 45, Loss: 0.5217165198082796\n",
      "Epoch 46, Loss: 0.5175355137972484\n",
      "Epoch 47, Loss: 0.5150575983837014\n",
      "Epoch 48, Loss: 0.5148088179967582\n",
      "Epoch 49, Loss: 0.5138108098223048\n",
      "Epoch 50, Loss: 0.5104581433266451\n",
      "Epoch 51, Loss: 0.5064754490357829\n",
      "Epoch 52, Loss: 0.5032887778656266\n",
      "Epoch 53, Loss: 0.501279475375244\n",
      "Epoch 54, Loss: 0.49995480273530635\n",
      "Epoch 55, Loss: 0.4985193293017911\n",
      "Epoch 56, Loss: 0.4964125952766874\n",
      "Epoch 57, Loss: 0.4935374291274162\n",
      "Epoch 58, Loss: 0.49023201930479365\n",
      "Epoch 59, Loss: 0.48715487453504613\n",
      "Epoch 60, Loss: 0.4847975856379783\n",
      "Epoch 61, Loss: 0.482804444008193\n",
      "Epoch 62, Loss: 0.48026600103217437\n",
      "Epoch 63, Loss: 0.4770342414979569\n",
      "Epoch 64, Loss: 0.4741344823233525\n",
      "Epoch 65, Loss: 0.4723644774719322\n",
      "Epoch 66, Loss: 0.470971565153628\n",
      "Epoch 67, Loss: 0.4694411745167574\n",
      "Epoch 68, Loss: 0.46802160572752677\n",
      "Epoch 69, Loss: 0.4670913278347575\n",
      "Epoch 70, Loss: 0.4666671253383744\n",
      "Epoch 71, Loss: 0.46617795702107456\n",
      "Epoch 72, Loss: 0.46521484564621796\n",
      "Epoch 73, Loss: 0.4638907336231996\n",
      "Epoch 74, Loss: 0.4627736422642229\n",
      "Epoch 75, Loss: 0.46209721230811646\n",
      "Epoch 76, Loss: 0.461513111388041\n",
      "Epoch 77, Loss: 0.4608832343534773\n",
      "Epoch 78, Loss: 0.46032161299625274\n",
      "Epoch 79, Loss: 0.45980278260391655\n",
      "Epoch 80, Loss: 0.4591284180920802\n",
      "Epoch 81, Loss: 0.4583793060770412\n",
      "Epoch 82, Loss: 0.45759274152454305\n",
      "Epoch 83, Loss: 0.45685053782068713\n",
      "Epoch 84, Loss: 0.4561724786351008\n",
      "Epoch 85, Loss: 0.4554652421662449\n",
      "Epoch 86, Loss: 0.45473804782807276\n",
      "Epoch 87, Loss: 0.45406257708155695\n",
      "Epoch 88, Loss: 0.45342575155295695\n",
      "Epoch 89, Loss: 0.45276632582952564\n",
      "Epoch 90, Loss: 0.45211445822856594\n",
      "Epoch 91, Loss: 0.45145460245479996\n",
      "Epoch 92, Loss: 0.45081394414169323\n",
      "Epoch 93, Loss: 0.4501930782899838\n",
      "Epoch 94, Loss: 0.4495930812080613\n",
      "Epoch 95, Loss: 0.44899241509116256\n",
      "Epoch 96, Loss: 0.4484306720386617\n",
      "Epoch 97, Loss: 0.4478923787326038\n",
      "Epoch 98, Loss: 0.4473390144206748\n",
      "Epoch 99, Loss: 0.4467740751886927\n",
      "Epoch 100, Loss: 0.44622760574932424\n",
      "Epoch 101, Loss: 0.4456857321820086\n",
      "Epoch 102, Loss: 0.4451587645867058\n",
      "Epoch 103, Loss: 0.44465555286721453\n",
      "Epoch 104, Loss: 0.4441513013269474\n",
      "Epoch 105, Loss: 0.4436396582517717\n",
      "Epoch 106, Loss: 0.44312012724894206\n",
      "Epoch 107, Loss: 0.4426121738194655\n",
      "Epoch 108, Loss: 0.44213166170760976\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21042745559147982\n",
      "Test R^2 score: 0.5201860933447142\n",
      "Num of epochs: 109\n",
      "Epoch 1, Loss: 0.5718771491505413\n",
      "Epoch 2, Loss: 0.5701720443632923\n",
      "Epoch 3, Loss: 0.5685956797995529\n",
      "Epoch 4, Loss: 0.5671676779401793\n",
      "Epoch 5, Loss: 0.5658609593585306\n",
      "Epoch 6, Loss: 0.5646749674298783\n",
      "Epoch 7, Loss: 0.5635783667139904\n",
      "Epoch 8, Loss: 0.5625644487970861\n",
      "Epoch 9, Loss: 0.5616326532714815\n",
      "Epoch 10, Loss: 0.5607820077520583\n",
      "Epoch 11, Loss: 0.5600122966438085\n",
      "Epoch 12, Loss: 0.5593448470955426\n",
      "Epoch 13, Loss: 0.5587654916804695\n",
      "Epoch 14, Loss: 0.558248426495806\n",
      "Epoch 15, Loss: 0.5577958817771417\n",
      "Epoch 16, Loss: 0.5574068918867651\n",
      "Epoch 17, Loss: 0.5570841578199534\n",
      "Epoch 18, Loss: 0.5568285976047921\n",
      "Epoch 19, Loss: 0.556619449681182\n",
      "Epoch 20, Loss: 0.5564521872141631\n",
      "Epoch 21, Loss: 0.5563242230561758\n",
      "Epoch 22, Loss: 0.5562322892359118\n",
      "Epoch 23, Loss: 0.5561716613897725\n",
      "Epoch 24, Loss: 0.556136642649717\n",
      "Epoch 25, Loss: 0.5561223344350988\n",
      "Epoch 26, Loss: 0.5561232186612808\n",
      "Epoch 27, Loss: 0.5561239689126963\n",
      "Epoch 28, Loss: 0.556108963692074\n",
      "Epoch 29, Loss: 0.556080425860621\n",
      "Epoch 30, Loss: 0.556025838153791\n",
      "Epoch 31, Loss: 0.5559403682847033\n",
      "Epoch 32, Loss: 0.555827942935975\n",
      "Epoch 33, Loss: 0.5556887066409377\n",
      "Epoch 34, Loss: 0.5555156650394594\n",
      "Epoch 35, Loss: 0.5552996897252976\n",
      "Epoch 36, Loss: 0.5550275754092272\n",
      "Epoch 37, Loss: 0.5546799511462975\n",
      "Epoch 38, Loss: 0.5542183624859883\n",
      "Epoch 39, Loss: 0.5535717070926018\n",
      "Epoch 40, Loss: 0.5526768145565208\n",
      "Epoch 41, Loss: 0.5515111591337596\n",
      "Epoch 42, Loss: 0.5500678995875389\n",
      "Epoch 43, Loss: 0.548369490925142\n",
      "Epoch 44, Loss: 0.5463465180663204\n",
      "Epoch 45, Loss: 0.5438709310906771\n",
      "Epoch 46, Loss: 0.5406497861439296\n",
      "Epoch 47, Loss: 0.5365441694999885\n",
      "Epoch 48, Loss: 0.5315383240922429\n",
      "Epoch 49, Loss: 0.525788365807639\n",
      "Epoch 50, Loss: 0.5197171617164493\n",
      "Epoch 51, Loss: 0.5138928768358342\n",
      "Epoch 52, Loss: 0.5095192617195172\n",
      "Epoch 53, Loss: 0.5070649440014824\n",
      "Epoch 54, Loss: 0.5046566838638129\n",
      "Epoch 55, Loss: 0.5005137069570604\n",
      "Epoch 56, Loss: 0.4954925859552934\n",
      "Epoch 57, Loss: 0.4915419992972476\n",
      "Epoch 58, Loss: 0.4891142948742712\n",
      "Epoch 59, Loss: 0.48768270810070896\n",
      "Epoch 60, Loss: 0.48639191358535844\n",
      "Epoch 61, Loss: 0.4846316857239606\n",
      "Epoch 62, Loss: 0.4823096140851421\n",
      "Epoch 63, Loss: 0.47967656275305315\n",
      "Epoch 64, Loss: 0.47725491173116547\n",
      "Epoch 65, Loss: 0.4753442577108313\n",
      "Epoch 66, Loss: 0.4738139799039831\n",
      "Epoch 67, Loss: 0.47212820270271133\n",
      "Epoch 68, Loss: 0.4701699525630862\n",
      "Epoch 69, Loss: 0.46834729698458366\n",
      "Epoch 70, Loss: 0.46693585932395776\n",
      "Epoch 71, Loss: 0.4658522844838524\n",
      "Epoch 72, Loss: 0.46473208456613596\n",
      "Epoch 73, Loss: 0.46345299147618796\n",
      "Epoch 74, Loss: 0.46209913098935224\n",
      "Epoch 75, Loss: 0.4608229155279802\n",
      "Epoch 76, Loss: 0.45965554694886307\n",
      "Epoch 77, Loss: 0.4585106535560962\n",
      "Epoch 78, Loss: 0.45728865327761864\n",
      "Epoch 79, Loss: 0.4559676518186822\n",
      "Epoch 80, Loss: 0.45461706618800884\n",
      "Epoch 81, Loss: 0.45334123516325303\n",
      "Epoch 82, Loss: 0.45227844807891526\n",
      "Epoch 83, Loss: 0.4513330048014508\n",
      "Epoch 84, Loss: 0.45038926586730166\n",
      "Epoch 85, Loss: 0.4494747593362674\n",
      "Epoch 86, Loss: 0.44868050547194765\n",
      "Epoch 87, Loss: 0.447974580155359\n",
      "Epoch 88, Loss: 0.44729479232368785\n",
      "Epoch 89, Loss: 0.44652347543673054\n",
      "Epoch 90, Loss: 0.44567762430644203\n",
      "Epoch 91, Loss: 0.4448360269865622\n",
      "Epoch 92, Loss: 0.44402139450627476\n",
      "Epoch 93, Loss: 0.4431984395075862\n",
      "Epoch 94, Loss: 0.44239556165770233\n",
      "Epoch 95, Loss: 0.4416271602157765\n",
      "Epoch 96, Loss: 0.44090014112218934\n",
      "Epoch 97, Loss: 0.44020873488434825\n",
      "Epoch 98, Loss: 0.4395003399386518\n",
      "Epoch 99, Loss: 0.43880005523786486\n",
      "Epoch 100, Loss: 0.43812145645297595\n",
      "Epoch 101, Loss: 0.43745963727865295\n",
      "Epoch 102, Loss: 0.43678264048209625\n",
      "Epoch 103, Loss: 0.43608359551575254\n",
      "Epoch 104, Loss: 0.4353850025393739\n",
      "Epoch 105, Loss: 0.43469063453997636\n",
      "Epoch 106, Loss: 0.4340032242081676\n",
      "Epoch 107, Loss: 0.4333058165867432\n",
      "Epoch 108, Loss: 0.43261234806014803\n",
      "Epoch 109, Loss: 0.4319077092659368\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21045262515987073\n",
      "Test R^2 score: 0.5200787625566382\n",
      "Num of epochs: 110\n",
      "Epoch 1, Loss: 0.5564675848518034\n",
      "Epoch 2, Loss: 0.5563033035541608\n",
      "Epoch 3, Loss: 0.5562067047157404\n",
      "Epoch 4, Loss: 0.5561697055427646\n",
      "Epoch 5, Loss: 0.5561767519182309\n",
      "Epoch 6, Loss: 0.5562016948342178\n",
      "Epoch 7, Loss: 0.556220046319163\n",
      "Epoch 8, Loss: 0.556215331250903\n",
      "Epoch 9, Loss: 0.5561945951922075\n",
      "Epoch 10, Loss: 0.5561640523024673\n",
      "Epoch 11, Loss: 0.5561309354846486\n",
      "Epoch 12, Loss: 0.5561001747319716\n",
      "Epoch 13, Loss: 0.556073297873198\n",
      "Epoch 14, Loss: 0.5560488047688908\n",
      "Epoch 15, Loss: 0.5560225150177371\n",
      "Epoch 16, Loss: 0.5559886125352114\n",
      "Epoch 17, Loss: 0.5559421909213708\n",
      "Epoch 18, Loss: 0.5558792796964193\n",
      "Epoch 19, Loss: 0.5557974335183281\n",
      "Epoch 20, Loss: 0.5556939624860667\n",
      "Epoch 21, Loss: 0.5555675670861763\n",
      "Epoch 22, Loss: 0.5554153609874553\n",
      "Epoch 23, Loss: 0.5552361421139638\n",
      "Epoch 24, Loss: 0.5550334550036136\n",
      "Epoch 25, Loss: 0.5547956441845798\n",
      "Epoch 26, Loss: 0.5545072396960665\n",
      "Epoch 27, Loss: 0.554156223595488\n",
      "Epoch 28, Loss: 0.5537389785151998\n",
      "Epoch 29, Loss: 0.553247005132196\n",
      "Epoch 30, Loss: 0.5526598553247386\n",
      "Epoch 31, Loss: 0.5519682626342522\n",
      "Epoch 32, Loss: 0.5511374978551661\n",
      "Epoch 33, Loss: 0.5501340485989914\n",
      "Epoch 34, Loss: 0.5489257237003923\n",
      "Epoch 35, Loss: 0.5474889034296365\n",
      "Epoch 36, Loss: 0.545784216653497\n",
      "Epoch 37, Loss: 0.5437638204287102\n",
      "Epoch 38, Loss: 0.5413854553720964\n",
      "Epoch 39, Loss: 0.5386322073269454\n",
      "Epoch 40, Loss: 0.5353945737454047\n",
      "Epoch 41, Loss: 0.531543173957265\n",
      "Epoch 42, Loss: 0.526997261659142\n",
      "Epoch 43, Loss: 0.5216751892512889\n",
      "Epoch 44, Loss: 0.5157127305736877\n",
      "Epoch 45, Loss: 0.5098187649093955\n",
      "Epoch 46, Loss: 0.5053195503228998\n",
      "Epoch 47, Loss: 0.5037841648982688\n",
      "Epoch 48, Loss: 0.5037461551396476\n",
      "Epoch 49, Loss: 0.5013849627528071\n",
      "Epoch 50, Loss: 0.49703637627431735\n",
      "Epoch 51, Loss: 0.4927385363955739\n",
      "Epoch 52, Loss: 0.4896040431843655\n",
      "Epoch 53, Loss: 0.4875577220000475\n",
      "Epoch 54, Loss: 0.4858990810453507\n",
      "Epoch 55, Loss: 0.4840422687279947\n",
      "Epoch 56, Loss: 0.481777486669289\n",
      "Epoch 57, Loss: 0.4791627828468266\n",
      "Epoch 58, Loss: 0.4765175344797466\n",
      "Epoch 59, Loss: 0.47425592078845014\n",
      "Epoch 60, Loss: 0.4728621200019491\n",
      "Epoch 61, Loss: 0.4724870173875762\n",
      "Epoch 62, Loss: 0.4725488430340813\n",
      "Epoch 63, Loss: 0.4717305157998785\n",
      "Epoch 64, Loss: 0.47002032129509425\n",
      "Epoch 65, Loss: 0.46789272117431824\n",
      "Epoch 66, Loss: 0.46626799241906897\n",
      "Epoch 67, Loss: 0.4651318466761096\n",
      "Epoch 68, Loss: 0.46424562777656864\n",
      "Epoch 69, Loss: 0.46345170537536273\n",
      "Epoch 70, Loss: 0.4626539727966272\n",
      "Epoch 71, Loss: 0.4618096102470408\n",
      "Epoch 72, Loss: 0.46106936298178675\n",
      "Epoch 73, Loss: 0.46049520317544923\n",
      "Epoch 74, Loss: 0.45994592144017565\n",
      "Epoch 75, Loss: 0.4592712155354427\n",
      "Epoch 76, Loss: 0.4584249943052688\n",
      "Epoch 77, Loss: 0.4575046467675367\n",
      "Epoch 78, Loss: 0.4566508772509239\n",
      "Epoch 79, Loss: 0.4559367842273179\n",
      "Epoch 80, Loss: 0.4552559402880586\n",
      "Epoch 81, Loss: 0.454537311800718\n",
      "Epoch 82, Loss: 0.45382133779574274\n",
      "Epoch 83, Loss: 0.453171053552082\n",
      "Epoch 84, Loss: 0.45259438062593754\n",
      "Epoch 85, Loss: 0.4520576995695993\n",
      "Epoch 86, Loss: 0.4514839447225384\n",
      "Epoch 87, Loss: 0.4508559867481709\n",
      "Epoch 88, Loss: 0.450209727025497\n",
      "Epoch 89, Loss: 0.44960151619095556\n",
      "Epoch 90, Loss: 0.449039688911388\n",
      "Epoch 91, Loss: 0.4484928568788965\n",
      "Epoch 92, Loss: 0.4479000306551668\n",
      "Epoch 93, Loss: 0.44731068280074643\n",
      "Epoch 94, Loss: 0.4467186227366642\n",
      "Epoch 95, Loss: 0.4461396716477112\n",
      "Epoch 96, Loss: 0.4455153856382181\n",
      "Epoch 97, Loss: 0.4448773114775942\n",
      "Epoch 98, Loss: 0.44425567908191127\n",
      "Epoch 99, Loss: 0.44369111274809947\n",
      "Epoch 100, Loss: 0.4431223634929266\n",
      "Epoch 101, Loss: 0.4425462164154556\n",
      "Epoch 102, Loss: 0.4419656938610241\n",
      "Epoch 103, Loss: 0.4413808460858556\n",
      "Epoch 104, Loss: 0.44076601369244894\n",
      "Epoch 105, Loss: 0.44012899347588336\n",
      "Epoch 106, Loss: 0.43949810221764657\n",
      "Epoch 107, Loss: 0.4388517545966844\n",
      "Epoch 108, Loss: 0.43818920209274126\n",
      "Epoch 109, Loss: 0.437527212931479\n",
      "Epoch 110, Loss: 0.43685260625264594\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21173399216971023\n",
      "Test R^2 score: 0.5167742845111805\n",
      "Num of epochs: 111\n",
      "Epoch 1, Loss: 0.560244648235043\n",
      "Epoch 2, Loss: 0.5595748128926383\n",
      "Epoch 3, Loss: 0.5589834334540817\n",
      "Epoch 4, Loss: 0.5584448502563317\n",
      "Epoch 5, Loss: 0.5579661598455238\n",
      "Epoch 6, Loss: 0.557554572175725\n",
      "Epoch 7, Loss: 0.5572075616944403\n",
      "Epoch 8, Loss: 0.5569114427811945\n",
      "Epoch 9, Loss: 0.5566691608810892\n",
      "Epoch 10, Loss: 0.5564730207855936\n",
      "Epoch 11, Loss: 0.5563273033261376\n",
      "Epoch 12, Loss: 0.5562185192843868\n",
      "Epoch 13, Loss: 0.5561369373843508\n",
      "Epoch 14, Loss: 0.5560842041928419\n",
      "Epoch 15, Loss: 0.5560507074447453\n",
      "Epoch 16, Loss: 0.5560257309561638\n",
      "Epoch 17, Loss: 0.5560069978534329\n",
      "Epoch 18, Loss: 0.5559843511283116\n",
      "Epoch 19, Loss: 0.5559518936807016\n",
      "Epoch 20, Loss: 0.5559041823491779\n",
      "Epoch 21, Loss: 0.5558374332217674\n",
      "Epoch 22, Loss: 0.5557468667707782\n",
      "Epoch 23, Loss: 0.5556253912530643\n",
      "Epoch 24, Loss: 0.555468157675383\n",
      "Epoch 25, Loss: 0.555268238860439\n",
      "Epoch 26, Loss: 0.5550190646531419\n",
      "Epoch 27, Loss: 0.5547202731914194\n",
      "Epoch 28, Loss: 0.5543585325631597\n",
      "Epoch 29, Loss: 0.5539064684438342\n",
      "Epoch 30, Loss: 0.553344336088166\n",
      "Epoch 31, Loss: 0.5526554334363225\n",
      "Epoch 32, Loss: 0.5518415539414456\n",
      "Epoch 33, Loss: 0.550847421553485\n",
      "Epoch 34, Loss: 0.5496148006819384\n",
      "Epoch 35, Loss: 0.5480837678353191\n",
      "Epoch 36, Loss: 0.5462003088201197\n",
      "Epoch 37, Loss: 0.5439562154392878\n",
      "Epoch 38, Loss: 0.541344635555162\n",
      "Epoch 39, Loss: 0.5383817825226712\n",
      "Epoch 40, Loss: 0.5350718744965276\n",
      "Epoch 41, Loss: 0.5313467049936348\n",
      "Epoch 42, Loss: 0.5271870415577594\n",
      "Epoch 43, Loss: 0.5226199469624295\n",
      "Epoch 44, Loss: 0.517860594629895\n",
      "Epoch 45, Loss: 0.5131950631207477\n",
      "Epoch 46, Loss: 0.5093052857323748\n",
      "Epoch 47, Loss: 0.5068850337304223\n",
      "Epoch 48, Loss: 0.5051061258129228\n",
      "Epoch 49, Loss: 0.5021023955096743\n",
      "Epoch 50, Loss: 0.4977342409736382\n",
      "Epoch 51, Loss: 0.4931479574160997\n",
      "Epoch 52, Loss: 0.4892422336679284\n",
      "Epoch 53, Loss: 0.4863097405693032\n",
      "Epoch 54, Loss: 0.48396854882769696\n",
      "Epoch 55, Loss: 0.48160858171459126\n",
      "Epoch 56, Loss: 0.47898146083868015\n",
      "Epoch 57, Loss: 0.4761814094571529\n",
      "Epoch 58, Loss: 0.47351928608820715\n",
      "Epoch 59, Loss: 0.4713644075774038\n",
      "Epoch 60, Loss: 0.4699148486746519\n",
      "Epoch 61, Loss: 0.46908106239181624\n",
      "Epoch 62, Loss: 0.4683671818608325\n",
      "Epoch 63, Loss: 0.4675690556844096\n",
      "Epoch 64, Loss: 0.4664819205543295\n",
      "Epoch 65, Loss: 0.46520051168325893\n",
      "Epoch 66, Loss: 0.46402292949855195\n",
      "Epoch 67, Loss: 0.4630096861874519\n",
      "Epoch 68, Loss: 0.4619707230058285\n",
      "Epoch 69, Loss: 0.46079979472130933\n",
      "Epoch 70, Loss: 0.45958858247781426\n",
      "Epoch 71, Loss: 0.45847990842288794\n",
      "Epoch 72, Loss: 0.45750518418069097\n",
      "Epoch 73, Loss: 0.4567986573024197\n",
      "Epoch 74, Loss: 0.45630664930993514\n",
      "Epoch 75, Loss: 0.45579560658386714\n",
      "Epoch 76, Loss: 0.4550769134636334\n",
      "Epoch 77, Loss: 0.4541599523269641\n",
      "Epoch 78, Loss: 0.45321120067043724\n",
      "Epoch 79, Loss: 0.4524253672756659\n",
      "Epoch 80, Loss: 0.45177577832785953\n",
      "Epoch 81, Loss: 0.45109020666482225\n",
      "Epoch 82, Loss: 0.4503731696922512\n",
      "Epoch 83, Loss: 0.4496620975872113\n",
      "Epoch 84, Loss: 0.4490171228788636\n",
      "Epoch 85, Loss: 0.44836238005941026\n",
      "Epoch 86, Loss: 0.4476558032874097\n",
      "Epoch 87, Loss: 0.44695764457659287\n",
      "Epoch 88, Loss: 0.44633209889127023\n",
      "Epoch 89, Loss: 0.44570203107320155\n",
      "Epoch 90, Loss: 0.44504162430308425\n",
      "Epoch 91, Loss: 0.4443787941857885\n",
      "Epoch 92, Loss: 0.4437733368714405\n",
      "Epoch 93, Loss: 0.4431370249032667\n",
      "Epoch 94, Loss: 0.44247257088386094\n",
      "Epoch 95, Loss: 0.4417820571316747\n",
      "Epoch 96, Loss: 0.4411081978853586\n",
      "Epoch 97, Loss: 0.4404277590013731\n",
      "Epoch 98, Loss: 0.439706127664155\n",
      "Epoch 99, Loss: 0.43905923781082445\n",
      "Epoch 100, Loss: 0.43838911310194834\n",
      "Epoch 101, Loss: 0.43770247270139706\n",
      "Epoch 102, Loss: 0.43706185676617926\n",
      "Epoch 103, Loss: 0.4363812549998371\n",
      "Epoch 104, Loss: 0.435674058622846\n",
      "Epoch 105, Loss: 0.4349643249790914\n",
      "Epoch 106, Loss: 0.4342326706353238\n",
      "Epoch 107, Loss: 0.43347002962099695\n",
      "Epoch 108, Loss: 0.4327180972931524\n",
      "Epoch 109, Loss: 0.4319621653446491\n",
      "Epoch 110, Loss: 0.4311989989046143\n",
      "Epoch 111, Loss: 0.43047318153384956\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21542604518788666\n",
      "Test R^2 score: 0.49695111910299844\n",
      "Num of epochs: 112\n",
      "Epoch 1, Loss: 0.6192021625153904\n",
      "Epoch 2, Loss: 0.616456576808203\n",
      "Epoch 3, Loss: 0.6137855303127455\n",
      "Epoch 4, Loss: 0.6112545566349993\n",
      "Epoch 5, Loss: 0.6088405613049432\n",
      "Epoch 6, Loss: 0.606488015948817\n",
      "Epoch 7, Loss: 0.6041988961622932\n",
      "Epoch 8, Loss: 0.6019985303147964\n",
      "Epoch 9, Loss: 0.5998562233242333\n",
      "Epoch 10, Loss: 0.5977639244672223\n",
      "Epoch 11, Loss: 0.5957345422683534\n",
      "Epoch 12, Loss: 0.5937296211359352\n",
      "Epoch 13, Loss: 0.5917993174083908\n",
      "Epoch 14, Loss: 0.5899104655348033\n",
      "Epoch 15, Loss: 0.5881095301248531\n",
      "Epoch 16, Loss: 0.5863339672267727\n",
      "Epoch 17, Loss: 0.5845801335104686\n",
      "Epoch 18, Loss: 0.5828516254127172\n",
      "Epoch 19, Loss: 0.5811532842506384\n",
      "Epoch 20, Loss: 0.5794902867053634\n",
      "Epoch 21, Loss: 0.5778597145740743\n",
      "Epoch 22, Loss: 0.5762474398442327\n",
      "Epoch 23, Loss: 0.5746739976799599\n",
      "Epoch 24, Loss: 0.5731588429782883\n",
      "Epoch 25, Loss: 0.5716758005878709\n",
      "Epoch 26, Loss: 0.5702313404600924\n",
      "Epoch 27, Loss: 0.5688251016099257\n",
      "Epoch 28, Loss: 0.5674694474436198\n",
      "Epoch 29, Loss: 0.566176716565486\n",
      "Epoch 30, Loss: 0.5649445977940991\n",
      "Epoch 31, Loss: 0.5637667749873756\n",
      "Epoch 32, Loss: 0.5626356967857551\n",
      "Epoch 33, Loss: 0.5615431541630175\n",
      "Epoch 34, Loss: 0.5604819815153002\n",
      "Epoch 35, Loss: 0.5594442069007792\n",
      "Epoch 36, Loss: 0.5584165118542261\n",
      "Epoch 37, Loss: 0.5574288392517417\n",
      "Epoch 38, Loss: 0.556569064710435\n",
      "Epoch 39, Loss: 0.5556752450149633\n",
      "Epoch 40, Loss: 0.5546051823959582\n",
      "Epoch 41, Loss: 0.553353007246425\n",
      "Epoch 42, Loss: 0.5518875644674901\n",
      "Epoch 43, Loss: 0.5502009479855656\n",
      "Epoch 44, Loss: 0.5482521700383426\n",
      "Epoch 45, Loss: 0.5459496434853133\n",
      "Epoch 46, Loss: 0.5431860344923741\n",
      "Epoch 47, Loss: 0.5398512612025933\n",
      "Epoch 48, Loss: 0.5358764090905462\n",
      "Epoch 49, Loss: 0.5313179309272584\n",
      "Epoch 50, Loss: 0.5264682425062164\n",
      "Epoch 51, Loss: 0.522062802358855\n",
      "Epoch 52, Loss: 0.5193672494964157\n",
      "Epoch 53, Loss: 0.5190438300167772\n",
      "Epoch 54, Loss: 0.5185462677985091\n",
      "Epoch 55, Loss: 0.5160677482852771\n",
      "Epoch 56, Loss: 0.5128243710796089\n",
      "Epoch 57, Loss: 0.5101702899957894\n",
      "Epoch 58, Loss: 0.5082284837475683\n",
      "Epoch 59, Loss: 0.5065132539828213\n",
      "Epoch 60, Loss: 0.5045441131511481\n",
      "Epoch 61, Loss: 0.502196375466366\n",
      "Epoch 62, Loss: 0.49972431211875074\n",
      "Epoch 63, Loss: 0.49762088284661443\n",
      "Epoch 64, Loss: 0.49618636040317043\n",
      "Epoch 65, Loss: 0.495089106920282\n",
      "Epoch 66, Loss: 0.49358049694308775\n",
      "Epoch 67, Loss: 0.49143677936565644\n",
      "Epoch 68, Loss: 0.4892566703737371\n",
      "Epoch 69, Loss: 0.4876686220271103\n",
      "Epoch 70, Loss: 0.48664384574761327\n",
      "Epoch 71, Loss: 0.4856568418346648\n",
      "Epoch 72, Loss: 0.48438604403795243\n",
      "Epoch 73, Loss: 0.4829251988057399\n",
      "Epoch 74, Loss: 0.4815373980684026\n",
      "Epoch 75, Loss: 0.4802215374381442\n",
      "Epoch 76, Loss: 0.4788634145724824\n",
      "Epoch 77, Loss: 0.4774551785987882\n",
      "Epoch 78, Loss: 0.4761945367041104\n",
      "Epoch 79, Loss: 0.4751452807308401\n",
      "Epoch 80, Loss: 0.47413443518115184\n",
      "Epoch 81, Loss: 0.47301582971662387\n",
      "Epoch 82, Loss: 0.47181405943394156\n",
      "Epoch 83, Loss: 0.470597504601629\n",
      "Epoch 84, Loss: 0.469452680973853\n",
      "Epoch 85, Loss: 0.46840182725234786\n",
      "Epoch 86, Loss: 0.467439918839263\n",
      "Epoch 87, Loss: 0.46654380737898765\n",
      "Epoch 88, Loss: 0.4655884139517357\n",
      "Epoch 89, Loss: 0.46457505674929944\n",
      "Epoch 90, Loss: 0.46356322920578474\n",
      "Epoch 91, Loss: 0.46262348691604743\n",
      "Epoch 92, Loss: 0.4616983890078181\n",
      "Epoch 93, Loss: 0.4607436855626544\n",
      "Epoch 94, Loss: 0.4597914397609734\n",
      "Epoch 95, Loss: 0.4588859127838857\n",
      "Epoch 96, Loss: 0.45803070011172275\n",
      "Epoch 97, Loss: 0.45716189286021114\n",
      "Epoch 98, Loss: 0.45624838724243233\n",
      "Epoch 99, Loss: 0.4552905687850898\n",
      "Epoch 100, Loss: 0.45431072381281534\n",
      "Epoch 101, Loss: 0.4533531666839558\n",
      "Epoch 102, Loss: 0.45239341805756317\n",
      "Epoch 103, Loss: 0.451468696222984\n",
      "Epoch 104, Loss: 0.45060684691330777\n",
      "Epoch 105, Loss: 0.4498386915160335\n",
      "Epoch 106, Loss: 0.4491281998634747\n",
      "Epoch 107, Loss: 0.4485027744224411\n",
      "Epoch 108, Loss: 0.447888552722299\n",
      "Epoch 109, Loss: 0.44719820472279304\n",
      "Epoch 110, Loss: 0.44640467375415943\n",
      "Epoch 111, Loss: 0.4455685297803742\n",
      "Epoch 112, Loss: 0.44478607851697594\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2136801442962305\n",
      "Test R^2 score: 0.5057391738255532\n",
      "Num of epochs: 113\n",
      "Epoch 1, Loss: 0.590619543343017\n",
      "Epoch 2, Loss: 0.5887826887398335\n",
      "Epoch 3, Loss: 0.5871823121512152\n",
      "Epoch 4, Loss: 0.5856255781889416\n",
      "Epoch 5, Loss: 0.584121381833744\n",
      "Epoch 6, Loss: 0.5826781345553013\n",
      "Epoch 7, Loss: 0.5812866517273247\n",
      "Epoch 8, Loss: 0.5799572237453027\n",
      "Epoch 9, Loss: 0.5786974624367874\n",
      "Epoch 10, Loss: 0.5774878006014021\n",
      "Epoch 11, Loss: 0.5763117992089486\n",
      "Epoch 12, Loss: 0.5751663744759994\n",
      "Epoch 13, Loss: 0.5740389639775186\n",
      "Epoch 14, Loss: 0.5729273332701038\n",
      "Epoch 15, Loss: 0.5718413723506828\n",
      "Epoch 16, Loss: 0.5707749360093228\n",
      "Epoch 17, Loss: 0.5697100605894418\n",
      "Epoch 18, Loss: 0.5686440819846503\n",
      "Epoch 19, Loss: 0.5675856577300514\n",
      "Epoch 20, Loss: 0.5665383020568413\n",
      "Epoch 21, Loss: 0.5654865032106562\n",
      "Epoch 22, Loss: 0.5643855387737651\n",
      "Epoch 23, Loss: 0.5631937146786394\n",
      "Epoch 24, Loss: 0.5619535175747974\n",
      "Epoch 25, Loss: 0.5606030160257331\n",
      "Epoch 26, Loss: 0.5591066846450994\n",
      "Epoch 27, Loss: 0.5574491818963242\n",
      "Epoch 28, Loss: 0.5555889970595537\n",
      "Epoch 29, Loss: 0.5534624352807024\n",
      "Epoch 30, Loss: 0.5509245936222986\n",
      "Epoch 31, Loss: 0.5477630489332426\n",
      "Epoch 32, Loss: 0.5439648718887162\n",
      "Epoch 33, Loss: 0.5397872475674222\n",
      "Epoch 34, Loss: 0.5357024197172541\n",
      "Epoch 35, Loss: 0.5324725221430558\n",
      "Epoch 36, Loss: 0.53135862361931\n",
      "Epoch 37, Loss: 0.5331545238213152\n",
      "Epoch 38, Loss: 0.534264650160939\n",
      "Epoch 39, Loss: 0.5324058020916139\n",
      "Epoch 40, Loss: 0.529008484148594\n",
      "Epoch 41, Loss: 0.525994984912897\n",
      "Epoch 42, Loss: 0.5240920230599788\n",
      "Epoch 43, Loss: 0.5231156569618465\n",
      "Epoch 44, Loss: 0.5225238797786074\n",
      "Epoch 45, Loss: 0.5218439184287142\n",
      "Epoch 46, Loss: 0.5207859748925859\n",
      "Epoch 47, Loss: 0.5192729623407193\n",
      "Epoch 48, Loss: 0.5174085231223506\n",
      "Epoch 49, Loss: 0.5153455555008485\n",
      "Epoch 50, Loss: 0.5133863170278288\n",
      "Epoch 51, Loss: 0.511886452720245\n",
      "Epoch 52, Loss: 0.5109984300313075\n",
      "Epoch 53, Loss: 0.5103830858459427\n",
      "Epoch 54, Loss: 0.5094281537459078\n",
      "Epoch 55, Loss: 0.5078887001966975\n",
      "Epoch 56, Loss: 0.5061410833861951\n",
      "Epoch 57, Loss: 0.5046509555305302\n",
      "Epoch 58, Loss: 0.5035564184125803\n",
      "Epoch 59, Loss: 0.5026548060336256\n",
      "Epoch 60, Loss: 0.5016536190178073\n",
      "Epoch 61, Loss: 0.5003976135004129\n",
      "Epoch 62, Loss: 0.49893451951073403\n",
      "Epoch 63, Loss: 0.497478340123105\n",
      "Epoch 64, Loss: 0.49621627075625313\n",
      "Epoch 65, Loss: 0.4951752096333919\n",
      "Epoch 66, Loss: 0.4941444999934912\n",
      "Epoch 67, Loss: 0.4929286432651941\n",
      "Epoch 68, Loss: 0.4915839688074471\n",
      "Epoch 69, Loss: 0.49034324136306123\n",
      "Epoch 70, Loss: 0.48928610592350086\n",
      "Epoch 71, Loss: 0.48828947441804027\n",
      "Epoch 72, Loss: 0.48718526290370145\n",
      "Epoch 73, Loss: 0.48598132349850653\n",
      "Epoch 74, Loss: 0.4847901779953029\n",
      "Epoch 75, Loss: 0.48370841520314617\n",
      "Epoch 76, Loss: 0.48266065919689216\n",
      "Epoch 77, Loss: 0.4815048583311456\n",
      "Epoch 78, Loss: 0.4802502391125522\n",
      "Epoch 79, Loss: 0.4790457922055613\n",
      "Epoch 80, Loss: 0.47791975640071704\n",
      "Epoch 81, Loss: 0.47679456157394984\n",
      "Epoch 82, Loss: 0.47557326344985806\n",
      "Epoch 83, Loss: 0.4743164477192211\n",
      "Epoch 84, Loss: 0.47311576070796996\n",
      "Epoch 85, Loss: 0.4719225019583345\n",
      "Epoch 86, Loss: 0.4706561116526799\n",
      "Epoch 87, Loss: 0.4693630501182177\n",
      "Epoch 88, Loss: 0.4681136580393233\n",
      "Epoch 89, Loss: 0.466848873290849\n",
      "Epoch 90, Loss: 0.465517389420325\n",
      "Epoch 91, Loss: 0.46417483116562264\n",
      "Epoch 92, Loss: 0.46283703908317053\n",
      "Epoch 93, Loss: 0.46147069964691595\n",
      "Epoch 94, Loss: 0.46024972714235257\n",
      "Epoch 95, Loss: 0.45903376861365386\n",
      "Epoch 96, Loss: 0.4578164357611827\n",
      "Epoch 97, Loss: 0.45655967967411004\n",
      "Epoch 98, Loss: 0.45529934004679873\n",
      "Epoch 99, Loss: 0.4540530927488269\n",
      "Epoch 100, Loss: 0.4527986107348724\n",
      "Epoch 101, Loss: 0.4515649313679745\n",
      "Epoch 102, Loss: 0.45035432667628\n",
      "Epoch 103, Loss: 0.44914681231804904\n",
      "Epoch 104, Loss: 0.44796581516162703\n",
      "Epoch 105, Loss: 0.44681161217515264\n",
      "Epoch 106, Loss: 0.4456671925134821\n",
      "Epoch 107, Loss: 0.44456068789551084\n",
      "Epoch 108, Loss: 0.44349569166019676\n",
      "Epoch 109, Loss: 0.4424600596910486\n",
      "Epoch 110, Loss: 0.44143909568449613\n",
      "Epoch 111, Loss: 0.4404375874895615\n",
      "Epoch 112, Loss: 0.4394675527959278\n",
      "Epoch 113, Loss: 0.43856198980337896\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22685003760552103\n",
      "Test R^2 score: 0.44245873805583974\n",
      "Num of epochs: 114\n",
      "Epoch 1, Loss: 0.5609139227627394\n",
      "Epoch 2, Loss: 0.559905346338644\n",
      "Epoch 3, Loss: 0.5590066517483612\n",
      "Epoch 4, Loss: 0.5582348931297584\n",
      "Epoch 5, Loss: 0.5575881923746409\n",
      "Epoch 6, Loss: 0.5570621433759806\n",
      "Epoch 7, Loss: 0.5566587478632192\n",
      "Epoch 8, Loss: 0.5563764781962264\n",
      "Epoch 9, Loss: 0.5562096248932439\n",
      "Epoch 10, Loss: 0.5561470118560946\n",
      "Epoch 11, Loss: 0.5561632753123423\n",
      "Epoch 12, Loss: 0.5562332268661291\n",
      "Epoch 13, Loss: 0.556324089131008\n",
      "Epoch 14, Loss: 0.5564100624560183\n",
      "Epoch 15, Loss: 0.5564677455205587\n",
      "Epoch 16, Loss: 0.5564832230598451\n",
      "Epoch 17, Loss: 0.5564517587520663\n",
      "Epoch 18, Loss: 0.5563761300234267\n",
      "Epoch 19, Loss: 0.5562638998973783\n",
      "Epoch 20, Loss: 0.5561242368593851\n",
      "Epoch 21, Loss: 0.5559648929685365\n",
      "Epoch 22, Loss: 0.5557900337938612\n",
      "Epoch 23, Loss: 0.5556016829997279\n",
      "Epoch 24, Loss: 0.5553962585103407\n",
      "Epoch 25, Loss: 0.5551631392597164\n",
      "Epoch 26, Loss: 0.5548829553665037\n",
      "Epoch 27, Loss: 0.5545275282875988\n",
      "Epoch 28, Loss: 0.5540722134293267\n",
      "Epoch 29, Loss: 0.553514395250073\n",
      "Epoch 30, Loss: 0.5528452731650544\n",
      "Epoch 31, Loss: 0.5520603936905673\n",
      "Epoch 32, Loss: 0.5511760784505261\n",
      "Epoch 33, Loss: 0.5502146247938352\n",
      "Epoch 34, Loss: 0.5490626312672562\n",
      "Epoch 35, Loss: 0.5476703037956524\n",
      "Epoch 36, Loss: 0.5459748898712736\n",
      "Epoch 37, Loss: 0.5438693419845814\n",
      "Epoch 38, Loss: 0.5412969856042966\n",
      "Epoch 39, Loss: 0.5381854565871464\n",
      "Epoch 40, Loss: 0.5344292094524777\n",
      "Epoch 41, Loss: 0.5299690454818377\n",
      "Epoch 42, Loss: 0.5248369894815977\n",
      "Epoch 43, Loss: 0.519167751410113\n",
      "Epoch 44, Loss: 0.5131852778761912\n",
      "Epoch 45, Loss: 0.5072888829222117\n",
      "Epoch 46, Loss: 0.5022788271323714\n",
      "Epoch 47, Loss: 0.49928524666933277\n",
      "Epoch 48, Loss: 0.4983425085739181\n",
      "Epoch 49, Loss: 0.49730856530997797\n",
      "Epoch 50, Loss: 0.49462987027916916\n",
      "Epoch 51, Loss: 0.49079877727973364\n",
      "Epoch 52, Loss: 0.48706406517957024\n",
      "Epoch 53, Loss: 0.4841207329118538\n",
      "Epoch 54, Loss: 0.48205036267639956\n",
      "Epoch 55, Loss: 0.48084518758760086\n",
      "Epoch 56, Loss: 0.4805943549745397\n",
      "Epoch 57, Loss: 0.4807760295020405\n",
      "Epoch 58, Loss: 0.47977234217456327\n",
      "Epoch 59, Loss: 0.47764920015782236\n",
      "Epoch 60, Loss: 0.4755129905073418\n",
      "Epoch 61, Loss: 0.4739528872278338\n",
      "Epoch 62, Loss: 0.4728973341307878\n",
      "Epoch 63, Loss: 0.4720472716081414\n",
      "Epoch 64, Loss: 0.4709963221730361\n",
      "Epoch 65, Loss: 0.46913485622750156\n",
      "Epoch 66, Loss: 0.4667779926646856\n",
      "Epoch 67, Loss: 0.4647650451707838\n",
      "Epoch 68, Loss: 0.46373853003514665\n",
      "Epoch 69, Loss: 0.46341156115901017\n",
      "Epoch 70, Loss: 0.4627872786259645\n",
      "Epoch 71, Loss: 0.4615143060285333\n",
      "Epoch 72, Loss: 0.46031499303905316\n",
      "Epoch 73, Loss: 0.4598464985440311\n",
      "Epoch 74, Loss: 0.4596346854257215\n",
      "Epoch 75, Loss: 0.45891101332034473\n",
      "Epoch 76, Loss: 0.4578908189305505\n",
      "Epoch 77, Loss: 0.45721317811039547\n",
      "Epoch 78, Loss: 0.45688101752789245\n",
      "Epoch 79, Loss: 0.45640752894696746\n",
      "Epoch 80, Loss: 0.4556402246786044\n",
      "Epoch 81, Loss: 0.4549198284623948\n",
      "Epoch 82, Loss: 0.45450444551272484\n",
      "Epoch 83, Loss: 0.4541775875645051\n",
      "Epoch 84, Loss: 0.4535865570507235\n",
      "Epoch 85, Loss: 0.4528819451743217\n",
      "Epoch 86, Loss: 0.4523718757647999\n",
      "Epoch 87, Loss: 0.45195382133832485\n",
      "Epoch 88, Loss: 0.4513882700190418\n",
      "Epoch 89, Loss: 0.4507083576048745\n",
      "Epoch 90, Loss: 0.45013582908233596\n",
      "Epoch 91, Loss: 0.4496759658670341\n",
      "Epoch 92, Loss: 0.4490448324806847\n",
      "Epoch 93, Loss: 0.4483865243735072\n",
      "Epoch 94, Loss: 0.447921355540847\n",
      "Epoch 95, Loss: 0.44739697122780714\n",
      "Epoch 96, Loss: 0.44669537235238727\n",
      "Epoch 97, Loss: 0.4461077398989228\n",
      "Epoch 98, Loss: 0.4455447845971816\n",
      "Epoch 99, Loss: 0.44481837313817335\n",
      "Epoch 100, Loss: 0.444241691906663\n",
      "Epoch 101, Loss: 0.44366832505364484\n",
      "Epoch 102, Loss: 0.4429859992273305\n",
      "Epoch 103, Loss: 0.44237543567292165\n",
      "Epoch 104, Loss: 0.4417421531347327\n",
      "Epoch 105, Loss: 0.4410390592554159\n",
      "Epoch 106, Loss: 0.44036061153353984\n",
      "Epoch 107, Loss: 0.43963400614984866\n",
      "Epoch 108, Loss: 0.43890066388419596\n",
      "Epoch 109, Loss: 0.43821023443898477\n",
      "Epoch 110, Loss: 0.437482850556085\n",
      "Epoch 111, Loss: 0.4368091476045429\n",
      "Epoch 112, Loss: 0.4360599318553506\n",
      "Epoch 113, Loss: 0.43537134644987596\n",
      "Epoch 114, Loss: 0.43462906343888114\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21678135478644206\n",
      "Test R^2 score: 0.49027589128890103\n",
      "Num of epochs: 115\n",
      "Epoch 1, Loss: 0.5735235872016068\n",
      "Epoch 2, Loss: 0.5718255026820491\n",
      "Epoch 3, Loss: 0.5702185357430464\n",
      "Epoch 4, Loss: 0.5687132320466501\n",
      "Epoch 5, Loss: 0.567314629717489\n",
      "Epoch 6, Loss: 0.5660896468744294\n",
      "Epoch 7, Loss: 0.5649300906301798\n",
      "Epoch 8, Loss: 0.5638542826556271\n",
      "Epoch 9, Loss: 0.5628668330695231\n",
      "Epoch 10, Loss: 0.5619525364554908\n",
      "Epoch 11, Loss: 0.5610880349573816\n",
      "Epoch 12, Loss: 0.5602796495789127\n",
      "Epoch 13, Loss: 0.5595332428002683\n",
      "Epoch 14, Loss: 0.5588485563434468\n",
      "Epoch 15, Loss: 0.5582176222630453\n",
      "Epoch 16, Loss: 0.557647971457622\n",
      "Epoch 17, Loss: 0.5571366358896993\n",
      "Epoch 18, Loss: 0.5566801090625679\n",
      "Epoch 19, Loss: 0.5562718826447298\n",
      "Epoch 20, Loss: 0.555899920295055\n",
      "Epoch 21, Loss: 0.5555616126789925\n",
      "Epoch 22, Loss: 0.5552481383559111\n",
      "Epoch 23, Loss: 0.5549539812443738\n",
      "Epoch 24, Loss: 0.5547697248093831\n",
      "Epoch 25, Loss: 0.5545609289478313\n",
      "Epoch 26, Loss: 0.554302108557137\n",
      "Epoch 27, Loss: 0.5539924403872957\n",
      "Epoch 28, Loss: 0.5536050846706324\n",
      "Epoch 29, Loss: 0.5530932713691946\n",
      "Epoch 30, Loss: 0.5524303017751624\n",
      "Epoch 31, Loss: 0.5516055817029122\n",
      "Epoch 32, Loss: 0.5506092371075371\n",
      "Epoch 33, Loss: 0.549424604144572\n",
      "Epoch 34, Loss: 0.5480041019554178\n",
      "Epoch 35, Loss: 0.5462811924650836\n",
      "Epoch 36, Loss: 0.5442648040096819\n",
      "Epoch 37, Loss: 0.5419794579463041\n",
      "Epoch 38, Loss: 0.5393640807937315\n",
      "Epoch 39, Loss: 0.5363382526061071\n",
      "Epoch 40, Loss: 0.5328558884570838\n",
      "Epoch 41, Loss: 0.5289450457950959\n",
      "Epoch 42, Loss: 0.52482554738902\n",
      "Epoch 43, Loss: 0.5209835662336701\n",
      "Epoch 44, Loss: 0.5180802410841959\n",
      "Epoch 45, Loss: 0.5163455898651772\n",
      "Epoch 46, Loss: 0.5146270689608828\n",
      "Epoch 47, Loss: 0.5115647411821659\n",
      "Epoch 48, Loss: 0.5077308589157915\n",
      "Epoch 49, Loss: 0.5045338943142793\n",
      "Epoch 50, Loss: 0.5024949055503597\n",
      "Epoch 51, Loss: 0.5007317076649587\n",
      "Epoch 52, Loss: 0.4982324291964911\n",
      "Epoch 53, Loss: 0.49503611666479336\n",
      "Epoch 54, Loss: 0.49186518878676394\n",
      "Epoch 55, Loss: 0.48941961723279154\n",
      "Epoch 56, Loss: 0.4875332405299592\n",
      "Epoch 57, Loss: 0.48521533489567126\n",
      "Epoch 58, Loss: 0.4821679841033566\n",
      "Epoch 59, Loss: 0.4791280447556875\n",
      "Epoch 60, Loss: 0.4768758431573416\n",
      "Epoch 61, Loss: 0.4749564797140232\n",
      "Epoch 62, Loss: 0.4727015197764983\n",
      "Epoch 63, Loss: 0.47012063545385824\n",
      "Epoch 64, Loss: 0.4678427340281356\n",
      "Epoch 65, Loss: 0.46625212482244355\n",
      "Epoch 66, Loss: 0.46493551807004213\n",
      "Epoch 67, Loss: 0.46375167211452206\n",
      "Epoch 68, Loss: 0.4630197272557484\n",
      "Epoch 69, Loss: 0.4624937746556901\n",
      "Epoch 70, Loss: 0.46165901223641415\n",
      "Epoch 71, Loss: 0.46065168086074143\n",
      "Epoch 72, Loss: 0.4596039992735725\n",
      "Epoch 73, Loss: 0.4582702763125083\n",
      "Epoch 74, Loss: 0.45701641482541533\n",
      "Epoch 75, Loss: 0.45622936228231703\n",
      "Epoch 76, Loss: 0.4556158597052897\n",
      "Epoch 77, Loss: 0.45491889492750975\n",
      "Epoch 78, Loss: 0.45425487924452623\n",
      "Epoch 79, Loss: 0.453579986631522\n",
      "Epoch 80, Loss: 0.45286480240234317\n",
      "Epoch 81, Loss: 0.4521532326231881\n",
      "Epoch 82, Loss: 0.4513351838449823\n",
      "Epoch 83, Loss: 0.45045468684542356\n",
      "Epoch 84, Loss: 0.4497209809797778\n",
      "Epoch 85, Loss: 0.4489309467037585\n",
      "Epoch 86, Loss: 0.44807349461014895\n",
      "Epoch 87, Loss: 0.4473235746598138\n",
      "Epoch 88, Loss: 0.4465673734960913\n",
      "Epoch 89, Loss: 0.4457990932537097\n",
      "Epoch 90, Loss: 0.4449483989147508\n",
      "Epoch 91, Loss: 0.4441528446123594\n",
      "Epoch 92, Loss: 0.4432788389219022\n",
      "Epoch 93, Loss: 0.4424397345630762\n",
      "Epoch 94, Loss: 0.4416307199292901\n",
      "Epoch 95, Loss: 0.4408315106999025\n",
      "Epoch 96, Loss: 0.4400135112443605\n",
      "Epoch 97, Loss: 0.4392178223395551\n",
      "Epoch 98, Loss: 0.4383365433029059\n",
      "Epoch 99, Loss: 0.4375139642939171\n",
      "Epoch 100, Loss: 0.4366149635712214\n",
      "Epoch 101, Loss: 0.4357436210441177\n",
      "Epoch 102, Loss: 0.4349174056346867\n",
      "Epoch 103, Loss: 0.4340988001464786\n",
      "Epoch 104, Loss: 0.4332641345336243\n",
      "Epoch 105, Loss: 0.4324538738537687\n",
      "Epoch 106, Loss: 0.431674386339618\n",
      "Epoch 107, Loss: 0.43094750244062197\n",
      "Epoch 108, Loss: 0.43035623357266356\n",
      "Epoch 109, Loss: 0.43006280634430777\n",
      "Epoch 110, Loss: 0.4293382439019066\n",
      "Epoch 111, Loss: 0.42824137700046017\n",
      "Epoch 112, Loss: 0.4275632019338323\n",
      "Epoch 113, Loss: 0.4272210686030367\n",
      "Epoch 114, Loss: 0.42657616981149654\n",
      "Epoch 115, Loss: 0.4255813164217212\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21863678152026933\n",
      "Test R^2 score: 0.48021106556694076\n",
      "Num of epochs: 116\n",
      "Epoch 1, Loss: 0.5656885796320527\n",
      "Epoch 2, Loss: 0.5642775688264684\n",
      "Epoch 3, Loss: 0.5630137693354297\n",
      "Epoch 4, Loss: 0.561870434565343\n",
      "Epoch 5, Loss: 0.5608592475564708\n",
      "Epoch 6, Loss: 0.5600132013365704\n",
      "Epoch 7, Loss: 0.5592846632315801\n",
      "Epoch 8, Loss: 0.5586876423493428\n",
      "Epoch 9, Loss: 0.5581772325088469\n",
      "Epoch 10, Loss: 0.5577273285112468\n",
      "Epoch 11, Loss: 0.5573500813562243\n",
      "Epoch 12, Loss: 0.5570365167184232\n",
      "Epoch 13, Loss: 0.5567573558816474\n",
      "Epoch 14, Loss: 0.5565226647387781\n",
      "Epoch 15, Loss: 0.5563353387327183\n",
      "Epoch 16, Loss: 0.5562004624500293\n",
      "Epoch 17, Loss: 0.5561084545792728\n",
      "Epoch 18, Loss: 0.5560514309958262\n",
      "Epoch 19, Loss: 0.5560222470220287\n",
      "Epoch 20, Loss: 0.5560108570850133\n",
      "Epoch 21, Loss: 0.5560004049375143\n",
      "Epoch 22, Loss: 0.5559808401333062\n",
      "Epoch 23, Loss: 0.5559419228869414\n",
      "Epoch 24, Loss: 0.5558725244249514\n",
      "Epoch 25, Loss: 0.5557656354536582\n",
      "Epoch 26, Loss: 0.5556161118988314\n",
      "Epoch 27, Loss: 0.5554199487036394\n",
      "Epoch 28, Loss: 0.5551734998080734\n",
      "Epoch 29, Loss: 0.5548689907974887\n",
      "Epoch 30, Loss: 0.5545009245525113\n",
      "Epoch 31, Loss: 0.5540592773137228\n",
      "Epoch 32, Loss: 0.5535333203897418\n",
      "Epoch 33, Loss: 0.5529163451961607\n",
      "Epoch 34, Loss: 0.5521834360695271\n",
      "Epoch 35, Loss: 0.5512962098335081\n",
      "Epoch 36, Loss: 0.5502139206496314\n",
      "Epoch 37, Loss: 0.5488772658751111\n",
      "Epoch 38, Loss: 0.5472743075197333\n",
      "Epoch 39, Loss: 0.5453834083166006\n",
      "Epoch 40, Loss: 0.543145734086132\n",
      "Epoch 41, Loss: 0.540518852794364\n",
      "Epoch 42, Loss: 0.5374715520294554\n",
      "Epoch 43, Loss: 0.5340141583880258\n",
      "Epoch 44, Loss: 0.5301905052570258\n",
      "Epoch 45, Loss: 0.5260761425945482\n",
      "Epoch 46, Loss: 0.5219047652110897\n",
      "Epoch 47, Loss: 0.5181645939404019\n",
      "Epoch 48, Loss: 0.5154210756658626\n",
      "Epoch 49, Loss: 0.513447614675812\n",
      "Epoch 50, Loss: 0.5111321734612814\n",
      "Epoch 51, Loss: 0.5077851801639224\n",
      "Epoch 52, Loss: 0.5040650819734781\n",
      "Epoch 53, Loss: 0.5007976785187799\n",
      "Epoch 54, Loss: 0.4984968807759929\n",
      "Epoch 55, Loss: 0.49676100844830784\n",
      "Epoch 56, Loss: 0.494768444988696\n",
      "Epoch 57, Loss: 0.4921519251485708\n",
      "Epoch 58, Loss: 0.4892852379579781\n",
      "Epoch 59, Loss: 0.4864837060583443\n",
      "Epoch 60, Loss: 0.48420977081609795\n",
      "Epoch 61, Loss: 0.4825240733510573\n",
      "Epoch 62, Loss: 0.48074971489543267\n",
      "Epoch 63, Loss: 0.47843337617239323\n",
      "Epoch 64, Loss: 0.4760570659970865\n",
      "Epoch 65, Loss: 0.4742691641692375\n",
      "Epoch 66, Loss: 0.4726167772693148\n",
      "Epoch 67, Loss: 0.4703530873879903\n",
      "Epoch 68, Loss: 0.46801329577441425\n",
      "Epoch 69, Loss: 0.4663713343089504\n",
      "Epoch 70, Loss: 0.4650808739320604\n",
      "Epoch 71, Loss: 0.4636518440322629\n",
      "Epoch 72, Loss: 0.4622507299950769\n",
      "Epoch 73, Loss: 0.4613640637978753\n",
      "Epoch 74, Loss: 0.46073312592823035\n",
      "Epoch 75, Loss: 0.45974572526750157\n",
      "Epoch 76, Loss: 0.4585653299496766\n",
      "Epoch 77, Loss: 0.45753255884600696\n",
      "Epoch 78, Loss: 0.45629482767587426\n",
      "Epoch 79, Loss: 0.45501954188667987\n",
      "Epoch 80, Loss: 0.4540486458740861\n",
      "Epoch 81, Loss: 0.45344481198746633\n",
      "Epoch 82, Loss: 0.4528836725769683\n",
      "Epoch 83, Loss: 0.4521823812641872\n",
      "Epoch 84, Loss: 0.45149300446376744\n",
      "Epoch 85, Loss: 0.4508257111782332\n",
      "Epoch 86, Loss: 0.4499935103319363\n",
      "Epoch 87, Loss: 0.4490961819827699\n",
      "Epoch 88, Loss: 0.4482290394834775\n",
      "Epoch 89, Loss: 0.4474140404078073\n",
      "Epoch 90, Loss: 0.4465605162729312\n",
      "Epoch 91, Loss: 0.4456494545613429\n",
      "Epoch 92, Loss: 0.4446214869244863\n",
      "Epoch 93, Loss: 0.4435542346409477\n",
      "Epoch 94, Loss: 0.44266002802881\n",
      "Epoch 95, Loss: 0.44184833095417037\n",
      "Epoch 96, Loss: 0.4411003436880474\n",
      "Epoch 97, Loss: 0.44033974957802885\n",
      "Epoch 98, Loss: 0.4395614321015131\n",
      "Epoch 99, Loss: 0.438775162668129\n",
      "Epoch 100, Loss: 0.43794568385211846\n",
      "Epoch 101, Loss: 0.43713227212914857\n",
      "Epoch 102, Loss: 0.436325899014306\n",
      "Epoch 103, Loss: 0.43558365191870135\n",
      "Epoch 104, Loss: 0.4348721602463116\n",
      "Epoch 105, Loss: 0.43415033856450863\n",
      "Epoch 106, Loss: 0.43341182638205156\n",
      "Epoch 107, Loss: 0.432679285970192\n",
      "Epoch 108, Loss: 0.43198374233516185\n",
      "Epoch 109, Loss: 0.43129134394620383\n",
      "Epoch 110, Loss: 0.4305670665754073\n",
      "Epoch 111, Loss: 0.42983863946781004\n",
      "Epoch 112, Loss: 0.4291140631346805\n",
      "Epoch 113, Loss: 0.42845427666002234\n",
      "Epoch 114, Loss: 0.4278367150909511\n",
      "Epoch 115, Loss: 0.42721341253354456\n",
      "Epoch 116, Loss: 0.42655755064611633\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21342185789089962\n",
      "Test R^2 score: 0.5068778360239167\n",
      "Num of epochs: 117\n",
      "Epoch 1, Loss: 0.5998940553112765\n",
      "Epoch 2, Loss: 0.5979298731932635\n",
      "Epoch 3, Loss: 0.5959851457245656\n",
      "Epoch 4, Loss: 0.5940578816900078\n",
      "Epoch 5, Loss: 0.5921486794019354\n",
      "Epoch 6, Loss: 0.5902894969474959\n",
      "Epoch 7, Loss: 0.5886210975946959\n",
      "Epoch 8, Loss: 0.5869630358379817\n",
      "Epoch 9, Loss: 0.5853168506531905\n",
      "Epoch 10, Loss: 0.583690403463068\n",
      "Epoch 11, Loss: 0.582076614967337\n",
      "Epoch 12, Loss: 0.580474204529386\n",
      "Epoch 13, Loss: 0.5788879257782124\n",
      "Epoch 14, Loss: 0.5773223769757584\n",
      "Epoch 15, Loss: 0.5757759414904329\n",
      "Epoch 16, Loss: 0.5742468016123935\n",
      "Epoch 17, Loss: 0.5727404814802964\n",
      "Epoch 18, Loss: 0.5712622220507776\n",
      "Epoch 19, Loss: 0.569803873334703\n",
      "Epoch 20, Loss: 0.5683658769897634\n",
      "Epoch 21, Loss: 0.5669487295601964\n",
      "Epoch 22, Loss: 0.5655726909159827\n",
      "Epoch 23, Loss: 0.5644486371030226\n",
      "Epoch 24, Loss: 0.5633555105412993\n",
      "Epoch 25, Loss: 0.5623695434183495\n",
      "Epoch 26, Loss: 0.5614150763735397\n",
      "Epoch 27, Loss: 0.5604283809028444\n",
      "Epoch 28, Loss: 0.5594201810267916\n",
      "Epoch 29, Loss: 0.5582645753494376\n",
      "Epoch 30, Loss: 0.5570337881322017\n",
      "Epoch 31, Loss: 0.5557013634898201\n",
      "Epoch 32, Loss: 0.5542765424788401\n",
      "Epoch 33, Loss: 0.55278478601487\n",
      "Epoch 34, Loss: 0.5512301732517898\n",
      "Epoch 35, Loss: 0.5496043353469887\n",
      "Epoch 36, Loss: 0.5478626868874609\n",
      "Epoch 37, Loss: 0.545920383510399\n",
      "Epoch 38, Loss: 0.5436881260362338\n",
      "Epoch 39, Loss: 0.5410834865494455\n",
      "Epoch 40, Loss: 0.5381069836940128\n",
      "Epoch 41, Loss: 0.5348839449900118\n",
      "Epoch 42, Loss: 0.5317635298129945\n",
      "Epoch 43, Loss: 0.5292824324435685\n",
      "Epoch 44, Loss: 0.5278328499448004\n",
      "Epoch 45, Loss: 0.5268079791086059\n",
      "Epoch 46, Loss: 0.5246887340156262\n",
      "Epoch 47, Loss: 0.5213935858743517\n",
      "Epoch 48, Loss: 0.5181397180341961\n",
      "Epoch 49, Loss: 0.5158349390061407\n",
      "Epoch 50, Loss: 0.5143615965643855\n",
      "Epoch 51, Loss: 0.5130781506374787\n",
      "Epoch 52, Loss: 0.5114659565851473\n",
      "Epoch 53, Loss: 0.50935876621519\n",
      "Epoch 54, Loss: 0.5069065522558168\n",
      "Epoch 55, Loss: 0.5045130425195434\n",
      "Epoch 56, Loss: 0.5025472131061487\n",
      "Epoch 57, Loss: 0.5012594394793883\n",
      "Epoch 58, Loss: 0.5002063980870093\n",
      "Epoch 59, Loss: 0.4986811619293805\n",
      "Epoch 60, Loss: 0.4967601535433289\n",
      "Epoch 61, Loss: 0.49507323000346415\n",
      "Epoch 62, Loss: 0.4938745045921334\n",
      "Epoch 63, Loss: 0.49287191367870054\n",
      "Epoch 64, Loss: 0.4916620022611756\n",
      "Epoch 65, Loss: 0.4901337691342013\n",
      "Epoch 66, Loss: 0.4885931773437033\n",
      "Epoch 67, Loss: 0.48742094927316354\n",
      "Epoch 68, Loss: 0.4865054377989989\n",
      "Epoch 69, Loss: 0.4853798994239\n",
      "Epoch 70, Loss: 0.4840048483150577\n",
      "Epoch 71, Loss: 0.4827841506585427\n",
      "Epoch 72, Loss: 0.4818455268762281\n",
      "Epoch 73, Loss: 0.48090409505535936\n",
      "Epoch 74, Loss: 0.4797847810693691\n",
      "Epoch 75, Loss: 0.47867744979239485\n",
      "Epoch 76, Loss: 0.4777442943575636\n",
      "Epoch 77, Loss: 0.4768166411601654\n",
      "Epoch 78, Loss: 0.4757707773192911\n",
      "Epoch 79, Loss: 0.47478849068762696\n",
      "Epoch 80, Loss: 0.4739028003842519\n",
      "Epoch 81, Loss: 0.4729353183339603\n",
      "Epoch 82, Loss: 0.47188511515506315\n",
      "Epoch 83, Loss: 0.47095354628737884\n",
      "Epoch 84, Loss: 0.47009499231615715\n",
      "Epoch 85, Loss: 0.46913649202252594\n",
      "Epoch 86, Loss: 0.4681662421400554\n",
      "Epoch 87, Loss: 0.4672558654725201\n",
      "Epoch 88, Loss: 0.46632020945836183\n",
      "Epoch 89, Loss: 0.46531869362833095\n",
      "Epoch 90, Loss: 0.4643137177992977\n",
      "Epoch 91, Loss: 0.46331059843769473\n",
      "Epoch 92, Loss: 0.462291684147114\n",
      "Epoch 93, Loss: 0.4613345424325254\n",
      "Epoch 94, Loss: 0.46043358753002817\n",
      "Epoch 95, Loss: 0.45950826411655793\n",
      "Epoch 96, Loss: 0.4585957119329489\n",
      "Epoch 97, Loss: 0.45767562629834807\n",
      "Epoch 98, Loss: 0.4566707819761353\n",
      "Epoch 99, Loss: 0.4556498721938518\n",
      "Epoch 100, Loss: 0.4546548733361016\n",
      "Epoch 101, Loss: 0.4536296073677492\n",
      "Epoch 102, Loss: 0.4525925533471397\n",
      "Epoch 103, Loss: 0.45160454485023727\n",
      "Epoch 104, Loss: 0.4506240755830931\n",
      "Epoch 105, Loss: 0.44960628876343567\n",
      "Epoch 106, Loss: 0.4486039474162692\n",
      "Epoch 107, Loss: 0.4476287733503257\n",
      "Epoch 108, Loss: 0.4466771414700477\n",
      "Epoch 109, Loss: 0.44576849094533794\n",
      "Epoch 110, Loss: 0.44487163404052593\n",
      "Epoch 111, Loss: 0.443953498331871\n",
      "Epoch 112, Loss: 0.443035562041553\n",
      "Epoch 113, Loss: 0.4421335659227279\n",
      "Epoch 114, Loss: 0.4412122654652125\n",
      "Epoch 115, Loss: 0.44032634867649656\n",
      "Epoch 116, Loss: 0.439466179547852\n",
      "Epoch 117, Loss: 0.4386516467871518\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21179537407079316\n",
      "Test R^2 score: 0.5153316944076358\n",
      "Num of epochs: 118\n",
      "Epoch 1, Loss: 0.571966880963272\n",
      "Epoch 2, Loss: 0.5701956955950974\n",
      "Epoch 3, Loss: 0.5685564990524214\n",
      "Epoch 4, Loss: 0.5670484388137045\n",
      "Epoch 5, Loss: 0.5656645028667318\n",
      "Epoch 6, Loss: 0.5644029905236607\n",
      "Epoch 7, Loss: 0.5633985971232246\n",
      "Epoch 8, Loss: 0.5624705412886126\n",
      "Epoch 9, Loss: 0.5616333430995227\n",
      "Epoch 10, Loss: 0.5608941042804633\n",
      "Epoch 11, Loss: 0.5602168264581041\n",
      "Epoch 12, Loss: 0.5595913495275225\n",
      "Epoch 13, Loss: 0.5590185404212444\n",
      "Epoch 14, Loss: 0.5584984544683125\n",
      "Epoch 15, Loss: 0.5580524943417421\n",
      "Epoch 16, Loss: 0.5576578583056857\n",
      "Epoch 17, Loss: 0.5573004576325399\n",
      "Epoch 18, Loss: 0.5569875338869824\n",
      "Epoch 19, Loss: 0.5567085893867033\n",
      "Epoch 20, Loss: 0.5564546776435688\n",
      "Epoch 21, Loss: 0.556232369604278\n",
      "Epoch 22, Loss: 0.5560495551207095\n",
      "Epoch 23, Loss: 0.5558885278516131\n",
      "Epoch 24, Loss: 0.5557283387778306\n",
      "Epoch 25, Loss: 0.5555627660150971\n",
      "Epoch 26, Loss: 0.5553804555432238\n",
      "Epoch 27, Loss: 0.5551673264476177\n",
      "Epoch 28, Loss: 0.554909406519494\n",
      "Epoch 29, Loss: 0.554592043762626\n",
      "Epoch 30, Loss: 0.5541965837458007\n",
      "Epoch 31, Loss: 0.5536994731059366\n",
      "Epoch 32, Loss: 0.5530865898373648\n",
      "Epoch 33, Loss: 0.5523260111030859\n",
      "Epoch 34, Loss: 0.5513691301139314\n",
      "Epoch 35, Loss: 0.5501759226086951\n",
      "Epoch 36, Loss: 0.5486564775077416\n",
      "Epoch 37, Loss: 0.5467156041685242\n",
      "Epoch 38, Loss: 0.5442866516248244\n",
      "Epoch 39, Loss: 0.541346755068482\n",
      "Epoch 40, Loss: 0.5378925786090243\n",
      "Epoch 41, Loss: 0.5339006047094121\n",
      "Epoch 42, Loss: 0.5294209859121312\n",
      "Epoch 43, Loss: 0.5246361913807541\n",
      "Epoch 44, Loss: 0.5198607869591284\n",
      "Epoch 45, Loss: 0.5157253283370229\n",
      "Epoch 46, Loss: 0.5132267695157332\n",
      "Epoch 47, Loss: 0.5125504061869135\n",
      "Epoch 48, Loss: 0.5114602171117997\n",
      "Epoch 49, Loss: 0.5082951233005679\n",
      "Epoch 50, Loss: 0.5041912367117063\n",
      "Epoch 51, Loss: 0.500772207717077\n",
      "Epoch 52, Loss: 0.4987608634989379\n",
      "Epoch 53, Loss: 0.49764982366080635\n",
      "Epoch 54, Loss: 0.4966266203209853\n",
      "Epoch 55, Loss: 0.49511228179006117\n",
      "Epoch 56, Loss: 0.49292323209152716\n",
      "Epoch 57, Loss: 0.49030467589379906\n",
      "Epoch 58, Loss: 0.4877038975556963\n",
      "Epoch 59, Loss: 0.4855886145257028\n",
      "Epoch 60, Loss: 0.4841168700258759\n",
      "Epoch 61, Loss: 0.4828710434119787\n",
      "Epoch 62, Loss: 0.4812405133241245\n",
      "Epoch 63, Loss: 0.47918005765641114\n",
      "Epoch 64, Loss: 0.47716763645541693\n",
      "Epoch 65, Loss: 0.4755685948023821\n",
      "Epoch 66, Loss: 0.4743165576754716\n",
      "Epoch 67, Loss: 0.47312968164846353\n",
      "Epoch 68, Loss: 0.4717388392413419\n",
      "Epoch 69, Loss: 0.4702158578324994\n",
      "Epoch 70, Loss: 0.46876769032475857\n",
      "Epoch 71, Loss: 0.46760729744142765\n",
      "Epoch 72, Loss: 0.4666602441510392\n",
      "Epoch 73, Loss: 0.46573740543264286\n",
      "Epoch 74, Loss: 0.46466227603427\n",
      "Epoch 75, Loss: 0.4635970925473222\n",
      "Epoch 76, Loss: 0.46275388734154366\n",
      "Epoch 77, Loss: 0.46213187632914826\n",
      "Epoch 78, Loss: 0.46154920753858936\n",
      "Epoch 79, Loss: 0.46086582337760357\n",
      "Epoch 80, Loss: 0.4601588380284222\n",
      "Epoch 81, Loss: 0.45949517903273907\n",
      "Epoch 82, Loss: 0.4588716896195429\n",
      "Epoch 83, Loss: 0.45821429643077727\n",
      "Epoch 84, Loss: 0.45746876894032723\n",
      "Epoch 85, Loss: 0.45667874362330185\n",
      "Epoch 86, Loss: 0.4559282866940009\n",
      "Epoch 87, Loss: 0.45525502380812616\n",
      "Epoch 88, Loss: 0.4546649350469416\n",
      "Epoch 89, Loss: 0.45401277391910627\n",
      "Epoch 90, Loss: 0.45332208819618863\n",
      "Epoch 91, Loss: 0.45265566427175163\n",
      "Epoch 92, Loss: 0.45204594812057197\n",
      "Epoch 93, Loss: 0.4514182767919724\n",
      "Epoch 94, Loss: 0.4507374178568518\n",
      "Epoch 95, Loss: 0.4500095869738529\n",
      "Epoch 96, Loss: 0.4492242895696995\n",
      "Epoch 97, Loss: 0.44848878680174586\n",
      "Epoch 98, Loss: 0.4477832747118196\n",
      "Epoch 99, Loss: 0.4470855650293562\n",
      "Epoch 100, Loss: 0.44641720791386846\n",
      "Epoch 101, Loss: 0.4457419984466256\n",
      "Epoch 102, Loss: 0.44501363194941734\n",
      "Epoch 103, Loss: 0.4442158798838884\n",
      "Epoch 104, Loss: 0.44344208067772134\n",
      "Epoch 105, Loss: 0.4426736612393309\n",
      "Epoch 106, Loss: 0.4418477407731585\n",
      "Epoch 107, Loss: 0.4409910291464308\n",
      "Epoch 108, Loss: 0.4402170281093899\n",
      "Epoch 109, Loss: 0.4394251327076486\n",
      "Epoch 110, Loss: 0.438646772011168\n",
      "Epoch 111, Loss: 0.4379118105198383\n",
      "Epoch 112, Loss: 0.4372347811203644\n",
      "Epoch 113, Loss: 0.4365252467039025\n",
      "Epoch 114, Loss: 0.4358349347890506\n",
      "Epoch 115, Loss: 0.43519316196552305\n",
      "Epoch 116, Loss: 0.4345043861016334\n",
      "Epoch 117, Loss: 0.43381391554550536\n",
      "Epoch 118, Loss: 0.4331618039071163\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2091666504736968\n",
      "Test R^2 score: 0.5250782660057393\n",
      "Num of epochs: 119\n",
      "Epoch 1, Loss: 0.5645353264005548\n",
      "Epoch 2, Loss: 0.563222685797136\n",
      "Epoch 3, Loss: 0.5620346263522134\n",
      "Epoch 4, Loss: 0.560968937962477\n",
      "Epoch 5, Loss: 0.5600076135049707\n",
      "Epoch 6, Loss: 0.5591510047178359\n",
      "Epoch 7, Loss: 0.5584102142362347\n",
      "Epoch 8, Loss: 0.5577746701702787\n",
      "Epoch 9, Loss: 0.5572444652164421\n",
      "Epoch 10, Loss: 0.556818000239624\n",
      "Epoch 11, Loss: 0.556525610033728\n",
      "Epoch 12, Loss: 0.5563038928466755\n",
      "Epoch 13, Loss: 0.5561497179995906\n",
      "Epoch 14, Loss: 0.5560566834124864\n",
      "Epoch 15, Loss: 0.5559844315325178\n",
      "Epoch 16, Loss: 0.5559569058132516\n",
      "Epoch 17, Loss: 0.5559600685260466\n",
      "Epoch 18, Loss: 0.5559667691293099\n",
      "Epoch 19, Loss: 0.5559632580232713\n",
      "Epoch 20, Loss: 0.5559369642266903\n",
      "Epoch 21, Loss: 0.5558784755017397\n",
      "Epoch 22, Loss: 0.5557832506265524\n",
      "Epoch 23, Loss: 0.5556479721555467\n",
      "Epoch 24, Loss: 0.5554696331204934\n",
      "Epoch 25, Loss: 0.5552468233442746\n",
      "Epoch 26, Loss: 0.5549772875666293\n",
      "Epoch 27, Loss: 0.5546574920274159\n",
      "Epoch 28, Loss: 0.5542817579470215\n",
      "Epoch 29, Loss: 0.553842007633476\n",
      "Epoch 30, Loss: 0.5533282321480312\n",
      "Epoch 31, Loss: 0.5527359655781967\n",
      "Epoch 32, Loss: 0.5520482472001063\n",
      "Epoch 33, Loss: 0.5512312275205128\n",
      "Epoch 34, Loss: 0.550210291584444\n",
      "Epoch 35, Loss: 0.5489330259373375\n",
      "Epoch 36, Loss: 0.5473798056838195\n",
      "Epoch 37, Loss: 0.5455294814075944\n",
      "Epoch 38, Loss: 0.5433797310060917\n",
      "Epoch 39, Loss: 0.5409437331485676\n",
      "Epoch 40, Loss: 0.5382446498082263\n",
      "Epoch 41, Loss: 0.5352584852591037\n",
      "Epoch 42, Loss: 0.5320565608385548\n",
      "Epoch 43, Loss: 0.528824063653351\n",
      "Epoch 44, Loss: 0.52577068097175\n",
      "Epoch 45, Loss: 0.522947623057206\n",
      "Epoch 46, Loss: 0.5200299902208922\n",
      "Epoch 47, Loss: 0.5167239644468358\n",
      "Epoch 48, Loss: 0.5131614382649803\n",
      "Epoch 49, Loss: 0.5097729620277638\n",
      "Epoch 50, Loss: 0.5067618431660842\n",
      "Epoch 51, Loss: 0.5039521425625733\n",
      "Epoch 52, Loss: 0.5010613858578269\n",
      "Epoch 53, Loss: 0.4980889246523973\n",
      "Epoch 54, Loss: 0.4952562877875931\n",
      "Epoch 55, Loss: 0.49263354178038204\n",
      "Epoch 56, Loss: 0.48999167890197975\n",
      "Epoch 57, Loss: 0.4873642665241729\n",
      "Epoch 58, Loss: 0.4850470280214023\n",
      "Epoch 59, Loss: 0.4827859871260479\n",
      "Epoch 60, Loss: 0.48033199069722093\n",
      "Epoch 61, Loss: 0.4779813781396928\n",
      "Epoch 62, Loss: 0.47577511512546894\n",
      "Epoch 63, Loss: 0.47344019797787035\n",
      "Epoch 64, Loss: 0.4711529177427502\n",
      "Epoch 65, Loss: 0.46900853338998416\n",
      "Epoch 66, Loss: 0.4668509001173788\n",
      "Epoch 67, Loss: 0.4647494629194533\n",
      "Epoch 68, Loss: 0.4628139384039369\n",
      "Epoch 69, Loss: 0.46105648380101877\n",
      "Epoch 70, Loss: 0.45977345267919034\n",
      "Epoch 71, Loss: 0.4590848934406513\n",
      "Epoch 72, Loss: 0.4587769059754486\n",
      "Epoch 73, Loss: 0.4583641569292227\n",
      "Epoch 74, Loss: 0.4576562536727369\n",
      "Epoch 75, Loss: 0.4566860851831318\n",
      "Epoch 76, Loss: 0.45553207676978597\n",
      "Epoch 77, Loss: 0.4541556377413324\n",
      "Epoch 78, Loss: 0.45275854222303025\n",
      "Epoch 79, Loss: 0.4515027240932913\n",
      "Epoch 80, Loss: 0.4504274113397185\n",
      "Epoch 81, Loss: 0.4495132973340958\n",
      "Epoch 82, Loss: 0.4487154089524806\n",
      "Epoch 83, Loss: 0.4478297112212777\n",
      "Epoch 84, Loss: 0.446787399428974\n",
      "Epoch 85, Loss: 0.4457360645796655\n",
      "Epoch 86, Loss: 0.4446953127155279\n",
      "Epoch 87, Loss: 0.4436772924953273\n",
      "Epoch 88, Loss: 0.44273239706125006\n",
      "Epoch 89, Loss: 0.4418804187523339\n",
      "Epoch 90, Loss: 0.4414493573500267\n",
      "Epoch 91, Loss: 0.4416050927258534\n",
      "Epoch 92, Loss: 0.43966040914836213\n",
      "Epoch 93, Loss: 0.4388658116942547\n",
      "Epoch 94, Loss: 0.4386068545599943\n",
      "Epoch 95, Loss: 0.43690376866457775\n",
      "Epoch 96, Loss: 0.4370956425559358\n",
      "Epoch 97, Loss: 0.4353533088029533\n",
      "Epoch 98, Loss: 0.43513732951207124\n",
      "Epoch 99, Loss: 0.43384141120920466\n",
      "Epoch 100, Loss: 0.4332068495594613\n",
      "Epoch 101, Loss: 0.4324248943550813\n",
      "Epoch 102, Loss: 0.43139541358145617\n",
      "Epoch 103, Loss: 0.43105924298843995\n",
      "Epoch 104, Loss: 0.4297393074014724\n",
      "Epoch 105, Loss: 0.4294273802889446\n",
      "Epoch 106, Loss: 0.42833209841299097\n",
      "Epoch 107, Loss: 0.42771315848627633\n",
      "Epoch 108, Loss: 0.4271382746209164\n",
      "Epoch 109, Loss: 0.42608470777059504\n",
      "Epoch 110, Loss: 0.4256819337977446\n",
      "Epoch 111, Loss: 0.42482992513820234\n",
      "Epoch 112, Loss: 0.42399226583206084\n",
      "Epoch 113, Loss: 0.4235500882792727\n",
      "Epoch 114, Loss: 0.42272709518929497\n",
      "Epoch 115, Loss: 0.4219202617807538\n",
      "Epoch 116, Loss: 0.42146975869333625\n",
      "Epoch 117, Loss: 0.42089333940502976\n",
      "Epoch 118, Loss: 0.42002319178242253\n",
      "Epoch 119, Loss: 0.41937505915338635\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2171402628151227\n",
      "Test R^2 score: 0.4896994646121214\n",
      "Num of epochs: 120\n",
      "Epoch 1, Loss: 0.5691340302744404\n",
      "Epoch 2, Loss: 0.5677621331810246\n",
      "Epoch 3, Loss: 0.5664514983946722\n",
      "Epoch 4, Loss: 0.5652344783421694\n",
      "Epoch 5, Loss: 0.5641099355094848\n",
      "Epoch 6, Loss: 0.563058125910292\n",
      "Epoch 7, Loss: 0.5620844948824717\n",
      "Epoch 8, Loss: 0.561200760718365\n",
      "Epoch 9, Loss: 0.5603962074383575\n",
      "Epoch 10, Loss: 0.5596724811372713\n",
      "Epoch 11, Loss: 0.559045542230038\n",
      "Epoch 12, Loss: 0.5584893028939003\n",
      "Epoch 13, Loss: 0.558005042731835\n",
      "Epoch 14, Loss: 0.5575831949057763\n",
      "Epoch 15, Loss: 0.5572218420428425\n",
      "Epoch 16, Loss: 0.5569179446426303\n",
      "Epoch 17, Loss: 0.5566683310590445\n",
      "Epoch 18, Loss: 0.5564719496698357\n",
      "Epoch 19, Loss: 0.5563481951418505\n",
      "Epoch 20, Loss: 0.5562439425277921\n",
      "Epoch 21, Loss: 0.5561662493031534\n",
      "Epoch 22, Loss: 0.5561098747348707\n",
      "Epoch 23, Loss: 0.5560700554125941\n",
      "Epoch 24, Loss: 0.5560411404030364\n",
      "Epoch 25, Loss: 0.5560167530815384\n",
      "Epoch 26, Loss: 0.5559893361671011\n",
      "Epoch 27, Loss: 0.5559526977691805\n",
      "Epoch 28, Loss: 0.5559011801509336\n",
      "Epoch 29, Loss: 0.5558314548967792\n",
      "Epoch 30, Loss: 0.5557344790928433\n",
      "Epoch 31, Loss: 0.5556002615451541\n",
      "Epoch 32, Loss: 0.5554277826109265\n",
      "Epoch 33, Loss: 0.5551989440648896\n",
      "Epoch 34, Loss: 0.5549053516529973\n",
      "Epoch 35, Loss: 0.5545258084887671\n",
      "Epoch 36, Loss: 0.5540371964685444\n",
      "Epoch 37, Loss: 0.5533995921993373\n",
      "Epoch 38, Loss: 0.5526046870376289\n",
      "Epoch 39, Loss: 0.5516231136138493\n",
      "Epoch 40, Loss: 0.5504014619906964\n",
      "Epoch 41, Loss: 0.5489092729519446\n",
      "Epoch 42, Loss: 0.5470922583495784\n",
      "Epoch 43, Loss: 0.5448774640980832\n",
      "Epoch 44, Loss: 0.5422764762844605\n",
      "Epoch 45, Loss: 0.5393000093314017\n",
      "Epoch 46, Loss: 0.5360089490769726\n",
      "Epoch 47, Loss: 0.532514861530793\n",
      "Epoch 48, Loss: 0.5289303119093927\n",
      "Epoch 49, Loss: 0.5254090316554525\n",
      "Epoch 50, Loss: 0.5221642338005801\n",
      "Epoch 51, Loss: 0.5195469674622603\n",
      "Epoch 52, Loss: 0.5176144857050383\n",
      "Epoch 53, Loss: 0.5159158175537503\n",
      "Epoch 54, Loss: 0.5139865564061423\n",
      "Epoch 55, Loss: 0.5117295533415754\n",
      "Epoch 56, Loss: 0.5091892945349412\n",
      "Epoch 57, Loss: 0.5066269166102134\n",
      "Epoch 58, Loss: 0.5040975104209388\n",
      "Epoch 59, Loss: 0.5015325305577008\n",
      "Epoch 60, Loss: 0.49905699973518075\n",
      "Epoch 61, Loss: 0.496818763621441\n",
      "Epoch 62, Loss: 0.49506447114517127\n",
      "Epoch 63, Loss: 0.49378229047719846\n",
      "Epoch 64, Loss: 0.4924821728418366\n",
      "Epoch 65, Loss: 0.4907572416197801\n",
      "Epoch 66, Loss: 0.4886692641666476\n",
      "Epoch 67, Loss: 0.4867043170044236\n",
      "Epoch 68, Loss: 0.4851675778600684\n",
      "Epoch 69, Loss: 0.48389329338033954\n",
      "Epoch 70, Loss: 0.4825834860742444\n",
      "Epoch 71, Loss: 0.4810074987897621\n",
      "Epoch 72, Loss: 0.47921022099733807\n",
      "Epoch 73, Loss: 0.477342670520617\n",
      "Epoch 74, Loss: 0.47551950856331016\n",
      "Epoch 75, Loss: 0.4738846099722324\n",
      "Epoch 76, Loss: 0.4724098382939596\n",
      "Epoch 77, Loss: 0.47102237496005717\n",
      "Epoch 78, Loss: 0.4695895306410418\n",
      "Epoch 79, Loss: 0.4681543698538874\n",
      "Epoch 80, Loss: 0.4667459244634439\n",
      "Epoch 81, Loss: 0.46539312644082603\n",
      "Epoch 82, Loss: 0.46416288889107243\n",
      "Epoch 83, Loss: 0.4631398491789072\n",
      "Epoch 84, Loss: 0.462330249616345\n",
      "Epoch 85, Loss: 0.46151559752828963\n",
      "Epoch 86, Loss: 0.46053852982923743\n",
      "Epoch 87, Loss: 0.4594984706068686\n",
      "Epoch 88, Loss: 0.4585264965698302\n",
      "Epoch 89, Loss: 0.4576627167322661\n",
      "Epoch 90, Loss: 0.4569051519690813\n",
      "Epoch 91, Loss: 0.4561240982722085\n",
      "Epoch 92, Loss: 0.4553549419878818\n",
      "Epoch 93, Loss: 0.45462603071597807\n",
      "Epoch 94, Loss: 0.4539330446669881\n",
      "Epoch 95, Loss: 0.4532360072471966\n",
      "Epoch 96, Loss: 0.45259862778599325\n",
      "Epoch 97, Loss: 0.4520114501667498\n",
      "Epoch 98, Loss: 0.45143912190728624\n",
      "Epoch 99, Loss: 0.45080690360499265\n",
      "Epoch 100, Loss: 0.4501599113794775\n",
      "Epoch 101, Loss: 0.4495324407885932\n",
      "Epoch 102, Loss: 0.44894269671134873\n",
      "Epoch 103, Loss: 0.44835353955866564\n",
      "Epoch 104, Loss: 0.44775565343617846\n",
      "Epoch 105, Loss: 0.4471727966194595\n",
      "Epoch 106, Loss: 0.446556562059885\n",
      "Epoch 107, Loss: 0.4459329265100653\n",
      "Epoch 108, Loss: 0.44534032299727294\n",
      "Epoch 109, Loss: 0.44474791826079396\n",
      "Epoch 110, Loss: 0.44413360348588954\n",
      "Epoch 111, Loss: 0.44349401169016583\n",
      "Epoch 112, Loss: 0.4428403227524541\n",
      "Epoch 113, Loss: 0.4421688008482773\n",
      "Epoch 114, Loss: 0.4414851869202025\n",
      "Epoch 115, Loss: 0.44077794754971006\n",
      "Epoch 116, Loss: 0.44003738558771827\n",
      "Epoch 117, Loss: 0.43928387243602496\n",
      "Epoch 118, Loss: 0.4384904447197359\n",
      "Epoch 119, Loss: 0.43766170306283136\n",
      "Epoch 120, Loss: 0.4368512418396379\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21150320574320483\n",
      "Test R^2 score: 0.5163179530608502\n",
      "Num of epochs: 121\n",
      "Epoch 1, Loss: 0.6031561462977789\n",
      "Epoch 2, Loss: 0.6008890767060538\n",
      "Epoch 3, Loss: 0.5986808023306106\n",
      "Epoch 4, Loss: 0.5965317263291811\n",
      "Epoch 5, Loss: 0.594433967761929\n",
      "Epoch 6, Loss: 0.5923883233472778\n",
      "Epoch 7, Loss: 0.5903921293931315\n",
      "Epoch 8, Loss: 0.5884431542739229\n",
      "Epoch 9, Loss: 0.5865400649237635\n",
      "Epoch 10, Loss: 0.584679588455997\n",
      "Epoch 11, Loss: 0.582858042433289\n",
      "Epoch 12, Loss: 0.5811162835819504\n",
      "Epoch 13, Loss: 0.5796247566589542\n",
      "Epoch 14, Loss: 0.5781572436027305\n",
      "Epoch 15, Loss: 0.5767129200465255\n",
      "Epoch 16, Loss: 0.5752946026373659\n",
      "Epoch 17, Loss: 0.5738967719413183\n",
      "Epoch 18, Loss: 0.5725202286990323\n",
      "Epoch 19, Loss: 0.5711649702883841\n",
      "Epoch 20, Loss: 0.5698317500305643\n",
      "Epoch 21, Loss: 0.5685187833949115\n",
      "Epoch 22, Loss: 0.5672505892720698\n",
      "Epoch 23, Loss: 0.5660829608003846\n",
      "Epoch 24, Loss: 0.5649410633557597\n",
      "Epoch 25, Loss: 0.5638188424971002\n",
      "Epoch 26, Loss: 0.5627395596597032\n",
      "Epoch 27, Loss: 0.5616655518193411\n",
      "Epoch 28, Loss: 0.5605596082351004\n",
      "Epoch 29, Loss: 0.5593683434202206\n",
      "Epoch 30, Loss: 0.5581448491871792\n",
      "Epoch 31, Loss: 0.5568615658956012\n",
      "Epoch 32, Loss: 0.555464106887748\n",
      "Epoch 33, Loss: 0.5538984516062928\n",
      "Epoch 34, Loss: 0.5521567733669763\n",
      "Epoch 35, Loss: 0.5501375427359103\n",
      "Epoch 36, Loss: 0.5477042586633429\n",
      "Epoch 37, Loss: 0.5447998730665639\n",
      "Epoch 38, Loss: 0.5414413264638184\n",
      "Epoch 39, Loss: 0.5377641882467824\n",
      "Epoch 40, Loss: 0.5340951577207594\n",
      "Epoch 41, Loss: 0.5310240713920715\n",
      "Epoch 42, Loss: 0.5290326518219852\n",
      "Epoch 43, Loss: 0.5275433762962568\n",
      "Epoch 44, Loss: 0.5251634524985626\n",
      "Epoch 45, Loss: 0.5217848065952975\n",
      "Epoch 46, Loss: 0.5183752866716146\n",
      "Epoch 47, Loss: 0.5156514710076052\n",
      "Epoch 48, Loss: 0.5135167979266632\n",
      "Epoch 49, Loss: 0.5113157476292424\n",
      "Epoch 50, Loss: 0.5085388564152356\n",
      "Epoch 51, Loss: 0.5050303024227396\n",
      "Epoch 52, Loss: 0.5009996434893834\n",
      "Epoch 53, Loss: 0.4968735281004787\n",
      "Epoch 54, Loss: 0.49314693005706733\n",
      "Epoch 55, Loss: 0.4898906277701664\n",
      "Epoch 56, Loss: 0.48638171165029603\n",
      "Epoch 57, Loss: 0.48227392854746043\n",
      "Epoch 58, Loss: 0.4782011906373292\n",
      "Epoch 59, Loss: 0.47491431153530034\n",
      "Epoch 60, Loss: 0.472693575811825\n",
      "Epoch 61, Loss: 0.47146826007802645\n",
      "Epoch 62, Loss: 0.470996353810567\n",
      "Epoch 63, Loss: 0.4703458482699181\n",
      "Epoch 64, Loss: 0.46915796328863013\n",
      "Epoch 65, Loss: 0.46782484946708436\n",
      "Epoch 66, Loss: 0.46677430549231985\n",
      "Epoch 67, Loss: 0.46574604394044467\n",
      "Epoch 68, Loss: 0.46438004902986646\n",
      "Epoch 69, Loss: 0.4628868263829171\n",
      "Epoch 70, Loss: 0.46186281528841555\n",
      "Epoch 71, Loss: 0.46132953588672115\n",
      "Epoch 72, Loss: 0.4609471012990527\n",
      "Epoch 73, Loss: 0.4604248169857974\n",
      "Epoch 74, Loss: 0.4597248030100614\n",
      "Epoch 75, Loss: 0.4589806252184343\n",
      "Epoch 76, Loss: 0.4582653988718595\n",
      "Epoch 77, Loss: 0.4575609577196211\n",
      "Epoch 78, Loss: 0.4568061111061881\n",
      "Epoch 79, Loss: 0.45597549502403756\n",
      "Epoch 80, Loss: 0.4551134218599244\n",
      "Epoch 81, Loss: 0.4543423250248041\n",
      "Epoch 82, Loss: 0.4536817189011327\n",
      "Epoch 83, Loss: 0.4530459367900566\n",
      "Epoch 84, Loss: 0.4523698828861832\n",
      "Epoch 85, Loss: 0.4516696413436051\n",
      "Epoch 86, Loss: 0.451008606140298\n",
      "Epoch 87, Loss: 0.4504165602244846\n",
      "Epoch 88, Loss: 0.449811196456108\n",
      "Epoch 89, Loss: 0.44917978864138375\n",
      "Epoch 90, Loss: 0.448514950938965\n",
      "Epoch 91, Loss: 0.44783343791262437\n",
      "Epoch 92, Loss: 0.4471752625183164\n",
      "Epoch 93, Loss: 0.4465517902624985\n",
      "Epoch 94, Loss: 0.4459475957613848\n",
      "Epoch 95, Loss: 0.4453463792461633\n",
      "Epoch 96, Loss: 0.444723341858552\n",
      "Epoch 97, Loss: 0.44408105938950176\n",
      "Epoch 98, Loss: 0.44343895555059737\n",
      "Epoch 99, Loss: 0.4428100207359671\n",
      "Epoch 100, Loss: 0.4421671832374367\n",
      "Epoch 101, Loss: 0.4414977426147209\n",
      "Epoch 102, Loss: 0.4408289079077442\n",
      "Epoch 103, Loss: 0.4401535217178934\n",
      "Epoch 104, Loss: 0.4394703162327533\n",
      "Epoch 105, Loss: 0.43880591310665484\n",
      "Epoch 106, Loss: 0.43816265942917776\n",
      "Epoch 107, Loss: 0.4375155139624738\n",
      "Epoch 108, Loss: 0.4368602980512509\n",
      "Epoch 109, Loss: 0.4362067795797256\n",
      "Epoch 110, Loss: 0.4355702415322429\n",
      "Epoch 111, Loss: 0.43494976493556337\n",
      "Epoch 112, Loss: 0.43433557235382675\n",
      "Epoch 113, Loss: 0.4337176240496461\n",
      "Epoch 114, Loss: 0.4330946309175457\n",
      "Epoch 115, Loss: 0.43248190389933505\n",
      "Epoch 116, Loss: 0.43187872762216867\n",
      "Epoch 117, Loss: 0.43128160070655613\n",
      "Epoch 118, Loss: 0.43070174071866035\n",
      "Epoch 119, Loss: 0.43012984655166836\n",
      "Epoch 120, Loss: 0.4295568267489813\n",
      "Epoch 121, Loss: 0.42898236417533575\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21367515532983328\n",
      "Test R^2 score: 0.5064188376006578\n",
      "Num of epochs: 122\n",
      "Epoch 1, Loss: 0.5769178055559101\n",
      "Epoch 2, Loss: 0.5752972187124199\n",
      "Epoch 3, Loss: 0.5737505450692839\n",
      "Epoch 4, Loss: 0.5723181951026381\n",
      "Epoch 5, Loss: 0.570944997094118\n",
      "Epoch 6, Loss: 0.5696347272141588\n",
      "Epoch 7, Loss: 0.5683899966246234\n",
      "Epoch 8, Loss: 0.5671935824653953\n",
      "Epoch 9, Loss: 0.5660321282612844\n",
      "Epoch 10, Loss: 0.5649250262234138\n",
      "Epoch 11, Loss: 0.5638899848433536\n",
      "Epoch 12, Loss: 0.562912445386659\n",
      "Epoch 13, Loss: 0.5619916738320987\n",
      "Epoch 14, Loss: 0.561144068731528\n",
      "Epoch 15, Loss: 0.5603611601908073\n",
      "Epoch 16, Loss: 0.5596347525409103\n",
      "Epoch 17, Loss: 0.5589661323988102\n",
      "Epoch 18, Loss: 0.558358976738418\n",
      "Epoch 19, Loss: 0.5578145013767958\n",
      "Epoch 20, Loss: 0.5573375154215511\n",
      "Epoch 21, Loss: 0.5569266404291933\n",
      "Epoch 22, Loss: 0.5565753563879822\n",
      "Epoch 23, Loss: 0.556284981602739\n",
      "Epoch 24, Loss: 0.5560537624317938\n",
      "Epoch 25, Loss: 0.5558755535846113\n",
      "Epoch 26, Loss: 0.5557448021769643\n",
      "Epoch 27, Loss: 0.5556459071942738\n",
      "Epoch 28, Loss: 0.5555564896920085\n",
      "Epoch 29, Loss: 0.5554501837566393\n",
      "Epoch 30, Loss: 0.5552996360563971\n",
      "Epoch 31, Loss: 0.5550823418217483\n",
      "Epoch 32, Loss: 0.5547701277104911\n",
      "Epoch 33, Loss: 0.5543226465923905\n",
      "Epoch 34, Loss: 0.5536907804611347\n",
      "Epoch 35, Loss: 0.5528213648195823\n",
      "Epoch 36, Loss: 0.5516592562265157\n",
      "Epoch 37, Loss: 0.550144476771363\n",
      "Epoch 38, Loss: 0.5482473049054088\n",
      "Epoch 39, Loss: 0.545919673827349\n",
      "Epoch 40, Loss: 0.5431199446465934\n",
      "Epoch 41, Loss: 0.5397826374093324\n",
      "Epoch 42, Loss: 0.5359166166279518\n",
      "Epoch 43, Loss: 0.5317116582701904\n",
      "Epoch 44, Loss: 0.5277473600584471\n",
      "Epoch 45, Loss: 0.5250715400000234\n",
      "Epoch 46, Loss: 0.5243281288705132\n",
      "Epoch 47, Loss: 0.5235591860854486\n",
      "Epoch 48, Loss: 0.5206520782426295\n",
      "Epoch 49, Loss: 0.5166952412404788\n",
      "Epoch 50, Loss: 0.5134009745649146\n",
      "Epoch 51, Loss: 0.5113568955757442\n",
      "Epoch 52, Loss: 0.5100961833835754\n",
      "Epoch 53, Loss: 0.5088712365974803\n",
      "Epoch 54, Loss: 0.5071760444029019\n",
      "Epoch 55, Loss: 0.5049231566611043\n",
      "Epoch 56, Loss: 0.5023576167967719\n",
      "Epoch 57, Loss: 0.49998401079838445\n",
      "Epoch 58, Loss: 0.4983741582485924\n",
      "Epoch 59, Loss: 0.49744103178075877\n",
      "Epoch 60, Loss: 0.4963177002770189\n",
      "Epoch 61, Loss: 0.4945149718825126\n",
      "Epoch 62, Loss: 0.4925288575814221\n",
      "Epoch 63, Loss: 0.49102150087323193\n",
      "Epoch 64, Loss: 0.4900139392845561\n",
      "Epoch 65, Loss: 0.48897810990927165\n",
      "Epoch 66, Loss: 0.4875523429060057\n",
      "Epoch 67, Loss: 0.48583294274111055\n",
      "Epoch 68, Loss: 0.4842644226848991\n",
      "Epoch 69, Loss: 0.48316919304782757\n",
      "Epoch 70, Loss: 0.4822850206986924\n",
      "Epoch 71, Loss: 0.48116173430179643\n",
      "Epoch 72, Loss: 0.47983003045818357\n",
      "Epoch 73, Loss: 0.47872881130311173\n",
      "Epoch 74, Loss: 0.4778743729034708\n",
      "Epoch 75, Loss: 0.47690951111232643\n",
      "Epoch 76, Loss: 0.47570692712721263\n",
      "Epoch 77, Loss: 0.47456708178047324\n",
      "Epoch 78, Loss: 0.4737374573559524\n",
      "Epoch 79, Loss: 0.47292750432988373\n",
      "Epoch 80, Loss: 0.4718784679512773\n",
      "Epoch 81, Loss: 0.47084272854920095\n",
      "Epoch 82, Loss: 0.4699787089669167\n",
      "Epoch 83, Loss: 0.46904106640117227\n",
      "Epoch 84, Loss: 0.4679985699203845\n",
      "Epoch 85, Loss: 0.4671012333098022\n",
      "Epoch 86, Loss: 0.466315256440662\n",
      "Epoch 87, Loss: 0.4653764125158046\n",
      "Epoch 88, Loss: 0.4644113661438871\n",
      "Epoch 89, Loss: 0.46357565301609377\n",
      "Epoch 90, Loss: 0.46268574490202063\n",
      "Epoch 91, Loss: 0.46172803233670756\n",
      "Epoch 92, Loss: 0.46089063826459853\n",
      "Epoch 93, Loss: 0.46003330576610757\n",
      "Epoch 94, Loss: 0.4590912065560813\n",
      "Epoch 95, Loss: 0.4582358404709676\n",
      "Epoch 96, Loss: 0.45739825910137694\n",
      "Epoch 97, Loss: 0.45652176914871506\n",
      "Epoch 98, Loss: 0.4557065104347851\n",
      "Epoch 99, Loss: 0.45490205821512764\n",
      "Epoch 100, Loss: 0.4540210447401785\n",
      "Epoch 101, Loss: 0.45315972556863593\n",
      "Epoch 102, Loss: 0.45230289399901447\n",
      "Epoch 103, Loss: 0.4514456574697052\n",
      "Epoch 104, Loss: 0.450627365820358\n",
      "Epoch 105, Loss: 0.4498451343924502\n",
      "Epoch 106, Loss: 0.44906640164585704\n",
      "Epoch 107, Loss: 0.4482894074743869\n",
      "Epoch 108, Loss: 0.4475012912145559\n",
      "Epoch 109, Loss: 0.44669033516560147\n",
      "Epoch 110, Loss: 0.4458716044830057\n",
      "Epoch 111, Loss: 0.4451031945888487\n",
      "Epoch 112, Loss: 0.4443410349123822\n",
      "Epoch 113, Loss: 0.44364824001354813\n",
      "Epoch 114, Loss: 0.44303998492107766\n",
      "Epoch 115, Loss: 0.4425632369928644\n",
      "Epoch 116, Loss: 0.44227226509752443\n",
      "Epoch 117, Loss: 0.44203665960945204\n",
      "Epoch 118, Loss: 0.44166462855798483\n",
      "Epoch 119, Loss: 0.4411297666498071\n",
      "Epoch 120, Loss: 0.44050763237670343\n",
      "Epoch 121, Loss: 0.43989676228897223\n",
      "Epoch 122, Loss: 0.43932264298221524\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21714873507459878\n",
      "Test R^2 score: 0.48809564479229806\n",
      "Num of epochs: 123\n",
      "Epoch 1, Loss: 0.5788841418370434\n",
      "Epoch 2, Loss: 0.5769608865782754\n",
      "Epoch 3, Loss: 0.5751346368311864\n",
      "Epoch 4, Loss: 0.5734068911748061\n",
      "Epoch 5, Loss: 0.5717780995221441\n",
      "Epoch 6, Loss: 0.5702490836641608\n",
      "Epoch 7, Loss: 0.568869450360401\n",
      "Epoch 8, Loss: 0.5675773352809802\n",
      "Epoch 9, Loss: 0.5664039611770161\n",
      "Epoch 10, Loss: 0.5653216006683591\n",
      "Epoch 11, Loss: 0.5643043453984835\n",
      "Epoch 12, Loss: 0.5633692912000191\n",
      "Epoch 13, Loss: 0.5624956289757335\n",
      "Epoch 14, Loss: 0.5616845737294882\n",
      "Epoch 15, Loss: 0.5609355203917699\n",
      "Epoch 16, Loss: 0.5602453131745653\n",
      "Epoch 17, Loss: 0.5596141165586117\n",
      "Epoch 18, Loss: 0.5590399180713783\n",
      "Epoch 19, Loss: 0.5585181711992352\n",
      "Epoch 20, Loss: 0.5580422673521832\n",
      "Epoch 21, Loss: 0.5576025965931171\n",
      "Epoch 22, Loss: 0.5571887078649209\n",
      "Epoch 23, Loss: 0.5567899804767629\n",
      "Epoch 24, Loss: 0.5563928420720515\n",
      "Epoch 25, Loss: 0.5559890145530442\n",
      "Epoch 26, Loss: 0.5555719121538452\n",
      "Epoch 27, Loss: 0.5551376933618178\n",
      "Epoch 28, Loss: 0.5546773990194951\n",
      "Epoch 29, Loss: 0.5541784610305844\n",
      "Epoch 30, Loss: 0.5536053000033121\n",
      "Epoch 31, Loss: 0.5529291194049123\n",
      "Epoch 32, Loss: 0.5520901109771238\n",
      "Epoch 33, Loss: 0.5510507830446808\n",
      "Epoch 34, Loss: 0.5497689650535629\n",
      "Epoch 35, Loss: 0.5481991404779593\n",
      "Epoch 36, Loss: 0.5462853658999104\n",
      "Epoch 37, Loss: 0.5439601601675041\n",
      "Epoch 38, Loss: 0.5411618307158191\n",
      "Epoch 39, Loss: 0.537855926480453\n",
      "Epoch 40, Loss: 0.5341115904646231\n",
      "Epoch 41, Loss: 0.530199189722427\n",
      "Epoch 42, Loss: 0.5268006813333836\n",
      "Epoch 43, Loss: 0.5249920435711272\n",
      "Epoch 44, Loss: 0.5249914191316805\n",
      "Epoch 45, Loss: 0.5241380245629242\n",
      "Epoch 46, Loss: 0.5211783379068393\n",
      "Epoch 47, Loss: 0.5175402933365655\n",
      "Epoch 48, Loss: 0.5146172240779135\n",
      "Epoch 49, Loss: 0.5127908672114622\n",
      "Epoch 50, Loss: 0.5116146069031885\n",
      "Epoch 51, Loss: 0.5104459410336492\n",
      "Epoch 52, Loss: 0.5088627152390259\n",
      "Epoch 53, Loss: 0.5067446117406358\n",
      "Epoch 54, Loss: 0.5042588530611068\n",
      "Epoch 55, Loss: 0.5017895264958302\n",
      "Epoch 56, Loss: 0.4998235391130202\n",
      "Epoch 57, Loss: 0.49853472284640044\n",
      "Epoch 58, Loss: 0.4974624196432236\n",
      "Epoch 59, Loss: 0.49591397610058796\n",
      "Epoch 60, Loss: 0.4938287316095157\n",
      "Epoch 61, Loss: 0.4917901115164499\n",
      "Epoch 62, Loss: 0.49019938796225804\n",
      "Epoch 63, Loss: 0.4889599013035906\n",
      "Epoch 64, Loss: 0.48770181989930567\n",
      "Epoch 65, Loss: 0.4861715746545638\n",
      "Epoch 66, Loss: 0.4844069316552339\n",
      "Epoch 67, Loss: 0.48268066445765745\n",
      "Epoch 68, Loss: 0.48124600941378276\n",
      "Epoch 69, Loss: 0.4800596433826942\n",
      "Epoch 70, Loss: 0.47880847299921675\n",
      "Epoch 71, Loss: 0.47736158759070807\n",
      "Epoch 72, Loss: 0.4759498785942685\n",
      "Epoch 73, Loss: 0.47475432705928633\n",
      "Epoch 74, Loss: 0.47371440066750414\n",
      "Epoch 75, Loss: 0.4726466816335621\n",
      "Epoch 76, Loss: 0.47149623043701494\n",
      "Epoch 77, Loss: 0.4703816150815469\n",
      "Epoch 78, Loss: 0.46940506621675554\n",
      "Epoch 79, Loss: 0.46842393660806636\n",
      "Epoch 80, Loss: 0.4673815461399443\n",
      "Epoch 81, Loss: 0.4663605186751796\n",
      "Epoch 82, Loss: 0.46545150840150973\n",
      "Epoch 83, Loss: 0.4646192377126714\n",
      "Epoch 84, Loss: 0.46371504045210055\n",
      "Epoch 85, Loss: 0.4626971295096845\n",
      "Epoch 86, Loss: 0.4617764064206689\n",
      "Epoch 87, Loss: 0.4608384042027441\n",
      "Epoch 88, Loss: 0.4598702181302822\n",
      "Epoch 89, Loss: 0.4589308687229981\n",
      "Epoch 90, Loss: 0.4580367674957549\n",
      "Epoch 91, Loss: 0.4571998480839114\n",
      "Epoch 92, Loss: 0.4563092944402662\n",
      "Epoch 93, Loss: 0.4553922297746723\n",
      "Epoch 94, Loss: 0.4544628715814328\n",
      "Epoch 95, Loss: 0.45351639648161596\n",
      "Epoch 96, Loss: 0.4525879604246123\n",
      "Epoch 97, Loss: 0.45164982964335\n",
      "Epoch 98, Loss: 0.4507023568757657\n",
      "Epoch 99, Loss: 0.4498152380040128\n",
      "Epoch 100, Loss: 0.44893474723421245\n",
      "Epoch 101, Loss: 0.4480653468001807\n",
      "Epoch 102, Loss: 0.44713837258441824\n",
      "Epoch 103, Loss: 0.44628071516314927\n",
      "Epoch 104, Loss: 0.44538423730016447\n",
      "Epoch 105, Loss: 0.4444742176229469\n",
      "Epoch 106, Loss: 0.4435820167551109\n",
      "Epoch 107, Loss: 0.44273699125395694\n",
      "Epoch 108, Loss: 0.4419076822758215\n",
      "Epoch 109, Loss: 0.44113157385156754\n",
      "Epoch 110, Loss: 0.440372082649982\n",
      "Epoch 111, Loss: 0.4395834157440446\n",
      "Epoch 112, Loss: 0.43882391070705185\n",
      "Epoch 113, Loss: 0.43809911033768173\n",
      "Epoch 114, Loss: 0.43733477878670896\n",
      "Epoch 115, Loss: 0.43660160192684155\n",
      "Epoch 116, Loss: 0.43583531087799926\n",
      "Epoch 117, Loss: 0.43509421325847436\n",
      "Epoch 118, Loss: 0.434365607921687\n",
      "Epoch 119, Loss: 0.4335991111630131\n",
      "Epoch 120, Loss: 0.43283526777296166\n",
      "Epoch 121, Loss: 0.43205812380988806\n",
      "Epoch 122, Loss: 0.4312918794724979\n",
      "Epoch 123, Loss: 0.4305425286458683\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21543660038387222\n",
      "Test R^2 score: 0.49691205687922574\n",
      "Num of epochs: 124\n",
      "Epoch 1, Loss: 0.569431643678129\n",
      "Epoch 2, Loss: 0.5678190041790445\n",
      "Epoch 3, Loss: 0.5663095325897007\n",
      "Epoch 4, Loss: 0.5649014444815221\n",
      "Epoch 5, Loss: 0.5635961871706535\n",
      "Epoch 6, Loss: 0.5623949005699536\n",
      "Epoch 7, Loss: 0.561299420328281\n",
      "Epoch 8, Loss: 0.5603109521200881\n",
      "Epoch 9, Loss: 0.559430356190295\n",
      "Epoch 10, Loss: 0.5586493937914577\n",
      "Epoch 11, Loss: 0.5579800201961356\n",
      "Epoch 12, Loss: 0.557452309411846\n",
      "Epoch 13, Loss: 0.5570474844301634\n",
      "Epoch 14, Loss: 0.5567229895974996\n",
      "Epoch 15, Loss: 0.5564746810109439\n",
      "Epoch 16, Loss: 0.556295026606975\n",
      "Epoch 17, Loss: 0.556174662127975\n",
      "Epoch 18, Loss: 0.5561032562429427\n",
      "Epoch 19, Loss: 0.556069439074969\n",
      "Epoch 20, Loss: 0.5560597651644729\n",
      "Epoch 21, Loss: 0.5560624181372853\n",
      "Epoch 22, Loss: 0.5560659018197353\n",
      "Epoch 23, Loss: 0.5560660358070859\n",
      "Epoch 24, Loss: 0.556044651017292\n",
      "Epoch 25, Loss: 0.5559976712665228\n",
      "Epoch 26, Loss: 0.5559214982833193\n",
      "Epoch 27, Loss: 0.5558110798532678\n",
      "Epoch 28, Loss: 0.5556617026119703\n",
      "Epoch 29, Loss: 0.5554770102872594\n",
      "Epoch 30, Loss: 0.555266091978776\n",
      "Epoch 31, Loss: 0.5550252665103815\n",
      "Epoch 32, Loss: 0.5547529101422218\n",
      "Epoch 33, Loss: 0.5544445419130938\n",
      "Epoch 34, Loss: 0.5540938894865362\n",
      "Epoch 35, Loss: 0.5537031062142546\n",
      "Epoch 36, Loss: 0.5533130703178456\n",
      "Epoch 37, Loss: 0.5528950002900631\n",
      "Epoch 38, Loss: 0.5524030845099508\n",
      "Epoch 39, Loss: 0.5518342361861416\n",
      "Epoch 40, Loss: 0.5511910557535411\n",
      "Epoch 41, Loss: 0.5504497856362177\n",
      "Epoch 42, Loss: 0.549564912321969\n",
      "Epoch 43, Loss: 0.5484938231236023\n",
      "Epoch 44, Loss: 0.5471907113077427\n",
      "Epoch 45, Loss: 0.5455870857917685\n",
      "Epoch 46, Loss: 0.5435766755021442\n",
      "Epoch 47, Loss: 0.5410875072994871\n",
      "Epoch 48, Loss: 0.5381382468494915\n",
      "Epoch 49, Loss: 0.5347932572954768\n",
      "Epoch 50, Loss: 0.5310681817324451\n",
      "Epoch 51, Loss: 0.5267570905783023\n",
      "Epoch 52, Loss: 0.5216769602199776\n",
      "Epoch 53, Loss: 0.5157011438270149\n",
      "Epoch 54, Loss: 0.5087736277518033\n",
      "Epoch 55, Loss: 0.5010151095367592\n",
      "Epoch 56, Loss: 0.49270266865006984\n",
      "Epoch 57, Loss: 0.4846311476442738\n",
      "Epoch 58, Loss: 0.4784587437045116\n",
      "Epoch 59, Loss: 0.4762120287068115\n",
      "Epoch 60, Loss: 0.4772723492604365\n",
      "Epoch 61, Loss: 0.4798942014951999\n",
      "Epoch 62, Loss: 0.47973061283968355\n",
      "Epoch 63, Loss: 0.47647314328304713\n",
      "Epoch 64, Loss: 0.47226129534608546\n",
      "Epoch 65, Loss: 0.4695236497413065\n",
      "Epoch 66, Loss: 0.46835679410679903\n",
      "Epoch 67, Loss: 0.46828723953280965\n",
      "Epoch 68, Loss: 0.4684723508618965\n",
      "Epoch 69, Loss: 0.4686034132319477\n",
      "Epoch 70, Loss: 0.46833865873130476\n",
      "Epoch 71, Loss: 0.4675345238774389\n",
      "Epoch 72, Loss: 0.46629923067129647\n",
      "Epoch 73, Loss: 0.4648853732154658\n",
      "Epoch 74, Loss: 0.46349991563942317\n",
      "Epoch 75, Loss: 0.4623296533506668\n",
      "Epoch 76, Loss: 0.46148763575063034\n",
      "Epoch 77, Loss: 0.4609480711161191\n",
      "Epoch 78, Loss: 0.46052487541633164\n",
      "Epoch 79, Loss: 0.4600535823878646\n",
      "Epoch 80, Loss: 0.45948416911345086\n",
      "Epoch 81, Loss: 0.45878655249053973\n",
      "Epoch 82, Loss: 0.45800745461781395\n",
      "Epoch 83, Loss: 0.4572477561474321\n",
      "Epoch 84, Loss: 0.4566169066914111\n",
      "Epoch 85, Loss: 0.4561331475215726\n",
      "Epoch 86, Loss: 0.45568710314678845\n",
      "Epoch 87, Loss: 0.4551574736086646\n",
      "Epoch 88, Loss: 0.45453821333622635\n",
      "Epoch 89, Loss: 0.45390023311231653\n",
      "Epoch 90, Loss: 0.45329616865284705\n",
      "Epoch 91, Loss: 0.45272915090816856\n",
      "Epoch 92, Loss: 0.4521797449465862\n",
      "Epoch 93, Loss: 0.4516268496218134\n",
      "Epoch 94, Loss: 0.4510641093173184\n",
      "Epoch 95, Loss: 0.4505044864342233\n",
      "Epoch 96, Loss: 0.4499184673675086\n",
      "Epoch 97, Loss: 0.4493525927638095\n",
      "Epoch 98, Loss: 0.44881947229343216\n",
      "Epoch 99, Loss: 0.4482541051539418\n",
      "Epoch 100, Loss: 0.4477207084171471\n",
      "Epoch 101, Loss: 0.4471876584525264\n",
      "Epoch 102, Loss: 0.4466479004498736\n",
      "Epoch 103, Loss: 0.44610899249489966\n",
      "Epoch 104, Loss: 0.4455337309499695\n",
      "Epoch 105, Loss: 0.44498831677369505\n",
      "Epoch 106, Loss: 0.4444590974253243\n",
      "Epoch 107, Loss: 0.44396244323143247\n",
      "Epoch 108, Loss: 0.4434584956343413\n",
      "Epoch 109, Loss: 0.4429657318712113\n",
      "Epoch 110, Loss: 0.4424783801330696\n",
      "Epoch 111, Loss: 0.4420028300906754\n",
      "Epoch 112, Loss: 0.4415218066978762\n",
      "Epoch 113, Loss: 0.44104189731133575\n",
      "Epoch 114, Loss: 0.440583940040301\n",
      "Epoch 115, Loss: 0.4400814396635021\n",
      "Epoch 116, Loss: 0.43957214439157494\n",
      "Epoch 117, Loss: 0.43905297605020466\n",
      "Epoch 118, Loss: 0.4385102223006226\n",
      "Epoch 119, Loss: 0.4379882472281725\n",
      "Epoch 120, Loss: 0.4374691066733677\n",
      "Epoch 121, Loss: 0.4369096690107509\n",
      "Epoch 122, Loss: 0.43637002045416373\n",
      "Epoch 123, Loss: 0.4358308319794384\n",
      "Epoch 124, Loss: 0.43527072654029847\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2154615847687239\n",
      "Test R^2 score: 0.49755096975970114\n",
      "Num of epochs: 125\n",
      "Epoch 1, Loss: 0.6106454126622232\n",
      "Epoch 2, Loss: 0.6084948565893402\n",
      "Epoch 3, Loss: 0.6064094373132204\n",
      "Epoch 4, Loss: 0.6043762687504103\n",
      "Epoch 5, Loss: 0.6023895968592005\n",
      "Epoch 6, Loss: 0.6004927400059602\n",
      "Epoch 7, Loss: 0.5986949894587265\n",
      "Epoch 8, Loss: 0.5969285711244338\n",
      "Epoch 9, Loss: 0.5951986709663207\n",
      "Epoch 10, Loss: 0.5935026456682326\n",
      "Epoch 11, Loss: 0.5918376644165473\n",
      "Epoch 12, Loss: 0.5902012632058514\n",
      "Epoch 13, Loss: 0.5885914778659227\n",
      "Epoch 14, Loss: 0.5870067504205478\n",
      "Epoch 15, Loss: 0.5854471316391853\n",
      "Epoch 16, Loss: 0.5839223669296617\n",
      "Epoch 17, Loss: 0.5823762114627484\n",
      "Epoch 18, Loss: 0.5808009515252739\n",
      "Epoch 19, Loss: 0.5792261153751791\n",
      "Epoch 20, Loss: 0.5776178352061844\n",
      "Epoch 21, Loss: 0.5759681988222396\n",
      "Epoch 22, Loss: 0.5742898235321451\n",
      "Epoch 23, Loss: 0.5725621051085323\n",
      "Epoch 24, Loss: 0.5708588112995\n",
      "Epoch 25, Loss: 0.5692022045494247\n",
      "Epoch 26, Loss: 0.5674972024924272\n",
      "Epoch 27, Loss: 0.5658166381590224\n",
      "Epoch 28, Loss: 0.5642753769995211\n",
      "Epoch 29, Loss: 0.5627737174050302\n",
      "Epoch 30, Loss: 0.561113954592992\n",
      "Epoch 31, Loss: 0.5590380522242527\n",
      "Epoch 32, Loss: 0.5564815628599795\n",
      "Epoch 33, Loss: 0.5534208637927189\n",
      "Epoch 34, Loss: 0.5497837096526639\n",
      "Epoch 35, Loss: 0.545645530681471\n",
      "Epoch 36, Loss: 0.5415001637748267\n",
      "Epoch 37, Loss: 0.5382273188842847\n",
      "Epoch 38, Loss: 0.5369819073710412\n",
      "Epoch 39, Loss: 0.5376613485664932\n",
      "Epoch 40, Loss: 0.5377700626225552\n",
      "Epoch 41, Loss: 0.5356002691962668\n",
      "Epoch 42, Loss: 0.5320489709622448\n",
      "Epoch 43, Loss: 0.5285835104099109\n",
      "Epoch 44, Loss: 0.5259424594457192\n",
      "Epoch 45, Loss: 0.5241693817405956\n",
      "Epoch 46, Loss: 0.522712803676196\n",
      "Epoch 47, Loss: 0.5212422355238225\n",
      "Epoch 48, Loss: 0.5194311690914898\n",
      "Epoch 49, Loss: 0.5172677026893315\n",
      "Epoch 50, Loss: 0.5149487482419621\n",
      "Epoch 51, Loss: 0.512826346954911\n",
      "Epoch 52, Loss: 0.5113054601252056\n",
      "Epoch 53, Loss: 0.5102529425360965\n",
      "Epoch 54, Loss: 0.5091115621361681\n",
      "Epoch 55, Loss: 0.5074661247335385\n",
      "Epoch 56, Loss: 0.5055671643256432\n",
      "Epoch 57, Loss: 0.503905954286947\n",
      "Epoch 58, Loss: 0.5025380804331762\n",
      "Epoch 59, Loss: 0.5011766714459714\n",
      "Epoch 60, Loss: 0.49955974508323153\n",
      "Epoch 61, Loss: 0.4976968619934254\n",
      "Epoch 62, Loss: 0.49585208864028907\n",
      "Epoch 63, Loss: 0.4942956764106574\n",
      "Epoch 64, Loss: 0.4929319987676292\n",
      "Epoch 65, Loss: 0.491406593261987\n",
      "Epoch 66, Loss: 0.48964849166961116\n",
      "Epoch 67, Loss: 0.48796422203227796\n",
      "Epoch 68, Loss: 0.48647698265231154\n",
      "Epoch 69, Loss: 0.48497421363237053\n",
      "Epoch 70, Loss: 0.4832893325519521\n",
      "Epoch 71, Loss: 0.4815639171789904\n",
      "Epoch 72, Loss: 0.4800619093140528\n",
      "Epoch 73, Loss: 0.47867306046224706\n",
      "Epoch 74, Loss: 0.4770889032724504\n",
      "Epoch 75, Loss: 0.4754568155767203\n",
      "Epoch 76, Loss: 0.47401472601569705\n",
      "Epoch 77, Loss: 0.4725799341304316\n",
      "Epoch 78, Loss: 0.4710112706696673\n",
      "Epoch 79, Loss: 0.4695499270464581\n",
      "Epoch 80, Loss: 0.4682192499753483\n",
      "Epoch 81, Loss: 0.4668011365879526\n",
      "Epoch 82, Loss: 0.46537160955275536\n",
      "Epoch 83, Loss: 0.4640974095889745\n",
      "Epoch 84, Loss: 0.46278507300791644\n",
      "Epoch 85, Loss: 0.4614339353456524\n",
      "Epoch 86, Loss: 0.4602077170379827\n",
      "Epoch 87, Loss: 0.45899546183729967\n",
      "Epoch 88, Loss: 0.45780724076514845\n",
      "Epoch 89, Loss: 0.4567049769211599\n",
      "Epoch 90, Loss: 0.4555520794446385\n",
      "Epoch 91, Loss: 0.4544684783823518\n",
      "Epoch 92, Loss: 0.45344510774651675\n",
      "Epoch 93, Loss: 0.45238902074626697\n",
      "Epoch 94, Loss: 0.4514086378700529\n",
      "Epoch 95, Loss: 0.45039859576091074\n",
      "Epoch 96, Loss: 0.44944067739022125\n",
      "Epoch 97, Loss: 0.4485223264580619\n",
      "Epoch 98, Loss: 0.44763399970928497\n",
      "Epoch 99, Loss: 0.44680754345828555\n",
      "Epoch 100, Loss: 0.44594879868541576\n",
      "Epoch 101, Loss: 0.44510826647574214\n",
      "Epoch 102, Loss: 0.4442372139049764\n",
      "Epoch 103, Loss: 0.44336340814176034\n",
      "Epoch 104, Loss: 0.44243599611973294\n",
      "Epoch 105, Loss: 0.4415379724351921\n",
      "Epoch 106, Loss: 0.44064807763774916\n",
      "Epoch 107, Loss: 0.43981040841771163\n",
      "Epoch 108, Loss: 0.4389867893796869\n",
      "Epoch 109, Loss: 0.4381627954623021\n",
      "Epoch 110, Loss: 0.4373189687846067\n",
      "Epoch 111, Loss: 0.4364531799716237\n",
      "Epoch 112, Loss: 0.4355604571632433\n",
      "Epoch 113, Loss: 0.43463586891414396\n",
      "Epoch 114, Loss: 0.4337379284588809\n",
      "Epoch 115, Loss: 0.43286595823476354\n",
      "Epoch 116, Loss: 0.43206095188127835\n",
      "Epoch 117, Loss: 0.4312677974069191\n",
      "Epoch 118, Loss: 0.4304540905126559\n",
      "Epoch 119, Loss: 0.42963565166810863\n",
      "Epoch 120, Loss: 0.42883206961095066\n",
      "Epoch 121, Loss: 0.4280594065461547\n",
      "Epoch 122, Loss: 0.42729314054584916\n",
      "Epoch 123, Loss: 0.426537201379227\n",
      "Epoch 124, Loss: 0.4258025102819534\n",
      "Epoch 125, Loss: 0.4251019369620105\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21559471737507482\n",
      "Test R^2 score: 0.49612735917945633\n",
      "Num of epochs: 126\n",
      "Epoch 1, Loss: 0.5568019432414197\n",
      "Epoch 2, Loss: 0.5564049204998207\n",
      "Epoch 3, Loss: 0.5562001677490579\n",
      "Epoch 4, Loss: 0.5561698127126417\n",
      "Epoch 5, Loss: 0.5562396294987955\n",
      "Epoch 6, Loss: 0.5563011606670274\n",
      "Epoch 7, Loss: 0.556305821435995\n",
      "Epoch 8, Loss: 0.5562572832380811\n",
      "Epoch 9, Loss: 0.5561822978619938\n",
      "Epoch 10, Loss: 0.5561063645323625\n",
      "Epoch 11, Loss: 0.5560451333900378\n",
      "Epoch 12, Loss: 0.555999306110594\n",
      "Epoch 13, Loss: 0.5559600685260466\n",
      "Epoch 14, Loss: 0.5559127867739638\n",
      "Epoch 15, Loss: 0.5558416689467425\n",
      "Epoch 16, Loss: 0.5557339696369735\n",
      "Epoch 17, Loss: 0.5555832306273538\n",
      "Epoch 18, Loss: 0.5553858484569072\n",
      "Epoch 19, Loss: 0.5551391965274416\n",
      "Epoch 20, Loss: 0.5548390463541308\n",
      "Epoch 21, Loss: 0.5544780281949101\n",
      "Epoch 22, Loss: 0.5540500255198112\n",
      "Epoch 23, Loss: 0.5535369007487848\n",
      "Epoch 24, Loss: 0.5529316796011227\n",
      "Epoch 25, Loss: 0.5522386734225313\n",
      "Epoch 26, Loss: 0.5514533088819316\n",
      "Epoch 27, Loss: 0.5505715099337556\n",
      "Epoch 28, Loss: 0.5495710672721368\n",
      "Epoch 29, Loss: 0.5484104671499807\n",
      "Epoch 30, Loss: 0.5470681530583998\n",
      "Epoch 31, Loss: 0.5454856390019875\n",
      "Epoch 32, Loss: 0.5436188079155037\n",
      "Epoch 33, Loss: 0.5414178227760701\n",
      "Epoch 34, Loss: 0.5388551119605528\n",
      "Epoch 35, Loss: 0.5358813309220998\n",
      "Epoch 36, Loss: 0.5324647422992093\n",
      "Epoch 37, Loss: 0.5286765880439463\n",
      "Epoch 38, Loss: 0.5245317437172737\n",
      "Epoch 39, Loss: 0.5200472972065747\n",
      "Epoch 40, Loss: 0.5152712677883992\n",
      "Epoch 41, Loss: 0.5101883403505253\n",
      "Epoch 42, Loss: 0.504760048437968\n",
      "Epoch 43, Loss: 0.49905234176625973\n",
      "Epoch 44, Loss: 0.49327787086989655\n",
      "Epoch 45, Loss: 0.48770101022199197\n",
      "Epoch 46, Loss: 0.4827132947164906\n",
      "Epoch 47, Loss: 0.47902222888989726\n",
      "Epoch 48, Loss: 0.47724951018282824\n",
      "Epoch 49, Loss: 0.4770184352689138\n",
      "Epoch 50, Loss: 0.47691974382487057\n",
      "Epoch 51, Loss: 0.47536905344760283\n",
      "Epoch 52, Loss: 0.47248348515022226\n",
      "Epoch 53, Loss: 0.46965617963128015\n",
      "Epoch 54, Loss: 0.4679468904462234\n",
      "Epoch 55, Loss: 0.46717550970402766\n",
      "Epoch 56, Loss: 0.4664887245140276\n",
      "Epoch 57, Loss: 0.46567710738513907\n",
      "Epoch 58, Loss: 0.4648727440006159\n",
      "Epoch 59, Loss: 0.463947779029096\n",
      "Epoch 60, Loss: 0.46285624316042295\n",
      "Epoch 61, Loss: 0.4616347712586092\n",
      "Epoch 62, Loss: 0.4602643447880446\n",
      "Epoch 63, Loss: 0.4588207358985292\n",
      "Epoch 64, Loss: 0.4574274807137762\n",
      "Epoch 65, Loss: 0.4561739649188236\n",
      "Epoch 66, Loss: 0.4550048212435235\n",
      "Epoch 67, Loss: 0.45395403690881386\n",
      "Epoch 68, Loss: 0.4530669043557498\n",
      "Epoch 69, Loss: 0.45213172832288695\n",
      "Epoch 70, Loss: 0.4511616363024182\n",
      "Epoch 71, Loss: 0.45016039135718466\n",
      "Epoch 72, Loss: 0.4492929314440442\n",
      "Epoch 73, Loss: 0.4485181071444151\n",
      "Epoch 74, Loss: 0.44771323648533784\n",
      "Epoch 75, Loss: 0.4469029484525459\n",
      "Epoch 76, Loss: 0.4460584182242495\n",
      "Epoch 77, Loss: 0.4452067299764725\n",
      "Epoch 78, Loss: 0.4443217851669624\n",
      "Epoch 79, Loss: 0.4434171798598894\n",
      "Epoch 80, Loss: 0.44247782446905276\n",
      "Epoch 81, Loss: 0.44151996734370536\n",
      "Epoch 82, Loss: 0.4405698193837597\n",
      "Epoch 83, Loss: 0.43968004937491634\n",
      "Epoch 84, Loss: 0.4387978988432848\n",
      "Epoch 85, Loss: 0.43791026225368834\n",
      "Epoch 86, Loss: 0.4370776931149075\n",
      "Epoch 87, Loss: 0.4363049465979701\n",
      "Epoch 88, Loss: 0.4356513988481171\n",
      "Epoch 89, Loss: 0.43496161856081966\n",
      "Epoch 90, Loss: 0.4339880825540167\n",
      "Epoch 91, Loss: 0.43304337977898777\n",
      "Epoch 92, Loss: 0.43251167198925006\n",
      "Epoch 93, Loss: 0.4317098018396798\n",
      "Epoch 94, Loss: 0.4307677129113525\n",
      "Epoch 95, Loss: 0.4302502155314498\n",
      "Epoch 96, Loss: 0.4296704028802925\n",
      "Epoch 97, Loss: 0.42869741640079906\n",
      "Epoch 98, Loss: 0.42806805698365247\n",
      "Epoch 99, Loss: 0.42765556550032136\n",
      "Epoch 100, Loss: 0.4269036888267448\n",
      "Epoch 101, Loss: 0.4260719426907642\n",
      "Epoch 102, Loss: 0.4255112833315584\n",
      "Epoch 103, Loss: 0.4250662338312716\n",
      "Epoch 104, Loss: 0.42438015826521613\n",
      "Epoch 105, Loss: 0.423567168591829\n",
      "Epoch 106, Loss: 0.42288153280071494\n",
      "Epoch 107, Loss: 0.42232561770406224\n",
      "Epoch 108, Loss: 0.42180163134037396\n",
      "Epoch 109, Loss: 0.42122257081107406\n",
      "Epoch 110, Loss: 0.4204203818181967\n",
      "Epoch 111, Loss: 0.4196318223482173\n",
      "Epoch 112, Loss: 0.41899188656451253\n",
      "Epoch 113, Loss: 0.418457672225479\n",
      "Epoch 114, Loss: 0.4180029560958792\n",
      "Epoch 115, Loss: 0.4176875443014018\n",
      "Epoch 116, Loss: 0.41749397835986024\n",
      "Epoch 117, Loss: 0.4167698573442946\n",
      "Epoch 118, Loss: 0.4155911532222739\n",
      "Epoch 119, Loss: 0.41475818778976015\n",
      "Epoch 120, Loss: 0.4145318376326323\n",
      "Epoch 121, Loss: 0.41442178936713536\n",
      "Epoch 122, Loss: 0.41362224421616356\n",
      "Epoch 123, Loss: 0.41259315984860423\n",
      "Epoch 124, Loss: 0.4120064195507794\n",
      "Epoch 125, Loss: 0.41189122867015415\n",
      "Epoch 126, Loss: 0.41169336302227816\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22267915250554982\n",
      "Test R^2 score: 0.464250891931237\n",
      "Num of epochs: 127\n",
      "Epoch 1, Loss: 0.5751923073656111\n",
      "Epoch 2, Loss: 0.5735847710197876\n",
      "Epoch 3, Loss: 0.5720399535287297\n",
      "Epoch 4, Loss: 0.5705645017527151\n",
      "Epoch 5, Loss: 0.5691551850707476\n",
      "Epoch 6, Loss: 0.5678167472936637\n",
      "Epoch 7, Loss: 0.5665487702058483\n",
      "Epoch 8, Loss: 0.5653527821896877\n",
      "Epoch 9, Loss: 0.5642288977007021\n",
      "Epoch 10, Loss: 0.5631791624130029\n",
      "Epoch 11, Loss: 0.5622012881697476\n",
      "Epoch 12, Loss: 0.5612962346053799\n",
      "Epoch 13, Loss: 0.5604612703784064\n",
      "Epoch 14, Loss: 0.5596773800768338\n",
      "Epoch 15, Loss: 0.558819865098106\n",
      "Epoch 16, Loss: 0.558072440437497\n",
      "Epoch 17, Loss: 0.5574051275056466\n",
      "Epoch 18, Loss: 0.5568288919731678\n",
      "Epoch 19, Loss: 0.556471173109622\n",
      "Epoch 20, Loss: 0.5561252550556253\n",
      "Epoch 21, Loss: 0.5558455293262003\n",
      "Epoch 22, Loss: 0.5556254985279296\n",
      "Epoch 23, Loss: 0.5554610486576457\n",
      "Epoch 24, Loss: 0.5553806433570183\n",
      "Epoch 25, Loss: 0.5553010851148915\n",
      "Epoch 26, Loss: 0.5551570194667441\n",
      "Epoch 27, Loss: 0.554915582749274\n",
      "Epoch 28, Loss: 0.5545552324368921\n",
      "Epoch 29, Loss: 0.5540937281294415\n",
      "Epoch 30, Loss: 0.5535051343485013\n",
      "Epoch 31, Loss: 0.5527472342892541\n",
      "Epoch 32, Loss: 0.5517967818010455\n",
      "Epoch 33, Loss: 0.5506568118809586\n",
      "Epoch 34, Loss: 0.5493238389254095\n",
      "Epoch 35, Loss: 0.5477682176047598\n",
      "Epoch 36, Loss: 0.5459434477073232\n",
      "Epoch 37, Loss: 0.5437550511618835\n",
      "Epoch 38, Loss: 0.5411436845175627\n",
      "Epoch 39, Loss: 0.5380728939850151\n",
      "Epoch 40, Loss: 0.5345575366655595\n",
      "Epoch 41, Loss: 0.5307155894401173\n",
      "Epoch 42, Loss: 0.526796466680711\n",
      "Epoch 43, Loss: 0.5231917929080755\n",
      "Epoch 44, Loss: 0.5205914285283898\n",
      "Epoch 45, Loss: 0.5195221290648198\n",
      "Epoch 46, Loss: 0.5184283201337326\n",
      "Epoch 47, Loss: 0.515939241079423\n",
      "Epoch 48, Loss: 0.5127726469297541\n",
      "Epoch 49, Loss: 0.5099719276836475\n",
      "Epoch 50, Loss: 0.5080074229636746\n",
      "Epoch 51, Loss: 0.5065889142425516\n",
      "Epoch 52, Loss: 0.5050260831215576\n",
      "Epoch 53, Loss: 0.5029652999565255\n",
      "Epoch 54, Loss: 0.5004392720859634\n",
      "Epoch 55, Loss: 0.4978033629858249\n",
      "Epoch 56, Loss: 0.49549610453401466\n",
      "Epoch 57, Loss: 0.49367182812975\n",
      "Epoch 58, Loss: 0.49194393489226573\n",
      "Epoch 59, Loss: 0.4899009391339612\n",
      "Epoch 60, Loss: 0.4875922109741809\n",
      "Epoch 61, Loss: 0.4854981567542289\n",
      "Epoch 62, Loss: 0.48381292894899025\n",
      "Epoch 63, Loss: 0.4823491122704917\n",
      "Epoch 64, Loss: 0.48082609766480466\n",
      "Epoch 65, Loss: 0.47911795251043693\n",
      "Epoch 66, Loss: 0.47738808895785034\n",
      "Epoch 67, Loss: 0.4758174575533367\n",
      "Epoch 68, Loss: 0.47435584184160184\n",
      "Epoch 69, Loss: 0.4728190401813719\n",
      "Epoch 70, Loss: 0.47122529061192264\n",
      "Epoch 71, Loss: 0.4697357620956263\n",
      "Epoch 72, Loss: 0.4683411563641882\n",
      "Epoch 73, Loss: 0.46688979113944673\n",
      "Epoch 74, Loss: 0.4654031481041722\n",
      "Epoch 75, Loss: 0.4640689290689891\n",
      "Epoch 76, Loss: 0.4628665129099558\n",
      "Epoch 77, Loss: 0.46161030304209905\n",
      "Epoch 78, Loss: 0.4603235552639199\n",
      "Epoch 79, Loss: 0.4591970397448407\n",
      "Epoch 80, Loss: 0.4581786855698743\n",
      "Epoch 81, Loss: 0.45710678780514163\n",
      "Epoch 82, Loss: 0.45608742573957806\n",
      "Epoch 83, Loss: 0.45518166669810717\n",
      "Epoch 84, Loss: 0.45427272401151053\n",
      "Epoch 85, Loss: 0.45336159744519944\n",
      "Epoch 86, Loss: 0.45252737557866823\n",
      "Epoch 87, Loss: 0.45167782310781324\n",
      "Epoch 88, Loss: 0.4507353351024876\n",
      "Epoch 89, Loss: 0.4498521734193011\n",
      "Epoch 90, Loss: 0.44899354348181447\n",
      "Epoch 91, Loss: 0.4481032079188952\n",
      "Epoch 92, Loss: 0.4472504659024451\n",
      "Epoch 93, Loss: 0.44628577366791977\n",
      "Epoch 94, Loss: 0.44522952260366755\n",
      "Epoch 95, Loss: 0.44426488622670324\n",
      "Epoch 96, Loss: 0.4432339595919543\n",
      "Epoch 97, Loss: 0.44216194281167803\n",
      "Epoch 98, Loss: 0.4411092113199863\n",
      "Epoch 99, Loss: 0.4399902282789351\n",
      "Epoch 100, Loss: 0.4389787105283778\n",
      "Epoch 101, Loss: 0.4378959873221636\n",
      "Epoch 102, Loss: 0.43686700055025546\n",
      "Epoch 103, Loss: 0.43585026869805515\n",
      "Epoch 104, Loss: 0.43487399345274885\n",
      "Epoch 105, Loss: 0.4339919281035299\n",
      "Epoch 106, Loss: 0.43308948715295337\n",
      "Epoch 107, Loss: 0.4321634052535802\n",
      "Epoch 108, Loss: 0.431256118675722\n",
      "Epoch 109, Loss: 0.43034238327858654\n",
      "Epoch 110, Loss: 0.429482428425534\n",
      "Epoch 111, Loss: 0.4286637855963692\n",
      "Epoch 112, Loss: 0.42785623634757736\n",
      "Epoch 113, Loss: 0.42702779370000354\n",
      "Epoch 114, Loss: 0.4261973386547177\n",
      "Epoch 115, Loss: 0.42536701385574655\n",
      "Epoch 116, Loss: 0.42453782041068266\n",
      "Epoch 117, Loss: 0.42370921985231996\n",
      "Epoch 118, Loss: 0.42287864334043446\n",
      "Epoch 119, Loss: 0.4220518165500478\n",
      "Epoch 120, Loss: 0.42125343522275704\n",
      "Epoch 121, Loss: 0.42050566790114047\n",
      "Epoch 122, Loss: 0.419727954888819\n",
      "Epoch 123, Loss: 0.4187970554900929\n",
      "Epoch 124, Loss: 0.4179117395611956\n",
      "Epoch 125, Loss: 0.4172294888457615\n",
      "Epoch 126, Loss: 0.416563971102636\n",
      "Epoch 127, Loss: 0.41579615933574327\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2193903820820259\n",
      "Test R^2 score: 0.4792786563846296\n",
      "Num of epochs: 128\n",
      "Epoch 1, Loss: 0.5696061868647706\n",
      "Epoch 2, Loss: 0.5678819309292799\n",
      "Epoch 3, Loss: 0.5663076380685267\n",
      "Epoch 4, Loss: 0.5648933198950177\n",
      "Epoch 5, Loss: 0.5636315355782807\n",
      "Epoch 6, Loss: 0.562516795013619\n",
      "Epoch 7, Loss: 0.5615378734557406\n",
      "Epoch 8, Loss: 0.5606763470885998\n",
      "Epoch 9, Loss: 0.55992637077859\n",
      "Epoch 10, Loss: 0.5592667853249823\n",
      "Epoch 11, Loss: 0.5587112196536399\n",
      "Epoch 12, Loss: 0.5582227475219067\n",
      "Epoch 13, Loss: 0.557791046456634\n",
      "Epoch 14, Loss: 0.5574335975189593\n",
      "Epoch 15, Loss: 0.5571153456887279\n",
      "Epoch 16, Loss: 0.5568467946300338\n",
      "Epoch 17, Loss: 0.5566263029698769\n",
      "Epoch 18, Loss: 0.5564507679322039\n",
      "Epoch 19, Loss: 0.5563171517632252\n",
      "Epoch 20, Loss: 0.5562237969131005\n",
      "Epoch 21, Loss: 0.5561634896545542\n",
      "Epoch 22, Loss: 0.5561321412286273\n",
      "Epoch 23, Loss: 0.5561256837692738\n",
      "Epoch 24, Loss: 0.5561307479242392\n",
      "Epoch 25, Loss: 0.5561428320442245\n",
      "Epoch 26, Loss: 0.5561548891084614\n",
      "Epoch 27, Loss: 0.5561595778961852\n",
      "Epoch 28, Loss: 0.5561510576697158\n",
      "Epoch 29, Loss: 0.5561239421180203\n",
      "Epoch 30, Loss: 0.5560757899994897\n",
      "Epoch 31, Loss: 0.5560038354075856\n",
      "Epoch 32, Loss: 0.5559029493054325\n",
      "Epoch 33, Loss: 0.5557634636813534\n",
      "Epoch 34, Loss: 0.555579207499677\n",
      "Epoch 35, Loss: 0.5553395911173652\n",
      "Epoch 36, Loss: 0.5550392271475608\n",
      "Epoch 37, Loss: 0.5546655247593245\n",
      "Epoch 38, Loss: 0.5542041122959888\n",
      "Epoch 39, Loss: 0.5536174661636647\n",
      "Epoch 40, Loss: 0.5528619841342177\n",
      "Epoch 41, Loss: 0.5519054384142982\n",
      "Epoch 42, Loss: 0.5506882284625245\n",
      "Epoch 43, Loss: 0.5491502298559023\n",
      "Epoch 44, Loss: 0.5473062177547794\n",
      "Epoch 45, Loss: 0.5450983069501165\n",
      "Epoch 46, Loss: 0.5424743157560594\n",
      "Epoch 47, Loss: 0.53942695681271\n",
      "Epoch 48, Loss: 0.5360485629119838\n",
      "Epoch 49, Loss: 0.532379940225896\n",
      "Epoch 50, Loss: 0.5286953876239334\n",
      "Epoch 51, Loss: 0.5254592283476868\n",
      "Epoch 52, Loss: 0.5235421659672405\n",
      "Epoch 53, Loss: 0.5231722543992644\n",
      "Epoch 54, Loss: 0.5223950210772887\n",
      "Epoch 55, Loss: 0.5199253337237775\n",
      "Epoch 56, Loss: 0.5165410430014947\n",
      "Epoch 57, Loss: 0.5134793635161722\n",
      "Epoch 58, Loss: 0.5113048481141932\n",
      "Epoch 59, Loss: 0.5098186479959829\n",
      "Epoch 60, Loss: 0.5084836193098208\n",
      "Epoch 61, Loss: 0.5069610206152575\n",
      "Epoch 62, Loss: 0.5051087809004662\n",
      "Epoch 63, Loss: 0.502863048101367\n",
      "Epoch 64, Loss: 0.5004362349081504\n",
      "Epoch 65, Loss: 0.49815867048163326\n",
      "Epoch 66, Loss: 0.49622217153165604\n",
      "Epoch 67, Loss: 0.4946606579725822\n",
      "Epoch 68, Loss: 0.49312831635804416\n",
      "Epoch 69, Loss: 0.49121127119109875\n",
      "Epoch 70, Loss: 0.4889201447611484\n",
      "Epoch 71, Loss: 0.4866018788714183\n",
      "Epoch 72, Loss: 0.48458253352273334\n",
      "Epoch 73, Loss: 0.4829601728652062\n",
      "Epoch 74, Loss: 0.4813691053760141\n",
      "Epoch 75, Loss: 0.47962803673994514\n",
      "Epoch 76, Loss: 0.4777510003030027\n",
      "Epoch 77, Loss: 0.47593831005265447\n",
      "Epoch 78, Loss: 0.4743695222088521\n",
      "Epoch 79, Loss: 0.47308146053423067\n",
      "Epoch 80, Loss: 0.4718034791113086\n",
      "Epoch 81, Loss: 0.47039233825908855\n",
      "Epoch 82, Loss: 0.4689870393961102\n",
      "Epoch 83, Loss: 0.46771881804010484\n",
      "Epoch 84, Loss: 0.466550434771609\n",
      "Epoch 85, Loss: 0.46535166071571576\n",
      "Epoch 86, Loss: 0.4641449749031155\n",
      "Epoch 87, Loss: 0.4630365262484959\n",
      "Epoch 88, Loss: 0.4620610622196333\n",
      "Epoch 89, Loss: 0.4611835954260202\n",
      "Epoch 90, Loss: 0.46030560516145264\n",
      "Epoch 91, Loss: 0.459436494253524\n",
      "Epoch 92, Loss: 0.4586751342512094\n",
      "Epoch 93, Loss: 0.4579888768948494\n",
      "Epoch 94, Loss: 0.45731695325392413\n",
      "Epoch 95, Loss: 0.45662637040574566\n",
      "Epoch 96, Loss: 0.45590771220257287\n",
      "Epoch 97, Loss: 0.45524153824724056\n",
      "Epoch 98, Loss: 0.45457705962236833\n",
      "Epoch 99, Loss: 0.45391144413036194\n",
      "Epoch 100, Loss: 0.45318713255470033\n",
      "Epoch 101, Loss: 0.45249614158060214\n",
      "Epoch 102, Loss: 0.45179861884693356\n",
      "Epoch 103, Loss: 0.45112216560020874\n",
      "Epoch 104, Loss: 0.45043389541794915\n",
      "Epoch 105, Loss: 0.4497541139954157\n",
      "Epoch 106, Loss: 0.4490747801575603\n",
      "Epoch 107, Loss: 0.4483891331444833\n",
      "Epoch 108, Loss: 0.4477161320817285\n",
      "Epoch 109, Loss: 0.44704880102291417\n",
      "Epoch 110, Loss: 0.4464226987997439\n",
      "Epoch 111, Loss: 0.4457914888347315\n",
      "Epoch 112, Loss: 0.44518418722166625\n",
      "Epoch 113, Loss: 0.44461858793133535\n",
      "Epoch 114, Loss: 0.44406951630302305\n",
      "Epoch 115, Loss: 0.44353424522363116\n",
      "Epoch 116, Loss: 0.4429847209816448\n",
      "Epoch 117, Loss: 0.44247708358261145\n",
      "Epoch 118, Loss: 0.4419313194178279\n",
      "Epoch 119, Loss: 0.44141214079850494\n",
      "Epoch 120, Loss: 0.4408713450235705\n",
      "Epoch 121, Loss: 0.4403501383801465\n",
      "Epoch 122, Loss: 0.43980541096034975\n",
      "Epoch 123, Loss: 0.439270778547752\n",
      "Epoch 124, Loss: 0.43874235529638184\n",
      "Epoch 125, Loss: 0.438215896167343\n",
      "Epoch 126, Loss: 0.43769396160824553\n",
      "Epoch 127, Loss: 0.43716934174572286\n",
      "Epoch 128, Loss: 0.43662912680911464\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2164413180596014\n",
      "Test R^2 score: 0.4942119418515379\n",
      "Num of epochs: 129\n",
      "Epoch 1, Loss: 0.5685869004019666\n",
      "Epoch 2, Loss: 0.5672164909583035\n",
      "Epoch 3, Loss: 0.5659353995744979\n",
      "Epoch 4, Loss: 0.5647455797583932\n",
      "Epoch 5, Loss: 0.5636478474466516\n",
      "Epoch 6, Loss: 0.5626419206239021\n",
      "Epoch 7, Loss: 0.5617265416906114\n",
      "Epoch 8, Loss: 0.5608993379155423\n",
      "Epoch 9, Loss: 0.5601571619087575\n",
      "Epoch 10, Loss: 0.5594958244130418\n",
      "Epoch 11, Loss: 0.5589193448907399\n",
      "Epoch 12, Loss: 0.558417072232047\n",
      "Epoch 13, Loss: 0.5579739045925473\n",
      "Epoch 14, Loss: 0.5575858940790147\n",
      "Epoch 15, Loss: 0.5572489843928314\n",
      "Epoch 16, Loss: 0.5569487137391717\n",
      "Epoch 17, Loss: 0.5566887550292746\n",
      "Epoch 18, Loss: 0.556473368897771\n",
      "Epoch 19, Loss: 0.5562882763841184\n",
      "Epoch 20, Loss: 0.5561286311666619\n",
      "Epoch 21, Loss: 0.5559889609506833\n",
      "Epoch 22, Loss: 0.5558636513047582\n",
      "Epoch 23, Loss: 0.5557469203964893\n",
      "Epoch 24, Loss: 0.5556313181583347\n",
      "Epoch 25, Loss: 0.5555123924998446\n",
      "Epoch 26, Loss: 0.5553826019828041\n",
      "Epoch 27, Loss: 0.5552359810888191\n",
      "Epoch 28, Loss: 0.5550645701762054\n",
      "Epoch 29, Loss: 0.5548623306484876\n",
      "Epoch 30, Loss: 0.5546005073351075\n",
      "Epoch 31, Loss: 0.5542617560909142\n",
      "Epoch 32, Loss: 0.553839962843941\n",
      "Epoch 33, Loss: 0.5533216881053238\n",
      "Epoch 34, Loss: 0.5527012953278388\n",
      "Epoch 35, Loss: 0.5519528474692303\n",
      "Epoch 36, Loss: 0.5510364779809163\n",
      "Epoch 37, Loss: 0.5499200784529507\n",
      "Epoch 38, Loss: 0.5485496493274352\n",
      "Epoch 39, Loss: 0.5468848363809167\n",
      "Epoch 40, Loss: 0.5449101983463478\n",
      "Epoch 41, Loss: 0.5425415004730654\n",
      "Epoch 42, Loss: 0.5397160479798389\n",
      "Epoch 43, Loss: 0.5364312624968146\n",
      "Epoch 44, Loss: 0.5327342560445348\n",
      "Epoch 45, Loss: 0.5287546287045439\n",
      "Epoch 46, Loss: 0.5248112373241459\n",
      "Epoch 47, Loss: 0.5212384047464961\n",
      "Epoch 48, Loss: 0.5180968941679934\n",
      "Epoch 49, Loss: 0.5150758535577191\n",
      "Epoch 50, Loss: 0.5115772663238692\n",
      "Epoch 51, Loss: 0.5077013921230571\n",
      "Epoch 52, Loss: 0.5042571095715777\n",
      "Epoch 53, Loss: 0.5014786314438531\n",
      "Epoch 54, Loss: 0.49916601663662846\n",
      "Epoch 55, Loss: 0.49691666662305856\n",
      "Epoch 56, Loss: 0.4940446300520132\n",
      "Epoch 57, Loss: 0.4904664087011789\n",
      "Epoch 58, Loss: 0.48678469387211776\n",
      "Epoch 59, Loss: 0.4834023061269992\n",
      "Epoch 60, Loss: 0.4798305273392467\n",
      "Epoch 61, Loss: 0.4760111918666359\n",
      "Epoch 62, Loss: 0.4730051030081315\n",
      "Epoch 63, Loss: 0.47077969763215305\n",
      "Epoch 64, Loss: 0.4690135532791789\n",
      "Epoch 65, Loss: 0.46787843740262003\n",
      "Epoch 66, Loss: 0.46719019771039455\n",
      "Epoch 67, Loss: 0.4661562685801863\n",
      "Epoch 68, Loss: 0.46493256946507716\n",
      "Epoch 69, Loss: 0.46397043785620157\n",
      "Epoch 70, Loss: 0.46356724729211984\n",
      "Epoch 71, Loss: 0.4631112775944683\n",
      "Epoch 72, Loss: 0.46204403425789964\n",
      "Epoch 73, Loss: 0.46054335084040804\n",
      "Epoch 74, Loss: 0.4593633183142313\n",
      "Epoch 75, Loss: 0.458538260668951\n",
      "Epoch 76, Loss: 0.45766981459676687\n",
      "Epoch 77, Loss: 0.45687566864131735\n",
      "Epoch 78, Loss: 0.45598430212925045\n",
      "Epoch 79, Loss: 0.4555317987215095\n",
      "Epoch 80, Loss: 0.4549943576714418\n",
      "Epoch 81, Loss: 0.45439179692448955\n",
      "Epoch 82, Loss: 0.4535724305317757\n",
      "Epoch 83, Loss: 0.4529576814792015\n",
      "Epoch 84, Loss: 0.4523500689129415\n",
      "Epoch 85, Loss: 0.4517279001930228\n",
      "Epoch 86, Loss: 0.4510048891656784\n",
      "Epoch 87, Loss: 0.4503237857502995\n",
      "Epoch 88, Loss: 0.44966529544833805\n",
      "Epoch 89, Loss: 0.44898015195693514\n",
      "Epoch 90, Loss: 0.44822192509881736\n",
      "Epoch 91, Loss: 0.44747260356133284\n",
      "Epoch 92, Loss: 0.44674962692586717\n",
      "Epoch 93, Loss: 0.4460432348026302\n",
      "Epoch 94, Loss: 0.44525442246624136\n",
      "Epoch 95, Loss: 0.44454872150647046\n",
      "Epoch 96, Loss: 0.44377716478291807\n",
      "Epoch 97, Loss: 0.443044491840344\n",
      "Epoch 98, Loss: 0.442223206416283\n",
      "Epoch 99, Loss: 0.4413841545853903\n",
      "Epoch 100, Loss: 0.4405882860674605\n",
      "Epoch 101, Loss: 0.439760448230845\n",
      "Epoch 102, Loss: 0.43892215440560683\n",
      "Epoch 103, Loss: 0.43810856591065644\n",
      "Epoch 104, Loss: 0.437310756898497\n",
      "Epoch 105, Loss: 0.4365289845636878\n",
      "Epoch 106, Loss: 0.4357089951208514\n",
      "Epoch 107, Loss: 0.4348726399646305\n",
      "Epoch 108, Loss: 0.4340632019421784\n",
      "Epoch 109, Loss: 0.4332777538633111\n",
      "Epoch 110, Loss: 0.43242675516601903\n",
      "Epoch 111, Loss: 0.43153566491117745\n",
      "Epoch 112, Loss: 0.43066824913152446\n",
      "Epoch 113, Loss: 0.4298322087149066\n",
      "Epoch 114, Loss: 0.4290214578401735\n",
      "Epoch 115, Loss: 0.42821896767849105\n",
      "Epoch 116, Loss: 0.4274367599112759\n",
      "Epoch 117, Loss: 0.42675390176268774\n",
      "Epoch 118, Loss: 0.42643804376425776\n",
      "Epoch 119, Loss: 0.426457332040903\n",
      "Epoch 120, Loss: 0.42532613035919675\n",
      "Epoch 121, Loss: 0.4235215198730767\n",
      "Epoch 122, Loss: 0.4238875738544045\n",
      "Epoch 123, Loss: 0.42282018038476493\n",
      "Epoch 124, Loss: 0.42156964306615524\n",
      "Epoch 125, Loss: 0.42181602701625\n",
      "Epoch 126, Loss: 0.42034067959961896\n",
      "Epoch 127, Loss: 0.42004529336958557\n",
      "Epoch 128, Loss: 0.41943986419502555\n",
      "Epoch 129, Loss: 0.4183688699622532\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21157141085039505\n",
      "Test R^2 score: 0.5126835020504172\n",
      "Num of epochs: 130\n",
      "Epoch 1, Loss: 0.578624046000207\n",
      "Epoch 2, Loss: 0.5761223205980834\n",
      "Epoch 3, Loss: 0.5739911984440089\n",
      "Epoch 4, Loss: 0.5719846484851864\n",
      "Epoch 5, Loss: 0.5701017382241464\n",
      "Epoch 6, Loss: 0.5683426477651552\n",
      "Epoch 7, Loss: 0.566708398666062\n",
      "Epoch 8, Loss: 0.5652046612335428\n",
      "Epoch 9, Loss: 0.5638226482584694\n",
      "Epoch 10, Loss: 0.5625578532667505\n",
      "Epoch 11, Loss: 0.5614093963254592\n",
      "Epoch 12, Loss: 0.5603766631510806\n",
      "Epoch 13, Loss: 0.559466127612894\n",
      "Epoch 14, Loss: 0.5586776670364533\n",
      "Epoch 15, Loss: 0.5580362058364883\n",
      "Epoch 16, Loss: 0.5574855615687735\n",
      "Epoch 17, Loss: 0.5570195029626481\n",
      "Epoch 18, Loss: 0.556573080683037\n",
      "Epoch 19, Loss: 0.5562145007517851\n",
      "Epoch 20, Loss: 0.5559153868387402\n",
      "Epoch 21, Loss: 0.5556618903307032\n",
      "Epoch 22, Loss: 0.5554345969472708\n",
      "Epoch 23, Loss: 0.5552112094978807\n",
      "Epoch 24, Loss: 0.554964453100117\n",
      "Epoch 25, Loss: 0.5546687217005309\n",
      "Epoch 26, Loss: 0.5542909252231852\n",
      "Epoch 27, Loss: 0.553779718880307\n",
      "Epoch 28, Loss: 0.5530838417645573\n",
      "Epoch 29, Loss: 0.5521360468140409\n",
      "Epoch 30, Loss: 0.5508509923188647\n",
      "Epoch 31, Loss: 0.5491617078176158\n",
      "Epoch 32, Loss: 0.5470122573811205\n",
      "Epoch 33, Loss: 0.5443300157217357\n",
      "Epoch 34, Loss: 0.5410995142930121\n",
      "Epoch 35, Loss: 0.5374021252523037\n",
      "Epoch 36, Loss: 0.5334276278654404\n",
      "Epoch 37, Loss: 0.5296024974483916\n",
      "Epoch 38, Loss: 0.5266577037469118\n",
      "Epoch 39, Loss: 0.5251070980551948\n",
      "Epoch 40, Loss: 0.523656457682304\n",
      "Epoch 41, Loss: 0.5206480714006678\n",
      "Epoch 42, Loss: 0.5171728886963437\n",
      "Epoch 43, Loss: 0.5142492378351612\n",
      "Epoch 44, Loss: 0.5123633772478009\n",
      "Epoch 45, Loss: 0.5109205645633046\n",
      "Epoch 46, Loss: 0.5091760082865522\n",
      "Epoch 47, Loss: 0.506895557932111\n",
      "Epoch 48, Loss: 0.5043217624045847\n",
      "Epoch 49, Loss: 0.5020011849161428\n",
      "Epoch 50, Loss: 0.5002788123965516\n",
      "Epoch 51, Loss: 0.498889823091185\n",
      "Epoch 52, Loss: 0.4971905396162971\n",
      "Epoch 53, Loss: 0.49516071978423726\n",
      "Epoch 54, Loss: 0.4932915551091261\n",
      "Epoch 55, Loss: 0.4918110785580725\n",
      "Epoch 56, Loss: 0.4903925454352945\n",
      "Epoch 57, Loss: 0.4887532203841396\n",
      "Epoch 58, Loss: 0.4869937248569835\n",
      "Epoch 59, Loss: 0.485411243108267\n",
      "Epoch 60, Loss: 0.4840454395555754\n",
      "Epoch 61, Loss: 0.48260628885941154\n",
      "Epoch 62, Loss: 0.4810680280687219\n",
      "Epoch 63, Loss: 0.479703200266614\n",
      "Epoch 64, Loss: 0.47842353401754834\n",
      "Epoch 65, Loss: 0.4769678736850297\n",
      "Epoch 66, Loss: 0.4753960890444191\n",
      "Epoch 67, Loss: 0.473969393031716\n",
      "Epoch 68, Loss: 0.47260821705288286\n",
      "Epoch 69, Loss: 0.47109073492448617\n",
      "Epoch 70, Loss: 0.46962968616416867\n",
      "Epoch 71, Loss: 0.46837763301332236\n",
      "Epoch 72, Loss: 0.4670797951088162\n",
      "Epoch 73, Loss: 0.4656544836041657\n",
      "Epoch 74, Loss: 0.46438442906065136\n",
      "Epoch 75, Loss: 0.46323618484726653\n",
      "Epoch 76, Loss: 0.4619893825165565\n",
      "Epoch 77, Loss: 0.46076452921490935\n",
      "Epoch 78, Loss: 0.459655093095187\n",
      "Epoch 79, Loss: 0.4584942574916221\n",
      "Epoch 80, Loss: 0.4573422702287064\n",
      "Epoch 81, Loss: 0.45629632988945423\n",
      "Epoch 82, Loss: 0.45529037241162507\n",
      "Epoch 83, Loss: 0.4543654300726089\n",
      "Epoch 84, Loss: 0.45350234992208094\n",
      "Epoch 85, Loss: 0.45269375043654325\n",
      "Epoch 86, Loss: 0.45199453812016716\n",
      "Epoch 87, Loss: 0.4512881339753811\n",
      "Epoch 88, Loss: 0.45061103013456655\n",
      "Epoch 89, Loss: 0.44997885707353175\n",
      "Epoch 90, Loss: 0.44934673973854156\n",
      "Epoch 91, Loss: 0.4487311328970194\n",
      "Epoch 92, Loss: 0.4480681237234865\n",
      "Epoch 93, Loss: 0.44744358104010934\n",
      "Epoch 94, Loss: 0.44681909918437357\n",
      "Epoch 95, Loss: 0.44619661538115524\n",
      "Epoch 96, Loss: 0.44551359621915293\n",
      "Epoch 97, Loss: 0.4447621910489324\n",
      "Epoch 98, Loss: 0.4439823462449817\n",
      "Epoch 99, Loss: 0.44318003115038057\n",
      "Epoch 100, Loss: 0.44235284969088456\n",
      "Epoch 101, Loss: 0.44150913356090404\n",
      "Epoch 102, Loss: 0.44072632199569034\n",
      "Epoch 103, Loss: 0.43995541159705587\n",
      "Epoch 104, Loss: 0.4392489997654807\n",
      "Epoch 105, Loss: 0.4384989573445642\n",
      "Epoch 106, Loss: 0.43770599624552137\n",
      "Epoch 107, Loss: 0.43685756926902014\n",
      "Epoch 108, Loss: 0.4360029116815496\n",
      "Epoch 109, Loss: 0.43513161060426087\n",
      "Epoch 110, Loss: 0.43423551886026523\n",
      "Epoch 111, Loss: 0.4333978330617423\n",
      "Epoch 112, Loss: 0.4325962276849363\n",
      "Epoch 113, Loss: 0.4317983106268699\n",
      "Epoch 114, Loss: 0.4309959084621949\n",
      "Epoch 115, Loss: 0.4302090167608983\n",
      "Epoch 116, Loss: 0.429438171875869\n",
      "Epoch 117, Loss: 0.4286616998781985\n",
      "Epoch 118, Loss: 0.4278769233798573\n",
      "Epoch 119, Loss: 0.4271042070482587\n",
      "Epoch 120, Loss: 0.4263333232465558\n",
      "Epoch 121, Loss: 0.42556885137481004\n",
      "Epoch 122, Loss: 0.42483448494071313\n",
      "Epoch 123, Loss: 0.4241175564226012\n",
      "Epoch 124, Loss: 0.4233888379953327\n",
      "Epoch 125, Loss: 0.42265329271787366\n",
      "Epoch 126, Loss: 0.42193820268009957\n",
      "Epoch 127, Loss: 0.4213680470950199\n",
      "Epoch 128, Loss: 0.4210843164806312\n",
      "Epoch 129, Loss: 0.42038376710944936\n",
      "Epoch 130, Loss: 0.4191222984097198\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22041978702735585\n",
      "Test R^2 score: 0.47174046832909444\n",
      "Num of epochs: 131\n",
      "Epoch 1, Loss: 0.56445370578406\n",
      "Epoch 2, Loss: 0.5632397502791145\n",
      "Epoch 3, Loss: 0.562152940918829\n",
      "Epoch 4, Loss: 0.5612975619921194\n",
      "Epoch 5, Loss: 0.5604969228358878\n",
      "Epoch 6, Loss: 0.5597319311315382\n",
      "Epoch 7, Loss: 0.5590339473386554\n",
      "Epoch 8, Loss: 0.5584083996551584\n",
      "Epoch 9, Loss: 0.5578581494797982\n",
      "Epoch 10, Loss: 0.5573851842640644\n",
      "Epoch 11, Loss: 0.5569919481363229\n",
      "Epoch 12, Loss: 0.5567006129014602\n",
      "Epoch 13, Loss: 0.5564703697703295\n",
      "Epoch 14, Loss: 0.5563072410877499\n",
      "Epoch 15, Loss: 0.5562044542932592\n",
      "Epoch 16, Loss: 0.5561480835976679\n",
      "Epoch 17, Loss: 0.5561249335201719\n",
      "Epoch 18, Loss: 0.5561286043722106\n",
      "Epoch 19, Loss: 0.5561444396678922\n",
      "Epoch 20, Loss: 0.5561905496952847\n",
      "Epoch 21, Loss: 0.5561654187307435\n",
      "Epoch 22, Loss: 0.5561380091453386\n",
      "Epoch 23, Loss: 0.5561041940907184\n",
      "Epoch 24, Loss: 0.5560448922037172\n",
      "Epoch 25, Loss: 0.555958728395703\n",
      "Epoch 26, Loss: 0.5558457169828518\n",
      "Epoch 27, Loss: 0.5557067801040109\n",
      "Epoch 28, Loss: 0.5555425688762182\n",
      "Epoch 29, Loss: 0.5553513168052145\n",
      "Epoch 30, Loss: 0.5551273589879717\n",
      "Epoch 31, Loss: 0.5548708975189753\n",
      "Epoch 32, Loss: 0.554575169969182\n",
      "Epoch 33, Loss: 0.5542259445132136\n",
      "Epoch 34, Loss: 0.5538095053482154\n",
      "Epoch 35, Loss: 0.5533102156461491\n",
      "Epoch 36, Loss: 0.5527127804261524\n",
      "Epoch 37, Loss: 0.5519914790580813\n",
      "Epoch 38, Loss: 0.5511001853902412\n",
      "Epoch 39, Loss: 0.5499988436686758\n",
      "Epoch 40, Loss: 0.5486635388970401\n",
      "Epoch 41, Loss: 0.5470537438517222\n",
      "Epoch 42, Loss: 0.5450999744831668\n",
      "Epoch 43, Loss: 0.5427244720939295\n",
      "Epoch 44, Loss: 0.539875909534703\n",
      "Epoch 45, Loss: 0.5365548340255908\n",
      "Epoch 46, Loss: 0.5327105919714606\n",
      "Epoch 47, Loss: 0.528237186457013\n",
      "Epoch 48, Loss: 0.5230242393102658\n",
      "Epoch 49, Loss: 0.5169724861659822\n",
      "Epoch 50, Loss: 0.5102013373787705\n",
      "Epoch 51, Loss: 0.5031533049683291\n",
      "Epoch 52, Loss: 0.4967066215625587\n",
      "Epoch 53, Loss: 0.4921954472218092\n",
      "Epoch 54, Loss: 0.4899302447307756\n",
      "Epoch 55, Loss: 0.4884735796752301\n",
      "Epoch 56, Loss: 0.48747250528317876\n",
      "Epoch 57, Loss: 0.48621337946403215\n",
      "Epoch 58, Loss: 0.4844016098588705\n",
      "Epoch 59, Loss: 0.4824533182005346\n",
      "Epoch 60, Loss: 0.480924467736862\n",
      "Epoch 61, Loss: 0.480020593186538\n",
      "Epoch 62, Loss: 0.47956985807944935\n",
      "Epoch 63, Loss: 0.4790676591698634\n",
      "Epoch 64, Loss: 0.4783185124704145\n",
      "Epoch 65, Loss: 0.47708298448552644\n",
      "Epoch 66, Loss: 0.4754470214993562\n",
      "Epoch 67, Loss: 0.47367699800439295\n",
      "Epoch 68, Loss: 0.47212425747571374\n",
      "Epoch 69, Loss: 0.47095911496583065\n",
      "Epoch 70, Loss: 0.4701060390061799\n",
      "Epoch 71, Loss: 0.46934716016390415\n",
      "Epoch 72, Loss: 0.4685514506410689\n",
      "Epoch 73, Loss: 0.46760428601651005\n",
      "Epoch 74, Loss: 0.4665334748465425\n",
      "Epoch 75, Loss: 0.46551119546508496\n",
      "Epoch 76, Loss: 0.4647308501011895\n",
      "Epoch 77, Loss: 0.4640751583286717\n",
      "Epoch 78, Loss: 0.4634004513522252\n",
      "Epoch 79, Loss: 0.46262321312988824\n",
      "Epoch 80, Loss: 0.4617911854836993\n",
      "Epoch 81, Loss: 0.4610456566078453\n",
      "Epoch 82, Loss: 0.4604278915498407\n",
      "Epoch 83, Loss: 0.4598960101716626\n",
      "Epoch 84, Loss: 0.459313797928537\n",
      "Epoch 85, Loss: 0.45861163323803533\n",
      "Epoch 86, Loss: 0.45785391363108663\n",
      "Epoch 87, Loss: 0.4571647938000297\n",
      "Epoch 88, Loss: 0.4565523687200748\n",
      "Epoch 89, Loss: 0.4559625373225188\n",
      "Epoch 90, Loss: 0.4553449118865559\n",
      "Epoch 91, Loss: 0.45466303415446163\n",
      "Epoch 92, Loss: 0.4539730095150468\n",
      "Epoch 93, Loss: 0.45333686348064206\n",
      "Epoch 94, Loss: 0.4527099945112783\n",
      "Epoch 95, Loss: 0.452059627898818\n",
      "Epoch 96, Loss: 0.45140338919245715\n",
      "Epoch 97, Loss: 0.4507654183977788\n",
      "Epoch 98, Loss: 0.4501848198915372\n",
      "Epoch 99, Loss: 0.44958844107141377\n",
      "Epoch 100, Loss: 0.44894737671347934\n",
      "Epoch 101, Loss: 0.4482734187264157\n",
      "Epoch 102, Loss: 0.44762449567990625\n",
      "Epoch 103, Loss: 0.4470065836816289\n",
      "Epoch 104, Loss: 0.44638688165281565\n",
      "Epoch 105, Loss: 0.445752144340368\n",
      "Epoch 106, Loss: 0.4451111120635422\n",
      "Epoch 107, Loss: 0.44447922963703007\n",
      "Epoch 108, Loss: 0.4438381382894233\n",
      "Epoch 109, Loss: 0.4431781146199304\n",
      "Epoch 110, Loss: 0.44249818152253373\n",
      "Epoch 111, Loss: 0.4417953464201666\n",
      "Epoch 112, Loss: 0.4410540939866275\n",
      "Epoch 113, Loss: 0.44027690394315167\n",
      "Epoch 114, Loss: 0.43949172804081765\n",
      "Epoch 115, Loss: 0.43868274556360903\n",
      "Epoch 116, Loss: 0.4378793638416477\n",
      "Epoch 117, Loss: 0.43708067621648317\n",
      "Epoch 118, Loss: 0.43626998951210677\n",
      "Epoch 119, Loss: 0.4354998644446459\n",
      "Epoch 120, Loss: 0.43487637489630016\n",
      "Epoch 121, Loss: 0.4345797591307785\n",
      "Epoch 122, Loss: 0.4338858196378876\n",
      "Epoch 123, Loss: 0.4325549078689701\n",
      "Epoch 124, Loss: 0.43184353301133027\n",
      "Epoch 125, Loss: 0.4315847472879529\n",
      "Epoch 126, Loss: 0.43045826187787994\n",
      "Epoch 127, Loss: 0.4295292996570079\n",
      "Epoch 128, Loss: 0.42923209592819533\n",
      "Epoch 129, Loss: 0.42836554654156295\n",
      "Epoch 130, Loss: 0.4274027858592909\n",
      "Epoch 131, Loss: 0.4270552901233449\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21840491991253416\n",
      "Test R^2 score: 0.48382463002578674\n",
      "Num of epochs: 132\n",
      "Epoch 1, Loss: 0.571769290805468\n",
      "Epoch 2, Loss: 0.5701271696611875\n",
      "Epoch 3, Loss: 0.5685880273172998\n",
      "Epoch 4, Loss: 0.567157326308172\n",
      "Epoch 5, Loss: 0.5658725723608891\n",
      "Epoch 6, Loss: 0.5646995877532778\n",
      "Epoch 7, Loss: 0.5636166244784694\n",
      "Epoch 8, Loss: 0.5626312473613877\n",
      "Epoch 9, Loss: 0.5617336244696162\n",
      "Epoch 10, Loss: 0.5609180670217148\n",
      "Epoch 11, Loss: 0.5601804113564136\n",
      "Epoch 12, Loss: 0.5595145472356083\n",
      "Epoch 13, Loss: 0.5589260899981839\n",
      "Epoch 14, Loss: 0.5584070120303568\n",
      "Epoch 15, Loss: 0.5579524059780825\n",
      "Epoch 16, Loss: 0.5575541980126617\n",
      "Epoch 17, Loss: 0.5572121881395242\n",
      "Epoch 18, Loss: 0.5569215032424673\n",
      "Epoch 19, Loss: 0.5566818489737811\n",
      "Epoch 20, Loss: 0.5564826071798277\n",
      "Epoch 21, Loss: 0.5563327406306202\n",
      "Epoch 22, Loss: 0.5562099463797386\n",
      "Epoch 23, Loss: 0.5561146174923801\n",
      "Epoch 24, Loss: 0.5560412475976929\n",
      "Epoch 25, Loss: 0.5559836274899336\n",
      "Epoch 26, Loss: 0.5559353828068216\n",
      "Epoch 27, Loss: 0.5558896805094482\n",
      "Epoch 28, Loss: 0.5558399800222988\n",
      "Epoch 29, Loss: 0.5557797115498748\n",
      "Epoch 30, Loss: 0.5557019266056357\n",
      "Epoch 31, Loss: 0.5555998592460295\n",
      "Epoch 32, Loss: 0.5554642946732583\n",
      "Epoch 33, Loss: 0.5552873725766109\n",
      "Epoch 34, Loss: 0.555058986218437\n",
      "Epoch 35, Loss: 0.5547704231711176\n",
      "Epoch 36, Loss: 0.5544195736982257\n",
      "Epoch 37, Loss: 0.5539976316325659\n",
      "Epoch 38, Loss: 0.5535044613118244\n",
      "Epoch 39, Loss: 0.552918123901141\n",
      "Epoch 40, Loss: 0.5521878617376709\n",
      "Epoch 41, Loss: 0.5512488254006949\n",
      "Epoch 42, Loss: 0.5500670327172229\n",
      "Epoch 43, Loss: 0.5486296433995195\n",
      "Epoch 44, Loss: 0.5469072332419682\n",
      "Epoch 45, Loss: 0.5448539445435855\n",
      "Epoch 46, Loss: 0.5423686326851687\n",
      "Epoch 47, Loss: 0.5393550465982924\n",
      "Epoch 48, Loss: 0.5358093063916088\n",
      "Epoch 49, Loss: 0.5317307989261357\n",
      "Epoch 50, Loss: 0.5271905747229565\n",
      "Epoch 51, Loss: 0.522482299367976\n",
      "Epoch 52, Loss: 0.5183965294522361\n",
      "Epoch 53, Loss: 0.5164279754270044\n",
      "Epoch 54, Loss: 0.5170695559346329\n",
      "Epoch 55, Loss: 0.5164499042198084\n",
      "Epoch 56, Loss: 0.5129151082060395\n",
      "Epoch 57, Loss: 0.5084564527602746\n",
      "Epoch 58, Loss: 0.5049723208273024\n",
      "Epoch 59, Loss: 0.5029275245990354\n",
      "Epoch 60, Loss: 0.5016674015234109\n",
      "Epoch 61, Loss: 0.5002704723273557\n",
      "Epoch 62, Loss: 0.4983084795674948\n",
      "Epoch 63, Loss: 0.4957506991163625\n",
      "Epoch 64, Loss: 0.49275854075349296\n",
      "Epoch 65, Loss: 0.48976879124326106\n",
      "Epoch 66, Loss: 0.4872942600395971\n",
      "Epoch 67, Loss: 0.4855202548646894\n",
      "Epoch 68, Loss: 0.48391249325315017\n",
      "Epoch 69, Loss: 0.481634802988077\n",
      "Epoch 70, Loss: 0.47872032925168295\n",
      "Epoch 71, Loss: 0.47598754093750323\n",
      "Epoch 72, Loss: 0.47404663255523694\n",
      "Epoch 73, Loss: 0.47262793842361706\n",
      "Epoch 74, Loss: 0.4712208951112833\n",
      "Epoch 75, Loss: 0.4695362173315948\n",
      "Epoch 76, Loss: 0.46774299857028856\n",
      "Epoch 77, Loss: 0.46653275619203394\n",
      "Epoch 78, Loss: 0.4663351001495846\n",
      "Epoch 79, Loss: 0.4666596534179308\n",
      "Epoch 80, Loss: 0.46655247886407186\n",
      "Epoch 81, Loss: 0.4655944148521764\n",
      "Epoch 82, Loss: 0.4642077029366911\n",
      "Epoch 83, Loss: 0.46303393563897866\n",
      "Epoch 84, Loss: 0.46212312189390714\n",
      "Epoch 85, Loss: 0.4612936809708184\n",
      "Epoch 86, Loss: 0.460465496661418\n",
      "Epoch 87, Loss: 0.45973428377916103\n",
      "Epoch 88, Loss: 0.4590767625393993\n",
      "Epoch 89, Loss: 0.45840586464077937\n",
      "Epoch 90, Loss: 0.4576369941908894\n",
      "Epoch 91, Loss: 0.45676412682592105\n",
      "Epoch 92, Loss: 0.45586600474527306\n",
      "Epoch 93, Loss: 0.45504934195330604\n",
      "Epoch 94, Loss: 0.45428007165299783\n",
      "Epoch 95, Loss: 0.4535385579464229\n",
      "Epoch 96, Loss: 0.4528856467433539\n",
      "Epoch 97, Loss: 0.45230828048974975\n",
      "Epoch 98, Loss: 0.45174526752976024\n",
      "Epoch 99, Loss: 0.451190320583309\n",
      "Epoch 100, Loss: 0.4505953883257638\n",
      "Epoch 101, Loss: 0.44992984383797896\n",
      "Epoch 102, Loss: 0.4492697811165981\n",
      "Epoch 103, Loss: 0.44867683563333044\n",
      "Epoch 104, Loss: 0.4480927328306636\n",
      "Epoch 105, Loss: 0.4475339559373759\n",
      "Epoch 106, Loss: 0.44699324930670487\n",
      "Epoch 107, Loss: 0.4464453125267019\n",
      "Epoch 108, Loss: 0.4458701674079431\n",
      "Epoch 109, Loss: 0.44527845085207135\n",
      "Epoch 110, Loss: 0.4446654889737185\n",
      "Epoch 111, Loss: 0.44406228494336947\n",
      "Epoch 112, Loss: 0.44348974453767664\n",
      "Epoch 113, Loss: 0.4429209553871885\n",
      "Epoch 114, Loss: 0.44236300594629996\n",
      "Epoch 115, Loss: 0.4418108275998801\n",
      "Epoch 116, Loss: 0.4412610650768946\n",
      "Epoch 117, Loss: 0.44071010958028184\n",
      "Epoch 118, Loss: 0.4401798597022377\n",
      "Epoch 119, Loss: 0.4396697464146504\n",
      "Epoch 120, Loss: 0.4391465367976439\n",
      "Epoch 121, Loss: 0.43860789076103596\n",
      "Epoch 122, Loss: 0.43805194847035855\n",
      "Epoch 123, Loss: 0.4375026225965095\n",
      "Epoch 124, Loss: 0.4369531176611581\n",
      "Epoch 125, Loss: 0.43641152536800576\n",
      "Epoch 126, Loss: 0.4358526106188311\n",
      "Epoch 127, Loss: 0.4352952204476724\n",
      "Epoch 128, Loss: 0.434730740198989\n",
      "Epoch 129, Loss: 0.43417386605791264\n",
      "Epoch 130, Loss: 0.43361473032737274\n",
      "Epoch 131, Loss: 0.4330421065952828\n",
      "Epoch 132, Loss: 0.432471618961477\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21107402667462122\n",
      "Test R^2 score: 0.5181814430517355\n",
      "Num of epochs: 133\n",
      "Epoch 1, Loss: 0.5935974176006876\n",
      "Epoch 2, Loss: 0.5903110295323343\n",
      "Epoch 3, Loss: 0.5872829249275976\n",
      "Epoch 4, Loss: 0.5844057789005065\n",
      "Epoch 5, Loss: 0.5816598001346246\n",
      "Epoch 6, Loss: 0.579044744525075\n",
      "Epoch 7, Loss: 0.5765585684706874\n",
      "Epoch 8, Loss: 0.5742104977384541\n",
      "Epoch 9, Loss: 0.5720037440480895\n",
      "Epoch 10, Loss: 0.5699395567234301\n",
      "Epoch 11, Loss: 0.5681433250652853\n",
      "Epoch 12, Loss: 0.5665134986100836\n",
      "Epoch 13, Loss: 0.5650018842631965\n",
      "Epoch 14, Loss: 0.5636078203992106\n",
      "Epoch 15, Loss: 0.5623658603095951\n",
      "Epoch 16, Loss: 0.5612425790053996\n",
      "Epoch 17, Loss: 0.560231056698276\n",
      "Epoch 18, Loss: 0.5593309939246118\n",
      "Epoch 19, Loss: 0.5585415955851404\n",
      "Epoch 20, Loss: 0.557862129461268\n",
      "Epoch 21, Loss: 0.557290270319345\n",
      "Epoch 22, Loss: 0.5568201946600803\n",
      "Epoch 23, Loss: 0.5564508750479498\n",
      "Epoch 24, Loss: 0.5561742066598258\n",
      "Epoch 25, Loss: 0.5560510826194973\n",
      "Epoch 26, Loss: 0.5559365621712179\n",
      "Epoch 27, Loss: 0.5558611046126821\n",
      "Epoch 28, Loss: 0.555810892184922\n",
      "Epoch 29, Loss: 0.555773947096433\n",
      "Epoch 30, Loss: 0.5557391982408063\n",
      "Epoch 31, Loss: 0.5556945792401444\n",
      "Epoch 32, Loss: 0.5556279390255207\n",
      "Epoch 33, Loss: 0.5555275211280969\n",
      "Epoch 34, Loss: 0.5553859289477596\n",
      "Epoch 35, Loss: 0.5552001518329006\n",
      "Epoch 36, Loss: 0.554965634527848\n",
      "Epoch 37, Loss: 0.5546758408731479\n",
      "Epoch 38, Loss: 0.5543183992600778\n",
      "Epoch 39, Loss: 0.553864176972231\n",
      "Epoch 40, Loss: 0.5533172445754164\n",
      "Epoch 41, Loss: 0.5526367748346079\n",
      "Epoch 42, Loss: 0.5517732331138114\n",
      "Epoch 43, Loss: 0.5507094424357962\n",
      "Epoch 44, Loss: 0.5493979160446371\n",
      "Epoch 45, Loss: 0.5477926185164211\n",
      "Epoch 46, Loss: 0.5458557439770393\n",
      "Epoch 47, Loss: 0.5435469588108236\n",
      "Epoch 48, Loss: 0.5408584972497347\n",
      "Epoch 49, Loss: 0.537750000810468\n",
      "Epoch 50, Loss: 0.5341651537938745\n",
      "Epoch 51, Loss: 0.5300795339342141\n",
      "Epoch 52, Loss: 0.525425877859683\n",
      "Epoch 53, Loss: 0.5200459218380515\n",
      "Epoch 54, Loss: 0.5137529200450026\n",
      "Epoch 55, Loss: 0.5065056049605426\n",
      "Epoch 56, Loss: 0.4984712774616702\n",
      "Epoch 57, Loss: 0.4903202057738019\n",
      "Epoch 58, Loss: 0.48354602448804695\n",
      "Epoch 59, Loss: 0.4802925593171316\n",
      "Epoch 60, Loss: 0.48164065036943776\n",
      "Epoch 61, Loss: 0.4832458717724404\n",
      "Epoch 62, Loss: 0.48151527190524296\n",
      "Epoch 63, Loss: 0.4783493220113848\n",
      "Epoch 64, Loss: 0.4776542696227005\n",
      "Epoch 65, Loss: 0.4751889179393721\n",
      "Epoch 66, Loss: 0.4714839205230065\n",
      "Epoch 67, Loss: 0.4699744286327581\n",
      "Epoch 68, Loss: 0.4701377195368464\n",
      "Epoch 69, Loss: 0.4701928661435231\n",
      "Epoch 70, Loss: 0.4696499609396996\n",
      "Epoch 71, Loss: 0.46895108678171005\n",
      "Epoch 72, Loss: 0.4685092466708011\n",
      "Epoch 73, Loss: 0.4681635366857804\n",
      "Epoch 74, Loss: 0.46744285162800003\n",
      "Epoch 75, Loss: 0.4661962563576737\n",
      "Epoch 76, Loss: 0.46484532075504376\n",
      "Epoch 77, Loss: 0.4638685366962287\n",
      "Epoch 78, Loss: 0.4633152619560908\n",
      "Epoch 79, Loss: 0.4628360088335391\n",
      "Epoch 80, Loss: 0.4621708259128258\n",
      "Epoch 81, Loss: 0.4615209572136574\n",
      "Epoch 82, Loss: 0.4610646121088015\n",
      "Epoch 83, Loss: 0.4605329969287186\n",
      "Epoch 84, Loss: 0.4595350979122141\n",
      "Epoch 85, Loss: 0.45845080264709054\n",
      "Epoch 86, Loss: 0.45779405823626806\n",
      "Epoch 87, Loss: 0.4572135692055485\n",
      "Epoch 88, Loss: 0.45646242461408787\n",
      "Epoch 89, Loss: 0.4557491806721816\n",
      "Epoch 90, Loss: 0.4551408094202572\n",
      "Epoch 91, Loss: 0.4543983392086539\n",
      "Epoch 92, Loss: 0.45360639913900175\n",
      "Epoch 93, Loss: 0.45296335625702183\n",
      "Epoch 94, Loss: 0.4522863552596354\n",
      "Epoch 95, Loss: 0.45155064260365047\n",
      "Epoch 96, Loss: 0.4509168952998184\n",
      "Epoch 97, Loss: 0.4504266835291926\n",
      "Epoch 98, Loss: 0.4498435278226483\n",
      "Epoch 99, Loss: 0.44925057671626145\n",
      "Epoch 100, Loss: 0.44874755361947455\n",
      "Epoch 101, Loss: 0.4481573918073151\n",
      "Epoch 102, Loss: 0.44756077518884557\n",
      "Epoch 103, Loss: 0.44707533274007155\n",
      "Epoch 104, Loss: 0.44652849782025766\n",
      "Epoch 105, Loss: 0.4459859707800479\n",
      "Epoch 106, Loss: 0.4454501591780097\n",
      "Epoch 107, Loss: 0.4448791536982416\n",
      "Epoch 108, Loss: 0.4443700923997426\n",
      "Epoch 109, Loss: 0.44384943559917334\n",
      "Epoch 110, Loss: 0.44334300678976296\n",
      "Epoch 111, Loss: 0.4428350902924998\n",
      "Epoch 112, Loss: 0.44228614609924044\n",
      "Epoch 113, Loss: 0.4417654280934138\n",
      "Epoch 114, Loss: 0.4412222115679223\n",
      "Epoch 115, Loss: 0.4407490082327708\n",
      "Epoch 116, Loss: 0.44026123344044465\n",
      "Epoch 117, Loss: 0.43976898709826656\n",
      "Epoch 118, Loss: 0.43927099904392014\n",
      "Epoch 119, Loss: 0.4387740079989719\n",
      "Epoch 120, Loss: 0.4383163329310018\n",
      "Epoch 121, Loss: 0.43782862174107123\n",
      "Epoch 122, Loss: 0.4373172650864729\n",
      "Epoch 123, Loss: 0.43682107016796007\n",
      "Epoch 124, Loss: 0.4363300483954921\n",
      "Epoch 125, Loss: 0.43585678159985275\n",
      "Epoch 126, Loss: 0.4353710897523629\n",
      "Epoch 127, Loss: 0.43484604906522295\n",
      "Epoch 128, Loss: 0.4343243535107207\n",
      "Epoch 129, Loss: 0.4338307806751559\n",
      "Epoch 130, Loss: 0.4333553517995409\n",
      "Epoch 131, Loss: 0.4328565258398744\n",
      "Epoch 132, Loss: 0.4323267769247765\n",
      "Epoch 133, Loss: 0.4318119244259018\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21532558730837975\n",
      "Test R^2 score: 0.4981779950569151\n",
      "Num of epochs: 134\n",
      "Epoch 1, Loss: 0.5582944962056177\n",
      "Epoch 2, Loss: 0.5578230763348982\n",
      "Epoch 3, Loss: 0.5574148582653097\n",
      "Epoch 4, Loss: 0.5570694459550384\n",
      "Epoch 5, Loss: 0.5567857519660293\n",
      "Epoch 6, Loss: 0.5565664944727621\n",
      "Epoch 7, Loss: 0.5564009300948157\n",
      "Epoch 8, Loss: 0.5562855173408772\n",
      "Epoch 9, Loss: 0.5562142596389058\n",
      "Epoch 10, Loss: 0.5561793507490053\n",
      "Epoch 11, Loss: 0.55617417986757\n",
      "Epoch 12, Loss: 0.5561904425294033\n",
      "Epoch 13, Loss: 0.5562200731092094\n",
      "Epoch 14, Loss: 0.5562547383481636\n",
      "Epoch 15, Loss: 0.5562873924202979\n",
      "Epoch 16, Loss: 0.5563128125162321\n",
      "Epoch 17, Loss: 0.5563279997326346\n",
      "Epoch 18, Loss: 0.5563308121346192\n",
      "Epoch 19, Loss: 0.5563217320427771\n",
      "Epoch 20, Loss: 0.5563033571262335\n",
      "Epoch 21, Loss: 0.556277615151017\n",
      "Epoch 22, Loss: 0.5562471303972955\n",
      "Epoch 23, Loss: 0.5562143935905184\n",
      "Epoch 24, Loss: 0.5561816548568554\n",
      "Epoch 25, Loss: 0.5561508433227126\n",
      "Epoch 26, Loss: 0.556123352634822\n",
      "Epoch 27, Loss: 0.5560997192028141\n",
      "Epoch 28, Loss: 0.5560790056298143\n",
      "Epoch 29, Loss: 0.5560602743218527\n",
      "Epoch 30, Loss: 0.5560423463417302\n",
      "Epoch 31, Loss: 0.5560233190040876\n",
      "Epoch 32, Loss: 0.5560011821552443\n",
      "Epoch 33, Loss: 0.5559729068110335\n",
      "Epoch 34, Loss: 0.5559353291992897\n",
      "Epoch 35, Loss: 0.5558857400181312\n",
      "Epoch 36, Loss: 0.5558217232257512\n",
      "Epoch 37, Loss: 0.5557396004390636\n",
      "Epoch 38, Loss: 0.5556347509071352\n",
      "Epoch 39, Loss: 0.555501609077149\n",
      "Epoch 40, Loss: 0.5553343319183628\n",
      "Epoch 41, Loss: 0.5551287011253154\n",
      "Epoch 42, Loss: 0.5548894272879604\n",
      "Epoch 43, Loss: 0.5546129203411166\n",
      "Epoch 44, Loss: 0.5542658963192953\n",
      "Epoch 45, Loss: 0.5538195952518568\n",
      "Epoch 46, Loss: 0.5532363660953616\n",
      "Epoch 47, Loss: 0.5524668231341227\n",
      "Epoch 48, Loss: 0.5514480666629341\n",
      "Epoch 49, Loss: 0.5501102662092947\n",
      "Epoch 50, Loss: 0.5483819362826906\n",
      "Epoch 51, Loss: 0.5462302085206667\n",
      "Epoch 52, Loss: 0.5436125307492888\n",
      "Epoch 53, Loss: 0.5405978025089018\n",
      "Epoch 54, Loss: 0.5371714885515767\n",
      "Epoch 55, Loss: 0.533193511317293\n",
      "Epoch 56, Loss: 0.5286140964797051\n",
      "Epoch 57, Loss: 0.5236880144207107\n",
      "Epoch 58, Loss: 0.5190633229726277\n",
      "Epoch 59, Loss: 0.5157437332316226\n",
      "Epoch 60, Loss: 0.5143987639952949\n",
      "Epoch 61, Loss: 0.5129974927933905\n",
      "Epoch 62, Loss: 0.5097109885916705\n",
      "Epoch 63, Loss: 0.5057376435260527\n",
      "Epoch 64, Loss: 0.5026416731627851\n",
      "Epoch 65, Loss: 0.500632303496579\n",
      "Epoch 66, Loss: 0.49910878685198645\n",
      "Epoch 67, Loss: 0.497228016596099\n",
      "Epoch 68, Loss: 0.494790987382389\n",
      "Epoch 69, Loss: 0.4918432697109837\n",
      "Epoch 70, Loss: 0.48875437893088797\n",
      "Epoch 71, Loss: 0.48621877337118025\n",
      "Epoch 72, Loss: 0.48458234901962394\n",
      "Epoch 73, Loss: 0.4831052873841287\n",
      "Epoch 74, Loss: 0.4808173426983367\n",
      "Epoch 75, Loss: 0.47804626489741553\n",
      "Epoch 76, Loss: 0.47546289563844896\n",
      "Epoch 77, Loss: 0.47339679303809445\n",
      "Epoch 78, Loss: 0.47143150102646375\n",
      "Epoch 79, Loss: 0.4691322198856527\n",
      "Epoch 80, Loss: 0.4664561412714907\n",
      "Epoch 81, Loss: 0.46383495018017357\n",
      "Epoch 82, Loss: 0.46171781794781536\n",
      "Epoch 83, Loss: 0.4602120558313438\n",
      "Epoch 84, Loss: 0.45932679085554456\n",
      "Epoch 85, Loss: 0.4592496551726266\n",
      "Epoch 86, Loss: 0.45925450593692974\n",
      "Epoch 87, Loss: 0.4586492248202986\n",
      "Epoch 88, Loss: 0.45795419212377586\n",
      "Epoch 89, Loss: 0.45665043672670036\n",
      "Epoch 90, Loss: 0.4552226839778731\n",
      "Epoch 91, Loss: 0.454150207539181\n",
      "Epoch 92, Loss: 0.4534611770316151\n",
      "Epoch 93, Loss: 0.4532324400496966\n",
      "Epoch 94, Loss: 0.4528374088141632\n",
      "Epoch 95, Loss: 0.4521954143335103\n",
      "Epoch 96, Loss: 0.4515848457852904\n",
      "Epoch 97, Loss: 0.45090815445338295\n",
      "Epoch 98, Loss: 0.4501478621162494\n",
      "Epoch 99, Loss: 0.4494484189929457\n",
      "Epoch 100, Loss: 0.44863340969818183\n",
      "Epoch 101, Loss: 0.4479347288201147\n",
      "Epoch 102, Loss: 0.4473394641144608\n",
      "Epoch 103, Loss: 0.44664800053649334\n",
      "Epoch 104, Loss: 0.446014503481603\n",
      "Epoch 105, Loss: 0.44539562921769027\n",
      "Epoch 106, Loss: 0.44473031117396883\n",
      "Epoch 107, Loss: 0.44412368903166577\n",
      "Epoch 108, Loss: 0.4433990662407066\n",
      "Epoch 109, Loss: 0.4427422080450162\n",
      "Epoch 110, Loss: 0.4420616044820557\n",
      "Epoch 111, Loss: 0.4414334246617315\n",
      "Epoch 112, Loss: 0.44067981324926225\n",
      "Epoch 113, Loss: 0.43993009326204324\n",
      "Epoch 114, Loss: 0.4391611103898317\n",
      "Epoch 115, Loss: 0.43842973012965963\n",
      "Epoch 116, Loss: 0.4376576514257392\n",
      "Epoch 117, Loss: 0.43694880368302164\n",
      "Epoch 118, Loss: 0.436242168705994\n",
      "Epoch 119, Loss: 0.4355080249377667\n",
      "Epoch 120, Loss: 0.43476151963975035\n",
      "Epoch 121, Loss: 0.4341027476942376\n",
      "Epoch 122, Loss: 0.4334063081856128\n",
      "Epoch 123, Loss: 0.43275304861113295\n",
      "Epoch 124, Loss: 0.43212130265092785\n",
      "Epoch 125, Loss: 0.43151475616034995\n",
      "Epoch 126, Loss: 0.43090726944171154\n",
      "Epoch 127, Loss: 0.43028649281328846\n",
      "Epoch 128, Loss: 0.42969485189910783\n",
      "Epoch 129, Loss: 0.4290828264927027\n",
      "Epoch 130, Loss: 0.42845984124518016\n",
      "Epoch 131, Loss: 0.42787701044437787\n",
      "Epoch 132, Loss: 0.42731744660877\n",
      "Epoch 133, Loss: 0.4267658782825271\n",
      "Epoch 134, Loss: 0.42623341900074924\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2169089346430771\n",
      "Test R^2 score: 0.4913626708681507\n",
      "Num of epochs: 135\n",
      "Epoch 1, Loss: 0.5654346683263053\n",
      "Epoch 2, Loss: 0.5644089836627633\n",
      "Epoch 3, Loss: 0.5634594522982391\n",
      "Epoch 4, Loss: 0.5625844203330284\n",
      "Epoch 5, Loss: 0.5617817690837834\n",
      "Epoch 6, Loss: 0.5610590864079587\n",
      "Epoch 7, Loss: 0.56039120842023\n",
      "Epoch 8, Loss: 0.559815677553311\n",
      "Epoch 9, Loss: 0.5593121317479568\n",
      "Epoch 10, Loss: 0.558844156759253\n",
      "Epoch 11, Loss: 0.5584098673314848\n",
      "Epoch 12, Loss: 0.5580283017347389\n",
      "Epoch 13, Loss: 0.5576964420575158\n",
      "Epoch 14, Loss: 0.5573937925604248\n",
      "Epoch 15, Loss: 0.557105422465322\n",
      "Epoch 16, Loss: 0.5568496846910851\n",
      "Epoch 17, Loss: 0.5566325136898734\n",
      "Epoch 18, Loss: 0.556433655927042\n",
      "Epoch 19, Loss: 0.5562524613315262\n",
      "Epoch 20, Loss: 0.5560939580665621\n",
      "Epoch 21, Loss: 0.5559559945197853\n",
      "Epoch 22, Loss: 0.5558307578681556\n",
      "Epoch 23, Loss: 0.5557095688352828\n",
      "Epoch 24, Loss: 0.5555821309753487\n",
      "Epoch 25, Loss: 0.5554413038895956\n",
      "Epoch 26, Loss: 0.5552784095995075\n",
      "Epoch 27, Loss: 0.5550825297364105\n",
      "Epoch 28, Loss: 0.5548494935228563\n",
      "Epoch 29, Loss: 0.5545656849522373\n",
      "Epoch 30, Loss: 0.5542131195341597\n",
      "Epoch 31, Loss: 0.5537732070813232\n",
      "Epoch 32, Loss: 0.5532096733327381\n",
      "Epoch 33, Loss: 0.5524886430893594\n",
      "Epoch 34, Loss: 0.5515643295387421\n",
      "Epoch 35, Loss: 0.5503715452267292\n",
      "Epoch 36, Loss: 0.5488540263189963\n",
      "Epoch 37, Loss: 0.5469500898852659\n",
      "Epoch 38, Loss: 0.5446041917588451\n",
      "Epoch 39, Loss: 0.5417571786916255\n",
      "Epoch 40, Loss: 0.5383688568887819\n",
      "Epoch 41, Loss: 0.5343612836449362\n",
      "Epoch 42, Loss: 0.5297814153723773\n",
      "Epoch 43, Loss: 0.524782956762701\n",
      "Epoch 44, Loss: 0.5198173308932904\n",
      "Epoch 45, Loss: 0.5159477610870264\n",
      "Epoch 46, Loss: 0.5148937936174309\n",
      "Epoch 47, Loss: 0.5155802331622319\n",
      "Epoch 48, Loss: 0.5138008042899787\n",
      "Epoch 49, Loss: 0.5098778027576456\n",
      "Epoch 50, Loss: 0.5060266637901136\n",
      "Epoch 51, Loss: 0.5035722497983611\n",
      "Epoch 52, Loss: 0.5023188761341684\n",
      "Epoch 53, Loss: 0.5014011598912941\n",
      "Epoch 54, Loss: 0.5001305171373349\n",
      "Epoch 55, Loss: 0.49820397087265833\n",
      "Epoch 56, Loss: 0.4956885808399746\n",
      "Epoch 57, Loss: 0.49291987652941377\n",
      "Epoch 58, Loss: 0.4903588307982413\n",
      "Epoch 59, Loss: 0.4884192920105065\n",
      "Epoch 60, Loss: 0.487066023181541\n",
      "Epoch 61, Loss: 0.4857842955151806\n",
      "Epoch 62, Loss: 0.48403440313884116\n",
      "Epoch 63, Loss: 0.48209765578117214\n",
      "Epoch 64, Loss: 0.48052824628950097\n",
      "Epoch 65, Loss: 0.47939061722563175\n",
      "Epoch 66, Loss: 0.4782111308489179\n",
      "Epoch 67, Loss: 0.47671384440660924\n",
      "Epoch 68, Loss: 0.47516408144246375\n",
      "Epoch 69, Loss: 0.4739176729248715\n",
      "Epoch 70, Loss: 0.4729840584209769\n",
      "Epoch 71, Loss: 0.4719031616043188\n",
      "Epoch 72, Loss: 0.47048677719682164\n",
      "Epoch 73, Loss: 0.46919116876300215\n",
      "Epoch 74, Loss: 0.46812072476929134\n",
      "Epoch 75, Loss: 0.4666182842747271\n",
      "Epoch 76, Loss: 0.4650134890660998\n",
      "Epoch 77, Loss: 0.4638814662944204\n",
      "Epoch 78, Loss: 0.46310986183949443\n",
      "Epoch 79, Loss: 0.4624379032564783\n",
      "Epoch 80, Loss: 0.4617638051210753\n",
      "Epoch 81, Loss: 0.46114957101204906\n",
      "Epoch 82, Loss: 0.4606344390533492\n",
      "Epoch 83, Loss: 0.459942114702026\n",
      "Epoch 84, Loss: 0.4591243287031468\n",
      "Epoch 85, Loss: 0.45837735557106934\n",
      "Epoch 86, Loss: 0.4576131100051667\n",
      "Epoch 87, Loss: 0.45687423356353307\n",
      "Epoch 88, Loss: 0.4562551151929503\n",
      "Epoch 89, Loss: 0.45564640565256337\n",
      "Epoch 90, Loss: 0.4550276797908863\n",
      "Epoch 91, Loss: 0.454487331152963\n",
      "Epoch 92, Loss: 0.4539891585828494\n",
      "Epoch 93, Loss: 0.45345079285521517\n",
      "Epoch 94, Loss: 0.4529430583182752\n",
      "Epoch 95, Loss: 0.45246110161461595\n",
      "Epoch 96, Loss: 0.4519336758898761\n",
      "Epoch 97, Loss: 0.4513793072131853\n",
      "Epoch 98, Loss: 0.4508647120808827\n",
      "Epoch 99, Loss: 0.45034132304658336\n",
      "Epoch 100, Loss: 0.4498176728534598\n",
      "Epoch 101, Loss: 0.44930976277418494\n",
      "Epoch 102, Loss: 0.44878359740571516\n",
      "Epoch 103, Loss: 0.4482724879709233\n",
      "Epoch 104, Loss: 0.4477574172553099\n",
      "Epoch 105, Loss: 0.4472361559092564\n",
      "Epoch 106, Loss: 0.4467207909317601\n",
      "Epoch 107, Loss: 0.4462150328691262\n",
      "Epoch 108, Loss: 0.44566690831057765\n",
      "Epoch 109, Loss: 0.4450986750369812\n",
      "Epoch 110, Loss: 0.4444955057210893\n",
      "Epoch 111, Loss: 0.44388198300140497\n",
      "Epoch 112, Loss: 0.4432490039185995\n",
      "Epoch 113, Loss: 0.44261616327061043\n",
      "Epoch 114, Loss: 0.4420327154939589\n",
      "Epoch 115, Loss: 0.4414419986798618\n",
      "Epoch 116, Loss: 0.4408691142613809\n",
      "Epoch 117, Loss: 0.4403003071219668\n",
      "Epoch 118, Loss: 0.43974001526787837\n",
      "Epoch 119, Loss: 0.4391749709711669\n",
      "Epoch 120, Loss: 0.438592177613487\n",
      "Epoch 121, Loss: 0.43801400099546384\n",
      "Epoch 122, Loss: 0.43739504917719807\n",
      "Epoch 123, Loss: 0.4367819069931592\n",
      "Epoch 124, Loss: 0.43616001097299895\n",
      "Epoch 125, Loss: 0.4355302816061216\n",
      "Epoch 126, Loss: 0.4349020559661416\n",
      "Epoch 127, Loss: 0.434267620151949\n",
      "Epoch 128, Loss: 0.43364029711817215\n",
      "Epoch 129, Loss: 0.43300096698282997\n",
      "Epoch 130, Loss: 0.43240047908459994\n",
      "Epoch 131, Loss: 0.4318061269669985\n",
      "Epoch 132, Loss: 0.43118408708373185\n",
      "Epoch 133, Loss: 0.43056300008996434\n",
      "Epoch 134, Loss: 0.4298998741358688\n",
      "Epoch 135, Loss: 0.42919755225785683\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2112092527202287\n",
      "Test R^2 score: 0.5147463592031389\n",
      "Num of epochs: 136\n",
      "Epoch 1, Loss: 0.5715969462414582\n",
      "Epoch 2, Loss: 0.5704073892326099\n",
      "Epoch 3, Loss: 0.5692513928201596\n",
      "Epoch 4, Loss: 0.5681313388248418\n",
      "Epoch 5, Loss: 0.5670673589911331\n",
      "Epoch 6, Loss: 0.5660506612123688\n",
      "Epoch 7, Loss: 0.5650685792842148\n",
      "Epoch 8, Loss: 0.5641214788991805\n",
      "Epoch 9, Loss: 0.5632111239860732\n",
      "Epoch 10, Loss: 0.5623486898151749\n",
      "Epoch 11, Loss: 0.5615307882076617\n",
      "Epoch 12, Loss: 0.5607586238077203\n",
      "Epoch 13, Loss: 0.5600358713956709\n",
      "Epoch 14, Loss: 0.5593665053079573\n",
      "Epoch 15, Loss: 0.5587547443709043\n",
      "Epoch 16, Loss: 0.5582036610327804\n",
      "Epoch 17, Loss: 0.5577092938087732\n",
      "Epoch 18, Loss: 0.5572776495575986\n",
      "Epoch 19, Loss: 0.5569166335738006\n",
      "Epoch 20, Loss: 0.5566245093438783\n",
      "Epoch 21, Loss: 0.5564033671912071\n",
      "Epoch 22, Loss: 0.5562504789800403\n",
      "Epoch 23, Loss: 0.5561567914213891\n",
      "Epoch 24, Loss: 0.556106257350258\n",
      "Epoch 25, Loss: 0.5560799971120804\n",
      "Epoch 26, Loss: 0.5560596579733861\n",
      "Epoch 27, Loss: 0.5560351374692919\n",
      "Epoch 28, Loss: 0.5560034602009525\n",
      "Epoch 29, Loss: 0.5559458093735181\n",
      "Epoch 30, Loss: 0.5558507300728021\n",
      "Epoch 31, Loss: 0.5557106146059017\n",
      "Epoch 32, Loss: 0.5555019577980735\n",
      "Epoch 33, Loss: 0.5552134639462377\n",
      "Epoch 34, Loss: 0.5548270144096552\n",
      "Epoch 35, Loss: 0.5543195820647508\n",
      "Epoch 36, Loss: 0.5536976430867928\n",
      "Epoch 37, Loss: 0.5530005309583519\n",
      "Epoch 38, Loss: 0.5522169515271648\n",
      "Epoch 39, Loss: 0.5513598872318667\n",
      "Epoch 40, Loss: 0.5504134823863203\n",
      "Epoch 41, Loss: 0.5493542467435251\n",
      "Epoch 42, Loss: 0.5481826679250325\n",
      "Epoch 43, Loss: 0.5467869278970036\n",
      "Epoch 44, Loss: 0.5450409789821646\n",
      "Epoch 45, Loss: 0.5428953052494128\n",
      "Epoch 46, Loss: 0.540392023944795\n",
      "Epoch 47, Loss: 0.537509921448094\n",
      "Epoch 48, Loss: 0.5341426132140595\n",
      "Epoch 49, Loss: 0.5304805007105009\n",
      "Epoch 50, Loss: 0.5268388945312058\n",
      "Epoch 51, Loss: 0.5236051774834125\n",
      "Epoch 52, Loss: 0.5209073649879719\n",
      "Epoch 53, Loss: 0.5186589597762364\n",
      "Epoch 54, Loss: 0.5173968015502611\n",
      "Epoch 55, Loss: 0.5166236569848407\n",
      "Epoch 56, Loss: 0.5150857475338154\n",
      "Epoch 57, Loss: 0.5127038573506685\n",
      "Epoch 58, Loss: 0.509968333663691\n",
      "Epoch 59, Loss: 0.507459429730664\n",
      "Epoch 60, Loss: 0.5054647607660666\n",
      "Epoch 61, Loss: 0.5039465540654852\n",
      "Epoch 62, Loss: 0.5026622468533131\n",
      "Epoch 63, Loss: 0.501302572142788\n",
      "Epoch 64, Loss: 0.49968603826980595\n",
      "Epoch 65, Loss: 0.4977880366289797\n",
      "Epoch 66, Loss: 0.49572266945211985\n",
      "Epoch 67, Loss: 0.4936937263869794\n",
      "Epoch 68, Loss: 0.49190554035674305\n",
      "Epoch 69, Loss: 0.4904465994887059\n",
      "Epoch 70, Loss: 0.4891489178049453\n",
      "Epoch 71, Loss: 0.4878018276261692\n",
      "Epoch 72, Loss: 0.48634362866305114\n",
      "Epoch 73, Loss: 0.48477586955174035\n",
      "Epoch 74, Loss: 0.4832698304152672\n",
      "Epoch 75, Loss: 0.4819685315547978\n",
      "Epoch 76, Loss: 0.4807931998586812\n",
      "Epoch 77, Loss: 0.4795784183198416\n",
      "Epoch 78, Loss: 0.4782110841085946\n",
      "Epoch 79, Loss: 0.47679159254947884\n",
      "Epoch 80, Loss: 0.47548901708095087\n",
      "Epoch 81, Loss: 0.47433446449617167\n",
      "Epoch 82, Loss: 0.4732674831631104\n",
      "Epoch 83, Loss: 0.4721438570385056\n",
      "Epoch 84, Loss: 0.4709500816502284\n",
      "Epoch 85, Loss: 0.4697543193523138\n",
      "Epoch 86, Loss: 0.4686028249484497\n",
      "Epoch 87, Loss: 0.4674875903139971\n",
      "Epoch 88, Loss: 0.4663324639566992\n",
      "Epoch 89, Loss: 0.4651437800910782\n",
      "Epoch 90, Loss: 0.4639869936772649\n",
      "Epoch 91, Loss: 0.46285247645536176\n",
      "Epoch 92, Loss: 0.4617191895613539\n",
      "Epoch 93, Loss: 0.46056106519637374\n",
      "Epoch 94, Loss: 0.45939977799627363\n",
      "Epoch 95, Loss: 0.4582762104619641\n",
      "Epoch 96, Loss: 0.45719737106795594\n",
      "Epoch 97, Loss: 0.4560858738301831\n",
      "Epoch 98, Loss: 0.45496265436272526\n",
      "Epoch 99, Loss: 0.4538598022070195\n",
      "Epoch 100, Loss: 0.4527683663300211\n",
      "Epoch 101, Loss: 0.4516701197169628\n",
      "Epoch 102, Loss: 0.45057713335064825\n",
      "Epoch 103, Loss: 0.44949380497912006\n",
      "Epoch 104, Loss: 0.44839459988284197\n",
      "Epoch 105, Loss: 0.447275386520542\n",
      "Epoch 106, Loss: 0.44614229355692675\n",
      "Epoch 107, Loss: 0.44501043414623825\n",
      "Epoch 108, Loss: 0.4439190931922834\n",
      "Epoch 109, Loss: 0.4428097851763564\n",
      "Epoch 110, Loss: 0.4416260130034122\n",
      "Epoch 111, Loss: 0.44033804064736515\n",
      "Epoch 112, Loss: 0.43917934790597035\n",
      "Epoch 113, Loss: 0.4383983244900463\n",
      "Epoch 114, Loss: 0.4377283283873351\n",
      "Epoch 115, Loss: 0.43663197646531715\n",
      "Epoch 116, Loss: 0.43592127287821836\n",
      "Epoch 117, Loss: 0.4353436051296524\n",
      "Epoch 118, Loss: 0.4343803419155179\n",
      "Epoch 119, Loss: 0.4336060874489652\n",
      "Epoch 120, Loss: 0.4330647308560814\n",
      "Epoch 121, Loss: 0.4323092671530331\n",
      "Epoch 122, Loss: 0.4317847309092336\n",
      "Epoch 123, Loss: 0.43130525013925314\n",
      "Epoch 124, Loss: 0.43061018626252473\n",
      "Epoch 125, Loss: 0.4300697533730782\n",
      "Epoch 126, Loss: 0.4295552483685722\n",
      "Epoch 127, Loss: 0.4288674244913464\n",
      "Epoch 128, Loss: 0.4282705004072645\n",
      "Epoch 129, Loss: 0.4277539705987353\n",
      "Epoch 130, Loss: 0.4271787230644124\n",
      "Epoch 131, Loss: 0.4266182782660456\n",
      "Epoch 132, Loss: 0.4261434746640219\n",
      "Epoch 133, Loss: 0.42564211330655644\n",
      "Epoch 134, Loss: 0.42508900215353973\n",
      "Epoch 135, Loss: 0.42450124492058333\n",
      "Epoch 136, Loss: 0.42393044146454617\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21890199362168347\n",
      "Test R^2 score: 0.4823281332973294\n",
      "Num of epochs: 137\n",
      "Epoch 1, Loss: 0.557471982953294\n",
      "Epoch 2, Loss: 0.5570310595326144\n",
      "Epoch 3, Loss: 0.5566858641327493\n",
      "Epoch 4, Loss: 0.5564263985640568\n",
      "Epoch 5, Loss: 0.5562549794434971\n",
      "Epoch 6, Loss: 0.5561560144211202\n",
      "Epoch 7, Loss: 0.5561185563619392\n",
      "Epoch 8, Loss: 0.5561232722507012\n",
      "Epoch 9, Loss: 0.5561498519667484\n",
      "Epoch 10, Loss: 0.5561746353357412\n",
      "Epoch 11, Loss: 0.5561830212418859\n",
      "Epoch 12, Loss: 0.5561655794867907\n",
      "Epoch 13, Loss: 0.5561197085429989\n",
      "Epoch 14, Loss: 0.5560460713358458\n",
      "Epoch 15, Loss: 0.5559492937866606\n",
      "Epoch 16, Loss: 0.5558353689643534\n",
      "Epoch 17, Loss: 0.5557069946222979\n",
      "Epoch 18, Loss: 0.5555637315969713\n",
      "Epoch 19, Loss: 0.55540360982228\n",
      "Epoch 20, Loss: 0.5552227231916971\n",
      "Epoch 21, Loss: 0.5550132654512077\n",
      "Epoch 22, Loss: 0.5547642184649162\n",
      "Epoch 23, Loss: 0.5544631128055232\n",
      "Epoch 24, Loss: 0.5540899900102614\n",
      "Epoch 25, Loss: 0.5536256754792038\n",
      "Epoch 26, Loss: 0.5530559022492445\n",
      "Epoch 27, Loss: 0.5523951267806437\n",
      "Epoch 28, Loss: 0.5516301640403477\n",
      "Epoch 29, Loss: 0.5506929096774051\n",
      "Epoch 30, Loss: 0.5495539308520015\n",
      "Epoch 31, Loss: 0.5482218913584278\n",
      "Epoch 32, Loss: 0.5466853494136312\n",
      "Epoch 33, Loss: 0.54487697183874\n",
      "Epoch 34, Loss: 0.5427990380585059\n",
      "Epoch 35, Loss: 0.5404895193758291\n",
      "Epoch 36, Loss: 0.5379441311554843\n",
      "Epoch 37, Loss: 0.5350725707184844\n",
      "Epoch 38, Loss: 0.5317765599564216\n",
      "Epoch 39, Loss: 0.5280397696256167\n",
      "Epoch 40, Loss: 0.5238541610130157\n",
      "Epoch 41, Loss: 0.5190911400763647\n",
      "Epoch 42, Loss: 0.5135497321474946\n",
      "Epoch 43, Loss: 0.5070912153759332\n",
      "Epoch 44, Loss: 0.49988748357304014\n",
      "Epoch 45, Loss: 0.4923723570013569\n",
      "Epoch 46, Loss: 0.48523217926241047\n",
      "Epoch 47, Loss: 0.4797907596993111\n",
      "Epoch 48, Loss: 0.4773715296776733\n",
      "Epoch 49, Loss: 0.47645151690816984\n",
      "Epoch 50, Loss: 0.4751414703208075\n",
      "Epoch 51, Loss: 0.4736187804984883\n",
      "Epoch 52, Loss: 0.47251300375064303\n",
      "Epoch 53, Loss: 0.4713447123750825\n",
      "Epoch 54, Loss: 0.4693616532207243\n",
      "Epoch 55, Loss: 0.4668813333758413\n",
      "Epoch 56, Loss: 0.4651002897276844\n",
      "Epoch 57, Loss: 0.4646325793773152\n",
      "Epoch 58, Loss: 0.4645030913173108\n",
      "Epoch 59, Loss: 0.4640288543063875\n",
      "Epoch 60, Loss: 0.46300566326245324\n",
      "Epoch 61, Loss: 0.4616965332108064\n",
      "Epoch 62, Loss: 0.46062695014985927\n",
      "Epoch 63, Loss: 0.45983457348112367\n",
      "Epoch 64, Loss: 0.4591034592701517\n",
      "Epoch 65, Loss: 0.45830948904898555\n",
      "Epoch 66, Loss: 0.457528927440909\n",
      "Epoch 67, Loss: 0.45691413683066\n",
      "Epoch 68, Loss: 0.45633835720822175\n",
      "Epoch 69, Loss: 0.4555619087283437\n",
      "Epoch 70, Loss: 0.4546601828008402\n",
      "Epoch 71, Loss: 0.4539622431506894\n",
      "Epoch 72, Loss: 0.45351250291746903\n",
      "Epoch 73, Loss: 0.45303340512279033\n",
      "Epoch 74, Loss: 0.45235792543010933\n",
      "Epoch 75, Loss: 0.45162485345563036\n",
      "Epoch 76, Loss: 0.45094815607096805\n",
      "Epoch 77, Loss: 0.4503550546037405\n",
      "Epoch 78, Loss: 0.4498431303199562\n",
      "Epoch 79, Loss: 0.44932626184052743\n",
      "Epoch 80, Loss: 0.44868816055906\n",
      "Epoch 81, Loss: 0.4480015725976727\n",
      "Epoch 82, Loss: 0.4474178871282135\n",
      "Epoch 83, Loss: 0.44688350896137\n",
      "Epoch 84, Loss: 0.4462991291805629\n",
      "Epoch 85, Loss: 0.44565141061897484\n",
      "Epoch 86, Loss: 0.44496690155551955\n",
      "Epoch 87, Loss: 0.44431948788554476\n",
      "Epoch 88, Loss: 0.44369262404975157\n",
      "Epoch 89, Loss: 0.4429949972998286\n",
      "Epoch 90, Loss: 0.44231052102744084\n",
      "Epoch 91, Loss: 0.4416711231972522\n",
      "Epoch 92, Loss: 0.4410373868210541\n",
      "Epoch 93, Loss: 0.44034032486012653\n",
      "Epoch 94, Loss: 0.4395726189806652\n",
      "Epoch 95, Loss: 0.4388447598344734\n",
      "Epoch 96, Loss: 0.43809159335168774\n",
      "Epoch 97, Loss: 0.4373023404070765\n",
      "Epoch 98, Loss: 0.4365041843751211\n",
      "Epoch 99, Loss: 0.4357307285527376\n",
      "Epoch 100, Loss: 0.4349263993293962\n",
      "Epoch 101, Loss: 0.43412293111658007\n",
      "Epoch 102, Loss: 0.43338707130659365\n",
      "Epoch 103, Loss: 0.43263742300546876\n",
      "Epoch 104, Loss: 0.4318804700259366\n",
      "Epoch 105, Loss: 0.43116205535008423\n",
      "Epoch 106, Loss: 0.43043184831857373\n",
      "Epoch 107, Loss: 0.4297247437028666\n",
      "Epoch 108, Loss: 0.4290130002946371\n",
      "Epoch 109, Loss: 0.4283166345107026\n",
      "Epoch 110, Loss: 0.42764626209441153\n",
      "Epoch 111, Loss: 0.4269731270867904\n",
      "Epoch 112, Loss: 0.4263022848263565\n",
      "Epoch 113, Loss: 0.4256091338686027\n",
      "Epoch 114, Loss: 0.4249245660819033\n",
      "Epoch 115, Loss: 0.42427484201207266\n",
      "Epoch 116, Loss: 0.42374067678857247\n",
      "Epoch 117, Loss: 0.4235159959564527\n",
      "Epoch 118, Loss: 0.4230317751513525\n",
      "Epoch 119, Loss: 0.4216254520566515\n",
      "Epoch 120, Loss: 0.42097553865765386\n",
      "Epoch 121, Loss: 0.42089459623278885\n",
      "Epoch 122, Loss: 0.4198013487552023\n",
      "Epoch 123, Loss: 0.41892909305360243\n",
      "Epoch 124, Loss: 0.418783427797349\n",
      "Epoch 125, Loss: 0.4179337567092888\n",
      "Epoch 126, Loss: 0.41694010067533094\n",
      "Epoch 127, Loss: 0.41659133548049737\n",
      "Epoch 128, Loss: 0.4160992175726764\n",
      "Epoch 129, Loss: 0.4151285770598702\n",
      "Epoch 130, Loss: 0.41443629756494754\n",
      "Epoch 131, Loss: 0.4140765169758121\n",
      "Epoch 132, Loss: 0.41352620572352033\n",
      "Epoch 133, Loss: 0.4127152314910215\n",
      "Epoch 134, Loss: 0.4120647532816465\n",
      "Epoch 135, Loss: 0.4116323159567121\n",
      "Epoch 136, Loss: 0.4111821197155448\n",
      "Epoch 137, Loss: 0.4106217603686316\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22233978420239944\n",
      "Test R^2 score: 0.4643965130537868\n",
      "Num of epochs: 138\n",
      "Epoch 1, Loss: 0.5596988124332503\n",
      "Epoch 2, Loss: 0.5590460486680884\n",
      "Epoch 3, Loss: 0.5584654493974538\n",
      "Epoch 4, Loss: 0.5579824771009745\n",
      "Epoch 5, Loss: 0.5575908647995036\n",
      "Epoch 6, Loss: 0.5572454546250574\n",
      "Epoch 7, Loss: 0.5569482589040361\n",
      "Epoch 8, Loss: 0.5567050561925747\n",
      "Epoch 9, Loss: 0.5565063314566097\n",
      "Epoch 10, Loss: 0.5563516502511542\n",
      "Epoch 11, Loss: 0.5562399241788597\n",
      "Epoch 12, Loss: 0.5561661957178741\n",
      "Epoch 13, Loss: 0.5561245316005937\n",
      "Epoch 14, Loss: 0.5561069272380726\n",
      "Epoch 15, Loss: 0.5561071416020029\n",
      "Epoch 16, Loss: 0.5561247727523755\n",
      "Epoch 17, Loss: 0.5561372589128639\n",
      "Epoch 18, Loss: 0.5561419210554167\n",
      "Epoch 19, Loss: 0.5561331594103956\n",
      "Epoch 20, Loss: 0.5561066056920223\n",
      "Epoch 21, Loss: 0.5560612926352138\n",
      "Epoch 22, Loss: 0.5559979660748253\n",
      "Epoch 23, Loss: 0.5559161373706406\n",
      "Epoch 24, Loss: 0.5558143774438633\n",
      "Epoch 25, Loss: 0.5557038572840999\n",
      "Epoch 26, Loss: 0.5555548803669748\n",
      "Epoch 27, Loss: 0.5553805092043145\n",
      "Epoch 28, Loss: 0.5551833502019501\n",
      "Epoch 29, Loss: 0.5549460869455687\n",
      "Epoch 30, Loss: 0.554641963540267\n",
      "Epoch 31, Loss: 0.554236188151219\n",
      "Epoch 32, Loss: 0.5537096188376466\n",
      "Epoch 33, Loss: 0.5530539353835136\n",
      "Epoch 34, Loss: 0.5522520569227257\n",
      "Epoch 35, Loss: 0.551319887008625\n",
      "Epoch 36, Loss: 0.5501713453332928\n",
      "Epoch 37, Loss: 0.5486771182364156\n",
      "Epoch 38, Loss: 0.5467483101283621\n",
      "Epoch 39, Loss: 0.5443248144025508\n",
      "Epoch 40, Loss: 0.541437115690801\n",
      "Epoch 41, Loss: 0.5380082533018954\n",
      "Epoch 42, Loss: 0.5339814538324651\n",
      "Epoch 43, Loss: 0.5294053364227881\n",
      "Epoch 44, Loss: 0.524455887531362\n",
      "Epoch 45, Loss: 0.5196493487825757\n",
      "Epoch 46, Loss: 0.5160086389454237\n",
      "Epoch 47, Loss: 0.5143473430257504\n",
      "Epoch 48, Loss: 0.5132796091549918\n",
      "Epoch 49, Loss: 0.5105073290381922\n",
      "Epoch 50, Loss: 0.506654828298239\n",
      "Epoch 51, Loss: 0.503527032857596\n",
      "Epoch 52, Loss: 0.5017759552226255\n",
      "Epoch 53, Loss: 0.50079583371451\n",
      "Epoch 54, Loss: 0.49938951416312205\n",
      "Epoch 55, Loss: 0.49721130889528187\n",
      "Epoch 56, Loss: 0.4944999353458914\n",
      "Epoch 57, Loss: 0.4918198953562873\n",
      "Epoch 58, Loss: 0.48969879378372183\n",
      "Epoch 59, Loss: 0.48812364705053335\n",
      "Epoch 60, Loss: 0.48642287039981946\n",
      "Epoch 61, Loss: 0.48415343539279715\n",
      "Epoch 62, Loss: 0.48176953770918657\n",
      "Epoch 63, Loss: 0.4798961111235872\n",
      "Epoch 64, Loss: 0.4784085212268374\n",
      "Epoch 65, Loss: 0.4766693308173379\n",
      "Epoch 66, Loss: 0.4744618975542681\n",
      "Epoch 67, Loss: 0.4721693415656345\n",
      "Epoch 68, Loss: 0.47030263301092845\n",
      "Epoch 69, Loss: 0.4689303051359609\n",
      "Epoch 70, Loss: 0.4675893879412726\n",
      "Epoch 71, Loss: 0.4661865554014456\n",
      "Epoch 72, Loss: 0.465053174582977\n",
      "Epoch 73, Loss: 0.4642865182927265\n",
      "Epoch 74, Loss: 0.46349329285259405\n",
      "Epoch 75, Loss: 0.4623464613019904\n",
      "Epoch 76, Loss: 0.46105469005972227\n",
      "Epoch 77, Loss: 0.45988023053922544\n",
      "Epoch 78, Loss: 0.45904391288132734\n",
      "Epoch 79, Loss: 0.45836017450575334\n",
      "Epoch 80, Loss: 0.4577761066019444\n",
      "Epoch 81, Loss: 0.4570791268336248\n",
      "Epoch 82, Loss: 0.4562074621829072\n",
      "Epoch 83, Loss: 0.4553100093388557\n",
      "Epoch 84, Loss: 0.4543941088702569\n",
      "Epoch 85, Loss: 0.4535663362813642\n",
      "Epoch 86, Loss: 0.4528521341020643\n",
      "Epoch 87, Loss: 0.4521881646320808\n",
      "Epoch 88, Loss: 0.4515982920575514\n",
      "Epoch 89, Loss: 0.4509866342456577\n",
      "Epoch 90, Loss: 0.45032674728505234\n",
      "Epoch 91, Loss: 0.44966582566145646\n",
      "Epoch 92, Loss: 0.44900955636701995\n",
      "Epoch 93, Loss: 0.44836003701134064\n",
      "Epoch 94, Loss: 0.44777017977728417\n",
      "Epoch 95, Loss: 0.4471992876590556\n",
      "Epoch 96, Loss: 0.44665795904302447\n",
      "Epoch 97, Loss: 0.4460759394843123\n",
      "Epoch 98, Loss: 0.4454975412966679\n",
      "Epoch 99, Loss: 0.44489978604833524\n",
      "Epoch 100, Loss: 0.4443238141428622\n",
      "Epoch 101, Loss: 0.44373948863837465\n",
      "Epoch 102, Loss: 0.44316165565317966\n",
      "Epoch 103, Loss: 0.44257668800491073\n",
      "Epoch 104, Loss: 0.44199416581139717\n",
      "Epoch 105, Loss: 0.4413992788388869\n",
      "Epoch 106, Loss: 0.4408018142949739\n",
      "Epoch 107, Loss: 0.44019157248978297\n",
      "Epoch 108, Loss: 0.43957409359349753\n",
      "Epoch 109, Loss: 0.43894213319614755\n",
      "Epoch 110, Loss: 0.4383074937874779\n",
      "Epoch 111, Loss: 0.4376714574806336\n",
      "Epoch 112, Loss: 0.43703843360100475\n",
      "Epoch 113, Loss: 0.4364014013330406\n",
      "Epoch 114, Loss: 0.4357733885889295\n",
      "Epoch 115, Loss: 0.4351480137372591\n",
      "Epoch 116, Loss: 0.4345053977916359\n",
      "Epoch 117, Loss: 0.4338487785832137\n",
      "Epoch 118, Loss: 0.4331267307571686\n",
      "Epoch 119, Loss: 0.4324150732758084\n",
      "Epoch 120, Loss: 0.4316801165298237\n",
      "Epoch 121, Loss: 0.43097900154822516\n",
      "Epoch 122, Loss: 0.4304151789013882\n",
      "Epoch 123, Loss: 0.42983127269433363\n",
      "Epoch 124, Loss: 0.42905620670357003\n",
      "Epoch 125, Loss: 0.4282747278339674\n",
      "Epoch 126, Loss: 0.42781289133370265\n",
      "Epoch 127, Loss: 0.4274084338621662\n",
      "Epoch 128, Loss: 0.4267538493864984\n",
      "Epoch 129, Loss: 0.42605936958760043\n",
      "Epoch 130, Loss: 0.4255802660105066\n",
      "Epoch 131, Loss: 0.4251636961229172\n",
      "Epoch 132, Loss: 0.42461682254327576\n",
      "Epoch 133, Loss: 0.42389989500136716\n",
      "Epoch 134, Loss: 0.4233586748240218\n",
      "Epoch 135, Loss: 0.42302000994282407\n",
      "Epoch 136, Loss: 0.4226452189643624\n",
      "Epoch 137, Loss: 0.4220646149525695\n",
      "Epoch 138, Loss: 0.42130033772412245\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22191572019294123\n",
      "Test R^2 score: 0.46961689813632146\n",
      "Num of epochs: 139\n",
      "Epoch 1, Loss: 0.5779451915418501\n",
      "Epoch 2, Loss: 0.5767338226837418\n",
      "Epoch 3, Loss: 0.5756311239026562\n",
      "Epoch 4, Loss: 0.5745651860883392\n",
      "Epoch 5, Loss: 0.5735282379205984\n",
      "Epoch 6, Loss: 0.572520384862868\n",
      "Epoch 7, Loss: 0.5715418851210099\n",
      "Epoch 8, Loss: 0.5705928897075038\n",
      "Epoch 9, Loss: 0.569678280536589\n",
      "Epoch 10, Loss: 0.5687920146137485\n",
      "Epoch 11, Loss: 0.5679333850287106\n",
      "Epoch 12, Loss: 0.5671025961389179\n",
      "Epoch 13, Loss: 0.5662996125960401\n",
      "Epoch 14, Loss: 0.5655242893490248\n",
      "Epoch 15, Loss: 0.5647764500878532\n",
      "Epoch 16, Loss: 0.5640271701473915\n",
      "Epoch 17, Loss: 0.5632952525690668\n",
      "Epoch 18, Loss: 0.5626035171200862\n",
      "Epoch 19, Loss: 0.5619330728157288\n",
      "Epoch 20, Loss: 0.5612916418230407\n",
      "Epoch 21, Loss: 0.560677277286943\n",
      "Epoch 22, Loss: 0.5600900150654066\n",
      "Epoch 23, Loss: 0.5595368912920319\n",
      "Epoch 24, Loss: 0.5590305887734747\n",
      "Epoch 25, Loss: 0.5585491722832938\n",
      "Epoch 26, Loss: 0.5581072042176238\n",
      "Epoch 27, Loss: 0.5576747991459521\n",
      "Epoch 28, Loss: 0.5572509631922575\n",
      "Epoch 29, Loss: 0.5568126479583383\n",
      "Epoch 30, Loss: 0.5562854905539826\n",
      "Epoch 31, Loss: 0.5556589672746677\n",
      "Epoch 32, Loss: 0.5550658319281127\n",
      "Epoch 33, Loss: 0.5545688018595539\n",
      "Epoch 34, Loss: 0.5541193564256882\n",
      "Epoch 35, Loss: 0.5535563634984755\n",
      "Epoch 36, Loss: 0.5528447880003398\n",
      "Epoch 37, Loss: 0.5519562221043349\n",
      "Epoch 38, Loss: 0.5508485306573312\n",
      "Epoch 39, Loss: 0.54946411859478\n",
      "Epoch 40, Loss: 0.547722405153372\n",
      "Epoch 41, Loss: 0.5455293721474118\n",
      "Epoch 42, Loss: 0.5428048304936712\n",
      "Epoch 43, Loss: 0.5395188542236548\n",
      "Epoch 44, Loss: 0.5357720945593398\n",
      "Epoch 45, Loss: 0.5318185905011851\n",
      "Epoch 46, Loss: 0.5282426308092163\n",
      "Epoch 47, Loss: 0.526006854828527\n",
      "Epoch 48, Loss: 0.5256616396840007\n",
      "Epoch 49, Loss: 0.5253748838200828\n",
      "Epoch 50, Loss: 0.5233598053619077\n",
      "Epoch 51, Loss: 0.5202954343912558\n",
      "Epoch 52, Loss: 0.5174998674070032\n",
      "Epoch 53, Loss: 0.5155958398607488\n",
      "Epoch 54, Loss: 0.5143817304632068\n",
      "Epoch 55, Loss: 0.5133011499086212\n",
      "Epoch 56, Loss: 0.5118948946336621\n",
      "Epoch 57, Loss: 0.5099471488850492\n",
      "Epoch 58, Loss: 0.5075511846898126\n",
      "Epoch 59, Loss: 0.504996665056\n",
      "Epoch 60, Loss: 0.5026293404028168\n",
      "Epoch 61, Loss: 0.500627183945139\n",
      "Epoch 62, Loss: 0.4988053772951569\n",
      "Epoch 63, Loss: 0.4966755556691495\n",
      "Epoch 64, Loss: 0.4941179021503587\n",
      "Epoch 65, Loss: 0.4915398772333413\n",
      "Epoch 66, Loss: 0.4891841018186373\n",
      "Epoch 67, Loss: 0.4870647994312317\n",
      "Epoch 68, Loss: 0.484864572021979\n",
      "Epoch 69, Loss: 0.4823847150197477\n",
      "Epoch 70, Loss: 0.4794317856170726\n",
      "Epoch 71, Loss: 0.4760108318679185\n",
      "Epoch 72, Loss: 0.4723702503358234\n",
      "Epoch 73, Loss: 0.46859462070161595\n",
      "Epoch 74, Loss: 0.4650073685113513\n",
      "Epoch 75, Loss: 0.46278789040137114\n",
      "Epoch 76, Loss: 0.4635523159075406\n",
      "Epoch 77, Loss: 0.464820123921569\n",
      "Epoch 78, Loss: 0.463664104778997\n",
      "Epoch 79, Loss: 0.4617984780348458\n",
      "Epoch 80, Loss: 0.4611004202039347\n",
      "Epoch 81, Loss: 0.4605481718011124\n",
      "Epoch 82, Loss: 0.45937227131558644\n",
      "Epoch 83, Loss: 0.45818019786818454\n",
      "Epoch 84, Loss: 0.4575174956546148\n",
      "Epoch 85, Loss: 0.4571499629591337\n",
      "Epoch 86, Loss: 0.4568187676147352\n",
      "Epoch 87, Loss: 0.45645152109385545\n",
      "Epoch 88, Loss: 0.45593629398931607\n",
      "Epoch 89, Loss: 0.45515600037494264\n",
      "Epoch 90, Loss: 0.4542062454155814\n",
      "Epoch 91, Loss: 0.4533366991308495\n",
      "Epoch 92, Loss: 0.45270833227710866\n",
      "Epoch 93, Loss: 0.4522231927953584\n",
      "Epoch 94, Loss: 0.45167727876116776\n",
      "Epoch 95, Loss: 0.45097135240957636\n",
      "Epoch 96, Loss: 0.45023254770136156\n",
      "Epoch 97, Loss: 0.44962774814214473\n",
      "Epoch 98, Loss: 0.44914341170434646\n",
      "Epoch 99, Loss: 0.4485966562823387\n",
      "Epoch 100, Loss: 0.44795023067901457\n",
      "Epoch 101, Loss: 0.447306935097592\n",
      "Epoch 102, Loss: 0.4467534126584737\n",
      "Epoch 103, Loss: 0.4461739556516702\n",
      "Epoch 104, Loss: 0.4455099504646133\n",
      "Epoch 105, Loss: 0.44483510578789065\n",
      "Epoch 106, Loss: 0.44424070238957625\n",
      "Epoch 107, Loss: 0.443704529568316\n",
      "Epoch 108, Loss: 0.44313781512605593\n",
      "Epoch 109, Loss: 0.44250055560923035\n",
      "Epoch 110, Loss: 0.441845211417036\n",
      "Epoch 111, Loss: 0.44117347521092304\n",
      "Epoch 112, Loss: 0.4404955897115871\n",
      "Epoch 113, Loss: 0.4397894187151791\n",
      "Epoch 114, Loss: 0.43910642723182974\n",
      "Epoch 115, Loss: 0.4384173244910546\n",
      "Epoch 116, Loss: 0.43768126274958324\n",
      "Epoch 117, Loss: 0.43696416670736227\n",
      "Epoch 118, Loss: 0.43628040691420233\n",
      "Epoch 119, Loss: 0.43561011227380764\n",
      "Epoch 120, Loss: 0.434899863112124\n",
      "Epoch 121, Loss: 0.4341688037216885\n",
      "Epoch 122, Loss: 0.4334433870527702\n",
      "Epoch 123, Loss: 0.4327287379440195\n",
      "Epoch 124, Loss: 0.43204803572151806\n",
      "Epoch 125, Loss: 0.4313181021724128\n",
      "Epoch 126, Loss: 0.43060463216308187\n",
      "Epoch 127, Loss: 0.4298867890565311\n",
      "Epoch 128, Loss: 0.42918073074048757\n",
      "Epoch 129, Loss: 0.42845394626050565\n",
      "Epoch 130, Loss: 0.4277213978649551\n",
      "Epoch 131, Loss: 0.42701938390733196\n",
      "Epoch 132, Loss: 0.42628823290653023\n",
      "Epoch 133, Loss: 0.42557168755520913\n",
      "Epoch 134, Loss: 0.4248637015907454\n",
      "Epoch 135, Loss: 0.4241680417041687\n",
      "Epoch 136, Loss: 0.42347975446168223\n",
      "Epoch 137, Loss: 0.4227892188790859\n",
      "Epoch 138, Loss: 0.4221215234251266\n",
      "Epoch 139, Loss: 0.42146346541501567\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21453229373437893\n",
      "Test R^2 score: 0.5009402481389025\n",
      "Num of epochs: 140\n",
      "Epoch 1, Loss: 0.5645488671014811\n",
      "Epoch 2, Loss: 0.5630706700356732\n",
      "Epoch 3, Loss: 0.5617222177029719\n",
      "Epoch 4, Loss: 0.5605150007695805\n",
      "Epoch 5, Loss: 0.559454035370023\n",
      "Epoch 6, Loss: 0.5585423159094565\n",
      "Epoch 7, Loss: 0.5577837533248661\n",
      "Epoch 8, Loss: 0.5571819952127499\n",
      "Epoch 9, Loss: 0.5567449906872807\n",
      "Epoch 10, Loss: 0.5564727530068474\n",
      "Epoch 11, Loss: 0.5563339459372261\n",
      "Epoch 12, Loss: 0.5562862137996856\n",
      "Epoch 13, Loss: 0.5563120893051093\n",
      "Epoch 14, Loss: 0.5563671042371218\n",
      "Epoch 15, Loss: 0.5564254880395088\n",
      "Epoch 16, Loss: 0.5564801704304666\n",
      "Epoch 17, Loss: 0.5565146588128264\n",
      "Epoch 18, Loss: 0.5565207101253431\n",
      "Epoch 19, Loss: 0.5565000389986804\n",
      "Epoch 20, Loss: 0.5564569806113797\n",
      "Epoch 21, Loss: 0.5563908334389018\n",
      "Epoch 22, Loss: 0.5563086071643198\n",
      "Epoch 23, Loss: 0.5562152508800747\n",
      "Epoch 24, Loss: 0.5561107589808638\n",
      "Epoch 25, Loss: 0.556002280978457\n",
      "Epoch 26, Loss: 0.5558987944639817\n",
      "Epoch 27, Loss: 0.555792393136998\n",
      "Epoch 28, Loss: 0.5556725633772112\n",
      "Epoch 29, Loss: 0.5555297742927995\n",
      "Epoch 30, Loss: 0.5553600639534537\n",
      "Epoch 31, Loss: 0.5551593278176313\n",
      "Epoch 32, Loss: 0.5549137567406704\n",
      "Epoch 33, Loss: 0.5545956172867615\n",
      "Epoch 34, Loss: 0.5541876569037636\n",
      "Epoch 35, Loss: 0.5536826797621738\n",
      "Epoch 36, Loss: 0.5530527768154943\n",
      "Epoch 37, Loss: 0.5522659527541157\n",
      "Epoch 38, Loss: 0.5512913985937078\n",
      "Epoch 39, Loss: 0.5500941217689188\n",
      "Epoch 40, Loss: 0.5486110108478739\n",
      "Epoch 41, Loss: 0.5467882087501478\n",
      "Epoch 42, Loss: 0.5445796206210812\n",
      "Epoch 43, Loss: 0.5418383130740697\n",
      "Epoch 44, Loss: 0.5384934227275211\n",
      "Epoch 45, Loss: 0.5345853558821957\n",
      "Epoch 46, Loss: 0.5304710624093848\n",
      "Epoch 47, Loss: 0.5267577129246522\n",
      "Epoch 48, Loss: 0.524355297241342\n",
      "Epoch 49, Loss: 0.5232353674204562\n",
      "Epoch 50, Loss: 0.5208706619873006\n",
      "Epoch 51, Loss: 0.516857869649697\n",
      "Epoch 52, Loss: 0.5128737075700125\n",
      "Epoch 53, Loss: 0.5100573001255763\n",
      "Epoch 54, Loss: 0.5083600246999226\n",
      "Epoch 55, Loss: 0.5067620195940312\n",
      "Epoch 56, Loss: 0.5047245035689717\n",
      "Epoch 57, Loss: 0.5021494321987607\n",
      "Epoch 58, Loss: 0.4993399644528308\n",
      "Epoch 59, Loss: 0.49684215772999746\n",
      "Epoch 60, Loss: 0.4949120994029978\n",
      "Epoch 61, Loss: 0.4932790036855693\n",
      "Epoch 62, Loss: 0.491430442105401\n",
      "Epoch 63, Loss: 0.4892643301828533\n",
      "Epoch 64, Loss: 0.48721023592159707\n",
      "Epoch 65, Loss: 0.4855821855983304\n",
      "Epoch 66, Loss: 0.4841793341902736\n",
      "Epoch 67, Loss: 0.48277501451469473\n",
      "Epoch 68, Loss: 0.48124650483286513\n",
      "Epoch 69, Loss: 0.47963221538943285\n",
      "Epoch 70, Loss: 0.4781652608139222\n",
      "Epoch 71, Loss: 0.47692861720548735\n",
      "Epoch 72, Loss: 0.47576448194900234\n",
      "Epoch 73, Loss: 0.474454407058157\n",
      "Epoch 74, Loss: 0.4730941383445391\n",
      "Epoch 75, Loss: 0.4719022616665063\n",
      "Epoch 76, Loss: 0.470857381276881\n",
      "Epoch 77, Loss: 0.4698124923939493\n",
      "Epoch 78, Loss: 0.4687161115476347\n",
      "Epoch 79, Loss: 0.46760113116960456\n",
      "Epoch 80, Loss: 0.46649741299434216\n",
      "Epoch 81, Loss: 0.4654343803703839\n",
      "Epoch 82, Loss: 0.4643881512521439\n",
      "Epoch 83, Loss: 0.4633435315215049\n",
      "Epoch 84, Loss: 0.46230580209292294\n",
      "Epoch 85, Loss: 0.4612972504364523\n",
      "Epoch 86, Loss: 0.46035501885846314\n",
      "Epoch 87, Loss: 0.45941756888135565\n",
      "Epoch 88, Loss: 0.45845705948847726\n",
      "Epoch 89, Loss: 0.4574950220796102\n",
      "Epoch 90, Loss: 0.45653678359467487\n",
      "Epoch 91, Loss: 0.455617102513987\n",
      "Epoch 92, Loss: 0.45473473818032134\n",
      "Epoch 93, Loss: 0.4538800427328204\n",
      "Epoch 94, Loss: 0.453049604128429\n",
      "Epoch 95, Loss: 0.4522473286855069\n",
      "Epoch 96, Loss: 0.4514485456300234\n",
      "Epoch 97, Loss: 0.4506250841508382\n",
      "Epoch 98, Loss: 0.44979383726363376\n",
      "Epoch 99, Loss: 0.4489289385502213\n",
      "Epoch 100, Loss: 0.4479847919051976\n",
      "Epoch 101, Loss: 0.4470371179018899\n",
      "Epoch 102, Loss: 0.44611460408170406\n",
      "Epoch 103, Loss: 0.4452419559752391\n",
      "Epoch 104, Loss: 0.4443655318580763\n",
      "Epoch 105, Loss: 0.44356305321514733\n",
      "Epoch 106, Loss: 0.4427609038461535\n",
      "Epoch 107, Loss: 0.442016786977186\n",
      "Epoch 108, Loss: 0.4412306377171967\n",
      "Epoch 109, Loss: 0.4404974840852245\n",
      "Epoch 110, Loss: 0.43970345043214926\n",
      "Epoch 111, Loss: 0.43885397863606623\n",
      "Epoch 112, Loss: 0.43793222670431026\n",
      "Epoch 113, Loss: 0.4370424057399671\n",
      "Epoch 114, Loss: 0.4361767170627223\n",
      "Epoch 115, Loss: 0.4352815273080545\n",
      "Epoch 116, Loss: 0.4344062238215329\n",
      "Epoch 117, Loss: 0.4335347900169102\n",
      "Epoch 118, Loss: 0.4326255573642759\n",
      "Epoch 119, Loss: 0.4317149275266378\n",
      "Epoch 120, Loss: 0.4308248725696128\n",
      "Epoch 121, Loss: 0.42994375390529704\n",
      "Epoch 122, Loss: 0.4290303841036919\n",
      "Epoch 123, Loss: 0.4281117242300132\n",
      "Epoch 124, Loss: 0.42721520884462844\n",
      "Epoch 125, Loss: 0.42639710569938183\n",
      "Epoch 126, Loss: 0.4257518338182416\n",
      "Epoch 127, Loss: 0.42551653621313934\n",
      "Epoch 128, Loss: 0.42457883245960704\n",
      "Epoch 129, Loss: 0.42310942084454717\n",
      "Epoch 130, Loss: 0.42277728831414224\n",
      "Epoch 131, Loss: 0.4220298553522843\n",
      "Epoch 132, Loss: 0.42089718068371124\n",
      "Epoch 133, Loss: 0.42064338621224656\n",
      "Epoch 134, Loss: 0.4197916228086892\n",
      "Epoch 135, Loss: 0.41882909483282327\n",
      "Epoch 136, Loss: 0.41848355969230416\n",
      "Epoch 137, Loss: 0.4175948672243631\n",
      "Epoch 138, Loss: 0.4167054237778062\n",
      "Epoch 139, Loss: 0.4162535546698018\n",
      "Epoch 140, Loss: 0.4154774762543098\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21880053264385182\n",
      "Test R^2 score: 0.48375276695621966\n",
      "Num of epochs: 141\n",
      "Epoch 1, Loss: 0.5572674350877589\n",
      "Epoch 2, Loss: 0.5568981712564043\n",
      "Epoch 3, Loss: 0.5566046719902951\n",
      "Epoch 4, Loss: 0.55638756604682\n",
      "Epoch 5, Loss: 0.5562514165795965\n",
      "Epoch 6, Loss: 0.5561779307708087\n",
      "Epoch 7, Loss: 0.5561544872105314\n",
      "Epoch 8, Loss: 0.5561653919380646\n",
      "Epoch 9, Loss: 0.556191246273011\n",
      "Epoch 10, Loss: 0.5562150633480972\n",
      "Epoch 11, Loss: 0.55622433271017\n",
      "Epoch 12, Loss: 0.5562130808633244\n",
      "Epoch 13, Loss: 0.5561788149086022\n",
      "Epoch 14, Loss: 0.5561241832700576\n",
      "Epoch 15, Loss: 0.5560516453811509\n",
      "Epoch 16, Loss: 0.5559632312208499\n",
      "Epoch 17, Loss: 0.5558606488876061\n",
      "Epoch 18, Loss: 0.5557434615275234\n",
      "Epoch 19, Loss: 0.5556114453442075\n",
      "Epoch 20, Loss: 0.5554555223394935\n",
      "Epoch 21, Loss: 0.5552622544071234\n",
      "Epoch 22, Loss: 0.5550202459646256\n",
      "Epoch 23, Loss: 0.5547135306684376\n",
      "Epoch 24, Loss: 0.5543275121672606\n",
      "Epoch 25, Loss: 0.5538427071650049\n",
      "Epoch 26, Loss: 0.5532291745292574\n",
      "Epoch 27, Loss: 0.552460943196557\n",
      "Epoch 28, Loss: 0.5514902191781942\n",
      "Epoch 29, Loss: 0.5502623690853213\n",
      "Epoch 30, Loss: 0.5486946622452966\n",
      "Epoch 31, Loss: 0.5466612261796066\n",
      "Epoch 32, Loss: 0.5440642742147773\n",
      "Epoch 33, Loss: 0.5407569073850077\n",
      "Epoch 34, Loss: 0.536726603665702\n",
      "Epoch 35, Loss: 0.5320637865242538\n",
      "Epoch 36, Loss: 0.526964093342301\n",
      "Epoch 37, Loss: 0.5218591379279156\n",
      "Epoch 38, Loss: 0.5176703604799543\n",
      "Epoch 39, Loss: 0.5156842111055684\n",
      "Epoch 40, Loss: 0.5156960004994285\n",
      "Epoch 41, Loss: 0.5145968387803179\n",
      "Epoch 42, Loss: 0.5111213283392948\n",
      "Epoch 43, Loss: 0.5067105000236308\n",
      "Epoch 44, Loss: 0.50301317429401\n",
      "Epoch 45, Loss: 0.5007514671003283\n",
      "Epoch 46, Loss: 0.4995234871202365\n",
      "Epoch 47, Loss: 0.49832829023390823\n",
      "Epoch 48, Loss: 0.49662531511232916\n",
      "Epoch 49, Loss: 0.4943103121985101\n",
      "Epoch 50, Loss: 0.49161723569999216\n",
      "Epoch 51, Loss: 0.488964167815957\n",
      "Epoch 52, Loss: 0.4867186146792596\n",
      "Epoch 53, Loss: 0.48501902496246335\n",
      "Epoch 54, Loss: 0.4835022323610119\n",
      "Epoch 55, Loss: 0.4815080303946564\n",
      "Epoch 56, Loss: 0.47906125159950114\n",
      "Epoch 57, Loss: 0.4768314540674448\n",
      "Epoch 58, Loss: 0.4751248797843317\n",
      "Epoch 59, Loss: 0.4736722949373931\n",
      "Epoch 60, Loss: 0.4719641007686496\n",
      "Epoch 61, Loss: 0.4703155599855763\n",
      "Epoch 62, Loss: 0.46908457259992986\n",
      "Epoch 63, Loss: 0.46802459854806455\n",
      "Epoch 64, Loss: 0.4667240868165277\n",
      "Epoch 65, Loss: 0.4653956238723275\n",
      "Epoch 66, Loss: 0.46462180344716375\n",
      "Epoch 67, Loss: 0.4637829031415195\n",
      "Epoch 68, Loss: 0.46273055709250516\n",
      "Epoch 69, Loss: 0.46179741320048684\n",
      "Epoch 70, Loss: 0.46112892249412324\n",
      "Epoch 71, Loss: 0.46039708025368575\n",
      "Epoch 72, Loss: 0.4595601792035022\n",
      "Epoch 73, Loss: 0.45880910895387966\n",
      "Epoch 74, Loss: 0.45801923204838596\n",
      "Epoch 75, Loss: 0.45709614415271016\n",
      "Epoch 76, Loss: 0.45628325066834236\n",
      "Epoch 77, Loss: 0.45557450167709235\n",
      "Epoch 78, Loss: 0.454756447064258\n",
      "Epoch 79, Loss: 0.4539504425281545\n",
      "Epoch 80, Loss: 0.45329886422291654\n",
      "Epoch 81, Loss: 0.4524941657148621\n",
      "Epoch 82, Loss: 0.451720956370119\n",
      "Epoch 83, Loss: 0.450997207321055\n",
      "Epoch 84, Loss: 0.4502393820949383\n",
      "Epoch 85, Loss: 0.4496696531188592\n",
      "Epoch 86, Loss: 0.448945235867495\n",
      "Epoch 87, Loss: 0.44827272065997753\n",
      "Epoch 88, Loss: 0.4475795527026084\n",
      "Epoch 89, Loss: 0.4468670030691962\n",
      "Epoch 90, Loss: 0.44614342915613603\n",
      "Epoch 91, Loss: 0.44537348078753136\n",
      "Epoch 92, Loss: 0.44466138386388315\n",
      "Epoch 93, Loss: 0.443899724443079\n",
      "Epoch 94, Loss: 0.4431372266624107\n",
      "Epoch 95, Loss: 0.4423705682470549\n",
      "Epoch 96, Loss: 0.4415854200123206\n",
      "Epoch 97, Loss: 0.4408108569522527\n",
      "Epoch 98, Loss: 0.4399981530920194\n",
      "Epoch 99, Loss: 0.43920940846565304\n",
      "Epoch 100, Loss: 0.4384082324645101\n",
      "Epoch 101, Loss: 0.4375884273265001\n",
      "Epoch 102, Loss: 0.43676841398855354\n",
      "Epoch 103, Loss: 0.43596394844902847\n",
      "Epoch 104, Loss: 0.4351902001661612\n",
      "Epoch 105, Loss: 0.4344190012648769\n",
      "Epoch 106, Loss: 0.4337443700144694\n",
      "Epoch 107, Loss: 0.43315863901162976\n",
      "Epoch 108, Loss: 0.43252882905476453\n",
      "Epoch 109, Loss: 0.43144489182969353\n",
      "Epoch 110, Loss: 0.4305110322156745\n",
      "Epoch 111, Loss: 0.42996818738072\n",
      "Epoch 112, Loss: 0.42931554474294487\n",
      "Epoch 113, Loss: 0.42838260877746087\n",
      "Epoch 114, Loss: 0.4274799513437888\n",
      "Epoch 115, Loss: 0.42679285040907283\n",
      "Epoch 116, Loss: 0.4262015167193677\n",
      "Epoch 117, Loss: 0.4254250567664665\n",
      "Epoch 118, Loss: 0.42461727875457306\n",
      "Epoch 119, Loss: 0.42379176955158854\n",
      "Epoch 120, Loss: 0.42305780539300886\n",
      "Epoch 121, Loss: 0.4224798493686968\n",
      "Epoch 122, Loss: 0.42208985756064776\n",
      "Epoch 123, Loss: 0.4221097857981449\n",
      "Epoch 124, Loss: 0.4218614364139049\n",
      "Epoch 125, Loss: 0.4207965523947063\n",
      "Epoch 126, Loss: 0.41913175546837456\n",
      "Epoch 127, Loss: 0.4194389049828795\n",
      "Epoch 128, Loss: 0.4192684678984391\n",
      "Epoch 129, Loss: 0.4173841041755593\n",
      "Epoch 130, Loss: 0.41775872845323075\n",
      "Epoch 131, Loss: 0.41764414294869606\n",
      "Epoch 132, Loss: 0.4156506150462183\n",
      "Epoch 133, Loss: 0.4164101247982938\n",
      "Epoch 134, Loss: 0.4160075298829109\n",
      "Epoch 135, Loss: 0.41391874012979113\n",
      "Epoch 136, Loss: 0.415088318538591\n",
      "Epoch 137, Loss: 0.41423921592801566\n",
      "Epoch 138, Loss: 0.412308920328521\n",
      "Epoch 139, Loss: 0.4136092566338366\n",
      "Epoch 140, Loss: 0.4121484421567435\n",
      "Epoch 141, Loss: 0.41087113703973777\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22086268989458116\n",
      "Test R^2 score: 0.4714566872284449\n",
      "Num of epochs: 142\n",
      "Epoch 1, Loss: 0.5871214032289375\n",
      "Epoch 2, Loss: 0.5845658587315719\n",
      "Epoch 3, Loss: 0.5822048568390648\n",
      "Epoch 4, Loss: 0.5800160846864071\n",
      "Epoch 5, Loss: 0.5779346461984168\n",
      "Epoch 6, Loss: 0.5759599198827735\n",
      "Epoch 7, Loss: 0.5740903334497004\n",
      "Epoch 8, Loss: 0.5723247302261721\n",
      "Epoch 9, Loss: 0.5706618297344436\n",
      "Epoch 10, Loss: 0.5691010659738229\n",
      "Epoch 11, Loss: 0.5676386612535794\n",
      "Epoch 12, Loss: 0.5662751934097496\n",
      "Epoch 13, Loss: 0.5650066051265861\n",
      "Epoch 14, Loss: 0.5638322154062306\n",
      "Epoch 15, Loss: 0.5627549441411457\n",
      "Epoch 16, Loss: 0.5618640430557486\n",
      "Epoch 17, Loss: 0.561151875836975\n",
      "Epoch 18, Loss: 0.5604340177163855\n",
      "Epoch 19, Loss: 0.5597709841847679\n",
      "Epoch 20, Loss: 0.5591527635899182\n",
      "Epoch 21, Loss: 0.5585835329201784\n",
      "Epoch 22, Loss: 0.5580640562217154\n",
      "Epoch 23, Loss: 0.5575930561783334\n",
      "Epoch 24, Loss: 0.5571657882371224\n",
      "Epoch 25, Loss: 0.556776465187339\n",
      "Epoch 26, Loss: 0.5564163023702905\n",
      "Epoch 27, Loss: 0.5560787376613308\n",
      "Epoch 28, Loss: 0.5557765209993113\n",
      "Epoch 29, Loss: 0.5554869626006338\n",
      "Epoch 30, Loss: 0.5551081123815509\n",
      "Epoch 31, Loss: 0.5547416284504537\n",
      "Epoch 32, Loss: 0.5542974309400979\n",
      "Epoch 33, Loss: 0.5537090536956767\n",
      "Epoch 34, Loss: 0.5529771413217608\n",
      "Epoch 35, Loss: 0.5520987478539477\n",
      "Epoch 36, Loss: 0.5510241737064957\n",
      "Epoch 37, Loss: 0.5497367640762887\n",
      "Epoch 38, Loss: 0.548206262121511\n",
      "Epoch 39, Loss: 0.5464152174430053\n",
      "Epoch 40, Loss: 0.5442905392037803\n",
      "Epoch 41, Loss: 0.5418540984877794\n",
      "Epoch 42, Loss: 0.5392008617687131\n",
      "Epoch 43, Loss: 0.5364890660738718\n",
      "Epoch 44, Loss: 0.5339085310880826\n",
      "Epoch 45, Loss: 0.5314374761203445\n",
      "Epoch 46, Loss: 0.5286688368980452\n",
      "Epoch 47, Loss: 0.5255968901458025\n",
      "Epoch 48, Loss: 0.522696326163375\n",
      "Epoch 49, Loss: 0.5200423401321188\n",
      "Epoch 50, Loss: 0.5176326794933259\n",
      "Epoch 51, Loss: 0.5152894575566689\n",
      "Epoch 52, Loss: 0.5132538287358613\n",
      "Epoch 53, Loss: 0.5112802796385807\n",
      "Epoch 54, Loss: 0.5094314298206105\n",
      "Epoch 55, Loss: 0.5075663630311871\n",
      "Epoch 56, Loss: 0.5054283809902947\n",
      "Epoch 57, Loss: 0.5031695044126765\n",
      "Epoch 58, Loss: 0.5010243889360235\n",
      "Epoch 59, Loss: 0.4989628465749647\n",
      "Epoch 60, Loss: 0.4968781315207017\n",
      "Epoch 61, Loss: 0.49487227904190095\n",
      "Epoch 62, Loss: 0.493142019855662\n",
      "Epoch 63, Loss: 0.49158119520175164\n",
      "Epoch 64, Loss: 0.48993290602404593\n",
      "Epoch 65, Loss: 0.48827038562131997\n",
      "Epoch 66, Loss: 0.4866639628427767\n",
      "Epoch 67, Loss: 0.4849569147675203\n",
      "Epoch 68, Loss: 0.48319021036564486\n",
      "Epoch 69, Loss: 0.48151869146960835\n",
      "Epoch 70, Loss: 0.4799200506981379\n",
      "Epoch 71, Loss: 0.47831186121199243\n",
      "Epoch 72, Loss: 0.47675168081526376\n",
      "Epoch 73, Loss: 0.4752162146371164\n",
      "Epoch 74, Loss: 0.47364088228567497\n",
      "Epoch 75, Loss: 0.47213206899318433\n",
      "Epoch 76, Loss: 0.47070208030996297\n",
      "Epoch 77, Loss: 0.4692504119098951\n",
      "Epoch 78, Loss: 0.46786545901567095\n",
      "Epoch 79, Loss: 0.4664533939528831\n",
      "Epoch 80, Loss: 0.46500852212992577\n",
      "Epoch 81, Loss: 0.463617470433033\n",
      "Epoch 82, Loss: 0.4622348373241077\n",
      "Epoch 83, Loss: 0.4609195899716644\n",
      "Epoch 84, Loss: 0.45966086348712576\n",
      "Epoch 85, Loss: 0.45843066641428165\n",
      "Epoch 86, Loss: 0.45727045369169067\n",
      "Epoch 87, Loss: 0.4561210273670036\n",
      "Epoch 88, Loss: 0.45500008892226135\n",
      "Epoch 89, Loss: 0.4538960637904586\n",
      "Epoch 90, Loss: 0.4528320121641733\n",
      "Epoch 91, Loss: 0.45181514245929494\n",
      "Epoch 92, Loss: 0.45085395411800483\n",
      "Epoch 93, Loss: 0.4499521488338468\n",
      "Epoch 94, Loss: 0.4490534602710762\n",
      "Epoch 95, Loss: 0.448148597138565\n",
      "Epoch 96, Loss: 0.447264558882463\n",
      "Epoch 97, Loss: 0.44640120218031354\n",
      "Epoch 98, Loss: 0.44554769428625335\n",
      "Epoch 99, Loss: 0.4447194550775146\n",
      "Epoch 100, Loss: 0.44392206388755956\n",
      "Epoch 101, Loss: 0.4431227502106666\n",
      "Epoch 102, Loss: 0.442314277375841\n",
      "Epoch 103, Loss: 0.4414359563773251\n",
      "Epoch 104, Loss: 0.44052649066413707\n",
      "Epoch 105, Loss: 0.4396374464249918\n",
      "Epoch 106, Loss: 0.4387893580582842\n",
      "Epoch 107, Loss: 0.4379831609352233\n",
      "Epoch 108, Loss: 0.4372221711694062\n",
      "Epoch 109, Loss: 0.43648670562564357\n",
      "Epoch 110, Loss: 0.4357567012324113\n",
      "Epoch 111, Loss: 0.4350060325237153\n",
      "Epoch 112, Loss: 0.43424118093870107\n",
      "Epoch 113, Loss: 0.43349689398492114\n",
      "Epoch 114, Loss: 0.4327565263711118\n",
      "Epoch 115, Loss: 0.43200230009958984\n",
      "Epoch 116, Loss: 0.4312323110518544\n",
      "Epoch 117, Loss: 0.4304595253954692\n",
      "Epoch 118, Loss: 0.42965987723601584\n",
      "Epoch 119, Loss: 0.42889634904394847\n",
      "Epoch 120, Loss: 0.4281134645620414\n",
      "Epoch 121, Loss: 0.42728763051438495\n",
      "Epoch 122, Loss: 0.42642174239371655\n",
      "Epoch 123, Loss: 0.42556296886631717\n",
      "Epoch 124, Loss: 0.42473870126650975\n",
      "Epoch 125, Loss: 0.4240021765749774\n",
      "Epoch 126, Loss: 0.4232613425855825\n",
      "Epoch 127, Loss: 0.4225971610742545\n",
      "Epoch 128, Loss: 0.42202478857930537\n",
      "Epoch 129, Loss: 0.42138279352757935\n",
      "Epoch 130, Loss: 0.4203032425211922\n",
      "Epoch 131, Loss: 0.4194173576578691\n",
      "Epoch 132, Loss: 0.41897051186346557\n",
      "Epoch 133, Loss: 0.4182748832118333\n",
      "Epoch 134, Loss: 0.4173121062650104\n",
      "Epoch 135, Loss: 0.4167786348422024\n",
      "Epoch 136, Loss: 0.41633137285594574\n",
      "Epoch 137, Loss: 0.4155861513725481\n",
      "Epoch 138, Loss: 0.41480911167744433\n",
      "Epoch 139, Loss: 0.4143793225530425\n",
      "Epoch 140, Loss: 0.4139146360856081\n",
      "Epoch 141, Loss: 0.4131360936659178\n",
      "Epoch 142, Loss: 0.4122899821309506\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.23043447549460608\n",
      "Test R^2 score: 0.4209293460465778\n",
      "Num of epochs: 143\n",
      "Epoch 1, Loss: 0.5568695935929859\n",
      "Epoch 2, Loss: 0.5565888497885066\n",
      "Epoch 3, Loss: 0.5563834683886458\n",
      "Epoch 4, Loss: 0.5562487645081933\n",
      "Epoch 5, Loss: 0.5561790828288683\n",
      "Epoch 6, Loss: 0.556161399814465\n",
      "Epoch 7, Loss: 0.5561778503945759\n",
      "Epoch 8, Loss: 0.5562101339134414\n",
      "Epoch 9, Loss: 0.5562332268661291\n",
      "Epoch 10, Loss: 0.5562377542583657\n",
      "Epoch 11, Loss: 0.5562193229874232\n",
      "Epoch 12, Loss: 0.5561815476892601\n",
      "Epoch 13, Loss: 0.5561307479242392\n",
      "Epoch 14, Loss: 0.5560725207562636\n",
      "Epoch 15, Loss: 0.5560108034847582\n",
      "Epoch 16, Loss: 0.5559466134707971\n",
      "Epoch 17, Loss: 0.5558782610496288\n",
      "Epoch 18, Loss: 0.5558016159277092\n",
      "Epoch 19, Loss: 0.5557106146059017\n",
      "Epoch 20, Loss: 0.555598357326724\n",
      "Epoch 21, Loss: 0.5554562198389912\n",
      "Epoch 22, Loss: 0.5552761554148331\n",
      "Epoch 23, Loss: 0.555048247680221\n",
      "Epoch 24, Loss: 0.5547666627514009\n",
      "Epoch 25, Loss: 0.5544247071905241\n",
      "Epoch 26, Loss: 0.5540094933109587\n",
      "Epoch 27, Loss: 0.5535059150700214\n",
      "Epoch 28, Loss: 0.5529006061027656\n",
      "Epoch 29, Loss: 0.5521726685946317\n",
      "Epoch 30, Loss: 0.5513020481355272\n",
      "Epoch 31, Loss: 0.5502747716323582\n",
      "Epoch 32, Loss: 0.5490877345218445\n",
      "Epoch 33, Loss: 0.5477487940285316\n",
      "Epoch 34, Loss: 0.5463097784910461\n",
      "Epoch 35, Loss: 0.5447855679794898\n",
      "Epoch 36, Loss: 0.5431421675344796\n",
      "Epoch 37, Loss: 0.5413392954458488\n",
      "Epoch 38, Loss: 0.5393236053133303\n",
      "Epoch 39, Loss: 0.5370487248249931\n",
      "Epoch 40, Loss: 0.5344604646925691\n",
      "Epoch 41, Loss: 0.5315662452525446\n",
      "Epoch 42, Loss: 0.528283391145408\n",
      "Epoch 43, Loss: 0.5245730764594746\n",
      "Epoch 44, Loss: 0.5205062665791126\n",
      "Epoch 45, Loss: 0.5160624642378472\n",
      "Epoch 46, Loss: 0.5113337284069616\n",
      "Epoch 47, Loss: 0.5062822908534774\n",
      "Epoch 48, Loss: 0.5009946764074948\n",
      "Epoch 49, Loss: 0.49584803165427077\n",
      "Epoch 50, Loss: 0.49147043521573014\n",
      "Epoch 51, Loss: 0.4885420598622945\n",
      "Epoch 52, Loss: 0.4864951463557199\n",
      "Epoch 53, Loss: 0.4835420183358262\n",
      "Epoch 54, Loss: 0.4792347078803849\n",
      "Epoch 55, Loss: 0.47471419695680384\n",
      "Epoch 56, Loss: 0.47091766470060414\n",
      "Epoch 57, Loss: 0.4680591260350624\n",
      "Epoch 58, Loss: 0.4661683515796255\n",
      "Epoch 59, Loss: 0.46499770684343356\n",
      "Epoch 60, Loss: 0.46420803998869337\n",
      "Epoch 61, Loss: 0.4635596289708451\n",
      "Epoch 62, Loss: 0.46296119956722687\n",
      "Epoch 63, Loss: 0.46233327927872153\n",
      "Epoch 64, Loss: 0.4616168398627828\n",
      "Epoch 65, Loss: 0.46094281791593494\n",
      "Epoch 66, Loss: 0.46019711272532987\n",
      "Epoch 67, Loss: 0.4593868357891776\n",
      "Epoch 68, Loss: 0.4585447762901084\n",
      "Epoch 69, Loss: 0.45750593330100414\n",
      "Epoch 70, Loss: 0.45658866123284997\n",
      "Epoch 71, Loss: 0.4557752222676729\n",
      "Epoch 72, Loss: 0.45499119726510917\n",
      "Epoch 73, Loss: 0.4542986370390344\n",
      "Epoch 74, Loss: 0.45358732906873106\n",
      "Epoch 75, Loss: 0.45282128448600517\n",
      "Epoch 76, Loss: 0.45201878511692345\n",
      "Epoch 77, Loss: 0.451206437145343\n",
      "Epoch 78, Loss: 0.4504289827447978\n",
      "Epoch 79, Loss: 0.44965416082842924\n",
      "Epoch 80, Loss: 0.44878236887659334\n",
      "Epoch 81, Loss: 0.4479145356800339\n",
      "Epoch 82, Loss: 0.44709191426376027\n",
      "Epoch 83, Loss: 0.4462022091682184\n",
      "Epoch 84, Loss: 0.4452494693787212\n",
      "Epoch 85, Loss: 0.44430716285177674\n",
      "Epoch 86, Loss: 0.44345036383822634\n",
      "Epoch 87, Loss: 0.44257539174245125\n",
      "Epoch 88, Loss: 0.4416749355903639\n",
      "Epoch 89, Loss: 0.44082845157247075\n",
      "Epoch 90, Loss: 0.4400388925063562\n",
      "Epoch 91, Loss: 0.43929542254974935\n",
      "Epoch 92, Loss: 0.43859117535038267\n",
      "Epoch 93, Loss: 0.4377922886901243\n",
      "Epoch 94, Loss: 0.43691065807832286\n",
      "Epoch 95, Loss: 0.43611882379957895\n",
      "Epoch 96, Loss: 0.435429698423579\n",
      "Epoch 97, Loss: 0.43477894778887255\n",
      "Epoch 98, Loss: 0.43402226211434014\n",
      "Epoch 99, Loss: 0.4331796060133749\n",
      "Epoch 100, Loss: 0.4324215345372735\n",
      "Epoch 101, Loss: 0.43172835412182387\n",
      "Epoch 102, Loss: 0.4309475888847922\n",
      "Epoch 103, Loss: 0.43012073524043665\n",
      "Epoch 104, Loss: 0.429295655961254\n",
      "Epoch 105, Loss: 0.42853547765737926\n",
      "Epoch 106, Loss: 0.427809826192588\n",
      "Epoch 107, Loss: 0.4270923621301032\n",
      "Epoch 108, Loss: 0.42642214425707375\n",
      "Epoch 109, Loss: 0.42577918515885865\n",
      "Epoch 110, Loss: 0.4252812310579772\n",
      "Epoch 111, Loss: 0.4248063536863427\n",
      "Epoch 112, Loss: 0.4240869707315232\n",
      "Epoch 113, Loss: 0.4230070995395608\n",
      "Epoch 114, Loss: 0.422260002783401\n",
      "Epoch 115, Loss: 0.42187213896734943\n",
      "Epoch 116, Loss: 0.4211411097404202\n",
      "Epoch 117, Loss: 0.4202206989991207\n",
      "Epoch 118, Loss: 0.41957688465232684\n",
      "Epoch 119, Loss: 0.419198837575138\n",
      "Epoch 120, Loss: 0.41856000205335997\n",
      "Epoch 121, Loss: 0.4176603231006672\n",
      "Epoch 122, Loss: 0.4169867557645353\n",
      "Epoch 123, Loss: 0.41661610495236234\n",
      "Epoch 124, Loss: 0.4161686682931146\n",
      "Epoch 125, Loss: 0.4154367135139322\n",
      "Epoch 126, Loss: 0.414652925270293\n",
      "Epoch 127, Loss: 0.41413544066371555\n",
      "Epoch 128, Loss: 0.413815028534484\n",
      "Epoch 129, Loss: 0.4133761673730009\n",
      "Epoch 130, Loss: 0.4127316409729362\n",
      "Epoch 131, Loss: 0.41193386155103\n",
      "Epoch 132, Loss: 0.4112462772908176\n",
      "Epoch 133, Loss: 0.4107066684662195\n",
      "Epoch 134, Loss: 0.41033346798060727\n",
      "Epoch 135, Loss: 0.4103007652365298\n",
      "Epoch 136, Loss: 0.41043399307869516\n",
      "Epoch 137, Loss: 0.41011811942014537\n",
      "Epoch 138, Loss: 0.4084121497473369\n",
      "Epoch 139, Loss: 0.40769669726528496\n",
      "Epoch 140, Loss: 0.40815219835256894\n",
      "Epoch 141, Loss: 0.4072383631910634\n",
      "Epoch 142, Loss: 0.40609035656381937\n",
      "Epoch 143, Loss: 0.40597346871110324\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22245152219858835\n",
      "Test R^2 score: 0.46529451088821633\n",
      "Num of epochs: 144\n",
      "Epoch 1, Loss: 0.5639339289923673\n",
      "Epoch 2, Loss: 0.5625848441245176\n",
      "Epoch 3, Loss: 0.5613810483105094\n",
      "Epoch 4, Loss: 0.5603020163138781\n",
      "Epoch 5, Loss: 0.5593427957822573\n",
      "Epoch 6, Loss: 0.5585501060241921\n",
      "Epoch 7, Loss: 0.5578847533802326\n",
      "Epoch 8, Loss: 0.5573284784678607\n",
      "Epoch 9, Loss: 0.556899402096606\n",
      "Epoch 10, Loss: 0.5565771233995223\n",
      "Epoch 11, Loss: 0.5563434543755611\n",
      "Epoch 12, Loss: 0.5562076959703732\n",
      "Epoch 13, Loss: 0.5561293546163604\n",
      "Epoch 14, Loss: 0.5561004158943156\n",
      "Epoch 15, Loss: 0.5561047567986248\n",
      "Epoch 16, Loss: 0.556119119055313\n",
      "Epoch 17, Loss: 0.5561310158676619\n",
      "Epoch 18, Loss: 0.5561357852389851\n",
      "Epoch 19, Loss: 0.5561249335201719\n",
      "Epoch 20, Loss: 0.5560867498631963\n",
      "Epoch 21, Loss: 0.5560124114901659\n",
      "Epoch 22, Loss: 0.5558977222417921\n",
      "Epoch 23, Loss: 0.5557432202102806\n",
      "Epoch 24, Loss: 0.5555486039547979\n",
      "Epoch 25, Loss: 0.555311550425081\n",
      "Epoch 26, Loss: 0.5550317367724259\n",
      "Epoch 27, Loss: 0.554697842568699\n",
      "Epoch 28, Loss: 0.5542929952323037\n",
      "Epoch 29, Loss: 0.5537884908521035\n",
      "Epoch 30, Loss: 0.5531466668405858\n",
      "Epoch 31, Loss: 0.5523336191071113\n",
      "Epoch 32, Loss: 0.5513110487300089\n",
      "Epoch 33, Loss: 0.5500307854792998\n",
      "Epoch 34, Loss: 0.5484328288778719\n",
      "Epoch 35, Loss: 0.5464401423540817\n",
      "Epoch 36, Loss: 0.5439555031936444\n",
      "Epoch 37, Loss: 0.5409011719756389\n",
      "Epoch 38, Loss: 0.5372301278058075\n",
      "Epoch 39, Loss: 0.5329578660017469\n",
      "Epoch 40, Loss: 0.5281117815699701\n",
      "Epoch 41, Loss: 0.5230046945419555\n",
      "Epoch 42, Loss: 0.5183449301183887\n",
      "Epoch 43, Loss: 0.5151385411234798\n",
      "Epoch 44, Loss: 0.513651539215081\n",
      "Epoch 45, Loss: 0.5118371666328201\n",
      "Epoch 46, Loss: 0.508132950836701\n",
      "Epoch 47, Loss: 0.5035563888207389\n",
      "Epoch 48, Loss: 0.4997736299203749\n",
      "Epoch 49, Loss: 0.4975314446436859\n",
      "Epoch 50, Loss: 0.4964786298105782\n",
      "Epoch 51, Loss: 0.49538603937697456\n",
      "Epoch 52, Loss: 0.4935923312542056\n",
      "Epoch 53, Loss: 0.4912768825911715\n",
      "Epoch 54, Loss: 0.4890020010093984\n",
      "Epoch 55, Loss: 0.48730404534612937\n",
      "Epoch 56, Loss: 0.4862566975914367\n",
      "Epoch 57, Loss: 0.48530566115513407\n",
      "Epoch 58, Loss: 0.48383929254057545\n",
      "Epoch 59, Loss: 0.4819329444393897\n",
      "Epoch 60, Loss: 0.48004157762957356\n",
      "Epoch 61, Loss: 0.4785426229529098\n",
      "Epoch 62, Loss: 0.47736197778640804\n",
      "Epoch 63, Loss: 0.47616418233013524\n",
      "Epoch 64, Loss: 0.47475569239614146\n",
      "Epoch 65, Loss: 0.4730683098999594\n",
      "Epoch 66, Loss: 0.47131010942064033\n",
      "Epoch 67, Loss: 0.46975734871521024\n",
      "Epoch 68, Loss: 0.4684621244833185\n",
      "Epoch 69, Loss: 0.4670222548342504\n",
      "Epoch 70, Loss: 0.46541630721298904\n",
      "Epoch 71, Loss: 0.464100572199552\n",
      "Epoch 72, Loss: 0.4632504830911159\n",
      "Epoch 73, Loss: 0.4624992518805562\n",
      "Epoch 74, Loss: 0.4615393766216841\n",
      "Epoch 75, Loss: 0.4605860582658391\n",
      "Epoch 76, Loss: 0.45990440199384086\n",
      "Epoch 77, Loss: 0.4591163607811956\n",
      "Epoch 78, Loss: 0.4580717713162964\n",
      "Epoch 79, Loss: 0.4572002391904671\n",
      "Epoch 80, Loss: 0.4564369119271861\n",
      "Epoch 81, Loss: 0.45551879568608883\n",
      "Epoch 82, Loss: 0.45468785983985743\n",
      "Epoch 83, Loss: 0.45407040396818893\n",
      "Epoch 84, Loss: 0.45336217263762185\n",
      "Epoch 85, Loss: 0.4526586270097098\n",
      "Epoch 86, Loss: 0.4521255816950812\n",
      "Epoch 87, Loss: 0.4515155457632775\n",
      "Epoch 88, Loss: 0.45080799439956687\n",
      "Epoch 89, Loss: 0.45019835762764876\n",
      "Epoch 90, Loss: 0.449550605598545\n",
      "Epoch 91, Loss: 0.44884935201011916\n",
      "Epoch 92, Loss: 0.4482629808577089\n",
      "Epoch 93, Loss: 0.44759012303091\n",
      "Epoch 94, Loss: 0.4469226038193039\n",
      "Epoch 95, Loss: 0.4463142872031914\n",
      "Epoch 96, Loss: 0.4456386208559227\n",
      "Epoch 97, Loss: 0.4450734483989773\n",
      "Epoch 98, Loss: 0.4444116716504153\n",
      "Epoch 99, Loss: 0.44380594021830244\n",
      "Epoch 100, Loss: 0.4431624122074447\n",
      "Epoch 101, Loss: 0.44249430887150926\n",
      "Epoch 102, Loss: 0.4418766924381893\n",
      "Epoch 103, Loss: 0.441195226544101\n",
      "Epoch 104, Loss: 0.44059357903096596\n",
      "Epoch 105, Loss: 0.4399131909805372\n",
      "Epoch 106, Loss: 0.43928300743731136\n",
      "Epoch 107, Loss: 0.4386228899216034\n",
      "Epoch 108, Loss: 0.43799302726904477\n",
      "Epoch 109, Loss: 0.4373384926913705\n",
      "Epoch 110, Loss: 0.4366974451808827\n",
      "Epoch 111, Loss: 0.4360516620856698\n",
      "Epoch 112, Loss: 0.4354165570777621\n",
      "Epoch 113, Loss: 0.4347882356616451\n",
      "Epoch 114, Loss: 0.43417583949502714\n",
      "Epoch 115, Loss: 0.4335287234372193\n",
      "Epoch 116, Loss: 0.4328918446274261\n",
      "Epoch 117, Loss: 0.43223318792161586\n",
      "Epoch 118, Loss: 0.43161033075274674\n",
      "Epoch 119, Loss: 0.4309892356694443\n",
      "Epoch 120, Loss: 0.43036698455614636\n",
      "Epoch 121, Loss: 0.42974513274272036\n",
      "Epoch 122, Loss: 0.4291113024558136\n",
      "Epoch 123, Loss: 0.42846147582833766\n",
      "Epoch 124, Loss: 0.42782851276287487\n",
      "Epoch 125, Loss: 0.42720457038733944\n",
      "Epoch 126, Loss: 0.42655742837874216\n",
      "Epoch 127, Loss: 0.42591047513314373\n",
      "Epoch 128, Loss: 0.42526388671107107\n",
      "Epoch 129, Loss: 0.42460501351875757\n",
      "Epoch 130, Loss: 0.42395425493057937\n",
      "Epoch 131, Loss: 0.4232931672337605\n",
      "Epoch 132, Loss: 0.4226455539048016\n",
      "Epoch 133, Loss: 0.42199502226641794\n",
      "Epoch 134, Loss: 0.42132741216807557\n",
      "Epoch 135, Loss: 0.42066883808138295\n",
      "Epoch 136, Loss: 0.4200938914857158\n",
      "Epoch 137, Loss: 0.41984319615158955\n",
      "Epoch 138, Loss: 0.4198291410027615\n",
      "Epoch 139, Loss: 0.4184470781992104\n",
      "Epoch 140, Loss: 0.41773944875198177\n",
      "Epoch 141, Loss: 0.4177693934376405\n",
      "Epoch 142, Loss: 0.4164742641477509\n",
      "Epoch 143, Loss: 0.41622419904528346\n",
      "Epoch 144, Loss: 0.4158057995544039\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21910744885548825\n",
      "Test R^2 score: 0.48187224288097885\n",
      "Num of epochs: 145\n",
      "Epoch 1, Loss: 0.5675447531627573\n",
      "Epoch 2, Loss: 0.5659623083430794\n",
      "Epoch 3, Loss: 0.564546385983704\n",
      "Epoch 4, Loss: 0.5632751739639841\n",
      "Epoch 5, Loss: 0.562147692447328\n",
      "Epoch 6, Loss: 0.5611552217060594\n",
      "Epoch 7, Loss: 0.5602917505986998\n",
      "Epoch 8, Loss: 0.5595539616564265\n",
      "Epoch 9, Loss: 0.5589244637149033\n",
      "Epoch 10, Loss: 0.5584034095267942\n",
      "Epoch 11, Loss: 0.5579822901629431\n",
      "Epoch 12, Loss: 0.5576355725679746\n",
      "Epoch 13, Loss: 0.5573532094278361\n",
      "Epoch 14, Loss: 0.557126873524173\n",
      "Epoch 15, Loss: 0.5569482856590543\n",
      "Epoch 16, Loss: 0.5568095971349849\n",
      "Epoch 17, Loss: 0.5567285033342458\n",
      "Epoch 18, Loss: 0.5566693750285128\n",
      "Epoch 19, Loss: 0.5566230369600075\n",
      "Epoch 20, Loss: 0.5565848874746595\n",
      "Epoch 21, Loss: 0.5565512334421137\n",
      "Epoch 22, Loss: 0.5565192642424943\n",
      "Epoch 23, Loss: 0.5564871860975658\n",
      "Epoch 24, Loss: 0.556453847501672\n",
      "Epoch 25, Loss: 0.5564189000822115\n",
      "Epoch 26, Loss: 0.5563823435360247\n",
      "Epoch 27, Loss: 0.5563446328749088\n",
      "Epoch 28, Loss: 0.5563063303681728\n",
      "Epoch 29, Loss: 0.5562678109221395\n",
      "Epoch 30, Loss: 0.5562295567045493\n",
      "Epoch 31, Loss: 0.556191728518618\n",
      "Epoch 32, Loss: 0.5561542192784168\n",
      "Epoch 33, Loss: 0.5561166003281622\n",
      "Epoch 34, Loss: 0.5560775318015571\n",
      "Epoch 35, Loss: 0.556035619850291\n",
      "Epoch 36, Loss: 0.5559874064799687\n",
      "Epoch 37, Loss: 0.555930692128209\n",
      "Epoch 38, Loss: 0.5558644019065124\n",
      "Epoch 39, Loss: 0.5557837600372492\n",
      "Epoch 40, Loss: 0.5556874463033388\n",
      "Epoch 41, Loss: 0.5555690690887197\n",
      "Epoch 42, Loss: 0.5554186340987818\n",
      "Epoch 43, Loss: 0.5552258095725364\n",
      "Epoch 44, Loss: 0.554967997375765\n",
      "Epoch 45, Loss: 0.5546009372274058\n",
      "Epoch 46, Loss: 0.5540637955755329\n",
      "Epoch 47, Loss: 0.55334185858942\n",
      "Epoch 48, Loss: 0.5525041242160751\n",
      "Epoch 49, Loss: 0.5515360698905417\n",
      "Epoch 50, Loss: 0.5504454542780565\n",
      "Epoch 51, Loss: 0.5491921517455247\n",
      "Epoch 52, Loss: 0.5477041770435888\n",
      "Epoch 53, Loss: 0.5459098746478414\n",
      "Epoch 54, Loss: 0.5437540098020536\n",
      "Epoch 55, Loss: 0.5412335008745043\n",
      "Epoch 56, Loss: 0.5382523184255518\n",
      "Epoch 57, Loss: 0.5347298085581439\n",
      "Epoch 58, Loss: 0.5307734820651222\n",
      "Epoch 59, Loss: 0.526533705606077\n",
      "Epoch 60, Loss: 0.522328925166287\n",
      "Epoch 61, Loss: 0.5186673776483607\n",
      "Epoch 62, Loss: 0.5156052614537687\n",
      "Epoch 63, Loss: 0.5124731254509484\n",
      "Epoch 64, Loss: 0.5096508203776623\n",
      "Epoch 65, Loss: 0.5075924616710826\n",
      "Epoch 66, Loss: 0.505895782692307\n",
      "Epoch 67, Loss: 0.5039665718346142\n",
      "Epoch 68, Loss: 0.5015268259641877\n",
      "Epoch 69, Loss: 0.498626581041761\n",
      "Epoch 70, Loss: 0.49536881833643753\n",
      "Epoch 71, Loss: 0.49203756864384585\n",
      "Epoch 72, Loss: 0.48896950090406377\n",
      "Epoch 73, Loss: 0.4863038114421899\n",
      "Epoch 74, Loss: 0.484017209223929\n",
      "Epoch 75, Loss: 0.48178546642728126\n",
      "Epoch 76, Loss: 0.4792959429320683\n",
      "Epoch 77, Loss: 0.47653431105495175\n",
      "Epoch 78, Loss: 0.47387385576150776\n",
      "Epoch 79, Loss: 0.4713707617126849\n",
      "Epoch 80, Loss: 0.4689241244841227\n",
      "Epoch 81, Loss: 0.46686508765671064\n",
      "Epoch 82, Loss: 0.4651561937213591\n",
      "Epoch 83, Loss: 0.4637513507967296\n",
      "Epoch 84, Loss: 0.4627132639335272\n",
      "Epoch 85, Loss: 0.4618719618081812\n",
      "Epoch 86, Loss: 0.46096229486534074\n",
      "Epoch 87, Loss: 0.45986415873484515\n",
      "Epoch 88, Loss: 0.45867939008047637\n",
      "Epoch 89, Loss: 0.4576220972479146\n",
      "Epoch 90, Loss: 0.45673760329859514\n",
      "Epoch 91, Loss: 0.45592397250108696\n",
      "Epoch 92, Loss: 0.4551867735999797\n",
      "Epoch 93, Loss: 0.454605708680264\n",
      "Epoch 94, Loss: 0.4540851549035132\n",
      "Epoch 95, Loss: 0.4535869184210183\n",
      "Epoch 96, Loss: 0.45302463932796627\n",
      "Epoch 97, Loss: 0.4524330084038024\n",
      "Epoch 98, Loss: 0.451867941409496\n",
      "Epoch 99, Loss: 0.45132293484242314\n",
      "Epoch 100, Loss: 0.45073903777025925\n",
      "Epoch 101, Loss: 0.4501160657399117\n",
      "Epoch 102, Loss: 0.4494915175555179\n",
      "Epoch 103, Loss: 0.44888981925512017\n",
      "Epoch 104, Loss: 0.44831136198815436\n",
      "Epoch 105, Loss: 0.4477472502401955\n",
      "Epoch 106, Loss: 0.4472100668970446\n",
      "Epoch 107, Loss: 0.446696039525185\n",
      "Epoch 108, Loss: 0.4461531317315276\n",
      "Epoch 109, Loss: 0.4455501859014477\n",
      "Epoch 110, Loss: 0.44494590392966016\n",
      "Epoch 111, Loss: 0.4444582760251354\n",
      "Epoch 112, Loss: 0.4439921296083691\n",
      "Epoch 113, Loss: 0.44349654844246217\n",
      "Epoch 114, Loss: 0.4429681707307772\n",
      "Epoch 115, Loss: 0.4424705334189712\n",
      "Epoch 116, Loss: 0.44201771404944923\n",
      "Epoch 117, Loss: 0.44156410972911936\n",
      "Epoch 118, Loss: 0.44106373959486456\n",
      "Epoch 119, Loss: 0.44053531910960697\n",
      "Epoch 120, Loss: 0.4400098368509639\n",
      "Epoch 121, Loss: 0.4394929147296775\n",
      "Epoch 122, Loss: 0.4389579696032166\n",
      "Epoch 123, Loss: 0.43840216534377396\n",
      "Epoch 124, Loss: 0.4377961859158329\n",
      "Epoch 125, Loss: 0.43717039839676086\n",
      "Epoch 126, Loss: 0.4365784783193814\n",
      "Epoch 127, Loss: 0.4360088583949695\n",
      "Epoch 128, Loss: 0.43542047556742836\n",
      "Epoch 129, Loss: 0.4348300800374804\n",
      "Epoch 130, Loss: 0.4342330824280368\n",
      "Epoch 131, Loss: 0.43360533140369384\n",
      "Epoch 132, Loss: 0.43293373461914636\n",
      "Epoch 133, Loss: 0.4322751245052941\n",
      "Epoch 134, Loss: 0.43165869696574005\n",
      "Epoch 135, Loss: 0.4310577565314238\n",
      "Epoch 136, Loss: 0.430476245018707\n",
      "Epoch 137, Loss: 0.4298850905666972\n",
      "Epoch 138, Loss: 0.42928690877076797\n",
      "Epoch 139, Loss: 0.42869699929070115\n",
      "Epoch 140, Loss: 0.428079544215964\n",
      "Epoch 141, Loss: 0.42744734029853826\n",
      "Epoch 142, Loss: 0.4268049480324807\n",
      "Epoch 143, Loss: 0.4261582306828926\n",
      "Epoch 144, Loss: 0.42555011810361154\n",
      "Epoch 145, Loss: 0.4249536538098177\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21252622925747983\n",
      "Test R^2 score: 0.509805665322846\n",
      "Num of epochs: 146\n",
      "Epoch 1, Loss: 0.5912403473660917\n",
      "Epoch 2, Loss: 0.5881893628258837\n",
      "Epoch 3, Loss: 0.5853001497822148\n",
      "Epoch 4, Loss: 0.5826490311036041\n",
      "Epoch 5, Loss: 0.580119173286568\n",
      "Epoch 6, Loss: 0.5777226671911553\n",
      "Epoch 7, Loss: 0.5754202644084667\n",
      "Epoch 8, Loss: 0.5732639964957406\n",
      "Epoch 9, Loss: 0.5712294849075942\n",
      "Epoch 10, Loss: 0.5693195530413383\n",
      "Epoch 11, Loss: 0.5675503980633688\n",
      "Epoch 12, Loss: 0.5659153883104187\n",
      "Epoch 13, Loss: 0.564419913717351\n",
      "Epoch 14, Loss: 0.5630717021348126\n",
      "Epoch 15, Loss: 0.5618579962494505\n",
      "Epoch 16, Loss: 0.560776002423044\n",
      "Epoch 17, Loss: 0.559823795977628\n",
      "Epoch 18, Loss: 0.5589949227650132\n",
      "Epoch 19, Loss: 0.558286862669436\n",
      "Epoch 20, Loss: 0.5576942510849258\n",
      "Epoch 21, Loss: 0.5572044328051816\n",
      "Epoch 22, Loss: 0.556820221421252\n",
      "Epoch 23, Loss: 0.5565126238433905\n",
      "Epoch 24, Loss: 0.5562826779228653\n",
      "Epoch 25, Loss: 0.5560496891119991\n",
      "Epoch 26, Loss: 0.5557881570364864\n",
      "Epoch 27, Loss: 0.5555187229688888\n",
      "Epoch 28, Loss: 0.5552206566488499\n",
      "Epoch 29, Loss: 0.5548740395668484\n",
      "Epoch 30, Loss: 0.5544385485690259\n",
      "Epoch 31, Loss: 0.5539060111105851\n",
      "Epoch 32, Loss: 0.5532299287053715\n",
      "Epoch 33, Loss: 0.5523407144206802\n",
      "Epoch 34, Loss: 0.5511807014520997\n",
      "Epoch 35, Loss: 0.5496934741000805\n",
      "Epoch 36, Loss: 0.5478299658559356\n",
      "Epoch 37, Loss: 0.5455590627970401\n",
      "Epoch 38, Loss: 0.5428627239967567\n",
      "Epoch 39, Loss: 0.539865393418668\n",
      "Epoch 40, Loss: 0.5368516338268458\n",
      "Epoch 41, Loss: 0.5343420141200709\n",
      "Epoch 42, Loss: 0.5327546745535575\n",
      "Epoch 43, Loss: 0.5315131489373393\n",
      "Epoch 44, Loss: 0.5292699321350501\n",
      "Epoch 45, Loss: 0.5261043253176457\n",
      "Epoch 46, Loss: 0.5231718271642433\n",
      "Epoch 47, Loss: 0.5210600423133764\n",
      "Epoch 48, Loss: 0.5195719193910582\n",
      "Epoch 49, Loss: 0.5181132878727219\n",
      "Epoch 50, Loss: 0.5162836261078317\n",
      "Epoch 51, Loss: 0.5140248235560188\n",
      "Epoch 52, Loss: 0.5114793581503149\n",
      "Epoch 53, Loss: 0.5089256118028672\n",
      "Epoch 54, Loss: 0.5066578576091799\n",
      "Epoch 55, Loss: 0.5047049587288838\n",
      "Epoch 56, Loss: 0.5027969629650453\n",
      "Epoch 57, Loss: 0.5009043680563002\n",
      "Epoch 58, Loss: 0.4992820383230302\n",
      "Epoch 59, Loss: 0.49788125968348207\n",
      "Epoch 60, Loss: 0.49643522810172985\n",
      "Epoch 61, Loss: 0.4947376037642654\n",
      "Epoch 62, Loss: 0.49285149063843925\n",
      "Epoch 63, Loss: 0.49110006366570863\n",
      "Epoch 64, Loss: 0.4896940315848034\n",
      "Epoch 65, Loss: 0.48842958867358793\n",
      "Epoch 66, Loss: 0.48697247390091886\n",
      "Epoch 67, Loss: 0.4853900610163599\n",
      "Epoch 68, Loss: 0.4838978047260611\n",
      "Epoch 69, Loss: 0.48239948050841075\n",
      "Epoch 70, Loss: 0.4808120586502824\n",
      "Epoch 71, Loss: 0.47928669366072546\n",
      "Epoch 72, Loss: 0.47798415272372\n",
      "Epoch 73, Loss: 0.47671137501161037\n",
      "Epoch 74, Loss: 0.475275647341746\n",
      "Epoch 75, Loss: 0.47392369412729596\n",
      "Epoch 76, Loss: 0.47276738334157564\n",
      "Epoch 77, Loss: 0.47170357021738\n",
      "Epoch 78, Loss: 0.47061301987434456\n",
      "Epoch 79, Loss: 0.46955605185915233\n",
      "Epoch 80, Loss: 0.46848610761313353\n",
      "Epoch 81, Loss: 0.4673470164203673\n",
      "Epoch 82, Loss: 0.4662707887673405\n",
      "Epoch 83, Loss: 0.4652529125860387\n",
      "Epoch 84, Loss: 0.46415377146388453\n",
      "Epoch 85, Loss: 0.4630074816288816\n",
      "Epoch 86, Loss: 0.4619366275364664\n",
      "Epoch 87, Loss: 0.4609088888825392\n",
      "Epoch 88, Loss: 0.4598394990880729\n",
      "Epoch 89, Loss: 0.45880011248445834\n",
      "Epoch 90, Loss: 0.45783160303249687\n",
      "Epoch 91, Loss: 0.45698613979369124\n",
      "Epoch 92, Loss: 0.45634834914804856\n",
      "Epoch 93, Loss: 0.4558389549617732\n",
      "Epoch 94, Loss: 0.45523669382201654\n",
      "Epoch 95, Loss: 0.4545505396060009\n",
      "Epoch 96, Loss: 0.45379679307233195\n",
      "Epoch 97, Loss: 0.4530627273651618\n",
      "Epoch 98, Loss: 0.4523016256111311\n",
      "Epoch 99, Loss: 0.4514855784598023\n",
      "Epoch 100, Loss: 0.4506809651968732\n",
      "Epoch 101, Loss: 0.44997357516056546\n",
      "Epoch 102, Loss: 0.44935310676521983\n",
      "Epoch 103, Loss: 0.4487560709061836\n",
      "Epoch 104, Loss: 0.44814759962270484\n",
      "Epoch 105, Loss: 0.44750322252850117\n",
      "Epoch 106, Loss: 0.4468125626487544\n",
      "Epoch 107, Loss: 0.44613496219246357\n",
      "Epoch 108, Loss: 0.44550172232178276\n",
      "Epoch 109, Loss: 0.44487561997737274\n",
      "Epoch 110, Loss: 0.44424611954934357\n",
      "Epoch 111, Loss: 0.4436345695749003\n",
      "Epoch 112, Loss: 0.4430436173670563\n",
      "Epoch 113, Loss: 0.4424605816994361\n",
      "Epoch 114, Loss: 0.44187670929941003\n",
      "Epoch 115, Loss: 0.4412725296698697\n",
      "Epoch 116, Loss: 0.44066018376665095\n",
      "Epoch 117, Loss: 0.44005646719885816\n",
      "Epoch 118, Loss: 0.439469587229634\n",
      "Epoch 119, Loss: 0.4388821092147675\n",
      "Epoch 120, Loss: 0.4382817572660452\n",
      "Epoch 121, Loss: 0.4376706233417129\n",
      "Epoch 122, Loss: 0.43705118523233966\n",
      "Epoch 123, Loss: 0.4364197371024411\n",
      "Epoch 124, Loss: 0.435791391751851\n",
      "Epoch 125, Loss: 0.4351530646818818\n",
      "Epoch 126, Loss: 0.43454358308004787\n",
      "Epoch 127, Loss: 0.4339492817998596\n",
      "Epoch 128, Loss: 0.43335328866175754\n",
      "Epoch 129, Loss: 0.4327484689439722\n",
      "Epoch 130, Loss: 0.4321308545429685\n",
      "Epoch 131, Loss: 0.43152302654706404\n",
      "Epoch 132, Loss: 0.43092630580667296\n",
      "Epoch 133, Loss: 0.43033085256874015\n",
      "Epoch 134, Loss: 0.4297315228192146\n",
      "Epoch 135, Loss: 0.42913396033253143\n",
      "Epoch 136, Loss: 0.4285212207800907\n",
      "Epoch 137, Loss: 0.4279196176950288\n",
      "Epoch 138, Loss: 0.4273306801033424\n",
      "Epoch 139, Loss: 0.42674786099980005\n",
      "Epoch 140, Loss: 0.42615992654332163\n",
      "Epoch 141, Loss: 0.42556851873512974\n",
      "Epoch 142, Loss: 0.4249699588985375\n",
      "Epoch 143, Loss: 0.4243676403795166\n",
      "Epoch 144, Loss: 0.42375092748242266\n",
      "Epoch 145, Loss: 0.4231322240283221\n",
      "Epoch 146, Loss: 0.4225185924592427\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21674608394852937\n",
      "Test R^2 score: 0.49238755747677476\n",
      "Num of epochs: 147\n",
      "Epoch 1, Loss: 0.5684431348608402\n",
      "Epoch 2, Loss: 0.5668302856104653\n",
      "Epoch 3, Loss: 0.5653209944171725\n",
      "Epoch 4, Loss: 0.5639174140042813\n",
      "Epoch 5, Loss: 0.5626208122638287\n",
      "Epoch 6, Loss: 0.5614388576331057\n",
      "Epoch 7, Loss: 0.5603745624320139\n",
      "Epoch 8, Loss: 0.5594308090074062\n",
      "Epoch 9, Loss: 0.5586083416933626\n",
      "Epoch 10, Loss: 0.5579051061101541\n",
      "Epoch 11, Loss: 0.557325510678917\n",
      "Epoch 12, Loss: 0.5568698879396906\n",
      "Epoch 13, Loss: 0.5565283678866865\n",
      "Epoch 14, Loss: 0.5562609800047997\n",
      "Epoch 15, Loss: 0.5560699750207687\n",
      "Epoch 16, Loss: 0.5559430754340705\n",
      "Epoch 17, Loss: 0.5558719346751333\n",
      "Epoch 18, Loss: 0.555833438742693\n",
      "Epoch 19, Loss: 0.5558048331442785\n",
      "Epoch 20, Loss: 0.5557633028089933\n",
      "Epoch 21, Loss: 0.5556873122247026\n",
      "Epoch 22, Loss: 0.555552251792727\n",
      "Epoch 23, Loss: 0.5553324804537995\n",
      "Epoch 24, Loss: 0.5550004586656067\n",
      "Epoch 25, Loss: 0.5545403459952509\n",
      "Epoch 26, Loss: 0.5539503975775985\n",
      "Epoch 27, Loss: 0.5531886091133905\n",
      "Epoch 28, Loss: 0.5522500332287925\n",
      "Epoch 29, Loss: 0.5511024836947853\n",
      "Epoch 30, Loss: 0.549711094101045\n",
      "Epoch 31, Loss: 0.548050896867064\n",
      "Epoch 32, Loss: 0.5460659582136183\n",
      "Epoch 33, Loss: 0.5436985682136946\n",
      "Epoch 34, Loss: 0.5408750826626408\n",
      "Epoch 35, Loss: 0.5376176960299758\n",
      "Epoch 36, Loss: 0.5340233945508209\n",
      "Epoch 37, Loss: 0.5303691686273263\n",
      "Epoch 38, Loss: 0.5272055268159319\n",
      "Epoch 39, Loss: 0.5251797391115355\n",
      "Epoch 40, Loss: 0.5240209658319546\n",
      "Epoch 41, Loss: 0.5220763885795234\n",
      "Epoch 42, Loss: 0.5188773780148868\n",
      "Epoch 43, Loss: 0.515475453740492\n",
      "Epoch 44, Loss: 0.5128384635531489\n",
      "Epoch 45, Loss: 0.5110156638176487\n",
      "Epoch 46, Loss: 0.5094531625327354\n",
      "Epoch 47, Loss: 0.5075997713982779\n",
      "Epoch 48, Loss: 0.5052819804622125\n",
      "Epoch 49, Loss: 0.502847875959256\n",
      "Epoch 50, Loss: 0.5006598648332237\n",
      "Epoch 51, Loss: 0.4989603081055534\n",
      "Epoch 52, Loss: 0.49752060255684766\n",
      "Epoch 53, Loss: 0.49584655911039427\n",
      "Epoch 54, Loss: 0.4939056561571152\n",
      "Epoch 55, Loss: 0.49209772532533663\n",
      "Epoch 56, Loss: 0.4905137257828273\n",
      "Epoch 57, Loss: 0.48893390524877733\n",
      "Epoch 58, Loss: 0.4873124391478202\n",
      "Epoch 59, Loss: 0.48570432066712727\n",
      "Epoch 60, Loss: 0.48423071219632785\n",
      "Epoch 61, Loss: 0.4827515097554491\n",
      "Epoch 62, Loss: 0.4810092800825368\n",
      "Epoch 63, Loss: 0.47926157204989933\n",
      "Epoch 64, Loss: 0.4777506884006509\n",
      "Epoch 65, Loss: 0.47632702497443186\n",
      "Epoch 66, Loss: 0.47466051744489995\n",
      "Epoch 67, Loss: 0.47283022807608377\n",
      "Epoch 68, Loss: 0.47114924899453015\n",
      "Epoch 69, Loss: 0.4696664910557547\n",
      "Epoch 70, Loss: 0.46807362713845996\n",
      "Epoch 71, Loss: 0.46636772380030866\n",
      "Epoch 72, Loss: 0.46481345582868633\n",
      "Epoch 73, Loss: 0.46338001568644355\n",
      "Epoch 74, Loss: 0.4619356920529251\n",
      "Epoch 75, Loss: 0.4605385621851853\n",
      "Epoch 76, Loss: 0.4591819662526782\n",
      "Epoch 77, Loss: 0.45781762377374713\n",
      "Epoch 78, Loss: 0.45658629512725535\n",
      "Epoch 79, Loss: 0.45541969872722066\n",
      "Epoch 80, Loss: 0.4541651855526259\n",
      "Epoch 81, Loss: 0.45299266658619664\n",
      "Epoch 82, Loss: 0.45188902958450167\n",
      "Epoch 83, Loss: 0.4507564762653097\n",
      "Epoch 84, Loss: 0.44968413419968306\n",
      "Epoch 85, Loss: 0.44857936635437423\n",
      "Epoch 86, Loss: 0.44747716573711876\n",
      "Epoch 87, Loss: 0.4464987464654377\n",
      "Epoch 88, Loss: 0.4454694772404649\n",
      "Epoch 89, Loss: 0.44444377554737197\n",
      "Epoch 90, Loss: 0.4433953190824011\n",
      "Epoch 91, Loss: 0.4424602617588846\n",
      "Epoch 92, Loss: 0.4415447557937705\n",
      "Epoch 93, Loss: 0.4406759922471099\n",
      "Epoch 94, Loss: 0.43984432186543504\n",
      "Epoch 95, Loss: 0.43897752244946864\n",
      "Epoch 96, Loss: 0.43797058954305085\n",
      "Epoch 97, Loss: 0.43694830919268834\n",
      "Epoch 98, Loss: 0.4359844900257602\n",
      "Epoch 99, Loss: 0.4348973447426975\n",
      "Epoch 100, Loss: 0.4338021679598504\n",
      "Epoch 101, Loss: 0.4327344197378086\n",
      "Epoch 102, Loss: 0.4316952010644612\n",
      "Epoch 103, Loss: 0.4307352988910941\n",
      "Epoch 104, Loss: 0.42968261022386434\n",
      "Epoch 105, Loss: 0.42867310168030126\n",
      "Epoch 106, Loss: 0.4276135243434647\n",
      "Epoch 107, Loss: 0.4266294727219515\n",
      "Epoch 108, Loss: 0.4256614201461864\n",
      "Epoch 109, Loss: 0.4246491421463922\n",
      "Epoch 110, Loss: 0.4236821041739912\n",
      "Epoch 111, Loss: 0.422618246573438\n",
      "Epoch 112, Loss: 0.42161702286326896\n",
      "Epoch 113, Loss: 0.42057309775648755\n",
      "Epoch 114, Loss: 0.4196034488319871\n",
      "Epoch 115, Loss: 0.41860208033879975\n",
      "Epoch 116, Loss: 0.4177007796570906\n",
      "Epoch 117, Loss: 0.41698970391920853\n",
      "Epoch 118, Loss: 0.41671718847427763\n",
      "Epoch 119, Loss: 0.4156718019794351\n",
      "Epoch 120, Loss: 0.4140445057539783\n",
      "Epoch 121, Loss: 0.41354306947036207\n",
      "Epoch 122, Loss: 0.4129839832211248\n",
      "Epoch 123, Loss: 0.41155308425200876\n",
      "Epoch 124, Loss: 0.4111571678504519\n",
      "Epoch 125, Loss: 0.410518449984355\n",
      "Epoch 126, Loss: 0.40931315282471653\n",
      "Epoch 127, Loss: 0.4088551183150893\n",
      "Epoch 128, Loss: 0.4082617649139844\n",
      "Epoch 129, Loss: 0.40719221962852575\n",
      "Epoch 130, Loss: 0.406656520360606\n",
      "Epoch 131, Loss: 0.4061459444738397\n",
      "Epoch 132, Loss: 0.4052080584266077\n",
      "Epoch 133, Loss: 0.4045857121069947\n",
      "Epoch 134, Loss: 0.4041653847755999\n",
      "Epoch 135, Loss: 0.4034203135215196\n",
      "Epoch 136, Loss: 0.4026231813896011\n",
      "Epoch 137, Loss: 0.40214315061720635\n",
      "Epoch 138, Loss: 0.401707266157859\n",
      "Epoch 139, Loss: 0.400979943500429\n",
      "Epoch 140, Loss: 0.4002472783722278\n",
      "Epoch 141, Loss: 0.39966211800589063\n",
      "Epoch 142, Loss: 0.3992224049260897\n",
      "Epoch 143, Loss: 0.39877217392569636\n",
      "Epoch 144, Loss: 0.39813591257946424\n",
      "Epoch 145, Loss: 0.39746091875455847\n",
      "Epoch 146, Loss: 0.3967760826351809\n",
      "Epoch 147, Loss: 0.3962369249996583\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22899867719048275\n",
      "Test R^2 score: 0.4325020024761573\n",
      "Num of epochs: 148\n",
      "Epoch 1, Loss: 0.6084597634747101\n",
      "Epoch 2, Loss: 0.6055535041801556\n",
      "Epoch 3, Loss: 0.6026755847554149\n",
      "Epoch 4, Loss: 0.5999112937839609\n",
      "Epoch 5, Loss: 0.5973469800410249\n",
      "Epoch 6, Loss: 0.594874872466136\n",
      "Epoch 7, Loss: 0.5924495710971635\n",
      "Epoch 8, Loss: 0.590074708702191\n",
      "Epoch 9, Loss: 0.5877567278186093\n",
      "Epoch 10, Loss: 0.5855492640797112\n",
      "Epoch 11, Loss: 0.5833949300624159\n",
      "Epoch 12, Loss: 0.5812942395756137\n",
      "Epoch 13, Loss: 0.5792519436862491\n",
      "Epoch 14, Loss: 0.5772867569519022\n",
      "Epoch 15, Loss: 0.5753868315261544\n",
      "Epoch 16, Loss: 0.5735902785422433\n",
      "Epoch 17, Loss: 0.5718732406505767\n",
      "Epoch 18, Loss: 0.5702308439560144\n",
      "Epoch 19, Loss: 0.5686581013391466\n",
      "Epoch 20, Loss: 0.5671592179910736\n",
      "Epoch 21, Loss: 0.5657397591106077\n",
      "Epoch 22, Loss: 0.5644023832857517\n",
      "Epoch 23, Loss: 0.5631702985760273\n",
      "Epoch 24, Loss: 0.5620305433526049\n",
      "Epoch 25, Loss: 0.5609777834568\n",
      "Epoch 26, Loss: 0.5600207049084412\n",
      "Epoch 27, Loss: 0.559155961524984\n",
      "Epoch 28, Loss: 0.5584413013638401\n",
      "Epoch 29, Loss: 0.5578281517931696\n",
      "Epoch 30, Loss: 0.5573030244852324\n",
      "Epoch 31, Loss: 0.5568541803117959\n",
      "Epoch 32, Loss: 0.5564780550020392\n",
      "Epoch 33, Loss: 0.5561700806372443\n",
      "Epoch 34, Loss: 0.5559245539804145\n",
      "Epoch 35, Loss: 0.5557321999445336\n",
      "Epoch 36, Loss: 0.555583069702806\n",
      "Epoch 37, Loss: 0.5554651531204966\n",
      "Epoch 38, Loss: 0.5553654302338792\n",
      "Epoch 39, Loss: 0.5552662798312529\n",
      "Epoch 40, Loss: 0.5551464438760083\n",
      "Epoch 41, Loss: 0.5549854499181209\n",
      "Epoch 42, Loss: 0.5547634932349864\n",
      "Epoch 43, Loss: 0.5544618228070494\n",
      "Epoch 44, Loss: 0.5540614557659811\n",
      "Epoch 45, Loss: 0.5535408848804968\n",
      "Epoch 46, Loss: 0.552872010473267\n",
      "Epoch 47, Loss: 0.5520161251929768\n",
      "Epoch 48, Loss: 0.5509165063451094\n",
      "Epoch 49, Loss: 0.5495001591533816\n",
      "Epoch 50, Loss: 0.547702816712563\n",
      "Epoch 51, Loss: 0.5454133801207036\n",
      "Epoch 52, Loss: 0.5425092550446324\n",
      "Epoch 53, Loss: 0.5389043880174986\n",
      "Epoch 54, Loss: 0.5346532253514495\n",
      "Epoch 55, Loss: 0.5300818952680748\n",
      "Epoch 56, Loss: 0.5259042377799507\n",
      "Epoch 57, Loss: 0.5233119130711605\n",
      "Epoch 58, Loss: 0.5230642382793097\n",
      "Epoch 59, Loss: 0.5224754260184414\n",
      "Epoch 60, Loss: 0.5191507882414335\n",
      "Epoch 61, Loss: 0.5147038525853886\n",
      "Epoch 62, Loss: 0.5111902142755936\n",
      "Epoch 63, Loss: 0.5091837635177106\n",
      "Epoch 64, Loss: 0.5078850620952685\n",
      "Epoch 65, Loss: 0.506239523602628\n",
      "Epoch 66, Loss: 0.5037933341383015\n",
      "Epoch 67, Loss: 0.5007005492602598\n",
      "Epoch 68, Loss: 0.49747273880822174\n",
      "Epoch 69, Loss: 0.49482033462460523\n",
      "Epoch 70, Loss: 0.4931348886453265\n",
      "Epoch 71, Loss: 0.4918249550969411\n",
      "Epoch 72, Loss: 0.4898196742272389\n",
      "Epoch 73, Loss: 0.4871796961777801\n",
      "Epoch 74, Loss: 0.4849151860140384\n",
      "Epoch 75, Loss: 0.48356243395746357\n",
      "Epoch 76, Loss: 0.48259413882971497\n",
      "Epoch 77, Loss: 0.48112345493214254\n",
      "Epoch 78, Loss: 0.4791903351729359\n",
      "Epoch 79, Loss: 0.4773538460420835\n",
      "Epoch 80, Loss: 0.4760613698937173\n",
      "Epoch 81, Loss: 0.4750148469712706\n",
      "Epoch 82, Loss: 0.4734261130546736\n",
      "Epoch 83, Loss: 0.47147820001712964\n",
      "Epoch 84, Loss: 0.46981748783457467\n",
      "Epoch 85, Loss: 0.4685818370539894\n",
      "Epoch 86, Loss: 0.46725993153123907\n",
      "Epoch 87, Loss: 0.46575492223983767\n",
      "Epoch 88, Loss: 0.4644344996639172\n",
      "Epoch 89, Loss: 0.4636072333894756\n",
      "Epoch 90, Loss: 0.4629170695931747\n",
      "Epoch 91, Loss: 0.4619366597944858\n",
      "Epoch 92, Loss: 0.46096287673664604\n",
      "Epoch 93, Loss: 0.46020985406072035\n",
      "Epoch 94, Loss: 0.4594072869041786\n",
      "Epoch 95, Loss: 0.4584702067029296\n",
      "Epoch 96, Loss: 0.45763075869890446\n",
      "Epoch 97, Loss: 0.45701573011342395\n",
      "Epoch 98, Loss: 0.4564461182051384\n",
      "Epoch 99, Loss: 0.4557891660884943\n",
      "Epoch 100, Loss: 0.4550606065251509\n",
      "Epoch 101, Loss: 0.4543383729436652\n",
      "Epoch 102, Loss: 0.4536762994491694\n",
      "Epoch 103, Loss: 0.4530272213902178\n",
      "Epoch 104, Loss: 0.45241377359342266\n",
      "Epoch 105, Loss: 0.4517955680140919\n",
      "Epoch 106, Loss: 0.4511208443454222\n",
      "Epoch 107, Loss: 0.4504409583255254\n",
      "Epoch 108, Loss: 0.44977112685047654\n",
      "Epoch 109, Loss: 0.44915562061724074\n",
      "Epoch 110, Loss: 0.4485757621259901\n",
      "Epoch 111, Loss: 0.4479138869561579\n",
      "Epoch 112, Loss: 0.4472415534459153\n",
      "Epoch 113, Loss: 0.44660642929715233\n",
      "Epoch 114, Loss: 0.446031107738202\n",
      "Epoch 115, Loss: 0.4453823804401749\n",
      "Epoch 116, Loss: 0.44472548627492814\n",
      "Epoch 117, Loss: 0.44409896064671894\n",
      "Epoch 118, Loss: 0.443540426921172\n",
      "Epoch 119, Loss: 0.4429334199194553\n",
      "Epoch 120, Loss: 0.4423076405772367\n",
      "Epoch 121, Loss: 0.44170381424288835\n",
      "Epoch 122, Loss: 0.44116091028756693\n",
      "Epoch 123, Loss: 0.44059503331651245\n",
      "Epoch 124, Loss: 0.4400177105135281\n",
      "Epoch 125, Loss: 0.4394609408213385\n",
      "Epoch 126, Loss: 0.4389168073362916\n",
      "Epoch 127, Loss: 0.4383497160882684\n",
      "Epoch 128, Loss: 0.43777256377109053\n",
      "Epoch 129, Loss: 0.43719101962349044\n",
      "Epoch 130, Loss: 0.4366178133198626\n",
      "Epoch 131, Loss: 0.4360304230948928\n",
      "Epoch 132, Loss: 0.43543916063141264\n",
      "Epoch 133, Loss: 0.43484113162668\n",
      "Epoch 134, Loss: 0.4342259274740931\n",
      "Epoch 135, Loss: 0.43360029679588247\n",
      "Epoch 136, Loss: 0.43298365655057325\n",
      "Epoch 137, Loss: 0.43230201141971325\n",
      "Epoch 138, Loss: 0.43161136648861215\n",
      "Epoch 139, Loss: 0.4309438026138842\n",
      "Epoch 140, Loss: 0.4303385397429666\n",
      "Epoch 141, Loss: 0.429823697786184\n",
      "Epoch 142, Loss: 0.42926018013988104\n",
      "Epoch 143, Loss: 0.4286837210738231\n",
      "Epoch 144, Loss: 0.4281383853407025\n",
      "Epoch 145, Loss: 0.4276283341740274\n",
      "Epoch 146, Loss: 0.4271959024648035\n",
      "Epoch 147, Loss: 0.4266767795892864\n",
      "Epoch 148, Loss: 0.4260810356635257\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21522146164239267\n",
      "Test R^2 score: 0.4989962468923882\n",
      "Num of epochs: 149\n",
      "Epoch 1, Loss: 0.5842935260544627\n",
      "Epoch 2, Loss: 0.5819392803674159\n",
      "Epoch 3, Loss: 0.5798359374967106\n",
      "Epoch 4, Loss: 0.5780333368989969\n",
      "Epoch 5, Loss: 0.5763161430132047\n",
      "Epoch 6, Loss: 0.5747687372286973\n",
      "Epoch 7, Loss: 0.5733686109527438\n",
      "Epoch 8, Loss: 0.5720330504592532\n",
      "Epoch 9, Loss: 0.5707165318976359\n",
      "Epoch 10, Loss: 0.5694417446222373\n",
      "Epoch 11, Loss: 0.5682195117758406\n",
      "Epoch 12, Loss: 0.5670386894202667\n",
      "Epoch 13, Loss: 0.565912939515037\n",
      "Epoch 14, Loss: 0.5648401115163111\n",
      "Epoch 15, Loss: 0.5638155388639723\n",
      "Epoch 16, Loss: 0.5629579481305622\n",
      "Epoch 17, Loss: 0.5621353397907153\n",
      "Epoch 18, Loss: 0.5613515839688671\n",
      "Epoch 19, Loss: 0.5606105117031447\n",
      "Epoch 20, Loss: 0.5599159118837262\n",
      "Epoch 21, Loss: 0.5592705687746485\n",
      "Epoch 22, Loss: 0.558677800397426\n",
      "Epoch 23, Loss: 0.5581350510601021\n",
      "Epoch 24, Loss: 0.5576483722791958\n",
      "Epoch 25, Loss: 0.5572194085261938\n",
      "Epoch 26, Loss: 0.556851156475671\n",
      "Epoch 27, Loss: 0.5565384620474664\n",
      "Epoch 28, Loss: 0.5562702218141143\n",
      "Epoch 29, Loss: 0.5560358878395542\n",
      "Epoch 30, Loss: 0.555830141265183\n",
      "Epoch 31, Loss: 0.5556750036680956\n",
      "Epoch 32, Loss: 0.5554970488602938\n",
      "Epoch 33, Loss: 0.5552746794556245\n",
      "Epoch 34, Loss: 0.5550052109035521\n",
      "Epoch 35, Loss: 0.5546588353017216\n",
      "Epoch 36, Loss: 0.5542015579779238\n",
      "Epoch 37, Loss: 0.5536060536670314\n",
      "Epoch 38, Loss: 0.5528318501175511\n",
      "Epoch 39, Loss: 0.5518358023559552\n",
      "Epoch 40, Loss: 0.5505618747461228\n",
      "Epoch 41, Loss: 0.5489520818751286\n",
      "Epoch 42, Loss: 0.5469375574571581\n",
      "Epoch 43, Loss: 0.5444555988055773\n",
      "Epoch 44, Loss: 0.5414857439963059\n",
      "Epoch 45, Loss: 0.538091752978017\n",
      "Epoch 46, Loss: 0.5344195341771592\n",
      "Epoch 47, Loss: 0.5308443652593136\n",
      "Epoch 48, Loss: 0.5280124804022397\n",
      "Epoch 49, Loss: 0.526382078055699\n",
      "Epoch 50, Loss: 0.5251317574153204\n",
      "Epoch 51, Loss: 0.5227790505789788\n",
      "Epoch 52, Loss: 0.5195837352886751\n",
      "Epoch 53, Loss: 0.5167322408174083\n",
      "Epoch 54, Loss: 0.5146902454629573\n",
      "Epoch 55, Loss: 0.5130046383646176\n",
      "Epoch 56, Loss: 0.5110727265388997\n",
      "Epoch 57, Loss: 0.5086535311721929\n",
      "Epoch 58, Loss: 0.5059187570720464\n",
      "Epoch 59, Loss: 0.5033337497656828\n",
      "Epoch 60, Loss: 0.5013855571524588\n",
      "Epoch 61, Loss: 0.5000539392940743\n",
      "Epoch 62, Loss: 0.4985024107996231\n",
      "Epoch 63, Loss: 0.4963256564229795\n",
      "Epoch 64, Loss: 0.49413192500119013\n",
      "Epoch 65, Loss: 0.49260285426601125\n",
      "Epoch 66, Loss: 0.4915553074605782\n",
      "Epoch 67, Loss: 0.4905046728516245\n",
      "Epoch 68, Loss: 0.4891414846678684\n",
      "Epoch 69, Loss: 0.4877272553041121\n",
      "Epoch 70, Loss: 0.4865418695965187\n",
      "Epoch 71, Loss: 0.48543002992935486\n",
      "Epoch 72, Loss: 0.48419750714796805\n",
      "Epoch 73, Loss: 0.48300051253648973\n",
      "Epoch 74, Loss: 0.4820047652574884\n",
      "Epoch 75, Loss: 0.48097772698968966\n",
      "Epoch 76, Loss: 0.4797262486765164\n",
      "Epoch 77, Loss: 0.47847766336387115\n",
      "Epoch 78, Loss: 0.4775008515904607\n",
      "Epoch 79, Loss: 0.4765778054453006\n",
      "Epoch 80, Loss: 0.475400884763643\n",
      "Epoch 81, Loss: 0.47419980119683336\n",
      "Epoch 82, Loss: 0.4731861800846892\n",
      "Epoch 83, Loss: 0.47214971150049395\n",
      "Epoch 84, Loss: 0.4710381451334095\n",
      "Epoch 85, Loss: 0.46998771339447576\n",
      "Epoch 86, Loss: 0.46892185239883016\n",
      "Epoch 87, Loss: 0.4677447666627789\n",
      "Epoch 88, Loss: 0.46663423522018044\n",
      "Epoch 89, Loss: 0.4655930066478184\n",
      "Epoch 90, Loss: 0.46443782040057874\n",
      "Epoch 91, Loss: 0.4632744947844794\n",
      "Epoch 92, Loss: 0.46217964392659766\n",
      "Epoch 93, Loss: 0.4610414387816866\n",
      "Epoch 94, Loss: 0.4598995094829215\n",
      "Epoch 95, Loss: 0.4588213042472087\n",
      "Epoch 96, Loss: 0.4576956980782506\n",
      "Epoch 97, Loss: 0.45656997682374967\n",
      "Epoch 98, Loss: 0.4554999528930924\n",
      "Epoch 99, Loss: 0.4543749898729494\n",
      "Epoch 100, Loss: 0.4532308290480743\n",
      "Epoch 101, Loss: 0.45216002150788465\n",
      "Epoch 102, Loss: 0.45121145694053166\n",
      "Epoch 103, Loss: 0.4505148392941909\n",
      "Epoch 104, Loss: 0.4500531449989864\n",
      "Epoch 105, Loss: 0.4496554035452131\n",
      "Epoch 106, Loss: 0.4491890607227936\n",
      "Epoch 107, Loss: 0.44857587839187385\n",
      "Epoch 108, Loss: 0.44791037717735666\n",
      "Epoch 109, Loss: 0.44727030589223793\n",
      "Epoch 110, Loss: 0.44668860049210257\n",
      "Epoch 111, Loss: 0.4461574068096544\n",
      "Epoch 112, Loss: 0.44562221932847745\n",
      "Epoch 113, Loss: 0.445106425203354\n",
      "Epoch 114, Loss: 0.4445700060370173\n",
      "Epoch 115, Loss: 0.4440296500804921\n",
      "Epoch 116, Loss: 0.4434496245766398\n",
      "Epoch 117, Loss: 0.44286717388937635\n",
      "Epoch 118, Loss: 0.4421039738302414\n",
      "Epoch 119, Loss: 0.4411131974735987\n",
      "Epoch 120, Loss: 0.4404079998622836\n",
      "Epoch 121, Loss: 0.43966994976488594\n",
      "Epoch 122, Loss: 0.4389826651107256\n",
      "Epoch 123, Loss: 0.43827266242714\n",
      "Epoch 124, Loss: 0.43761556665756607\n",
      "Epoch 125, Loss: 0.43704143401832046\n",
      "Epoch 126, Loss: 0.4364565428952781\n",
      "Epoch 127, Loss: 0.435900198458333\n",
      "Epoch 128, Loss: 0.4353639192740021\n",
      "Epoch 129, Loss: 0.4347748521509424\n",
      "Epoch 130, Loss: 0.43415382229274435\n",
      "Epoch 131, Loss: 0.43355828217479414\n",
      "Epoch 132, Loss: 0.4329547813472228\n",
      "Epoch 133, Loss: 0.43232229614519657\n",
      "Epoch 134, Loss: 0.4316670336347417\n",
      "Epoch 135, Loss: 0.43107289741192273\n",
      "Epoch 136, Loss: 0.4304553886596929\n",
      "Epoch 137, Loss: 0.42989843566318864\n",
      "Epoch 138, Loss: 0.42926903201364525\n",
      "Epoch 139, Loss: 0.42860315658143006\n",
      "Epoch 140, Loss: 0.42795901735568237\n",
      "Epoch 141, Loss: 0.4273099143181717\n",
      "Epoch 142, Loss: 0.4267415408037428\n",
      "Epoch 143, Loss: 0.4261992441369814\n",
      "Epoch 144, Loss: 0.4257034440651081\n",
      "Epoch 145, Loss: 0.4251904895177756\n",
      "Epoch 146, Loss: 0.4246920381462146\n",
      "Epoch 147, Loss: 0.4241618060256317\n",
      "Epoch 148, Loss: 0.4235990757960935\n",
      "Epoch 149, Loss: 0.4230232154662014\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21730909141734775\n",
      "Test R^2 score: 0.48727588025134055\n",
      "Num of epochs: 150\n",
      "Epoch 1, Loss: 0.5831071267450207\n",
      "Epoch 2, Loss: 0.5810752288008457\n",
      "Epoch 3, Loss: 0.5791198573189829\n",
      "Epoch 4, Loss: 0.5772779806665355\n",
      "Epoch 5, Loss: 0.5755745587940958\n",
      "Epoch 6, Loss: 0.5739431173819646\n",
      "Epoch 7, Loss: 0.5723680007549942\n",
      "Epoch 8, Loss: 0.5708528597710393\n",
      "Epoch 9, Loss: 0.5694161517265929\n",
      "Epoch 10, Loss: 0.5680386139561876\n",
      "Epoch 11, Loss: 0.5667404241337657\n",
      "Epoch 12, Loss: 0.5655142501819824\n",
      "Epoch 13, Loss: 0.5644331931848648\n",
      "Epoch 14, Loss: 0.5634509895643698\n",
      "Epoch 15, Loss: 0.5625806326824166\n",
      "Epoch 16, Loss: 0.5617971797937514\n",
      "Epoch 17, Loss: 0.5610674258680172\n",
      "Epoch 18, Loss: 0.5603803859250196\n",
      "Epoch 19, Loss: 0.559726926180644\n",
      "Epoch 20, Loss: 0.5591098828437225\n",
      "Epoch 21, Loss: 0.5585335652400453\n",
      "Epoch 22, Loss: 0.5580092352988183\n",
      "Epoch 23, Loss: 0.5575467146986643\n",
      "Epoch 24, Loss: 0.5571500087155031\n",
      "Epoch 25, Loss: 0.5567916932820988\n",
      "Epoch 26, Loss: 0.556478965440576\n",
      "Epoch 27, Loss: 0.556207454854544\n",
      "Epoch 28, Loss: 0.5559737912748666\n",
      "Epoch 29, Loss: 0.5557607020327087\n",
      "Epoch 30, Loss: 0.5555596815062005\n",
      "Epoch 31, Loss: 0.5553495995574796\n",
      "Epoch 32, Loss: 0.555100381339232\n",
      "Epoch 33, Loss: 0.554785437735775\n",
      "Epoch 34, Loss: 0.5543761118089607\n",
      "Epoch 35, Loss: 0.5538499445739646\n",
      "Epoch 36, Loss: 0.5531791003219525\n",
      "Epoch 37, Loss: 0.5523330255786512\n",
      "Epoch 38, Loss: 0.5512518259048498\n",
      "Epoch 39, Loss: 0.5498840654167442\n",
      "Epoch 40, Loss: 0.5481476553102923\n",
      "Epoch 41, Loss: 0.5459641637115489\n",
      "Epoch 42, Loss: 0.5432582056239489\n",
      "Epoch 43, Loss: 0.5400089027854162\n",
      "Epoch 44, Loss: 0.5362095456547492\n",
      "Epoch 45, Loss: 0.5319588364042278\n",
      "Epoch 46, Loss: 0.5277628893034954\n",
      "Epoch 47, Loss: 0.5246536304386441\n",
      "Epoch 48, Loss: 0.5232355382937536\n",
      "Epoch 49, Loss: 0.5213078689470112\n",
      "Epoch 50, Loss: 0.5176807805589755\n",
      "Epoch 51, Loss: 0.5139644355344665\n",
      "Epoch 52, Loss: 0.5115313878557625\n",
      "Epoch 53, Loss: 0.5100965923577648\n",
      "Epoch 54, Loss: 0.5086904712125753\n",
      "Epoch 55, Loss: 0.5066954430870042\n",
      "Epoch 56, Loss: 0.5041337793306041\n",
      "Epoch 57, Loss: 0.5014813948799914\n",
      "Epoch 58, Loss: 0.4993983165181712\n",
      "Epoch 59, Loss: 0.49808555901583107\n",
      "Epoch 60, Loss: 0.4967563889442511\n",
      "Epoch 61, Loss: 0.49487652469235366\n",
      "Epoch 62, Loss: 0.49300179408542033\n",
      "Epoch 63, Loss: 0.4916328605112686\n",
      "Epoch 64, Loss: 0.4904359653789671\n",
      "Epoch 65, Loss: 0.48891307388376143\n",
      "Epoch 66, Loss: 0.48703755489376765\n",
      "Epoch 67, Loss: 0.4852951753892948\n",
      "Epoch 68, Loss: 0.48399439594279536\n",
      "Epoch 69, Loss: 0.4827814962561895\n",
      "Epoch 70, Loss: 0.48113836752442746\n",
      "Epoch 71, Loss: 0.47932811967879757\n",
      "Epoch 72, Loss: 0.4778269112798183\n",
      "Epoch 73, Loss: 0.47651618982653027\n",
      "Epoch 74, Loss: 0.4750559397433817\n",
      "Epoch 75, Loss: 0.4734714193751653\n",
      "Epoch 76, Loss: 0.47205300100116276\n",
      "Epoch 77, Loss: 0.4707529983374375\n",
      "Epoch 78, Loss: 0.4693330476555217\n",
      "Epoch 79, Loss: 0.4678573692377389\n",
      "Epoch 80, Loss: 0.4666044564873938\n",
      "Epoch 81, Loss: 0.4654538774627378\n",
      "Epoch 82, Loss: 0.46417316183388946\n",
      "Epoch 83, Loss: 0.46296678391398655\n",
      "Epoch 84, Loss: 0.4620278925897874\n",
      "Epoch 85, Loss: 0.4611785549304939\n",
      "Epoch 86, Loss: 0.46033575899158136\n",
      "Epoch 87, Loss: 0.45960566899013006\n",
      "Epoch 88, Loss: 0.45889146554346405\n",
      "Epoch 89, Loss: 0.4580403948746294\n",
      "Epoch 90, Loss: 0.4570769262719654\n",
      "Epoch 91, Loss: 0.45615655386273635\n",
      "Epoch 92, Loss: 0.4553763922461421\n",
      "Epoch 93, Loss: 0.4546449916671982\n",
      "Epoch 94, Loss: 0.4539543979865764\n",
      "Epoch 95, Loss: 0.4532584125508186\n",
      "Epoch 96, Loss: 0.4525399541866653\n",
      "Epoch 97, Loss: 0.45183126971377335\n",
      "Epoch 98, Loss: 0.4511122726110065\n",
      "Epoch 99, Loss: 0.45038266534711413\n",
      "Epoch 100, Loss: 0.4497001887659326\n",
      "Epoch 101, Loss: 0.4489410371244076\n",
      "Epoch 102, Loss: 0.4481351304871074\n",
      "Epoch 103, Loss: 0.447418203523658\n",
      "Epoch 104, Loss: 0.4466896179456447\n",
      "Epoch 105, Loss: 0.44603037275400315\n",
      "Epoch 106, Loss: 0.4453129182780125\n",
      "Epoch 107, Loss: 0.4445220054644026\n",
      "Epoch 108, Loss: 0.4437736726544702\n",
      "Epoch 109, Loss: 0.4429813907979311\n",
      "Epoch 110, Loss: 0.4422766619182687\n",
      "Epoch 111, Loss: 0.4415084585500627\n",
      "Epoch 112, Loss: 0.4407833903631571\n",
      "Epoch 113, Loss: 0.44003315264258874\n",
      "Epoch 114, Loss: 0.43934545257540186\n",
      "Epoch 115, Loss: 0.43859188882604777\n",
      "Epoch 116, Loss: 0.43786142951220053\n",
      "Epoch 117, Loss: 0.4370834206519511\n",
      "Epoch 118, Loss: 0.4363562585952504\n",
      "Epoch 119, Loss: 0.4355302131784462\n",
      "Epoch 120, Loss: 0.43471094491947404\n",
      "Epoch 121, Loss: 0.4339309103211438\n",
      "Epoch 122, Loss: 0.4331131238809192\n",
      "Epoch 123, Loss: 0.43232591524000247\n",
      "Epoch 124, Loss: 0.43154650736573197\n",
      "Epoch 125, Loss: 0.43076800694412964\n",
      "Epoch 126, Loss: 0.4299894485731561\n",
      "Epoch 127, Loss: 0.4292125851716485\n",
      "Epoch 128, Loss: 0.42848667196491314\n",
      "Epoch 129, Loss: 0.4277669293282405\n",
      "Epoch 130, Loss: 0.4270361684326819\n",
      "Epoch 131, Loss: 0.42633804172742384\n",
      "Epoch 132, Loss: 0.4257787651899434\n",
      "Epoch 133, Loss: 0.4257774002881081\n",
      "Epoch 134, Loss: 0.42562649915658035\n",
      "Epoch 135, Loss: 0.4238522782013752\n",
      "Epoch 136, Loss: 0.4234003817910197\n",
      "Epoch 137, Loss: 0.42336295129701884\n",
      "Epoch 138, Loss: 0.4217971623987278\n",
      "Epoch 139, Loss: 0.42188006857193744\n",
      "Epoch 140, Loss: 0.42101912748487125\n",
      "Epoch 141, Loss: 0.42012675410559674\n",
      "Epoch 142, Loss: 0.42003275272409074\n",
      "Epoch 143, Loss: 0.4188885772631122\n",
      "Epoch 144, Loss: 0.4186502409006371\n",
      "Epoch 145, Loss: 0.41805425108089667\n",
      "Epoch 146, Loss: 0.4171729667503839\n",
      "Epoch 147, Loss: 0.4169678156071122\n",
      "Epoch 148, Loss: 0.41619557531782914\n",
      "Epoch 149, Loss: 0.41548567135981496\n",
      "Epoch 150, Loss: 0.41524468209078463\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22121590908533134\n",
      "Test R^2 score: 0.4719718260603571\n",
      "Num of epochs: 151\n",
      "Epoch 1, Loss: 0.6125030926217613\n",
      "Epoch 2, Loss: 0.609810575677092\n",
      "Epoch 3, Loss: 0.6071804339537142\n",
      "Epoch 4, Loss: 0.6046113126403069\n",
      "Epoch 5, Loss: 0.6021036711121083\n",
      "Epoch 6, Loss: 0.5996592000830788\n",
      "Epoch 7, Loss: 0.5973759910350177\n",
      "Epoch 8, Loss: 0.5951675508907945\n",
      "Epoch 9, Loss: 0.5929972494762761\n",
      "Epoch 10, Loss: 0.5908557219179907\n",
      "Epoch 11, Loss: 0.5887432568967798\n",
      "Epoch 12, Loss: 0.5866805895955834\n",
      "Epoch 13, Loss: 0.584662385133046\n",
      "Epoch 14, Loss: 0.5827841273706267\n",
      "Epoch 15, Loss: 0.5809479944062031\n",
      "Epoch 16, Loss: 0.5792475189975756\n",
      "Epoch 17, Loss: 0.577699582056215\n",
      "Epoch 18, Loss: 0.5761702456693726\n",
      "Epoch 19, Loss: 0.5746621476555902\n",
      "Epoch 20, Loss: 0.5732156984619944\n",
      "Epoch 21, Loss: 0.5718379065985698\n",
      "Epoch 22, Loss: 0.5704817847270167\n",
      "Epoch 23, Loss: 0.5692162363361791\n",
      "Epoch 24, Loss: 0.5679917080317612\n",
      "Epoch 25, Loss: 0.5667929808931772\n",
      "Epoch 26, Loss: 0.5656147128692411\n",
      "Epoch 27, Loss: 0.5644468683338226\n",
      "Epoch 28, Loss: 0.5632758882349403\n",
      "Epoch 29, Loss: 0.5621583748907223\n",
      "Epoch 30, Loss: 0.5610425930343707\n",
      "Epoch 31, Loss: 0.5599198772383603\n",
      "Epoch 32, Loss: 0.5587793055365541\n",
      "Epoch 33, Loss: 0.5576113885955452\n",
      "Epoch 34, Loss: 0.5563990018351616\n",
      "Epoch 35, Loss: 0.5551190913503742\n",
      "Epoch 36, Loss: 0.5537439030382671\n",
      "Epoch 37, Loss: 0.5522472540103721\n",
      "Epoch 38, Loss: 0.550586178912502\n",
      "Epoch 39, Loss: 0.5487229052916994\n",
      "Epoch 40, Loss: 0.5466578188573658\n",
      "Epoch 41, Loss: 0.5444415583690823\n",
      "Epoch 42, Loss: 0.5421315331939458\n",
      "Epoch 43, Loss: 0.5399200970644319\n",
      "Epoch 44, Loss: 0.5377999876917493\n",
      "Epoch 45, Loss: 0.535932965718209\n",
      "Epoch 46, Loss: 0.5343940486078316\n",
      "Epoch 47, Loss: 0.5328724992368121\n",
      "Epoch 48, Loss: 0.5306155960813332\n",
      "Epoch 49, Loss: 0.5273494296297877\n",
      "Epoch 50, Loss: 0.523757978801906\n",
      "Epoch 51, Loss: 0.5206530227080296\n",
      "Epoch 52, Loss: 0.5180968366453093\n",
      "Epoch 53, Loss: 0.5158592905601699\n",
      "Epoch 54, Loss: 0.5136824922225883\n",
      "Epoch 55, Loss: 0.5113301148168258\n",
      "Epoch 56, Loss: 0.5087895896747808\n",
      "Epoch 57, Loss: 0.5061746447016813\n",
      "Epoch 58, Loss: 0.5036419019838239\n",
      "Epoch 59, Loss: 0.5012070569885698\n",
      "Epoch 60, Loss: 0.49880249447497094\n",
      "Epoch 61, Loss: 0.4964958123571196\n",
      "Epoch 62, Loss: 0.4944743058864636\n",
      "Epoch 63, Loss: 0.4927322007568737\n",
      "Epoch 64, Loss: 0.49109117325808604\n",
      "Epoch 65, Loss: 0.48933405481979564\n",
      "Epoch 66, Loss: 0.48747284153335657\n",
      "Epoch 67, Loss: 0.4857316399852925\n",
      "Epoch 68, Loss: 0.48424611376501303\n",
      "Epoch 69, Loss: 0.48287292583809116\n",
      "Epoch 70, Loss: 0.481410212910606\n",
      "Epoch 71, Loss: 0.47987921918766546\n",
      "Epoch 72, Loss: 0.4784283305360249\n",
      "Epoch 73, Loss: 0.47704567413563764\n",
      "Epoch 74, Loss: 0.4756674412753573\n",
      "Epoch 75, Loss: 0.4743441873024786\n",
      "Epoch 76, Loss: 0.47312355585520366\n",
      "Epoch 77, Loss: 0.47187057328831994\n",
      "Epoch 78, Loss: 0.470611626687086\n",
      "Epoch 79, Loss: 0.46958610353891017\n",
      "Epoch 80, Loss: 0.46874081284738794\n",
      "Epoch 81, Loss: 0.46784754347287255\n",
      "Epoch 82, Loss: 0.46677563032383834\n",
      "Epoch 83, Loss: 0.4656695235810311\n",
      "Epoch 84, Loss: 0.4645982943750275\n",
      "Epoch 85, Loss: 0.463544841998365\n",
      "Epoch 86, Loss: 0.4624711401415129\n",
      "Epoch 87, Loss: 0.46138743084780437\n",
      "Epoch 88, Loss: 0.4603608290298432\n",
      "Epoch 89, Loss: 0.45941583361112776\n",
      "Epoch 90, Loss: 0.45844511453536474\n",
      "Epoch 91, Loss: 0.4574314386816042\n",
      "Epoch 92, Loss: 0.4564653136768479\n",
      "Epoch 93, Loss: 0.4555337123444472\n",
      "Epoch 94, Loss: 0.45464586021387016\n",
      "Epoch 95, Loss: 0.453782705935813\n",
      "Epoch 96, Loss: 0.4529825348350394\n",
      "Epoch 97, Loss: 0.4521948706099348\n",
      "Epoch 98, Loss: 0.4513867514714555\n",
      "Epoch 99, Loss: 0.4506096081743848\n",
      "Epoch 100, Loss: 0.4498689175793722\n",
      "Epoch 101, Loss: 0.44911980575904376\n",
      "Epoch 102, Loss: 0.4483198377050505\n",
      "Epoch 103, Loss: 0.4475344387314028\n",
      "Epoch 104, Loss: 0.44680756013343026\n",
      "Epoch 105, Loss: 0.44612950116615296\n",
      "Epoch 106, Loss: 0.4454223764955811\n",
      "Epoch 107, Loss: 0.4446952121894208\n",
      "Epoch 108, Loss: 0.4439823462449817\n",
      "Epoch 109, Loss: 0.44332604976218487\n",
      "Epoch 110, Loss: 0.44272522800596287\n",
      "Epoch 111, Loss: 0.4420945025940719\n",
      "Epoch 112, Loss: 0.44147911145595137\n",
      "Epoch 113, Loss: 0.44083778099972465\n",
      "Epoch 114, Loss: 0.44018283870665814\n",
      "Epoch 115, Loss: 0.4395248863120258\n",
      "Epoch 116, Loss: 0.43883659347830417\n",
      "Epoch 117, Loss: 0.43814492374889435\n",
      "Epoch 118, Loss: 0.43745716770856263\n",
      "Epoch 119, Loss: 0.4367842439187389\n",
      "Epoch 120, Loss: 0.436103550586579\n",
      "Epoch 121, Loss: 0.43540986647459573\n",
      "Epoch 122, Loss: 0.43471180187664754\n",
      "Epoch 123, Loss: 0.4339920826115037\n",
      "Epoch 124, Loss: 0.4332547795945026\n",
      "Epoch 125, Loss: 0.43260489073901803\n",
      "Epoch 126, Loss: 0.4320225126683276\n",
      "Epoch 127, Loss: 0.43120523648899783\n",
      "Epoch 128, Loss: 0.4300829368273622\n",
      "Epoch 129, Loss: 0.42941783766300307\n",
      "Epoch 130, Loss: 0.4289157699612398\n",
      "Epoch 131, Loss: 0.4278719606729004\n",
      "Epoch 132, Loss: 0.4269510351131627\n",
      "Epoch 133, Loss: 0.4264591490075095\n",
      "Epoch 134, Loss: 0.4256731298516585\n",
      "Epoch 135, Loss: 0.4245987316155771\n",
      "Epoch 136, Loss: 0.42399486654588364\n",
      "Epoch 137, Loss: 0.42346701642302953\n",
      "Epoch 138, Loss: 0.422534268558233\n",
      "Epoch 139, Loss: 0.4216132765010053\n",
      "Epoch 140, Loss: 0.4211209410485682\n",
      "Epoch 141, Loss: 0.42041285001133216\n",
      "Epoch 142, Loss: 0.4194515877217887\n",
      "Epoch 143, Loss: 0.4188180120948218\n",
      "Epoch 144, Loss: 0.4182260024670356\n",
      "Epoch 145, Loss: 0.4173824262104023\n",
      "Epoch 146, Loss: 0.4165530427344257\n",
      "Epoch 147, Loss: 0.41589831995270443\n",
      "Epoch 148, Loss: 0.41532665386436673\n",
      "Epoch 149, Loss: 0.41474688848532065\n",
      "Epoch 150, Loss: 0.41415172191433697\n",
      "Epoch 151, Loss: 0.4134297484509558\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22912334386275193\n",
      "Test R^2 score: 0.43202178325766\n",
      "Num of epochs: 152\n",
      "Epoch 1, Loss: 0.579689923510151\n",
      "Epoch 2, Loss: 0.5778253655164424\n",
      "Epoch 3, Loss: 0.5760286832131516\n",
      "Epoch 4, Loss: 0.574317923564752\n",
      "Epoch 5, Loss: 0.5726852180679455\n",
      "Epoch 6, Loss: 0.5711331668302411\n",
      "Epoch 7, Loss: 0.5697003305887204\n",
      "Epoch 8, Loss: 0.5683429361699268\n",
      "Epoch 9, Loss: 0.5670424210138363\n",
      "Epoch 10, Loss: 0.5657872467860985\n",
      "Epoch 11, Loss: 0.5646192312851657\n",
      "Epoch 12, Loss: 0.5635793450029352\n",
      "Epoch 13, Loss: 0.5625981669066908\n",
      "Epoch 14, Loss: 0.5616753148885605\n",
      "Epoch 15, Loss: 0.5608099609150871\n",
      "Epoch 16, Loss: 0.560013999593676\n",
      "Epoch 17, Loss: 0.5592772830025913\n",
      "Epoch 18, Loss: 0.5585854002855384\n",
      "Epoch 19, Loss: 0.5579827441551964\n",
      "Epoch 20, Loss: 0.5575055814044547\n",
      "Epoch 21, Loss: 0.5570869664045439\n",
      "Epoch 22, Loss: 0.5566727478395685\n",
      "Epoch 23, Loss: 0.5562427906040662\n",
      "Epoch 24, Loss: 0.5558096857440427\n",
      "Epoch 25, Loss: 0.5553143679748958\n",
      "Epoch 26, Loss: 0.5548675137552138\n",
      "Epoch 27, Loss: 0.5544096559790073\n",
      "Epoch 28, Loss: 0.553917175314352\n",
      "Epoch 29, Loss: 0.5533578544185416\n",
      "Epoch 30, Loss: 0.5527219737248938\n",
      "Epoch 31, Loss: 0.5519554391908288\n",
      "Epoch 32, Loss: 0.5509770363281982\n",
      "Epoch 33, Loss: 0.5497245391372594\n",
      "Epoch 34, Loss: 0.548094153455145\n",
      "Epoch 35, Loss: 0.5460089501723293\n",
      "Epoch 36, Loss: 0.5434564554463341\n",
      "Epoch 37, Loss: 0.5404534845106969\n",
      "Epoch 38, Loss: 0.5370307448659191\n",
      "Epoch 39, Loss: 0.5333082773114538\n",
      "Epoch 40, Loss: 0.5296143427828394\n",
      "Epoch 41, Loss: 0.526561184663573\n",
      "Epoch 42, Loss: 0.5248757714931108\n",
      "Epoch 43, Loss: 0.5241546841855406\n",
      "Epoch 44, Loss: 0.522323561816581\n",
      "Epoch 45, Loss: 0.5189008688712293\n",
      "Epoch 46, Loss: 0.515103480997841\n",
      "Epoch 47, Loss: 0.5120467088709606\n",
      "Epoch 48, Loss: 0.509946535243863\n",
      "Epoch 49, Loss: 0.5083112761397047\n",
      "Epoch 50, Loss: 0.5065254333414411\n",
      "Epoch 51, Loss: 0.5043070478174158\n",
      "Epoch 52, Loss: 0.5016754807472064\n",
      "Epoch 53, Loss: 0.49889772328426735\n",
      "Epoch 54, Loss: 0.49637331557054104\n",
      "Epoch 55, Loss: 0.4944093599206578\n",
      "Epoch 56, Loss: 0.4928866219762371\n",
      "Epoch 57, Loss: 0.49120189741852316\n",
      "Epoch 58, Loss: 0.4890148755123963\n",
      "Epoch 59, Loss: 0.4867136396259196\n",
      "Epoch 60, Loss: 0.4848000445814789\n",
      "Epoch 61, Loss: 0.4833172045954394\n",
      "Epoch 62, Loss: 0.481868441892099\n",
      "Epoch 63, Loss: 0.4801262355749812\n",
      "Epoch 64, Loss: 0.4782007388046202\n",
      "Epoch 65, Loss: 0.47647170468265726\n",
      "Epoch 66, Loss: 0.4751255854427642\n",
      "Epoch 67, Loss: 0.4739247945998883\n",
      "Epoch 68, Loss: 0.47248469935979115\n",
      "Epoch 69, Loss: 0.47088714421517996\n",
      "Epoch 70, Loss: 0.46944939571073163\n",
      "Epoch 71, Loss: 0.4682564839536889\n",
      "Epoch 72, Loss: 0.46709169470794953\n",
      "Epoch 73, Loss: 0.46580342196185825\n",
      "Epoch 74, Loss: 0.4645157145427887\n",
      "Epoch 75, Loss: 0.4635153630826703\n",
      "Epoch 76, Loss: 0.46265669436499457\n",
      "Epoch 77, Loss: 0.4616975337283829\n",
      "Epoch 78, Loss: 0.46067231842331235\n",
      "Epoch 79, Loss: 0.4597644264639868\n",
      "Epoch 80, Loss: 0.45894882389121133\n",
      "Epoch 81, Loss: 0.4580945744110523\n",
      "Epoch 82, Loss: 0.4572165024085327\n",
      "Epoch 83, Loss: 0.4563807071641344\n",
      "Epoch 84, Loss: 0.455534415639746\n",
      "Epoch 85, Loss: 0.45459067962274624\n",
      "Epoch 86, Loss: 0.45363399265339127\n",
      "Epoch 87, Loss: 0.45274980401909565\n",
      "Epoch 88, Loss: 0.45188037349413157\n",
      "Epoch 89, Loss: 0.4510604423538388\n",
      "Epoch 90, Loss: 0.450317548264235\n",
      "Epoch 91, Loss: 0.449615170916229\n",
      "Epoch 92, Loss: 0.44891081497309093\n",
      "Epoch 93, Loss: 0.4482374004033592\n",
      "Epoch 94, Loss: 0.4475793030067958\n",
      "Epoch 95, Loss: 0.44692623805027015\n",
      "Epoch 96, Loss: 0.4463022342799897\n",
      "Epoch 97, Loss: 0.4456830574352385\n",
      "Epoch 98, Loss: 0.4450667020816048\n",
      "Epoch 99, Loss: 0.4444662385140209\n",
      "Epoch 100, Loss: 0.443843828946473\n",
      "Epoch 101, Loss: 0.4431612857817356\n",
      "Epoch 102, Loss: 0.44245706234064547\n",
      "Epoch 103, Loss: 0.44179266498424935\n",
      "Epoch 104, Loss: 0.44117744389594926\n",
      "Epoch 105, Loss: 0.44054272674918393\n",
      "Epoch 106, Loss: 0.43987603077573945\n",
      "Epoch 107, Loss: 0.43920981559229466\n",
      "Epoch 108, Loss: 0.438562091735328\n",
      "Epoch 109, Loss: 0.4378748037592094\n",
      "Epoch 110, Loss: 0.43712127846608195\n",
      "Epoch 111, Loss: 0.4363314485892925\n",
      "Epoch 112, Loss: 0.43552183070688644\n",
      "Epoch 113, Loss: 0.43472648985998635\n",
      "Epoch 114, Loss: 0.43394596812334085\n",
      "Epoch 115, Loss: 0.43315574930425066\n",
      "Epoch 116, Loss: 0.4324188811242481\n",
      "Epoch 117, Loss: 0.43168168714096594\n",
      "Epoch 118, Loss: 0.4309283805640207\n",
      "Epoch 119, Loss: 0.4301828996500192\n",
      "Epoch 120, Loss: 0.429486695966182\n",
      "Epoch 121, Loss: 0.42883418924856825\n",
      "Epoch 122, Loss: 0.4281998631534598\n",
      "Epoch 123, Loss: 0.4275759573431427\n",
      "Epoch 124, Loss: 0.4269254516679591\n",
      "Epoch 125, Loss: 0.4262826574517796\n",
      "Epoch 126, Loss: 0.4256269017707809\n",
      "Epoch 127, Loss: 0.4250117531722044\n",
      "Epoch 128, Loss: 0.42443714245862735\n",
      "Epoch 129, Loss: 0.42384881527231\n",
      "Epoch 130, Loss: 0.42327232658412106\n",
      "Epoch 131, Loss: 0.4227020140179136\n",
      "Epoch 132, Loss: 0.42215901104338094\n",
      "Epoch 133, Loss: 0.42163252043272614\n",
      "Epoch 134, Loss: 0.4211151910252629\n",
      "Epoch 135, Loss: 0.4206360886629836\n",
      "Epoch 136, Loss: 0.42013792645613024\n",
      "Epoch 137, Loss: 0.4196363498594827\n",
      "Epoch 138, Loss: 0.4191170187183666\n",
      "Epoch 139, Loss: 0.4185611946856859\n",
      "Epoch 140, Loss: 0.4179971631811698\n",
      "Epoch 141, Loss: 0.4174268900080777\n",
      "Epoch 142, Loss: 0.416937688263359\n",
      "Epoch 143, Loss: 0.4165278402162167\n",
      "Epoch 144, Loss: 0.4161715506324485\n",
      "Epoch 145, Loss: 0.4156281901359027\n",
      "Epoch 146, Loss: 0.41500647921847206\n",
      "Epoch 147, Loss: 0.414584262965069\n",
      "Epoch 148, Loss: 0.414279862697857\n",
      "Epoch 149, Loss: 0.41377649686278817\n",
      "Epoch 150, Loss: 0.4132644772506272\n",
      "Epoch 151, Loss: 0.41288647897708486\n",
      "Epoch 152, Loss: 0.41252357675625767\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21831478278360142\n",
      "Test R^2 score: 0.48185206413499493\n",
      "Num of epochs: 153\n",
      "Epoch 1, Loss: 0.5650387797930182\n",
      "Epoch 2, Loss: 0.5638661219735775\n",
      "Epoch 3, Loss: 0.5628359109519981\n",
      "Epoch 4, Loss: 0.5619445548536982\n",
      "Epoch 5, Loss: 0.561124338045535\n",
      "Epoch 6, Loss: 0.5604491464309393\n",
      "Epoch 7, Loss: 0.5598363859569064\n",
      "Epoch 8, Loss: 0.5592688369170624\n",
      "Epoch 9, Loss: 0.5587497306669469\n",
      "Epoch 10, Loss: 0.5582802699860097\n",
      "Epoch 11, Loss: 0.557860713766415\n",
      "Epoch 12, Loss: 0.5574894372940146\n",
      "Epoch 13, Loss: 0.5571828242697857\n",
      "Epoch 14, Loss: 0.5569003386036327\n",
      "Epoch 15, Loss: 0.556663405638221\n",
      "Epoch 16, Loss: 0.5564703429923331\n",
      "Epoch 17, Loss: 0.5563114196643426\n",
      "Epoch 18, Loss: 0.5561831819928452\n",
      "Epoch 19, Loss: 0.5560892687255505\n",
      "Epoch 20, Loss: 0.5560224882181721\n",
      "Epoch 21, Loss: 0.5559721295537762\n",
      "Epoch 22, Loss: 0.5559398054104071\n",
      "Epoch 23, Loss: 0.5559176920406397\n",
      "Epoch 24, Loss: 0.5558809148886797\n",
      "Epoch 25, Loss: 0.5558352885385848\n",
      "Epoch 26, Loss: 0.5557861998399023\n",
      "Epoch 27, Loss: 0.5557226006055326\n",
      "Epoch 28, Loss: 0.5556370304551679\n",
      "Epoch 29, Loss: 0.5555173281259738\n",
      "Epoch 30, Loss: 0.5553482311218891\n",
      "Epoch 31, Loss: 0.5551154406660117\n",
      "Epoch 32, Loss: 0.554812296408491\n",
      "Epoch 33, Loss: 0.5544365328557895\n",
      "Epoch 34, Loss: 0.5539820577508171\n",
      "Epoch 35, Loss: 0.5534374227582984\n",
      "Epoch 36, Loss: 0.5527620611906472\n",
      "Epoch 37, Loss: 0.5519716641713556\n",
      "Epoch 38, Loss: 0.5510096786483215\n",
      "Epoch 39, Loss: 0.5498157723700087\n",
      "Epoch 40, Loss: 0.5483379143182467\n",
      "Epoch 41, Loss: 0.5464511318607286\n",
      "Epoch 42, Loss: 0.5440356249802349\n",
      "Epoch 43, Loss: 0.5410114935431432\n",
      "Epoch 44, Loss: 0.5373743132085287\n",
      "Epoch 45, Loss: 0.5330745276454877\n",
      "Epoch 46, Loss: 0.5281660380022171\n",
      "Epoch 47, Loss: 0.5229348858348182\n",
      "Epoch 48, Loss: 0.5179630791309101\n",
      "Epoch 49, Loss: 0.5142971917652243\n",
      "Epoch 50, Loss: 0.5127743905253943\n",
      "Epoch 51, Loss: 0.5111956944338794\n",
      "Epoch 52, Loss: 0.5077153919977896\n",
      "Epoch 53, Loss: 0.5035550571860795\n",
      "Epoch 54, Loss: 0.5002354425183281\n",
      "Epoch 55, Loss: 0.4981701268296835\n",
      "Epoch 56, Loss: 0.4967582637481548\n",
      "Epoch 57, Loss: 0.4952498790494337\n",
      "Epoch 58, Loss: 0.49318805296304546\n",
      "Epoch 59, Loss: 0.4905168547772407\n",
      "Epoch 60, Loss: 0.48743203129484364\n",
      "Epoch 61, Loss: 0.4844045014780207\n",
      "Epoch 62, Loss: 0.48193234150732545\n",
      "Epoch 63, Loss: 0.48018158495446367\n",
      "Epoch 64, Loss: 0.4788266941969711\n",
      "Epoch 65, Loss: 0.4772178177860985\n",
      "Epoch 66, Loss: 0.4751546576591487\n",
      "Epoch 67, Loss: 0.4730307616459186\n",
      "Epoch 68, Loss: 0.47123841362529206\n",
      "Epoch 69, Loss: 0.46976810200271485\n",
      "Epoch 70, Loss: 0.4684162541229127\n",
      "Epoch 71, Loss: 0.4670595842370234\n",
      "Epoch 72, Loss: 0.46589856720032863\n",
      "Epoch 73, Loss: 0.46496117334905485\n",
      "Epoch 74, Loss: 0.46415051290333137\n",
      "Epoch 75, Loss: 0.46348237790760705\n",
      "Epoch 76, Loss: 0.4625443398640348\n",
      "Epoch 77, Loss: 0.46138276399184275\n",
      "Epoch 78, Loss: 0.4602386543309388\n",
      "Epoch 79, Loss: 0.45936015552747816\n",
      "Epoch 80, Loss: 0.4586532047339834\n",
      "Epoch 81, Loss: 0.458006364702161\n",
      "Epoch 82, Loss: 0.457302094762798\n",
      "Epoch 83, Loss: 0.4565536416178106\n",
      "Epoch 84, Loss: 0.4558223156873149\n",
      "Epoch 85, Loss: 0.45516451232618693\n",
      "Epoch 86, Loss: 0.454518559456726\n",
      "Epoch 87, Loss: 0.4538121767766611\n",
      "Epoch 88, Loss: 0.4530756693328593\n",
      "Epoch 89, Loss: 0.4523772284944851\n",
      "Epoch 90, Loss: 0.4517254426527021\n",
      "Epoch 91, Loss: 0.45110185088021276\n",
      "Epoch 92, Loss: 0.4504416199505386\n",
      "Epoch 93, Loss: 0.4497437104913994\n",
      "Epoch 94, Loss: 0.44903101107866894\n",
      "Epoch 95, Loss: 0.44835938893205324\n",
      "Epoch 96, Loss: 0.44771521680903154\n",
      "Epoch 97, Loss: 0.44703093455735843\n",
      "Epoch 98, Loss: 0.44634902517888086\n",
      "Epoch 99, Loss: 0.4457121945928594\n",
      "Epoch 100, Loss: 0.44511680318456764\n",
      "Epoch 101, Loss: 0.44451610559501015\n",
      "Epoch 102, Loss: 0.44387028366844683\n",
      "Epoch 103, Loss: 0.4432097026915808\n",
      "Epoch 104, Loss: 0.442574533176914\n",
      "Epoch 105, Loss: 0.44192061373625025\n",
      "Epoch 106, Loss: 0.44121979683014867\n",
      "Epoch 107, Loss: 0.44048533965578857\n",
      "Epoch 108, Loss: 0.4397694275908984\n",
      "Epoch 109, Loss: 0.43906239411159337\n",
      "Epoch 110, Loss: 0.43833197097905047\n",
      "Epoch 111, Loss: 0.4376269394777933\n",
      "Epoch 112, Loss: 0.43694541044499624\n",
      "Epoch 113, Loss: 0.43627060431651443\n",
      "Epoch 114, Loss: 0.4356269078643922\n",
      "Epoch 115, Loss: 0.4350032578543639\n",
      "Epoch 116, Loss: 0.4343590212016763\n",
      "Epoch 117, Loss: 0.43373222545515905\n",
      "Epoch 118, Loss: 0.43312597387515367\n",
      "Epoch 119, Loss: 0.4325106384093517\n",
      "Epoch 120, Loss: 0.4319072952561468\n",
      "Epoch 121, Loss: 0.4313046628060067\n",
      "Epoch 122, Loss: 0.43070499286215447\n",
      "Epoch 123, Loss: 0.43014566097396795\n",
      "Epoch 124, Loss: 0.42966880757681614\n",
      "Epoch 125, Loss: 0.42941311832234996\n",
      "Epoch 126, Loss: 0.42892647019825975\n",
      "Epoch 127, Loss: 0.42796822691680375\n",
      "Epoch 128, Loss: 0.4276806174859885\n",
      "Epoch 129, Loss: 0.42723214262936576\n",
      "Epoch 130, Loss: 0.42643753708581095\n",
      "Epoch 131, Loss: 0.4261941744864517\n",
      "Epoch 132, Loss: 0.425509147141168\n",
      "Epoch 133, Loss: 0.42493291213157647\n",
      "Epoch 134, Loss: 0.42464496635342647\n",
      "Epoch 135, Loss: 0.4239140436656129\n",
      "Epoch 136, Loss: 0.42347363180584363\n",
      "Epoch 137, Loss: 0.4231364499660136\n",
      "Epoch 138, Loss: 0.4224145582527396\n",
      "Epoch 139, Loss: 0.4220228642488903\n",
      "Epoch 140, Loss: 0.4216350473484195\n",
      "Epoch 141, Loss: 0.4209470964171903\n",
      "Epoch 142, Loss: 0.4205544608429592\n",
      "Epoch 143, Loss: 0.420122657502626\n",
      "Epoch 144, Loss: 0.41949476655280415\n",
      "Epoch 145, Loss: 0.41900429832807523\n",
      "Epoch 146, Loss: 0.41858264368693937\n",
      "Epoch 147, Loss: 0.4180140604433268\n",
      "Epoch 148, Loss: 0.4173971706521596\n",
      "Epoch 149, Loss: 0.41700158566463885\n",
      "Epoch 150, Loss: 0.4166487590597358\n",
      "Epoch 151, Loss: 0.4160269256632964\n",
      "Epoch 152, Loss: 0.4153628892375715\n",
      "Epoch 153, Loss: 0.4148578741970216\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21269660416159433\n",
      "Test R^2 score: 0.5124977095739494\n",
      "Num of epochs: 154\n",
      "Epoch 1, Loss: 0.5786506479808661\n",
      "Epoch 2, Loss: 0.5756478205494877\n",
      "Epoch 3, Loss: 0.5730923614443529\n",
      "Epoch 4, Loss: 0.5707177329364272\n",
      "Epoch 5, Loss: 0.5685263843889065\n",
      "Epoch 6, Loss: 0.566521310629341\n",
      "Epoch 7, Loss: 0.5646950490390997\n",
      "Epoch 8, Loss: 0.5630545002354951\n",
      "Epoch 9, Loss: 0.5615988771929344\n",
      "Epoch 10, Loss: 0.5603272808740135\n",
      "Epoch 11, Loss: 0.5592535164048509\n",
      "Epoch 12, Loss: 0.5583764567256907\n",
      "Epoch 13, Loss: 0.5576620267620673\n",
      "Epoch 14, Loss: 0.5571030954304752\n",
      "Epoch 15, Loss: 0.55668198281288\n",
      "Epoch 16, Loss: 0.5563886373250266\n",
      "Epoch 17, Loss: 0.5562097588459726\n",
      "Epoch 18, Loss: 0.5561249603148001\n",
      "Epoch 19, Loss: 0.5561202444403528\n",
      "Epoch 20, Loss: 0.556170777240607\n",
      "Epoch 21, Loss: 0.5562549794434971\n",
      "Epoch 22, Loss: 0.5563505521179652\n",
      "Epoch 23, Loss: 0.5564344325396147\n",
      "Epoch 24, Loss: 0.556465067701913\n",
      "Epoch 25, Loss: 0.5564583195417719\n",
      "Epoch 26, Loss: 0.5564199177392456\n",
      "Epoch 27, Loss: 0.5563236605702543\n",
      "Epoch 28, Loss: 0.5561637307894438\n",
      "Epoch 29, Loss: 0.5559376611221535\n",
      "Epoch 30, Loss: 0.5556406508945863\n",
      "Epoch 31, Loss: 0.5552721568980765\n",
      "Epoch 32, Loss: 0.554840953178522\n",
      "Epoch 33, Loss: 0.5543361679462682\n",
      "Epoch 34, Loss: 0.5537466209256856\n",
      "Epoch 35, Loss: 0.5530504327285904\n",
      "Epoch 36, Loss: 0.5522270165613103\n",
      "Epoch 37, Loss: 0.5512269834008097\n",
      "Epoch 38, Loss: 0.5500206802555018\n",
      "Epoch 39, Loss: 0.5485590210528635\n",
      "Epoch 40, Loss: 0.546802679457026\n",
      "Epoch 41, Loss: 0.5447742986980127\n",
      "Epoch 42, Loss: 0.5424421762158721\n",
      "Epoch 43, Loss: 0.539680983079396\n",
      "Epoch 44, Loss: 0.5364629566277347\n",
      "Epoch 45, Loss: 0.5327589819198872\n",
      "Epoch 46, Loss: 0.5285769983084705\n",
      "Epoch 47, Loss: 0.5242799839691848\n",
      "Epoch 48, Loss: 0.5206141551102942\n",
      "Epoch 49, Loss: 0.5184590454407334\n",
      "Epoch 50, Loss: 0.5175730291151703\n",
      "Epoch 51, Loss: 0.5155704931868937\n",
      "Epoch 52, Loss: 0.5119155912874951\n",
      "Epoch 53, Loss: 0.5078436621861355\n",
      "Epoch 54, Loss: 0.5044542334528007\n",
      "Epoch 55, Loss: 0.5019663946275417\n",
      "Epoch 56, Loss: 0.49992350648833467\n",
      "Epoch 57, Loss: 0.4978173269216237\n",
      "Epoch 58, Loss: 0.49539195004153486\n",
      "Epoch 59, Loss: 0.4925863375724071\n",
      "Epoch 60, Loss: 0.489472956761776\n",
      "Epoch 61, Loss: 0.48644852584112047\n",
      "Epoch 62, Loss: 0.4838186422090447\n",
      "Epoch 63, Loss: 0.4817267131363773\n",
      "Epoch 64, Loss: 0.4798869199969047\n",
      "Epoch 65, Loss: 0.4777322234185615\n",
      "Epoch 66, Loss: 0.47517410086731704\n",
      "Epoch 67, Loss: 0.47263072867100975\n",
      "Epoch 68, Loss: 0.47059188414703507\n",
      "Epoch 69, Loss: 0.4692670989937617\n",
      "Epoch 70, Loss: 0.46820246189273523\n",
      "Epoch 71, Loss: 0.46709134378577183\n",
      "Epoch 72, Loss: 0.46594315034854583\n",
      "Epoch 73, Loss: 0.46496820787220916\n",
      "Epoch 74, Loss: 0.46433578112530527\n",
      "Epoch 75, Loss: 0.4639682218042855\n",
      "Epoch 76, Loss: 0.46353047246667817\n",
      "Epoch 77, Loss: 0.46285081845153764\n",
      "Epoch 78, Loss: 0.4620369068376112\n",
      "Epoch 79, Loss: 0.4613077164027116\n",
      "Epoch 80, Loss: 0.4606710730793695\n",
      "Epoch 81, Loss: 0.4600316376016872\n",
      "Epoch 82, Loss: 0.45933496599202517\n",
      "Epoch 83, Loss: 0.4585967842014672\n",
      "Epoch 84, Loss: 0.45789483797888036\n",
      "Epoch 85, Loss: 0.4572537035669556\n",
      "Epoch 86, Loss: 0.45664772830917266\n",
      "Epoch 87, Loss: 0.4559888608423156\n",
      "Epoch 88, Loss: 0.455326078260889\n",
      "Epoch 89, Loss: 0.4547269718826007\n",
      "Epoch 90, Loss: 0.4541263368472964\n",
      "Epoch 91, Loss: 0.45342397692000685\n",
      "Epoch 92, Loss: 0.45262720453989125\n",
      "Epoch 93, Loss: 0.4518632257017097\n",
      "Epoch 94, Loss: 0.45116062893413317\n",
      "Epoch 95, Loss: 0.4504962337444427\n",
      "Epoch 96, Loss: 0.4498051506301808\n",
      "Epoch 97, Loss: 0.44915721305967393\n",
      "Epoch 98, Loss: 0.44856617839166607\n",
      "Epoch 99, Loss: 0.4479862554593927\n",
      "Epoch 100, Loss: 0.44735556951611477\n",
      "Epoch 101, Loss: 0.4466558239045443\n",
      "Epoch 102, Loss: 0.44596983262425777\n",
      "Epoch 103, Loss: 0.4453251652840582\n",
      "Epoch 104, Loss: 0.444639818848118\n",
      "Epoch 105, Loss: 0.4439495544633715\n",
      "Epoch 106, Loss: 0.4432914110430324\n",
      "Epoch 107, Loss: 0.4426229301055195\n",
      "Epoch 108, Loss: 0.44192533438371506\n",
      "Epoch 109, Loss: 0.44122533550977017\n",
      "Epoch 110, Loss: 0.44054920410363174\n",
      "Epoch 111, Loss: 0.43988065480085076\n",
      "Epoch 112, Loss: 0.4392194338494307\n",
      "Epoch 113, Loss: 0.4385481098483993\n",
      "Epoch 114, Loss: 0.4378715878516217\n",
      "Epoch 115, Loss: 0.4371587239652948\n",
      "Epoch 116, Loss: 0.4364192420126422\n",
      "Epoch 117, Loss: 0.4356835839272442\n",
      "Epoch 118, Loss: 0.43493297745690873\n",
      "Epoch 119, Loss: 0.434196568622938\n",
      "Epoch 120, Loss: 0.4334793799147976\n",
      "Epoch 121, Loss: 0.4327945905209426\n",
      "Epoch 122, Loss: 0.43209302505406966\n",
      "Epoch 123, Loss: 0.43135105966853704\n",
      "Epoch 124, Loss: 0.43059871463251576\n",
      "Epoch 125, Loss: 0.42986543612477573\n",
      "Epoch 126, Loss: 0.4291069790928451\n",
      "Epoch 127, Loss: 0.4283343248906267\n",
      "Epoch 128, Loss: 0.4275791984111096\n",
      "Epoch 129, Loss: 0.42679906510404425\n",
      "Epoch 130, Loss: 0.426038839133408\n",
      "Epoch 131, Loss: 0.4253092082763024\n",
      "Epoch 132, Loss: 0.4246079087780411\n",
      "Epoch 133, Loss: 0.4238618933941444\n",
      "Epoch 134, Loss: 0.4231424366388304\n",
      "Epoch 135, Loss: 0.4224556353373424\n",
      "Epoch 136, Loss: 0.4218218028119032\n",
      "Epoch 137, Loss: 0.4211461340712647\n",
      "Epoch 138, Loss: 0.4204380145794932\n",
      "Epoch 139, Loss: 0.4197521665209351\n",
      "Epoch 140, Loss: 0.4190789389746214\n",
      "Epoch 141, Loss: 0.4184084566961173\n",
      "Epoch 142, Loss: 0.41772453803056814\n",
      "Epoch 143, Loss: 0.41705489747972696\n",
      "Epoch 144, Loss: 0.4163926793333027\n",
      "Epoch 145, Loss: 0.4157272736479117\n",
      "Epoch 146, Loss: 0.41508756466367996\n",
      "Epoch 147, Loss: 0.414472413041182\n",
      "Epoch 148, Loss: 0.4138600016209081\n",
      "Epoch 149, Loss: 0.41320656532475325\n",
      "Epoch 150, Loss: 0.4124684328947504\n",
      "Epoch 151, Loss: 0.4117775073460724\n",
      "Epoch 152, Loss: 0.4112063996702488\n",
      "Epoch 153, Loss: 0.41064527513797255\n",
      "Epoch 154, Loss: 0.4100366327156175\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2311115812297358\n",
      "Test R^2 score: 0.42205738306744695\n",
      "Num of epochs: 155\n",
      "Epoch 1, Loss: 0.5614002922032884\n",
      "Epoch 2, Loss: 0.5604624668063729\n",
      "Epoch 3, Loss: 0.5597064533357784\n",
      "Epoch 4, Loss: 0.5590593225123356\n",
      "Epoch 5, Loss: 0.5584702788788785\n",
      "Epoch 6, Loss: 0.557943432398311\n",
      "Epoch 7, Loss: 0.5575007702946152\n",
      "Epoch 8, Loss: 0.5571143293020024\n",
      "Epoch 9, Loss: 0.5567903016281647\n",
      "Epoch 10, Loss: 0.5565281001345711\n",
      "Epoch 11, Loss: 0.5563232320091704\n",
      "Epoch 12, Loss: 0.5561866917105436\n",
      "Epoch 13, Loss: 0.5561021844149764\n",
      "Epoch 14, Loss: 0.5560514041976549\n",
      "Epoch 15, Loss: 0.5560259453513976\n",
      "Epoch 16, Loss: 0.5560160294853306\n",
      "Epoch 17, Loss: 0.5560105354834047\n",
      "Epoch 18, Loss: 0.5559978856725766\n",
      "Epoch 19, Loss: 0.5559674391851946\n",
      "Epoch 20, Loss: 0.5559105887715746\n",
      "Epoch 21, Loss: 0.5558194444351876\n",
      "Epoch 22, Loss: 0.5556791065505913\n",
      "Epoch 23, Loss: 0.5554413843724118\n",
      "Epoch 24, Loss: 0.5551018309178684\n",
      "Epoch 25, Loss: 0.554799592418356\n",
      "Epoch 26, Loss: 0.5544252178494623\n",
      "Epoch 27, Loss: 0.5539688774397526\n",
      "Epoch 28, Loss: 0.553413405365083\n",
      "Epoch 29, Loss: 0.5527448349896424\n",
      "Epoch 30, Loss: 0.5519416435327203\n",
      "Epoch 31, Loss: 0.5509700316346673\n",
      "Epoch 32, Loss: 0.5497902687038598\n",
      "Epoch 33, Loss: 0.5483839470781485\n",
      "Epoch 34, Loss: 0.5466720749521611\n",
      "Epoch 35, Loss: 0.5445893342880013\n",
      "Epoch 36, Loss: 0.5421359309756183\n",
      "Epoch 37, Loss: 0.539176652404118\n",
      "Epoch 38, Loss: 0.5356328749105601\n",
      "Epoch 39, Loss: 0.531458252872275\n",
      "Epoch 40, Loss: 0.526721049812703\n",
      "Epoch 41, Loss: 0.5215932610950414\n",
      "Epoch 42, Loss: 0.5163091686599847\n",
      "Epoch 43, Loss: 0.5115475550235458\n",
      "Epoch 44, Loss: 0.5087344090840067\n",
      "Epoch 45, Loss: 0.5084857878822883\n",
      "Epoch 46, Loss: 0.5071716372864478\n",
      "Epoch 47, Loss: 0.5029447386628283\n",
      "Epoch 48, Loss: 0.49804150447567824\n",
      "Epoch 49, Loss: 0.4949079293301251\n",
      "Epoch 50, Loss: 0.4940651847336926\n",
      "Epoch 51, Loss: 0.49228042149248535\n",
      "Epoch 52, Loss: 0.48869045658292964\n",
      "Epoch 53, Loss: 0.48487406831018987\n",
      "Epoch 54, Loss: 0.4820096652547799\n",
      "Epoch 55, Loss: 0.4802875952633155\n",
      "Epoch 56, Loss: 0.4793802196661158\n",
      "Epoch 57, Loss: 0.47903157658814377\n",
      "Epoch 58, Loss: 0.4788094066385009\n",
      "Epoch 59, Loss: 0.47806281639085657\n",
      "Epoch 60, Loss: 0.47672054921838747\n",
      "Epoch 61, Loss: 0.4751867698845453\n",
      "Epoch 62, Loss: 0.47388912226574426\n",
      "Epoch 63, Loss: 0.4728897715859722\n",
      "Epoch 64, Loss: 0.4720988652058307\n",
      "Epoch 65, Loss: 0.47136258983638013\n",
      "Epoch 66, Loss: 0.47065872362850864\n",
      "Epoch 67, Loss: 0.4698867524705133\n",
      "Epoch 68, Loss: 0.4690444180626828\n",
      "Epoch 69, Loss: 0.4681710960041266\n",
      "Epoch 70, Loss: 0.46731146376646565\n",
      "Epoch 71, Loss: 0.46643772434381037\n",
      "Epoch 72, Loss: 0.4655844293111138\n",
      "Epoch 73, Loss: 0.46481403287896667\n",
      "Epoch 74, Loss: 0.464113848507302\n",
      "Epoch 75, Loss: 0.46347868059255465\n",
      "Epoch 76, Loss: 0.46288507192636785\n",
      "Epoch 77, Loss: 0.4623087029872958\n",
      "Epoch 78, Loss: 0.4617184956867789\n",
      "Epoch 79, Loss: 0.46110562313438513\n",
      "Epoch 80, Loss: 0.46039837488746016\n",
      "Epoch 81, Loss: 0.4596422553341669\n",
      "Epoch 82, Loss: 0.45890336640711554\n",
      "Epoch 83, Loss: 0.45817727083467796\n",
      "Epoch 84, Loss: 0.4575450975568354\n",
      "Epoch 85, Loss: 0.4570462640105726\n",
      "Epoch 86, Loss: 0.45658781269984\n",
      "Epoch 87, Loss: 0.4560832274040872\n",
      "Epoch 88, Loss: 0.45552335905777414\n",
      "Epoch 89, Loss: 0.45498101176474925\n",
      "Epoch 90, Loss: 0.45445937959151816\n",
      "Epoch 91, Loss: 0.4539252646529337\n",
      "Epoch 92, Loss: 0.45341650038084375\n",
      "Epoch 93, Loss: 0.45289073018218734\n",
      "Epoch 94, Loss: 0.4523384403582566\n",
      "Epoch 95, Loss: 0.451810904424723\n",
      "Epoch 96, Loss: 0.4513077964648554\n",
      "Epoch 97, Loss: 0.45079892089163714\n",
      "Epoch 98, Loss: 0.4503309661975732\n",
      "Epoch 99, Loss: 0.44983951965441726\n",
      "Epoch 100, Loss: 0.4493387642471128\n",
      "Epoch 101, Loss: 0.4488590458908465\n",
      "Epoch 102, Loss: 0.4483297756944956\n",
      "Epoch 103, Loss: 0.44782418767527127\n",
      "Epoch 104, Loss: 0.44729569179972606\n",
      "Epoch 105, Loss: 0.4467941531161627\n",
      "Epoch 106, Loss: 0.44627894550767844\n",
      "Epoch 107, Loss: 0.44578463639003657\n",
      "Epoch 108, Loss: 0.44527418406765523\n",
      "Epoch 109, Loss: 0.4447594772441995\n",
      "Epoch 110, Loss: 0.4442318134084403\n",
      "Epoch 111, Loss: 0.4437120857966096\n",
      "Epoch 112, Loss: 0.44317821549016073\n",
      "Epoch 113, Loss: 0.44266578432446657\n",
      "Epoch 114, Loss: 0.4420977214889123\n",
      "Epoch 115, Loss: 0.4415492948486517\n",
      "Epoch 116, Loss: 0.44093800918474\n",
      "Epoch 117, Loss: 0.44032601026461266\n",
      "Epoch 118, Loss: 0.439732102746111\n",
      "Epoch 119, Loss: 0.43909139368414457\n",
      "Epoch 120, Loss: 0.4385019477683537\n",
      "Epoch 121, Loss: 0.4378461830529508\n",
      "Epoch 122, Loss: 0.43716794423558863\n",
      "Epoch 123, Loss: 0.436521867241478\n",
      "Epoch 124, Loss: 0.43581069346219936\n",
      "Epoch 125, Loss: 0.43514335654314784\n",
      "Epoch 126, Loss: 0.43448097939556307\n",
      "Epoch 127, Loss: 0.43377059904100457\n",
      "Epoch 128, Loss: 0.43305741896190025\n",
      "Epoch 129, Loss: 0.4323836960173091\n",
      "Epoch 130, Loss: 0.43175770824379\n",
      "Epoch 131, Loss: 0.43105611450899384\n",
      "Epoch 132, Loss: 0.4303110453429391\n",
      "Epoch 133, Loss: 0.42957991206782864\n",
      "Epoch 134, Loss: 0.42888226051155376\n",
      "Epoch 135, Loss: 0.4282115382422603\n",
      "Epoch 136, Loss: 0.4275496445379206\n",
      "Epoch 137, Loss: 0.42692737135210973\n",
      "Epoch 138, Loss: 0.4263694619831504\n",
      "Epoch 139, Loss: 0.42609093279409077\n",
      "Epoch 140, Loss: 0.42688059840852766\n",
      "Epoch 141, Loss: 0.4254347414902684\n",
      "Epoch 142, Loss: 0.4239617765444588\n",
      "Epoch 143, Loss: 0.4238046208909236\n",
      "Epoch 144, Loss: 0.4232536853025978\n",
      "Epoch 145, Loss: 0.42222435932218105\n",
      "Epoch 146, Loss: 0.42171017641254543\n",
      "Epoch 147, Loss: 0.42132725301574864\n",
      "Epoch 148, Loss: 0.4205011851864418\n",
      "Epoch 149, Loss: 0.4197051620175496\n",
      "Epoch 150, Loss: 0.4193260934400053\n",
      "Epoch 151, Loss: 0.41904158475314374\n",
      "Epoch 152, Loss: 0.41814379725377787\n",
      "Epoch 153, Loss: 0.41732244345070946\n",
      "Epoch 154, Loss: 0.41695493223482316\n",
      "Epoch 155, Loss: 0.4166089335816493\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21214053845169736\n",
      "Test R^2 score: 0.5108824357433084\n",
      "Num of epochs: 156\n",
      "Epoch 1, Loss: 0.6037788434375294\n",
      "Epoch 2, Loss: 0.6004119621064306\n",
      "Epoch 3, Loss: 0.5971273438054514\n",
      "Epoch 4, Loss: 0.5939280092528204\n",
      "Epoch 5, Loss: 0.5908200098462552\n",
      "Epoch 6, Loss: 0.5878346311954887\n",
      "Epoch 7, Loss: 0.5852577589988086\n",
      "Epoch 8, Loss: 0.5830135888303932\n",
      "Epoch 9, Loss: 0.580829147034623\n",
      "Epoch 10, Loss: 0.5787118047217863\n",
      "Epoch 11, Loss: 0.5766673656920605\n",
      "Epoch 12, Loss: 0.5746991749293755\n",
      "Epoch 13, Loss: 0.572849431572068\n",
      "Epoch 14, Loss: 0.5713257606652516\n",
      "Epoch 15, Loss: 0.5698620310498151\n",
      "Epoch 16, Loss: 0.5684585746897531\n",
      "Epoch 17, Loss: 0.5671161543686202\n",
      "Epoch 18, Loss: 0.5658337034169009\n",
      "Epoch 19, Loss: 0.5646363327328119\n",
      "Epoch 20, Loss: 0.5635681606794047\n",
      "Epoch 21, Loss: 0.5625830165214402\n",
      "Epoch 22, Loss: 0.5616417270956822\n",
      "Epoch 23, Loss: 0.560757135705534\n",
      "Epoch 24, Loss: 0.5599368028658761\n",
      "Epoch 25, Loss: 0.5591701921142476\n",
      "Epoch 26, Loss: 0.5584623809207075\n",
      "Epoch 27, Loss: 0.5578225420734465\n",
      "Epoch 28, Loss: 0.5572512573375182\n",
      "Epoch 29, Loss: 0.5569742106677411\n",
      "Epoch 30, Loss: 0.5567597914178615\n",
      "Epoch 31, Loss: 0.5565237089814984\n",
      "Epoch 32, Loss: 0.5563287497078874\n",
      "Epoch 33, Loss: 0.5561715006354833\n",
      "Epoch 34, Loss: 0.5560466341025712\n",
      "Epoch 35, Loss: 0.5559500442727867\n",
      "Epoch 36, Loss: 0.5558735162755072\n",
      "Epoch 37, Loss: 0.5558091227374028\n",
      "Epoch 38, Loss: 0.5557480197224276\n",
      "Epoch 39, Loss: 0.5556746818721089\n",
      "Epoch 40, Loss: 0.5555760694398652\n",
      "Epoch 41, Loss: 0.555440177128945\n",
      "Epoch 42, Loss: 0.5552574238596466\n",
      "Epoch 43, Loss: 0.5550137218720753\n",
      "Epoch 44, Loss: 0.554694753250195\n",
      "Epoch 45, Loss: 0.5542865701138248\n",
      "Epoch 46, Loss: 0.5537780774836488\n",
      "Epoch 47, Loss: 0.5531548831432099\n",
      "Epoch 48, Loss: 0.5523899474511688\n",
      "Epoch 49, Loss: 0.5514274756091034\n",
      "Epoch 50, Loss: 0.5502297907579686\n",
      "Epoch 51, Loss: 0.5487120427535814\n",
      "Epoch 52, Loss: 0.5468006355950987\n",
      "Epoch 53, Loss: 0.5444329368689983\n",
      "Epoch 54, Loss: 0.5416306398099414\n",
      "Epoch 55, Loss: 0.538558945910487\n",
      "Epoch 56, Loss: 0.5356775793488363\n",
      "Epoch 57, Loss: 0.5334225437188386\n",
      "Epoch 58, Loss: 0.5315687401442837\n",
      "Epoch 59, Loss: 0.5297094897541614\n",
      "Epoch 60, Loss: 0.5273514075959498\n",
      "Epoch 61, Loss: 0.5244287243716785\n",
      "Epoch 62, Loss: 0.5214878896530526\n",
      "Epoch 63, Loss: 0.5185404055365367\n",
      "Epoch 64, Loss: 0.5154597277630787\n",
      "Epoch 65, Loss: 0.5124892338342985\n",
      "Epoch 66, Loss: 0.5099496618841078\n",
      "Epoch 67, Loss: 0.5073069770533974\n",
      "Epoch 68, Loss: 0.5042442252925868\n",
      "Epoch 69, Loss: 0.5015380271098622\n",
      "Epoch 70, Loss: 0.4994580639971336\n",
      "Epoch 71, Loss: 0.4973074117095549\n",
      "Epoch 72, Loss: 0.494920981390552\n",
      "Epoch 73, Loss: 0.4927166864145431\n",
      "Epoch 74, Loss: 0.49090096190213217\n",
      "Epoch 75, Loss: 0.4887877926763873\n",
      "Epoch 76, Loss: 0.48644710142523023\n",
      "Epoch 77, Loss: 0.48432805233750026\n",
      "Epoch 78, Loss: 0.48197302999960023\n",
      "Epoch 79, Loss: 0.4793596880977753\n",
      "Epoch 80, Loss: 0.4769669364410355\n",
      "Epoch 81, Loss: 0.4747545624624725\n",
      "Epoch 82, Loss: 0.47241144697749105\n",
      "Epoch 83, Loss: 0.4706617946603362\n",
      "Epoch 84, Loss: 0.4691863889710278\n",
      "Epoch 85, Loss: 0.46763521194932206\n",
      "Epoch 86, Loss: 0.466413012891649\n",
      "Epoch 87, Loss: 0.4651600378751694\n",
      "Epoch 88, Loss: 0.463650028192928\n",
      "Epoch 89, Loss: 0.4620358586782955\n",
      "Epoch 90, Loss: 0.4602737173199218\n",
      "Epoch 91, Loss: 0.45895487913764615\n",
      "Epoch 92, Loss: 0.4580591331636143\n",
      "Epoch 93, Loss: 0.45696936294315255\n",
      "Epoch 94, Loss: 0.45592650546020785\n",
      "Epoch 95, Loss: 0.4551311183739254\n",
      "Epoch 96, Loss: 0.4542984894373671\n",
      "Epoch 97, Loss: 0.453442478770416\n",
      "Epoch 98, Loss: 0.4525121951699162\n",
      "Epoch 99, Loss: 0.45163478470757573\n",
      "Epoch 100, Loss: 0.45092517333653653\n",
      "Epoch 101, Loss: 0.45001281547841554\n",
      "Epoch 102, Loss: 0.44934614282516505\n",
      "Epoch 103, Loss: 0.4495508376260412\n",
      "Epoch 104, Loss: 0.44800212141049867\n",
      "Epoch 105, Loss: 0.4463982813640978\n",
      "Epoch 106, Loss: 0.4464272049474239\n",
      "Epoch 107, Loss: 0.4445535315643101\n",
      "Epoch 108, Loss: 0.44446142751147694\n",
      "Epoch 109, Loss: 0.44284437744578564\n",
      "Epoch 110, Loss: 0.44234821782202083\n",
      "Epoch 111, Loss: 0.44112306135988777\n",
      "Epoch 112, Loss: 0.4404190975700762\n",
      "Epoch 113, Loss: 0.4395628220019876\n",
      "Epoch 114, Loss: 0.4385017948494502\n",
      "Epoch 115, Loss: 0.4379321246257555\n",
      "Epoch 116, Loss: 0.4366574177812044\n",
      "Epoch 117, Loss: 0.4361857018729547\n",
      "Epoch 118, Loss: 0.4349093197161026\n",
      "Epoch 119, Loss: 0.4343513880288021\n",
      "Epoch 120, Loss: 0.4333708937884766\n",
      "Epoch 121, Loss: 0.4325403528462106\n",
      "Epoch 122, Loss: 0.4318734831169198\n",
      "Epoch 123, Loss: 0.4308574354831899\n",
      "Epoch 124, Loss: 0.43027930686434906\n",
      "Epoch 125, Loss: 0.42951923890595084\n",
      "Epoch 126, Loss: 0.42873604946406596\n",
      "Epoch 127, Loss: 0.4281970965805489\n",
      "Epoch 128, Loss: 0.4274279398166264\n",
      "Epoch 129, Loss: 0.4266466917016321\n",
      "Epoch 130, Loss: 0.4260798990525428\n",
      "Epoch 131, Loss: 0.42539624647449276\n",
      "Epoch 132, Loss: 0.4246472998898515\n",
      "Epoch 133, Loss: 0.42401836010929744\n",
      "Epoch 134, Loss: 0.4234587470491798\n",
      "Epoch 135, Loss: 0.4227685472434145\n",
      "Epoch 136, Loss: 0.4220314618773566\n",
      "Epoch 137, Loss: 0.4213967261336131\n",
      "Epoch 138, Loss: 0.4208002883224805\n",
      "Epoch 139, Loss: 0.42017669043537675\n",
      "Epoch 140, Loss: 0.4195249411394512\n",
      "Epoch 141, Loss: 0.41884868014231164\n",
      "Epoch 142, Loss: 0.41819454048192517\n",
      "Epoch 143, Loss: 0.4175324167869544\n",
      "Epoch 144, Loss: 0.4169118477751713\n",
      "Epoch 145, Loss: 0.4163781140467818\n",
      "Epoch 146, Loss: 0.41606705755093054\n",
      "Epoch 147, Loss: 0.41605964391942063\n",
      "Epoch 148, Loss: 0.4163711712001824\n",
      "Epoch 149, Loss: 0.4146974122300827\n",
      "Epoch 150, Loss: 0.41325138827862085\n",
      "Epoch 151, Loss: 0.41323512564496573\n",
      "Epoch 152, Loss: 0.4131037210013861\n",
      "Epoch 153, Loss: 0.4120220616125859\n",
      "Epoch 154, Loss: 0.41101933451350614\n",
      "Epoch 155, Loss: 0.41096286477832356\n",
      "Epoch 156, Loss: 0.4106287459924032\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21337151441224403\n",
      "Test R^2 score: 0.5084105716870584\n",
      "Num of epochs: 157\n",
      "Epoch 1, Loss: 0.5677363858306117\n",
      "Epoch 2, Loss: 0.5664780406837131\n",
      "Epoch 3, Loss: 0.5653015676762457\n",
      "Epoch 4, Loss: 0.5642401481549204\n",
      "Epoch 5, Loss: 0.5632629783090095\n",
      "Epoch 6, Loss: 0.5623574076162858\n",
      "Epoch 7, Loss: 0.5615231986667291\n",
      "Epoch 8, Loss: 0.5607583315022454\n",
      "Epoch 9, Loss: 0.5600605626225473\n",
      "Epoch 10, Loss: 0.5594276392799311\n",
      "Epoch 11, Loss: 0.5588570887716453\n",
      "Epoch 12, Loss: 0.5583475544053106\n",
      "Epoch 13, Loss: 0.5578950366764721\n",
      "Epoch 14, Loss: 0.5574961729730875\n",
      "Epoch 15, Loss: 0.5571482702662999\n",
      "Epoch 16, Loss: 0.5568450819941847\n",
      "Epoch 17, Loss: 0.556582799216822\n",
      "Epoch 18, Loss: 0.5563567391327585\n",
      "Epoch 19, Loss: 0.5561616141573996\n",
      "Epoch 20, Loss: 0.5559909174335087\n",
      "Epoch 21, Loss: 0.5558368970517475\n",
      "Epoch 22, Loss: 0.5556910395987378\n",
      "Epoch 23, Loss: 0.5555402352949244\n",
      "Epoch 24, Loss: 0.5553705013212288\n",
      "Epoch 25, Loss: 0.5551683195580635\n",
      "Epoch 26, Loss: 0.554921785763037\n",
      "Epoch 27, Loss: 0.554621007453144\n",
      "Epoch 28, Loss: 0.5542607613561109\n",
      "Epoch 29, Loss: 0.5538338822409823\n",
      "Epoch 30, Loss: 0.5533108350572967\n",
      "Epoch 31, Loss: 0.5526521709227971\n",
      "Epoch 32, Loss: 0.5518342361861416\n",
      "Epoch 33, Loss: 0.5508084662456493\n",
      "Epoch 34, Loss: 0.5495468266730515\n",
      "Epoch 35, Loss: 0.5480034493543144\n",
      "Epoch 36, Loss: 0.5461683339716389\n",
      "Epoch 37, Loss: 0.5440225049896477\n",
      "Epoch 38, Loss: 0.5415078413246758\n",
      "Epoch 39, Loss: 0.5385679657919817\n",
      "Epoch 40, Loss: 0.5352742976838943\n",
      "Epoch 41, Loss: 0.5318116977195593\n",
      "Epoch 42, Loss: 0.5284638553591448\n",
      "Epoch 43, Loss: 0.5258044913654754\n",
      "Epoch 44, Loss: 0.5242923190345677\n",
      "Epoch 45, Loss: 0.5232049226039328\n",
      "Epoch 46, Loss: 0.5209220397430858\n",
      "Epoch 47, Loss: 0.5175127671919753\n",
      "Epoch 48, Loss: 0.5141284494504581\n",
      "Epoch 49, Loss: 0.5115302808958544\n",
      "Epoch 50, Loss: 0.5096882728556767\n",
      "Epoch 51, Loss: 0.5081102525323467\n",
      "Epoch 52, Loss: 0.5063394455717646\n",
      "Epoch 53, Loss: 0.5041180838146657\n",
      "Epoch 54, Loss: 0.5014580389079281\n",
      "Epoch 55, Loss: 0.49864814217742615\n",
      "Epoch 56, Loss: 0.49602108520828697\n",
      "Epoch 57, Loss: 0.4937963983005796\n",
      "Epoch 58, Loss: 0.49186261368682616\n",
      "Epoch 59, Loss: 0.48989969204840217\n",
      "Epoch 60, Loss: 0.4875358079328365\n",
      "Epoch 61, Loss: 0.48515960765911453\n",
      "Epoch 62, Loss: 0.48323219600428835\n",
      "Epoch 63, Loss: 0.48185383021637485\n",
      "Epoch 64, Loss: 0.48039932059475027\n",
      "Epoch 65, Loss: 0.4787329978015423\n",
      "Epoch 66, Loss: 0.47703058674451027\n",
      "Epoch 67, Loss: 0.4755986582094648\n",
      "Epoch 68, Loss: 0.4743029071975329\n",
      "Epoch 69, Loss: 0.47277551517693506\n",
      "Epoch 70, Loss: 0.471146323463623\n",
      "Epoch 71, Loss: 0.4695731882163251\n",
      "Epoch 72, Loss: 0.4679732562884623\n",
      "Epoch 73, Loss: 0.4661931239457697\n",
      "Epoch 74, Loss: 0.4643334384509833\n",
      "Epoch 75, Loss: 0.4625130413124111\n",
      "Epoch 76, Loss: 0.46079622140223436\n",
      "Epoch 77, Loss: 0.4591527427124503\n",
      "Epoch 78, Loss: 0.4580611012901076\n",
      "Epoch 79, Loss: 0.4574747134865645\n",
      "Epoch 80, Loss: 0.45755232751442115\n",
      "Epoch 81, Loss: 0.457770052038871\n",
      "Epoch 82, Loss: 0.45714308519708957\n",
      "Epoch 83, Loss: 0.4559881092296791\n",
      "Epoch 84, Loss: 0.45479221121452096\n",
      "Epoch 85, Loss: 0.45364544018430203\n",
      "Epoch 86, Loss: 0.4527545763170989\n",
      "Epoch 87, Loss: 0.45209514394471273\n",
      "Epoch 88, Loss: 0.45146981842449024\n",
      "Epoch 89, Loss: 0.45075722007237157\n",
      "Epoch 90, Loss: 0.4501390401297288\n",
      "Epoch 91, Loss: 0.44950542424825546\n",
      "Epoch 92, Loss: 0.4488529540416136\n",
      "Epoch 93, Loss: 0.4481440251726397\n",
      "Epoch 94, Loss: 0.4473216925381767\n",
      "Epoch 95, Loss: 0.4464428425960123\n",
      "Epoch 96, Loss: 0.4456641665791328\n",
      "Epoch 97, Loss: 0.4449249890413565\n",
      "Epoch 98, Loss: 0.4443228583454521\n",
      "Epoch 99, Loss: 0.44373330971398445\n",
      "Epoch 100, Loss: 0.4431098370183943\n",
      "Epoch 101, Loss: 0.4424212104351826\n",
      "Epoch 102, Loss: 0.4416663829634613\n",
      "Epoch 103, Loss: 0.44093163892607184\n",
      "Epoch 104, Loss: 0.44023474800750717\n",
      "Epoch 105, Loss: 0.43950388297360926\n",
      "Epoch 106, Loss: 0.4386441562553794\n",
      "Epoch 107, Loss: 0.4378036569196455\n",
      "Epoch 108, Loss: 0.4369510033056542\n",
      "Epoch 109, Loss: 0.43611638080480014\n",
      "Epoch 110, Loss: 0.4353252240338946\n",
      "Epoch 111, Loss: 0.43452544248582653\n",
      "Epoch 112, Loss: 0.43382926936645266\n",
      "Epoch 113, Loss: 0.43317850522802526\n",
      "Epoch 114, Loss: 0.4324794403602823\n",
      "Epoch 115, Loss: 0.431847035348664\n",
      "Epoch 116, Loss: 0.4312238623120241\n",
      "Epoch 117, Loss: 0.43064008373534995\n",
      "Epoch 118, Loss: 0.43003193315321847\n",
      "Epoch 119, Loss: 0.4293897464113418\n",
      "Epoch 120, Loss: 0.4287672244857759\n",
      "Epoch 121, Loss: 0.4281378806745197\n",
      "Epoch 122, Loss: 0.42751364042036805\n",
      "Epoch 123, Loss: 0.42691276408383827\n",
      "Epoch 124, Loss: 0.4263206005638282\n",
      "Epoch 125, Loss: 0.42573928626216734\n",
      "Epoch 126, Loss: 0.4251381978972993\n",
      "Epoch 127, Loss: 0.42455022798252867\n",
      "Epoch 128, Loss: 0.4239720394658955\n",
      "Epoch 129, Loss: 0.42338255564500044\n",
      "Epoch 130, Loss: 0.42283471758902447\n",
      "Epoch 131, Loss: 0.422284704407239\n",
      "Epoch 132, Loss: 0.4217164130073688\n",
      "Epoch 133, Loss: 0.42114737245346223\n",
      "Epoch 134, Loss: 0.4205856400052352\n",
      "Epoch 135, Loss: 0.42002638469994785\n",
      "Epoch 136, Loss: 0.4194782841668967\n",
      "Epoch 137, Loss: 0.4189179062493306\n",
      "Epoch 138, Loss: 0.41836707128574563\n",
      "Epoch 139, Loss: 0.41789064836314804\n",
      "Epoch 140, Loss: 0.4176094079142692\n",
      "Epoch 141, Loss: 0.41730430410900105\n",
      "Epoch 142, Loss: 0.4163392469309635\n",
      "Epoch 143, Loss: 0.4156547736495956\n",
      "Epoch 144, Loss: 0.41556402777398005\n",
      "Epoch 145, Loss: 0.41475175674484915\n",
      "Epoch 146, Loss: 0.41404594532243844\n",
      "Epoch 147, Loss: 0.41383598537660476\n",
      "Epoch 148, Loss: 0.41308348454317506\n",
      "Epoch 149, Loss: 0.41238793454752215\n",
      "Epoch 150, Loss: 0.4121128281001195\n",
      "Epoch 151, Loss: 0.41148944527866643\n",
      "Epoch 152, Loss: 0.4107607247327558\n",
      "Epoch 153, Loss: 0.41037764250769887\n",
      "Epoch 154, Loss: 0.4099561293902964\n",
      "Epoch 155, Loss: 0.4092221294961216\n",
      "Epoch 156, Loss: 0.4086724280322808\n",
      "Epoch 157, Loss: 0.408288499583114\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22097104226576514\n",
      "Test R^2 score: 0.47176262284271464\n",
      "Num of epochs: 158\n",
      "Epoch 1, Loss: 0.5707495856515431\n",
      "Epoch 2, Loss: 0.5697450296771863\n",
      "Epoch 3, Loss: 0.5687723920417537\n",
      "Epoch 4, Loss: 0.5678335687468705\n",
      "Epoch 5, Loss: 0.5669379008260931\n",
      "Epoch 6, Loss: 0.5661443960059859\n",
      "Epoch 7, Loss: 0.5654610211744631\n",
      "Epoch 8, Loss: 0.5647930718740639\n",
      "Epoch 9, Loss: 0.5641410519331915\n",
      "Epoch 10, Loss: 0.5635053339708278\n",
      "Epoch 11, Loss: 0.5628858408569083\n",
      "Epoch 12, Loss: 0.5623032172694965\n",
      "Epoch 13, Loss: 0.5617251887900813\n",
      "Epoch 14, Loss: 0.5611632676429028\n",
      "Epoch 15, Loss: 0.5605689652506369\n",
      "Epoch 16, Loss: 0.5600019990084937\n",
      "Epoch 17, Loss: 0.5594631178940549\n",
      "Epoch 18, Loss: 0.5589655459129764\n",
      "Epoch 19, Loss: 0.5585173708042271\n",
      "Epoch 20, Loss: 0.5580972185301047\n",
      "Epoch 21, Loss: 0.5577099884895936\n",
      "Epoch 22, Loss: 0.557357647516409\n",
      "Epoch 23, Loss: 0.5570423216073913\n",
      "Epoch 24, Loss: 0.556766107703894\n",
      "Epoch 25, Loss: 0.556530831200104\n",
      "Epoch 26, Loss: 0.5563378564695673\n",
      "Epoch 27, Loss: 0.5561878973336498\n",
      "Epoch 28, Loss: 0.5560763259391684\n",
      "Epoch 29, Loss: 0.5559928471084558\n",
      "Epoch 30, Loss: 0.5559294591432619\n",
      "Epoch 31, Loss: 0.5558798158255592\n",
      "Epoch 32, Loss: 0.5558348864095667\n",
      "Epoch 33, Loss: 0.5557818296363517\n",
      "Epoch 34, Loss: 0.555708818024394\n",
      "Epoch 35, Loss: 0.5556039626834325\n",
      "Epoch 36, Loss: 0.5554559783969565\n",
      "Epoch 37, Loss: 0.5552555453020565\n",
      "Epoch 38, Loss: 0.5549921891375935\n",
      "Epoch 39, Loss: 0.5546382559825037\n",
      "Epoch 40, Loss: 0.5542038971959741\n",
      "Epoch 41, Loss: 0.5536993116339024\n",
      "Epoch 42, Loss: 0.5530567913780325\n",
      "Epoch 43, Loss: 0.5522223483511263\n",
      "Epoch 44, Loss: 0.5511756188517594\n",
      "Epoch 45, Loss: 0.5499328951646636\n",
      "Epoch 46, Loss: 0.5484609767312336\n",
      "Epoch 47, Loss: 0.5466849950687444\n",
      "Epoch 48, Loss: 0.5445839986332529\n",
      "Epoch 49, Loss: 0.5421647355635211\n",
      "Epoch 50, Loss: 0.5393033249883932\n",
      "Epoch 51, Loss: 0.5358671214434609\n",
      "Epoch 52, Loss: 0.5317608677014026\n",
      "Epoch 53, Loss: 0.526909232379393\n",
      "Epoch 54, Loss: 0.5213954435376954\n",
      "Epoch 55, Loss: 0.5156518466780645\n",
      "Epoch 56, Loss: 0.5102472478258745\n",
      "Epoch 57, Loss: 0.5058285029943729\n",
      "Epoch 58, Loss: 0.5017047965438813\n",
      "Epoch 59, Loss: 0.4970691583466387\n",
      "Epoch 60, Loss: 0.49209428843137315\n",
      "Epoch 61, Loss: 0.487356775592235\n",
      "Epoch 62, Loss: 0.4832969481924556\n",
      "Epoch 63, Loss: 0.4800412516947943\n",
      "Epoch 64, Loss: 0.47768573029861744\n",
      "Epoch 65, Loss: 0.4760688977066418\n",
      "Epoch 66, Loss: 0.4749843074063555\n",
      "Epoch 67, Loss: 0.4741211408935272\n",
      "Epoch 68, Loss: 0.4734971628899658\n",
      "Epoch 69, Loss: 0.4730324154698526\n",
      "Epoch 70, Loss: 0.4723611493680652\n",
      "Epoch 71, Loss: 0.4712032178277907\n",
      "Epoch 72, Loss: 0.4698683114414261\n",
      "Epoch 73, Loss: 0.4686390904505839\n",
      "Epoch 74, Loss: 0.46730451234850734\n",
      "Epoch 75, Loss: 0.46571396867388565\n",
      "Epoch 76, Loss: 0.46419768756551805\n",
      "Epoch 77, Loss: 0.4630826559799199\n",
      "Epoch 78, Loss: 0.46221081997922275\n",
      "Epoch 79, Loss: 0.4614039017268441\n",
      "Epoch 80, Loss: 0.46075809349427804\n",
      "Epoch 81, Loss: 0.4600395410844079\n",
      "Epoch 82, Loss: 0.4592608491667891\n",
      "Epoch 83, Loss: 0.4586215756502401\n",
      "Epoch 84, Loss: 0.45782266872426747\n",
      "Epoch 85, Loss: 0.4569265131474133\n",
      "Epoch 86, Loss: 0.4561104423863559\n",
      "Epoch 87, Loss: 0.45520268319622154\n",
      "Epoch 88, Loss: 0.4543583625780341\n",
      "Epoch 89, Loss: 0.453405309989681\n",
      "Epoch 90, Loss: 0.45249661908019484\n",
      "Epoch 91, Loss: 0.4516778396031559\n",
      "Epoch 92, Loss: 0.4508591430906718\n",
      "Epoch 93, Loss: 0.45007910231894865\n",
      "Epoch 94, Loss: 0.44923780649648604\n",
      "Epoch 95, Loss: 0.44845908242635385\n",
      "Epoch 96, Loss: 0.4476329178246999\n",
      "Epoch 97, Loss: 0.4468565490221403\n",
      "Epoch 98, Loss: 0.4460491144727613\n",
      "Epoch 99, Loss: 0.4453148758138892\n",
      "Epoch 100, Loss: 0.44453955376081483\n",
      "Epoch 101, Loss: 0.4436971579238214\n",
      "Epoch 102, Loss: 0.4429333021724785\n",
      "Epoch 103, Loss: 0.44214076142262315\n",
      "Epoch 104, Loss: 0.44137846597646496\n",
      "Epoch 105, Loss: 0.44063801712395795\n",
      "Epoch 106, Loss: 0.43985689052107646\n",
      "Epoch 107, Loss: 0.43906607643381335\n",
      "Epoch 108, Loss: 0.43827461740843615\n",
      "Epoch 109, Loss: 0.4374688682378869\n",
      "Epoch 110, Loss: 0.4366408154003788\n",
      "Epoch 111, Loss: 0.43580917192351154\n",
      "Epoch 112, Loss: 0.4349845711942525\n",
      "Epoch 113, Loss: 0.4342035696280039\n",
      "Epoch 114, Loss: 0.43342308603535135\n",
      "Epoch 115, Loss: 0.43263134384243535\n",
      "Epoch 116, Loss: 0.431866358078477\n",
      "Epoch 117, Loss: 0.4311252987286292\n",
      "Epoch 118, Loss: 0.4304087048311494\n",
      "Epoch 119, Loss: 0.42969537207588354\n",
      "Epoch 120, Loss: 0.42899733516003274\n",
      "Epoch 121, Loss: 0.4282097287113391\n",
      "Epoch 122, Loss: 0.42747372911834225\n",
      "Epoch 123, Loss: 0.42679614979491887\n",
      "Epoch 124, Loss: 0.4261533703444824\n",
      "Epoch 125, Loss: 0.4255195653453722\n",
      "Epoch 126, Loss: 0.42495060311084\n",
      "Epoch 127, Loss: 0.4244451996800448\n",
      "Epoch 128, Loss: 0.42391073942355684\n",
      "Epoch 129, Loss: 0.4233872894134318\n",
      "Epoch 130, Loss: 0.4223986484074733\n",
      "Epoch 131, Loss: 0.4216094417466645\n",
      "Epoch 132, Loss: 0.4211950120212136\n",
      "Epoch 133, Loss: 0.420756836192489\n",
      "Epoch 134, Loss: 0.4201100127575366\n",
      "Epoch 135, Loss: 0.4191968114048231\n",
      "Epoch 136, Loss: 0.41862982762133916\n",
      "Epoch 137, Loss: 0.41831759574564353\n",
      "Epoch 138, Loss: 0.4176716684563043\n",
      "Epoch 139, Loss: 0.4168297408784348\n",
      "Epoch 140, Loss: 0.4161881460736758\n",
      "Epoch 141, Loss: 0.4157619508825161\n",
      "Epoch 142, Loss: 0.41525612932925926\n",
      "Epoch 143, Loss: 0.4145321791286531\n",
      "Epoch 144, Loss: 0.4137562392879386\n",
      "Epoch 145, Loss: 0.41303617209213056\n",
      "Epoch 146, Loss: 0.41245591477143817\n",
      "Epoch 147, Loss: 0.4119926576619835\n",
      "Epoch 148, Loss: 0.41162163676704616\n",
      "Epoch 149, Loss: 0.4115840763991057\n",
      "Epoch 150, Loss: 0.41103882066321773\n",
      "Epoch 151, Loss: 0.41001897058560816\n",
      "Epoch 152, Loss: 0.40899859952920037\n",
      "Epoch 153, Loss: 0.40883986535137007\n",
      "Epoch 154, Loss: 0.4088821786246235\n",
      "Epoch 155, Loss: 0.40793752471166306\n",
      "Epoch 156, Loss: 0.4068170954259681\n",
      "Epoch 157, Loss: 0.40654729088990305\n",
      "Epoch 158, Loss: 0.4065190121485062\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.23279886307731648\n",
      "Test R^2 score: 0.4161232249557088\n",
      "Num of epochs: 159\n",
      "Epoch 1, Loss: 0.5933289289668199\n",
      "Epoch 2, Loss: 0.5909331411022403\n",
      "Epoch 3, Loss: 0.5886009715310418\n",
      "Epoch 4, Loss: 0.5863351616891471\n",
      "Epoch 5, Loss: 0.5841361521597727\n",
      "Epoch 6, Loss: 0.5820103583970772\n",
      "Epoch 7, Loss: 0.5799547571590477\n",
      "Epoch 8, Loss: 0.57796971065527\n",
      "Epoch 9, Loss: 0.5760571123044844\n",
      "Epoch 10, Loss: 0.5742195025588314\n",
      "Epoch 11, Loss: 0.5724595037655168\n",
      "Epoch 12, Loss: 0.5707785387494313\n",
      "Epoch 13, Loss: 0.5691779360719034\n",
      "Epoch 14, Loss: 0.5676592417731855\n",
      "Epoch 15, Loss: 0.566229615128769\n",
      "Epoch 16, Loss: 0.564889574104741\n",
      "Epoch 17, Loss: 0.5635677905088738\n",
      "Epoch 18, Loss: 0.5621954570332263\n",
      "Epoch 19, Loss: 0.5609331029863084\n",
      "Epoch 20, Loss: 0.5597718094073493\n",
      "Epoch 21, Loss: 0.5586846284366855\n",
      "Epoch 22, Loss: 0.5574998347962139\n",
      "Epoch 23, Loss: 0.5564213370998954\n",
      "Epoch 24, Loss: 0.5554345164634712\n",
      "Epoch 25, Loss: 0.5544681115212619\n",
      "Epoch 26, Loss: 0.553444907786648\n",
      "Epoch 27, Loss: 0.5523278456668362\n",
      "Epoch 28, Loss: 0.5511181389495574\n",
      "Epoch 29, Loss: 0.5498989424196387\n",
      "Epoch 30, Loss: 0.5486006621748613\n",
      "Epoch 31, Loss: 0.5471313148379883\n",
      "Epoch 32, Loss: 0.5453901022534392\n",
      "Epoch 33, Loss: 0.5432548592460277\n",
      "Epoch 34, Loss: 0.5406093517971494\n",
      "Epoch 35, Loss: 0.5374552774675396\n",
      "Epoch 36, Loss: 0.5339569520082837\n",
      "Epoch 37, Loss: 0.5302927705672302\n",
      "Epoch 38, Loss: 0.5268244977302856\n",
      "Epoch 39, Loss: 0.5239593694182428\n",
      "Epoch 40, Loss: 0.5216880143563969\n",
      "Epoch 41, Loss: 0.5193415704244511\n",
      "Epoch 42, Loss: 0.5165045490286136\n",
      "Epoch 43, Loss: 0.5134291274722541\n",
      "Epoch 44, Loss: 0.5108310191873197\n",
      "Epoch 45, Loss: 0.5088928175439781\n",
      "Epoch 46, Loss: 0.5072359773851272\n",
      "Epoch 47, Loss: 0.5054093940706414\n",
      "Epoch 48, Loss: 0.5032206462195902\n",
      "Epoch 49, Loss: 0.5009249238585073\n",
      "Epoch 50, Loss: 0.49882276348437976\n",
      "Epoch 51, Loss: 0.4971909741916272\n",
      "Epoch 52, Loss: 0.4958181141139135\n",
      "Epoch 53, Loss: 0.4941937263514333\n",
      "Epoch 54, Loss: 0.49230966111609625\n",
      "Epoch 55, Loss: 0.4905999632843539\n",
      "Epoch 56, Loss: 0.4892276899312259\n",
      "Epoch 57, Loss: 0.4878814891879154\n",
      "Epoch 58, Loss: 0.48629592114800446\n",
      "Epoch 59, Loss: 0.48456861871610146\n",
      "Epoch 60, Loss: 0.4829983992224283\n",
      "Epoch 61, Loss: 0.4816794145469025\n",
      "Epoch 62, Loss: 0.480306892734576\n",
      "Epoch 63, Loss: 0.47879733142993486\n",
      "Epoch 64, Loss: 0.4774416490672402\n",
      "Epoch 65, Loss: 0.4763392410119971\n",
      "Epoch 66, Loss: 0.47525868524384063\n",
      "Epoch 67, Loss: 0.4740506718014295\n",
      "Epoch 68, Loss: 0.4728880542412367\n",
      "Epoch 69, Loss: 0.47184733063372347\n",
      "Epoch 70, Loss: 0.47076540649676396\n",
      "Epoch 71, Loss: 0.46962746508705006\n",
      "Epoch 72, Loss: 0.4686114106343464\n",
      "Epoch 73, Loss: 0.4677093876130839\n",
      "Epoch 74, Loss: 0.4667395871813756\n",
      "Epoch 75, Loss: 0.46575474627518726\n",
      "Epoch 76, Loss: 0.4648560113652138\n",
      "Epoch 77, Loss: 0.4639423510238609\n",
      "Epoch 78, Loss: 0.4629990655897858\n",
      "Epoch 79, Loss: 0.46210569314142885\n",
      "Epoch 80, Loss: 0.46116314230432565\n",
      "Epoch 81, Loss: 0.4601913328673018\n",
      "Epoch 82, Loss: 0.4593143170038303\n",
      "Epoch 83, Loss: 0.45847207555942193\n",
      "Epoch 84, Loss: 0.45760083366735754\n",
      "Epoch 85, Loss: 0.45677959001673646\n",
      "Epoch 86, Loss: 0.4559867040375136\n",
      "Epoch 87, Loss: 0.4552096884799692\n",
      "Epoch 88, Loss: 0.45449479007672494\n",
      "Epoch 89, Loss: 0.4537969408371806\n",
      "Epoch 90, Loss: 0.4531129473694665\n",
      "Epoch 91, Loss: 0.45245398790669983\n",
      "Epoch 92, Loss: 0.451774195115512\n",
      "Epoch 93, Loss: 0.4510979034422887\n",
      "Epoch 94, Loss: 0.4504157166054887\n",
      "Epoch 95, Loss: 0.4497073626025177\n",
      "Epoch 96, Loss: 0.44902269812179163\n",
      "Epoch 97, Loss: 0.44833552566805346\n",
      "Epoch 98, Loss: 0.4476521084046305\n",
      "Epoch 99, Loss: 0.4469815313963729\n",
      "Epoch 100, Loss: 0.4463623621072134\n",
      "Epoch 101, Loss: 0.4457656161257377\n",
      "Epoch 102, Loss: 0.4451684384135202\n",
      "Epoch 103, Loss: 0.44456204540669747\n",
      "Epoch 104, Loss: 0.44394034077872513\n",
      "Epoch 105, Loss: 0.44328658729005105\n",
      "Epoch 106, Loss: 0.4425838257977152\n",
      "Epoch 107, Loss: 0.4418868764983581\n",
      "Epoch 108, Loss: 0.4412385402520532\n",
      "Epoch 109, Loss: 0.4405653209717727\n",
      "Epoch 110, Loss: 0.4398936119749166\n",
      "Epoch 111, Loss: 0.43920606662020695\n",
      "Epoch 112, Loss: 0.4385431319851833\n",
      "Epoch 113, Loss: 0.43789811412930485\n",
      "Epoch 114, Loss: 0.4372322932399192\n",
      "Epoch 115, Loss: 0.4365508649090675\n",
      "Epoch 116, Loss: 0.4358905753308529\n",
      "Epoch 117, Loss: 0.43522283020758334\n",
      "Epoch 118, Loss: 0.4345368447435698\n",
      "Epoch 119, Loss: 0.43385667819257495\n",
      "Epoch 120, Loss: 0.4331616147020578\n",
      "Epoch 121, Loss: 0.4324463448841828\n",
      "Epoch 122, Loss: 0.43174802729890954\n",
      "Epoch 123, Loss: 0.4310586034668636\n",
      "Epoch 124, Loss: 0.4303801589056108\n",
      "Epoch 125, Loss: 0.42980599936833125\n",
      "Epoch 126, Loss: 0.42931063337554737\n",
      "Epoch 127, Loss: 0.4287347287330515\n",
      "Epoch 128, Loss: 0.42769377006205944\n",
      "Epoch 129, Loss: 0.4270806215556821\n",
      "Epoch 130, Loss: 0.4267470055091262\n",
      "Epoch 131, Loss: 0.42585139615456075\n",
      "Epoch 132, Loss: 0.42501099936893333\n",
      "Epoch 133, Loss: 0.4245526848844372\n",
      "Epoch 134, Loss: 0.4239960263185263\n",
      "Epoch 135, Loss: 0.4232369620190283\n",
      "Epoch 136, Loss: 0.422461543477365\n",
      "Epoch 137, Loss: 0.4218909649124039\n",
      "Epoch 138, Loss: 0.42128125547374107\n",
      "Epoch 139, Loss: 0.4203648204926473\n",
      "Epoch 140, Loss: 0.4194809483895339\n",
      "Epoch 141, Loss: 0.41881016683334205\n",
      "Epoch 142, Loss: 0.41830826277035227\n",
      "Epoch 143, Loss: 0.41784541369198186\n",
      "Epoch 144, Loss: 0.4171268504773031\n",
      "Epoch 145, Loss: 0.41635161250729746\n",
      "Epoch 146, Loss: 0.415624909651897\n",
      "Epoch 147, Loss: 0.41507498193028664\n",
      "Epoch 148, Loss: 0.4146531408890393\n",
      "Epoch 149, Loss: 0.414259719664389\n",
      "Epoch 150, Loss: 0.41401960042727914\n",
      "Epoch 151, Loss: 0.413283821487359\n",
      "Epoch 152, Loss: 0.41233219432647794\n",
      "Epoch 153, Loss: 0.41148196727945635\n",
      "Epoch 154, Loss: 0.4110978716502658\n",
      "Epoch 155, Loss: 0.41087552535206556\n",
      "Epoch 156, Loss: 0.4102659169677039\n",
      "Epoch 157, Loss: 0.40939909667519675\n",
      "Epoch 158, Loss: 0.4085693359375\n",
      "Epoch 159, Loss: 0.4081220591966376\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2240323223854114\n",
      "Test R^2 score: 0.45741282666812216\n",
      "Num of epochs: 160\n",
      "Epoch 1, Loss: 0.5669213419249558\n",
      "Epoch 2, Loss: 0.5657636746445078\n",
      "Epoch 3, Loss: 0.5646759174301134\n",
      "Epoch 4, Loss: 0.5636508348203466\n",
      "Epoch 5, Loss: 0.5626873393157591\n",
      "Epoch 6, Loss: 0.5618029354926608\n",
      "Epoch 7, Loss: 0.5609908522201759\n",
      "Epoch 8, Loss: 0.5602395414732064\n",
      "Epoch 9, Loss: 0.5595548138294567\n",
      "Epoch 10, Loss: 0.558935261080887\n",
      "Epoch 11, Loss: 0.5583796324203644\n",
      "Epoch 12, Loss: 0.5579288500233565\n",
      "Epoch 13, Loss: 0.5575258143397188\n",
      "Epoch 14, Loss: 0.5571713243362657\n",
      "Epoch 15, Loss: 0.5568634925535279\n",
      "Epoch 16, Loss: 0.556600334984805\n",
      "Epoch 17, Loss: 0.556379156441248\n",
      "Epoch 18, Loss: 0.5561959079630311\n",
      "Epoch 19, Loss: 0.5560428555150602\n",
      "Epoch 20, Loss: 0.5559236158295843\n",
      "Epoch 21, Loss: 0.5558261467337045\n",
      "Epoch 22, Loss: 0.5557382865903455\n",
      "Epoch 23, Loss: 0.555645987647454\n",
      "Epoch 24, Loss: 0.5555382235790448\n",
      "Epoch 25, Loss: 0.5553946755508773\n",
      "Epoch 26, Loss: 0.5552007959747655\n",
      "Epoch 27, Loss: 0.5549404480919528\n",
      "Epoch 28, Loss: 0.5545949724420036\n",
      "Epoch 29, Loss: 0.5541443112771209\n",
      "Epoch 30, Loss: 0.5535552598200458\n",
      "Epoch 31, Loss: 0.5527867538382589\n",
      "Epoch 32, Loss: 0.551803019874359\n",
      "Epoch 33, Loss: 0.5505539986669342\n",
      "Epoch 34, Loss: 0.5489655997889001\n",
      "Epoch 35, Loss: 0.5469677437750856\n",
      "Epoch 36, Loss: 0.5444919982511363\n",
      "Epoch 37, Loss: 0.5414719292681702\n",
      "Epoch 38, Loss: 0.5378385276192912\n",
      "Epoch 39, Loss: 0.5336255646320858\n",
      "Epoch 40, Loss: 0.5290420312859433\n",
      "Epoch 41, Loss: 0.5245534189566069\n",
      "Epoch 42, Loss: 0.5209357415291456\n",
      "Epoch 43, Loss: 0.5190509497673974\n",
      "Epoch 44, Loss: 0.5182429524286154\n",
      "Epoch 45, Loss: 0.5161765067965324\n",
      "Epoch 46, Loss: 0.5125269150063055\n",
      "Epoch 47, Loss: 0.5088570342541122\n",
      "Epoch 48, Loss: 0.5062621880465242\n",
      "Epoch 49, Loss: 0.5045801727685244\n",
      "Epoch 50, Loss: 0.5031509357188569\n",
      "Epoch 51, Loss: 0.5012964190538776\n",
      "Epoch 52, Loss: 0.49889286968329927\n",
      "Epoch 53, Loss: 0.4963922278537368\n",
      "Epoch 54, Loss: 0.4941596830409576\n",
      "Epoch 55, Loss: 0.4926786243065578\n",
      "Epoch 56, Loss: 0.491672685621349\n",
      "Epoch 57, Loss: 0.4901720288515283\n",
      "Epoch 58, Loss: 0.48790422761156277\n",
      "Epoch 59, Loss: 0.48551799906200954\n",
      "Epoch 60, Loss: 0.4836511741155426\n",
      "Epoch 61, Loss: 0.4822958654244262\n",
      "Epoch 62, Loss: 0.4809849764843047\n",
      "Epoch 63, Loss: 0.4792538300999443\n",
      "Epoch 64, Loss: 0.4771617030307391\n",
      "Epoch 65, Loss: 0.47523313121767724\n",
      "Epoch 66, Loss: 0.4738302546844046\n",
      "Epoch 67, Loss: 0.47261209518119457\n",
      "Epoch 68, Loss: 0.47116684923763313\n",
      "Epoch 69, Loss: 0.4697504334917246\n",
      "Epoch 70, Loss: 0.468746646233323\n",
      "Epoch 71, Loss: 0.4678864949684715\n",
      "Epoch 72, Loss: 0.466760546176397\n",
      "Epoch 73, Loss: 0.46557426752302095\n",
      "Epoch 74, Loss: 0.4646230382018382\n",
      "Epoch 75, Loss: 0.463798244773863\n",
      "Epoch 76, Loss: 0.4628083844101695\n",
      "Epoch 77, Loss: 0.4617583191725824\n",
      "Epoch 78, Loss: 0.46085909807061404\n",
      "Epoch 79, Loss: 0.459962784101339\n",
      "Epoch 80, Loss: 0.4590018898077314\n",
      "Epoch 81, Loss: 0.45803479926470186\n",
      "Epoch 82, Loss: 0.4571937370005236\n",
      "Epoch 83, Loss: 0.45635682253343035\n",
      "Epoch 84, Loss: 0.45542758408828055\n",
      "Epoch 85, Loss: 0.45454614677159744\n",
      "Epoch 86, Loss: 0.45368712186607096\n",
      "Epoch 87, Loss: 0.4528291986412646\n",
      "Epoch 88, Loss: 0.4520883046446734\n",
      "Epoch 89, Loss: 0.45137589040608717\n",
      "Epoch 90, Loss: 0.45060387068481594\n",
      "Epoch 91, Loss: 0.4498564795931913\n",
      "Epoch 92, Loss: 0.4491798715767706\n",
      "Epoch 93, Loss: 0.4485026415254848\n",
      "Epoch 94, Loss: 0.447840059368069\n",
      "Epoch 95, Loss: 0.44715853412686485\n",
      "Epoch 96, Loss: 0.4464318779414206\n",
      "Epoch 97, Loss: 0.4456685132187189\n",
      "Epoch 98, Loss: 0.4449159797632907\n",
      "Epoch 99, Loss: 0.44421562829733857\n",
      "Epoch 100, Loss: 0.4434918109197965\n",
      "Epoch 101, Loss: 0.44275528340927117\n",
      "Epoch 102, Loss: 0.44205862128423434\n",
      "Epoch 103, Loss: 0.4413311480882706\n",
      "Epoch 104, Loss: 0.44059139759364574\n",
      "Epoch 105, Loss: 0.4398778770040492\n",
      "Epoch 106, Loss: 0.43914826733098494\n",
      "Epoch 107, Loss: 0.43839125451202066\n",
      "Epoch 108, Loss: 0.4376317915641417\n",
      "Epoch 109, Loss: 0.4368072031212756\n",
      "Epoch 110, Loss: 0.4359948458946569\n",
      "Epoch 111, Loss: 0.43520639565515673\n",
      "Epoch 112, Loss: 0.4344621159309687\n",
      "Epoch 113, Loss: 0.4337783970180788\n",
      "Epoch 114, Loss: 0.43312691997746566\n",
      "Epoch 115, Loss: 0.43253070664411314\n",
      "Epoch 116, Loss: 0.4319444165565397\n",
      "Epoch 117, Loss: 0.4313797140612785\n",
      "Epoch 118, Loss: 0.4307802869573599\n",
      "Epoch 119, Loss: 0.4301946248355816\n",
      "Epoch 120, Loss: 0.42960618723595223\n",
      "Epoch 121, Loss: 0.42903159972832416\n",
      "Epoch 122, Loss: 0.4284303307298621\n",
      "Epoch 123, Loss: 0.4278378992781926\n",
      "Epoch 124, Loss: 0.4272421002882562\n",
      "Epoch 125, Loss: 0.4266430418948116\n",
      "Epoch 126, Loss: 0.42602783901964786\n",
      "Epoch 127, Loss: 0.42541572209526407\n",
      "Epoch 128, Loss: 0.424823892093512\n",
      "Epoch 129, Loss: 0.424223614238018\n",
      "Epoch 130, Loss: 0.4236156616678736\n",
      "Epoch 131, Loss: 0.42304852415769023\n",
      "Epoch 132, Loss: 0.4226134513014967\n",
      "Epoch 133, Loss: 0.4223242240002146\n",
      "Epoch 134, Loss: 0.42153376448121216\n",
      "Epoch 135, Loss: 0.4207737465808117\n",
      "Epoch 136, Loss: 0.4205141193716017\n",
      "Epoch 137, Loss: 0.41990493030515313\n",
      "Epoch 138, Loss: 0.4191216051207092\n",
      "Epoch 139, Loss: 0.4188076050834797\n",
      "Epoch 140, Loss: 0.418188091017112\n",
      "Epoch 141, Loss: 0.4174879820744333\n",
      "Epoch 142, Loss: 0.41711613333986264\n",
      "Epoch 143, Loss: 0.41659092413387605\n",
      "Epoch 144, Loss: 0.415864836538521\n",
      "Epoch 145, Loss: 0.4154317815429251\n",
      "Epoch 146, Loss: 0.4149694586339221\n",
      "Epoch 147, Loss: 0.4142103650925484\n",
      "Epoch 148, Loss: 0.4137023763245349\n",
      "Epoch 149, Loss: 0.4132189164630503\n",
      "Epoch 150, Loss: 0.41262335161182045\n",
      "Epoch 151, Loss: 0.4119811378300029\n",
      "Epoch 152, Loss: 0.41142878446426817\n",
      "Epoch 153, Loss: 0.41097249146798204\n",
      "Epoch 154, Loss: 0.41045321658409095\n",
      "Epoch 155, Loss: 0.40990711093238386\n",
      "Epoch 156, Loss: 0.4092861938247877\n",
      "Epoch 157, Loss: 0.40867653002719445\n",
      "Epoch 158, Loss: 0.40815188802735497\n",
      "Epoch 159, Loss: 0.40762172709241623\n",
      "Epoch 160, Loss: 0.4071020031900112\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22488205808695097\n",
      "Test R^2 score: 0.4521747678625083\n",
      "Num of epochs: 161\n",
      "Epoch 1, Loss: 0.5637402107759092\n",
      "Epoch 2, Loss: 0.5625234440050593\n",
      "Epoch 3, Loss: 0.5614233574621672\n",
      "Epoch 4, Loss: 0.5604821144469547\n",
      "Epoch 5, Loss: 0.5596501691201284\n",
      "Epoch 6, Loss: 0.5589089471348286\n",
      "Epoch 7, Loss: 0.5582910798107192\n",
      "Epoch 8, Loss: 0.5577676439815914\n",
      "Epoch 9, Loss: 0.5573406970360516\n",
      "Epoch 10, Loss: 0.5569857414242328\n",
      "Epoch 11, Loss: 0.5567019512458896\n",
      "Epoch 12, Loss: 0.5564855259095233\n",
      "Epoch 13, Loss: 0.5563315085367241\n",
      "Epoch 14, Loss: 0.556233387602579\n",
      "Epoch 15, Loss: 0.5561826997398278\n",
      "Epoch 16, Loss: 0.556171018372337\n",
      "Epoch 17, Loss: 0.5562070797852686\n",
      "Epoch 18, Loss: 0.5562442104166888\n",
      "Epoch 19, Loss: 0.5562845530118569\n",
      "Epoch 20, Loss: 0.5563200713609815\n",
      "Epoch 21, Loss: 0.5563451417715827\n",
      "Epoch 22, Loss: 0.5563563373806399\n",
      "Epoch 23, Loss: 0.5563522127087774\n",
      "Epoch 24, Loss: 0.5563335709532284\n",
      "Epoch 25, Loss: 0.5563006517301201\n",
      "Epoch 26, Loss: 0.556253559658362\n",
      "Epoch 27, Loss: 0.5561921839724185\n",
      "Epoch 28, Loss: 0.5561112145009782\n",
      "Epoch 29, Loss: 0.556013295891158\n",
      "Epoch 30, Loss: 0.555901716258952\n",
      "Epoch 31, Loss: 0.5557733304304316\n",
      "Epoch 32, Loss: 0.5556216366197294\n",
      "Epoch 33, Loss: 0.5554434232665311\n",
      "Epoch 34, Loss: 0.5552339145953168\n",
      "Epoch 35, Loss: 0.5549819057539299\n",
      "Epoch 36, Loss: 0.5546765124884895\n",
      "Epoch 37, Loss: 0.5543099313801827\n",
      "Epoch 38, Loss: 0.5538732435456433\n",
      "Epoch 39, Loss: 0.5533418047306283\n",
      "Epoch 40, Loss: 0.5526887045819879\n",
      "Epoch 41, Loss: 0.5518774122399287\n",
      "Epoch 42, Loss: 0.5508763116276038\n",
      "Epoch 43, Loss: 0.5496461683807587\n",
      "Epoch 44, Loss: 0.5481218021695363\n",
      "Epoch 45, Loss: 0.5461969531858818\n",
      "Epoch 46, Loss: 0.5436665284554036\n",
      "Epoch 47, Loss: 0.540307749015258\n",
      "Epoch 48, Loss: 0.5362378349347081\n",
      "Epoch 49, Loss: 0.5314929630965654\n",
      "Epoch 50, Loss: 0.5262209772366074\n",
      "Epoch 51, Loss: 0.5207172709530272\n",
      "Epoch 52, Loss: 0.5155485269884515\n",
      "Epoch 53, Loss: 0.5115157736735424\n",
      "Epoch 54, Loss: 0.5086634328894776\n",
      "Epoch 55, Loss: 0.5057667238673194\n",
      "Epoch 56, Loss: 0.5023577947714822\n",
      "Epoch 57, Loss: 0.49900941773072316\n",
      "Epoch 58, Loss: 0.49677449175505484\n",
      "Epoch 59, Loss: 0.4956819973193954\n",
      "Epoch 60, Loss: 0.4944006194410178\n",
      "Epoch 61, Loss: 0.4920972559711886\n",
      "Epoch 62, Loss: 0.4892944657231254\n",
      "Epoch 63, Loss: 0.48689716247045944\n",
      "Epoch 64, Loss: 0.4854023559518246\n",
      "Epoch 65, Loss: 0.4842577300087416\n",
      "Epoch 66, Loss: 0.4825876082553397\n",
      "Epoch 67, Loss: 0.4805892545109192\n",
      "Epoch 68, Loss: 0.47890742863421376\n",
      "Epoch 69, Loss: 0.4777150678125289\n",
      "Epoch 70, Loss: 0.47656415720166845\n",
      "Epoch 71, Loss: 0.4751898586902534\n",
      "Epoch 72, Loss: 0.473790942664909\n",
      "Epoch 73, Loss: 0.4728602922619315\n",
      "Epoch 74, Loss: 0.47243057727447635\n",
      "Epoch 75, Loss: 0.4719990030516586\n",
      "Epoch 76, Loss: 0.4710572046683519\n",
      "Epoch 77, Loss: 0.4698229906870512\n",
      "Epoch 78, Loss: 0.46878614286319814\n",
      "Epoch 79, Loss: 0.46792424902656216\n",
      "Epoch 80, Loss: 0.46708464431181707\n",
      "Epoch 81, Loss: 0.4660531827464154\n",
      "Epoch 82, Loss: 0.4650302641003031\n",
      "Epoch 83, Loss: 0.4641958738614115\n",
      "Epoch 84, Loss: 0.4634831173670782\n",
      "Epoch 85, Loss: 0.4627309435244296\n",
      "Epoch 86, Loss: 0.46198447983133184\n",
      "Epoch 87, Loss: 0.4613802286904425\n",
      "Epoch 88, Loss: 0.4608957304051808\n",
      "Epoch 89, Loss: 0.46034326881703097\n",
      "Epoch 90, Loss: 0.4596870724736345\n",
      "Epoch 91, Loss: 0.45906559651617834\n",
      "Epoch 92, Loss: 0.4585216381038146\n",
      "Epoch 93, Loss: 0.4580025906458302\n",
      "Epoch 94, Loss: 0.45743906133796763\n",
      "Epoch 95, Loss: 0.456875391410733\n",
      "Epoch 96, Loss: 0.4563558103068425\n",
      "Epoch 97, Loss: 0.455853191029789\n",
      "Epoch 98, Loss: 0.45535217677809053\n",
      "Epoch 99, Loss: 0.4548674656599634\n",
      "Epoch 100, Loss: 0.454431754218492\n",
      "Epoch 101, Loss: 0.45397653806976135\n",
      "Epoch 102, Loss: 0.4534722181735283\n",
      "Epoch 103, Loss: 0.45297034682761855\n",
      "Epoch 104, Loss: 0.4525122116348437\n",
      "Epoch 105, Loss: 0.4520675553880769\n",
      "Epoch 106, Loss: 0.451599760399232\n",
      "Epoch 107, Loss: 0.4511192753503371\n",
      "Epoch 108, Loss: 0.45064211372438295\n",
      "Epoch 109, Loss: 0.45016001068525197\n",
      "Epoch 110, Loss: 0.4496603743780039\n",
      "Epoch 111, Loss: 0.44914875314457287\n",
      "Epoch 112, Loss: 0.4486391557802214\n",
      "Epoch 113, Loss: 0.44812799798555836\n",
      "Epoch 114, Loss: 0.4476146585473099\n",
      "Epoch 115, Loss: 0.4470867482268553\n",
      "Epoch 116, Loss: 0.4465708270941628\n",
      "Epoch 117, Loss: 0.44606576754963473\n",
      "Epoch 118, Loss: 0.44555247683735094\n",
      "Epoch 119, Loss: 0.44501885553659853\n",
      "Epoch 120, Loss: 0.4444771510828646\n",
      "Epoch 121, Loss: 0.44394269037038747\n",
      "Epoch 122, Loss: 0.44341094603549713\n",
      "Epoch 123, Loss: 0.44286902447167653\n",
      "Epoch 124, Loss: 0.44231230656025466\n",
      "Epoch 125, Loss: 0.4417434855748797\n",
      "Epoch 126, Loss: 0.4411808383599218\n",
      "Epoch 127, Loss: 0.44060641378066906\n",
      "Epoch 128, Loss: 0.4400267184880052\n",
      "Epoch 129, Loss: 0.4394447495404125\n",
      "Epoch 130, Loss: 0.4388572043220115\n",
      "Epoch 131, Loss: 0.4382619183742746\n",
      "Epoch 132, Loss: 0.4376564257130105\n",
      "Epoch 133, Loss: 0.4370423716445073\n",
      "Epoch 134, Loss: 0.43639892577442085\n",
      "Epoch 135, Loss: 0.4357384743525872\n",
      "Epoch 136, Loss: 0.4350575833464084\n",
      "Epoch 137, Loss: 0.4343877001490654\n",
      "Epoch 138, Loss: 0.43370565053030846\n",
      "Epoch 139, Loss: 0.43302331809783245\n",
      "Epoch 140, Loss: 0.43236642980008577\n",
      "Epoch 141, Loss: 0.43171116524383507\n",
      "Epoch 142, Loss: 0.43106297639275953\n",
      "Epoch 143, Loss: 0.43042712278612016\n",
      "Epoch 144, Loss: 0.42981444130986496\n",
      "Epoch 145, Loss: 0.4292100507912126\n",
      "Epoch 146, Loss: 0.4286062681989375\n",
      "Epoch 147, Loss: 0.4280053765179831\n",
      "Epoch 148, Loss: 0.42740859075006954\n",
      "Epoch 149, Loss: 0.42682109511962135\n",
      "Epoch 150, Loss: 0.42623436292229266\n",
      "Epoch 151, Loss: 0.4256595822707893\n",
      "Epoch 152, Loss: 0.42508001065234724\n",
      "Epoch 153, Loss: 0.4244833245883119\n",
      "Epoch 154, Loss: 0.4238921965235586\n",
      "Epoch 155, Loss: 0.4233257990952615\n",
      "Epoch 156, Loss: 0.42275994698131536\n",
      "Epoch 157, Loss: 0.4221910246695577\n",
      "Epoch 158, Loss: 0.4216206985070996\n",
      "Epoch 159, Loss: 0.4210543421209405\n",
      "Epoch 160, Loss: 0.42048367910769463\n",
      "Epoch 161, Loss: 0.4198955261480441\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21714423357275867\n",
      "Test R^2 score: 0.48791356212439974\n",
      "Num of epochs: 162\n",
      "Epoch 1, Loss: 0.6057179584160478\n",
      "Epoch 2, Loss: 0.6032112613322422\n",
      "Epoch 3, Loss: 0.6007724627384207\n",
      "Epoch 4, Loss: 0.5983935277734812\n",
      "Epoch 5, Loss: 0.5960751731847668\n",
      "Epoch 6, Loss: 0.5938181336110262\n",
      "Epoch 7, Loss: 0.5916389531598408\n",
      "Epoch 8, Loss: 0.5895473164811561\n",
      "Epoch 9, Loss: 0.58751800996487\n",
      "Epoch 10, Loss: 0.5855578909480947\n",
      "Epoch 11, Loss: 0.5836596910024254\n",
      "Epoch 12, Loss: 0.581819611032516\n",
      "Epoch 13, Loss: 0.5800368682883537\n",
      "Epoch 14, Loss: 0.5784509616235454\n",
      "Epoch 15, Loss: 0.5769115032661286\n",
      "Epoch 16, Loss: 0.5754085074427956\n",
      "Epoch 17, Loss: 0.5740040488017236\n",
      "Epoch 18, Loss: 0.5726469416466816\n",
      "Epoch 19, Loss: 0.5713240131870254\n",
      "Epoch 20, Loss: 0.5700366777197501\n",
      "Epoch 21, Loss: 0.568851035439601\n",
      "Epoch 22, Loss: 0.5677131833443844\n",
      "Epoch 23, Loss: 0.5665971894540908\n",
      "Epoch 24, Loss: 0.5655055546964166\n",
      "Epoch 25, Loss: 0.5644415091933043\n",
      "Epoch 26, Loss: 0.5634029875905291\n",
      "Epoch 27, Loss: 0.5623771480342069\n",
      "Epoch 28, Loss: 0.5613573442365515\n",
      "Epoch 29, Loss: 0.5603170954041927\n",
      "Epoch 30, Loss: 0.5591839160286302\n",
      "Epoch 31, Loss: 0.5579141337237742\n",
      "Epoch 32, Loss: 0.5565042696803593\n",
      "Epoch 33, Loss: 0.5549518599982454\n",
      "Epoch 34, Loss: 0.5531519199005962\n",
      "Epoch 35, Loss: 0.5510573270143259\n",
      "Epoch 36, Loss: 0.5486112553023565\n",
      "Epoch 37, Loss: 0.5457900866151607\n",
      "Epoch 38, Loss: 0.5424903573440539\n",
      "Epoch 39, Loss: 0.5386814484495893\n",
      "Epoch 40, Loss: 0.5345511530939991\n",
      "Epoch 41, Loss: 0.5305947582492093\n",
      "Epoch 42, Loss: 0.5279407371637616\n",
      "Epoch 43, Loss: 0.5280535689131568\n",
      "Epoch 44, Loss: 0.5299903577701202\n",
      "Epoch 45, Loss: 0.5292431849877448\n",
      "Epoch 46, Loss: 0.5256494217958612\n",
      "Epoch 47, Loss: 0.5216204576420227\n",
      "Epoch 48, Loss: 0.5188028779713254\n",
      "Epoch 49, Loss: 0.5173678564816727\n",
      "Epoch 50, Loss: 0.5166753993783272\n",
      "Epoch 51, Loss: 0.5160456299992155\n",
      "Epoch 52, Loss: 0.515133883933995\n",
      "Epoch 53, Loss: 0.5136354382722211\n",
      "Epoch 54, Loss: 0.5116078496836324\n",
      "Epoch 55, Loss: 0.5093216405898641\n",
      "Epoch 56, Loss: 0.507227487309861\n",
      "Epoch 57, Loss: 0.5058236422492867\n",
      "Epoch 58, Loss: 0.5052024080643457\n",
      "Epoch 59, Loss: 0.5046981975732602\n",
      "Epoch 60, Loss: 0.5034827589342883\n",
      "Epoch 61, Loss: 0.501586602128044\n",
      "Epoch 62, Loss: 0.4997259372387316\n",
      "Epoch 63, Loss: 0.49841919987964955\n",
      "Epoch 64, Loss: 0.4975788685090375\n",
      "Epoch 65, Loss: 0.49678774973321194\n",
      "Epoch 66, Loss: 0.49572379668099975\n",
      "Epoch 67, Loss: 0.4943427475392733\n",
      "Epoch 68, Loss: 0.49285696306827576\n",
      "Epoch 69, Loss: 0.49158656052321575\n",
      "Epoch 70, Loss: 0.49063660735474085\n",
      "Epoch 71, Loss: 0.4897526049347515\n",
      "Epoch 72, Loss: 0.4885685037617589\n",
      "Epoch 73, Loss: 0.4871170049465945\n",
      "Epoch 74, Loss: 0.4857469172721026\n",
      "Epoch 75, Loss: 0.4846566058457709\n",
      "Epoch 76, Loss: 0.48370442579905143\n",
      "Epoch 77, Loss: 0.4826513817845143\n",
      "Epoch 78, Loss: 0.4814338141068361\n",
      "Epoch 79, Loss: 0.4801993506440297\n",
      "Epoch 80, Loss: 0.47911840347816725\n",
      "Epoch 81, Loss: 0.47819609580929123\n",
      "Epoch 82, Loss: 0.4772008934964307\n",
      "Epoch 83, Loss: 0.47606437477302577\n",
      "Epoch 84, Loss: 0.4749562914715448\n",
      "Epoch 85, Loss: 0.47400015517224214\n",
      "Epoch 86, Loss: 0.47307722402250535\n",
      "Epoch 87, Loss: 0.47206191851311025\n",
      "Epoch 88, Loss: 0.47101560485404487\n",
      "Epoch 89, Loss: 0.47004634892425656\n",
      "Epoch 90, Loss: 0.4691338080451672\n",
      "Epoch 91, Loss: 0.468134571430871\n",
      "Epoch 92, Loss: 0.4670869891386316\n",
      "Epoch 93, Loss: 0.46609971725833405\n",
      "Epoch 94, Loss: 0.46516708540797935\n",
      "Epoch 95, Loss: 0.46419190936846855\n",
      "Epoch 96, Loss: 0.463191743280763\n",
      "Epoch 97, Loss: 0.4622210879498532\n",
      "Epoch 98, Loss: 0.4612379226550718\n",
      "Epoch 99, Loss: 0.4602361451041936\n",
      "Epoch 100, Loss: 0.4592640126374295\n",
      "Epoch 101, Loss: 0.45824644139287374\n",
      "Epoch 102, Loss: 0.457181807930401\n",
      "Epoch 103, Loss: 0.45610676698839786\n",
      "Epoch 104, Loss: 0.45499373541700827\n",
      "Epoch 105, Loss: 0.45393906834155606\n",
      "Epoch 106, Loss: 0.45299195934469055\n",
      "Epoch 107, Loss: 0.4521526558928489\n",
      "Epoch 108, Loss: 0.45135180695961125\n",
      "Epoch 109, Loss: 0.45053539546592186\n",
      "Epoch 110, Loss: 0.4497306560726663\n",
      "Epoch 111, Loss: 0.44886030740787475\n",
      "Epoch 112, Loss: 0.44800597971199463\n",
      "Epoch 113, Loss: 0.4470668334292277\n",
      "Epoch 114, Loss: 0.44610142676166553\n",
      "Epoch 115, Loss: 0.4452781998658845\n",
      "Epoch 116, Loss: 0.4445831449550574\n",
      "Epoch 117, Loss: 0.4441374786184984\n",
      "Epoch 118, Loss: 0.4438718447163533\n",
      "Epoch 119, Loss: 0.4435136669412046\n",
      "Epoch 120, Loss: 0.44291257821699453\n",
      "Epoch 121, Loss: 0.4421692389501949\n",
      "Epoch 122, Loss: 0.44149490748910547\n",
      "Epoch 123, Loss: 0.4408757896145876\n",
      "Epoch 124, Loss: 0.44031105219952904\n",
      "Epoch 125, Loss: 0.43996150810220275\n",
      "Epoch 126, Loss: 0.43967845649881077\n",
      "Epoch 127, Loss: 0.4392682173918435\n",
      "Epoch 128, Loss: 0.43872630731891193\n",
      "Epoch 129, Loss: 0.43838097224913974\n",
      "Epoch 130, Loss: 0.43779293539373443\n",
      "Epoch 131, Loss: 0.4372246250262003\n",
      "Epoch 132, Loss: 0.43673001378910187\n",
      "Epoch 133, Loss: 0.43605330238303414\n",
      "Epoch 134, Loss: 0.4357435013543074\n",
      "Epoch 135, Loss: 0.4352099565275146\n",
      "Epoch 136, Loss: 0.43469488522956345\n",
      "Epoch 137, Loss: 0.4343936346708679\n",
      "Epoch 138, Loss: 0.4338115969682711\n",
      "Epoch 139, Loss: 0.43330351248553756\n",
      "Epoch 140, Loss: 0.4328790393181534\n",
      "Epoch 141, Loss: 0.43224894262706304\n",
      "Epoch 142, Loss: 0.43170854198137937\n",
      "Epoch 143, Loss: 0.43126797016684115\n",
      "Epoch 144, Loss: 0.4306823311388855\n",
      "Epoch 145, Loss: 0.43011510553151444\n",
      "Epoch 146, Loss: 0.42963435104422326\n",
      "Epoch 147, Loss: 0.4291186295016199\n",
      "Epoch 148, Loss: 0.4286370528732833\n",
      "Epoch 149, Loss: 0.42812521161819017\n",
      "Epoch 150, Loss: 0.4275584272701732\n",
      "Epoch 151, Loss: 0.42689653319954785\n",
      "Epoch 152, Loss: 0.4262068310185706\n",
      "Epoch 153, Loss: 0.42563481393778585\n",
      "Epoch 154, Loss: 0.4251118744133714\n",
      "Epoch 155, Loss: 0.42462427978185036\n",
      "Epoch 156, Loss: 0.4240996023095732\n",
      "Epoch 157, Loss: 0.4238426452118306\n",
      "Epoch 158, Loss: 0.4233695331093257\n",
      "Epoch 159, Loss: 0.42251243824115164\n",
      "Epoch 160, Loss: 0.42161972658516456\n",
      "Epoch 161, Loss: 0.42122412735131326\n",
      "Epoch 162, Loss: 0.42109038540941524\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21637296594002833\n",
      "Test R^2 score: 0.4923018376849578\n",
      "Num of epochs: 163\n",
      "Epoch 1, Loss: 0.589592937171098\n",
      "Epoch 2, Loss: 0.5868501549073699\n",
      "Epoch 3, Loss: 0.5842876348620477\n",
      "Epoch 4, Loss: 0.5820428731897046\n",
      "Epoch 5, Loss: 0.5799304247512013\n",
      "Epoch 6, Loss: 0.578050015715919\n",
      "Epoch 7, Loss: 0.5763579504551989\n",
      "Epoch 8, Loss: 0.5747761000207205\n",
      "Epoch 9, Loss: 0.5732672196857627\n",
      "Epoch 10, Loss: 0.5718452810684638\n",
      "Epoch 11, Loss: 0.570494322338153\n",
      "Epoch 12, Loss: 0.569204770088515\n",
      "Epoch 13, Loss: 0.5679783018796558\n",
      "Epoch 14, Loss: 0.5668135395400156\n",
      "Epoch 15, Loss: 0.565741760890099\n",
      "Epoch 16, Loss: 0.5647365558049054\n",
      "Epoch 17, Loss: 0.5637504929923124\n",
      "Epoch 18, Loss: 0.5628095146155091\n",
      "Epoch 19, Loss: 0.5619257008524378\n",
      "Epoch 20, Loss: 0.5610980205325569\n",
      "Epoch 21, Loss: 0.5603258714075043\n",
      "Epoch 22, Loss: 0.5596135840070607\n",
      "Epoch 23, Loss: 0.5589616271054756\n",
      "Epoch 24, Loss: 0.5583467270777158\n",
      "Epoch 25, Loss: 0.5577667890780688\n",
      "Epoch 26, Loss: 0.5572453744028026\n",
      "Epoch 27, Loss: 0.5567856181518743\n",
      "Epoch 28, Loss: 0.5564587479988171\n",
      "Epoch 29, Loss: 0.5561775020974331\n",
      "Epoch 30, Loss: 0.5559289230619971\n",
      "Epoch 31, Loss: 0.555717559545465\n",
      "Epoch 32, Loss: 0.5555347365875967\n",
      "Epoch 33, Loss: 0.5553603591002246\n",
      "Epoch 34, Loss: 0.5551778211195484\n",
      "Epoch 35, Loss: 0.5549645068014321\n",
      "Epoch 36, Loss: 0.554690374447534\n",
      "Epoch 37, Loss: 0.5543162486996606\n",
      "Epoch 38, Loss: 0.5538068415829824\n",
      "Epoch 39, Loss: 0.5531390430801412\n",
      "Epoch 40, Loss: 0.5523072874128215\n",
      "Epoch 41, Loss: 0.5513077512319693\n",
      "Epoch 42, Loss: 0.550139520028365\n",
      "Epoch 43, Loss: 0.548798746972141\n",
      "Epoch 44, Loss: 0.5472731367163393\n",
      "Epoch 45, Loss: 0.5455350536478898\n",
      "Epoch 46, Loss: 0.5435003244544695\n",
      "Epoch 47, Loss: 0.5410259259616989\n",
      "Epoch 48, Loss: 0.5380058159691086\n",
      "Epoch 49, Loss: 0.5344338657905571\n",
      "Epoch 50, Loss: 0.5303275289749371\n",
      "Epoch 51, Loss: 0.5257714461933076\n",
      "Epoch 52, Loss: 0.520812727202642\n",
      "Epoch 53, Loss: 0.5155531515290583\n",
      "Epoch 54, Loss: 0.5102517743955913\n",
      "Epoch 55, Loss: 0.5053305494473773\n",
      "Epoch 56, Loss: 0.5010658467169004\n",
      "Epoch 57, Loss: 0.49646623399728107\n",
      "Epoch 58, Loss: 0.49093530706623684\n",
      "Epoch 59, Loss: 0.48797874235243244\n",
      "Epoch 60, Loss: 0.48477828249825033\n",
      "Epoch 61, Loss: 0.4810645898132012\n",
      "Epoch 62, Loss: 0.4798179964628006\n",
      "Epoch 63, Loss: 0.4782705808419713\n",
      "Epoch 64, Loss: 0.47665534131338577\n",
      "Epoch 65, Loss: 0.4764501095178682\n",
      "Epoch 66, Loss: 0.4756045954684792\n",
      "Epoch 67, Loss: 0.47431043150266405\n",
      "Epoch 68, Loss: 0.4737046492064781\n",
      "Epoch 69, Loss: 0.4729879177155275\n",
      "Epoch 70, Loss: 0.4717234083806762\n",
      "Epoch 71, Loss: 0.4706180859750635\n",
      "Epoch 72, Loss: 0.4695557979824931\n",
      "Epoch 73, Loss: 0.46794782983448086\n",
      "Epoch 74, Loss: 0.466378443414618\n",
      "Epoch 75, Loss: 0.4652316934939088\n",
      "Epoch 76, Loss: 0.46393173571765733\n",
      "Epoch 77, Loss: 0.46277172637955405\n",
      "Epoch 78, Loss: 0.46199176933132247\n",
      "Epoch 79, Loss: 0.46110861236911466\n",
      "Epoch 80, Loss: 0.4604004139282726\n",
      "Epoch 81, Loss: 0.45984465147572334\n",
      "Epoch 82, Loss: 0.45916583755485235\n",
      "Epoch 83, Loss: 0.4584722705700952\n",
      "Epoch 84, Loss: 0.45778024058556527\n",
      "Epoch 85, Loss: 0.45694400900221266\n",
      "Epoch 86, Loss: 0.45612865558810095\n",
      "Epoch 87, Loss: 0.45533147807683494\n",
      "Epoch 88, Loss: 0.4544823311465243\n",
      "Epoch 89, Loss: 0.4537077806340784\n",
      "Epoch 90, Loss: 0.45285838603480416\n",
      "Epoch 91, Loss: 0.45209929691497125\n",
      "Epoch 92, Loss: 0.45133503527416663\n",
      "Epoch 93, Loss: 0.4506372198545814\n",
      "Epoch 94, Loss: 0.4499499134164102\n",
      "Epoch 95, Loss: 0.44928462333338814\n",
      "Epoch 96, Loss: 0.4485792833079632\n",
      "Epoch 97, Loss: 0.44784185612803595\n",
      "Epoch 98, Loss: 0.4470517509210275\n",
      "Epoch 99, Loss: 0.44626617372945954\n",
      "Epoch 100, Loss: 0.4454406420063114\n",
      "Epoch 101, Loss: 0.44464730891386356\n",
      "Epoch 102, Loss: 0.4438039256627956\n",
      "Epoch 103, Loss: 0.44302230995566577\n",
      "Epoch 104, Loss: 0.4422624268422061\n",
      "Epoch 105, Loss: 0.44153652125539716\n",
      "Epoch 106, Loss: 0.44083377545460173\n",
      "Epoch 107, Loss: 0.4401002992840048\n",
      "Epoch 108, Loss: 0.4393732803712622\n",
      "Epoch 109, Loss: 0.43866581220504963\n",
      "Epoch 110, Loss: 0.4379317503375177\n",
      "Epoch 111, Loss: 0.437167467035983\n",
      "Epoch 112, Loss: 0.4364286144793723\n",
      "Epoch 113, Loss: 0.4357287108604144\n",
      "Epoch 114, Loss: 0.43505148662409154\n",
      "Epoch 115, Loss: 0.43438361797428576\n",
      "Epoch 116, Loss: 0.43372231373111997\n",
      "Epoch 117, Loss: 0.433009432667896\n",
      "Epoch 118, Loss: 0.43224723618232175\n",
      "Epoch 119, Loss: 0.4314670818012309\n",
      "Epoch 120, Loss: 0.4307643055757084\n",
      "Epoch 121, Loss: 0.43035813795324035\n",
      "Epoch 122, Loss: 0.43084064418718887\n",
      "Epoch 123, Loss: 0.42972646016443133\n",
      "Epoch 124, Loss: 0.42797536462558483\n",
      "Epoch 125, Loss: 0.4278145283887104\n",
      "Epoch 126, Loss: 0.4273648342252365\n",
      "Epoch 127, Loss: 0.42609042570288264\n",
      "Epoch 128, Loss: 0.4258835345959054\n",
      "Epoch 129, Loss: 0.4252127255267893\n",
      "Epoch 130, Loss: 0.4243234824763722\n",
      "Epoch 131, Loss: 0.4241215266032934\n",
      "Epoch 132, Loss: 0.42329807801449015\n",
      "Epoch 133, Loss: 0.42262653239304365\n",
      "Epoch 134, Loss: 0.4223520089999144\n",
      "Epoch 135, Loss: 0.42156905984263854\n",
      "Epoch 136, Loss: 0.4209334144309055\n",
      "Epoch 137, Loss: 0.4205850199876019\n",
      "Epoch 138, Loss: 0.4199575719520219\n",
      "Epoch 139, Loss: 0.41921758807259796\n",
      "Epoch 140, Loss: 0.41864127128237105\n",
      "Epoch 141, Loss: 0.4181882691804593\n",
      "Epoch 142, Loss: 0.41779794500730305\n",
      "Epoch 143, Loss: 0.41728862794038546\n",
      "Epoch 144, Loss: 0.4167743980689396\n",
      "Epoch 145, Loss: 0.41612469671598723\n",
      "Epoch 146, Loss: 0.41548084756454784\n",
      "Epoch 147, Loss: 0.4148424288626286\n",
      "Epoch 148, Loss: 0.414260421090049\n",
      "Epoch 149, Loss: 0.4137136501295001\n",
      "Epoch 150, Loss: 0.413214535006608\n",
      "Epoch 151, Loss: 0.4128254639627967\n",
      "Epoch 152, Loss: 0.41283048121342764\n",
      "Epoch 153, Loss: 0.414330485730553\n",
      "Epoch 154, Loss: 0.41516766519182685\n",
      "Epoch 155, Loss: 0.4134518240698462\n",
      "Epoch 156, Loss: 0.4105417710412565\n",
      "Epoch 157, Loss: 0.41340064287430967\n",
      "Epoch 158, Loss: 0.41151586162616677\n",
      "Epoch 159, Loss: 0.40998964104708174\n",
      "Epoch 160, Loss: 0.41163501286079196\n",
      "Epoch 161, Loss: 0.40844704673017895\n",
      "Epoch 162, Loss: 0.4101787560963899\n",
      "Epoch 163, Loss: 0.4081376675776502\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22320643228601159\n",
      "Test R^2 score: 0.4605844248021362\n",
      "Num of epochs: 164\n",
      "Epoch 1, Loss: 0.5678255385989224\n",
      "Epoch 2, Loss: 0.5667110806712146\n",
      "Epoch 3, Loss: 0.5656485125886724\n",
      "Epoch 4, Loss: 0.5646312129092895\n",
      "Epoch 5, Loss: 0.5636608014304471\n",
      "Epoch 6, Loss: 0.5627427372118482\n",
      "Epoch 7, Loss: 0.56188807051141\n",
      "Epoch 8, Loss: 0.5610752074816909\n",
      "Epoch 9, Loss: 0.5603160848252889\n",
      "Epoch 10, Loss: 0.5596103354316254\n",
      "Epoch 11, Loss: 0.5589610139562381\n",
      "Epoch 12, Loss: 0.5583742417346801\n",
      "Epoch 13, Loss: 0.5578548372588058\n",
      "Epoch 14, Loss: 0.5573977223906506\n",
      "Epoch 15, Loss: 0.5570063677737116\n",
      "Epoch 16, Loss: 0.5566809388670556\n",
      "Epoch 17, Loss: 0.5564169986653972\n",
      "Epoch 18, Loss: 0.5562055259241477\n",
      "Epoch 19, Loss: 0.5560383265359129\n",
      "Epoch 20, Loss: 0.5559087928363418\n",
      "Epoch 21, Loss: 0.5558093908358739\n",
      "Epoch 22, Loss: 0.5557310469600636\n",
      "Epoch 23, Loss: 0.5556540329066558\n",
      "Epoch 24, Loss: 0.5555602715874881\n",
      "Epoch 25, Loss: 0.5554319678037835\n",
      "Epoch 26, Loss: 0.5552516539839731\n",
      "Epoch 27, Loss: 0.5549994384058268\n",
      "Epoch 28, Loss: 0.5546567397923837\n",
      "Epoch 29, Loss: 0.5542064783906401\n",
      "Epoch 30, Loss: 0.5536310047401947\n",
      "Epoch 31, Loss: 0.5529090416657272\n",
      "Epoch 32, Loss: 0.5520175558767627\n",
      "Epoch 33, Loss: 0.5509174530224873\n",
      "Epoch 34, Loss: 0.549543437242337\n",
      "Epoch 35, Loss: 0.5478280346284097\n",
      "Epoch 36, Loss: 0.5456618340502931\n",
      "Epoch 37, Loss: 0.5430088165649325\n",
      "Epoch 38, Loss: 0.539793072321642\n",
      "Epoch 39, Loss: 0.5359572103896327\n",
      "Epoch 40, Loss: 0.5314924023678224\n",
      "Epoch 41, Loss: 0.5265248191776312\n",
      "Epoch 42, Loss: 0.5214293090092842\n",
      "Epoch 43, Loss: 0.5170736193250388\n",
      "Epoch 44, Loss: 0.5148183697709389\n",
      "Epoch 45, Loss: 0.514543236651651\n",
      "Epoch 46, Loss: 0.5128400616442574\n",
      "Epoch 47, Loss: 0.5088954235936309\n",
      "Epoch 48, Loss: 0.5047741594111183\n",
      "Epoch 49, Loss: 0.5019797826434544\n",
      "Epoch 50, Loss: 0.5006048001751526\n",
      "Epoch 51, Loss: 0.4997238797464896\n",
      "Epoch 52, Loss: 0.4984906482163699\n",
      "Epoch 53, Loss: 0.4965198969345259\n",
      "Epoch 54, Loss: 0.4939358856279051\n",
      "Epoch 55, Loss: 0.4912604578132936\n",
      "Epoch 56, Loss: 0.48912361725948805\n",
      "Epoch 57, Loss: 0.4879039680116317\n",
      "Epoch 58, Loss: 0.48704179235313105\n",
      "Epoch 59, Loss: 0.48544295312110525\n",
      "Epoch 60, Loss: 0.482967963389284\n",
      "Epoch 61, Loss: 0.4805039028551058\n",
      "Epoch 62, Loss: 0.4787568087878\n",
      "Epoch 63, Loss: 0.4775642123162323\n",
      "Epoch 64, Loss: 0.4762651891864382\n",
      "Epoch 65, Loss: 0.47446035863599795\n",
      "Epoch 66, Loss: 0.47242097279516276\n",
      "Epoch 67, Loss: 0.4707175446513686\n",
      "Epoch 68, Loss: 0.46974640485129837\n",
      "Epoch 69, Loss: 0.46883596585682025\n",
      "Epoch 70, Loss: 0.46740875682246563\n",
      "Epoch 71, Loss: 0.4659893760738961\n",
      "Epoch 72, Loss: 0.4649928358766927\n",
      "Epoch 73, Loss: 0.46413776737778806\n",
      "Epoch 74, Loss: 0.46285212231912143\n",
      "Epoch 75, Loss: 0.4613275009525739\n",
      "Epoch 76, Loss: 0.4602705769764429\n",
      "Epoch 77, Loss: 0.459572257294372\n",
      "Epoch 78, Loss: 0.45831799120222916\n",
      "Epoch 79, Loss: 0.4571003657841726\n",
      "Epoch 80, Loss: 0.45635597356934726\n",
      "Epoch 81, Loss: 0.4556287945614221\n",
      "Epoch 82, Loss: 0.45448901966730293\n",
      "Epoch 83, Loss: 0.45345284670643815\n",
      "Epoch 84, Loss: 0.45280438623207875\n",
      "Epoch 85, Loss: 0.45194729312441034\n",
      "Epoch 86, Loss: 0.45089123407257914\n",
      "Epoch 87, Loss: 0.45026678482003185\n",
      "Epoch 88, Loss: 0.44966493092645654\n",
      "Epoch 89, Loss: 0.44876143355932585\n",
      "Epoch 90, Loss: 0.4481918871878568\n",
      "Epoch 91, Loss: 0.44758228270107253\n",
      "Epoch 92, Loss: 0.4467590161509375\n",
      "Epoch 93, Loss: 0.4462234649195381\n",
      "Epoch 94, Loss: 0.4452830020437174\n",
      "Epoch 95, Loss: 0.4445893791017659\n",
      "Epoch 96, Loss: 0.44379089798307236\n",
      "Epoch 97, Loss: 0.443004701558216\n",
      "Epoch 98, Loss: 0.44237026508381044\n",
      "Epoch 99, Loss: 0.44153981171435785\n",
      "Epoch 100, Loss: 0.4408878049956644\n",
      "Epoch 101, Loss: 0.44006970701423354\n",
      "Epoch 102, Loss: 0.43933826216975286\n",
      "Epoch 103, Loss: 0.4386036610069592\n",
      "Epoch 104, Loss: 0.43788679939661096\n",
      "Epoch 105, Loss: 0.43719691609296635\n",
      "Epoch 106, Loss: 0.4364673655295372\n",
      "Epoch 107, Loss: 0.43578448464337616\n",
      "Epoch 108, Loss: 0.4350808391599409\n",
      "Epoch 109, Loss: 0.43440665260089373\n",
      "Epoch 110, Loss: 0.43370960165644545\n",
      "Epoch 111, Loss: 0.43304491103551246\n",
      "Epoch 112, Loss: 0.4323910365355153\n",
      "Epoch 113, Loss: 0.4317636444020969\n",
      "Epoch 114, Loss: 0.4311515834019697\n",
      "Epoch 115, Loss: 0.4305383927076109\n",
      "Epoch 116, Loss: 0.4299246220446331\n",
      "Epoch 117, Loss: 0.4292952914985422\n",
      "Epoch 118, Loss: 0.4286929672054983\n",
      "Epoch 119, Loss: 0.42809158807396996\n",
      "Epoch 120, Loss: 0.4274993843219183\n",
      "Epoch 121, Loss: 0.4269170747633758\n",
      "Epoch 122, Loss: 0.42631682562888046\n",
      "Epoch 123, Loss: 0.4257255482766832\n",
      "Epoch 124, Loss: 0.4251356392280338\n",
      "Epoch 125, Loss: 0.4245457002260523\n",
      "Epoch 126, Loss: 0.4239673473733939\n",
      "Epoch 127, Loss: 0.42338392826731747\n",
      "Epoch 128, Loss: 0.4227912278332696\n",
      "Epoch 129, Loss: 0.42221223633059957\n",
      "Epoch 130, Loss: 0.4216625950482271\n",
      "Epoch 131, Loss: 0.42111529718025065\n",
      "Epoch 132, Loss: 0.42057357606944384\n",
      "Epoch 133, Loss: 0.4200367615142834\n",
      "Epoch 134, Loss: 0.41952739195230715\n",
      "Epoch 135, Loss: 0.41901512720255063\n",
      "Epoch 136, Loss: 0.41850492365822284\n",
      "Epoch 137, Loss: 0.4180075190737113\n",
      "Epoch 138, Loss: 0.4175226915211967\n",
      "Epoch 139, Loss: 0.41702122107031336\n",
      "Epoch 140, Loss: 0.4165129576724749\n",
      "Epoch 141, Loss: 0.41602042468530387\n",
      "Epoch 142, Loss: 0.4155594917529273\n",
      "Epoch 143, Loss: 0.41513733541855186\n",
      "Epoch 144, Loss: 0.41476772639061477\n",
      "Epoch 145, Loss: 0.41449071226539624\n",
      "Epoch 146, Loss: 0.41407943187139035\n",
      "Epoch 147, Loss: 0.4133919378362813\n",
      "Epoch 148, Loss: 0.4127443492983195\n",
      "Epoch 149, Loss: 0.4124972971914349\n",
      "Epoch 150, Loss: 0.41218470386658623\n",
      "Epoch 151, Loss: 0.411594394528382\n",
      "Epoch 152, Loss: 0.41095708140435516\n",
      "Epoch 153, Loss: 0.4107057614211925\n",
      "Epoch 154, Loss: 0.41053596358675987\n",
      "Epoch 155, Loss: 0.4099175803277792\n",
      "Epoch 156, Loss: 0.4091717666915428\n",
      "Epoch 157, Loss: 0.40886053052027443\n",
      "Epoch 158, Loss: 0.4086632394142615\n",
      "Epoch 159, Loss: 0.4080367776058517\n",
      "Epoch 160, Loss: 0.4073373108805943\n",
      "Epoch 161, Loss: 0.40688289347549467\n",
      "Epoch 162, Loss: 0.4066175851881704\n",
      "Epoch 163, Loss: 0.40625416313385765\n",
      "Epoch 164, Loss: 0.4056976304470949\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21950907835504269\n",
      "Test R^2 score: 0.4793305941864424\n",
      "Num of epochs: 165\n",
      "Epoch 1, Loss: 0.5859415181340091\n",
      "Epoch 2, Loss: 0.5836776387130873\n",
      "Epoch 3, Loss: 0.5815204708894667\n",
      "Epoch 4, Loss: 0.57946655196163\n",
      "Epoch 5, Loss: 0.5775326194055469\n",
      "Epoch 6, Loss: 0.5757829549652902\n",
      "Epoch 7, Loss: 0.5741536369515495\n",
      "Epoch 8, Loss: 0.5726680187145359\n",
      "Epoch 9, Loss: 0.571247431876589\n",
      "Epoch 10, Loss: 0.5698946637147608\n",
      "Epoch 11, Loss: 0.5686513144424664\n",
      "Epoch 12, Loss: 0.5674920822212988\n",
      "Epoch 13, Loss: 0.5663910962412521\n",
      "Epoch 14, Loss: 0.5653439524321636\n",
      "Epoch 15, Loss: 0.5643505808467922\n",
      "Epoch 16, Loss: 0.5634105518093682\n",
      "Epoch 17, Loss: 0.5625236559238129\n",
      "Epoch 18, Loss: 0.5616907815774758\n",
      "Epoch 19, Loss: 0.5609429053681038\n",
      "Epoch 20, Loss: 0.5602310301000335\n",
      "Epoch 21, Loss: 0.5595557991529052\n",
      "Epoch 22, Loss: 0.5589359009182507\n",
      "Epoch 23, Loss: 0.5583448055379268\n",
      "Epoch 24, Loss: 0.5577703689778248\n",
      "Epoch 25, Loss: 0.5572033096098801\n",
      "Epoch 26, Loss: 0.5567002916983184\n",
      "Epoch 27, Loss: 0.5563806294705146\n",
      "Epoch 28, Loss: 0.5560223274207549\n",
      "Epoch 29, Loss: 0.5556325249865022\n",
      "Epoch 30, Loss: 0.5552870505559869\n",
      "Epoch 31, Loss: 0.5549160661034868\n",
      "Epoch 32, Loss: 0.5544564746563616\n",
      "Epoch 33, Loss: 0.5538576930705499\n",
      "Epoch 34, Loss: 0.5530778067332182\n",
      "Epoch 35, Loss: 0.5520868721134803\n",
      "Epoch 36, Loss: 0.5509173177829615\n",
      "Epoch 37, Loss: 0.5495672441614209\n",
      "Epoch 38, Loss: 0.5479528160160697\n",
      "Epoch 39, Loss: 0.5459291725855562\n",
      "Epoch 40, Loss: 0.5434080309168762\n",
      "Epoch 41, Loss: 0.5405112990399008\n",
      "Epoch 42, Loss: 0.5373662715716772\n",
      "Epoch 43, Loss: 0.5339825142504985\n",
      "Epoch 44, Loss: 0.5302554245167285\n",
      "Epoch 45, Loss: 0.5261878449438532\n",
      "Epoch 46, Loss: 0.5219659474783002\n",
      "Epoch 47, Loss: 0.5181263449436305\n",
      "Epoch 48, Loss: 0.5154385952253884\n",
      "Epoch 49, Loss: 0.5142266646187303\n",
      "Epoch 50, Loss: 0.5129162702809384\n",
      "Epoch 51, Loss: 0.5100375798348398\n",
      "Epoch 52, Loss: 0.5062402594771335\n",
      "Epoch 53, Loss: 0.5027433179698676\n",
      "Epoch 54, Loss: 0.5001098392956502\n",
      "Epoch 55, Loss: 0.4982330871731915\n",
      "Epoch 56, Loss: 0.4965995702956373\n",
      "Epoch 57, Loss: 0.4947654784115168\n",
      "Epoch 58, Loss: 0.492588182871517\n",
      "Epoch 59, Loss: 0.4902402109961392\n",
      "Epoch 60, Loss: 0.4880637485548266\n",
      "Epoch 61, Loss: 0.486282989981285\n",
      "Epoch 62, Loss: 0.48478914829327346\n",
      "Epoch 63, Loss: 0.48327797053322374\n",
      "Epoch 64, Loss: 0.4816157288934942\n",
      "Epoch 65, Loss: 0.47998605688030094\n",
      "Epoch 66, Loss: 0.47864905851963513\n",
      "Epoch 67, Loss: 0.47749869833264513\n",
      "Epoch 68, Loss: 0.4762662216737951\n",
      "Epoch 69, Loss: 0.4747877845281838\n",
      "Epoch 70, Loss: 0.4732250542713557\n",
      "Epoch 71, Loss: 0.4718647627320018\n",
      "Epoch 72, Loss: 0.4708659258535987\n",
      "Epoch 73, Loss: 0.4699716226147661\n",
      "Epoch 74, Loss: 0.46885408199636963\n",
      "Epoch 75, Loss: 0.4676053376274152\n",
      "Epoch 76, Loss: 0.4664562211351617\n",
      "Epoch 77, Loss: 0.4653641648620648\n",
      "Epoch 78, Loss: 0.4642329651085524\n",
      "Epoch 79, Loss: 0.46312165430278757\n",
      "Epoch 80, Loss: 0.46214865923023296\n",
      "Epoch 81, Loss: 0.4612077631905355\n",
      "Epoch 82, Loss: 0.4601533491370274\n",
      "Epoch 83, Loss: 0.45908736027243835\n",
      "Epoch 84, Loss: 0.45815344733873264\n",
      "Epoch 85, Loss: 0.4572808651817912\n",
      "Epoch 86, Loss: 0.4563514185235471\n",
      "Epoch 87, Loss: 0.45541634495343675\n",
      "Epoch 88, Loss: 0.4545394099169575\n",
      "Epoch 89, Loss: 0.453643567867586\n",
      "Epoch 90, Loss: 0.4526929439779295\n",
      "Epoch 91, Loss: 0.4517885262834218\n",
      "Epoch 92, Loss: 0.45090498193034706\n",
      "Epoch 93, Loss: 0.4499337187273115\n",
      "Epoch 94, Loss: 0.44907753424806196\n",
      "Epoch 95, Loss: 0.4482537394844742\n",
      "Epoch 96, Loss: 0.4473880783433302\n",
      "Epoch 97, Loss: 0.44663770817832965\n",
      "Epoch 98, Loss: 0.4458008481012066\n",
      "Epoch 99, Loss: 0.44498521924920775\n",
      "Epoch 100, Loss: 0.4441900831345754\n",
      "Epoch 101, Loss: 0.4433385869332759\n",
      "Epoch 102, Loss: 0.44254732757104526\n",
      "Epoch 103, Loss: 0.4416751380173967\n",
      "Epoch 104, Loss: 0.44085610125696945\n",
      "Epoch 105, Loss: 0.43998919533338154\n",
      "Epoch 106, Loss: 0.4391436016617775\n",
      "Epoch 107, Loss: 0.43827815335245657\n",
      "Epoch 108, Loss: 0.4374156427799615\n",
      "Epoch 109, Loss: 0.4365333538934568\n",
      "Epoch 110, Loss: 0.4356639687555062\n",
      "Epoch 111, Loss: 0.43481841131054766\n",
      "Epoch 112, Loss: 0.4339818677992894\n",
      "Epoch 113, Loss: 0.4331405092190167\n",
      "Epoch 114, Loss: 0.43232074509529106\n",
      "Epoch 115, Loss: 0.4315298292098108\n",
      "Epoch 116, Loss: 0.4307016715238511\n",
      "Epoch 117, Loss: 0.42990226580268287\n",
      "Epoch 118, Loss: 0.4291092015499321\n",
      "Epoch 119, Loss: 0.4283258363825913\n",
      "Epoch 120, Loss: 0.42752550852112764\n",
      "Epoch 121, Loss: 0.42674531198171395\n",
      "Epoch 122, Loss: 0.4259453028735934\n",
      "Epoch 123, Loss: 0.42516501042300014\n",
      "Epoch 124, Loss: 0.4243935711298676\n",
      "Epoch 125, Loss: 0.42365104738054454\n",
      "Epoch 126, Loss: 0.4228999966904863\n",
      "Epoch 127, Loss: 0.4221517573431085\n",
      "Epoch 128, Loss: 0.4213809900347485\n",
      "Epoch 129, Loss: 0.4206240793135884\n",
      "Epoch 130, Loss: 0.4199319705193151\n",
      "Epoch 131, Loss: 0.4194107493528805\n",
      "Epoch 132, Loss: 0.41865800017728316\n",
      "Epoch 133, Loss: 0.41763026355371097\n",
      "Epoch 134, Loss: 0.41695734454702577\n",
      "Epoch 135, Loss: 0.4164811873864084\n",
      "Epoch 136, Loss: 0.4158832536456813\n",
      "Epoch 137, Loss: 0.4149513600754273\n",
      "Epoch 138, Loss: 0.4144540770553023\n",
      "Epoch 139, Loss: 0.41401744093530723\n",
      "Epoch 140, Loss: 0.4134071490045661\n",
      "Epoch 141, Loss: 0.4125429376738569\n",
      "Epoch 142, Loss: 0.41207202181641034\n",
      "Epoch 143, Loss: 0.4116539087937715\n",
      "Epoch 144, Loss: 0.41127524547716826\n",
      "Epoch 145, Loss: 0.4104419984438835\n",
      "Epoch 146, Loss: 0.4099048570692297\n",
      "Epoch 147, Loss: 0.4095134602874128\n",
      "Epoch 148, Loss: 0.40905697969656196\n",
      "Epoch 149, Loss: 0.40851500793632206\n",
      "Epoch 150, Loss: 0.40785689934383734\n",
      "Epoch 151, Loss: 0.40743462532551944\n",
      "Epoch 152, Loss: 0.4069685999417389\n",
      "Epoch 153, Loss: 0.40661529476780606\n",
      "Epoch 154, Loss: 0.40638675588678297\n",
      "Epoch 155, Loss: 0.4061831822832782\n",
      "Epoch 156, Loss: 0.4062677159481335\n",
      "Epoch 157, Loss: 0.40577381910145566\n",
      "Epoch 158, Loss: 0.4049363538393479\n",
      "Epoch 159, Loss: 0.4042578047150539\n",
      "Epoch 160, Loss: 0.40428697878017855\n",
      "Epoch 161, Loss: 0.40431639029907\n",
      "Epoch 162, Loss: 0.40339377336935384\n",
      "Epoch 163, Loss: 0.4028823173810028\n",
      "Epoch 164, Loss: 0.4028937275197315\n",
      "Epoch 165, Loss: 0.4027104049638542\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.23731608376183247\n",
      "Test R^2 score: 0.38794104879583624\n",
      "Num of epochs: 166\n",
      "Epoch 1, Loss: 0.583059618515564\n",
      "Epoch 2, Loss: 0.5799766220527874\n",
      "Epoch 3, Loss: 0.5771943153181381\n",
      "Epoch 4, Loss: 0.5746656223051239\n",
      "Epoch 5, Loss: 0.572329859334607\n",
      "Epoch 6, Loss: 0.5701139966843413\n",
      "Epoch 7, Loss: 0.5680300620461635\n",
      "Epoch 8, Loss: 0.5660889887997791\n",
      "Epoch 9, Loss: 0.5643186309985013\n",
      "Epoch 10, Loss: 0.5627059824288427\n",
      "Epoch 11, Loss: 0.56126979240743\n",
      "Epoch 12, Loss: 0.5601076538628181\n",
      "Epoch 13, Loss: 0.5591405579696301\n",
      "Epoch 14, Loss: 0.5583173428091307\n",
      "Epoch 15, Loss: 0.5577012514793578\n",
      "Epoch 16, Loss: 0.5572102092023977\n",
      "Epoch 17, Loss: 0.5568144677397479\n",
      "Epoch 18, Loss: 0.5565120347719019\n",
      "Epoch 19, Loss: 0.5562988838404036\n",
      "Epoch 20, Loss: 0.5561551838334254\n",
      "Epoch 21, Loss: 0.556093663309149\n",
      "Epoch 22, Loss: 0.556098727755711\n",
      "Epoch 23, Loss: 0.5561395096072518\n",
      "Epoch 24, Loss: 0.5562051776443354\n",
      "Epoch 25, Loss: 0.5562735970453252\n",
      "Epoch 26, Loss: 0.5563348566115964\n",
      "Epoch 27, Loss: 0.5563779512325837\n",
      "Epoch 28, Loss: 0.5563904584932441\n",
      "Epoch 29, Loss: 0.556358399705104\n",
      "Epoch 30, Loss: 0.5562787937898479\n",
      "Epoch 31, Loss: 0.5561653383527027\n",
      "Epoch 32, Loss: 0.5559807865301571\n",
      "Epoch 33, Loss: 0.5557527119428367\n",
      "Epoch 34, Loss: 0.5554650458146644\n",
      "Epoch 35, Loss: 0.5551122731410093\n",
      "Epoch 36, Loss: 0.5546832017329062\n",
      "Epoch 37, Loss: 0.5541669794191707\n",
      "Epoch 38, Loss: 0.5535302784123581\n",
      "Epoch 39, Loss: 0.5527335392706386\n",
      "Epoch 40, Loss: 0.5517396636948813\n",
      "Epoch 41, Loss: 0.550542414400715\n",
      "Epoch 42, Loss: 0.5491540830045512\n",
      "Epoch 43, Loss: 0.5475510097500274\n",
      "Epoch 44, Loss: 0.5457188510471992\n",
      "Epoch 45, Loss: 0.5435876132479438\n",
      "Epoch 46, Loss: 0.5410898756725151\n",
      "Epoch 47, Loss: 0.5381768733065135\n",
      "Epoch 48, Loss: 0.5347695171473704\n",
      "Epoch 49, Loss: 0.5308462179208222\n",
      "Epoch 50, Loss: 0.52650928171785\n",
      "Epoch 51, Loss: 0.5220058562637181\n",
      "Epoch 52, Loss: 0.5177744079373539\n",
      "Epoch 53, Loss: 0.5143462421262531\n",
      "Epoch 54, Loss: 0.5116980162635208\n",
      "Epoch 55, Loss: 0.5089536316516935\n",
      "Epoch 56, Loss: 0.5056028857304967\n",
      "Epoch 57, Loss: 0.5021244454336867\n",
      "Epoch 58, Loss: 0.4992918722122628\n",
      "Epoch 59, Loss: 0.49719101914767416\n",
      "Epoch 60, Loss: 0.49548333828952273\n",
      "Epoch 61, Loss: 0.4937089987522912\n",
      "Epoch 62, Loss: 0.49157107065032335\n",
      "Epoch 63, Loss: 0.48916396651532773\n",
      "Epoch 64, Loss: 0.48687524927742565\n",
      "Epoch 65, Loss: 0.4850145701304162\n",
      "Epoch 66, Loss: 0.4834137576979663\n",
      "Epoch 67, Loss: 0.48164377513143064\n",
      "Epoch 68, Loss: 0.47967131273623215\n",
      "Epoch 69, Loss: 0.47789058735815987\n",
      "Epoch 70, Loss: 0.47648766977622437\n",
      "Epoch 71, Loss: 0.4750828833797304\n",
      "Epoch 72, Loss: 0.4733076099952631\n",
      "Epoch 73, Loss: 0.4714617650284601\n",
      "Epoch 74, Loss: 0.4699160378110227\n",
      "Epoch 75, Loss: 0.4686565305980278\n",
      "Epoch 76, Loss: 0.4674736447988731\n",
      "Epoch 77, Loss: 0.46600259857005766\n",
      "Epoch 78, Loss: 0.46462959677880517\n",
      "Epoch 79, Loss: 0.4635525569993787\n",
      "Epoch 80, Loss: 0.4624739272269059\n",
      "Epoch 81, Loss: 0.46110502528511377\n",
      "Epoch 82, Loss: 0.4597214968497299\n",
      "Epoch 83, Loss: 0.4588048218496596\n",
      "Epoch 84, Loss: 0.45757943883794855\n",
      "Epoch 85, Loss: 0.45649154291853167\n",
      "Epoch 86, Loss: 0.45579457676457735\n",
      "Epoch 87, Loss: 0.45474402807109227\n",
      "Epoch 88, Loss: 0.45383074488633063\n",
      "Epoch 89, Loss: 0.45310858992754544\n",
      "Epoch 90, Loss: 0.45209300152450416\n",
      "Epoch 91, Loss: 0.4513423977246384\n",
      "Epoch 92, Loss: 0.45051131670240685\n",
      "Epoch 93, Loss: 0.4496389994071094\n",
      "Epoch 94, Loss: 0.44902410851453745\n",
      "Epoch 95, Loss: 0.44819137185471963\n",
      "Epoch 96, Loss: 0.44758020191106934\n",
      "Epoch 97, Loss: 0.44675451335004024\n",
      "Epoch 98, Loss: 0.44605963755252126\n",
      "Epoch 99, Loss: 0.44530316393250996\n",
      "Epoch 100, Loss: 0.4445803965400339\n",
      "Epoch 101, Loss: 0.44388968727179\n",
      "Epoch 102, Loss: 0.4431417494057786\n",
      "Epoch 103, Loss: 0.44249092448351374\n",
      "Epoch 104, Loss: 0.44173665466832207\n",
      "Epoch 105, Loss: 0.4410742295878414\n",
      "Epoch 106, Loss: 0.4403668377813122\n",
      "Epoch 107, Loss: 0.43969523224474305\n",
      "Epoch 108, Loss: 0.4389801531913018\n",
      "Epoch 109, Loss: 0.4382667464306166\n",
      "Epoch 110, Loss: 0.4375717581074799\n",
      "Epoch 111, Loss: 0.4368090793772064\n",
      "Epoch 112, Loss: 0.4360807251907219\n",
      "Epoch 113, Loss: 0.43528664516939825\n",
      "Epoch 114, Loss: 0.43447657227760955\n",
      "Epoch 115, Loss: 0.4336694359234017\n",
      "Epoch 116, Loss: 0.43286244692929476\n",
      "Epoch 117, Loss: 0.43211059531517326\n",
      "Epoch 118, Loss: 0.43142924591860293\n",
      "Epoch 119, Loss: 0.43072393438012685\n",
      "Epoch 120, Loss: 0.4300317598967339\n",
      "Epoch 121, Loss: 0.4293955591435435\n",
      "Epoch 122, Loss: 0.428757979955453\n",
      "Epoch 123, Loss: 0.4281110803053697\n",
      "Epoch 124, Loss: 0.42745161072662585\n",
      "Epoch 125, Loss: 0.42681882583615927\n",
      "Epoch 126, Loss: 0.42620261804339576\n",
      "Epoch 127, Loss: 0.42559915550962\n",
      "Epoch 128, Loss: 0.42501143762681176\n",
      "Epoch 129, Loss: 0.4244456736294827\n",
      "Epoch 130, Loss: 0.4239472779871911\n",
      "Epoch 131, Loss: 0.42339723191457873\n",
      "Epoch 132, Loss: 0.42270825360508757\n",
      "Epoch 133, Loss: 0.42197270498207057\n",
      "Epoch 134, Loss: 0.42149042331997855\n",
      "Epoch 135, Loss: 0.42113797834897454\n",
      "Epoch 136, Loss: 0.42042582235710113\n",
      "Epoch 137, Loss: 0.41970020919723694\n",
      "Epoch 138, Loss: 0.4192150465851097\n",
      "Epoch 139, Loss: 0.4187593914516122\n",
      "Epoch 140, Loss: 0.4181358502495523\n",
      "Epoch 141, Loss: 0.4174372243513353\n",
      "Epoch 142, Loss: 0.4169330420972695\n",
      "Epoch 143, Loss: 0.41653669436194585\n",
      "Epoch 144, Loss: 0.4160204425944737\n",
      "Epoch 145, Loss: 0.4154230831968171\n",
      "Epoch 146, Loss: 0.41477663607198517\n",
      "Epoch 147, Loss: 0.41426090669173327\n",
      "Epoch 148, Loss: 0.41381873746871556\n",
      "Epoch 149, Loss: 0.41338654891135357\n",
      "Epoch 150, Loss: 0.41301243265595405\n",
      "Epoch 151, Loss: 0.41252785718661344\n",
      "Epoch 152, Loss: 0.4119651144197602\n",
      "Epoch 153, Loss: 0.411348481141005\n",
      "Epoch 154, Loss: 0.4108225542025275\n",
      "Epoch 155, Loss: 0.41041908925046633\n",
      "Epoch 156, Loss: 0.4100800943063902\n",
      "Epoch 157, Loss: 0.4097312178225906\n",
      "Epoch 158, Loss: 0.4092343824152902\n",
      "Epoch 159, Loss: 0.40864827100480666\n",
      "Epoch 160, Loss: 0.40809387132131797\n",
      "Epoch 161, Loss: 0.4076470232994429\n",
      "Epoch 162, Loss: 0.4072766536212396\n",
      "Epoch 163, Loss: 0.40696189933892113\n",
      "Epoch 164, Loss: 0.40669658763177113\n",
      "Epoch 165, Loss: 0.40642342167076373\n",
      "Epoch 166, Loss: 0.4061386799514601\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22621588175950483\n",
      "Test R^2 score: 0.4453015857403224\n",
      "Num of epochs: 167\n",
      "Epoch 1, Loss: 0.5641118902419731\n",
      "Epoch 2, Loss: 0.5629862432120392\n",
      "Epoch 3, Loss: 0.5619413197535751\n",
      "Epoch 4, Loss: 0.560979961605172\n",
      "Epoch 5, Loss: 0.5601074676340726\n",
      "Epoch 6, Loss: 0.5593352831161276\n",
      "Epoch 7, Loss: 0.5586559020991596\n",
      "Epoch 8, Loss: 0.5580935072263675\n",
      "Epoch 9, Loss: 0.5576347441840571\n",
      "Epoch 10, Loss: 0.5572561240820235\n",
      "Epoch 11, Loss: 0.556942105215693\n",
      "Epoch 12, Loss: 0.5566992210198406\n",
      "Epoch 13, Loss: 0.5565192642424943\n",
      "Epoch 14, Loss: 0.5563924939094917\n",
      "Epoch 15, Loss: 0.5563051250017342\n",
      "Epoch 16, Loss: 0.5562503450371176\n",
      "Epoch 17, Loss: 0.5562169922454182\n",
      "Epoch 18, Loss: 0.5561953721385794\n",
      "Epoch 19, Loss: 0.5561777432262475\n",
      "Epoch 20, Loss: 0.55615569290345\n",
      "Epoch 21, Loss: 0.5561200032866074\n",
      "Epoch 22, Loss: 0.556053816027908\n",
      "Epoch 23, Loss: 0.5559473907637278\n",
      "Epoch 24, Loss: 0.5558015891174929\n",
      "Epoch 25, Loss: 0.5556180160564128\n",
      "Epoch 26, Loss: 0.5554252339203395\n",
      "Epoch 27, Loss: 0.5551858463230518\n",
      "Epoch 28, Loss: 0.5548922469811697\n",
      "Epoch 29, Loss: 0.5545492671598848\n",
      "Epoch 30, Loss: 0.5541257297004216\n",
      "Epoch 31, Loss: 0.5535897420016173\n",
      "Epoch 32, Loss: 0.5529245649212994\n",
      "Epoch 33, Loss: 0.5520869260946968\n",
      "Epoch 34, Loss: 0.5510505937551462\n",
      "Epoch 35, Loss: 0.5497560632049537\n",
      "Epoch 36, Loss: 0.5481887840296841\n",
      "Epoch 37, Loss: 0.5463035322447669\n",
      "Epoch 38, Loss: 0.5439761853317235\n",
      "Epoch 39, Loss: 0.5411526062449455\n",
      "Epoch 40, Loss: 0.5377452346345876\n",
      "Epoch 41, Loss: 0.53370972206677\n",
      "Epoch 42, Loss: 0.52903411649398\n",
      "Epoch 43, Loss: 0.5239175331909884\n",
      "Epoch 44, Loss: 0.5187261552960603\n",
      "Epoch 45, Loss: 0.5144301065380122\n",
      "Epoch 46, Loss: 0.5119834099015211\n",
      "Epoch 47, Loss: 0.5106173302530851\n",
      "Epoch 48, Loss: 0.5077963019501934\n",
      "Epoch 49, Loss: 0.5039099759696005\n",
      "Epoch 50, Loss: 0.5008753624141973\n",
      "Epoch 51, Loss: 0.4995655616237862\n",
      "Epoch 52, Loss: 0.498786496760703\n",
      "Epoch 53, Loss: 0.497590937138787\n",
      "Epoch 54, Loss: 0.4956363762299149\n",
      "Epoch 55, Loss: 0.49304447045946537\n",
      "Epoch 56, Loss: 0.49016721044999023\n",
      "Epoch 57, Loss: 0.48751274666872263\n",
      "Epoch 58, Loss: 0.4854897315847766\n",
      "Epoch 59, Loss: 0.48416897791520386\n",
      "Epoch 60, Loss: 0.48290307451538494\n",
      "Epoch 61, Loss: 0.48105387221037665\n",
      "Epoch 62, Loss: 0.47901015904629696\n",
      "Epoch 63, Loss: 0.4772032822932534\n",
      "Epoch 64, Loss: 0.4756892285985317\n",
      "Epoch 65, Loss: 0.4741490647524482\n",
      "Epoch 66, Loss: 0.4724333213755595\n",
      "Epoch 67, Loss: 0.47062080898166586\n",
      "Epoch 68, Loss: 0.4687628744264706\n",
      "Epoch 69, Loss: 0.4672917412400523\n",
      "Epoch 70, Loss: 0.46615837833281554\n",
      "Epoch 71, Loss: 0.4650463175778451\n",
      "Epoch 72, Loss: 0.46369895695282537\n",
      "Epoch 73, Loss: 0.4623960436157152\n",
      "Epoch 74, Loss: 0.46138830285025856\n",
      "Epoch 75, Loss: 0.4604847511019958\n",
      "Epoch 76, Loss: 0.45952926108699366\n",
      "Epoch 77, Loss: 0.45859957858643136\n",
      "Epoch 78, Loss: 0.45778675072030595\n",
      "Epoch 79, Loss: 0.4570133988244275\n",
      "Epoch 80, Loss: 0.4562899944334112\n",
      "Epoch 81, Loss: 0.45562016046305964\n",
      "Epoch 82, Loss: 0.4549351250593976\n",
      "Epoch 83, Loss: 0.4542104446969323\n",
      "Epoch 84, Loss: 0.4534731218265154\n",
      "Epoch 85, Loss: 0.452854404550777\n",
      "Epoch 86, Loss: 0.4521529689751243\n",
      "Epoch 87, Loss: 0.45137420675249734\n",
      "Epoch 88, Loss: 0.450737202969942\n",
      "Epoch 89, Loss: 0.450169725994282\n",
      "Epoch 90, Loss: 0.4495392692521555\n",
      "Epoch 91, Loss: 0.44891385221699626\n",
      "Epoch 92, Loss: 0.4482984154367534\n",
      "Epoch 93, Loss: 0.44769045381211964\n",
      "Epoch 94, Loss: 0.4470704164917351\n",
      "Epoch 95, Loss: 0.4464444113373579\n",
      "Epoch 96, Loss: 0.4457765135996477\n",
      "Epoch 97, Loss: 0.44510515304707293\n",
      "Epoch 98, Loss: 0.4444560465026847\n",
      "Epoch 99, Loss: 0.443772195207239\n",
      "Epoch 100, Loss: 0.44311045914696273\n",
      "Epoch 101, Loss: 0.442406626348813\n",
      "Epoch 102, Loss: 0.4416867942842206\n",
      "Epoch 103, Loss: 0.441050918153517\n",
      "Epoch 104, Loss: 0.4403919449089915\n",
      "Epoch 105, Loss: 0.43976856354724303\n",
      "Epoch 106, Loss: 0.4391218844400149\n",
      "Epoch 107, Loss: 0.4384748293156343\n",
      "Epoch 108, Loss: 0.4378556951361321\n",
      "Epoch 109, Loss: 0.4371819702627651\n",
      "Epoch 110, Loss: 0.4365319372796118\n",
      "Epoch 111, Loss: 0.4358587474172327\n",
      "Epoch 112, Loss: 0.4352490214928984\n",
      "Epoch 113, Loss: 0.4346347203905286\n",
      "Epoch 114, Loss: 0.4340190348274423\n",
      "Epoch 115, Loss: 0.4333875354772663\n",
      "Epoch 116, Loss: 0.43276516900012885\n",
      "Epoch 117, Loss: 0.4321539747650103\n",
      "Epoch 118, Loss: 0.43154975314309496\n",
      "Epoch 119, Loss: 0.43093804534368607\n",
      "Epoch 120, Loss: 0.430340115250458\n",
      "Epoch 121, Loss: 0.42972850603895646\n",
      "Epoch 122, Loss: 0.42909973866453194\n",
      "Epoch 123, Loss: 0.4284514073925606\n",
      "Epoch 124, Loss: 0.4277815596800717\n",
      "Epoch 125, Loss: 0.42712470373735656\n",
      "Epoch 126, Loss: 0.42647752788838134\n",
      "Epoch 127, Loss: 0.42583738184507985\n",
      "Epoch 128, Loss: 0.4251909275906478\n",
      "Epoch 129, Loss: 0.42451744453073653\n",
      "Epoch 130, Loss: 0.4238253123106554\n",
      "Epoch 131, Loss: 0.42310931518987027\n",
      "Epoch 132, Loss: 0.42241623386675203\n",
      "Epoch 133, Loss: 0.42170037081491596\n",
      "Epoch 134, Loss: 0.42094049442758297\n",
      "Epoch 135, Loss: 0.4201999719298824\n",
      "Epoch 136, Loss: 0.4194191518302299\n",
      "Epoch 137, Loss: 0.4186262147053739\n",
      "Epoch 138, Loss: 0.41783592751900633\n",
      "Epoch 139, Loss: 0.41706363324995066\n",
      "Epoch 140, Loss: 0.41636455033656494\n",
      "Epoch 141, Loss: 0.41602509895246964\n",
      "Epoch 142, Loss: 0.4160880979353917\n",
      "Epoch 143, Loss: 0.414693621322194\n",
      "Epoch 144, Loss: 0.4139152300945216\n",
      "Epoch 145, Loss: 0.413713325966874\n",
      "Epoch 146, Loss: 0.4123990636212294\n",
      "Epoch 147, Loss: 0.4123886391568734\n",
      "Epoch 148, Loss: 0.41127211143161463\n",
      "Epoch 149, Loss: 0.41074605042967\n",
      "Epoch 150, Loss: 0.410236859347671\n",
      "Epoch 151, Loss: 0.40918649745181496\n",
      "Epoch 152, Loss: 0.4090214789901708\n",
      "Epoch 153, Loss: 0.4079412870831839\n",
      "Epoch 154, Loss: 0.4075252983220879\n",
      "Epoch 155, Loss: 0.4069796758329111\n",
      "Epoch 156, Loss: 0.40607175217771474\n",
      "Epoch 157, Loss: 0.40577907043153705\n",
      "Epoch 158, Loss: 0.4049982262501905\n",
      "Epoch 159, Loss: 0.40435825563811895\n",
      "Epoch 160, Loss: 0.4039682351810896\n",
      "Epoch 161, Loss: 0.4031722787737428\n",
      "Epoch 162, Loss: 0.40260421321945944\n",
      "Epoch 163, Loss: 0.40218952148806825\n",
      "Epoch 164, Loss: 0.40146246009068914\n",
      "Epoch 165, Loss: 0.40081747608911794\n",
      "Epoch 166, Loss: 0.4003432641279884\n",
      "Epoch 167, Loss: 0.3998768370974603\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22914708637085884\n",
      "Test R^2 score: 0.42814789516660245\n",
      "Num of epochs: 168\n",
      "Epoch 1, Loss: 0.5937332853675039\n",
      "Epoch 2, Loss: 0.5909705105119364\n",
      "Epoch 3, Loss: 0.5882947172976565\n",
      "Epoch 4, Loss: 0.5857080391765087\n",
      "Epoch 5, Loss: 0.5832129138449514\n",
      "Epoch 6, Loss: 0.5808102903169094\n",
      "Epoch 7, Loss: 0.5785021969037226\n",
      "Epoch 8, Loss: 0.5762920965428868\n",
      "Epoch 9, Loss: 0.5742062418087874\n",
      "Epoch 10, Loss: 0.5722158364780159\n",
      "Epoch 11, Loss: 0.5703221673015467\n",
      "Epoch 12, Loss: 0.568527354163589\n",
      "Epoch 13, Loss: 0.5668340974412072\n",
      "Epoch 14, Loss: 0.5652465523737389\n",
      "Epoch 15, Loss: 0.5637712154498732\n",
      "Epoch 16, Loss: 0.5624109038681684\n",
      "Epoch 17, Loss: 0.5611867940439222\n",
      "Epoch 18, Loss: 0.560119731994932\n",
      "Epoch 19, Loss: 0.5591562813174847\n",
      "Epoch 20, Loss: 0.5582876100132516\n",
      "Epoch 21, Loss: 0.5575179831850333\n",
      "Epoch 22, Loss: 0.5568443059543313\n",
      "Epoch 23, Loss: 0.5562637123818017\n",
      "Epoch 24, Loss: 0.5559006708478371\n",
      "Epoch 25, Loss: 0.5555532442150779\n",
      "Epoch 26, Loss: 0.5552167919247005\n",
      "Epoch 27, Loss: 0.5548956037401178\n",
      "Epoch 28, Loss: 0.5545725636209164\n",
      "Epoch 29, Loss: 0.5542261058318149\n",
      "Epoch 30, Loss: 0.5538198643134374\n",
      "Epoch 31, Loss: 0.5533249736014602\n",
      "Epoch 32, Loss: 0.5526963615151397\n",
      "Epoch 33, Loss: 0.5518670168133996\n",
      "Epoch 34, Loss: 0.5507945877516405\n",
      "Epoch 35, Loss: 0.5494118840635136\n",
      "Epoch 36, Loss: 0.5476259525206327\n",
      "Epoch 37, Loss: 0.5453774246871875\n",
      "Epoch 38, Loss: 0.5426402298803038\n",
      "Epoch 39, Loss: 0.5394121224899373\n",
      "Epoch 40, Loss: 0.5356357681545175\n",
      "Epoch 41, Loss: 0.531371215006383\n",
      "Epoch 42, Loss: 0.5269921720274452\n",
      "Epoch 43, Loss: 0.5232043814733034\n",
      "Epoch 44, Loss: 0.5207124919578265\n",
      "Epoch 45, Loss: 0.5191538881512104\n",
      "Epoch 46, Loss: 0.5166019663241274\n",
      "Epoch 47, Loss: 0.5122828104785075\n",
      "Epoch 48, Loss: 0.5073877171860786\n",
      "Epoch 49, Loss: 0.5032733816901451\n",
      "Epoch 50, Loss: 0.5002314210822679\n",
      "Epoch 51, Loss: 0.4976592556370109\n",
      "Epoch 52, Loss: 0.4949089680880257\n",
      "Epoch 53, Loss: 0.49183472600567574\n",
      "Epoch 54, Loss: 0.4887656746177688\n",
      "Epoch 55, Loss: 0.4863739451688859\n",
      "Epoch 56, Loss: 0.48492157769074995\n",
      "Epoch 57, Loss: 0.48367540535973175\n",
      "Epoch 58, Loss: 0.4819934038733819\n",
      "Epoch 59, Loss: 0.4803134388067518\n",
      "Epoch 60, Loss: 0.4791502500569032\n",
      "Epoch 61, Loss: 0.47830834083637985\n",
      "Epoch 62, Loss: 0.4773675653538461\n",
      "Epoch 63, Loss: 0.47638999443308994\n",
      "Epoch 64, Loss: 0.47556621346118655\n",
      "Epoch 65, Loss: 0.4748985288805255\n",
      "Epoch 66, Loss: 0.47419115957223373\n",
      "Epoch 67, Loss: 0.47324257731372427\n",
      "Epoch 68, Loss: 0.4721940200072763\n",
      "Epoch 69, Loss: 0.47123035013024467\n",
      "Epoch 70, Loss: 0.4704431789496847\n",
      "Epoch 71, Loss: 0.46971766409901666\n",
      "Epoch 72, Loss: 0.468995125574431\n",
      "Epoch 73, Loss: 0.46830968839829007\n",
      "Epoch 74, Loss: 0.46763618382854016\n",
      "Epoch 75, Loss: 0.4668716466545798\n",
      "Epoch 76, Loss: 0.4659263442179599\n",
      "Epoch 77, Loss: 0.4649445560687552\n",
      "Epoch 78, Loss: 0.46411015622283497\n",
      "Epoch 79, Loss: 0.4633450430424092\n",
      "Epoch 80, Loss: 0.46264265154456197\n",
      "Epoch 81, Loss: 0.46193636947223043\n",
      "Epoch 82, Loss: 0.4612737657528934\n",
      "Epoch 83, Loss: 0.46056142109426046\n",
      "Epoch 84, Loss: 0.4598123913933731\n",
      "Epoch 85, Loss: 0.45903443408448397\n",
      "Epoch 86, Loss: 0.4582952642525314\n",
      "Epoch 87, Loss: 0.45757714298632046\n",
      "Epoch 88, Loss: 0.4568437534037151\n",
      "Epoch 89, Loss: 0.4560970637954815\n",
      "Epoch 90, Loss: 0.4553856199640318\n",
      "Epoch 91, Loss: 0.4546701296867192\n",
      "Epoch 92, Loss: 0.4539611927600081\n",
      "Epoch 93, Loss: 0.45326061521346417\n",
      "Epoch 94, Loss: 0.45256145555248994\n",
      "Epoch 95, Loss: 0.451863720358683\n",
      "Epoch 96, Loss: 0.45119312781277165\n",
      "Epoch 97, Loss: 0.45050514796593727\n",
      "Epoch 98, Loss: 0.44980346109717506\n",
      "Epoch 99, Loss: 0.44912181305915844\n",
      "Epoch 100, Loss: 0.44841088338940205\n",
      "Epoch 101, Loss: 0.44772611675324464\n",
      "Epoch 102, Loss: 0.4470307845560242\n",
      "Epoch 103, Loss: 0.4463319987338119\n",
      "Epoch 104, Loss: 0.44561690249582997\n",
      "Epoch 105, Loss: 0.44488220171928766\n",
      "Epoch 106, Loss: 0.4441540523972022\n",
      "Epoch 107, Loss: 0.44341260951742534\n",
      "Epoch 108, Loss: 0.4426845675054502\n",
      "Epoch 109, Loss: 0.44192557041476466\n",
      "Epoch 110, Loss: 0.4411674292306443\n",
      "Epoch 111, Loss: 0.440387427761835\n",
      "Epoch 112, Loss: 0.43958626319788713\n",
      "Epoch 113, Loss: 0.4387826000231162\n",
      "Epoch 114, Loss: 0.4379528290722656\n",
      "Epoch 115, Loss: 0.437144918760813\n",
      "Epoch 116, Loss: 0.43632314981409154\n",
      "Epoch 117, Loss: 0.43552422571522353\n",
      "Epoch 118, Loss: 0.43475894905715967\n",
      "Epoch 119, Loss: 0.4339970268376202\n",
      "Epoch 120, Loss: 0.43325142621236484\n",
      "Epoch 121, Loss: 0.4325340139376383\n",
      "Epoch 122, Loss: 0.43182923006794965\n",
      "Epoch 123, Loss: 0.43112111653552865\n",
      "Epoch 124, Loss: 0.4304003784104903\n",
      "Epoch 125, Loss: 0.42968914725248\n",
      "Epoch 126, Loss: 0.4290069392405555\n",
      "Epoch 127, Loss: 0.4283974094122875\n",
      "Epoch 128, Loss: 0.42786456003806234\n",
      "Epoch 129, Loss: 0.42714274001017394\n",
      "Epoch 130, Loss: 0.4262505840621929\n",
      "Epoch 131, Loss: 0.42577383052416024\n",
      "Epoch 132, Loss: 0.4252249907551958\n",
      "Epoch 133, Loss: 0.4244240645078407\n",
      "Epoch 134, Loss: 0.4239832686449711\n",
      "Epoch 135, Loss: 0.42339608809889817\n",
      "Epoch 136, Loss: 0.4226639047095213\n",
      "Epoch 137, Loss: 0.42222794144957837\n",
      "Epoch 138, Loss: 0.4217003354790167\n",
      "Epoch 139, Loss: 0.4209517690764804\n",
      "Epoch 140, Loss: 0.4204503836531243\n",
      "Epoch 141, Loss: 0.4200370098451608\n",
      "Epoch 142, Loss: 0.41934526465978395\n",
      "Epoch 143, Loss: 0.4187013320255251\n",
      "Epoch 144, Loss: 0.4182382944456194\n",
      "Epoch 145, Loss: 0.41770764689337564\n",
      "Epoch 146, Loss: 0.41708926783838796\n",
      "Epoch 147, Loss: 0.41648718027784787\n",
      "Epoch 148, Loss: 0.4159621083398023\n",
      "Epoch 149, Loss: 0.4154749656863617\n",
      "Epoch 150, Loss: 0.4149794412311942\n",
      "Epoch 151, Loss: 0.41441333950115217\n",
      "Epoch 152, Loss: 0.41383758770316126\n",
      "Epoch 153, Loss: 0.41326734378833274\n",
      "Epoch 154, Loss: 0.41270409289008864\n",
      "Epoch 155, Loss: 0.41216279537849904\n",
      "Epoch 156, Loss: 0.4116524427610433\n",
      "Epoch 157, Loss: 0.4111709214622926\n",
      "Epoch 158, Loss: 0.4107772667054344\n",
      "Epoch 159, Loss: 0.41070822857898015\n",
      "Epoch 160, Loss: 0.4111881898386292\n",
      "Epoch 161, Loss: 0.4103604671160312\n",
      "Epoch 162, Loss: 0.4088683844683944\n",
      "Epoch 163, Loss: 0.4086250606815717\n",
      "Epoch 164, Loss: 0.4088458426857218\n",
      "Epoch 165, Loss: 0.40769998671821944\n",
      "Epoch 166, Loss: 0.4071774167197878\n",
      "Epoch 167, Loss: 0.4072484438206661\n",
      "Epoch 168, Loss: 0.4065840704705922\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.23334796947503064\n",
      "Test R^2 score: 0.4078347160476235\n",
      "Num of epochs: 169\n",
      "Epoch 1, Loss: 0.5707467398665259\n",
      "Epoch 2, Loss: 0.5688867383637279\n",
      "Epoch 3, Loss: 0.5671533064610563\n",
      "Epoch 4, Loss: 0.5656209302724198\n",
      "Epoch 5, Loss: 0.5642150852165693\n",
      "Epoch 6, Loss: 0.5629237221511681\n",
      "Epoch 7, Loss: 0.5617169917348367\n",
      "Epoch 8, Loss: 0.560639430256934\n",
      "Epoch 9, Loss: 0.5596853940105166\n",
      "Epoch 10, Loss: 0.5588511160855848\n",
      "Epoch 11, Loss: 0.5581593992220147\n",
      "Epoch 12, Loss: 0.5576659547020669\n",
      "Epoch 13, Loss: 0.5572474601776718\n",
      "Epoch 14, Loss: 0.5569018637688483\n",
      "Epoch 15, Loss: 0.5566095979308507\n",
      "Epoch 16, Loss: 0.5563667024924879\n",
      "Epoch 17, Loss: 0.5561698662975726\n",
      "Epoch 18, Loss: 0.5560206122454097\n",
      "Epoch 19, Loss: 0.5559013409833934\n",
      "Epoch 20, Loss: 0.5558033853991269\n",
      "Epoch 21, Loss: 0.5557198119396571\n",
      "Epoch 22, Loss: 0.5556364940917662\n",
      "Epoch 23, Loss: 0.5555444732858722\n",
      "Epoch 24, Loss: 0.5554328263009845\n",
      "Epoch 25, Loss: 0.5552924980464007\n",
      "Epoch 26, Loss: 0.5551107967460616\n",
      "Epoch 27, Loss: 0.5548779335331139\n",
      "Epoch 28, Loss: 0.5545804632367223\n",
      "Epoch 29, Loss: 0.55420596753015\n",
      "Epoch 30, Loss: 0.5537390054252809\n",
      "Epoch 31, Loss: 0.5531590047179052\n",
      "Epoch 32, Loss: 0.5524398234551885\n",
      "Epoch 33, Loss: 0.5515563056749265\n",
      "Epoch 34, Loss: 0.5504769099916821\n",
      "Epoch 35, Loss: 0.5492145901735441\n",
      "Epoch 36, Loss: 0.5477795613075859\n",
      "Epoch 37, Loss: 0.5461048425249125\n",
      "Epoch 38, Loss: 0.5441360823968145\n",
      "Epoch 39, Loss: 0.541868343466382\n",
      "Epoch 40, Loss: 0.5393569252813655\n",
      "Epoch 41, Loss: 0.5365351711416305\n",
      "Epoch 42, Loss: 0.533308109665488\n",
      "Epoch 43, Loss: 0.5295825201559039\n",
      "Epoch 44, Loss: 0.5252508097955125\n",
      "Epoch 45, Loss: 0.5203873886880547\n",
      "Epoch 46, Loss: 0.5150447817655942\n",
      "Epoch 47, Loss: 0.5095468687525573\n",
      "Epoch 48, Loss: 0.5048640411842297\n",
      "Epoch 49, Loss: 0.5020133253281908\n",
      "Epoch 50, Loss: 0.5003130052267332\n",
      "Epoch 51, Loss: 0.49751175200417447\n",
      "Epoch 52, Loss: 0.49324302418895305\n",
      "Epoch 53, Loss: 0.4889685104778135\n",
      "Epoch 54, Loss: 0.48583972106625334\n",
      "Epoch 55, Loss: 0.48372948610442634\n",
      "Epoch 56, Loss: 0.4820135759424282\n",
      "Epoch 57, Loss: 0.48034294156046264\n",
      "Epoch 58, Loss: 0.47834477391279495\n",
      "Epoch 59, Loss: 0.4759933168188518\n",
      "Epoch 60, Loss: 0.4732845481085127\n",
      "Epoch 61, Loss: 0.47080329367365464\n",
      "Epoch 62, Loss: 0.46920933470424236\n",
      "Epoch 63, Loss: 0.46832535900960937\n",
      "Epoch 64, Loss: 0.46714885960137276\n",
      "Epoch 65, Loss: 0.4657462838967076\n",
      "Epoch 66, Loss: 0.4647937555435732\n",
      "Epoch 67, Loss: 0.46428587639721985\n",
      "Epoch 68, Loss: 0.4639669210732312\n",
      "Epoch 69, Loss: 0.4632377288858556\n",
      "Epoch 70, Loss: 0.46195359494362637\n",
      "Epoch 71, Loss: 0.4606417984403249\n",
      "Epoch 72, Loss: 0.45951943559709735\n",
      "Epoch 73, Loss: 0.4586078641626867\n",
      "Epoch 74, Loss: 0.4580095531048265\n",
      "Epoch 75, Loss: 0.45725968349708623\n",
      "Epoch 76, Loss: 0.45635063485516963\n",
      "Epoch 77, Loss: 0.4556237089664708\n",
      "Epoch 78, Loss: 0.454938154838249\n",
      "Epoch 79, Loss: 0.4543097726265361\n",
      "Epoch 80, Loss: 0.4535544925039094\n",
      "Epoch 81, Loss: 0.45261879302148567\n",
      "Epoch 82, Loss: 0.4517622878615331\n",
      "Epoch 83, Loss: 0.4509112443371745\n",
      "Epoch 84, Loss: 0.4502540765172171\n",
      "Epoch 85, Loss: 0.4494880532468833\n",
      "Epoch 86, Loss: 0.44877523005974085\n",
      "Epoch 87, Loss: 0.4480210966162524\n",
      "Epoch 88, Loss: 0.4473228084873597\n",
      "Epoch 89, Loss: 0.44668880064708083\n",
      "Epoch 90, Loss: 0.44588774619399796\n",
      "Epoch 91, Loss: 0.44511385720159174\n",
      "Epoch 92, Loss: 0.44445227472871374\n",
      "Epoch 93, Loss: 0.4437632128937832\n",
      "Epoch 94, Loss: 0.44297866608354397\n",
      "Epoch 95, Loss: 0.44225521647502\n",
      "Epoch 96, Loss: 0.44160311874527103\n",
      "Epoch 97, Loss: 0.4408899173705883\n",
      "Epoch 98, Loss: 0.440071552430015\n",
      "Epoch 99, Loss: 0.43927586689266956\n",
      "Epoch 100, Loss: 0.43861764112307444\n",
      "Epoch 101, Loss: 0.43793862357961105\n",
      "Epoch 102, Loss: 0.4371082732022251\n",
      "Epoch 103, Loss: 0.43636909845732985\n",
      "Epoch 104, Loss: 0.4356997268760391\n",
      "Epoch 105, Loss: 0.4349930667872764\n",
      "Epoch 106, Loss: 0.43426199273199795\n",
      "Epoch 107, Loss: 0.43346468404991967\n",
      "Epoch 108, Loss: 0.43274027362914097\n",
      "Epoch 109, Loss: 0.43215952619270304\n",
      "Epoch 110, Loss: 0.4315482856403959\n",
      "Epoch 111, Loss: 0.43101402474639244\n",
      "Epoch 112, Loss: 0.43008524085870187\n",
      "Epoch 113, Loss: 0.4292951700109028\n",
      "Epoch 114, Loss: 0.428759735041388\n",
      "Epoch 115, Loss: 0.42824530894999896\n",
      "Epoch 116, Loss: 0.427765448848093\n",
      "Epoch 117, Loss: 0.42686015981567627\n",
      "Epoch 118, Loss: 0.4260843405613122\n",
      "Epoch 119, Loss: 0.42563413125660754\n",
      "Epoch 120, Loss: 0.42524189866863826\n",
      "Epoch 121, Loss: 0.4248387816329078\n",
      "Epoch 122, Loss: 0.4238380395810751\n",
      "Epoch 123, Loss: 0.42310241236047447\n",
      "Epoch 124, Loss: 0.42285929754287715\n",
      "Epoch 125, Loss: 0.4222467691762039\n",
      "Epoch 126, Loss: 0.4215408167200637\n",
      "Epoch 127, Loss: 0.42080588329920005\n",
      "Epoch 128, Loss: 0.4205544608429592\n",
      "Epoch 129, Loss: 0.4202145288578372\n",
      "Epoch 130, Loss: 0.41934210209075323\n",
      "Epoch 131, Loss: 0.4187762935411444\n",
      "Epoch 132, Loss: 0.41862479088756116\n",
      "Epoch 133, Loss: 0.4179363594695648\n",
      "Epoch 134, Loss: 0.4171617149928368\n",
      "Epoch 135, Loss: 0.41658157035977056\n",
      "Epoch 136, Loss: 0.4162815121874024\n",
      "Epoch 137, Loss: 0.4159752732170157\n",
      "Epoch 138, Loss: 0.4151706262639854\n",
      "Epoch 139, Loss: 0.41434150868278663\n",
      "Epoch 140, Loss: 0.4139309980194846\n",
      "Epoch 141, Loss: 0.4137239331565387\n",
      "Epoch 142, Loss: 0.41358041589771094\n",
      "Epoch 143, Loss: 0.4124127577510809\n",
      "Epoch 144, Loss: 0.4118201700915581\n",
      "Epoch 145, Loss: 0.4117508544565587\n",
      "Epoch 146, Loss: 0.4113642206683624\n",
      "Epoch 147, Loss: 0.4105367258198462\n",
      "Epoch 148, Loss: 0.4098085655499428\n",
      "Epoch 149, Loss: 0.4094676276966509\n",
      "Epoch 150, Loss: 0.4096088207589634\n",
      "Epoch 151, Loss: 0.40880717070196393\n",
      "Epoch 152, Loss: 0.40817176661895\n",
      "Epoch 153, Loss: 0.4074346618986519\n",
      "Epoch 154, Loss: 0.40702203604726855\n",
      "Epoch 155, Loss: 0.4067240480128468\n",
      "Epoch 156, Loss: 0.40660041588298995\n",
      "Epoch 157, Loss: 0.40684207539866085\n",
      "Epoch 158, Loss: 0.4060052354432781\n",
      "Epoch 159, Loss: 0.40521260000236414\n",
      "Epoch 160, Loss: 0.40446409738536865\n",
      "Epoch 161, Loss: 0.40418037173378335\n",
      "Epoch 162, Loss: 0.4039681982941253\n",
      "Epoch 163, Loss: 0.40384796577962384\n",
      "Epoch 164, Loss: 0.4037921353253028\n",
      "Epoch 165, Loss: 0.4032009400691226\n",
      "Epoch 166, Loss: 0.4024470298575973\n",
      "Epoch 167, Loss: 0.4017317849251155\n",
      "Epoch 168, Loss: 0.4014167105387185\n",
      "Epoch 169, Loss: 0.40123924945083994\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22597947914878605\n",
      "Test R^2 score: 0.4484718183939172\n",
      "Num of epochs: 170\n",
      "Epoch 1, Loss: 0.5595256794276969\n",
      "Epoch 2, Loss: 0.5589795147719842\n",
      "Epoch 3, Loss: 0.5584932516965877\n",
      "Epoch 4, Loss: 0.5580672069927382\n",
      "Epoch 5, Loss: 0.5577004231929968\n",
      "Epoch 6, Loss: 0.557389809234846\n",
      "Epoch 7, Loss: 0.5571301633267342\n",
      "Epoch 8, Loss: 0.5569192557083736\n",
      "Epoch 9, Loss: 0.5567434918571806\n",
      "Epoch 10, Loss: 0.5565970688225602\n",
      "Epoch 11, Loss: 0.5564712802214401\n",
      "Epoch 12, Loss: 0.5563636492237899\n",
      "Epoch 13, Loss: 0.5562798384903602\n",
      "Epoch 14, Loss: 0.5562136166707166\n",
      "Epoch 15, Loss: 0.5561666779852021\n",
      "Epoch 16, Loss: 0.5561423229624276\n",
      "Epoch 17, Loss: 0.5561148050582299\n",
      "Epoch 18, Loss: 0.5561061501681327\n",
      "Epoch 19, Loss: 0.5561042476819722\n",
      "Epoch 20, Loss: 0.556105480279382\n",
      "Epoch 21, Loss: 0.5561008714229024\n",
      "Epoch 22, Loss: 0.5560861871370687\n",
      "Epoch 23, Loss: 0.5560597919622413\n",
      "Epoch 24, Loss: 0.5560214430341281\n",
      "Epoch 25, Loss: 0.5559676268006977\n",
      "Epoch 26, Loss: 0.555897507797106\n",
      "Epoch 27, Loss: 0.5558105436578258\n",
      "Epoch 28, Loss: 0.5557037768392978\n",
      "Epoch 29, Loss: 0.5555688813386239\n",
      "Epoch 30, Loss: 0.5553999610080781\n",
      "Epoch 31, Loss: 0.5551909727301222\n",
      "Epoch 32, Loss: 0.5549340036176593\n",
      "Epoch 33, Loss: 0.5546308945262418\n",
      "Epoch 34, Loss: 0.5542602236608793\n",
      "Epoch 35, Loss: 0.5538119269418544\n",
      "Epoch 36, Loss: 0.553275985369538\n",
      "Epoch 37, Loss: 0.5526369905445855\n",
      "Epoch 38, Loss: 0.551859294369786\n",
      "Epoch 39, Loss: 0.5509022789405804\n",
      "Epoch 40, Loss: 0.5497419141909435\n",
      "Epoch 41, Loss: 0.5483201143107199\n",
      "Epoch 42, Loss: 0.5465425298149403\n",
      "Epoch 43, Loss: 0.5443618521870924\n",
      "Epoch 44, Loss: 0.5416544368781556\n",
      "Epoch 45, Loss: 0.5382926806826588\n",
      "Epoch 46, Loss: 0.5343454442021076\n",
      "Epoch 47, Loss: 0.5300465584943957\n",
      "Epoch 48, Loss: 0.5260649257339762\n",
      "Epoch 49, Loss: 0.5235116536010158\n",
      "Epoch 50, Loss: 0.5224772798353121\n",
      "Epoch 51, Loss: 0.5205423654964667\n",
      "Epoch 52, Loss: 0.5170627259086006\n",
      "Epoch 53, Loss: 0.5132203238687898\n",
      "Epoch 54, Loss: 0.5099539573305681\n",
      "Epoch 55, Loss: 0.5073723572847572\n",
      "Epoch 56, Loss: 0.5050050451007791\n",
      "Epoch 57, Loss: 0.5026433333189029\n",
      "Epoch 58, Loss: 0.49995462390517476\n",
      "Epoch 59, Loss: 0.4969212996306164\n",
      "Epoch 60, Loss: 0.4938066431945557\n",
      "Epoch 61, Loss: 0.4909188253297726\n",
      "Epoch 62, Loss: 0.48831802229698595\n",
      "Epoch 63, Loss: 0.48566669081408814\n",
      "Epoch 64, Loss: 0.482876767816154\n",
      "Epoch 65, Loss: 0.4801898239717026\n",
      "Epoch 66, Loss: 0.47708924684094045\n",
      "Epoch 67, Loss: 0.47376549818712155\n",
      "Epoch 68, Loss: 0.47085424822656713\n",
      "Epoch 69, Loss: 0.4684231413255947\n",
      "Epoch 70, Loss: 0.4668088296931623\n",
      "Epoch 71, Loss: 0.4664870954059529\n",
      "Epoch 72, Loss: 0.46681120782658775\n",
      "Epoch 73, Loss: 0.4662086899075548\n",
      "Epoch 74, Loss: 0.4648419548448793\n",
      "Epoch 75, Loss: 0.4632761512720222\n",
      "Epoch 76, Loss: 0.46183345486524496\n",
      "Epoch 77, Loss: 0.4605896332153892\n",
      "Epoch 78, Loss: 0.45983507576582705\n",
      "Epoch 79, Loss: 0.45930343252095784\n",
      "Epoch 80, Loss: 0.4588017364089537\n",
      "Epoch 81, Loss: 0.4583296306055953\n",
      "Epoch 82, Loss: 0.45772774924154186\n",
      "Epoch 83, Loss: 0.45686397588765393\n",
      "Epoch 84, Loss: 0.4559155400970621\n",
      "Epoch 85, Loss: 0.45502546930816545\n",
      "Epoch 86, Loss: 0.45417816172351955\n",
      "Epoch 87, Loss: 0.45336250131867845\n",
      "Epoch 88, Loss: 0.45263726194281223\n",
      "Epoch 89, Loss: 0.45194613913739556\n",
      "Epoch 90, Loss: 0.45126275802710175\n",
      "Epoch 91, Loss: 0.4505370326428148\n",
      "Epoch 92, Loss: 0.4497753841049711\n",
      "Epoch 93, Loss: 0.44902824011014314\n",
      "Epoch 94, Loss: 0.44827764034313783\n",
      "Epoch 95, Loss: 0.44754394467322806\n",
      "Epoch 96, Loss: 0.44684195963218565\n",
      "Epoch 97, Loss: 0.4461750744715111\n",
      "Epoch 98, Loss: 0.445529382995431\n",
      "Epoch 99, Loss: 0.4449076569037845\n",
      "Epoch 100, Loss: 0.4442741267211533\n",
      "Epoch 101, Loss: 0.4436351741732276\n",
      "Epoch 102, Loss: 0.4429972005383235\n",
      "Epoch 103, Loss: 0.4423551403426535\n",
      "Epoch 104, Loss: 0.44172564066318454\n",
      "Epoch 105, Loss: 0.44111618706516925\n",
      "Epoch 106, Loss: 0.44048743704635146\n",
      "Epoch 107, Loss: 0.4398490986744443\n",
      "Epoch 108, Loss: 0.43922050253166645\n",
      "Epoch 109, Loss: 0.43862115731544143\n",
      "Epoch 110, Loss: 0.43801109229046936\n",
      "Epoch 111, Loss: 0.43740489470957405\n",
      "Epoch 112, Loss: 0.43678942946077265\n",
      "Epoch 113, Loss: 0.43617362528864356\n",
      "Epoch 114, Loss: 0.4355627493253452\n",
      "Epoch 115, Loss: 0.43494907974503644\n",
      "Epoch 116, Loss: 0.4343455386976824\n",
      "Epoch 117, Loss: 0.4337957100871992\n",
      "Epoch 118, Loss: 0.4333665957278256\n",
      "Epoch 119, Loss: 0.432751051469007\n",
      "Epoch 120, Loss: 0.4319734282887057\n",
      "Epoch 121, Loss: 0.43110336768609775\n",
      "Epoch 122, Loss: 0.43047925655884234\n",
      "Epoch 123, Loss: 0.4299729179570126\n",
      "Epoch 124, Loss: 0.4293764896172639\n",
      "Epoch 125, Loss: 0.42857466423993046\n",
      "Epoch 126, Loss: 0.4277680962913339\n",
      "Epoch 127, Loss: 0.4271783044714154\n",
      "Epoch 128, Loss: 0.4267160844806906\n",
      "Epoch 129, Loss: 0.4262238922681571\n",
      "Epoch 130, Loss: 0.42568797218432103\n",
      "Epoch 131, Loss: 0.4248601066131594\n",
      "Epoch 132, Loss: 0.4241136213395779\n",
      "Epoch 133, Loss: 0.4236416560332032\n",
      "Epoch 134, Loss: 0.4233774874625103\n",
      "Epoch 135, Loss: 0.42315122280820877\n",
      "Epoch 136, Loss: 0.4221750887522534\n",
      "Epoch 137, Loss: 0.4212375345847759\n",
      "Epoch 138, Loss: 0.4208504279916841\n",
      "Epoch 139, Loss: 0.4205739126597166\n",
      "Epoch 140, Loss: 0.42007544614744\n",
      "Epoch 141, Loss: 0.41911589877528677\n",
      "Epoch 142, Loss: 0.4185661787840042\n",
      "Epoch 143, Loss: 0.4184449059455623\n",
      "Epoch 144, Loss: 0.41785580900640773\n",
      "Epoch 145, Loss: 0.41705420075397753\n",
      "Epoch 146, Loss: 0.4164271043490128\n",
      "Epoch 147, Loss: 0.41610979975345336\n",
      "Epoch 148, Loss: 0.41569766578179557\n",
      "Epoch 149, Loss: 0.41498777184797636\n",
      "Epoch 150, Loss: 0.41424182391572956\n",
      "Epoch 151, Loss: 0.41368643759363266\n",
      "Epoch 152, Loss: 0.41328389359838347\n",
      "Epoch 153, Loss: 0.41298499350728607\n",
      "Epoch 154, Loss: 0.41262820881240436\n",
      "Epoch 155, Loss: 0.41209552615069256\n",
      "Epoch 156, Loss: 0.41115676918817523\n",
      "Epoch 157, Loss: 0.41026382851990945\n",
      "Epoch 158, Loss: 0.4096711696276919\n",
      "Epoch 159, Loss: 0.4093487192410433\n",
      "Epoch 160, Loss: 0.4093063085742765\n",
      "Epoch 161, Loss: 0.4094966671229309\n",
      "Epoch 162, Loss: 0.4092197079991404\n",
      "Epoch 163, Loss: 0.4075304173894766\n",
      "Epoch 164, Loss: 0.40635148028036855\n",
      "Epoch 165, Loss: 0.4066739071464617\n",
      "Epoch 166, Loss: 0.40676110468068555\n",
      "Epoch 167, Loss: 0.4052655506515626\n",
      "Epoch 168, Loss: 0.40422129270080476\n",
      "Epoch 169, Loss: 0.4043433121259385\n",
      "Epoch 170, Loss: 0.4043290498618793\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22685755797897136\n",
      "Test R^2 score: 0.43925960594004315\n",
      "Num of epochs: 171\n",
      "Epoch 1, Loss: 0.564114267610195\n",
      "Epoch 2, Loss: 0.5629388104263966\n",
      "Epoch 3, Loss: 0.5618641756604206\n",
      "Epoch 4, Loss: 0.5608681479167902\n",
      "Epoch 5, Loss: 0.5599558302796447\n",
      "Epoch 6, Loss: 0.5591328027318506\n",
      "Epoch 7, Loss: 0.5584270255158339\n",
      "Epoch 8, Loss: 0.5578104943418375\n",
      "Epoch 9, Loss: 0.5572974896943762\n",
      "Epoch 10, Loss: 0.5568685499988703\n",
      "Epoch 11, Loss: 0.5565281269097884\n",
      "Epoch 12, Loss: 0.556273275595616\n",
      "Epoch 13, Loss: 0.5560983526131029\n",
      "Epoch 14, Loss: 0.5560115270877671\n",
      "Epoch 15, Loss: 0.5559626415672511\n",
      "Epoch 16, Loss: 0.5559532070246157\n",
      "Epoch 17, Loss: 0.555970950264828\n",
      "Epoch 18, Loss: 0.5559958220108777\n",
      "Epoch 19, Loss: 0.5559733356421586\n",
      "Epoch 20, Loss: 0.5559162713940877\n",
      "Epoch 21, Loss: 0.5558138144419759\n",
      "Epoch 22, Loss: 0.5556523702293034\n",
      "Epoch 23, Loss: 0.5554275679848018\n",
      "Epoch 24, Loss: 0.5551386328408097\n",
      "Epoch 25, Loss: 0.5547903798291701\n",
      "Epoch 26, Loss: 0.5543935292275052\n",
      "Epoch 27, Loss: 0.5539683394612115\n",
      "Epoch 28, Loss: 0.5535035459806303\n",
      "Epoch 29, Loss: 0.552974069337464\n",
      "Epoch 30, Loss: 0.5523777272782306\n",
      "Epoch 31, Loss: 0.5517002041880466\n",
      "Epoch 32, Loss: 0.5509392802468811\n",
      "Epoch 33, Loss: 0.5500673577937515\n",
      "Epoch 34, Loss: 0.5490733783145824\n",
      "Epoch 35, Loss: 0.5479833271055423\n",
      "Epoch 36, Loss: 0.546735255234008\n",
      "Epoch 37, Loss: 0.5452552787248885\n",
      "Epoch 38, Loss: 0.5434939636677851\n",
      "Epoch 39, Loss: 0.5414554171785168\n",
      "Epoch 40, Loss: 0.5390660106157624\n",
      "Epoch 41, Loss: 0.5362514788378262\n",
      "Epoch 42, Loss: 0.5330928646567558\n",
      "Epoch 43, Loss: 0.5292479432633214\n",
      "Epoch 44, Loss: 0.5246537724481368\n",
      "Epoch 45, Loss: 0.519672231260648\n",
      "Epoch 46, Loss: 0.5149655894014603\n",
      "Epoch 47, Loss: 0.511528241752911\n",
      "Epoch 48, Loss: 0.5107540326176334\n",
      "Epoch 49, Loss: 0.5108841941161113\n",
      "Epoch 50, Loss: 0.508533640648021\n",
      "Epoch 51, Loss: 0.5044198486828145\n",
      "Epoch 52, Loss: 0.5004312920107306\n",
      "Epoch 53, Loss: 0.49733431836819875\n",
      "Epoch 54, Loss: 0.49493035999422275\n",
      "Epoch 55, Loss: 0.4928094174150176\n",
      "Epoch 56, Loss: 0.49047133049798\n",
      "Epoch 57, Loss: 0.4875986286797693\n",
      "Epoch 58, Loss: 0.4842080474586563\n",
      "Epoch 59, Loss: 0.48062401100523233\n",
      "Epoch 60, Loss: 0.4771867790541483\n",
      "Epoch 61, Loss: 0.4742378224743419\n",
      "Epoch 62, Loss: 0.4718686785495562\n",
      "Epoch 63, Loss: 0.47013507297093576\n",
      "Epoch 64, Loss: 0.4691154485930086\n",
      "Epoch 65, Loss: 0.4683230044740732\n",
      "Epoch 66, Loss: 0.46749213247767907\n",
      "Epoch 67, Loss: 0.46653401782921483\n",
      "Epoch 68, Loss: 0.4653278042420158\n",
      "Epoch 69, Loss: 0.46452836950328397\n",
      "Epoch 70, Loss: 0.46364102923817513\n",
      "Epoch 71, Loss: 0.46274338968008144\n",
      "Epoch 72, Loss: 0.46204611441187243\n",
      "Epoch 73, Loss: 0.46145668531802403\n",
      "Epoch 74, Loss: 0.460981997265638\n",
      "Epoch 75, Loss: 0.46063170553681165\n",
      "Epoch 76, Loss: 0.4602483835259293\n",
      "Epoch 77, Loss: 0.4596875100878125\n",
      "Epoch 78, Loss: 0.45900714898931105\n",
      "Epoch 79, Loss: 0.4582670409493411\n",
      "Epoch 80, Loss: 0.4575152320619113\n",
      "Epoch 81, Loss: 0.456810302797984\n",
      "Epoch 82, Loss: 0.4561617315163844\n",
      "Epoch 83, Loss: 0.45556163069827493\n",
      "Epoch 84, Loss: 0.4550204752150743\n",
      "Epoch 85, Loss: 0.4544663963327746\n",
      "Epoch 86, Loss: 0.4539420555292682\n",
      "Epoch 87, Loss: 0.45348960085514983\n",
      "Epoch 88, Loss: 0.4529826006263623\n",
      "Epoch 89, Loss: 0.4523543513081899\n",
      "Epoch 90, Loss: 0.45174625710149086\n",
      "Epoch 91, Loss: 0.4511991880662356\n",
      "Epoch 92, Loss: 0.4506851642618475\n",
      "Epoch 93, Loss: 0.45018629284344275\n",
      "Epoch 94, Loss: 0.4496595459096881\n",
      "Epoch 95, Loss: 0.44909945023374986\n",
      "Epoch 96, Loss: 0.4485261636734116\n",
      "Epoch 97, Loss: 0.4479487171091282\n",
      "Epoch 98, Loss: 0.4473621314266528\n",
      "Epoch 99, Loss: 0.44677592626461443\n",
      "Epoch 100, Loss: 0.44615981152309914\n",
      "Epoch 101, Loss: 0.44555413232384716\n",
      "Epoch 102, Loss: 0.44499231840854475\n",
      "Epoch 103, Loss: 0.44446358995460344\n",
      "Epoch 104, Loss: 0.4439265450682458\n",
      "Epoch 105, Loss: 0.4433411245748967\n",
      "Epoch 106, Loss: 0.4427453380901469\n",
      "Epoch 107, Loss: 0.4421582525710633\n",
      "Epoch 108, Loss: 0.44157033588019734\n",
      "Epoch 109, Loss: 0.4409285298008875\n",
      "Epoch 110, Loss: 0.4402758547476493\n",
      "Epoch 111, Loss: 0.4396419543309818\n",
      "Epoch 112, Loss: 0.43903778794002807\n",
      "Epoch 113, Loss: 0.43839422867532396\n",
      "Epoch 114, Loss: 0.43776796853720484\n",
      "Epoch 115, Loss: 0.43719427462080884\n",
      "Epoch 116, Loss: 0.4365612756088006\n",
      "Epoch 117, Loss: 0.4358816357165757\n",
      "Epoch 118, Loss: 0.4352164276536588\n",
      "Epoch 119, Loss: 0.43452791157152987\n",
      "Epoch 120, Loss: 0.43377008375123816\n",
      "Epoch 121, Loss: 0.4330533242472325\n",
      "Epoch 122, Loss: 0.43236865273498554\n",
      "Epoch 123, Loss: 0.4317077480961785\n",
      "Epoch 124, Loss: 0.4311436342286367\n",
      "Epoch 125, Loss: 0.4305773797024441\n",
      "Epoch 126, Loss: 0.43002068866262627\n",
      "Epoch 127, Loss: 0.4294603440925532\n",
      "Epoch 128, Loss: 0.42889442080112905\n",
      "Epoch 129, Loss: 0.4283556671789155\n",
      "Epoch 130, Loss: 0.42785757720405737\n",
      "Epoch 131, Loss: 0.4274933366646607\n",
      "Epoch 132, Loss: 0.42700188333064754\n",
      "Epoch 133, Loss: 0.42630467919934395\n",
      "Epoch 134, Loss: 0.42569163017974504\n",
      "Epoch 135, Loss: 0.4252916548453531\n",
      "Epoch 136, Loss: 0.42479856640143693\n",
      "Epoch 137, Loss: 0.4241556405181317\n",
      "Epoch 138, Loss: 0.4237234628014227\n",
      "Epoch 139, Loss: 0.4231422781691707\n",
      "Epoch 140, Loss: 0.4224580691483148\n",
      "Epoch 141, Loss: 0.42201107091302686\n",
      "Epoch 142, Loss: 0.42153839528794385\n",
      "Epoch 143, Loss: 0.4208486753285859\n",
      "Epoch 144, Loss: 0.420286330929343\n",
      "Epoch 145, Loss: 0.41995079473226576\n",
      "Epoch 146, Loss: 0.4194809661509614\n",
      "Epoch 147, Loss: 0.4188939131926751\n",
      "Epoch 148, Loss: 0.41832842458578107\n",
      "Epoch 149, Loss: 0.41798099606836514\n",
      "Epoch 150, Loss: 0.41754849420658996\n",
      "Epoch 151, Loss: 0.4170018536700299\n",
      "Epoch 152, Loss: 0.4164655696850226\n",
      "Epoch 153, Loss: 0.41607042408394496\n",
      "Epoch 154, Loss: 0.4156899408645329\n",
      "Epoch 155, Loss: 0.41528989505029534\n",
      "Epoch 156, Loss: 0.4147513974656561\n",
      "Epoch 157, Loss: 0.4143164953297263\n",
      "Epoch 158, Loss: 0.41398873661793795\n",
      "Epoch 159, Loss: 0.41377525442674623\n",
      "Epoch 160, Loss: 0.41335210499258074\n",
      "Epoch 161, Loss: 0.4127792951757203\n",
      "Epoch 162, Loss: 0.4122712779999401\n",
      "Epoch 163, Loss: 0.4118578174694323\n",
      "Epoch 164, Loss: 0.4115005443344595\n",
      "Epoch 165, Loss: 0.41114397554805004\n",
      "Epoch 166, Loss: 0.4107667103918875\n",
      "Epoch 167, Loss: 0.4102693855835931\n",
      "Epoch 168, Loss: 0.4098305998891112\n",
      "Epoch 169, Loss: 0.40941300033782413\n",
      "Epoch 170, Loss: 0.4090141562446302\n",
      "Epoch 171, Loss: 0.40863973821910565\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22353676452688767\n",
      "Test R^2 score: 0.46097700967873156\n",
      "Num of epochs: 172\n",
      "Epoch 1, Loss: 0.5819931273808371\n",
      "Epoch 2, Loss: 0.5802324905251909\n",
      "Epoch 3, Loss: 0.5785390556788454\n",
      "Epoch 4, Loss: 0.576913569598233\n",
      "Epoch 5, Loss: 0.575356064306887\n",
      "Epoch 6, Loss: 0.5738661844967804\n",
      "Epoch 7, Loss: 0.5724438074178653\n",
      "Epoch 8, Loss: 0.5710885242061292\n",
      "Epoch 9, Loss: 0.569800421341258\n",
      "Epoch 10, Loss: 0.5685787498548053\n",
      "Epoch 11, Loss: 0.5674259346679271\n",
      "Epoch 12, Loss: 0.566332976764741\n",
      "Epoch 13, Loss: 0.5653009350438789\n",
      "Epoch 14, Loss: 0.564334262885815\n",
      "Epoch 15, Loss: 0.563420734251284\n",
      "Epoch 16, Loss: 0.5625602636904175\n",
      "Epoch 17, Loss: 0.5617549518490882\n",
      "Epoch 18, Loss: 0.5610149701954906\n",
      "Epoch 19, Loss: 0.5603377586837125\n",
      "Epoch 20, Loss: 0.5597016611442976\n",
      "Epoch 21, Loss: 0.5591073775896869\n",
      "Epoch 22, Loss: 0.5585571757260567\n",
      "Epoch 23, Loss: 0.5580450978171376\n",
      "Epoch 24, Loss: 0.5575597837065738\n",
      "Epoch 25, Loss: 0.5570989227919263\n",
      "Epoch 26, Loss: 0.5566600595394321\n",
      "Epoch 27, Loss: 0.5562398438115849\n",
      "Epoch 28, Loss: 0.5558252620349301\n",
      "Epoch 29, Loss: 0.5554037976282447\n",
      "Epoch 30, Loss: 0.5549673261131752\n",
      "Epoch 31, Loss: 0.5545125873571366\n",
      "Epoch 32, Loss: 0.5540339958832493\n",
      "Epoch 33, Loss: 0.5535318667035202\n",
      "Epoch 34, Loss: 0.5529706470190721\n",
      "Epoch 35, Loss: 0.5523377468101242\n",
      "Epoch 36, Loss: 0.5515921014725796\n",
      "Epoch 37, Loss: 0.5506941814456722\n",
      "Epoch 38, Loss: 0.5496074532785011\n",
      "Epoch 39, Loss: 0.5482730977715304\n",
      "Epoch 40, Loss: 0.546603298812875\n",
      "Epoch 41, Loss: 0.5444849374962905\n",
      "Epoch 42, Loss: 0.541793896942645\n",
      "Epoch 43, Loss: 0.5384449392946112\n",
      "Epoch 44, Loss: 0.534388666926282\n",
      "Epoch 45, Loss: 0.5297741585570056\n",
      "Epoch 46, Loss: 0.5251547698817552\n",
      "Epoch 47, Loss: 0.5215927182923806\n",
      "Epoch 48, Loss: 0.5202288139333613\n",
      "Epoch 49, Loss: 0.5202641014981655\n",
      "Epoch 50, Loss: 0.5186843278978419\n",
      "Epoch 51, Loss: 0.5150874254407382\n",
      "Epoch 52, Loss: 0.5110619676271595\n",
      "Epoch 53, Loss: 0.5079343209498682\n",
      "Epoch 54, Loss: 0.5056801850484441\n",
      "Epoch 55, Loss: 0.5034298678008445\n",
      "Epoch 56, Loss: 0.5004386765623549\n",
      "Epoch 57, Loss: 0.4965483617480346\n",
      "Epoch 58, Loss: 0.4919928362555503\n",
      "Epoch 59, Loss: 0.48735257144733707\n",
      "Epoch 60, Loss: 0.48340170502762453\n",
      "Epoch 61, Loss: 0.4807586105714229\n",
      "Epoch 62, Loss: 0.4795494123134884\n",
      "Epoch 63, Loss: 0.4791137071727205\n",
      "Epoch 64, Loss: 0.4783554743362127\n",
      "Epoch 65, Loss: 0.47687170285026254\n",
      "Epoch 66, Loss: 0.47527185365336627\n",
      "Epoch 67, Loss: 0.47423738257616505\n",
      "Epoch 68, Loss: 0.47359725976019124\n",
      "Epoch 69, Loss: 0.4730206023148969\n",
      "Epoch 70, Loss: 0.4722818042138767\n",
      "Epoch 71, Loss: 0.4713274033115855\n",
      "Epoch 72, Loss: 0.47025081065187646\n",
      "Epoch 73, Loss: 0.4692823883508208\n",
      "Epoch 74, Loss: 0.4685879109201042\n",
      "Epoch 75, Loss: 0.46817731842511545\n",
      "Epoch 76, Loss: 0.46791176552497177\n",
      "Epoch 77, Loss: 0.467514284854043\n",
      "Epoch 78, Loss: 0.4668888177065321\n",
      "Epoch 79, Loss: 0.4660245979257415\n",
      "Epoch 80, Loss: 0.4650675451279048\n",
      "Epoch 81, Loss: 0.4641757139828622\n",
      "Epoch 82, Loss: 0.463432863589121\n",
      "Epoch 83, Loss: 0.46284146591095815\n",
      "Epoch 84, Loss: 0.4622790646593897\n",
      "Epoch 85, Loss: 0.4616678077491999\n",
      "Epoch 86, Loss: 0.4610318717686022\n",
      "Epoch 87, Loss: 0.46038932855780546\n",
      "Epoch 88, Loss: 0.4597500035979295\n",
      "Epoch 89, Loss: 0.4591277203021014\n",
      "Epoch 90, Loss: 0.4585417378448796\n",
      "Epoch 91, Loss: 0.4580201755311031\n",
      "Epoch 92, Loss: 0.45752195766786713\n",
      "Epoch 93, Loss: 0.45696321616832636\n",
      "Epoch 94, Loss: 0.4563755809714413\n",
      "Epoch 95, Loss: 0.45586203318575147\n",
      "Epoch 96, Loss: 0.4553754596472281\n",
      "Epoch 97, Loss: 0.45487552438796414\n",
      "Epoch 98, Loss: 0.45435724751084483\n",
      "Epoch 99, Loss: 0.4538107976825047\n",
      "Epoch 100, Loss: 0.45321360083593437\n",
      "Epoch 101, Loss: 0.45266802534457556\n",
      "Epoch 102, Loss: 0.45216372898683427\n",
      "Epoch 103, Loss: 0.4516022186234935\n",
      "Epoch 104, Loss: 0.4510854663094893\n",
      "Epoch 105, Loss: 0.4505798286516635\n",
      "Epoch 106, Loss: 0.45004950290830903\n",
      "Epoch 107, Loss: 0.44953784390182244\n",
      "Epoch 108, Loss: 0.4490312599672206\n",
      "Epoch 109, Loss: 0.44852948591126846\n",
      "Epoch 110, Loss: 0.44802944478700135\n",
      "Epoch 111, Loss: 0.44750199048436073\n",
      "Epoch 112, Loss: 0.44700598364330435\n",
      "Epoch 113, Loss: 0.44650190023635156\n",
      "Epoch 114, Loss: 0.4459866223082351\n",
      "Epoch 115, Loss: 0.44547864257361125\n",
      "Epoch 116, Loss: 0.4449685759646841\n",
      "Epoch 117, Loss: 0.4444373046612783\n",
      "Epoch 118, Loss: 0.4439073277010217\n",
      "Epoch 119, Loss: 0.44338500163087524\n",
      "Epoch 120, Loss: 0.4428554645711987\n",
      "Epoch 121, Loss: 0.44231570915943497\n",
      "Epoch 122, Loss: 0.4417764242415563\n",
      "Epoch 123, Loss: 0.4412453619845597\n",
      "Epoch 124, Loss: 0.4407267784367103\n",
      "Epoch 125, Loss: 0.4402112228682657\n",
      "Epoch 126, Loss: 0.4396854210528561\n",
      "Epoch 127, Loss: 0.4391435846956172\n",
      "Epoch 128, Loss: 0.438582222830886\n",
      "Epoch 129, Loss: 0.4380096634458534\n",
      "Epoch 130, Loss: 0.437436201348457\n",
      "Epoch 131, Loss: 0.4368472338517817\n",
      "Epoch 132, Loss: 0.4362519890212484\n",
      "Epoch 133, Loss: 0.43564749953783627\n",
      "Epoch 134, Loss: 0.43504773606988306\n",
      "Epoch 135, Loss: 0.4344566282238452\n",
      "Epoch 136, Loss: 0.4338895287209169\n",
      "Epoch 137, Loss: 0.4333502799015499\n",
      "Epoch 138, Loss: 0.4328438744035641\n",
      "Epoch 139, Loss: 0.4323144546691816\n",
      "Epoch 140, Loss: 0.4317861285873088\n",
      "Epoch 141, Loss: 0.43127313565654\n",
      "Epoch 142, Loss: 0.43076658866653045\n",
      "Epoch 143, Loss: 0.43025735001655796\n",
      "Epoch 144, Loss: 0.4297486695185244\n",
      "Epoch 145, Loss: 0.4292236425331322\n",
      "Epoch 146, Loss: 0.4287344506838985\n",
      "Epoch 147, Loss: 0.42836751195097283\n",
      "Epoch 148, Loss: 0.4281656886347352\n",
      "Epoch 149, Loss: 0.42755185766404274\n",
      "Epoch 150, Loss: 0.4266968952059293\n",
      "Epoch 151, Loss: 0.4261671819524642\n",
      "Epoch 152, Loss: 0.4258970575591062\n",
      "Epoch 153, Loss: 0.4253134476190755\n",
      "Epoch 154, Loss: 0.42457560358445395\n",
      "Epoch 155, Loss: 0.42415075723206563\n",
      "Epoch 156, Loss: 0.4239589647418045\n",
      "Epoch 157, Loss: 0.423368354022131\n",
      "Epoch 158, Loss: 0.422764211887257\n",
      "Epoch 159, Loss: 0.4223927570267056\n",
      "Epoch 160, Loss: 0.42204360771517446\n",
      "Epoch 161, Loss: 0.421437973140998\n",
      "Epoch 162, Loss: 0.4209711671377114\n",
      "Epoch 163, Loss: 0.4205608563027509\n",
      "Epoch 164, Loss: 0.42019841159586613\n",
      "Epoch 165, Loss: 0.41967423699981615\n",
      "Epoch 166, Loss: 0.41915754797795735\n",
      "Epoch 167, Loss: 0.4186943743184547\n",
      "Epoch 168, Loss: 0.41837054397106516\n",
      "Epoch 169, Loss: 0.4180548035638466\n",
      "Epoch 170, Loss: 0.41772384242171884\n",
      "Epoch 171, Loss: 0.41729939421064266\n",
      "Epoch 172, Loss: 0.4166772980128425\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2190809092977321\n",
      "Test R^2 score: 0.48070411873704294\n",
      "Num of epochs: 173\n",
      "Epoch 1, Loss: 0.5674145635495945\n",
      "Epoch 2, Loss: 0.5661769271168278\n",
      "Epoch 3, Loss: 0.5650521238302809\n",
      "Epoch 4, Loss: 0.5640329823471317\n",
      "Epoch 5, Loss: 0.5631641070369924\n",
      "Epoch 6, Loss: 0.5623677946071285\n",
      "Epoch 7, Loss: 0.561645839453112\n",
      "Epoch 8, Loss: 0.5609921537673377\n",
      "Epoch 9, Loss: 0.5604093695334478\n",
      "Epoch 10, Loss: 0.5598521962275298\n",
      "Epoch 11, Loss: 0.5593310738477358\n",
      "Epoch 12, Loss: 0.5588505028150988\n",
      "Epoch 13, Loss: 0.5584086931907324\n",
      "Epoch 14, Loss: 0.5580010370651644\n",
      "Epoch 15, Loss: 0.557625685324779\n",
      "Epoch 16, Loss: 0.5572790132553741\n",
      "Epoch 17, Loss: 0.5569580779094181\n",
      "Epoch 18, Loss: 0.5566619333572318\n",
      "Epoch 19, Loss: 0.5563928152903239\n",
      "Epoch 20, Loss: 0.556144841573083\n",
      "Epoch 21, Loss: 0.5559042359597135\n",
      "Epoch 22, Loss: 0.5556597986040958\n",
      "Epoch 23, Loss: 0.5554157365913741\n",
      "Epoch 24, Loss: 0.5551854705636035\n",
      "Epoch 25, Loss: 0.5549476174816637\n",
      "Epoch 26, Loss: 0.5546825569899694\n",
      "Epoch 27, Loss: 0.5543719724037045\n",
      "Epoch 28, Loss: 0.5539896161142559\n",
      "Epoch 29, Loss: 0.5535010961161635\n",
      "Epoch 30, Loss: 0.5528866453675733\n",
      "Epoch 31, Loss: 0.5521352911437648\n",
      "Epoch 32, Loss: 0.5512355527044255\n",
      "Epoch 33, Loss: 0.5501674993091343\n",
      "Epoch 34, Loss: 0.548945594244081\n",
      "Epoch 35, Loss: 0.5475245024802716\n",
      "Epoch 36, Loss: 0.5458541879479821\n",
      "Epoch 37, Loss: 0.5438903561675027\n",
      "Epoch 38, Loss: 0.5416598564111081\n",
      "Epoch 39, Loss: 0.5391366050757187\n",
      "Epoch 40, Loss: 0.5363251110195038\n",
      "Epoch 41, Loss: 0.5333085846622543\n",
      "Epoch 42, Loss: 0.5301654066334469\n",
      "Epoch 43, Loss: 0.5269823036570498\n",
      "Epoch 44, Loss: 0.5238386012316242\n",
      "Epoch 45, Loss: 0.5208833638639545\n",
      "Epoch 46, Loss: 0.5180955711446404\n",
      "Epoch 47, Loss: 0.5153541431522863\n",
      "Epoch 48, Loss: 0.5123136716659158\n",
      "Epoch 49, Loss: 0.5086744475911149\n",
      "Epoch 50, Loss: 0.5048830190986491\n",
      "Epoch 51, Loss: 0.5010362258689746\n",
      "Epoch 52, Loss: 0.49746279407240146\n",
      "Epoch 53, Loss: 0.4941223653804641\n",
      "Epoch 54, Loss: 0.4908880913321754\n",
      "Epoch 55, Loss: 0.4876832428134917\n",
      "Epoch 56, Loss: 0.484318037682987\n",
      "Epoch 57, Loss: 0.48098942216733814\n",
      "Epoch 58, Loss: 0.4779482845278404\n",
      "Epoch 59, Loss: 0.47534091912155735\n",
      "Epoch 60, Loss: 0.47315679796062554\n",
      "Epoch 61, Loss: 0.4710249058158217\n",
      "Epoch 62, Loss: 0.46891594174775736\n",
      "Epoch 63, Loss: 0.46701628823434094\n",
      "Epoch 64, Loss: 0.4655657378509303\n",
      "Epoch 65, Loss: 0.46446074406540133\n",
      "Epoch 66, Loss: 0.4635017963650325\n",
      "Epoch 67, Loss: 0.46254852787806616\n",
      "Epoch 68, Loss: 0.46165418673711234\n",
      "Epoch 69, Loss: 0.46081948790121163\n",
      "Epoch 70, Loss: 0.4600889185816506\n",
      "Epoch 71, Loss: 0.45928005677609574\n",
      "Epoch 72, Loss: 0.45834985255325056\n",
      "Epoch 73, Loss: 0.4573825399033267\n",
      "Epoch 74, Loss: 0.45650102555284067\n",
      "Epoch 75, Loss: 0.45567878081304614\n",
      "Epoch 76, Loss: 0.4548877104859545\n",
      "Epoch 77, Loss: 0.4541276165450822\n",
      "Epoch 78, Loss: 0.45336352022843956\n",
      "Epoch 79, Loss: 0.4526102825786101\n",
      "Epoch 80, Loss: 0.451822892847711\n",
      "Epoch 81, Loss: 0.4509716993543025\n",
      "Epoch 82, Loss: 0.4500423676361388\n",
      "Epoch 83, Loss: 0.4490008779519297\n",
      "Epoch 84, Loss: 0.4479407167261975\n",
      "Epoch 85, Loss: 0.44691063398725395\n",
      "Epoch 86, Loss: 0.4459692311910156\n",
      "Epoch 87, Loss: 0.44510476805169225\n",
      "Epoch 88, Loss: 0.4442382202014223\n",
      "Epoch 89, Loss: 0.4433290916553067\n",
      "Epoch 90, Loss: 0.4424477502180044\n",
      "Epoch 91, Loss: 0.44156928975796794\n",
      "Epoch 92, Loss: 0.4407188329144105\n",
      "Epoch 93, Loss: 0.43990035294199714\n",
      "Epoch 94, Loss: 0.43913218328766845\n",
      "Epoch 95, Loss: 0.4383728822331198\n",
      "Epoch 96, Loss: 0.4376521867633596\n",
      "Epoch 97, Loss: 0.4369413351142472\n",
      "Epoch 98, Loss: 0.4362144315259757\n",
      "Epoch 99, Loss: 0.4354721484207353\n",
      "Epoch 100, Loss: 0.434728854973108\n",
      "Epoch 101, Loss: 0.4339772495951818\n",
      "Epoch 102, Loss: 0.4332206770675121\n",
      "Epoch 103, Loss: 0.43243314733518645\n",
      "Epoch 104, Loss: 0.4316277653086062\n",
      "Epoch 105, Loss: 0.43084152613559984\n",
      "Epoch 106, Loss: 0.4300709140876424\n",
      "Epoch 107, Loss: 0.4292853641094877\n",
      "Epoch 108, Loss: 0.42846471019791027\n",
      "Epoch 109, Loss: 0.42765251665363874\n",
      "Epoch 110, Loss: 0.42686153870968396\n",
      "Epoch 111, Loss: 0.42604067537274803\n",
      "Epoch 112, Loss: 0.42520491063959764\n",
      "Epoch 113, Loss: 0.4244039464974702\n",
      "Epoch 114, Loss: 0.42361356868274214\n",
      "Epoch 115, Loss: 0.42280067331446336\n",
      "Epoch 116, Loss: 0.42201294233263315\n",
      "Epoch 117, Loss: 0.4213085610409724\n",
      "Epoch 118, Loss: 0.4207036038735161\n",
      "Epoch 119, Loss: 0.4200162027560167\n",
      "Epoch 120, Loss: 0.41899192212883024\n",
      "Epoch 121, Loss: 0.41820396507345564\n",
      "Epoch 122, Loss: 0.4177986583257218\n",
      "Epoch 123, Loss: 0.41708431968165843\n",
      "Epoch 124, Loss: 0.41613137510898845\n",
      "Epoch 125, Loss: 0.41560592535891894\n",
      "Epoch 126, Loss: 0.4151508315439498\n",
      "Epoch 127, Loss: 0.4142271829996415\n",
      "Epoch 128, Loss: 0.4135766327662539\n",
      "Epoch 129, Loss: 0.41315751774478493\n",
      "Epoch 130, Loss: 0.41238220729351666\n",
      "Epoch 131, Loss: 0.41169010547689683\n",
      "Epoch 132, Loss: 0.4112892306379376\n",
      "Epoch 133, Loss: 0.41062460906592213\n",
      "Epoch 134, Loss: 0.40989705933416193\n",
      "Epoch 135, Loss: 0.4093762929182529\n",
      "Epoch 136, Loss: 0.4089104032615309\n",
      "Epoch 137, Loss: 0.40826244014560736\n",
      "Epoch 138, Loss: 0.40758877021352263\n",
      "Epoch 139, Loss: 0.40698778575710387\n",
      "Epoch 140, Loss: 0.40649058480755207\n",
      "Epoch 141, Loss: 0.4061208483001508\n",
      "Epoch 142, Loss: 0.4057912253474594\n",
      "Epoch 143, Loss: 0.40550998999875754\n",
      "Epoch 144, Loss: 0.4048166849445091\n",
      "Epoch 145, Loss: 0.40396045195699576\n",
      "Epoch 146, Loss: 0.4033821372614477\n",
      "Epoch 147, Loss: 0.4031620223026345\n",
      "Epoch 148, Loss: 0.4030391091509742\n",
      "Epoch 149, Loss: 0.4025114321121764\n",
      "Epoch 150, Loss: 0.40169545136127754\n",
      "Epoch 151, Loss: 0.40109241668158574\n",
      "Epoch 152, Loss: 0.40089968442792645\n",
      "Epoch 153, Loss: 0.4007568359375\n",
      "Epoch 154, Loss: 0.40004184697719297\n",
      "Epoch 155, Loss: 0.3993613621050255\n",
      "Epoch 156, Loss: 0.3988708869210363\n",
      "Epoch 157, Loss: 0.3986953947891552\n",
      "Epoch 158, Loss: 0.39863250672601075\n",
      "Epoch 159, Loss: 0.39806612321998835\n",
      "Epoch 160, Loss: 0.39740359105862005\n",
      "Epoch 161, Loss: 0.3967361402512513\n",
      "Epoch 162, Loss: 0.39645400659175\n",
      "Epoch 163, Loss: 0.39650748800925445\n",
      "Epoch 164, Loss: 0.3963357618706403\n",
      "Epoch 165, Loss: 0.396001286596077\n",
      "Epoch 166, Loss: 0.39501583441854043\n",
      "Epoch 167, Loss: 0.39465080942428327\n",
      "Epoch 168, Loss: 0.39461935589209635\n",
      "Epoch 169, Loss: 0.3945101175219548\n",
      "Epoch 170, Loss: 0.39410851747605324\n",
      "Epoch 171, Loss: 0.39320295343332773\n",
      "Epoch 172, Loss: 0.3931159325904886\n",
      "Epoch 173, Loss: 0.3928828788353262\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.23273594570835793\n",
      "Test R^2 score: 0.41211601567068507\n",
      "Num of epochs: 174\n",
      "Epoch 1, Loss: 0.5853717106790478\n",
      "Epoch 2, Loss: 0.5841100296022146\n",
      "Epoch 3, Loss: 0.5828642804254076\n",
      "Epoch 4, Loss: 0.5816341043674249\n",
      "Epoch 5, Loss: 0.5804197544865605\n",
      "Epoch 6, Loss: 0.5792180888128713\n",
      "Epoch 7, Loss: 0.5780311714531569\n",
      "Epoch 8, Loss: 0.576860333356467\n",
      "Epoch 9, Loss: 0.5757067856068525\n",
      "Epoch 10, Loss: 0.5745713325733661\n",
      "Epoch 11, Loss: 0.5734544974985986\n",
      "Epoch 12, Loss: 0.5723603987088308\n",
      "Epoch 13, Loss: 0.571328029770793\n",
      "Epoch 14, Loss: 0.5704926245527747\n",
      "Epoch 15, Loss: 0.5696585577028087\n",
      "Epoch 16, Loss: 0.56881999329197\n",
      "Epoch 17, Loss: 0.5679869070390977\n",
      "Epoch 18, Loss: 0.5671799998142166\n",
      "Epoch 19, Loss: 0.566405592293193\n",
      "Epoch 20, Loss: 0.5656510415589515\n",
      "Epoch 21, Loss: 0.5649089622578055\n",
      "Epoch 22, Loss: 0.5641838936403633\n",
      "Epoch 23, Loss: 0.5635091154060204\n",
      "Epoch 24, Loss: 0.5628431386196134\n",
      "Epoch 25, Loss: 0.5621932570887346\n",
      "Epoch 26, Loss: 0.5615619679375762\n",
      "Epoch 27, Loss: 0.5609644753178121\n",
      "Epoch 28, Loss: 0.5604030943105087\n",
      "Epoch 29, Loss: 0.5598665155822709\n",
      "Epoch 30, Loss: 0.5593572080968687\n",
      "Epoch 31, Loss: 0.5588768461756203\n",
      "Epoch 32, Loss: 0.5584284397750068\n",
      "Epoch 33, Loss: 0.5580154039229056\n",
      "Epoch 34, Loss: 0.557632659857789\n",
      "Epoch 35, Loss: 0.5572877836240685\n",
      "Epoch 36, Loss: 0.5569761636896928\n",
      "Epoch 37, Loss: 0.5567028345514504\n",
      "Epoch 38, Loss: 0.5564646124714616\n",
      "Epoch 39, Loss: 0.5562630158948209\n",
      "Epoch 40, Loss: 0.556087955702981\n",
      "Epoch 41, Loss: 0.5559329168549995\n",
      "Epoch 42, Loss: 0.5557883179016526\n",
      "Epoch 43, Loss: 0.5556404095326922\n",
      "Epoch 44, Loss: 0.5554699013828196\n",
      "Epoch 45, Loss: 0.5552507146962121\n",
      "Epoch 46, Loss: 0.5549522359158718\n",
      "Epoch 47, Loss: 0.5545400504120386\n",
      "Epoch 48, Loss: 0.5539907189273467\n",
      "Epoch 49, Loss: 0.5532865428482869\n",
      "Epoch 50, Loss: 0.5524489673503692\n",
      "Epoch 51, Loss: 0.5515519830063083\n",
      "Epoch 52, Loss: 0.5506298587597692\n",
      "Epoch 53, Loss: 0.5496331823163751\n",
      "Epoch 54, Loss: 0.5485391093405882\n",
      "Epoch 55, Loss: 0.5473069528662563\n",
      "Epoch 56, Loss: 0.5458392826027889\n",
      "Epoch 57, Loss: 0.5440677525564217\n",
      "Epoch 58, Loss: 0.5418534934803979\n",
      "Epoch 59, Loss: 0.5390889534471793\n",
      "Epoch 60, Loss: 0.5357940659835535\n",
      "Epoch 61, Loss: 0.5320712361594845\n",
      "Epoch 62, Loss: 0.5278666693996418\n",
      "Epoch 63, Loss: 0.5232795647872803\n",
      "Epoch 64, Loss: 0.5184618333345166\n",
      "Epoch 65, Loss: 0.513495817581572\n",
      "Epoch 66, Loss: 0.5089137534085276\n",
      "Epoch 67, Loss: 0.5056219243261394\n",
      "Epoch 68, Loss: 0.5041017079343886\n",
      "Epoch 69, Loss: 0.5024645089194038\n",
      "Epoch 70, Loss: 0.4988152653911808\n",
      "Epoch 71, Loss: 0.49392832843365525\n",
      "Epoch 72, Loss: 0.4890991380026831\n",
      "Epoch 73, Loss: 0.4849537345360532\n",
      "Epoch 74, Loss: 0.481574762672184\n",
      "Epoch 75, Loss: 0.47872319293355675\n",
      "Epoch 76, Loss: 0.47637790481754777\n",
      "Epoch 77, Loss: 0.4747986435750709\n",
      "Epoch 78, Loss: 0.4739324506741944\n",
      "Epoch 79, Loss: 0.4731502473562659\n",
      "Epoch 80, Loss: 0.4718453568501243\n",
      "Epoch 81, Loss: 0.470337690268103\n",
      "Epoch 82, Loss: 0.4690516931507524\n",
      "Epoch 83, Loss: 0.4680499889949589\n",
      "Epoch 84, Loss: 0.467170661444204\n",
      "Epoch 85, Loss: 0.4662878541178967\n",
      "Epoch 86, Loss: 0.46534509630465126\n",
      "Epoch 87, Loss: 0.46414609856067657\n",
      "Epoch 88, Loss: 0.46292312121705587\n",
      "Epoch 89, Loss: 0.46191151398485975\n",
      "Epoch 90, Loss: 0.46113971541851456\n",
      "Epoch 91, Loss: 0.4604552057226925\n",
      "Epoch 92, Loss: 0.4596863269077791\n",
      "Epoch 93, Loss: 0.45880792350861366\n",
      "Epoch 94, Loss: 0.45788020977521166\n",
      "Epoch 95, Loss: 0.45696540097309396\n",
      "Epoch 96, Loss: 0.45618637764872755\n",
      "Epoch 97, Loss: 0.4555624647879721\n",
      "Epoch 98, Loss: 0.45499070600826746\n",
      "Epoch 99, Loss: 0.4544126040129406\n",
      "Epoch 100, Loss: 0.4537854478719518\n",
      "Epoch 101, Loss: 0.4530543403780059\n",
      "Epoch 102, Loss: 0.4522903252711612\n",
      "Epoch 103, Loss: 0.4515928970982461\n",
      "Epoch 104, Loss: 0.45097862167185665\n",
      "Epoch 105, Loss: 0.45042147303312635\n",
      "Epoch 106, Loss: 0.44985565148602913\n",
      "Epoch 107, Loss: 0.44925608272499756\n",
      "Epoch 108, Loss: 0.4486328450503107\n",
      "Epoch 109, Loss: 0.44800932243771907\n",
      "Epoch 110, Loss: 0.4474371035824951\n",
      "Epoch 111, Loss: 0.4469186528099085\n",
      "Epoch 112, Loss: 0.446409680784272\n",
      "Epoch 113, Loss: 0.445869666101599\n",
      "Epoch 114, Loss: 0.44528392231578595\n",
      "Epoch 115, Loss: 0.4446713198400945\n",
      "Epoch 116, Loss: 0.44407944874428446\n",
      "Epoch 117, Loss: 0.4435136333432281\n",
      "Epoch 118, Loss: 0.4429553203128041\n",
      "Epoch 119, Loss: 0.44237326302231833\n",
      "Epoch 120, Loss: 0.44176203812138176\n",
      "Epoch 121, Loss: 0.4411529894732153\n",
      "Epoch 122, Loss: 0.4405346764318081\n",
      "Epoch 123, Loss: 0.43991269982236697\n",
      "Epoch 124, Loss: 0.4392864335006604\n",
      "Epoch 125, Loss: 0.4386711113805061\n",
      "Epoch 126, Loss: 0.43806529989285253\n",
      "Epoch 127, Loss: 0.43743046139797526\n",
      "Epoch 128, Loss: 0.4367588952844925\n",
      "Epoch 129, Loss: 0.4360842960088742\n",
      "Epoch 130, Loss: 0.43541445237224874\n",
      "Epoch 131, Loss: 0.4347811241163429\n",
      "Epoch 132, Loss: 0.43415138540203957\n",
      "Epoch 133, Loss: 0.43351172625049517\n",
      "Epoch 134, Loss: 0.43283309887505256\n",
      "Epoch 135, Loss: 0.432184248144531\n",
      "Epoch 136, Loss: 0.4315269631263965\n",
      "Epoch 137, Loss: 0.4308664793395461\n",
      "Epoch 138, Loss: 0.43018120232932255\n",
      "Epoch 139, Loss: 0.42953247394852256\n",
      "Epoch 140, Loss: 0.4289518300836139\n",
      "Epoch 141, Loss: 0.4283909744164988\n",
      "Epoch 142, Loss: 0.42778364968948734\n",
      "Epoch 143, Loss: 0.4269331478041701\n",
      "Epoch 144, Loss: 0.4261576887054562\n",
      "Epoch 145, Loss: 0.42562810961109737\n",
      "Epoch 146, Loss: 0.4251755422009447\n",
      "Epoch 147, Loss: 0.4245027192335349\n",
      "Epoch 148, Loss: 0.4237098880507593\n",
      "Epoch 149, Loss: 0.42317258001034336\n",
      "Epoch 150, Loss: 0.422716731540635\n",
      "Epoch 151, Loss: 0.42210321964490116\n",
      "Epoch 152, Loss: 0.42139868868450436\n",
      "Epoch 153, Loss: 0.4208771950302235\n",
      "Epoch 154, Loss: 0.4204496748335188\n",
      "Epoch 155, Loss: 0.41982603531928275\n",
      "Epoch 156, Loss: 0.4190994192668247\n",
      "Epoch 157, Loss: 0.41845060363604747\n",
      "Epoch 158, Loss: 0.41792084963116477\n",
      "Epoch 159, Loss: 0.41748400234935484\n",
      "Epoch 160, Loss: 0.4168597151657919\n",
      "Epoch 161, Loss: 0.4161256814723624\n",
      "Epoch 162, Loss: 0.41532396299273705\n",
      "Epoch 163, Loss: 0.4146477683552011\n",
      "Epoch 164, Loss: 0.41412466410270077\n",
      "Epoch 165, Loss: 0.41368092643193644\n",
      "Epoch 166, Loss: 0.4132300952772408\n",
      "Epoch 167, Loss: 0.41268221197534544\n",
      "Epoch 168, Loss: 0.41202567818975105\n",
      "Epoch 169, Loss: 0.4113246080731838\n",
      "Epoch 170, Loss: 0.4107229767940119\n",
      "Epoch 171, Loss: 0.4102589796479474\n",
      "Epoch 172, Loss: 0.4099045844236531\n",
      "Epoch 173, Loss: 0.4096079840410019\n",
      "Epoch 174, Loss: 0.40921105967866345\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22542961329912234\n",
      "Test R^2 score: 0.45189415081682405\n",
      "Num of epochs: 175\n",
      "Epoch 1, Loss: 0.5804380847742712\n",
      "Epoch 2, Loss: 0.5790223554765671\n",
      "Epoch 3, Loss: 0.5776308886507083\n",
      "Epoch 4, Loss: 0.5762688506677847\n",
      "Epoch 5, Loss: 0.5749823754138822\n",
      "Epoch 6, Loss: 0.5737133267053492\n",
      "Epoch 7, Loss: 0.5724704102611263\n",
      "Epoch 8, Loss: 0.5712625611508101\n",
      "Epoch 9, Loss: 0.5700829710302868\n",
      "Epoch 10, Loss: 0.5689269440367416\n",
      "Epoch 11, Loss: 0.5677982982314387\n",
      "Epoch 12, Loss: 0.5667349815095115\n",
      "Epoch 13, Loss: 0.5656371584265203\n",
      "Epoch 14, Loss: 0.5645431657933077\n",
      "Epoch 15, Loss: 0.563428536257581\n",
      "Epoch 16, Loss: 0.5623414557925034\n",
      "Epoch 17, Loss: 0.5612611373611941\n",
      "Epoch 18, Loss: 0.5601998028922015\n",
      "Epoch 19, Loss: 0.5591513245131715\n",
      "Epoch 20, Loss: 0.5581110756259534\n",
      "Epoch 21, Loss: 0.5570994309995748\n",
      "Epoch 22, Loss: 0.556109928325577\n",
      "Epoch 23, Loss: 0.5551156017261222\n",
      "Epoch 24, Loss: 0.5541037859651894\n",
      "Epoch 25, Loss: 0.5530613717158075\n",
      "Epoch 26, Loss: 0.5519680196665142\n",
      "Epoch 27, Loss: 0.5507894204257409\n",
      "Epoch 28, Loss: 0.5494913729597017\n",
      "Epoch 29, Loss: 0.5480211508838879\n",
      "Epoch 30, Loss: 0.5463204705896639\n",
      "Epoch 31, Loss: 0.5443226791097585\n",
      "Epoch 32, Loss: 0.5419754163192079\n",
      "Epoch 33, Loss: 0.5392872438616612\n",
      "Epoch 34, Loss: 0.5363710079289031\n",
      "Epoch 35, Loss: 0.5333792147669919\n",
      "Epoch 36, Loss: 0.5306115802285577\n",
      "Epoch 37, Loss: 0.5284216707770027\n",
      "Epoch 38, Loss: 0.5269459672332856\n",
      "Epoch 39, Loss: 0.5254507491300707\n",
      "Epoch 40, Loss: 0.5229688510718019\n",
      "Epoch 41, Loss: 0.5195784583190615\n",
      "Epoch 42, Loss: 0.516161812600056\n",
      "Epoch 43, Loss: 0.5134044284582752\n",
      "Epoch 44, Loss: 0.5113539815241726\n",
      "Epoch 45, Loss: 0.5096240376829934\n",
      "Epoch 46, Loss: 0.5077649020849483\n",
      "Epoch 47, Loss: 0.5055789243737366\n",
      "Epoch 48, Loss: 0.5032183957340595\n",
      "Epoch 49, Loss: 0.5009583289563042\n",
      "Epoch 50, Loss: 0.4990414132839015\n",
      "Epoch 51, Loss: 0.49760863526991506\n",
      "Epoch 52, Loss: 0.4963772031542556\n",
      "Epoch 53, Loss: 0.49488420290386176\n",
      "Epoch 54, Loss: 0.4930636917556323\n",
      "Epoch 55, Loss: 0.4913361315894488\n",
      "Epoch 56, Loss: 0.4900491220073465\n",
      "Epoch 57, Loss: 0.48900305231288493\n",
      "Epoch 58, Loss: 0.4877805660530656\n",
      "Epoch 59, Loss: 0.48629389876072737\n",
      "Epoch 60, Loss: 0.48483074958821376\n",
      "Epoch 61, Loss: 0.48369714004565434\n",
      "Epoch 62, Loss: 0.48274309838496376\n",
      "Epoch 63, Loss: 0.481560760955344\n",
      "Epoch 64, Loss: 0.48026902614458633\n",
      "Epoch 65, Loss: 0.47923086779795704\n",
      "Epoch 66, Loss: 0.47832670569674246\n",
      "Epoch 67, Loss: 0.4771608130106738\n",
      "Epoch 68, Loss: 0.4758469102523699\n",
      "Epoch 69, Loss: 0.47463610852462934\n",
      "Epoch 70, Loss: 0.47336422885157087\n",
      "Epoch 71, Loss: 0.47185983633472756\n",
      "Epoch 72, Loss: 0.47037632467938456\n",
      "Epoch 73, Loss: 0.46903339402423394\n",
      "Epoch 74, Loss: 0.46754559919256344\n",
      "Epoch 75, Loss: 0.46598042229633474\n",
      "Epoch 76, Loss: 0.4646797852687072\n",
      "Epoch 77, Loss: 0.46383633159607796\n",
      "Epoch 78, Loss: 0.4632619342347504\n",
      "Epoch 79, Loss: 0.4625210634796329\n",
      "Epoch 80, Loss: 0.4614105383560348\n",
      "Epoch 81, Loss: 0.4603238951599191\n",
      "Epoch 82, Loss: 0.4595618004421978\n",
      "Epoch 83, Loss: 0.45898857926411396\n",
      "Epoch 84, Loss: 0.45844591087525494\n",
      "Epoch 85, Loss: 0.4578293735402112\n",
      "Epoch 86, Loss: 0.4570761927490579\n",
      "Epoch 87, Loss: 0.4562653375686561\n",
      "Epoch 88, Loss: 0.455458813357703\n",
      "Epoch 89, Loss: 0.4546441558943058\n",
      "Epoch 90, Loss: 0.45387267219978206\n",
      "Epoch 91, Loss: 0.4531473121411403\n",
      "Epoch 92, Loss: 0.45244638006752197\n",
      "Epoch 93, Loss: 0.45171310526838454\n",
      "Epoch 94, Loss: 0.4509580196171689\n",
      "Epoch 95, Loss: 0.45017508835784525\n",
      "Epoch 96, Loss: 0.4493556270216904\n",
      "Epoch 97, Loss: 0.44850491738042414\n",
      "Epoch 98, Loss: 0.4476999730832073\n",
      "Epoch 99, Loss: 0.44696796290588314\n",
      "Epoch 100, Loss: 0.4462568743093457\n",
      "Epoch 101, Loss: 0.44554082136942963\n",
      "Epoch 102, Loss: 0.44483441907491256\n",
      "Epoch 103, Loss: 0.444165727481362\n",
      "Epoch 104, Loss: 0.44352475413444703\n",
      "Epoch 105, Loss: 0.4428298577707189\n",
      "Epoch 106, Loss: 0.44212131476706623\n",
      "Epoch 107, Loss: 0.4414257112787145\n",
      "Epoch 108, Loss: 0.44073643120831624\n",
      "Epoch 109, Loss: 0.4400674891189724\n",
      "Epoch 110, Loss: 0.43941709582665156\n",
      "Epoch 111, Loss: 0.43877961151206174\n",
      "Epoch 112, Loss: 0.4381781159227088\n",
      "Epoch 113, Loss: 0.43758561795205597\n",
      "Epoch 114, Loss: 0.4370018302608545\n",
      "Epoch 115, Loss: 0.43638793070988985\n",
      "Epoch 116, Loss: 0.43575405102989906\n",
      "Epoch 117, Loss: 0.435092877579532\n",
      "Epoch 118, Loss: 0.4344940290040776\n",
      "Epoch 119, Loss: 0.4339467579138234\n",
      "Epoch 120, Loss: 0.433444298083757\n",
      "Epoch 121, Loss: 0.43311873182354704\n",
      "Epoch 122, Loss: 0.43279431508005195\n",
      "Epoch 123, Loss: 0.43229187731756874\n",
      "Epoch 124, Loss: 0.43099075693698685\n",
      "Epoch 125, Loss: 0.43067181292629164\n",
      "Epoch 126, Loss: 0.43055069657458667\n",
      "Epoch 127, Loss: 0.4293081516384972\n",
      "Epoch 128, Loss: 0.42911180597718274\n",
      "Epoch 129, Loss: 0.4289691295287234\n",
      "Epoch 130, Loss: 0.4277106674800803\n",
      "Epoch 131, Loss: 0.4276707745651109\n",
      "Epoch 132, Loss: 0.4274305719192602\n",
      "Epoch 133, Loss: 0.4262094531812633\n",
      "Epoch 134, Loss: 0.42642789260885994\n",
      "Epoch 135, Loss: 0.42607103338281493\n",
      "Epoch 136, Loss: 0.4247682577714265\n",
      "Epoch 137, Loss: 0.4252780425543403\n",
      "Epoch 138, Loss: 0.42449938447074165\n",
      "Epoch 139, Loss: 0.42344908751226024\n",
      "Epoch 140, Loss: 0.42394286681260374\n",
      "Epoch 141, Loss: 0.4226013571019189\n",
      "Epoch 142, Loss: 0.4223737770496376\n",
      "Epoch 143, Loss: 0.42203716410928116\n",
      "Epoch 144, Loss: 0.42102457798300796\n",
      "Epoch 145, Loss: 0.42108015841770535\n",
      "Epoch 146, Loss: 0.42023101782605765\n",
      "Epoch 147, Loss: 0.41985297414047207\n",
      "Epoch 148, Loss: 0.4196799535065766\n",
      "Epoch 149, Loss: 0.4188034777868528\n",
      "Epoch 150, Loss: 0.4186300233942201\n",
      "Epoch 151, Loss: 0.41840352414048326\n",
      "Epoch 152, Loss: 0.41751234144826416\n",
      "Epoch 153, Loss: 0.41727573661787176\n",
      "Epoch 154, Loss: 0.41717864609370475\n",
      "Epoch 155, Loss: 0.41634146596157084\n",
      "Epoch 156, Loss: 0.4158856005141732\n",
      "Epoch 157, Loss: 0.41580332680587384\n",
      "Epoch 158, Loss: 0.41525230763739795\n",
      "Epoch 159, Loss: 0.4146122611638849\n",
      "Epoch 160, Loss: 0.414231607704521\n",
      "Epoch 161, Loss: 0.4139890605649114\n",
      "Epoch 162, Loss: 0.4136702821176784\n",
      "Epoch 163, Loss: 0.4131232711478805\n",
      "Epoch 164, Loss: 0.4125881938865042\n",
      "Epoch 165, Loss: 0.41215390150150355\n",
      "Epoch 166, Loss: 0.4118219249953499\n",
      "Epoch 167, Loss: 0.4115743191932915\n",
      "Epoch 168, Loss: 0.41143765779851776\n",
      "Epoch 169, Loss: 0.4115385287233033\n",
      "Epoch 170, Loss: 0.41142737195667006\n",
      "Epoch 171, Loss: 0.41113114526551053\n",
      "Epoch 172, Loss: 0.4098830084953396\n",
      "Epoch 173, Loss: 0.4093190686404651\n",
      "Epoch 174, Loss: 0.409495411701604\n",
      "Epoch 175, Loss: 0.40926041637486904\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22017040969994303\n",
      "Test R^2 score: 0.47348877588276084\n",
      "Num of epochs: 176\n",
      "Epoch 1, Loss: 0.5659704175841015\n",
      "Epoch 2, Loss: 0.5647568990751224\n",
      "Epoch 3, Loss: 0.5636274112709905\n",
      "Epoch 4, Loss: 0.5625706999110892\n",
      "Epoch 5, Loss: 0.5615540869267841\n",
      "Epoch 6, Loss: 0.5605793853795783\n",
      "Epoch 7, Loss: 0.5597516044143915\n",
      "Epoch 8, Loss: 0.5590657993942143\n",
      "Epoch 9, Loss: 0.5584623542382271\n",
      "Epoch 10, Loss: 0.5579315742322427\n",
      "Epoch 11, Loss: 0.5574658617763522\n",
      "Epoch 12, Loss: 0.5570695262026282\n",
      "Epoch 13, Loss: 0.5567461683366715\n",
      "Epoch 14, Loss: 0.5564970132382591\n",
      "Epoch 15, Loss: 0.5563214374060461\n",
      "Epoch 16, Loss: 0.5562159742171101\n",
      "Epoch 17, Loss: 0.556174662127975\n",
      "Epoch 18, Loss: 0.5561876294176299\n",
      "Epoch 19, Loss: 0.556240674272864\n",
      "Epoch 20, Loss: 0.5563173660461503\n",
      "Epoch 21, Loss: 0.556400715844073\n",
      "Epoch 22, Loss: 0.5564752701219743\n",
      "Epoch 23, Loss: 0.5565300011718008\n",
      "Epoch 24, Loss: 0.5565579804756912\n",
      "Epoch 25, Loss: 0.5565561598556407\n",
      "Epoch 26, Loss: 0.5565260652142842\n",
      "Epoch 27, Loss: 0.556472619117426\n",
      "Epoch 28, Loss: 0.556402162034985\n",
      "Epoch 29, Loss: 0.5563212499098633\n",
      "Epoch 30, Loss: 0.5562355843294069\n",
      "Epoch 31, Loss: 0.5561485926741916\n",
      "Epoch 32, Loss: 0.5560620429701811\n",
      "Epoch 33, Loss: 0.5559764714597082\n",
      "Epoch 34, Loss: 0.555890404270123\n",
      "Epoch 35, Loss: 0.5558006239488441\n",
      "Epoch 36, Loss: 0.5557029187606843\n",
      "Epoch 37, Loss: 0.5555908476692948\n",
      "Epoch 38, Loss: 0.5554571587792394\n",
      "Epoch 39, Loss: 0.555294537487191\n",
      "Epoch 40, Loss: 0.5550952540955334\n",
      "Epoch 41, Loss: 0.5548474793025477\n",
      "Epoch 42, Loss: 0.554538438137198\n",
      "Epoch 43, Loss: 0.5541464087242115\n",
      "Epoch 44, Loss: 0.5536547704664937\n",
      "Epoch 45, Loss: 0.5530432656886132\n",
      "Epoch 46, Loss: 0.5522876457414296\n",
      "Epoch 47, Loss: 0.5513655356782067\n",
      "Epoch 48, Loss: 0.5502292762053221\n",
      "Epoch 49, Loss: 0.5488538362718409\n",
      "Epoch 50, Loss: 0.5471982273202759\n",
      "Epoch 51, Loss: 0.545240466325292\n",
      "Epoch 52, Loss: 0.5430489624931639\n",
      "Epoch 53, Loss: 0.5406751146407157\n",
      "Epoch 54, Loss: 0.5382657174802397\n",
      "Epoch 55, Loss: 0.5361746405177642\n",
      "Epoch 56, Loss: 0.5341443986412076\n",
      "Epoch 57, Loss: 0.5315825038870949\n",
      "Epoch 58, Loss: 0.5283343300925318\n",
      "Epoch 59, Loss: 0.5247787826953486\n",
      "Epoch 60, Loss: 0.5212275983721598\n",
      "Epoch 61, Loss: 0.5177780628897101\n",
      "Epoch 62, Loss: 0.5141440132700705\n",
      "Epoch 63, Loss: 0.5101730063521294\n",
      "Epoch 64, Loss: 0.5059338371233799\n",
      "Epoch 65, Loss: 0.5016537972422791\n",
      "Epoch 66, Loss: 0.49720022006639936\n",
      "Epoch 67, Loss: 0.49223999470103025\n",
      "Epoch 68, Loss: 0.48683016498372234\n",
      "Epoch 69, Loss: 0.48185746384908423\n",
      "Epoch 70, Loss: 0.47839249564304503\n",
      "Epoch 71, Loss: 0.4771713526154028\n",
      "Epoch 72, Loss: 0.47727843741514414\n",
      "Epoch 73, Loss: 0.4762865268036271\n",
      "Epoch 74, Loss: 0.4739046083818699\n",
      "Epoch 75, Loss: 0.47137915473023484\n",
      "Epoch 76, Loss: 0.4696577025636053\n",
      "Epoch 77, Loss: 0.46892666666440713\n",
      "Epoch 78, Loss: 0.4684979714926791\n",
      "Epoch 79, Loss: 0.46766779270068276\n",
      "Epoch 80, Loss: 0.4664347213412912\n",
      "Epoch 81, Loss: 0.4650466380008975\n",
      "Epoch 82, Loss: 0.46380854185713466\n",
      "Epoch 83, Loss: 0.4628110406763739\n",
      "Epoch 84, Loss: 0.46204369562729675\n",
      "Epoch 85, Loss: 0.4613828931788022\n",
      "Epoch 86, Loss: 0.46064200870679656\n",
      "Epoch 87, Loss: 0.45971814204508954\n",
      "Epoch 88, Loss: 0.4587780103005884\n",
      "Epoch 89, Loss: 0.4579215222634365\n",
      "Epoch 90, Loss: 0.4572810932869018\n",
      "Epoch 91, Loss: 0.45681283084253543\n",
      "Epoch 92, Loss: 0.4563547654254291\n",
      "Epoch 93, Loss: 0.4557999056456126\n",
      "Epoch 94, Loss: 0.4552308182506231\n",
      "Epoch 95, Loss: 0.45472582494975583\n",
      "Epoch 96, Loss: 0.4542341469437432\n",
      "Epoch 97, Loss: 0.45365470311121264\n",
      "Epoch 98, Loss: 0.4529932915893992\n",
      "Epoch 99, Loss: 0.45231281036349436\n",
      "Epoch 100, Loss: 0.45166068412131316\n",
      "Epoch 101, Loss: 0.45104512998148427\n",
      "Epoch 102, Loss: 0.450414128612504\n",
      "Epoch 103, Loss: 0.4497226708226476\n",
      "Epoch 104, Loss: 0.44902259856448923\n",
      "Epoch 105, Loss: 0.44834114262304026\n",
      "Epoch 106, Loss: 0.4476362966248122\n",
      "Epoch 107, Loss: 0.44685546525526443\n",
      "Epoch 108, Loss: 0.44604001097332496\n",
      "Epoch 109, Loss: 0.4452504399204812\n",
      "Epoch 110, Loss: 0.44445882921318464\n",
      "Epoch 111, Loss: 0.4436221583327244\n",
      "Epoch 112, Loss: 0.4427905698203695\n",
      "Epoch 113, Loss: 0.44199116530154803\n",
      "Epoch 114, Loss: 0.44119230503762646\n",
      "Epoch 115, Loss: 0.4403914712028501\n",
      "Epoch 116, Loss: 0.4396173297548112\n",
      "Epoch 117, Loss: 0.4388580871371904\n",
      "Epoch 118, Loss: 0.43808368507108936\n",
      "Epoch 119, Loss: 0.4372956956941618\n",
      "Epoch 120, Loss: 0.43648534006886386\n",
      "Epoch 121, Loss: 0.43567953099553014\n",
      "Epoch 122, Loss: 0.43484793378302444\n",
      "Epoch 123, Loss: 0.43402035664465843\n",
      "Epoch 124, Loss: 0.43320464812441817\n",
      "Epoch 125, Loss: 0.43238760752960964\n",
      "Epoch 126, Loss: 0.43157970637245857\n",
      "Epoch 127, Loss: 0.43080304729562496\n",
      "Epoch 128, Loss: 0.43003503443248414\n",
      "Epoch 129, Loss: 0.4293069888616571\n",
      "Epoch 130, Loss: 0.4285587396900401\n",
      "Epoch 131, Loss: 0.4277893623297915\n",
      "Epoch 132, Loss: 0.4269889537300412\n",
      "Epoch 133, Loss: 0.4262047157955763\n",
      "Epoch 134, Loss: 0.42545244662695086\n",
      "Epoch 135, Loss: 0.42472807094643267\n",
      "Epoch 136, Loss: 0.42412507514042275\n",
      "Epoch 137, Loss: 0.4237665228309008\n",
      "Epoch 138, Loss: 0.4233836115087162\n",
      "Epoch 139, Loss: 0.4220751534837054\n",
      "Epoch 140, Loss: 0.42142135460091523\n",
      "Epoch 141, Loss: 0.4212513835612592\n",
      "Epoch 142, Loss: 0.4200347393859595\n",
      "Epoch 143, Loss: 0.4194185123241301\n",
      "Epoch 144, Loss: 0.4189530307441167\n",
      "Epoch 145, Loss: 0.41787595699268043\n",
      "Epoch 146, Loss: 0.41737869539135847\n",
      "Epoch 147, Loss: 0.4168369978207642\n",
      "Epoch 148, Loss: 0.4157957651213015\n",
      "Epoch 149, Loss: 0.4154027265615798\n",
      "Epoch 150, Loss: 0.41486069380646223\n",
      "Epoch 151, Loss: 0.41384930790314106\n",
      "Epoch 152, Loss: 0.4132488281281847\n",
      "Epoch 153, Loss: 0.4129779214522553\n",
      "Epoch 154, Loss: 0.41220760530686235\n",
      "Epoch 155, Loss: 0.4112294461815775\n",
      "Epoch 156, Loss: 0.41072000179696466\n",
      "Epoch 157, Loss: 0.4103854311112041\n",
      "Epoch 158, Loss: 0.4098535237981176\n",
      "Epoch 159, Loss: 0.40896349455572034\n",
      "Epoch 160, Loss: 0.40825906397632467\n",
      "Epoch 161, Loss: 0.4079600253682578\n",
      "Epoch 162, Loss: 0.40772067311396876\n",
      "Epoch 163, Loss: 0.4072433395040135\n",
      "Epoch 164, Loss: 0.40625535521278805\n",
      "Epoch 165, Loss: 0.4055357670020579\n",
      "Epoch 166, Loss: 0.4052280814287198\n",
      "Epoch 167, Loss: 0.40505828661699833\n",
      "Epoch 168, Loss: 0.40477621070907405\n",
      "Epoch 169, Loss: 0.40402898344091187\n",
      "Epoch 170, Loss: 0.40327453353473647\n",
      "Epoch 171, Loss: 0.4026654633136688\n",
      "Epoch 172, Loss: 0.4023398612121496\n",
      "Epoch 173, Loss: 0.4021209544368745\n",
      "Epoch 174, Loss: 0.4018741756270572\n",
      "Epoch 175, Loss: 0.40181855302156627\n",
      "Epoch 176, Loss: 0.4013210186543574\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22676641653918206\n",
      "Test R^2 score: 0.44423141119274745\n",
      "Num of epochs: 177\n",
      "Epoch 1, Loss: 0.5735896030942212\n",
      "Epoch 2, Loss: 0.5719370240309657\n",
      "Epoch 3, Loss: 0.5703622456632944\n",
      "Epoch 4, Loss: 0.5688925271080367\n",
      "Epoch 5, Loss: 0.5674969661732382\n",
      "Epoch 6, Loss: 0.5661780325100878\n",
      "Epoch 7, Loss: 0.5649371332453733\n",
      "Epoch 8, Loss: 0.5637814706700759\n",
      "Epoch 9, Loss: 0.562730450577446\n",
      "Epoch 10, Loss: 0.5617587450668418\n",
      "Epoch 11, Loss: 0.5608787218926394\n",
      "Epoch 12, Loss: 0.5600853857867316\n",
      "Epoch 13, Loss: 0.5593685565342951\n",
      "Epoch 14, Loss: 0.5587278618576559\n",
      "Epoch 15, Loss: 0.5581612146125908\n",
      "Epoch 16, Loss: 0.557667771698966\n",
      "Epoch 17, Loss: 0.5572440106227055\n",
      "Epoch 18, Loss: 0.5568832671710988\n",
      "Epoch 19, Loss: 0.5565791045876082\n",
      "Epoch 20, Loss: 0.5563254015962624\n",
      "Epoch 21, Loss: 0.5561143495410565\n",
      "Epoch 22, Loss: 0.5559381435877316\n",
      "Epoch 23, Loss: 0.5557866824369605\n",
      "Epoch 24, Loss: 0.5556437617718356\n",
      "Epoch 25, Loss: 0.5554948760379184\n",
      "Epoch 26, Loss: 0.5553212642031742\n",
      "Epoch 27, Loss: 0.5550974821706031\n",
      "Epoch 28, Loss: 0.5547854914544181\n",
      "Epoch 29, Loss: 0.5543501728179736\n",
      "Epoch 30, Loss: 0.5537557970608968\n",
      "Epoch 31, Loss: 0.5529770065859653\n",
      "Epoch 32, Loss: 0.5519980658656249\n",
      "Epoch 33, Loss: 0.5507493517140691\n",
      "Epoch 34, Loss: 0.54922471022865\n",
      "Epoch 35, Loss: 0.5472958988635462\n",
      "Epoch 36, Loss: 0.5449318833611312\n",
      "Epoch 37, Loss: 0.542080378874992\n",
      "Epoch 38, Loss: 0.5387390935727642\n",
      "Epoch 39, Loss: 0.5349449520222684\n",
      "Epoch 40, Loss: 0.5307968956205432\n",
      "Epoch 41, Loss: 0.5264957815854439\n",
      "Epoch 42, Loss: 0.5224394606694837\n",
      "Epoch 43, Loss: 0.5194758335473456\n",
      "Epoch 44, Loss: 0.5183659729181932\n",
      "Epoch 45, Loss: 0.517700065787276\n",
      "Epoch 46, Loss: 0.515091012671687\n",
      "Epoch 47, Loss: 0.5111380915356418\n",
      "Epoch 48, Loss: 0.5075683006591176\n",
      "Epoch 49, Loss: 0.5051758909787631\n",
      "Epoch 50, Loss: 0.5037009833936121\n",
      "Epoch 51, Loss: 0.5024187177423338\n",
      "Epoch 52, Loss: 0.5008596837934305\n",
      "Epoch 53, Loss: 0.49877414336602044\n",
      "Epoch 54, Loss: 0.4962640304888122\n",
      "Epoch 55, Loss: 0.4937105078536503\n",
      "Epoch 56, Loss: 0.4915796492508014\n",
      "Epoch 57, Loss: 0.49013949992167394\n",
      "Epoch 58, Loss: 0.48903909998966616\n",
      "Epoch 59, Loss: 0.48759294443052337\n",
      "Epoch 60, Loss: 0.48563359929231825\n",
      "Epoch 61, Loss: 0.48368697369472063\n",
      "Epoch 62, Loss: 0.4822196536614066\n",
      "Epoch 63, Loss: 0.48112184440646344\n",
      "Epoch 64, Loss: 0.48010078544306134\n",
      "Epoch 65, Loss: 0.47875526811275915\n",
      "Epoch 66, Loss: 0.4771616874163663\n",
      "Epoch 67, Loss: 0.4756392619417133\n",
      "Epoch 68, Loss: 0.4744190572300611\n",
      "Epoch 69, Loss: 0.47337143754991085\n",
      "Epoch 70, Loss: 0.47221225976563985\n",
      "Epoch 71, Loss: 0.4709484837952833\n",
      "Epoch 72, Loss: 0.469830808749909\n",
      "Epoch 73, Loss: 0.468955265243009\n",
      "Epoch 74, Loss: 0.46809696167019094\n",
      "Epoch 75, Loss: 0.46705446358526315\n",
      "Epoch 76, Loss: 0.4659163497995823\n",
      "Epoch 77, Loss: 0.46491370756590267\n",
      "Epoch 78, Loss: 0.4640466603873608\n",
      "Epoch 79, Loss: 0.4631396883078031\n",
      "Epoch 80, Loss: 0.4621275555604743\n",
      "Epoch 81, Loss: 0.4611624475931105\n",
      "Epoch 82, Loss: 0.4603562003198644\n",
      "Epoch 83, Loss: 0.45961382295569125\n",
      "Epoch 84, Loss: 0.4588388090417773\n",
      "Epoch 85, Loss: 0.45812690666811584\n",
      "Epoch 86, Loss: 0.4575242863655309\n",
      "Epoch 87, Loss: 0.45690580423358274\n",
      "Epoch 88, Loss: 0.45625418439017557\n",
      "Epoch 89, Loss: 0.4556801706043018\n",
      "Epoch 90, Loss: 0.45516713135608394\n",
      "Epoch 91, Loss: 0.45462378550344446\n",
      "Epoch 92, Loss: 0.45406904206679316\n",
      "Epoch 93, Loss: 0.4535568908527497\n",
      "Epoch 94, Loss: 0.4529866961174023\n",
      "Epoch 95, Loss: 0.45238032481381857\n",
      "Epoch 96, Loss: 0.4518159010138177\n",
      "Epoch 97, Loss: 0.4512569132668927\n",
      "Epoch 98, Loss: 0.45067289759217005\n",
      "Epoch 99, Loss: 0.4500784401610267\n",
      "Epoch 100, Loss: 0.449526672976426\n",
      "Epoch 101, Loss: 0.4490173385889547\n",
      "Epoch 102, Loss: 0.4484953321322444\n",
      "Epoch 103, Loss: 0.44798525758205104\n",
      "Epoch 104, Loss: 0.4474359379632004\n",
      "Epoch 105, Loss: 0.4468652357355162\n",
      "Epoch 106, Loss: 0.44630086536785135\n",
      "Epoch 107, Loss: 0.44574402095787674\n",
      "Epoch 108, Loss: 0.44521226926119056\n",
      "Epoch 109, Loss: 0.44468221062136903\n",
      "Epoch 110, Loss: 0.4441107042847895\n",
      "Epoch 111, Loss: 0.443518924993159\n",
      "Epoch 112, Loss: 0.44292788577770953\n",
      "Epoch 113, Loss: 0.4422808902372181\n",
      "Epoch 114, Loss: 0.44159638689897995\n",
      "Epoch 115, Loss: 0.4409791686377828\n",
      "Epoch 116, Loss: 0.4404021802208141\n",
      "Epoch 117, Loss: 0.439813711790557\n",
      "Epoch 118, Loss: 0.4392276779021953\n",
      "Epoch 119, Loss: 0.4386475873084849\n",
      "Epoch 120, Loss: 0.4380399573555317\n",
      "Epoch 121, Loss: 0.4374457393785387\n",
      "Epoch 122, Loss: 0.43669689922227733\n",
      "Epoch 123, Loss: 0.4357923833574475\n",
      "Epoch 124, Loss: 0.43501946030309907\n",
      "Epoch 125, Loss: 0.43431943016545194\n",
      "Epoch 126, Loss: 0.4336785757584487\n",
      "Epoch 127, Loss: 0.43307020179263067\n",
      "Epoch 128, Loss: 0.4324621435091219\n",
      "Epoch 129, Loss: 0.43180950882748476\n",
      "Epoch 130, Loss: 0.43123526548009433\n",
      "Epoch 131, Loss: 0.4306355854056639\n",
      "Epoch 132, Loss: 0.430043991633048\n",
      "Epoch 133, Loss: 0.42945557317231997\n",
      "Epoch 134, Loss: 0.42884160789772563\n",
      "Epoch 135, Loss: 0.4283489706503731\n",
      "Epoch 136, Loss: 0.42785658462239173\n",
      "Epoch 137, Loss: 0.42720682018154305\n",
      "Epoch 138, Loss: 0.42671872097421754\n",
      "Epoch 139, Loss: 0.42621483730475546\n",
      "Epoch 140, Loss: 0.4256084161348002\n",
      "Epoch 141, Loss: 0.4251006224669209\n",
      "Epoch 142, Loss: 0.4246208406951561\n",
      "Epoch 143, Loss: 0.4240736184458218\n",
      "Epoch 144, Loss: 0.4234258614942998\n",
      "Epoch 145, Loss: 0.42285565028516336\n",
      "Epoch 146, Loss: 0.4223481985938212\n",
      "Epoch 147, Loss: 0.42176745068164123\n",
      "Epoch 148, Loss: 0.4211496546054018\n",
      "Epoch 149, Loss: 0.4205577737387045\n",
      "Epoch 150, Loss: 0.41999761208922626\n",
      "Epoch 151, Loss: 0.4194151016084629\n",
      "Epoch 152, Loss: 0.4188821206974594\n",
      "Epoch 153, Loss: 0.41860471454085135\n",
      "Epoch 154, Loss: 0.41860140398694984\n",
      "Epoch 155, Loss: 0.41768879293777933\n",
      "Epoch 156, Loss: 0.41665187054430164\n",
      "Epoch 157, Loss: 0.4167181718305218\n",
      "Epoch 158, Loss: 0.41598057487301526\n",
      "Epoch 159, Loss: 0.4152915814702214\n",
      "Epoch 160, Loss: 0.4152689577560212\n",
      "Epoch 161, Loss: 0.41436957722563483\n",
      "Epoch 162, Loss: 0.41377012258617507\n",
      "Epoch 163, Loss: 0.4135868471417699\n",
      "Epoch 164, Loss: 0.41277855513356737\n",
      "Epoch 165, Loss: 0.4122537296813513\n",
      "Epoch 166, Loss: 0.4121287734541858\n",
      "Epoch 167, Loss: 0.41149051355317423\n",
      "Epoch 168, Loss: 0.4108237692968709\n",
      "Epoch 169, Loss: 0.41056202389600505\n",
      "Epoch 170, Loss: 0.41026048698132506\n",
      "Epoch 171, Loss: 0.40962942894667764\n",
      "Epoch 172, Loss: 0.40906122354609914\n",
      "Epoch 173, Loss: 0.40872580544146625\n",
      "Epoch 174, Loss: 0.4084554193735137\n",
      "Epoch 175, Loss: 0.40808143809691644\n",
      "Epoch 176, Loss: 0.40747132481275594\n",
      "Epoch 177, Loss: 0.40686167005158774\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22765942311202056\n",
      "Test R^2 score: 0.4343811913111232\n",
      "Num of epochs: 178\n",
      "Epoch 1, Loss: 0.5664910351665929\n",
      "Epoch 2, Loss: 0.5654806532480536\n",
      "Epoch 3, Loss: 0.5645361446587587\n",
      "Epoch 4, Loss: 0.5637129844642637\n",
      "Epoch 5, Loss: 0.5629610715115341\n",
      "Epoch 6, Loss: 0.5622513274367535\n",
      "Epoch 7, Loss: 0.561582797686145\n",
      "Epoch 8, Loss: 0.5609616064560661\n",
      "Epoch 9, Loss: 0.5603882834421353\n",
      "Epoch 10, Loss: 0.5598723709749914\n",
      "Epoch 11, Loss: 0.5593938898914177\n",
      "Epoch 12, Loss: 0.5589517899778474\n",
      "Epoch 13, Loss: 0.5585457040891482\n",
      "Epoch 14, Loss: 0.5581778732151362\n",
      "Epoch 15, Loss: 0.557844312813197\n",
      "Epoch 16, Loss: 0.5575445231376934\n",
      "Epoch 17, Loss: 0.5572779704279637\n",
      "Epoch 18, Loss: 0.5570422948568896\n",
      "Epoch 19, Loss: 0.5568397567334386\n",
      "Epoch 20, Loss: 0.5566701245438468\n",
      "Epoch 21, Loss: 0.5565311792761208\n",
      "Epoch 22, Loss: 0.5564090180000114\n",
      "Epoch 23, Loss: 0.5563210891987992\n",
      "Epoch 24, Loss: 0.5562498896309389\n",
      "Epoch 25, Loss: 0.5561930680875549\n",
      "Epoch 26, Loss: 0.5561481907717115\n",
      "Epoch 27, Loss: 0.5561135992766636\n",
      "Epoch 28, Loss: 0.5560846597347088\n",
      "Epoch 29, Loss: 0.5560634900419021\n",
      "Epoch 30, Loss: 0.5560421855500555\n",
      "Epoch 31, Loss: 0.5560156810868205\n",
      "Epoch 32, Loss: 0.5559814565691484\n",
      "Epoch 33, Loss: 0.5559352755917525\n",
      "Epoch 34, Loss: 0.555872953333517\n",
      "Epoch 35, Loss: 0.5557908917379788\n",
      "Epoch 36, Loss: 0.5556854887520383\n",
      "Epoch 37, Loss: 0.5555508302116765\n",
      "Epoch 38, Loss: 0.5553817434079674\n",
      "Epoch 39, Loss: 0.5551723188226876\n",
      "Epoch 40, Loss: 0.5549086814793157\n",
      "Epoch 41, Loss: 0.5545733159701269\n",
      "Epoch 42, Loss: 0.5541343617404638\n",
      "Epoch 43, Loss: 0.5535568749584651\n",
      "Epoch 44, Loss: 0.5528250306533076\n",
      "Epoch 45, Loss: 0.5519463951094715\n",
      "Epoch 46, Loss: 0.5509539123877452\n",
      "Epoch 47, Loss: 0.5498371555098774\n",
      "Epoch 48, Loss: 0.5486209519089842\n",
      "Epoch 49, Loss: 0.5472346349487437\n",
      "Epoch 50, Loss: 0.5456013152410086\n",
      "Epoch 51, Loss: 0.5435442447515921\n",
      "Epoch 52, Loss: 0.5407943824070707\n",
      "Epoch 53, Loss: 0.5372722309478024\n",
      "Epoch 54, Loss: 0.5329446690201235\n",
      "Epoch 55, Loss: 0.5277768087657041\n",
      "Epoch 56, Loss: 0.5217879479723105\n",
      "Epoch 57, Loss: 0.5152821123221333\n",
      "Epoch 58, Loss: 0.5091301768484834\n",
      "Epoch 59, Loss: 0.5050924961438222\n",
      "Epoch 60, Loss: 0.5041286066627645\n",
      "Epoch 61, Loss: 0.5023046665204995\n",
      "Epoch 62, Loss: 0.49764567652897473\n",
      "Epoch 63, Loss: 0.49229351294654666\n",
      "Epoch 64, Loss: 0.4885431884085808\n",
      "Epoch 65, Loss: 0.4873395001469828\n",
      "Epoch 66, Loss: 0.4871688225269196\n",
      "Epoch 67, Loss: 0.4860027251059264\n",
      "Epoch 68, Loss: 0.483671446491804\n",
      "Epoch 69, Loss: 0.480686774060231\n",
      "Epoch 70, Loss: 0.4779463047619825\n",
      "Epoch 71, Loss: 0.4762310845581073\n",
      "Epoch 72, Loss: 0.4756163601084306\n",
      "Epoch 73, Loss: 0.47552320626688005\n",
      "Epoch 74, Loss: 0.47509820512698736\n",
      "Epoch 75, Loss: 0.47404238895212475\n",
      "Epoch 76, Loss: 0.47270049526474334\n",
      "Epoch 77, Loss: 0.4716067208347897\n",
      "Epoch 78, Loss: 0.4708767487615239\n",
      "Epoch 79, Loss: 0.47029029185434185\n",
      "Epoch 80, Loss: 0.4695210314509885\n",
      "Epoch 81, Loss: 0.4684411939051615\n",
      "Epoch 82, Loss: 0.4672333340823479\n",
      "Epoch 83, Loss: 0.4661587619231768\n",
      "Epoch 84, Loss: 0.4652930740748957\n",
      "Epoch 85, Loss: 0.4645043745071014\n",
      "Epoch 86, Loss: 0.463646332214791\n",
      "Epoch 87, Loss: 0.462633149853184\n",
      "Epoch 88, Loss: 0.461706280096165\n",
      "Epoch 89, Loss: 0.460975952484216\n",
      "Epoch 90, Loss: 0.4604164022844801\n",
      "Epoch 91, Loss: 0.45998197859728124\n",
      "Epoch 92, Loss: 0.45953072030024916\n",
      "Epoch 93, Loss: 0.45896153494638403\n",
      "Epoch 94, Loss: 0.4583478043901554\n",
      "Epoch 95, Loss: 0.45774397744092504\n",
      "Epoch 96, Loss: 0.45712416266848926\n",
      "Epoch 97, Loss: 0.4565362940009646\n",
      "Epoch 98, Loss: 0.4560265542609847\n",
      "Epoch 99, Loss: 0.45552355533079975\n",
      "Epoch 100, Loss: 0.4550000234226598\n",
      "Epoch 101, Loss: 0.4544841344338769\n",
      "Epoch 102, Loss: 0.454022620117586\n",
      "Epoch 103, Loss: 0.45357159278253045\n",
      "Epoch 104, Loss: 0.45308772295502947\n",
      "Epoch 105, Loss: 0.4525934422945034\n",
      "Epoch 106, Loss: 0.4521228791298664\n",
      "Epoch 107, Loss: 0.4516452766235661\n",
      "Epoch 108, Loss: 0.45111293325143625\n",
      "Epoch 109, Loss: 0.45057835698623633\n",
      "Epoch 110, Loss: 0.4500735898245454\n",
      "Epoch 111, Loss: 0.4495606655378818\n",
      "Epoch 112, Loss: 0.4490529791102074\n",
      "Epoch 113, Loss: 0.44852701084640256\n",
      "Epoch 114, Loss: 0.44798213088532024\n",
      "Epoch 115, Loss: 0.44747293656843834\n",
      "Epoch 116, Loss: 0.44696079510950576\n",
      "Epoch 117, Loss: 0.4464453125267019\n",
      "Epoch 118, Loss: 0.44594161450760805\n",
      "Epoch 119, Loss: 0.44542214231750366\n",
      "Epoch 120, Loss: 0.4448933887823896\n",
      "Epoch 121, Loss: 0.44436232939091835\n",
      "Epoch 122, Loss: 0.44384698479562795\n",
      "Epoch 123, Loss: 0.44334603176119974\n",
      "Epoch 124, Loss: 0.4428160106382476\n",
      "Epoch 125, Loss: 0.4422892625263918\n",
      "Epoch 126, Loss: 0.4417542967444337\n",
      "Epoch 127, Loss: 0.4412185303540051\n",
      "Epoch 128, Loss: 0.4406837018457561\n",
      "Epoch 129, Loss: 0.4401509318438408\n",
      "Epoch 130, Loss: 0.43961119458039083\n",
      "Epoch 131, Loss: 0.43902782629083126\n",
      "Epoch 132, Loss: 0.4384192618330891\n",
      "Epoch 133, Loss: 0.43776534753034907\n",
      "Epoch 134, Loss: 0.43704550841567436\n",
      "Epoch 135, Loss: 0.4363270601619886\n",
      "Epoch 136, Loss: 0.4356356132670277\n",
      "Epoch 137, Loss: 0.4349469556475433\n",
      "Epoch 138, Loss: 0.43432536562007973\n",
      "Epoch 139, Loss: 0.4337448509801153\n",
      "Epoch 140, Loss: 0.43315746937048916\n",
      "Epoch 141, Loss: 0.4325155823441829\n",
      "Epoch 142, Loss: 0.4318514347961978\n",
      "Epoch 143, Loss: 0.43121575896840736\n",
      "Epoch 144, Loss: 0.4306195294457637\n",
      "Epoch 145, Loss: 0.4300760766308864\n",
      "Epoch 146, Loss: 0.4295031932550013\n",
      "Epoch 147, Loss: 0.42894045306021167\n",
      "Epoch 148, Loss: 0.42818561250189613\n",
      "Epoch 149, Loss: 0.42745103552859415\n",
      "Epoch 150, Loss: 0.4268514150803609\n",
      "Epoch 151, Loss: 0.42632458518112154\n",
      "Epoch 152, Loss: 0.4258473371261016\n",
      "Epoch 153, Loss: 0.4252286702547314\n",
      "Epoch 154, Loss: 0.424526009188565\n",
      "Epoch 155, Loss: 0.4238880484273241\n",
      "Epoch 156, Loss: 0.42341278750106603\n",
      "Epoch 157, Loss: 0.42309098370402337\n",
      "Epoch 158, Loss: 0.42276889970944065\n",
      "Epoch 159, Loss: 0.4220466794269181\n",
      "Epoch 160, Loss: 0.4212218279148413\n",
      "Epoch 161, Loss: 0.4209023672393949\n",
      "Epoch 162, Loss: 0.420717930865289\n",
      "Epoch 163, Loss: 0.42013210977737125\n",
      "Epoch 164, Loss: 0.41935205166561457\n",
      "Epoch 165, Loss: 0.41901418479930536\n",
      "Epoch 166, Loss: 0.41882027136055616\n",
      "Epoch 167, Loss: 0.4181967496679961\n",
      "Epoch 168, Loss: 0.41750536392672266\n",
      "Epoch 169, Loss: 0.41723979236465963\n",
      "Epoch 170, Loss: 0.4170186304646377\n",
      "Epoch 171, Loss: 0.4163721374795822\n",
      "Epoch 172, Loss: 0.4157621300855186\n",
      "Epoch 173, Loss: 0.4154432415600614\n",
      "Epoch 174, Loss: 0.4151703391306401\n",
      "Epoch 175, Loss: 0.4147626607203006\n",
      "Epoch 176, Loss: 0.4141448676757874\n",
      "Epoch 177, Loss: 0.41365684575632133\n",
      "Epoch 178, Loss: 0.41339388432032326\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2230020385692225\n",
      "Test R^2 score: 0.46262321160249875\n",
      "Num of epochs: 179\n",
      "Epoch 1, Loss: 0.5649564406390005\n",
      "Epoch 2, Loss: 0.563782897928203\n",
      "Epoch 3, Loss: 0.5627041552192096\n",
      "Epoch 4, Loss: 0.5617229074210229\n",
      "Epoch 5, Loss: 0.5608225287558184\n",
      "Epoch 6, Loss: 0.5600031431995464\n",
      "Epoch 7, Loss: 0.5592588719707455\n",
      "Epoch 8, Loss: 0.5585887081745667\n",
      "Epoch 9, Loss: 0.5579957762459216\n",
      "Epoch 10, Loss: 0.5574781842517891\n",
      "Epoch 11, Loss: 0.5570335206230292\n",
      "Epoch 12, Loss: 0.5566592029349086\n",
      "Epoch 13, Loss: 0.5563516234674437\n",
      "Epoch 14, Loss: 0.5561013001553491\n",
      "Epoch 15, Loss: 0.5559206673452396\n",
      "Epoch 16, Loss: 0.555782499915201\n",
      "Epoch 17, Loss: 0.5556726974594062\n",
      "Epoch 18, Loss: 0.5555858590550351\n",
      "Epoch 19, Loss: 0.5555344951796863\n",
      "Epoch 20, Loss: 0.5554520348288673\n",
      "Epoch 21, Loss: 0.555306237292248\n",
      "Epoch 22, Loss: 0.5550863417058215\n",
      "Epoch 23, Loss: 0.5547828860942348\n",
      "Epoch 24, Loss: 0.5543866214587749\n",
      "Epoch 25, Loss: 0.5538930442107473\n",
      "Epoch 26, Loss: 0.5532886974110354\n",
      "Epoch 27, Loss: 0.5525478142550563\n",
      "Epoch 28, Loss: 0.5516545021765454\n",
      "Epoch 29, Loss: 0.5506062060384322\n",
      "Epoch 30, Loss: 0.5494073004226793\n",
      "Epoch 31, Loss: 0.5480334953909889\n",
      "Epoch 32, Loss: 0.5464485140330442\n",
      "Epoch 33, Loss: 0.5446612921147674\n",
      "Epoch 34, Loss: 0.542680705118349\n",
      "Epoch 35, Loss: 0.5404782708005759\n",
      "Epoch 36, Loss: 0.5380156483235724\n",
      "Epoch 37, Loss: 0.5352665864012855\n",
      "Epoch 38, Loss: 0.5321911161325634\n",
      "Epoch 39, Loss: 0.5286545463056961\n",
      "Epoch 40, Loss: 0.5244418799270053\n",
      "Epoch 41, Loss: 0.5195422637460396\n",
      "Epoch 42, Loss: 0.5138816840150738\n",
      "Epoch 43, Loss: 0.5076296550515688\n",
      "Epoch 44, Loss: 0.5017721540124687\n",
      "Epoch 45, Loss: 0.49807155772362216\n",
      "Epoch 46, Loss: 0.4970560427792736\n",
      "Epoch 47, Loss: 0.49502964487315865\n",
      "Epoch 48, Loss: 0.49088942697305193\n",
      "Epoch 49, Loss: 0.4867059855984027\n",
      "Epoch 50, Loss: 0.48405467485736203\n",
      "Epoch 51, Loss: 0.4828658281275343\n",
      "Epoch 52, Loss: 0.4821767454499353\n",
      "Epoch 53, Loss: 0.48114947036928873\n",
      "Epoch 54, Loss: 0.4795261068058978\n",
      "Epoch 55, Loss: 0.4775342258450265\n",
      "Epoch 56, Loss: 0.4754329803580938\n",
      "Epoch 57, Loss: 0.473598298063877\n",
      "Epoch 58, Loss: 0.4721837953362847\n",
      "Epoch 59, Loss: 0.4710819097394277\n",
      "Epoch 60, Loss: 0.47000042709879036\n",
      "Epoch 61, Loss: 0.4684638739573795\n",
      "Epoch 62, Loss: 0.466861943773481\n",
      "Epoch 63, Loss: 0.46588409435012773\n",
      "Epoch 64, Loss: 0.46507166235938585\n",
      "Epoch 65, Loss: 0.4640478806167671\n",
      "Epoch 66, Loss: 0.46288919247433763\n",
      "Epoch 67, Loss: 0.4615154683784766\n",
      "Epoch 68, Loss: 0.46005458647849795\n",
      "Epoch 69, Loss: 0.4588857341852401\n",
      "Epoch 70, Loss: 0.4580363283044348\n",
      "Epoch 71, Loss: 0.4573266631473868\n",
      "Epoch 72, Loss: 0.45669946283313456\n",
      "Epoch 73, Loss: 0.45593627764804023\n",
      "Epoch 74, Loss: 0.45524921393706297\n",
      "Epoch 75, Loss: 0.45465313627553483\n",
      "Epoch 76, Loss: 0.4540269523772713\n",
      "Epoch 77, Loss: 0.4533947109063676\n",
      "Epoch 78, Loss: 0.4526034675244491\n",
      "Epoch 79, Loss: 0.4518269328910867\n",
      "Epoch 80, Loss: 0.45108032949189675\n",
      "Epoch 81, Loss: 0.45033152871625637\n",
      "Epoch 82, Loss: 0.4495651899512118\n",
      "Epoch 83, Loss: 0.4487033541086641\n",
      "Epoch 84, Loss: 0.44784959209556013\n",
      "Epoch 85, Loss: 0.44705711735242604\n",
      "Epoch 86, Loss: 0.44624941125932427\n",
      "Epoch 87, Loss: 0.4454320613239492\n",
      "Epoch 88, Loss: 0.444528977936367\n",
      "Epoch 89, Loss: 0.44363359549808423\n",
      "Epoch 90, Loss: 0.4427892405311055\n",
      "Epoch 91, Loss: 0.4419710714746807\n",
      "Epoch 92, Loss: 0.4411247841393193\n",
      "Epoch 93, Loss: 0.44025470107913767\n",
      "Epoch 94, Loss: 0.4394234880414323\n",
      "Epoch 95, Loss: 0.43859815716949924\n",
      "Epoch 96, Loss: 0.43774471931823505\n",
      "Epoch 97, Loss: 0.4368610996277923\n",
      "Epoch 98, Loss: 0.4360494750129191\n",
      "Epoch 99, Loss: 0.4352953744930429\n",
      "Epoch 100, Loss: 0.4345314780038882\n",
      "Epoch 101, Loss: 0.4337659785875684\n",
      "Epoch 102, Loss: 0.4330673975161779\n",
      "Epoch 103, Loss: 0.43236920415892793\n",
      "Epoch 104, Loss: 0.43165177550952094\n",
      "Epoch 105, Loss: 0.4309969456745886\n",
      "Epoch 106, Loss: 0.4305878829185366\n",
      "Epoch 107, Loss: 0.4305905649178259\n",
      "Epoch 108, Loss: 0.4291471898958589\n",
      "Epoch 109, Loss: 0.4282757020498428\n",
      "Epoch 110, Loss: 0.4282021773170712\n",
      "Epoch 111, Loss: 0.4269404947798229\n",
      "Epoch 112, Loss: 0.42658874514818873\n",
      "Epoch 113, Loss: 0.42599195114107635\n",
      "Epoch 114, Loss: 0.424991347421193\n",
      "Epoch 115, Loss: 0.4247797465401982\n",
      "Epoch 116, Loss: 0.4237699688507745\n",
      "Epoch 117, Loss: 0.42329527940449746\n",
      "Epoch 118, Loss: 0.42269892944221127\n",
      "Epoch 119, Loss: 0.4218698430629184\n",
      "Epoch 120, Loss: 0.4214564118818431\n",
      "Epoch 121, Loss: 0.42062647058306385\n",
      "Epoch 122, Loss: 0.4200470671223174\n",
      "Epoch 123, Loss: 0.41955479390662054\n",
      "Epoch 124, Loss: 0.4187407094010218\n",
      "Epoch 125, Loss: 0.4182799063466108\n",
      "Epoch 126, Loss: 0.41773978762582853\n",
      "Epoch 127, Loss: 0.4169010357540328\n",
      "Epoch 128, Loss: 0.4164158503300669\n",
      "Epoch 129, Loss: 0.4159186702452756\n",
      "Epoch 130, Loss: 0.41508864162741954\n",
      "Epoch 131, Loss: 0.4144322885350459\n",
      "Epoch 132, Loss: 0.41394847523444966\n",
      "Epoch 133, Loss: 0.41334601257217174\n",
      "Epoch 134, Loss: 0.41262660178954397\n",
      "Epoch 135, Loss: 0.4119969074401711\n",
      "Epoch 136, Loss: 0.4114666849407421\n",
      "Epoch 137, Loss: 0.41099181668402257\n",
      "Epoch 138, Loss: 0.41047004321954284\n",
      "Epoch 139, Loss: 0.4099433528042066\n",
      "Epoch 140, Loss: 0.40934402334063036\n",
      "Epoch 141, Loss: 0.40877835569107274\n",
      "Epoch 142, Loss: 0.40818074726295206\n",
      "Epoch 143, Loss: 0.40762816095866644\n",
      "Epoch 144, Loss: 0.4071097446543191\n",
      "Epoch 145, Loss: 0.4066047036962801\n",
      "Epoch 146, Loss: 0.40612005943329466\n",
      "Epoch 147, Loss: 0.4056396484375\n",
      "Epoch 148, Loss: 0.4051883654181379\n",
      "Epoch 149, Loss: 0.4048158383216337\n",
      "Epoch 150, Loss: 0.4048010589457597\n",
      "Epoch 151, Loss: 0.40592954908282824\n",
      "Epoch 152, Loss: 0.40752418308816213\n",
      "Epoch 153, Loss: 0.4045907762918629\n",
      "Epoch 154, Loss: 0.4029165283361998\n",
      "Epoch 155, Loss: 0.4048507508438533\n",
      "Epoch 156, Loss: 0.4024276460749582\n",
      "Epoch 157, Loss: 0.4024470483707925\n",
      "Epoch 158, Loss: 0.40271813834433934\n",
      "Epoch 159, Loss: 0.4010056029449164\n",
      "Epoch 160, Loss: 0.4019859723163072\n",
      "Epoch 161, Loss: 0.4007590668843059\n",
      "Epoch 162, Loss: 0.4005344783738866\n",
      "Epoch 163, Loss: 0.4007229612025509\n",
      "Epoch 164, Loss: 0.39942637380265944\n",
      "Epoch 165, Loss: 0.39998595093850625\n",
      "Epoch 166, Loss: 0.39905728025316106\n",
      "Epoch 167, Loss: 0.3988236818430386\n",
      "Epoch 168, Loss: 0.398856148776714\n",
      "Epoch 169, Loss: 0.3979764776898675\n",
      "Epoch 170, Loss: 0.39815919169348324\n",
      "Epoch 171, Loss: 0.39766753354954676\n",
      "Epoch 172, Loss: 0.3971681570930119\n",
      "Epoch 173, Loss: 0.39728180318803036\n",
      "Epoch 174, Loss: 0.3966319368623222\n",
      "Epoch 175, Loss: 0.3963713085396046\n",
      "Epoch 176, Loss: 0.39634132623446455\n",
      "Epoch 177, Loss: 0.3957072002656692\n",
      "Epoch 178, Loss: 0.39550909348268637\n",
      "Epoch 179, Loss: 0.39535040843272407\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.23074648518214563\n",
      "Test R^2 score: 0.4248419155335765\n",
      "Num of epochs: 180\n",
      "Epoch 1, Loss: 0.5723427209576711\n",
      "Epoch 2, Loss: 0.5709760542005625\n",
      "Epoch 3, Loss: 0.5697834748882841\n",
      "Epoch 4, Loss: 0.5687096424246557\n",
      "Epoch 5, Loss: 0.5677381968445051\n",
      "Epoch 6, Loss: 0.5668228721834788\n",
      "Epoch 7, Loss: 0.5659346623299546\n",
      "Epoch 8, Loss: 0.5650868801396985\n",
      "Epoch 9, Loss: 0.5643258660812536\n",
      "Epoch 10, Loss: 0.5635579809012096\n",
      "Epoch 11, Loss: 0.5628125858677486\n",
      "Epoch 12, Loss: 0.5620932698013682\n",
      "Epoch 13, Loss: 0.5614128999133094\n",
      "Epoch 14, Loss: 0.5607625566302031\n",
      "Epoch 15, Loss: 0.5601460688688605\n",
      "Epoch 16, Loss: 0.5595660251100341\n",
      "Epoch 17, Loss: 0.5590248311862202\n",
      "Epoch 18, Loss: 0.5585224666328495\n",
      "Epoch 19, Loss: 0.5580700640324395\n",
      "Epoch 20, Loss: 0.5576540906356086\n",
      "Epoch 21, Loss: 0.5572732375713441\n",
      "Epoch 22, Loss: 0.5569304932881407\n",
      "Epoch 23, Loss: 0.5567051632593929\n",
      "Epoch 24, Loss: 0.5564926753937344\n",
      "Epoch 25, Loss: 0.5562950801798446\n",
      "Epoch 26, Loss: 0.5561182616175637\n",
      "Epoch 27, Loss: 0.5559718079297656\n",
      "Epoch 28, Loss: 0.555850542417843\n",
      "Epoch 29, Loss: 0.555742818014643\n",
      "Epoch 30, Loss: 0.5556391759035968\n",
      "Epoch 31, Loss: 0.5555268505415993\n",
      "Epoch 32, Loss: 0.5553905437371225\n",
      "Epoch 33, Loss: 0.5552167919247005\n",
      "Epoch 34, Loss: 0.5549898532421027\n",
      "Epoch 35, Loss: 0.5546782049555434\n",
      "Epoch 36, Loss: 0.5542276383561849\n",
      "Epoch 37, Loss: 0.553616093446564\n",
      "Epoch 38, Loss: 0.5528388312210829\n",
      "Epoch 39, Loss: 0.5519265516057239\n",
      "Epoch 40, Loss: 0.5509285155032739\n",
      "Epoch 41, Loss: 0.5496781306853534\n",
      "Epoch 42, Loss: 0.5481160115513063\n",
      "Epoch 43, Loss: 0.5462072928382825\n",
      "Epoch 44, Loss: 0.5439237251312735\n",
      "Epoch 45, Loss: 0.5412175596968465\n",
      "Epoch 46, Loss: 0.5380988976221113\n",
      "Epoch 47, Loss: 0.5345984844886286\n",
      "Epoch 48, Loss: 0.5308981459538715\n",
      "Epoch 49, Loss: 0.5273092753126475\n",
      "Epoch 50, Loss: 0.5241707462895968\n",
      "Epoch 51, Loss: 0.5209284186987589\n",
      "Epoch 52, Loss: 0.5167285784676873\n",
      "Epoch 53, Loss: 0.5120969350367404\n",
      "Epoch 54, Loss: 0.5080280433389799\n",
      "Epoch 55, Loss: 0.5048357353176395\n",
      "Epoch 56, Loss: 0.5022843451845127\n",
      "Epoch 57, Loss: 0.500053581704654\n",
      "Epoch 58, Loss: 0.4978593660313968\n",
      "Epoch 59, Loss: 0.4957786069715989\n",
      "Epoch 60, Loss: 0.49388058420440695\n",
      "Epoch 61, Loss: 0.49198113005396643\n",
      "Epoch 62, Loss: 0.4899562791616427\n",
      "Epoch 63, Loss: 0.4877807340720031\n",
      "Epoch 64, Loss: 0.48561543404916446\n",
      "Epoch 65, Loss: 0.4835687664770307\n",
      "Epoch 66, Loss: 0.48152141472521653\n",
      "Epoch 67, Loss: 0.4795493346303445\n",
      "Epoch 68, Loss: 0.4777704002290691\n",
      "Epoch 69, Loss: 0.47616365032900787\n",
      "Epoch 70, Loss: 0.4746694173627127\n",
      "Epoch 71, Loss: 0.47321529272645807\n",
      "Epoch 72, Loss: 0.47184968337298716\n",
      "Epoch 73, Loss: 0.47063043436709817\n",
      "Epoch 74, Loss: 0.4696229594411983\n",
      "Epoch 75, Loss: 0.4687913558518612\n",
      "Epoch 76, Loss: 0.46789001413847825\n",
      "Epoch 77, Loss: 0.46695612341773507\n",
      "Epoch 78, Loss: 0.46573809331969107\n",
      "Epoch 79, Loss: 0.464637213591854\n",
      "Epoch 80, Loss: 0.4636566487409781\n",
      "Epoch 81, Loss: 0.4627627586458615\n",
      "Epoch 82, Loss: 0.46192993394871984\n",
      "Epoch 83, Loss: 0.46117351437987647\n",
      "Epoch 84, Loss: 0.4605124178381171\n",
      "Epoch 85, Loss: 0.45977961049811394\n",
      "Epoch 86, Loss: 0.45893338508636605\n",
      "Epoch 87, Loss: 0.45802261556360024\n",
      "Epoch 88, Loss: 0.457096893943385\n",
      "Epoch 89, Loss: 0.45621500730230286\n",
      "Epoch 90, Loss: 0.45544016439203727\n",
      "Epoch 91, Loss: 0.45472207282066546\n",
      "Epoch 92, Loss: 0.45408295624053935\n",
      "Epoch 93, Loss: 0.4535305740297787\n",
      "Epoch 94, Loss: 0.45296523138537\n",
      "Epoch 95, Loss: 0.4523705416900031\n",
      "Epoch 96, Loss: 0.45174554790863736\n",
      "Epoch 97, Loss: 0.4511316454898142\n",
      "Epoch 98, Loss: 0.4505700229699869\n",
      "Epoch 99, Loss: 0.449960212802974\n",
      "Epoch 100, Loss: 0.4493343702048687\n",
      "Epoch 101, Loss: 0.4487078871664405\n",
      "Epoch 102, Loss: 0.44809855235435686\n",
      "Epoch 103, Loss: 0.44751624203088636\n",
      "Epoch 104, Loss: 0.4469024816479156\n",
      "Epoch 105, Loss: 0.44627333598735686\n",
      "Epoch 106, Loss: 0.44567080354636984\n",
      "Epoch 107, Loss: 0.4450503297000783\n",
      "Epoch 108, Loss: 0.44440902276579386\n",
      "Epoch 109, Loss: 0.4437591330165983\n",
      "Epoch 110, Loss: 0.4431292739199342\n",
      "Epoch 111, Loss: 0.44247620798794507\n",
      "Epoch 112, Loss: 0.44181804521938883\n",
      "Epoch 113, Loss: 0.4411499325750585\n",
      "Epoch 114, Loss: 0.4404891453974139\n",
      "Epoch 115, Loss: 0.4398138642533201\n",
      "Epoch 116, Loss: 0.43911767660408946\n",
      "Epoch 117, Loss: 0.43836057696452174\n",
      "Epoch 118, Loss: 0.4376278077498287\n",
      "Epoch 119, Loss: 0.4369253915094712\n",
      "Epoch 120, Loss: 0.4362179500097813\n",
      "Epoch 121, Loss: 0.43545139446514897\n",
      "Epoch 122, Loss: 0.43463883449093627\n",
      "Epoch 123, Loss: 0.43388271153926544\n",
      "Epoch 124, Loss: 0.43314816373065734\n",
      "Epoch 125, Loss: 0.43244989402576517\n",
      "Epoch 126, Loss: 0.4318627523846874\n",
      "Epoch 127, Loss: 0.43118619515923384\n",
      "Epoch 128, Loss: 0.43033843586314907\n",
      "Epoch 129, Loss: 0.42952673245327005\n",
      "Epoch 130, Loss: 0.42894083519413945\n",
      "Epoch 131, Loss: 0.4284061573731633\n",
      "Epoch 132, Loss: 0.427698090290188\n",
      "Epoch 133, Loss: 0.4268362117308075\n",
      "Epoch 134, Loss: 0.42609194697469654\n",
      "Epoch 135, Loss: 0.42551524050837425\n",
      "Epoch 136, Loss: 0.4249544603127838\n",
      "Epoch 137, Loss: 0.4241690429172519\n",
      "Epoch 138, Loss: 0.42336909315180127\n",
      "Epoch 139, Loss: 0.422719428228772\n",
      "Epoch 140, Loss: 0.4221929835281771\n",
      "Epoch 141, Loss: 0.42172176615826146\n",
      "Epoch 142, Loss: 0.4211381906474354\n",
      "Epoch 143, Loss: 0.4204887644506156\n",
      "Epoch 144, Loss: 0.41970828634725293\n",
      "Epoch 145, Loss: 0.4189733393615448\n",
      "Epoch 146, Loss: 0.4183682110420539\n",
      "Epoch 147, Loss: 0.4179096358377534\n",
      "Epoch 148, Loss: 0.41765803972139803\n",
      "Epoch 149, Loss: 0.41746153314490314\n",
      "Epoch 150, Loss: 0.4165898152844388\n",
      "Epoch 151, Loss: 0.4152984167829832\n",
      "Epoch 152, Loss: 0.4148056630612476\n",
      "Epoch 153, Loss: 0.41476628932730825\n",
      "Epoch 154, Loss: 0.4139467113471597\n",
      "Epoch 155, Loss: 0.4128929932092402\n",
      "Epoch 156, Loss: 0.41257493898952624\n",
      "Epoch 157, Loss: 0.41244149949212333\n",
      "Epoch 158, Loss: 0.41162102134767303\n",
      "Epoch 159, Loss: 0.41058701192871133\n",
      "Epoch 160, Loss: 0.4103561277648501\n",
      "Epoch 161, Loss: 0.4100622705238885\n",
      "Epoch 162, Loss: 0.4094498318425293\n",
      "Epoch 163, Loss: 0.4084061113363584\n",
      "Epoch 164, Loss: 0.40813934704038807\n",
      "Epoch 165, Loss: 0.40790660254766353\n",
      "Epoch 166, Loss: 0.4072674701004192\n",
      "Epoch 167, Loss: 0.4062275513535471\n",
      "Epoch 168, Loss: 0.40576757617307835\n",
      "Epoch 169, Loss: 0.40554697388376065\n",
      "Epoch 170, Loss: 0.4052086100377149\n",
      "Epoch 171, Loss: 0.4044312884850463\n",
      "Epoch 172, Loss: 0.40357150552244936\n",
      "Epoch 173, Loss: 0.40296569456234127\n",
      "Epoch 174, Loss: 0.40235706418424033\n",
      "Epoch 175, Loss: 0.4020596028607078\n",
      "Epoch 176, Loss: 0.401964453267874\n",
      "Epoch 177, Loss: 0.4019393555235471\n",
      "Epoch 178, Loss: 0.40163639071565627\n",
      "Epoch 179, Loss: 0.40081143479329856\n",
      "Epoch 180, Loss: 0.3995039635844784\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.23633302915232438\n",
      "Test R^2 score: 0.395190616466316\n",
      "Num of epochs: 181\n",
      "Epoch 1, Loss: 0.5665294644739376\n",
      "Epoch 2, Loss: 0.5650287847444571\n",
      "Epoch 3, Loss: 0.5636358449184011\n",
      "Epoch 4, Loss: 0.5623658603095951\n",
      "Epoch 5, Loss: 0.5612176742675097\n",
      "Epoch 6, Loss: 0.5601858910628262\n",
      "Epoch 7, Loss: 0.5592726203528497\n",
      "Epoch 8, Loss: 0.5584825258296164\n",
      "Epoch 9, Loss: 0.5578352306446914\n",
      "Epoch 10, Loss: 0.557339333489204\n",
      "Epoch 11, Loss: 0.5569379313709881\n",
      "Epoch 12, Loss: 0.5566295154199064\n",
      "Epoch 13, Loss: 0.5564115354034651\n",
      "Epoch 14, Loss: 0.556271159380394\n",
      "Epoch 15, Loss: 0.5562078299235665\n",
      "Epoch 16, Loss: 0.5561906836526075\n",
      "Epoch 17, Loss: 0.556202257443483\n",
      "Epoch 18, Loss: 0.5562307890242766\n",
      "Epoch 19, Loss: 0.5562625337110156\n",
      "Epoch 20, Loss: 0.5562715076188952\n",
      "Epoch 21, Loss: 0.5562778026619072\n",
      "Epoch 22, Loss: 0.5562624533470074\n",
      "Epoch 23, Loss: 0.5562191086667271\n",
      "Epoch 24, Loss: 0.5561458061443559\n",
      "Epoch 25, Loss: 0.5560399344617271\n",
      "Epoch 26, Loss: 0.5559035926329453\n",
      "Epoch 27, Loss: 0.5557421476879335\n",
      "Epoch 28, Loss: 0.5555634097365331\n",
      "Epoch 29, Loss: 0.5553630422454929\n",
      "Epoch 30, Loss: 0.5551406996889952\n",
      "Epoch 31, Loss: 0.5548881651349292\n",
      "Epoch 32, Loss: 0.5545909421452794\n",
      "Epoch 33, Loss: 0.5542366452120195\n",
      "Epoch 34, Loss: 0.553804662129171\n",
      "Epoch 35, Loss: 0.5532704910917139\n",
      "Epoch 36, Loss: 0.5526224568965772\n",
      "Epoch 37, Loss: 0.5518703649721527\n",
      "Epoch 38, Loss: 0.550928840071483\n",
      "Epoch 39, Loss: 0.5497186569743783\n",
      "Epoch 40, Loss: 0.5481664938972335\n",
      "Epoch 41, Loss: 0.5461882229839603\n",
      "Epoch 42, Loss: 0.5437024599975621\n",
      "Epoch 43, Loss: 0.5406665433235984\n",
      "Epoch 44, Loss: 0.5370838228563317\n",
      "Epoch 45, Loss: 0.5330632064623226\n",
      "Epoch 46, Loss: 0.5290449324077898\n",
      "Epoch 47, Loss: 0.5256253253604639\n",
      "Epoch 48, Loss: 0.5230714172576783\n",
      "Epoch 49, Loss: 0.5207132073790612\n",
      "Epoch 50, Loss: 0.5175600444586659\n",
      "Epoch 51, Loss: 0.5133655345351582\n",
      "Epoch 52, Loss: 0.5090404921634153\n",
      "Epoch 53, Loss: 0.5056605003352286\n",
      "Epoch 54, Loss: 0.5034487813849404\n",
      "Epoch 55, Loss: 0.5014912599256487\n",
      "Epoch 56, Loss: 0.4994085360069462\n",
      "Epoch 57, Loss: 0.49724073804742114\n",
      "Epoch 58, Loss: 0.4952477427849512\n",
      "Epoch 59, Loss: 0.4935819762474947\n",
      "Epoch 60, Loss: 0.4918086849670163\n",
      "Epoch 61, Loss: 0.4895718417611371\n",
      "Epoch 62, Loss: 0.4870502518639023\n",
      "Epoch 63, Loss: 0.48476789291060357\n",
      "Epoch 64, Loss: 0.48272942380747524\n",
      "Epoch 65, Loss: 0.4805945255058228\n",
      "Epoch 66, Loss: 0.47831075525607364\n",
      "Epoch 67, Loss: 0.4762145945637249\n",
      "Epoch 68, Loss: 0.4744515490179899\n",
      "Epoch 69, Loss: 0.4726624449016567\n",
      "Epoch 70, Loss: 0.47074016251214346\n",
      "Epoch 71, Loss: 0.4690876539374389\n",
      "Epoch 72, Loss: 0.4677278659737848\n",
      "Epoch 73, Loss: 0.46654933287430067\n",
      "Epoch 74, Loss: 0.4653153471542573\n",
      "Epoch 75, Loss: 0.4641677685672595\n",
      "Epoch 76, Loss: 0.463247523760778\n",
      "Epoch 77, Loss: 0.4623930143645792\n",
      "Epoch 78, Loss: 0.46174152208382313\n",
      "Epoch 79, Loss: 0.46111092295349193\n",
      "Epoch 80, Loss: 0.46017591955764836\n",
      "Epoch 81, Loss: 0.45915756204732183\n",
      "Epoch 82, Loss: 0.45817988890441935\n",
      "Epoch 83, Loss: 0.4571651360445247\n",
      "Epoch 84, Loss: 0.45626902801863456\n",
      "Epoch 85, Loss: 0.45545436384929083\n",
      "Epoch 86, Loss: 0.45460162777485497\n",
      "Epoch 87, Loss: 0.45387680890566734\n",
      "Epoch 88, Loss: 0.45320940875777194\n",
      "Epoch 89, Loss: 0.45246586049103954\n",
      "Epoch 90, Loss: 0.4518055779669177\n",
      "Epoch 91, Loss: 0.45102988316544185\n",
      "Epoch 92, Loss: 0.4501956600427838\n",
      "Epoch 93, Loss: 0.4493911743967121\n",
      "Epoch 94, Loss: 0.4485306154665342\n",
      "Epoch 95, Loss: 0.4477943061066235\n",
      "Epoch 96, Loss: 0.4470280678564825\n",
      "Epoch 97, Loss: 0.4463738292100818\n",
      "Epoch 98, Loss: 0.44559488210782416\n",
      "Epoch 99, Loss: 0.44486588953930617\n",
      "Epoch 100, Loss: 0.44408260291902\n",
      "Epoch 101, Loss: 0.44326599751029583\n",
      "Epoch 102, Loss: 0.44248442503895413\n",
      "Epoch 103, Loss: 0.44163905393306513\n",
      "Epoch 104, Loss: 0.44088951179538793\n",
      "Epoch 105, Loss: 0.44011382556977746\n",
      "Epoch 106, Loss: 0.4393039534960314\n",
      "Epoch 107, Loss: 0.43857085779431615\n",
      "Epoch 108, Loss: 0.4378311572840653\n",
      "Epoch 109, Loss: 0.43707470999297177\n",
      "Epoch 110, Loss: 0.436282661138968\n",
      "Epoch 111, Loss: 0.4354485713032548\n",
      "Epoch 112, Loss: 0.4345825707924804\n",
      "Epoch 113, Loss: 0.43373464752312935\n",
      "Epoch 114, Loss: 0.43292528466368796\n",
      "Epoch 115, Loss: 0.4321179232306163\n",
      "Epoch 116, Loss: 0.4313377422413779\n",
      "Epoch 117, Loss: 0.4306458276880267\n",
      "Epoch 118, Loss: 0.4303966911914623\n",
      "Epoch 119, Loss: 0.43077860928605727\n",
      "Epoch 120, Loss: 0.4301696499789185\n",
      "Epoch 121, Loss: 0.4280344811692355\n",
      "Epoch 122, Loss: 0.4292491931485573\n",
      "Epoch 123, Loss: 0.42703953572681796\n",
      "Epoch 124, Loss: 0.427378676415134\n",
      "Epoch 125, Loss: 0.4259284228829125\n",
      "Epoch 126, Loss: 0.425846812248907\n",
      "Epoch 127, Loss: 0.4250483548481085\n",
      "Epoch 128, Loss: 0.4244036480555831\n",
      "Epoch 129, Loss: 0.4239746754501381\n",
      "Epoch 130, Loss: 0.4228440211374644\n",
      "Epoch 131, Loss: 0.42286238094877204\n",
      "Epoch 132, Loss: 0.421599192001647\n",
      "Epoch 133, Loss: 0.4218085907836766\n",
      "Epoch 134, Loss: 0.4206916850030208\n",
      "Epoch 135, Loss: 0.42009270320467645\n",
      "Epoch 136, Loss: 0.4198508446523082\n",
      "Epoch 137, Loss: 0.41862493326956035\n",
      "Epoch 138, Loss: 0.41832336641244705\n",
      "Epoch 139, Loss: 0.4177241277998484\n",
      "Epoch 140, Loss: 0.4167058528911128\n",
      "Epoch 141, Loss: 0.4163239281389671\n",
      "Epoch 142, Loss: 0.41584502111355187\n",
      "Epoch 143, Loss: 0.4149675554496325\n",
      "Epoch 144, Loss: 0.41427250700719565\n",
      "Epoch 145, Loss: 0.41393726182297486\n",
      "Epoch 146, Loss: 0.41361330966793547\n",
      "Epoch 147, Loss: 0.41274505329922456\n",
      "Epoch 148, Loss: 0.41190105072206057\n",
      "Epoch 149, Loss: 0.4112398819128011\n",
      "Epoch 150, Loss: 0.4107690864929945\n",
      "Epoch 151, Loss: 0.41053206165712897\n",
      "Epoch 152, Loss: 0.41055097205878927\n",
      "Epoch 153, Loss: 0.41163935683021236\n",
      "Epoch 154, Loss: 0.4098153832319493\n",
      "Epoch 155, Loss: 0.4081546444371726\n",
      "Epoch 156, Loss: 0.4075865583697128\n",
      "Epoch 157, Loss: 0.40793631928432156\n",
      "Epoch 158, Loss: 0.4079797124248172\n",
      "Epoch 159, Loss: 0.40613724904537063\n",
      "Epoch 160, Loss: 0.4059342294198565\n",
      "Epoch 161, Loss: 0.40658095523896903\n",
      "Epoch 162, Loss: 0.40512626457546647\n",
      "Epoch 163, Loss: 0.40398715774973465\n",
      "Epoch 164, Loss: 0.4038445711541515\n",
      "Epoch 165, Loss: 0.40386392382679204\n",
      "Epoch 166, Loss: 0.40389323702422886\n",
      "Epoch 167, Loss: 0.40244939953966213\n",
      "Epoch 168, Loss: 0.4015316776959462\n",
      "Epoch 169, Loss: 0.401382817244816\n",
      "Epoch 170, Loss: 0.4015489709556655\n",
      "Epoch 171, Loss: 0.40240816878370633\n",
      "Epoch 172, Loss: 0.4009293258499747\n",
      "Epoch 173, Loss: 0.3997232783799706\n",
      "Epoch 174, Loss: 0.39878386981463176\n",
      "Epoch 175, Loss: 0.39881473335701306\n",
      "Epoch 176, Loss: 0.39943321946891197\n",
      "Epoch 177, Loss: 0.39886221968792707\n",
      "Epoch 178, Loss: 0.3983175994879416\n",
      "Epoch 179, Loss: 0.39690926997089526\n",
      "Epoch 180, Loss: 0.39621372098940694\n",
      "Epoch 181, Loss: 0.3961096435006662\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.23178272500793695\n",
      "Test R^2 score: 0.4205526153830635\n",
      "Num of epochs: 182\n",
      "Epoch 1, Loss: 0.5613013317533427\n",
      "Epoch 2, Loss: 0.5602800751137127\n",
      "Epoch 3, Loss: 0.559378732636854\n",
      "Epoch 4, Loss: 0.558586867496799\n",
      "Epoch 5, Loss: 0.5579013935284357\n",
      "Epoch 6, Loss: 0.5573459373026952\n",
      "Epoch 7, Loss: 0.5569048873296469\n",
      "Epoch 8, Loss: 0.5565757579820066\n",
      "Epoch 9, Loss: 0.55635197165558\n",
      "Epoch 10, Loss: 0.5562261276265921\n",
      "Epoch 11, Loss: 0.5561768590867503\n",
      "Epoch 12, Loss: 0.5561876026260207\n",
      "Epoch 13, Loss: 0.5562360933258486\n",
      "Epoch 14, Loss: 0.5563001160065569\n",
      "Epoch 15, Loss: 0.5563698896586053\n",
      "Epoch 16, Loss: 0.5564190072040922\n",
      "Epoch 17, Loss: 0.5564358786428962\n",
      "Epoch 18, Loss: 0.5564329596527794\n",
      "Epoch 19, Loss: 0.5564058578391274\n",
      "Epoch 20, Loss: 0.5563588282390983\n",
      "Epoch 21, Loss: 0.5562983481151379\n",
      "Epoch 22, Loss: 0.5562323428148239\n",
      "Epoch 23, Loss: 0.5561638647532262\n",
      "Epoch 24, Loss: 0.5560947887457042\n",
      "Epoch 25, Loss: 0.5560261061477687\n",
      "Epoch 26, Loss: 0.5559585407771971\n",
      "Epoch 27, Loss: 0.5558911816416502\n",
      "Epoch 28, Loss: 0.555821535560999\n",
      "Epoch 29, Loss: 0.5557452579970376\n",
      "Epoch 30, Loss: 0.5556576800524543\n",
      "Epoch 31, Loss: 0.5555544243907009\n",
      "Epoch 32, Loss: 0.555429741070484\n",
      "Epoch 33, Loss: 0.5552809321286504\n",
      "Epoch 34, Loss: 0.5551146622081523\n",
      "Epoch 35, Loss: 0.5549081981186705\n",
      "Epoch 36, Loss: 0.5546419098077228\n",
      "Epoch 37, Loss: 0.5543064904269454\n",
      "Epoch 38, Loss: 0.5538890357093315\n",
      "Epoch 39, Loss: 0.5533927258775488\n",
      "Epoch 40, Loss: 0.5527954067867481\n",
      "Epoch 41, Loss: 0.5520911905941159\n",
      "Epoch 42, Loss: 0.5512447436075606\n",
      "Epoch 43, Loss: 0.5501888416953835\n",
      "Epoch 44, Loss: 0.5488704244257434\n",
      "Epoch 45, Loss: 0.5472269288240931\n",
      "Epoch 46, Loss: 0.5452205974009474\n",
      "Epoch 47, Loss: 0.5428118856511128\n",
      "Epoch 48, Loss: 0.539946784470298\n",
      "Epoch 49, Loss: 0.536470345174387\n",
      "Epoch 50, Loss: 0.5322721969218929\n",
      "Epoch 51, Loss: 0.5273129206935266\n",
      "Epoch 52, Loss: 0.5214882325447651\n",
      "Epoch 53, Loss: 0.514850034082061\n",
      "Epoch 54, Loss: 0.5075721465350687\n",
      "Epoch 55, Loss: 0.4998101082463511\n",
      "Epoch 56, Loss: 0.49226138150787047\n",
      "Epoch 57, Loss: 0.48623726850184584\n",
      "Epoch 58, Loss: 0.4825937683030372\n",
      "Epoch 59, Loss: 0.479917473602853\n",
      "Epoch 60, Loss: 0.4777774800701963\n",
      "Epoch 61, Loss: 0.47799144762061513\n",
      "Epoch 62, Loss: 0.4788605361701842\n",
      "Epoch 63, Loss: 0.47755614642142985\n",
      "Epoch 64, Loss: 0.47522902363252734\n",
      "Epoch 65, Loss: 0.47321293103211826\n",
      "Epoch 66, Loss: 0.4720517856811812\n",
      "Epoch 67, Loss: 0.4708958939396986\n",
      "Epoch 68, Loss: 0.4700050717952681\n",
      "Epoch 69, Loss: 0.4692888976870645\n",
      "Epoch 70, Loss: 0.4688127157853879\n",
      "Epoch 71, Loss: 0.46814794023275175\n",
      "Epoch 72, Loss: 0.467345119284279\n",
      "Epoch 73, Loss: 0.4664519084773612\n",
      "Epoch 74, Loss: 0.46551532477773544\n",
      "Epoch 75, Loss: 0.46452086318048275\n",
      "Epoch 76, Loss: 0.4634092781234979\n",
      "Epoch 77, Loss: 0.4622483283993178\n",
      "Epoch 78, Loss: 0.461084100072253\n",
      "Epoch 79, Loss: 0.46009343662522045\n",
      "Epoch 80, Loss: 0.459037274497912\n",
      "Epoch 81, Loss: 0.4582890377169853\n",
      "Epoch 82, Loss: 0.45759202511063796\n",
      "Epoch 83, Loss: 0.45673509115035277\n",
      "Epoch 84, Loss: 0.4558728527440053\n",
      "Epoch 85, Loss: 0.4551397781193945\n",
      "Epoch 86, Loss: 0.45443623013477025\n",
      "Epoch 87, Loss: 0.45380932007697217\n",
      "Epoch 88, Loss: 0.45331097765395667\n",
      "Epoch 89, Loss: 0.452874657107757\n",
      "Epoch 90, Loss: 0.4524162767999646\n",
      "Epoch 91, Loss: 0.4519147990205329\n",
      "Epoch 92, Loss: 0.4514007813362404\n",
      "Epoch 93, Loss: 0.4508482527893705\n",
      "Epoch 94, Loss: 0.45027105393502354\n",
      "Epoch 95, Loss: 0.4497067993030923\n",
      "Epoch 96, Loss: 0.44917836215033274\n",
      "Epoch 97, Loss: 0.448678114268292\n",
      "Epoch 98, Loss: 0.4481835586668195\n",
      "Epoch 99, Loss: 0.44768384678644335\n",
      "Epoch 100, Loss: 0.4471714970186443\n",
      "Epoch 101, Loss: 0.4466543559909186\n",
      "Epoch 102, Loss: 0.4461172261382461\n",
      "Epoch 103, Loss: 0.44558297693461735\n",
      "Epoch 104, Loss: 0.4449952651961387\n",
      "Epoch 105, Loss: 0.44440421114384737\n",
      "Epoch 106, Loss: 0.44382529627310335\n",
      "Epoch 107, Loss: 0.4431924547739667\n",
      "Epoch 108, Loss: 0.442596619666542\n",
      "Epoch 109, Loss: 0.4420069936041526\n",
      "Epoch 110, Loss: 0.44142098528817675\n",
      "Epoch 111, Loss: 0.44079375180672786\n",
      "Epoch 112, Loss: 0.4401486805030348\n",
      "Epoch 113, Loss: 0.43952685267489366\n",
      "Epoch 114, Loss: 0.43885669500475427\n",
      "Epoch 115, Loss: 0.43821276777392953\n",
      "Epoch 116, Loss: 0.4375824509992381\n",
      "Epoch 117, Loss: 0.4369910720124879\n",
      "Epoch 118, Loss: 0.4364195322377648\n",
      "Epoch 119, Loss: 0.4358653285674127\n",
      "Epoch 120, Loss: 0.43530350458801215\n",
      "Epoch 121, Loss: 0.4347565326956659\n",
      "Epoch 122, Loss: 0.4342064180438366\n",
      "Epoch 123, Loss: 0.4336667729652992\n",
      "Epoch 124, Loss: 0.43309961979474343\n",
      "Epoch 125, Loss: 0.43252758880778897\n",
      "Epoch 126, Loss: 0.4319499879261893\n",
      "Epoch 127, Loss: 0.43135997226950235\n",
      "Epoch 128, Loss: 0.43076747076656186\n",
      "Epoch 129, Loss: 0.43016499084726095\n",
      "Epoch 130, Loss: 0.4295690546644346\n",
      "Epoch 131, Loss: 0.4289497631353811\n",
      "Epoch 132, Loss: 0.42830482312264967\n",
      "Epoch 133, Loss: 0.4276589627610211\n",
      "Epoch 134, Loss: 0.42702119848241904\n",
      "Epoch 135, Loss: 0.42639270239556043\n",
      "Epoch 136, Loss: 0.4257640660169317\n",
      "Epoch 137, Loss: 0.4251421585467537\n",
      "Epoch 138, Loss: 0.4245106523534185\n",
      "Epoch 139, Loss: 0.4238551786024242\n",
      "Epoch 140, Loss: 0.42319504528561513\n",
      "Epoch 141, Loss: 0.4225522010201522\n",
      "Epoch 142, Loss: 0.42191401054015404\n",
      "Epoch 143, Loss: 0.42128189215219597\n",
      "Epoch 144, Loss: 0.4206764892817003\n",
      "Epoch 145, Loss: 0.420281969968253\n",
      "Epoch 146, Loss: 0.42042585780012054\n",
      "Epoch 147, Loss: 0.4198356539900759\n",
      "Epoch 148, Loss: 0.4183860371390083\n",
      "Epoch 149, Loss: 0.4187041969301254\n",
      "Epoch 150, Loss: 0.4177167257415588\n",
      "Epoch 151, Loss: 0.417069957190292\n",
      "Epoch 152, Loss: 0.4169567727409509\n",
      "Epoch 153, Loss: 0.41586119960088663\n",
      "Epoch 154, Loss: 0.4160519973543275\n",
      "Epoch 155, Loss: 0.4150171072145567\n",
      "Epoch 156, Loss: 0.41480102893808407\n",
      "Epoch 157, Loss: 0.4142983322794111\n",
      "Epoch 158, Loss: 0.4136275760320255\n",
      "Epoch 159, Loss: 0.4135729396759755\n",
      "Epoch 160, Loss: 0.41269925463590423\n",
      "Epoch 161, Loss: 0.4125010902216983\n",
      "Epoch 162, Loss: 0.41201857158552346\n",
      "Epoch 163, Loss: 0.41142505398497464\n",
      "Epoch 164, Loss: 0.4112156039350341\n",
      "Epoch 165, Loss: 0.41059710107375513\n",
      "Epoch 166, Loss: 0.41021157754390475\n",
      "Epoch 167, Loss: 0.40989798634540076\n",
      "Epoch 168, Loss: 0.4092096941376696\n",
      "Epoch 169, Loss: 0.4088999262996037\n",
      "Epoch 170, Loss: 0.40849434352703173\n",
      "Epoch 171, Loss: 0.4079468209937741\n",
      "Epoch 172, Loss: 0.40753738287432706\n",
      "Epoch 173, Loss: 0.4071894384061356\n",
      "Epoch 174, Loss: 0.40674471077296526\n",
      "Epoch 175, Loss: 0.40622423163632504\n",
      "Epoch 176, Loss: 0.40582800001338487\n",
      "Epoch 177, Loss: 0.4054453106170918\n",
      "Epoch 178, Loss: 0.40505863609996157\n",
      "Epoch 179, Loss: 0.40464655179268294\n",
      "Epoch 180, Loss: 0.40418835349086474\n",
      "Epoch 181, Loss: 0.40373059480052553\n",
      "Epoch 182, Loss: 0.40331138988905463\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.23031677320472288\n",
      "Test R^2 score: 0.42530947986621076\n",
      "Num of epochs: 183\n",
      "Epoch 1, Loss: 0.5745079713472568\n",
      "Epoch 2, Loss: 0.5725604394801315\n",
      "Epoch 3, Loss: 0.5707287510439112\n",
      "Epoch 4, Loss: 0.569008132499341\n",
      "Epoch 5, Loss: 0.567255422765468\n",
      "Epoch 6, Loss: 0.5656602089814322\n",
      "Epoch 7, Loss: 0.564175837957345\n",
      "Epoch 8, Loss: 0.5627939992402423\n",
      "Epoch 9, Loss: 0.5615630558798729\n",
      "Epoch 10, Loss: 0.5604909942100824\n",
      "Epoch 11, Loss: 0.5595310057570567\n",
      "Epoch 12, Loss: 0.5587143134342049\n",
      "Epoch 13, Loss: 0.557991556872818\n",
      "Epoch 14, Loss: 0.55738074639475\n",
      "Epoch 15, Loss: 0.5568772197983123\n",
      "Epoch 16, Loss: 0.5564853116913506\n",
      "Epoch 17, Loss: 0.5562076691797307\n",
      "Epoch 18, Loss: 0.556035485855611\n",
      "Epoch 19, Loss: 0.5559762570453963\n",
      "Epoch 20, Loss: 0.5559396177855151\n",
      "Epoch 21, Loss: 0.5559518400747617\n",
      "Epoch 22, Loss: 0.5559908102291486\n",
      "Epoch 23, Loss: 0.5560043178157419\n",
      "Epoch 24, Loss: 0.5559572006431709\n",
      "Epoch 25, Loss: 0.5558512662294787\n",
      "Epoch 26, Loss: 0.5556676023132526\n",
      "Epoch 27, Loss: 0.5553922608582599\n",
      "Epoch 28, Loss: 0.555005586785043\n",
      "Epoch 29, Loss: 0.554481414335536\n",
      "Epoch 30, Loss: 0.5538128417633624\n",
      "Epoch 31, Loss: 0.5530203898156187\n",
      "Epoch 32, Loss: 0.5520959678739658\n",
      "Epoch 33, Loss: 0.5510180079447694\n",
      "Epoch 34, Loss: 0.5497318849757937\n",
      "Epoch 35, Loss: 0.5482225165186365\n",
      "Epoch 36, Loss: 0.5464641662743978\n",
      "Epoch 37, Loss: 0.5444323073572948\n",
      "Epoch 38, Loss: 0.5420964870963232\n",
      "Epoch 39, Loss: 0.5393983927811358\n",
      "Epoch 40, Loss: 0.5362313880002451\n",
      "Epoch 41, Loss: 0.5325715233224498\n",
      "Epoch 42, Loss: 0.5282798934959725\n",
      "Epoch 43, Loss: 0.5233265203996285\n",
      "Epoch 44, Loss: 0.5178512716195403\n",
      "Epoch 45, Loss: 0.5122668119588123\n",
      "Epoch 46, Loss: 0.507368803589344\n",
      "Epoch 47, Loss: 0.5040158884405095\n",
      "Epoch 48, Loss: 0.501795911103531\n",
      "Epoch 49, Loss: 0.4985505044724737\n",
      "Epoch 50, Loss: 0.4938988376774447\n",
      "Epoch 51, Loss: 0.48924651294687765\n",
      "Epoch 52, Loss: 0.4857496781762864\n",
      "Epoch 53, Loss: 0.48360286204884995\n",
      "Epoch 54, Loss: 0.48231327517927775\n",
      "Epoch 55, Loss: 0.48134101217633357\n",
      "Epoch 56, Loss: 0.4803099020774141\n",
      "Epoch 57, Loss: 0.47890951332859794\n",
      "Epoch 58, Loss: 0.4772669479094514\n",
      "Epoch 59, Loss: 0.47582019778034884\n",
      "Epoch 60, Loss: 0.47448933029036855\n",
      "Epoch 61, Loss: 0.4729375238762637\n",
      "Epoch 62, Loss: 0.47114053560301083\n",
      "Epoch 63, Loss: 0.46948750017566765\n",
      "Epoch 64, Loss: 0.46822878151928343\n",
      "Epoch 65, Loss: 0.46717536617074246\n",
      "Epoch 66, Loss: 0.46623010424179856\n",
      "Epoch 67, Loss: 0.46543422029235376\n",
      "Epoch 68, Loss: 0.46475223634191026\n",
      "Epoch 69, Loss: 0.46385962229131117\n",
      "Epoch 70, Loss: 0.4626133567202436\n",
      "Epoch 71, Loss: 0.46127804606286166\n",
      "Epoch 72, Loss: 0.4603897493212658\n",
      "Epoch 73, Loss: 0.46002269743297564\n",
      "Epoch 74, Loss: 0.4596242299938418\n",
      "Epoch 75, Loss: 0.45878270365277707\n",
      "Epoch 76, Loss: 0.4577900708533761\n",
      "Epoch 77, Loss: 0.4571002679862015\n",
      "Epoch 78, Loss: 0.45669885921590553\n",
      "Epoch 79, Loss: 0.4562487138442632\n",
      "Epoch 80, Loss: 0.4556399794001303\n",
      "Epoch 81, Loss: 0.45498163403658426\n",
      "Epoch 82, Loss: 0.45433379766986726\n",
      "Epoch 83, Loss: 0.453679206254181\n",
      "Epoch 84, Loss: 0.45308224706547046\n",
      "Epoch 85, Loss: 0.4525823961764608\n",
      "Epoch 86, Loss: 0.45203235034037326\n",
      "Epoch 87, Loss: 0.451357468913494\n",
      "Epoch 88, Loss: 0.450716242739013\n",
      "Epoch 89, Loss: 0.45024944319259047\n",
      "Epoch 90, Loss: 0.4498066745172524\n",
      "Epoch 91, Loss: 0.4492212875957963\n",
      "Epoch 92, Loss: 0.44858936502990193\n",
      "Epoch 93, Loss: 0.4480398215792137\n",
      "Epoch 94, Loss: 0.44749541397515274\n",
      "Epoch 95, Loss: 0.4468921117907575\n",
      "Epoch 96, Loss: 0.44628680873443677\n",
      "Epoch 97, Loss: 0.4456948596345093\n",
      "Epoch 98, Loss: 0.4450659989855727\n",
      "Epoch 99, Loss: 0.4444565829301607\n",
      "Epoch 100, Loss: 0.443880841616642\n",
      "Epoch 101, Loss: 0.4432223776339588\n",
      "Epoch 102, Loss: 0.44254399409590645\n",
      "Epoch 103, Loss: 0.4418984428780602\n",
      "Epoch 104, Loss: 0.4412075371883519\n",
      "Epoch 105, Loss: 0.44050149268829447\n",
      "Epoch 106, Loss: 0.4398050213256946\n",
      "Epoch 107, Loss: 0.43907637659048326\n",
      "Epoch 108, Loss: 0.4383711486388343\n",
      "Epoch 109, Loss: 0.43760914803423906\n",
      "Epoch 110, Loss: 0.43687010447170016\n",
      "Epoch 111, Loss: 0.43614151053802896\n",
      "Epoch 112, Loss: 0.4354093360131685\n",
      "Epoch 113, Loss: 0.43467320284994926\n",
      "Epoch 114, Loss: 0.4339268066789735\n",
      "Epoch 115, Loss: 0.43319221324610374\n",
      "Epoch 116, Loss: 0.4324217240661523\n",
      "Epoch 117, Loss: 0.431668345394086\n",
      "Epoch 118, Loss: 0.43088726392666854\n",
      "Epoch 119, Loss: 0.4301221210036393\n",
      "Epoch 120, Loss: 0.42934666033399177\n",
      "Epoch 121, Loss: 0.4285733082423543\n",
      "Epoch 122, Loss: 0.4277940647508471\n",
      "Epoch 123, Loss: 0.42701938390733196\n",
      "Epoch 124, Loss: 0.426269583685698\n",
      "Epoch 125, Loss: 0.42554472556988654\n",
      "Epoch 126, Loss: 0.4248212613785954\n",
      "Epoch 127, Loss: 0.424103678065323\n",
      "Epoch 128, Loss: 0.4233605754840202\n",
      "Epoch 129, Loss: 0.4226061348810108\n",
      "Epoch 130, Loss: 0.42185476042622994\n",
      "Epoch 131, Loss: 0.42109880745138445\n",
      "Epoch 132, Loss: 0.4203619137331304\n",
      "Epoch 133, Loss: 0.419624045567795\n",
      "Epoch 134, Loss: 0.41890019171608633\n",
      "Epoch 135, Loss: 0.41820282486951676\n",
      "Epoch 136, Loss: 0.4175117347118897\n",
      "Epoch 137, Loss: 0.4169133131845582\n",
      "Epoch 138, Loss: 0.4162819954314415\n",
      "Epoch 139, Loss: 0.41549551603213675\n",
      "Epoch 140, Loss: 0.4146102305493855\n",
      "Epoch 141, Loss: 0.4138976974726943\n",
      "Epoch 142, Loss: 0.41331974924682047\n",
      "Epoch 143, Loss: 0.4127536817255909\n",
      "Epoch 144, Loss: 0.41209928671977153\n",
      "Epoch 145, Loss: 0.41130915685899805\n",
      "Epoch 146, Loss: 0.41050616279348245\n",
      "Epoch 147, Loss: 0.40974038249069966\n",
      "Epoch 148, Loss: 0.40910192948005014\n",
      "Epoch 149, Loss: 0.4085101018296269\n",
      "Epoch 150, Loss: 0.4080823874901115\n",
      "Epoch 151, Loss: 0.4081112881528755\n",
      "Epoch 152, Loss: 0.40816992300701677\n",
      "Epoch 153, Loss: 0.40677172831275293\n",
      "Epoch 154, Loss: 0.40526341805079785\n",
      "Epoch 155, Loss: 0.4058543626257309\n",
      "Epoch 156, Loss: 0.40530650911631577\n",
      "Epoch 157, Loss: 0.40373386120502386\n",
      "Epoch 158, Loss: 0.40399335442166634\n",
      "Epoch 159, Loss: 0.403412058003659\n",
      "Epoch 160, Loss: 0.4021443734095653\n",
      "Epoch 161, Loss: 0.40208838052826656\n",
      "Epoch 162, Loss: 0.4015895849214808\n",
      "Epoch 163, Loss: 0.40046246512158923\n",
      "Epoch 164, Loss: 0.40055871552030553\n",
      "Epoch 165, Loss: 0.3999324875720336\n",
      "Epoch 166, Loss: 0.3990760809574687\n",
      "Epoch 167, Loss: 0.3988586892308033\n",
      "Epoch 168, Loss: 0.39864915947896684\n",
      "Epoch 169, Loss: 0.3976712806723898\n",
      "Epoch 170, Loss: 0.39731737773110004\n",
      "Epoch 171, Loss: 0.3972104757283129\n",
      "Epoch 172, Loss: 0.3966670249822478\n",
      "Epoch 173, Loss: 0.39593836578780295\n",
      "Epoch 174, Loss: 0.39557660293452024\n",
      "Epoch 175, Loss: 0.39551640253981823\n",
      "Epoch 176, Loss: 0.39496731973010774\n",
      "Epoch 177, Loss: 0.3944189270571871\n",
      "Epoch 178, Loss: 0.39392655365309426\n",
      "Epoch 179, Loss: 0.39371562913714\n",
      "Epoch 180, Loss: 0.3934248338498159\n",
      "Epoch 181, Loss: 0.393003375763263\n",
      "Epoch 182, Loss: 0.39259657175935203\n",
      "Epoch 183, Loss: 0.3921263833317967\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.23710620412137104\n",
      "Test R^2 score: 0.3880998215095356\n",
      "Num of epochs: 184\n",
      "Epoch 1, Loss: 0.5885979082584964\n",
      "Epoch 2, Loss: 0.5857525088427059\n",
      "Epoch 3, Loss: 0.583193188817081\n",
      "Epoch 4, Loss: 0.5808560071794967\n",
      "Epoch 5, Loss: 0.5785905922090923\n",
      "Epoch 6, Loss: 0.5764044599332078\n",
      "Epoch 7, Loss: 0.5742929371768983\n",
      "Epoch 8, Loss: 0.5721526311044985\n",
      "Epoch 9, Loss: 0.570115460363466\n",
      "Epoch 10, Loss: 0.5682253335414963\n",
      "Epoch 11, Loss: 0.5664602845824647\n",
      "Epoch 12, Loss: 0.5648188742492912\n",
      "Epoch 13, Loss: 0.5633087172669566\n",
      "Epoch 14, Loss: 0.5619366526910747\n",
      "Epoch 15, Loss: 0.5607082918738817\n",
      "Epoch 16, Loss: 0.5595990984105038\n",
      "Epoch 17, Loss: 0.5586352299581323\n",
      "Epoch 18, Loss: 0.5578321854139145\n",
      "Epoch 19, Loss: 0.5571857125878882\n",
      "Epoch 20, Loss: 0.556713782070712\n",
      "Epoch 21, Loss: 0.5563695146988332\n",
      "Epoch 22, Loss: 0.5561469046818237\n",
      "Epoch 23, Loss: 0.556037334979343\n",
      "Epoch 24, Loss: 0.5559766590721632\n",
      "Epoch 25, Loss: 0.5559507143488289\n",
      "Epoch 26, Loss: 0.5558675383385903\n",
      "Epoch 27, Loss: 0.5558203023339081\n",
      "Epoch 28, Loss: 0.5557432470233127\n",
      "Epoch 29, Loss: 0.5555994837665837\n",
      "Epoch 30, Loss: 0.5553727282920463\n",
      "Epoch 31, Loss: 0.555046341567976\n",
      "Epoch 32, Loss: 0.5546088633069447\n",
      "Epoch 33, Loss: 0.5540448347654571\n",
      "Epoch 34, Loss: 0.5533460864882017\n",
      "Epoch 35, Loss: 0.5524914480643568\n",
      "Epoch 36, Loss: 0.5514593887126851\n",
      "Epoch 37, Loss: 0.5502238869144791\n",
      "Epoch 38, Loss: 0.5487286351939246\n",
      "Epoch 39, Loss: 0.5469160609497935\n",
      "Epoch 40, Loss: 0.5447560266491382\n",
      "Epoch 41, Loss: 0.5422710079557416\n",
      "Epoch 42, Loss: 0.5395095464217111\n",
      "Epoch 43, Loss: 0.5364992595233766\n",
      "Epoch 44, Loss: 0.5332301485808117\n",
      "Epoch 45, Loss: 0.529773961665281\n",
      "Epoch 46, Loss: 0.5263646679536609\n",
      "Epoch 47, Loss: 0.5233830380930609\n",
      "Epoch 48, Loss: 0.5212171348438343\n",
      "Epoch 49, Loss: 0.5195262880016654\n",
      "Epoch 50, Loss: 0.5173985007626725\n",
      "Epoch 51, Loss: 0.5146081318716482\n",
      "Epoch 52, Loss: 0.5117676107360929\n",
      "Epoch 53, Loss: 0.5093276674711109\n",
      "Epoch 54, Loss: 0.5072271054000211\n",
      "Epoch 55, Loss: 0.5051134420203964\n",
      "Epoch 56, Loss: 0.5026789957057786\n",
      "Epoch 57, Loss: 0.49990226863347076\n",
      "Epoch 58, Loss: 0.49700790942881146\n",
      "Epoch 59, Loss: 0.4942326064312575\n",
      "Epoch 60, Loss: 0.4919412238971563\n",
      "Epoch 61, Loss: 0.4900738274659352\n",
      "Epoch 62, Loss: 0.48807089279819554\n",
      "Epoch 63, Loss: 0.48556633539706817\n",
      "Epoch 64, Loss: 0.48303841178892293\n",
      "Epoch 65, Loss: 0.480884728588382\n",
      "Epoch 66, Loss: 0.47905686578591467\n",
      "Epoch 67, Loss: 0.47730547412807806\n",
      "Epoch 68, Loss: 0.47547837750644156\n",
      "Epoch 69, Loss: 0.4736399699191395\n",
      "Epoch 70, Loss: 0.47200530128916557\n",
      "Epoch 71, Loss: 0.4706332997809861\n",
      "Epoch 72, Loss: 0.46930975870756064\n",
      "Epoch 73, Loss: 0.46791625580241686\n",
      "Epoch 74, Loss: 0.46656903887674356\n",
      "Epoch 75, Loss: 0.4654361412250821\n",
      "Epoch 76, Loss: 0.4644466595404235\n",
      "Epoch 77, Loss: 0.4634402428441026\n",
      "Epoch 78, Loss: 0.4623865851966789\n",
      "Epoch 79, Loss: 0.4614758176770616\n",
      "Epoch 80, Loss: 0.460738769622066\n",
      "Epoch 81, Loss: 0.45995089445063453\n",
      "Epoch 82, Loss: 0.45901528112368295\n",
      "Epoch 83, Loss: 0.45811215576547815\n",
      "Epoch 84, Loss: 0.4573571599956409\n",
      "Epoch 85, Loss: 0.4565857403145137\n",
      "Epoch 86, Loss: 0.45572151904274266\n",
      "Epoch 87, Loss: 0.4548763433563951\n",
      "Epoch 88, Loss: 0.45408292342459344\n",
      "Epoch 89, Loss: 0.4532545167705283\n",
      "Epoch 90, Loss: 0.4523645959507838\n",
      "Epoch 91, Loss: 0.4515075920803712\n",
      "Epoch 92, Loss: 0.4507162096779419\n",
      "Epoch 93, Loss: 0.44989601165574816\n",
      "Epoch 94, Loss: 0.4490778660650546\n",
      "Epoch 95, Loss: 0.4483329332035553\n",
      "Epoch 96, Loss: 0.44757905331084386\n",
      "Epoch 97, Loss: 0.4468033913278753\n",
      "Epoch 98, Loss: 0.44605851844313726\n",
      "Epoch 99, Loss: 0.445357638296629\n",
      "Epoch 100, Loss: 0.4446635956012379\n",
      "Epoch 101, Loss: 0.44397073346522814\n",
      "Epoch 102, Loss: 0.44329250352335114\n",
      "Epoch 103, Loss: 0.44258177201063836\n",
      "Epoch 104, Loss: 0.44184487416845897\n",
      "Epoch 105, Loss: 0.4411131636927872\n",
      "Epoch 106, Loss: 0.44036208350767103\n",
      "Epoch 107, Loss: 0.4395978901096559\n",
      "Epoch 108, Loss: 0.4388284439485086\n",
      "Epoch 109, Loss: 0.43802864628679494\n",
      "Epoch 110, Loss: 0.4372132758230774\n",
      "Epoch 111, Loss: 0.43640051354811615\n",
      "Epoch 112, Loss: 0.4355771178278955\n",
      "Epoch 113, Loss: 0.434754116320742\n",
      "Epoch 114, Loss: 0.4339222909107312\n",
      "Epoch 115, Loss: 0.43307496730053624\n",
      "Epoch 116, Loss: 0.4322335843818598\n",
      "Epoch 117, Loss: 0.431383479234811\n",
      "Epoch 118, Loss: 0.43054085004810233\n",
      "Epoch 119, Loss: 0.4296816565376368\n",
      "Epoch 120, Loss: 0.42883116615566685\n",
      "Epoch 121, Loss: 0.4279639616437584\n",
      "Epoch 122, Loss: 0.42711697616497957\n",
      "Epoch 123, Loss: 0.42625685910050665\n",
      "Epoch 124, Loss: 0.42541263968230286\n",
      "Epoch 125, Loss: 0.42456391625495954\n",
      "Epoch 126, Loss: 0.423739903141237\n",
      "Epoch 127, Loss: 0.42290367880109864\n",
      "Epoch 128, Loss: 0.4220411891677831\n",
      "Epoch 129, Loss: 0.4211895283498632\n",
      "Epoch 130, Loss: 0.42033764859658407\n",
      "Epoch 131, Loss: 0.4194826179604288\n",
      "Epoch 132, Loss: 0.41865787560287654\n",
      "Epoch 133, Loss: 0.4178170971842196\n",
      "Epoch 134, Loss: 0.41694254881246967\n",
      "Epoch 135, Loss: 0.4160753484847692\n",
      "Epoch 136, Loss: 0.41520757507941486\n",
      "Epoch 137, Loss: 0.41431708876249185\n",
      "Epoch 138, Loss: 0.41342648656568254\n",
      "Epoch 139, Loss: 0.4125962658017899\n",
      "Epoch 140, Loss: 0.4119141283392458\n",
      "Epoch 141, Loss: 0.4116747041772211\n",
      "Epoch 142, Loss: 0.4110545176710782\n",
      "Epoch 143, Loss: 0.40948287547173884\n",
      "Epoch 144, Loss: 0.40901714364919056\n",
      "Epoch 145, Loss: 0.4084788764537136\n",
      "Epoch 146, Loss: 0.40721377345798593\n",
      "Epoch 147, Loss: 0.4068597655659784\n",
      "Epoch 148, Loss: 0.4061039331912625\n",
      "Epoch 149, Loss: 0.40511903694163975\n",
      "Epoch 150, Loss: 0.40480015707347483\n",
      "Epoch 151, Loss: 0.40384850079951373\n",
      "Epoch 152, Loss: 0.403159897055266\n",
      "Epoch 153, Loss: 0.40271815684507156\n",
      "Epoch 154, Loss: 0.4018555058308952\n",
      "Epoch 155, Loss: 0.40131999757039943\n",
      "Epoch 156, Loss: 0.40087307032473685\n",
      "Epoch 157, Loss: 0.40012492225929847\n",
      "Epoch 158, Loss: 0.399507525638124\n",
      "Epoch 159, Loss: 0.39911478110880205\n",
      "Epoch 160, Loss: 0.3984948285316515\n",
      "Epoch 161, Loss: 0.39783089405694905\n",
      "Epoch 162, Loss: 0.3973664117456828\n",
      "Epoch 163, Loss: 0.3969373135945431\n",
      "Epoch 164, Loss: 0.39636226709269917\n",
      "Epoch 165, Loss: 0.39573743771214237\n",
      "Epoch 166, Loss: 0.39521660150429744\n",
      "Epoch 167, Loss: 0.3947750131655972\n",
      "Epoch 168, Loss: 0.3942680236165335\n",
      "Epoch 169, Loss: 0.39372622630086823\n",
      "Epoch 170, Loss: 0.39315988128151896\n",
      "Epoch 171, Loss: 0.39261516946644587\n",
      "Epoch 172, Loss: 0.39212921438971243\n",
      "Epoch 173, Loss: 0.3916532144705092\n",
      "Epoch 174, Loss: 0.39127210423608927\n",
      "Epoch 175, Loss: 0.39103025395697816\n",
      "Epoch 176, Loss: 0.39111882466591785\n",
      "Epoch 177, Loss: 0.39110118451979087\n",
      "Epoch 178, Loss: 0.39055327710686427\n",
      "Epoch 179, Loss: 0.3891299438236031\n",
      "Epoch 180, Loss: 0.38881546511896864\n",
      "Epoch 181, Loss: 0.3891810623354483\n",
      "Epoch 182, Loss: 0.3883615913396936\n",
      "Epoch 183, Loss: 0.38745530624443314\n",
      "Epoch 184, Loss: 0.3874286916709644\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.24732911498027474\n",
      "Test R^2 score: 0.33781165652025874\n",
      "Num of epochs: 185\n",
      "Epoch 1, Loss: 0.5790671841740226\n",
      "Epoch 2, Loss: 0.5772705465322002\n",
      "Epoch 3, Loss: 0.575676475526192\n",
      "Epoch 4, Loss: 0.5742551830956294\n",
      "Epoch 5, Loss: 0.5729199727280913\n",
      "Epoch 6, Loss: 0.5716250483105988\n",
      "Epoch 7, Loss: 0.5703771894163387\n",
      "Epoch 8, Loss: 0.5692087230903965\n",
      "Epoch 9, Loss: 0.5680897128704919\n",
      "Epoch 10, Loss: 0.5670151693040644\n",
      "Epoch 11, Loss: 0.566009145506108\n",
      "Epoch 12, Loss: 0.5650923650068851\n",
      "Epoch 13, Loss: 0.5642688014675958\n",
      "Epoch 14, Loss: 0.5634878015306376\n",
      "Epoch 15, Loss: 0.5627375472007312\n",
      "Epoch 16, Loss: 0.5620191426122403\n",
      "Epoch 17, Loss: 0.5613304536329162\n",
      "Epoch 18, Loss: 0.5606711911040845\n",
      "Epoch 19, Loss: 0.5600410332292194\n",
      "Epoch 20, Loss: 0.5594374414042694\n",
      "Epoch 21, Loss: 0.5588612749465949\n",
      "Epoch 22, Loss: 0.5584256379373154\n",
      "Epoch 23, Loss: 0.5579403877580977\n",
      "Epoch 24, Loss: 0.5574559180617987\n",
      "Epoch 25, Loss: 0.5570106748657225\n",
      "Epoch 26, Loss: 0.5565961318052635\n",
      "Epoch 27, Loss: 0.5561413047974358\n",
      "Epoch 28, Loss: 0.555613108144028\n",
      "Epoch 29, Loss: 0.5550154401590339\n",
      "Epoch 30, Loss: 0.5543118400247214\n",
      "Epoch 31, Loss: 0.5534491618223923\n",
      "Epoch 32, Loss: 0.5523327827713701\n",
      "Epoch 33, Loss: 0.5508683318428538\n",
      "Epoch 34, Loss: 0.5489486887722197\n",
      "Epoch 35, Loss: 0.5465294700051326\n",
      "Epoch 36, Loss: 0.5436258250984812\n",
      "Epoch 37, Loss: 0.5402904291096369\n",
      "Epoch 38, Loss: 0.5365787451211659\n",
      "Epoch 39, Loss: 0.5328071717026608\n",
      "Epoch 40, Loss: 0.5298095978754932\n",
      "Epoch 41, Loss: 0.5286981497247888\n",
      "Epoch 42, Loss: 0.5292878097377237\n",
      "Epoch 43, Loss: 0.5285848071824372\n",
      "Epoch 44, Loss: 0.5255421983542833\n",
      "Epoch 45, Loss: 0.5217628735451558\n",
      "Epoch 46, Loss: 0.5188141369524407\n",
      "Epoch 47, Loss: 0.5170740227804995\n",
      "Epoch 48, Loss: 0.5160012461920779\n",
      "Epoch 49, Loss: 0.5149050223165782\n",
      "Epoch 50, Loss: 0.5133944150059917\n",
      "Epoch 51, Loss: 0.5113507469074811\n",
      "Epoch 52, Loss: 0.5089214833561913\n",
      "Epoch 53, Loss: 0.5064886884433575\n",
      "Epoch 54, Loss: 0.5045741777773306\n",
      "Epoch 55, Loss: 0.5034009780754557\n",
      "Epoch 56, Loss: 0.5025322389936302\n",
      "Epoch 57, Loss: 0.5011550258263056\n",
      "Epoch 58, Loss: 0.49917501696807576\n",
      "Epoch 59, Loss: 0.49729118611099854\n",
      "Epoch 60, Loss: 0.49585866990256405\n",
      "Epoch 61, Loss: 0.4946809912594981\n",
      "Epoch 62, Loss: 0.49333558074282463\n",
      "Epoch 63, Loss: 0.4916957790705238\n",
      "Epoch 64, Loss: 0.4897775383207885\n",
      "Epoch 65, Loss: 0.4879342791877459\n",
      "Epoch 66, Loss: 0.48623225787726765\n",
      "Epoch 67, Loss: 0.4843011153691327\n",
      "Epoch 68, Loss: 0.48202821368925863\n",
      "Epoch 69, Loss: 0.4797439225156286\n",
      "Epoch 70, Loss: 0.4775739473733972\n",
      "Epoch 71, Loss: 0.47525200683956653\n",
      "Epoch 72, Loss: 0.4726078386971974\n",
      "Epoch 73, Loss: 0.4699310048168534\n",
      "Epoch 74, Loss: 0.46764818079417264\n",
      "Epoch 75, Loss: 0.4658888120689216\n",
      "Epoch 76, Loss: 0.4647619351746968\n",
      "Epoch 77, Loss: 0.46449431741213476\n",
      "Epoch 78, Loss: 0.46450127880569186\n",
      "Epoch 79, Loss: 0.4641097227788188\n",
      "Epoch 80, Loss: 0.46312545099378033\n",
      "Epoch 81, Loss: 0.4618235654673291\n",
      "Epoch 82, Loss: 0.46044467183494464\n",
      "Epoch 83, Loss: 0.45920768337666995\n",
      "Epoch 84, Loss: 0.45818192155694587\n",
      "Epoch 85, Loss: 0.45746295461078845\n",
      "Epoch 86, Loss: 0.4569210506510433\n",
      "Epoch 87, Loss: 0.45635416135227064\n",
      "Epoch 88, Loss: 0.45572820572524714\n",
      "Epoch 89, Loss: 0.4550831675761732\n",
      "Epoch 90, Loss: 0.4543915345752905\n",
      "Epoch 91, Loss: 0.45365265017386736\n",
      "Epoch 92, Loss: 0.4529047463587592\n",
      "Epoch 93, Loss: 0.4521559185290771\n",
      "Epoch 94, Loss: 0.4513914556511829\n",
      "Epoch 95, Loss: 0.4506595229047277\n",
      "Epoch 96, Loss: 0.4499949011248891\n",
      "Epoch 97, Loss: 0.44935900944894835\n",
      "Epoch 98, Loss: 0.44872552082376477\n",
      "Epoch 99, Loss: 0.4480982863206366\n",
      "Epoch 100, Loss: 0.44742612998914777\n",
      "Epoch 101, Loss: 0.4467002927283461\n",
      "Epoch 102, Loss: 0.44599890093069267\n",
      "Epoch 103, Loss: 0.4453612183808178\n",
      "Epoch 104, Loss: 0.44474749945140785\n",
      "Epoch 105, Loss: 0.44415992352673433\n",
      "Epoch 106, Loss: 0.4435901797299752\n",
      "Epoch 107, Loss: 0.4430337121548917\n",
      "Epoch 108, Loss: 0.44251392434189624\n",
      "Epoch 109, Loss: 0.4419766007396193\n",
      "Epoch 110, Loss: 0.4414105710518588\n",
      "Epoch 111, Loss: 0.4408432399751943\n",
      "Epoch 112, Loss: 0.4402663949527216\n",
      "Epoch 113, Loss: 0.43969684200488857\n",
      "Epoch 114, Loss: 0.43913505063389807\n",
      "Epoch 115, Loss: 0.43857816270963107\n",
      "Epoch 116, Loss: 0.43802650310401503\n",
      "Epoch 117, Loss: 0.4374764640471875\n",
      "Epoch 118, Loss: 0.43691986653101256\n",
      "Epoch 119, Loss: 0.4363735718311727\n",
      "Epoch 120, Loss: 0.4358419436661248\n",
      "Epoch 121, Loss: 0.4353213218019631\n",
      "Epoch 122, Loss: 0.4348018415229565\n",
      "Epoch 123, Loss: 0.4342781027428471\n",
      "Epoch 124, Loss: 0.4337468091918815\n",
      "Epoch 125, Loss: 0.43319898969707693\n",
      "Epoch 126, Loss: 0.4326194263684484\n",
      "Epoch 127, Loss: 0.43198077577846694\n",
      "Epoch 128, Loss: 0.4313532187457502\n",
      "Epoch 129, Loss: 0.43074112805967635\n",
      "Epoch 130, Loss: 0.430093486764466\n",
      "Epoch 131, Loss: 0.4294989432254176\n",
      "Epoch 132, Loss: 0.42896320680527317\n",
      "Epoch 133, Loss: 0.4283191741775158\n",
      "Epoch 134, Loss: 0.427647133208422\n",
      "Epoch 135, Loss: 0.4270679385814391\n",
      "Epoch 136, Loss: 0.4264433551158816\n",
      "Epoch 137, Loss: 0.42580884441585426\n",
      "Epoch 138, Loss: 0.42506462124795974\n",
      "Epoch 139, Loss: 0.42441116170510673\n",
      "Epoch 140, Loss: 0.42380600972642396\n",
      "Epoch 141, Loss: 0.42328866123429615\n",
      "Epoch 142, Loss: 0.4228073343664876\n",
      "Epoch 143, Loss: 0.42230663470951196\n",
      "Epoch 144, Loss: 0.4217349102405107\n",
      "Epoch 145, Loss: 0.42114620483605986\n",
      "Epoch 146, Loss: 0.4206346185103103\n",
      "Epoch 147, Loss: 0.4201259915375068\n",
      "Epoch 148, Loss: 0.419588941731074\n",
      "Epoch 149, Loss: 0.4190162118527188\n",
      "Epoch 150, Loss: 0.4184310709179504\n",
      "Epoch 151, Loss: 0.41790640891935077\n",
      "Epoch 152, Loss: 0.4173987771579302\n",
      "Epoch 153, Loss: 0.4169519480959726\n",
      "Epoch 154, Loss: 0.4165943758559725\n",
      "Epoch 155, Loss: 0.4163018079540663\n",
      "Epoch 156, Loss: 0.41583057998301204\n",
      "Epoch 157, Loss: 0.4150517719791161\n",
      "Epoch 158, Loss: 0.41448228178014507\n",
      "Epoch 159, Loss: 0.41431054297223957\n",
      "Epoch 160, Loss: 0.41390622986807507\n",
      "Epoch 161, Loss: 0.4131599522289079\n",
      "Epoch 162, Loss: 0.4125489877742712\n",
      "Epoch 163, Loss: 0.41234675797683995\n",
      "Epoch 164, Loss: 0.4121997969082254\n",
      "Epoch 165, Loss: 0.41159222231213516\n",
      "Epoch 166, Loss: 0.4108590417379307\n",
      "Epoch 167, Loss: 0.41035325904724257\n",
      "Epoch 168, Loss: 0.4101766672048087\n",
      "Epoch 169, Loss: 0.4098584683589921\n",
      "Epoch 170, Loss: 0.40934127493981626\n",
      "Epoch 171, Loss: 0.4087061178642742\n",
      "Epoch 172, Loss: 0.40822068318108784\n",
      "Epoch 173, Loss: 0.40795098507501926\n",
      "Epoch 174, Loss: 0.4076812364809686\n",
      "Epoch 175, Loss: 0.40736553281684995\n",
      "Epoch 176, Loss: 0.40709665911457843\n",
      "Epoch 177, Loss: 0.4064886969124513\n",
      "Epoch 178, Loss: 0.4057982574059798\n",
      "Epoch 179, Loss: 0.4051595137082546\n",
      "Epoch 180, Loss: 0.4047579324768462\n",
      "Epoch 181, Loss: 0.40461348147609255\n",
      "Epoch 182, Loss: 0.40449425122569455\n",
      "Epoch 183, Loss: 0.40437413827253027\n",
      "Epoch 184, Loss: 0.40349290678579985\n",
      "Epoch 185, Loss: 0.4026640940780333\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22041102349041006\n",
      "Test R^2 score: 0.47233039292793955\n",
      "Num of epochs: 186\n",
      "Epoch 1, Loss: 0.5816875697572707\n",
      "Epoch 2, Loss: 0.5797511248361747\n",
      "Epoch 3, Loss: 0.5779051233700523\n",
      "Epoch 4, Loss: 0.5761812370962108\n",
      "Epoch 5, Loss: 0.5745175421155577\n",
      "Epoch 6, Loss: 0.5729150569777561\n",
      "Epoch 7, Loss: 0.5713757049849957\n",
      "Epoch 8, Loss: 0.5700013605319065\n",
      "Epoch 9, Loss: 0.5687235029566854\n",
      "Epoch 10, Loss: 0.5675255338243269\n",
      "Epoch 11, Loss: 0.5663966474047945\n",
      "Epoch 12, Loss: 0.5653181740226696\n",
      "Epoch 13, Loss: 0.5643176275855398\n",
      "Epoch 14, Loss: 0.5634149686314479\n",
      "Epoch 15, Loss: 0.562553350249813\n",
      "Epoch 16, Loss: 0.5617369403466984\n",
      "Epoch 17, Loss: 0.5609812366149289\n",
      "Epoch 18, Loss: 0.5602851017190791\n",
      "Epoch 19, Loss: 0.5596452965684527\n",
      "Epoch 20, Loss: 0.559063134019811\n",
      "Epoch 21, Loss: 0.5585389010303878\n",
      "Epoch 22, Loss: 0.5580717462078524\n",
      "Epoch 23, Loss: 0.557659595166298\n",
      "Epoch 24, Loss: 0.5573645451983842\n",
      "Epoch 25, Loss: 0.5571031489256383\n",
      "Epoch 26, Loss: 0.5568745171901267\n",
      "Epoch 27, Loss: 0.5566775661056278\n",
      "Epoch 28, Loss: 0.5565050461943892\n",
      "Epoch 29, Loss: 0.5563459185077138\n",
      "Epoch 30, Loss: 0.5561855932516603\n",
      "Epoch 31, Loss: 0.555999011303002\n",
      "Epoch 32, Loss: 0.5557588788008401\n",
      "Epoch 33, Loss: 0.5554275143282577\n",
      "Epoch 34, Loss: 0.5549876784340146\n",
      "Epoch 35, Loss: 0.5544647790491101\n",
      "Epoch 36, Loss: 0.5538098820412547\n",
      "Epoch 37, Loss: 0.5531267316974321\n",
      "Epoch 38, Loss: 0.5523574676321035\n",
      "Epoch 39, Loss: 0.551390047643337\n",
      "Epoch 40, Loss: 0.5501250558344755\n",
      "Epoch 41, Loss: 0.5484886341221388\n",
      "Epoch 42, Loss: 0.5462458124589485\n",
      "Epoch 43, Loss: 0.5434592247821859\n",
      "Epoch 44, Loss: 0.5405098654687414\n",
      "Epoch 45, Loss: 0.5375724045091954\n",
      "Epoch 46, Loss: 0.5347883811773477\n",
      "Epoch 47, Loss: 0.5318474495517738\n",
      "Epoch 48, Loss: 0.5287904745081526\n",
      "Epoch 49, Loss: 0.5258521849804227\n",
      "Epoch 50, Loss: 0.5230323305166137\n",
      "Epoch 51, Loss: 0.5202584590856578\n",
      "Epoch 52, Loss: 0.5175305614569358\n",
      "Epoch 53, Loss: 0.5151462065921283\n",
      "Epoch 54, Loss: 0.5130138461287462\n",
      "Epoch 55, Loss: 0.5106849127724825\n",
      "Epoch 56, Loss: 0.5084164769023763\n",
      "Epoch 57, Loss: 0.5063142241253308\n",
      "Epoch 58, Loss: 0.504234029930247\n",
      "Epoch 59, Loss: 0.5020604890820846\n",
      "Epoch 60, Loss: 0.5000456252739099\n",
      "Epoch 61, Loss: 0.4982422389408386\n",
      "Epoch 62, Loss: 0.4964977181575236\n",
      "Epoch 63, Loss: 0.4945994873938505\n",
      "Epoch 64, Loss: 0.49247715011104853\n",
      "Epoch 65, Loss: 0.49026393421315695\n",
      "Epoch 66, Loss: 0.48819434346227686\n",
      "Epoch 67, Loss: 0.48636069437683155\n",
      "Epoch 68, Loss: 0.48459248121138176\n",
      "Epoch 69, Loss: 0.48278785445139044\n",
      "Epoch 70, Loss: 0.48099425505837623\n",
      "Epoch 71, Loss: 0.4792334641323604\n",
      "Epoch 72, Loss: 0.47761639551989504\n",
      "Epoch 73, Loss: 0.47609049451345326\n",
      "Epoch 74, Loss: 0.47446547787541826\n",
      "Epoch 75, Loss: 0.47280603983033975\n",
      "Epoch 76, Loss: 0.4711854133817812\n",
      "Epoch 77, Loss: 0.46969114237456144\n",
      "Epoch 78, Loss: 0.46831875673475226\n",
      "Epoch 79, Loss: 0.4669530280146467\n",
      "Epoch 80, Loss: 0.4656085926723843\n",
      "Epoch 81, Loss: 0.4643119045484306\n",
      "Epoch 82, Loss: 0.46308904330637185\n",
      "Epoch 83, Loss: 0.4618832858198011\n",
      "Epoch 84, Loss: 0.46069500897086424\n",
      "Epoch 85, Loss: 0.4595640539544845\n",
      "Epoch 86, Loss: 0.45851591837216\n",
      "Epoch 87, Loss: 0.45752532857603057\n",
      "Epoch 88, Loss: 0.45654949652752985\n",
      "Epoch 89, Loss: 0.4556352373236786\n",
      "Epoch 90, Loss: 0.4548132293273857\n",
      "Epoch 91, Loss: 0.45402860978386983\n",
      "Epoch 92, Loss: 0.4532387524906716\n",
      "Epoch 93, Loss: 0.4524336506479173\n",
      "Epoch 94, Loss: 0.4515898448755975\n",
      "Epoch 95, Loss: 0.4507167386547883\n",
      "Epoch 96, Loss: 0.4498770658472638\n",
      "Epoch 97, Loss: 0.44902682973037467\n",
      "Epoch 98, Loss: 0.4481170745638245\n",
      "Epoch 99, Loss: 0.4472192132182545\n",
      "Epoch 100, Loss: 0.446299947192723\n",
      "Epoch 101, Loss: 0.4453833005069031\n",
      "Epoch 102, Loss: 0.44446773041712345\n",
      "Epoch 103, Loss: 0.4435131125742669\n",
      "Epoch 104, Loss: 0.4425581527742108\n",
      "Epoch 105, Loss: 0.4415924725953066\n",
      "Epoch 106, Loss: 0.4405967581605889\n",
      "Epoch 107, Loss: 0.4396123301025555\n",
      "Epoch 108, Loss: 0.43863163777957676\n",
      "Epoch 109, Loss: 0.4376470795405728\n",
      "Epoch 110, Loss: 0.4366266013497497\n",
      "Epoch 111, Loss: 0.4356250436199938\n",
      "Epoch 112, Loss: 0.43470720856645767\n",
      "Epoch 113, Loss: 0.4339227888494586\n",
      "Epoch 114, Loss: 0.4333180246797403\n",
      "Epoch 115, Loss: 0.433361799041807\n",
      "Epoch 116, Loss: 0.43265237083914054\n",
      "Epoch 117, Loss: 0.43071428209423196\n",
      "Epoch 118, Loss: 0.4306456027756583\n",
      "Epoch 119, Loss: 0.42955828371036525\n",
      "Epoch 120, Loss: 0.4285499948438164\n",
      "Epoch 121, Loss: 0.42836098953991963\n",
      "Epoch 122, Loss: 0.4269901751665474\n",
      "Epoch 123, Loss: 0.4269051897479636\n",
      "Epoch 124, Loss: 0.4258044000334214\n",
      "Epoch 125, Loss: 0.4252288454682008\n",
      "Epoch 126, Loss: 0.42464342235235153\n",
      "Epoch 127, Loss: 0.423655742976147\n",
      "Epoch 128, Loss: 0.4233418324917694\n",
      "Epoch 129, Loss: 0.42229975404540265\n",
      "Epoch 130, Loss: 0.4219137279960183\n",
      "Epoch 131, Loss: 0.42111289099395716\n",
      "Epoch 132, Loss: 0.42048493715992663\n",
      "Epoch 133, Loss: 0.4199213782019227\n",
      "Epoch 134, Loss: 0.4190886103484368\n",
      "Epoch 135, Loss: 0.4186272291726111\n",
      "Epoch 136, Loss: 0.4178416335135243\n",
      "Epoch 137, Loss: 0.4172089346190483\n",
      "Epoch 138, Loss: 0.41661572939735814\n",
      "Epoch 139, Loss: 0.4158128235134952\n",
      "Epoch 140, Loss: 0.4152504595766045\n",
      "Epoch 141, Loss: 0.4145464498161064\n",
      "Epoch 142, Loss: 0.41376324401933323\n",
      "Epoch 143, Loss: 0.4131444975195123\n",
      "Epoch 144, Loss: 0.41252021740006145\n",
      "Epoch 145, Loss: 0.41172438080210844\n",
      "Epoch 146, Loss: 0.41104346094965977\n",
      "Epoch 147, Loss: 0.4104635994438844\n",
      "Epoch 148, Loss: 0.40992646819838935\n",
      "Epoch 149, Loss: 0.4092616907219814\n",
      "Epoch 150, Loss: 0.40859951503909736\n",
      "Epoch 151, Loss: 0.40798729114046184\n",
      "Epoch 152, Loss: 0.4074856599379154\n",
      "Epoch 153, Loss: 0.40700307151797654\n",
      "Epoch 154, Loss: 0.4066790186101835\n",
      "Epoch 155, Loss: 0.406463365277626\n",
      "Epoch 156, Loss: 0.4061663614886837\n",
      "Epoch 157, Loss: 0.40512168524991793\n",
      "Epoch 158, Loss: 0.404348195085239\n",
      "Epoch 159, Loss: 0.40403267156572303\n",
      "Epoch 160, Loss: 0.40386320434459777\n",
      "Epoch 161, Loss: 0.4035487786380065\n",
      "Epoch 162, Loss: 0.4027091283867663\n",
      "Epoch 163, Loss: 0.4021213805854277\n",
      "Epoch 164, Loss: 0.40190910268817753\n",
      "Epoch 165, Loss: 0.40169699082855925\n",
      "Epoch 166, Loss: 0.40127722110096753\n",
      "Epoch 167, Loss: 0.4006646869837166\n",
      "Epoch 168, Loss: 0.4001415687617533\n",
      "Epoch 169, Loss: 0.3997503604326657\n",
      "Epoch 170, Loss: 0.3994555090406523\n",
      "Epoch 171, Loss: 0.3992329119057231\n",
      "Epoch 172, Loss: 0.3989807987445009\n",
      "Epoch 173, Loss: 0.3986505051255958\n",
      "Epoch 174, Loss: 0.3982139034807031\n",
      "Epoch 175, Loss: 0.3976963105473492\n",
      "Epoch 176, Loss: 0.3972313895238439\n",
      "Epoch 177, Loss: 0.39681250988853156\n",
      "Epoch 178, Loss: 0.396501944768064\n",
      "Epoch 179, Loss: 0.3962689834102845\n",
      "Epoch 180, Loss: 0.396272010492758\n",
      "Epoch 181, Loss: 0.3967481966272147\n",
      "Epoch 182, Loss: 0.39753025209721304\n",
      "Epoch 183, Loss: 0.39635615789019374\n",
      "Epoch 184, Loss: 0.39473566104268853\n",
      "Epoch 185, Loss: 0.3947282809031822\n",
      "Epoch 186, Loss: 0.3954443609885394\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.25093372925321084\n",
      "Test R^2 score: 0.31539474976695586\n",
      "Num of epochs: 187\n",
      "Epoch 1, Loss: 0.588620312817686\n",
      "Epoch 2, Loss: 0.58580748069157\n",
      "Epoch 3, Loss: 0.583103855726892\n",
      "Epoch 4, Loss: 0.5806406806167047\n",
      "Epoch 5, Loss: 0.5783076899786189\n",
      "Epoch 6, Loss: 0.5760769523404428\n",
      "Epoch 7, Loss: 0.5739612650810825\n",
      "Epoch 8, Loss: 0.5719563035547072\n",
      "Epoch 9, Loss: 0.5700621643383275\n",
      "Epoch 10, Loss: 0.5682855145155685\n",
      "Epoch 11, Loss: 0.5666290634198079\n",
      "Epoch 12, Loss: 0.5650794702105423\n",
      "Epoch 13, Loss: 0.5636325666503877\n",
      "Epoch 14, Loss: 0.5622847463100189\n",
      "Epoch 15, Loss: 0.560972444301237\n",
      "Epoch 16, Loss: 0.5598323933937122\n",
      "Epoch 17, Loss: 0.5588359441094185\n",
      "Epoch 18, Loss: 0.5579241761045736\n",
      "Epoch 19, Loss: 0.5571012230965303\n",
      "Epoch 20, Loss: 0.556394904261208\n",
      "Epoch 21, Loss: 0.5558152889695195\n",
      "Epoch 22, Loss: 0.5552955840394254\n",
      "Epoch 23, Loss: 0.55478127452511\n",
      "Epoch 24, Loss: 0.5542765962468036\n",
      "Epoch 25, Loss: 0.5537772971458265\n",
      "Epoch 26, Loss: 0.5532288782455027\n",
      "Epoch 27, Loss: 0.552589586253142\n",
      "Epoch 28, Loss: 0.5518225707814703\n",
      "Epoch 29, Loss: 0.5508945700222907\n",
      "Epoch 30, Loss: 0.5497509132228481\n",
      "Epoch 31, Loss: 0.548338593696399\n",
      "Epoch 32, Loss: 0.5466385739026168\n",
      "Epoch 33, Loss: 0.5445661032864066\n",
      "Epoch 34, Loss: 0.5421283447799251\n",
      "Epoch 35, Loss: 0.539375186844989\n",
      "Epoch 36, Loss: 0.5363935382069064\n",
      "Epoch 37, Loss: 0.5333944124274567\n",
      "Epoch 38, Loss: 0.5307575636265024\n",
      "Epoch 39, Loss: 0.5286890741963619\n",
      "Epoch 40, Loss: 0.5267080360574514\n",
      "Epoch 41, Loss: 0.5240151648165227\n",
      "Epoch 42, Loss: 0.5206540244118848\n",
      "Epoch 43, Loss: 0.5174016111709346\n",
      "Epoch 44, Loss: 0.5147868482435493\n",
      "Epoch 45, Loss: 0.5127715135894088\n",
      "Epoch 46, Loss: 0.5109170647130504\n",
      "Epoch 47, Loss: 0.508921249117078\n",
      "Epoch 48, Loss: 0.5066150926496094\n",
      "Epoch 49, Loss: 0.5041501246121423\n",
      "Epoch 50, Loss: 0.5018216565810337\n",
      "Epoch 51, Loss: 0.4998535150287789\n",
      "Epoch 52, Loss: 0.4980902409840677\n",
      "Epoch 53, Loss: 0.4961683562641551\n",
      "Epoch 54, Loss: 0.49409077509753585\n",
      "Epoch 55, Loss: 0.49223669502601086\n",
      "Epoch 56, Loss: 0.4907059851704122\n",
      "Epoch 57, Loss: 0.48921716639245066\n",
      "Epoch 58, Loss: 0.4875332405299592\n",
      "Epoch 59, Loss: 0.48573777549957897\n",
      "Epoch 60, Loss: 0.48401300685819876\n",
      "Epoch 61, Loss: 0.4825109330109739\n",
      "Epoch 62, Loss: 0.4810827720209747\n",
      "Epoch 63, Loss: 0.4795468176896733\n",
      "Epoch 64, Loss: 0.47796250118823574\n",
      "Epoch 65, Loss: 0.4765017580188051\n",
      "Epoch 66, Loss: 0.47505568880594246\n",
      "Epoch 67, Loss: 0.4734815847688956\n",
      "Epoch 68, Loss: 0.47196447964039484\n",
      "Epoch 69, Loss: 0.4706491938042369\n",
      "Epoch 70, Loss: 0.4693170138071007\n",
      "Epoch 71, Loss: 0.46780592899128787\n",
      "Epoch 72, Loss: 0.46625388258884753\n",
      "Epoch 73, Loss: 0.4647754009871133\n",
      "Epoch 74, Loss: 0.46329913241529347\n",
      "Epoch 75, Loss: 0.4619148689892041\n",
      "Epoch 76, Loss: 0.46075940328390325\n",
      "Epoch 77, Loss: 0.4597245923240829\n",
      "Epoch 78, Loss: 0.4587401206852324\n",
      "Epoch 79, Loss: 0.45802087500841465\n",
      "Epoch 80, Loss: 0.45762598840877156\n",
      "Epoch 81, Loss: 0.457338376653897\n",
      "Epoch 82, Loss: 0.4570539419947544\n",
      "Epoch 83, Loss: 0.45665410774891185\n",
      "Epoch 84, Loss: 0.4560844362672954\n",
      "Epoch 85, Loss: 0.45539597638216056\n",
      "Epoch 86, Loss: 0.4546806826522839\n",
      "Epoch 87, Loss: 0.45393507992292226\n",
      "Epoch 88, Loss: 0.45328558345434006\n",
      "Epoch 89, Loss: 0.45271906263180417\n",
      "Epoch 90, Loss: 0.45221544926756624\n",
      "Epoch 91, Loss: 0.45175834619446864\n",
      "Epoch 92, Loss: 0.45126165182123174\n",
      "Epoch 93, Loss: 0.45069944740258994\n",
      "Epoch 94, Loss: 0.45015961346202255\n",
      "Epoch 95, Loss: 0.44958608784095466\n",
      "Epoch 96, Loss: 0.44897899034363403\n",
      "Epoch 97, Loss: 0.4483688940010525\n",
      "Epoch 98, Loss: 0.4477796307977167\n",
      "Epoch 99, Loss: 0.4472528147632864\n",
      "Epoch 100, Loss: 0.4467713402516727\n",
      "Epoch 101, Loss: 0.44635626956736624\n",
      "Epoch 102, Loss: 0.4459545125302509\n",
      "Epoch 103, Loss: 0.4455029766216656\n",
      "Epoch 104, Loss: 0.44497388380009145\n",
      "Epoch 105, Loss: 0.4443939338813857\n",
      "Epoch 106, Loss: 0.443844701843165\n",
      "Epoch 107, Loss: 0.4433014953744675\n",
      "Epoch 108, Loss: 0.44274175368178703\n",
      "Epoch 109, Loss: 0.44220078114760203\n",
      "Epoch 110, Loss: 0.4416856472267468\n",
      "Epoch 111, Loss: 0.4411117955677483\n",
      "Epoch 112, Loss: 0.4404473311787379\n",
      "Epoch 113, Loss: 0.4398776398742413\n",
      "Epoch 114, Loss: 0.43934948864776074\n",
      "Epoch 115, Loss: 0.4387869299320006\n",
      "Epoch 116, Loss: 0.4381993188282971\n",
      "Epoch 117, Loss: 0.4376611242598289\n",
      "Epoch 118, Loss: 0.4371349821524489\n",
      "Epoch 119, Loss: 0.4365738705169427\n",
      "Epoch 120, Loss: 0.4359816532266742\n",
      "Epoch 121, Loss: 0.43533410661562016\n",
      "Epoch 122, Loss: 0.434644645591412\n",
      "Epoch 123, Loss: 0.4339671546135914\n",
      "Epoch 124, Loss: 0.4333239910451373\n",
      "Epoch 125, Loss: 0.4326895315333912\n",
      "Epoch 126, Loss: 0.43213226834298557\n",
      "Epoch 127, Loss: 0.4316074134166994\n",
      "Epoch 128, Loss: 0.43104479302621074\n",
      "Epoch 129, Loss: 0.430445557262018\n",
      "Epoch 130, Loss: 0.42984484479314783\n",
      "Epoch 131, Loss: 0.4292405144416013\n",
      "Epoch 132, Loss: 0.4286339936257083\n",
      "Epoch 133, Loss: 0.42798305929049335\n",
      "Epoch 134, Loss: 0.42729706378443955\n",
      "Epoch 135, Loss: 0.42665812988917656\n",
      "Epoch 136, Loss: 0.42609222674823194\n",
      "Epoch 137, Loss: 0.4255739634887733\n",
      "Epoch 138, Loss: 0.42506793404835547\n",
      "Epoch 139, Loss: 0.4244697741384002\n",
      "Epoch 140, Loss: 0.42381121342402817\n",
      "Epoch 141, Loss: 0.4231631076167772\n",
      "Epoch 142, Loss: 0.422570679299814\n",
      "Epoch 143, Loss: 0.4220039559117884\n",
      "Epoch 144, Loss: 0.4214952313683981\n",
      "Epoch 145, Loss: 0.42110965323629185\n",
      "Epoch 146, Loss: 0.4207789523645927\n",
      "Epoch 147, Loss: 0.4201132759539946\n",
      "Epoch 148, Loss: 0.41922021840706003\n",
      "Epoch 149, Loss: 0.4188848420719752\n",
      "Epoch 150, Loss: 0.4185880547136411\n",
      "Epoch 151, Loss: 0.41777288892512887\n",
      "Epoch 152, Loss: 0.4171327090626986\n",
      "Epoch 153, Loss: 0.41686379021552994\n",
      "Epoch 154, Loss: 0.41627177559539275\n",
      "Epoch 155, Loss: 0.415454737128194\n",
      "Epoch 156, Loss: 0.4149222534959432\n",
      "Epoch 157, Loss: 0.4146016407603375\n",
      "Epoch 158, Loss: 0.4141075901456067\n",
      "Epoch 159, Loss: 0.4134174576772084\n",
      "Epoch 160, Loss: 0.412676687402546\n",
      "Epoch 161, Loss: 0.4121221929066391\n",
      "Epoch 162, Loss: 0.41173958119457305\n",
      "Epoch 163, Loss: 0.41137168269644064\n",
      "Epoch 164, Loss: 0.41096083426131125\n",
      "Epoch 165, Loss: 0.41051079095138726\n",
      "Epoch 166, Loss: 0.40981852841768396\n",
      "Epoch 167, Loss: 0.4090749929864868\n",
      "Epoch 168, Loss: 0.4084968240409012\n",
      "Epoch 169, Loss: 0.40810029774402357\n",
      "Epoch 170, Loss: 0.407822518207372\n",
      "Epoch 171, Loss: 0.40757829583873534\n",
      "Epoch 172, Loss: 0.4071253918454677\n",
      "Epoch 173, Loss: 0.40621419895585825\n",
      "Epoch 174, Loss: 0.4052887143852127\n",
      "Epoch 175, Loss: 0.40482518788476285\n",
      "Epoch 176, Loss: 0.4046709845276934\n",
      "Epoch 177, Loss: 0.4044372204429003\n",
      "Epoch 178, Loss: 0.4037103867953844\n",
      "Epoch 179, Loss: 0.4028035101764135\n",
      "Epoch 180, Loss: 0.40195090364633856\n",
      "Epoch 181, Loss: 0.4015138826737331\n",
      "Epoch 182, Loss: 0.4014619218909728\n",
      "Epoch 183, Loss: 0.4015095590508128\n",
      "Epoch 184, Loss: 0.40132421184560546\n",
      "Epoch 185, Loss: 0.4000515502256002\n",
      "Epoch 186, Loss: 0.39890077248744993\n",
      "Epoch 187, Loss: 0.39860912441389185\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.23344456008178446\n",
      "Test R^2 score: 0.4093548199336936\n",
      "Num of epochs: 188\n",
      "Epoch 1, Loss: 0.5765046532617648\n",
      "Epoch 2, Loss: 0.5735183388589041\n",
      "Epoch 3, Loss: 0.5707397689386909\n",
      "Epoch 4, Loss: 0.5683013781553491\n",
      "Epoch 5, Loss: 0.5662507468549169\n",
      "Epoch 6, Loss: 0.5643719149449244\n",
      "Epoch 7, Loss: 0.5626791297945108\n",
      "Epoch 8, Loss: 0.5611735970758683\n",
      "Epoch 9, Loss: 0.5598840017325392\n",
      "Epoch 10, Loss: 0.5587917857152082\n",
      "Epoch 11, Loss: 0.5578818152607775\n",
      "Epoch 12, Loss: 0.5572225105895114\n",
      "Epoch 13, Loss: 0.5567043602577545\n",
      "Epoch 14, Loss: 0.5563192945887625\n",
      "Epoch 15, Loss: 0.5560634632443119\n",
      "Epoch 16, Loss: 0.5559201580599962\n",
      "Epoch 17, Loss: 0.5558515879232364\n",
      "Epoch 18, Loss: 0.5558382642842761\n",
      "Epoch 19, Loss: 0.5558540542358607\n",
      "Epoch 20, Loss: 0.5558685838120169\n",
      "Epoch 21, Loss: 0.5558456365585803\n",
      "Epoch 22, Loss: 0.5557572700618711\n",
      "Epoch 23, Loss: 0.555587521931432\n",
      "Epoch 24, Loss: 0.5553291531686352\n",
      "Epoch 25, Loss: 0.5549820131531773\n",
      "Epoch 26, Loss: 0.554537336413361\n",
      "Epoch 27, Loss: 0.5539846937754\n",
      "Epoch 28, Loss: 0.5533127471482041\n",
      "Epoch 29, Loss: 0.5525105161227051\n",
      "Epoch 30, Loss: 0.55157100249483\n",
      "Epoch 31, Loss: 0.5505023818471245\n",
      "Epoch 32, Loss: 0.549327039827634\n",
      "Epoch 33, Loss: 0.5481044301313159\n",
      "Epoch 34, Loss: 0.5468732288876873\n",
      "Epoch 35, Loss: 0.5455718180813043\n",
      "Epoch 36, Loss: 0.5441080942171994\n",
      "Epoch 37, Loss: 0.5424073699677633\n",
      "Epoch 38, Loss: 0.5403598432830898\n",
      "Epoch 39, Loss: 0.5379134661576579\n",
      "Epoch 40, Loss: 0.5350105477122205\n",
      "Epoch 41, Loss: 0.5317275201218263\n",
      "Epoch 42, Loss: 0.5280535406941228\n",
      "Epoch 43, Loss: 0.5239641187991803\n",
      "Epoch 44, Loss: 0.5195067263673503\n",
      "Epoch 45, Loss: 0.5149177266577294\n",
      "Epoch 46, Loss: 0.5107254988385438\n",
      "Epoch 47, Loss: 0.5074186117935091\n",
      "Epoch 48, Loss: 0.504217894239855\n",
      "Epoch 49, Loss: 0.5000709542950931\n",
      "Epoch 50, Loss: 0.4954944956143665\n",
      "Epoch 51, Loss: 0.49141608442160223\n",
      "Epoch 52, Loss: 0.4882552025523175\n",
      "Epoch 53, Loss: 0.48556188558637087\n",
      "Epoch 54, Loss: 0.48304633986856654\n",
      "Epoch 55, Loss: 0.4804458767788538\n",
      "Epoch 56, Loss: 0.47795176078978063\n",
      "Epoch 57, Loss: 0.4757495575169617\n",
      "Epoch 58, Loss: 0.4739487371067092\n",
      "Epoch 59, Loss: 0.47251678805323066\n",
      "Epoch 60, Loss: 0.47110438358584905\n",
      "Epoch 61, Loss: 0.4695293464558586\n",
      "Epoch 62, Loss: 0.46811087269977786\n",
      "Epoch 63, Loss: 0.46721566539565446\n",
      "Epoch 64, Loss: 0.46642433847083065\n",
      "Epoch 65, Loss: 0.4657896019750822\n",
      "Epoch 66, Loss: 0.46506086456191725\n",
      "Epoch 67, Loss: 0.4641638038342651\n",
      "Epoch 68, Loss: 0.463040275365796\n",
      "Epoch 69, Loss: 0.46160688126201654\n",
      "Epoch 70, Loss: 0.4603170648207346\n",
      "Epoch 71, Loss: 0.45919202611937404\n",
      "Epoch 72, Loss: 0.4582231580642808\n",
      "Epoch 73, Loss: 0.45725909691339384\n",
      "Epoch 74, Loss: 0.456280491084407\n",
      "Epoch 75, Loss: 0.45541200955072686\n",
      "Epoch 76, Loss: 0.45458809005120415\n",
      "Epoch 77, Loss: 0.45382517945838685\n",
      "Epoch 78, Loss: 0.4530482556038687\n",
      "Epoch 79, Loss: 0.45228670119563563\n",
      "Epoch 80, Loss: 0.4515124930177342\n",
      "Epoch 81, Loss: 0.4507338970045718\n",
      "Epoch 82, Loss: 0.44991101537503025\n",
      "Epoch 83, Loss: 0.4490519006443184\n",
      "Epoch 84, Loss: 0.4481576744308588\n",
      "Epoch 85, Loss: 0.4473227085517255\n",
      "Epoch 86, Loss: 0.4465476524388706\n",
      "Epoch 87, Loss: 0.4458446836215125\n",
      "Epoch 88, Loss: 0.4451865971920398\n",
      "Epoch 89, Loss: 0.4445274359567936\n",
      "Epoch 90, Loss: 0.44384079058113834\n",
      "Epoch 91, Loss: 0.44310422100746144\n",
      "Epoch 92, Loss: 0.44232827496720634\n",
      "Epoch 93, Loss: 0.4415630298457439\n",
      "Epoch 94, Loss: 0.44079248410648025\n",
      "Epoch 95, Loss: 0.4399979837598988\n",
      "Epoch 96, Loss: 0.43918499714105774\n",
      "Epoch 97, Loss: 0.4383788817761118\n",
      "Epoch 98, Loss: 0.4375780580912537\n",
      "Epoch 99, Loss: 0.4367803547218123\n",
      "Epoch 100, Loss: 0.43596376046008\n",
      "Epoch 101, Loss: 0.4351253608136652\n",
      "Epoch 102, Loss: 0.43428717830048635\n",
      "Epoch 103, Loss: 0.4334587196210989\n",
      "Epoch 104, Loss: 0.432657605903019\n",
      "Epoch 105, Loss: 0.43192200961050675\n",
      "Epoch 106, Loss: 0.43130582019722746\n",
      "Epoch 107, Loss: 0.43038448679049446\n",
      "Epoch 108, Loss: 0.4294264086858178\n",
      "Epoch 109, Loss: 0.4287839405928168\n",
      "Epoch 110, Loss: 0.428055159587307\n",
      "Epoch 111, Loss: 0.4270895186030636\n",
      "Epoch 112, Loss: 0.4263004671911677\n",
      "Epoch 113, Loss: 0.4256435486593087\n",
      "Epoch 114, Loss: 0.42480875649092925\n",
      "Epoch 115, Loss: 0.42392629374253643\n",
      "Epoch 116, Loss: 0.4232221393563564\n",
      "Epoch 117, Loss: 0.42255994154290016\n",
      "Epoch 118, Loss: 0.4217477535918354\n",
      "Epoch 119, Loss: 0.4209169175766493\n",
      "Epoch 120, Loss: 0.420222773422823\n",
      "Epoch 121, Loss: 0.41963285213938506\n",
      "Epoch 122, Loss: 0.41904096245090927\n",
      "Epoch 123, Loss: 0.41830603636189717\n",
      "Epoch 124, Loss: 0.41751539296195544\n",
      "Epoch 125, Loss: 0.41676465511470173\n",
      "Epoch 126, Loss: 0.4161126287849573\n",
      "Epoch 127, Loss: 0.4155077274053812\n",
      "Epoch 128, Loss: 0.41495171918148605\n",
      "Epoch 129, Loss: 0.4146114704833152\n",
      "Epoch 130, Loss: 0.41430930213770195\n",
      "Epoch 131, Loss: 0.41370858956175777\n",
      "Epoch 132, Loss: 0.4123826409054358\n",
      "Epoch 133, Loss: 0.41186121840856615\n",
      "Epoch 134, Loss: 0.4118650172967344\n",
      "Epoch 135, Loss: 0.41092437389572317\n",
      "Epoch 136, Loss: 0.40994318923224404\n",
      "Epoch 137, Loss: 0.409729963119932\n",
      "Epoch 138, Loss: 0.40936739310265957\n",
      "Epoch 139, Loss: 0.4084208514695725\n",
      "Epoch 140, Loss: 0.40767668585475203\n",
      "Epoch 141, Loss: 0.4073924360309997\n",
      "Epoch 142, Loss: 0.406970558840301\n",
      "Epoch 143, Loss: 0.4060928517618259\n",
      "Epoch 144, Loss: 0.40541781875522453\n",
      "Epoch 145, Loss: 0.40500157441315926\n",
      "Epoch 146, Loss: 0.4046408438575354\n",
      "Epoch 147, Loss: 0.40411492644125524\n",
      "Epoch 148, Loss: 0.40344779375980927\n",
      "Epoch 149, Loss: 0.4028026593221861\n",
      "Epoch 150, Loss: 0.4021582870425879\n",
      "Epoch 151, Loss: 0.40167417643215647\n",
      "Epoch 152, Loss: 0.4013110490507456\n",
      "Epoch 153, Loss: 0.4011006642166588\n",
      "Epoch 154, Loss: 0.4014571894141256\n",
      "Epoch 155, Loss: 0.40194730763725306\n",
      "Epoch 156, Loss: 0.4014433442791629\n",
      "Epoch 157, Loss: 0.3988756500831789\n",
      "Epoch 158, Loss: 0.39926213590466153\n",
      "Epoch 159, Loss: 0.40027912727392906\n",
      "Epoch 160, Loss: 0.3979136819710896\n",
      "Epoch 161, Loss: 0.39806990402434606\n",
      "Epoch 162, Loss: 0.3989033500126679\n",
      "Epoch 163, Loss: 0.39680019259356814\n",
      "Epoch 164, Loss: 0.3970392600628528\n",
      "Epoch 165, Loss: 0.3976338828041138\n",
      "Epoch 166, Loss: 0.3952278747747944\n",
      "Epoch 167, Loss: 0.3964436702786346\n",
      "Epoch 168, Loss: 0.3957110600932695\n",
      "Epoch 169, Loss: 0.3943656725014707\n",
      "Epoch 170, Loss: 0.3955470878032403\n",
      "Epoch 171, Loss: 0.39464369200770444\n",
      "Epoch 172, Loss: 0.3934659644897742\n",
      "Epoch 173, Loss: 0.39487968770378623\n",
      "Epoch 174, Loss: 0.3930846026455833\n",
      "Epoch 175, Loss: 0.3928590025950666\n",
      "Epoch 176, Loss: 0.39318893134142047\n",
      "Epoch 177, Loss: 0.3918451897448448\n",
      "Epoch 178, Loss: 0.39186429844165854\n",
      "Epoch 179, Loss: 0.3918310810343758\n",
      "Epoch 180, Loss: 0.39070786550872927\n",
      "Epoch 181, Loss: 0.39108988755041413\n",
      "Epoch 182, Loss: 0.3905195284550559\n",
      "Epoch 183, Loss: 0.38991151499757265\n",
      "Epoch 184, Loss: 0.39004815424837064\n",
      "Epoch 185, Loss: 0.3895479230376624\n",
      "Epoch 186, Loss: 0.3890817101266946\n",
      "Epoch 187, Loss: 0.3888630804039471\n",
      "Epoch 188, Loss: 0.3888033543859999\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.23537945859417136\n",
      "Test R^2 score: 0.4009606946156375\n",
      "Num of epochs: 189\n",
      "Epoch 1, Loss: 0.557231602744577\n",
      "Epoch 2, Loss: 0.5569224664685879\n",
      "Epoch 3, Loss: 0.5566895045185157\n",
      "Epoch 4, Loss: 0.5565062779040765\n",
      "Epoch 5, Loss: 0.5563721126292068\n",
      "Epoch 6, Loss: 0.5562852494718726\n",
      "Epoch 7, Loss: 0.5562272527951271\n",
      "Epoch 8, Loss: 0.5561917553100284\n",
      "Epoch 9, Loss: 0.5561730813839755\n",
      "Epoch 10, Loss: 0.5561664100589604\n",
      "Epoch 11, Loss: 0.5561663028884276\n",
      "Epoch 12, Loss: 0.5561684462951608\n",
      "Epoch 13, Loss: 0.5561547819357084\n",
      "Epoch 14, Loss: 0.5561488070220622\n",
      "Epoch 15, Loss: 0.556130801512934\n",
      "Epoch 16, Loss: 0.5561020236406032\n",
      "Epoch 17, Loss: 0.5560589880286259\n",
      "Epoch 18, Loss: 0.5560007801462092\n",
      "Epoch 19, Loss: 0.5559292983189368\n",
      "Epoch 20, Loss: 0.5558432238250265\n",
      "Epoch 21, Loss: 0.555742067248674\n",
      "Epoch 22, Loss: 0.5556212075171613\n",
      "Epoch 23, Loss: 0.5554766615506731\n",
      "Epoch 24, Loss: 0.5553020779861213\n",
      "Epoch 25, Loss: 0.5550971331955804\n",
      "Epoch 26, Loss: 0.5548610415781566\n",
      "Epoch 27, Loss: 0.5545999968375706\n",
      "Epoch 28, Loss: 0.5542902262573215\n",
      "Epoch 29, Loss: 0.5539182513702957\n",
      "Epoch 30, Loss: 0.5534820352617996\n",
      "Epoch 31, Loss: 0.5529693804864234\n",
      "Epoch 32, Loss: 0.5523713338350004\n",
      "Epoch 33, Loss: 0.5516843493682693\n",
      "Epoch 34, Loss: 0.550885373276903\n",
      "Epoch 35, Loss: 0.5499587173574252\n",
      "Epoch 36, Loss: 0.5488956450608747\n",
      "Epoch 37, Loss: 0.5475886456913955\n",
      "Epoch 38, Loss: 0.5459313561847688\n",
      "Epoch 39, Loss: 0.5439327930262998\n",
      "Epoch 40, Loss: 0.5415813916890541\n",
      "Epoch 41, Loss: 0.538907540204502\n",
      "Epoch 42, Loss: 0.5360624896068734\n",
      "Epoch 43, Loss: 0.5329738305575794\n",
      "Epoch 44, Loss: 0.5295196571105404\n",
      "Epoch 45, Loss: 0.5255856630571968\n",
      "Epoch 46, Loss: 0.521106168493167\n",
      "Epoch 47, Loss: 0.5160263984473827\n",
      "Epoch 48, Loss: 0.5104602743191874\n",
      "Epoch 49, Loss: 0.504651457500479\n",
      "Epoch 50, Loss: 0.49918395743516625\n",
      "Epoch 51, Loss: 0.4947933816043514\n",
      "Epoch 52, Loss: 0.4912051282050012\n",
      "Epoch 53, Loss: 0.48642161439720344\n",
      "Epoch 54, Loss: 0.48064104728051443\n",
      "Epoch 55, Loss: 0.4760102527389758\n",
      "Epoch 56, Loss: 0.47361478476281965\n",
      "Epoch 57, Loss: 0.4719734777549573\n",
      "Epoch 58, Loss: 0.4704145916362822\n",
      "Epoch 59, Loss: 0.46896861064952283\n",
      "Epoch 60, Loss: 0.4670550378667603\n",
      "Epoch 61, Loss: 0.46474386793013595\n",
      "Epoch 62, Loss: 0.4630225914949293\n",
      "Epoch 63, Loss: 0.4631738239040526\n",
      "Epoch 64, Loss: 0.46345813584379936\n",
      "Epoch 65, Loss: 0.46252721693529203\n",
      "Epoch 66, Loss: 0.46136490354650084\n",
      "Epoch 67, Loss: 0.4601019058131689\n",
      "Epoch 68, Loss: 0.4588094824496988\n",
      "Epoch 69, Loss: 0.45801446580426197\n",
      "Epoch 70, Loss: 0.45761993185955196\n",
      "Epoch 71, Loss: 0.456913337821089\n",
      "Epoch 72, Loss: 0.4558459014339702\n",
      "Epoch 73, Loss: 0.4548611430620307\n",
      "Epoch 74, Loss: 0.45395342964102003\n",
      "Epoch 75, Loss: 0.4532703462516766\n",
      "Epoch 76, Loss: 0.45287475581824566\n",
      "Epoch 77, Loss: 0.45236079129548806\n",
      "Epoch 78, Loss: 0.4517009324921143\n",
      "Epoch 79, Loss: 0.4509312206684989\n",
      "Epoch 80, Loss: 0.4500317224606437\n",
      "Epoch 81, Loss: 0.44933238043575574\n",
      "Epoch 82, Loss: 0.4486599639528422\n",
      "Epoch 83, Loss: 0.4480920012280513\n",
      "Epoch 84, Loss: 0.44744289833048856\n",
      "Epoch 85, Loss: 0.4467401207598451\n",
      "Epoch 86, Loss: 0.4460407626454533\n",
      "Epoch 87, Loss: 0.44542706003127547\n",
      "Epoch 88, Loss: 0.4448151236817602\n",
      "Epoch 89, Loss: 0.4441096473700797\n",
      "Epoch 90, Loss: 0.4433415783238544\n",
      "Epoch 91, Loss: 0.4426236370823024\n",
      "Epoch 92, Loss: 0.44195121275157845\n",
      "Epoch 93, Loss: 0.44132687690546224\n",
      "Epoch 94, Loss: 0.4406071239930561\n",
      "Epoch 95, Loss: 0.4399053323840081\n",
      "Epoch 96, Loss: 0.4391715779684366\n",
      "Epoch 97, Loss: 0.4385301009289308\n",
      "Epoch 98, Loss: 0.43783165077730335\n",
      "Epoch 99, Loss: 0.4370758009656412\n",
      "Epoch 100, Loss: 0.4364013330419567\n",
      "Epoch 101, Loss: 0.4356986495580401\n",
      "Epoch 102, Loss: 0.43497364315117537\n",
      "Epoch 103, Loss: 0.4342869724298256\n",
      "Epoch 104, Loss: 0.4336307097482724\n",
      "Epoch 105, Loss: 0.4329654505978066\n",
      "Epoch 106, Loss: 0.4322529932517467\n",
      "Epoch 107, Loss: 0.4315743373874381\n",
      "Epoch 108, Loss: 0.43090721757035844\n",
      "Epoch 109, Loss: 0.430226456150364\n",
      "Epoch 110, Loss: 0.4296210324290397\n",
      "Epoch 111, Loss: 0.42918918498074987\n",
      "Epoch 112, Loss: 0.4294071323193324\n",
      "Epoch 113, Loss: 0.4304250109929395\n",
      "Epoch 114, Loss: 0.42817539837314705\n",
      "Epoch 115, Loss: 0.427070328661783\n",
      "Epoch 116, Loss: 0.4278774980053656\n",
      "Epoch 117, Loss: 0.4255957067943079\n",
      "Epoch 118, Loss: 0.4262648294895247\n",
      "Epoch 119, Loss: 0.4251408441760254\n",
      "Epoch 120, Loss: 0.42427561468397135\n",
      "Epoch 121, Loss: 0.4245194979582995\n",
      "Epoch 122, Loss: 0.422868864837533\n",
      "Epoch 123, Loss: 0.4232722561747817\n",
      "Epoch 124, Loss: 0.42200538598370446\n",
      "Epoch 125, Loss: 0.4217830310463706\n",
      "Epoch 126, Loss: 0.4214322097640893\n",
      "Epoch 127, Loss: 0.4203825619244578\n",
      "Epoch 128, Loss: 0.420619916700961\n",
      "Epoch 129, Loss: 0.41953145884929555\n",
      "Epoch 130, Loss: 0.41921126098426964\n",
      "Epoch 131, Loss: 0.4189179951758207\n",
      "Epoch 132, Loss: 0.4179381421727295\n",
      "Epoch 133, Loss: 0.4178106062281965\n",
      "Epoch 134, Loss: 0.4172155420829898\n",
      "Epoch 135, Loss: 0.416519880267983\n",
      "Epoch 136, Loss: 0.41638153174575704\n",
      "Epoch 137, Loss: 0.41580689257624137\n",
      "Epoch 138, Loss: 0.41509178275569997\n",
      "Epoch 139, Loss: 0.4148233369162058\n",
      "Epoch 140, Loss: 0.41440595022181637\n",
      "Epoch 141, Loss: 0.41372524778079867\n",
      "Epoch 142, Loss: 0.41317957184397724\n",
      "Epoch 143, Loss: 0.4128505315595422\n",
      "Epoch 144, Loss: 0.41242489781313396\n",
      "Epoch 145, Loss: 0.4118839026778368\n",
      "Epoch 146, Loss: 0.41129424851363694\n",
      "Epoch 147, Loss: 0.4107862085251356\n",
      "Epoch 148, Loss: 0.4103467408105306\n",
      "Epoch 149, Loss: 0.40996485286185996\n",
      "Epoch 150, Loss: 0.4097027951374474\n",
      "Epoch 151, Loss: 0.40960398232276873\n",
      "Epoch 152, Loss: 0.4096204436860439\n",
      "Epoch 153, Loss: 0.4095545578792981\n",
      "Epoch 154, Loss: 0.40868446043394857\n",
      "Epoch 155, Loss: 0.4075583883007042\n",
      "Epoch 156, Loss: 0.40689221385280694\n",
      "Epoch 157, Loss: 0.4070061835187152\n",
      "Epoch 158, Loss: 0.4071920732488736\n",
      "Epoch 159, Loss: 0.40642807798860875\n",
      "Epoch 160, Loss: 0.40546511977376926\n",
      "Epoch 161, Loss: 0.40493214035785324\n",
      "Epoch 162, Loss: 0.4049374945997216\n",
      "Epoch 163, Loss: 0.40496558940957267\n",
      "Epoch 164, Loss: 0.4044913409347185\n",
      "Epoch 165, Loss: 0.40375523058925183\n",
      "Epoch 166, Loss: 0.4030623638669241\n",
      "Epoch 167, Loss: 0.4028004581909547\n",
      "Epoch 168, Loss: 0.4028430544183088\n",
      "Epoch 169, Loss: 0.4026967509295181\n",
      "Epoch 170, Loss: 0.40251385694546166\n",
      "Epoch 171, Loss: 0.4017689311594297\n",
      "Epoch 172, Loss: 0.4010671529061576\n",
      "Epoch 173, Loss: 0.40050471471423565\n",
      "Epoch 174, Loss: 0.4002181635411722\n",
      "Epoch 175, Loss: 0.40012846016452824\n",
      "Epoch 176, Loss: 0.4001370068696776\n",
      "Epoch 177, Loss: 0.40044996240596376\n",
      "Epoch 178, Loss: 0.4004498135617599\n",
      "Epoch 179, Loss: 0.40014456654822783\n",
      "Epoch 180, Loss: 0.3988058967635518\n",
      "Epoch 181, Loss: 0.39770485331773114\n",
      "Epoch 182, Loss: 0.3974051471517021\n",
      "Epoch 183, Loss: 0.3976570226815442\n",
      "Epoch 184, Loss: 0.3979313009710003\n",
      "Epoch 185, Loss: 0.39741287128259684\n",
      "Epoch 186, Loss: 0.39658536705299346\n",
      "Epoch 187, Loss: 0.3956248169185944\n",
      "Epoch 188, Loss: 0.3952155269450058\n",
      "Epoch 189, Loss: 0.39530885189619686\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22883618391467897\n",
      "Test R^2 score: 0.4333964366052947\n",
      "Num of epochs: 190\n",
      "Epoch 1, Loss: 0.5918054359748459\n",
      "Epoch 2, Loss: 0.5898610548297778\n",
      "Epoch 3, Loss: 0.5879575368119658\n",
      "Epoch 4, Loss: 0.5861058057024637\n",
      "Epoch 5, Loss: 0.5842876858682975\n",
      "Epoch 6, Loss: 0.5825081989628146\n",
      "Epoch 7, Loss: 0.5807767571990566\n",
      "Epoch 8, Loss: 0.5790875386539069\n",
      "Epoch 9, Loss: 0.577482252839108\n",
      "Epoch 10, Loss: 0.5761119229435553\n",
      "Epoch 11, Loss: 0.5748976761537896\n",
      "Epoch 12, Loss: 0.5737099761549653\n",
      "Epoch 13, Loss: 0.572553568711759\n",
      "Epoch 14, Loss: 0.5714407434188918\n",
      "Epoch 15, Loss: 0.5703682284365977\n",
      "Epoch 16, Loss: 0.5692533560743149\n",
      "Epoch 17, Loss: 0.568144977415579\n",
      "Epoch 18, Loss: 0.5670510140971917\n",
      "Epoch 19, Loss: 0.5659805539719908\n",
      "Epoch 20, Loss: 0.5649394807642614\n",
      "Epoch 21, Loss: 0.5639317886771901\n",
      "Epoch 22, Loss: 0.5629666035590332\n",
      "Epoch 23, Loss: 0.5620462123649225\n",
      "Epoch 24, Loss: 0.5611667462135412\n",
      "Epoch 25, Loss: 0.5603375193450684\n",
      "Epoch 26, Loss: 0.5595622170280458\n",
      "Epoch 27, Loss: 0.5588342109049069\n",
      "Epoch 28, Loss: 0.5581519507194561\n",
      "Epoch 29, Loss: 0.5575225803267144\n",
      "Epoch 30, Loss: 0.5569515765164986\n",
      "Epoch 31, Loss: 0.5564316474412241\n",
      "Epoch 32, Loss: 0.5559563429556987\n",
      "Epoch 33, Loss: 0.5555117487192905\n",
      "Epoch 34, Loss: 0.5550926501892393\n",
      "Epoch 35, Loss: 0.5546850553646752\n",
      "Epoch 36, Loss: 0.5542317519532777\n",
      "Epoch 37, Loss: 0.5537086500224878\n",
      "Epoch 38, Loss: 0.5530908196874544\n",
      "Epoch 39, Loss: 0.5523151115104507\n",
      "Epoch 40, Loss: 0.551312778557159\n",
      "Epoch 41, Loss: 0.5500945551829033\n",
      "Epoch 42, Loss: 0.5486804315442176\n",
      "Epoch 43, Loss: 0.5470121484171075\n",
      "Epoch 44, Loss: 0.5452874984037788\n",
      "Epoch 45, Loss: 0.5432879381094531\n",
      "Epoch 46, Loss: 0.5410054064725554\n",
      "Epoch 47, Loss: 0.5384959408687665\n",
      "Epoch 48, Loss: 0.5358027430573433\n",
      "Epoch 49, Loss: 0.5329720132504747\n",
      "Epoch 50, Loss: 0.5300102915754304\n",
      "Epoch 51, Loss: 0.5268162101988777\n",
      "Epoch 52, Loss: 0.5233612859098561\n",
      "Epoch 53, Loss: 0.5200521109677612\n",
      "Epoch 54, Loss: 0.517008658889997\n",
      "Epoch 55, Loss: 0.5143243685029861\n",
      "Epoch 56, Loss: 0.51185608979113\n",
      "Epoch 57, Loss: 0.509478023852487\n",
      "Epoch 58, Loss: 0.5071788355568488\n",
      "Epoch 59, Loss: 0.504964264842276\n",
      "Epoch 60, Loss: 0.5026235889641746\n",
      "Epoch 61, Loss: 0.5000122784060644\n",
      "Epoch 62, Loss: 0.49735238516283464\n",
      "Epoch 63, Loss: 0.4948395772793563\n",
      "Epoch 64, Loss: 0.4923992004451566\n",
      "Epoch 65, Loss: 0.49002169368853205\n",
      "Epoch 66, Loss: 0.48793626423685743\n",
      "Epoch 67, Loss: 0.4860813020088988\n",
      "Epoch 68, Loss: 0.484220864782796\n",
      "Epoch 69, Loss: 0.4823858116353838\n",
      "Epoch 70, Loss: 0.48067018891746777\n",
      "Epoch 71, Loss: 0.4789457451121734\n",
      "Epoch 72, Loss: 0.47720798178674023\n",
      "Epoch 73, Loss: 0.4756248818496377\n",
      "Epoch 74, Loss: 0.47404961877169216\n",
      "Epoch 75, Loss: 0.47252350511568236\n",
      "Epoch 76, Loss: 0.47121621496481386\n",
      "Epoch 77, Loss: 0.469922173706873\n",
      "Epoch 78, Loss: 0.4686094868184036\n",
      "Epoch 79, Loss: 0.46734715990093467\n",
      "Epoch 80, Loss: 0.4660762987185145\n",
      "Epoch 81, Loss: 0.46487949137763085\n",
      "Epoch 82, Loss: 0.4637373250581293\n",
      "Epoch 83, Loss: 0.4626219569324924\n",
      "Epoch 84, Loss: 0.46154444546213275\n",
      "Epoch 85, Loss: 0.4604357073228449\n",
      "Epoch 86, Loss: 0.45941265496829037\n",
      "Epoch 87, Loss: 0.45844517954275454\n",
      "Epoch 88, Loss: 0.45752413980448897\n",
      "Epoch 89, Loss: 0.45669791300350854\n",
      "Epoch 90, Loss: 0.45588679357868644\n",
      "Epoch 91, Loss: 0.45506710644918313\n",
      "Epoch 92, Loss: 0.4541361805836003\n",
      "Epoch 93, Loss: 0.4531947279587695\n",
      "Epoch 94, Loss: 0.4523758120860231\n",
      "Epoch 95, Loss: 0.4515502961037503\n",
      "Epoch 96, Loss: 0.4506916776946728\n",
      "Epoch 97, Loss: 0.4498796494135843\n",
      "Epoch 98, Loss: 0.44901498236542003\n",
      "Epoch 99, Loss: 0.44813953628798825\n",
      "Epoch 100, Loss: 0.4472535643971284\n",
      "Epoch 101, Loss: 0.44638960225457697\n",
      "Epoch 102, Loss: 0.4454976918142529\n",
      "Epoch 103, Loss: 0.44459687001726333\n",
      "Epoch 104, Loss: 0.44355147985040144\n",
      "Epoch 105, Loss: 0.4425101865253278\n",
      "Epoch 106, Loss: 0.44155977330644935\n",
      "Epoch 107, Loss: 0.4406979033849402\n",
      "Epoch 108, Loss: 0.4398604137455411\n",
      "Epoch 109, Loss: 0.4390567942075492\n",
      "Epoch 110, Loss: 0.43825901131469636\n",
      "Epoch 111, Loss: 0.437351218538341\n",
      "Epoch 112, Loss: 0.4363821257504181\n",
      "Epoch 113, Loss: 0.4354367993763784\n",
      "Epoch 114, Loss: 0.4345370504958485\n",
      "Epoch 115, Loss: 0.4336687143492729\n",
      "Epoch 116, Loss: 0.4328336152803024\n",
      "Epoch 117, Loss: 0.43200862956368613\n",
      "Epoch 118, Loss: 0.43120076133372415\n",
      "Epoch 119, Loss: 0.43041716957186\n",
      "Epoch 120, Loss: 0.42963910263773475\n",
      "Epoch 121, Loss: 0.4288539256991745\n",
      "Epoch 122, Loss: 0.4281442846702366\n",
      "Epoch 123, Loss: 0.4275288371069685\n",
      "Epoch 124, Loss: 0.42654555080961043\n",
      "Epoch 125, Loss: 0.4254791517943965\n",
      "Epoch 126, Loss: 0.4249691699570346\n",
      "Epoch 127, Loss: 0.42433308699186917\n",
      "Epoch 128, Loss: 0.4234105879335963\n",
      "Epoch 129, Loss: 0.4228841579639748\n",
      "Epoch 130, Loss: 0.4223927041097395\n",
      "Epoch 131, Loss: 0.4216260175310982\n",
      "Epoch 132, Loss: 0.4209689725113941\n",
      "Epoch 133, Loss: 0.42052754924149577\n",
      "Epoch 134, Loss: 0.4198237282252546\n",
      "Epoch 135, Loss: 0.4191451763037512\n",
      "Epoch 136, Loss: 0.4186025609039237\n",
      "Epoch 137, Loss: 0.41807369447702863\n",
      "Epoch 138, Loss: 0.41744580933659076\n",
      "Epoch 139, Loss: 0.4168123844768337\n",
      "Epoch 140, Loss: 0.4162887070962055\n",
      "Epoch 141, Loss: 0.415768778462321\n",
      "Epoch 142, Loss: 0.4152450230005647\n",
      "Epoch 143, Loss: 0.41461968270573285\n",
      "Epoch 144, Loss: 0.41400862289285184\n",
      "Epoch 145, Loss: 0.41330583279336003\n",
      "Epoch 146, Loss: 0.41270077110973663\n",
      "Epoch 147, Loss: 0.4121065184869344\n",
      "Epoch 148, Loss: 0.4115285712864716\n",
      "Epoch 149, Loss: 0.41105323075650185\n",
      "Epoch 150, Loss: 0.41064821438946325\n",
      "Epoch 151, Loss: 0.4107312667635616\n",
      "Epoch 152, Loss: 0.41170027617208294\n",
      "Epoch 153, Loss: 0.4109708779707564\n",
      "Epoch 154, Loss: 0.40848044507509895\n",
      "Epoch 155, Loss: 0.4095831363764173\n",
      "Epoch 156, Loss: 0.40815588572823003\n",
      "Epoch 157, Loss: 0.4075355546746032\n",
      "Epoch 158, Loss: 0.4076422895188223\n",
      "Epoch 159, Loss: 0.4061262235614242\n",
      "Epoch 160, Loss: 0.4065844186420554\n",
      "Epoch 161, Loss: 0.40533376957034384\n",
      "Epoch 162, Loss: 0.40531380693611724\n",
      "Epoch 163, Loss: 0.40478764108739546\n",
      "Epoch 164, Loss: 0.40424440568651876\n",
      "Epoch 165, Loss: 0.4039639378270862\n",
      "Epoch 166, Loss: 0.40353317739563616\n",
      "Epoch 167, Loss: 0.40299302092015765\n",
      "Epoch 168, Loss: 0.40275415765994876\n",
      "Epoch 169, Loss: 0.40212601260578607\n",
      "Epoch 170, Loss: 0.4018324779362687\n",
      "Epoch 171, Loss: 0.4015441652854698\n",
      "Epoch 172, Loss: 0.400883143747587\n",
      "Epoch 173, Loss: 0.4008562683330051\n",
      "Epoch 174, Loss: 0.4001481042797729\n",
      "Epoch 175, Loss: 0.40000616083765067\n",
      "Epoch 176, Loss: 0.3994285002619592\n",
      "Epoch 177, Loss: 0.3992693202766925\n",
      "Epoch 178, Loss: 0.3986904612848483\n",
      "Epoch 179, Loss: 0.3984289355386017\n",
      "Epoch 180, Loss: 0.39812825861844386\n",
      "Epoch 181, Loss: 0.3975556844118995\n",
      "Epoch 182, Loss: 0.3973716991823854\n",
      "Epoch 183, Loss: 0.3968989455140596\n",
      "Epoch 184, Loss: 0.3965180481390475\n",
      "Epoch 185, Loss: 0.3962887060352751\n",
      "Epoch 186, Loss: 0.39579035709714766\n",
      "Epoch 187, Loss: 0.3954484306309132\n",
      "Epoch 188, Loss: 0.3951725421773337\n",
      "Epoch 189, Loss: 0.3947357365421239\n",
      "Epoch 190, Loss: 0.39438815401753374\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.23313977332790725\n",
      "Test R^2 score: 0.41249634757328724\n",
      "Num of epochs: 191\n",
      "Epoch 1, Loss: 0.6096955703287255\n",
      "Epoch 2, Loss: 0.6062164120365793\n",
      "Epoch 3, Loss: 0.6029410234824634\n",
      "Epoch 4, Loss: 0.5999699108208518\n",
      "Epoch 5, Loss: 0.5971179857023723\n",
      "Epoch 6, Loss: 0.5944093005193984\n",
      "Epoch 7, Loss: 0.5918271148308036\n",
      "Epoch 8, Loss: 0.5893308417888263\n",
      "Epoch 9, Loss: 0.5869152050038927\n",
      "Epoch 10, Loss: 0.584580515865824\n",
      "Epoch 11, Loss: 0.5824187096369671\n",
      "Epoch 12, Loss: 0.5803851461466433\n",
      "Epoch 13, Loss: 0.5784676799186226\n",
      "Epoch 14, Loss: 0.5766127370642214\n",
      "Epoch 15, Loss: 0.5749289862691496\n",
      "Epoch 16, Loss: 0.5733762256200884\n",
      "Epoch 17, Loss: 0.5718689673267127\n",
      "Epoch 18, Loss: 0.5704103150814066\n",
      "Epoch 19, Loss: 0.5689976310311934\n",
      "Epoch 20, Loss: 0.5676253517702546\n",
      "Epoch 21, Loss: 0.5662929026874841\n",
      "Epoch 22, Loss: 0.5650124072510224\n",
      "Epoch 23, Loss: 0.5637801755623523\n",
      "Epoch 24, Loss: 0.5626057154603473\n",
      "Epoch 25, Loss: 0.561518023920915\n",
      "Epoch 26, Loss: 0.5604524433198097\n",
      "Epoch 27, Loss: 0.5594046781967582\n",
      "Epoch 28, Loss: 0.5583645810687445\n",
      "Epoch 29, Loss: 0.5573231845630217\n",
      "Epoch 30, Loss: 0.5562659357767128\n",
      "Epoch 31, Loss: 0.5551794583778429\n",
      "Epoch 32, Loss: 0.5540432210495309\n",
      "Epoch 33, Loss: 0.5528313649410564\n",
      "Epoch 34, Loss: 0.5515510104012002\n",
      "Epoch 35, Loss: 0.5502078270563784\n",
      "Epoch 36, Loss: 0.5488029555661688\n",
      "Epoch 37, Loss: 0.547240108137447\n",
      "Epoch 38, Loss: 0.5454020145255954\n",
      "Epoch 39, Loss: 0.5432324215238891\n",
      "Epoch 40, Loss: 0.540704768696042\n",
      "Epoch 41, Loss: 0.5378764276009067\n",
      "Epoch 42, Loss: 0.5349400772868763\n",
      "Epoch 43, Loss: 0.5321849841754469\n",
      "Epoch 44, Loss: 0.5300492292159095\n",
      "Epoch 45, Loss: 0.5289841463547375\n",
      "Epoch 46, Loss: 0.5284632632191957\n",
      "Epoch 47, Loss: 0.5269183385634344\n",
      "Epoch 48, Loss: 0.5239316970192579\n",
      "Epoch 49, Loss: 0.5205185193075345\n",
      "Epoch 50, Loss: 0.5176224599599526\n",
      "Epoch 51, Loss: 0.5155857822647167\n",
      "Epoch 52, Loss: 0.5141258409429713\n",
      "Epoch 53, Loss: 0.5128031880557841\n",
      "Epoch 54, Loss: 0.5112290696614094\n",
      "Epoch 55, Loss: 0.5092531163715335\n",
      "Epoch 56, Loss: 0.5069720723042654\n",
      "Epoch 57, Loss: 0.504676466782849\n",
      "Epoch 58, Loss: 0.5026742230807799\n",
      "Epoch 59, Loss: 0.5010708428319147\n",
      "Epoch 60, Loss: 0.49955242211151085\n",
      "Epoch 61, Loss: 0.4977478625712924\n",
      "Epoch 62, Loss: 0.49570341598706613\n",
      "Epoch 63, Loss: 0.49382364713705307\n",
      "Epoch 64, Loss: 0.49232104170090407\n",
      "Epoch 65, Loss: 0.4909452474408956\n",
      "Epoch 66, Loss: 0.48933757200384537\n",
      "Epoch 67, Loss: 0.4875002604263784\n",
      "Epoch 68, Loss: 0.48573634899942203\n",
      "Epoch 69, Loss: 0.4842973769964234\n",
      "Epoch 70, Loss: 0.48303315203782643\n",
      "Epoch 71, Loss: 0.48161557419377515\n",
      "Epoch 72, Loss: 0.4801613669552614\n",
      "Epoch 73, Loss: 0.4789452784256456\n",
      "Epoch 74, Loss: 0.4778617907311716\n",
      "Epoch 75, Loss: 0.47663709963395323\n",
      "Epoch 76, Loss: 0.4753189590837865\n",
      "Epoch 77, Loss: 0.47416311248738935\n",
      "Epoch 78, Loss: 0.4730895239758878\n",
      "Epoch 79, Loss: 0.47187251538765695\n",
      "Epoch 80, Loss: 0.47061851342481686\n",
      "Epoch 81, Loss: 0.46946371103693196\n",
      "Epoch 82, Loss: 0.46830023805028587\n",
      "Epoch 83, Loss: 0.4670387184258063\n",
      "Epoch 84, Loss: 0.465798447453666\n",
      "Epoch 85, Loss: 0.46461615881257795\n",
      "Epoch 86, Loss: 0.4633603991720831\n",
      "Epoch 87, Loss: 0.4621383251624742\n",
      "Epoch 88, Loss: 0.4610769254949431\n",
      "Epoch 89, Loss: 0.46007199576608127\n",
      "Epoch 90, Loss: 0.45908142037869343\n",
      "Epoch 91, Loss: 0.4582122476617597\n",
      "Epoch 92, Loss: 0.45748876836674857\n",
      "Epoch 93, Loss: 0.45686030655180165\n",
      "Epoch 94, Loss: 0.4563154173683169\n",
      "Epoch 95, Loss: 0.4558193898581898\n",
      "Epoch 96, Loss: 0.45535482745289835\n",
      "Epoch 97, Loss: 0.4547658184282435\n",
      "Epoch 98, Loss: 0.45416290525167863\n",
      "Epoch 99, Loss: 0.4535693259238734\n",
      "Epoch 100, Loss: 0.4529683236853392\n",
      "Epoch 101, Loss: 0.4523581066060445\n",
      "Epoch 102, Loss: 0.45165698900916523\n",
      "Epoch 103, Loss: 0.4510953103366526\n",
      "Epoch 104, Loss: 0.450540009312833\n",
      "Epoch 105, Loss: 0.45000596108726854\n",
      "Epoch 106, Loss: 0.44951734156037015\n",
      "Epoch 107, Loss: 0.44903753191318085\n",
      "Epoch 108, Loss: 0.448504369182845\n",
      "Epoch 109, Loss: 0.44795856353812513\n",
      "Epoch 110, Loss: 0.4473915755661795\n",
      "Epoch 111, Loss: 0.4468719382281219\n",
      "Epoch 112, Loss: 0.446366384807121\n",
      "Epoch 113, Loss: 0.445861127096971\n",
      "Epoch 114, Loss: 0.4453377967475645\n",
      "Epoch 115, Loss: 0.4448600612231926\n",
      "Epoch 116, Loss: 0.44438226479280485\n",
      "Epoch 117, Loss: 0.44389525977618177\n",
      "Epoch 118, Loss: 0.4434221366118855\n",
      "Epoch 119, Loss: 0.4429405519636813\n",
      "Epoch 120, Loss: 0.44246034595378897\n",
      "Epoch 121, Loss: 0.44198481022185626\n",
      "Epoch 122, Loss: 0.44151733486018463\n",
      "Epoch 123, Loss: 0.4410456306785123\n",
      "Epoch 124, Loss: 0.44055010044021853\n",
      "Epoch 125, Loss: 0.4400425327941348\n",
      "Epoch 126, Loss: 0.4395235980005493\n",
      "Epoch 127, Loss: 0.43895588187806706\n",
      "Epoch 128, Loss: 0.43834684360495146\n",
      "Epoch 129, Loss: 0.43773239639110106\n",
      "Epoch 130, Loss: 0.43710658572809546\n",
      "Epoch 131, Loss: 0.4364930554085498\n",
      "Epoch 132, Loss: 0.4358913957833984\n",
      "Epoch 133, Loss: 0.4353260113220613\n",
      "Epoch 134, Loss: 0.434800847658333\n",
      "Epoch 135, Loss: 0.4343043166907636\n",
      "Epoch 136, Loss: 0.4338838448816736\n",
      "Epoch 137, Loss: 0.43344500284226345\n",
      "Epoch 138, Loss: 0.432826609329892\n",
      "Epoch 139, Loss: 0.4322389279409716\n",
      "Epoch 140, Loss: 0.43183504446999266\n",
      "Epoch 141, Loss: 0.43137156182983005\n",
      "Epoch 142, Loss: 0.43081714219094097\n",
      "Epoch 143, Loss: 0.4303263336927769\n",
      "Epoch 144, Loss: 0.42994536551772444\n",
      "Epoch 145, Loss: 0.42960844179597685\n",
      "Epoch 146, Loss: 0.4291875705288415\n",
      "Epoch 147, Loss: 0.428679706244025\n",
      "Epoch 148, Loss: 0.4282007505409847\n",
      "Epoch 149, Loss: 0.4278255870536647\n",
      "Epoch 150, Loss: 0.4274916809510701\n",
      "Epoch 151, Loss: 0.4271074342517848\n",
      "Epoch 152, Loss: 0.4266952887852759\n",
      "Epoch 153, Loss: 0.42621385837827036\n",
      "Epoch 154, Loss: 0.4257673033783724\n",
      "Epoch 155, Loss: 0.4253393382252206\n",
      "Epoch 156, Loss: 0.42492977361532147\n",
      "Epoch 157, Loss: 0.42451523313609907\n",
      "Epoch 158, Loss: 0.42412249279208686\n",
      "Epoch 159, Loss: 0.4237102924861449\n",
      "Epoch 160, Loss: 0.4234210225801993\n",
      "Epoch 161, Loss: 0.4236162596617261\n",
      "Epoch 162, Loss: 0.4236149229684198\n",
      "Epoch 163, Loss: 0.4222332704695701\n",
      "Epoch 164, Loss: 0.4213668977710438\n",
      "Epoch 165, Loss: 0.4217479125854807\n",
      "Epoch 166, Loss: 0.42064657442218656\n",
      "Epoch 167, Loss: 0.41992020717555784\n",
      "Epoch 168, Loss: 0.42010426663259537\n",
      "Epoch 169, Loss: 0.41901155317147254\n",
      "Epoch 170, Loss: 0.4185853314096034\n",
      "Epoch 171, Loss: 0.4185914721681504\n",
      "Epoch 172, Loss: 0.41760569696422745\n",
      "Epoch 173, Loss: 0.4173028043643577\n",
      "Epoch 174, Loss: 0.41718232512389886\n",
      "Epoch 175, Loss: 0.4163640671883414\n",
      "Epoch 176, Loss: 0.4160181502144696\n",
      "Epoch 177, Loss: 0.415912687075977\n",
      "Epoch 178, Loss: 0.41526038159294876\n",
      "Epoch 179, Loss: 0.41477277403602003\n",
      "Epoch 180, Loss: 0.41461292605319683\n",
      "Epoch 181, Loss: 0.4141418452983408\n",
      "Epoch 182, Loss: 0.41352067440891604\n",
      "Epoch 183, Loss: 0.4132046359895201\n",
      "Epoch 184, Loss: 0.41297651424318554\n",
      "Epoch 185, Loss: 0.4125362011889993\n",
      "Epoch 186, Loss: 0.41200394208304525\n",
      "Epoch 187, Loss: 0.41156776598644024\n",
      "Epoch 188, Loss: 0.4113125985630475\n",
      "Epoch 189, Loss: 0.4111233164218427\n",
      "Epoch 190, Loss: 0.41084406265475537\n",
      "Epoch 191, Loss: 0.4106138492330153\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22091749651825915\n",
      "Test R^2 score: 0.47092170369733344\n",
      "Num of epochs: 192\n",
      "Epoch 1, Loss: 0.5627145622903877\n",
      "Epoch 2, Loss: 0.56143373519245\n",
      "Epoch 3, Loss: 0.5603080001284424\n",
      "Epoch 4, Loss: 0.559379078940752\n",
      "Epoch 5, Loss: 0.5585981248804315\n",
      "Epoch 6, Loss: 0.5579406548324655\n",
      "Epoch 7, Loss: 0.5574097523109541\n",
      "Epoch 8, Loss: 0.5569931520164353\n",
      "Epoch 9, Loss: 0.5566714094249285\n",
      "Epoch 10, Loss: 0.5564355037275915\n",
      "Epoch 11, Loss: 0.5562756864639071\n",
      "Epoch 12, Loss: 0.556181681648751\n",
      "Epoch 13, Loss: 0.5561410636528227\n",
      "Epoch 14, Loss: 0.556141144034372\n",
      "Epoch 15, Loss: 0.55616908931557\n",
      "Epoch 16, Loss: 0.5562120360374252\n",
      "Epoch 17, Loss: 0.5562581672497489\n",
      "Epoch 18, Loss: 0.5562979998934384\n",
      "Epoch 19, Loss: 0.5563239284207641\n",
      "Epoch 20, Loss: 0.5563306514263174\n",
      "Epoch 21, Loss: 0.5563155178532068\n",
      "Epoch 22, Loss: 0.5562789277259206\n",
      "Epoch 23, Loss: 0.5562241183914042\n",
      "Epoch 24, Loss: 0.556149182130637\n",
      "Epoch 25, Loss: 0.5560533604607727\n",
      "Epoch 26, Loss: 0.5559398858210558\n",
      "Epoch 27, Loss: 0.5558052889151199\n",
      "Epoch 28, Loss: 0.5556404631686778\n",
      "Epoch 29, Loss: 0.5554315653827637\n",
      "Epoch 30, Loss: 0.5551644544695745\n",
      "Epoch 31, Loss: 0.5548246778187538\n",
      "Epoch 32, Loss: 0.5544137951029077\n",
      "Epoch 33, Loss: 0.5539327510202778\n",
      "Epoch 34, Loss: 0.553370537651343\n",
      "Epoch 35, Loss: 0.5527098956938554\n",
      "Epoch 36, Loss: 0.5519116752595022\n",
      "Epoch 37, Loss: 0.5508821273301088\n",
      "Epoch 38, Loss: 0.5494982880313158\n",
      "Epoch 39, Loss: 0.547700558555601\n",
      "Epoch 40, Loss: 0.5454376678221755\n",
      "Epoch 41, Loss: 0.5426459416300886\n",
      "Epoch 42, Loss: 0.5393296008491719\n",
      "Epoch 43, Loss: 0.5354155587458249\n",
      "Epoch 44, Loss: 0.530916894936122\n",
      "Epoch 45, Loss: 0.5257298675415535\n",
      "Epoch 46, Loss: 0.5201429623539243\n",
      "Epoch 47, Loss: 0.5150545895448927\n",
      "Epoch 48, Loss: 0.5119612024776948\n",
      "Epoch 49, Loss: 0.5120461268471177\n",
      "Epoch 50, Loss: 0.511550992301461\n",
      "Epoch 51, Loss: 0.5078394956015598\n",
      "Epoch 52, Loss: 0.5028801754773574\n",
      "Epoch 53, Loss: 0.4989130603529752\n",
      "Epoch 54, Loss: 0.49679083921122613\n",
      "Epoch 55, Loss: 0.4955583521803721\n",
      "Epoch 56, Loss: 0.4939271518540884\n",
      "Epoch 57, Loss: 0.4914183283111406\n",
      "Epoch 58, Loss: 0.4882774352878331\n",
      "Epoch 59, Loss: 0.48487895467728265\n",
      "Epoch 60, Loss: 0.48182227057722676\n",
      "Epoch 61, Loss: 0.4794531687847911\n",
      "Epoch 62, Loss: 0.47771904484878297\n",
      "Epoch 63, Loss: 0.47636152938979726\n",
      "Epoch 64, Loss: 0.47516801711028483\n",
      "Epoch 65, Loss: 0.4742833497291942\n",
      "Epoch 66, Loss: 0.4735811657619639\n",
      "Epoch 67, Loss: 0.47273370407679743\n",
      "Epoch 68, Loss: 0.47166536044837426\n",
      "Epoch 69, Loss: 0.4705229291629232\n",
      "Epoch 70, Loss: 0.4695570990989208\n",
      "Epoch 71, Loss: 0.46873265870124464\n",
      "Epoch 72, Loss: 0.46784504320479225\n",
      "Epoch 73, Loss: 0.4668765139778643\n",
      "Epoch 74, Loss: 0.4657209758284287\n",
      "Epoch 75, Loss: 0.4644843403021273\n",
      "Epoch 76, Loss: 0.4633333527470088\n",
      "Epoch 77, Loss: 0.46222624602799006\n",
      "Epoch 78, Loss: 0.46119731111090045\n",
      "Epoch 79, Loss: 0.46031562428602196\n",
      "Epoch 80, Loss: 0.45947982344677374\n",
      "Epoch 81, Loss: 0.458670748431642\n",
      "Epoch 82, Loss: 0.4578724317413543\n",
      "Epoch 83, Loss: 0.45715521085014627\n",
      "Epoch 84, Loss: 0.45644921956901846\n",
      "Epoch 85, Loss: 0.455689784573615\n",
      "Epoch 86, Loss: 0.4549097232548433\n",
      "Epoch 87, Loss: 0.45415104422108515\n",
      "Epoch 88, Loss: 0.4533790172349494\n",
      "Epoch 89, Loss: 0.45258512892226704\n",
      "Epoch 90, Loss: 0.4518471655444476\n",
      "Epoch 91, Loss: 0.4511355596021559\n",
      "Epoch 92, Loss: 0.45042426851311324\n",
      "Epoch 93, Loss: 0.4497421035592908\n",
      "Epoch 94, Loss: 0.44903738258215226\n",
      "Epoch 95, Loss: 0.44833082266049024\n",
      "Epoch 96, Loss: 0.44762291442951957\n",
      "Epoch 97, Loss: 0.4468870268050291\n",
      "Epoch 98, Loss: 0.4461644205209743\n",
      "Epoch 99, Loss: 0.44546022809085084\n",
      "Epoch 100, Loss: 0.4447679033862652\n",
      "Epoch 101, Loss: 0.44407095920524176\n",
      "Epoch 102, Loss: 0.44339167271409735\n",
      "Epoch 103, Loss: 0.44272442021780833\n",
      "Epoch 104, Loss: 0.4420284510901772\n",
      "Epoch 105, Loss: 0.4413493465778306\n",
      "Epoch 106, Loss: 0.44066882355191483\n",
      "Epoch 107, Loss: 0.43999341176801027\n",
      "Epoch 108, Loss: 0.4393128743481476\n",
      "Epoch 109, Loss: 0.43864011369302464\n",
      "Epoch 110, Loss: 0.4379922277640621\n",
      "Epoch 111, Loss: 0.43729624090517766\n",
      "Epoch 112, Loss: 0.4366059193355792\n",
      "Epoch 113, Loss: 0.43593821029878677\n",
      "Epoch 114, Loss: 0.4352770940617981\n",
      "Epoch 115, Loss: 0.4346350118072556\n",
      "Epoch 116, Loss: 0.434026416352574\n",
      "Epoch 117, Loss: 0.43343382970662747\n",
      "Epoch 118, Loss: 0.43281839828052765\n",
      "Epoch 119, Loss: 0.4322232762973281\n",
      "Epoch 120, Loss: 0.43161854752225803\n",
      "Epoch 121, Loss: 0.43101516563193293\n",
      "Epoch 122, Loss: 0.4304411261361344\n",
      "Epoch 123, Loss: 0.4298756100971122\n",
      "Epoch 124, Loss: 0.42938912175484073\n",
      "Epoch 125, Loss: 0.4291244285439682\n",
      "Epoch 126, Loss: 0.42878182070680027\n",
      "Epoch 127, Loss: 0.4280086143342007\n",
      "Epoch 128, Loss: 0.42707114861327206\n",
      "Epoch 129, Loss: 0.42694300773060084\n",
      "Epoch 130, Loss: 0.4263262978560581\n",
      "Epoch 131, Loss: 0.42548412489945864\n",
      "Epoch 132, Loss: 0.42532984401814733\n",
      "Epoch 133, Loss: 0.42471296701430017\n",
      "Epoch 134, Loss: 0.42390569513202353\n",
      "Epoch 135, Loss: 0.42367969497984814\n",
      "Epoch 136, Loss: 0.42307703645077765\n",
      "Epoch 137, Loss: 0.4222894328390294\n",
      "Epoch 138, Loss: 0.42201707355030754\n",
      "Epoch 139, Loss: 0.421483812163846\n",
      "Epoch 140, Loss: 0.4206871157179559\n",
      "Epoch 141, Loss: 0.42040840175142935\n",
      "Epoch 142, Loss: 0.41999835715086115\n",
      "Epoch 143, Loss: 0.41916942159772475\n",
      "Epoch 144, Loss: 0.41875200769313226\n",
      "Epoch 145, Loss: 0.41850025928539414\n",
      "Epoch 146, Loss: 0.41778603240971085\n",
      "Epoch 147, Loss: 0.41707179718882326\n",
      "Epoch 148, Loss: 0.41665174537008376\n",
      "Epoch 149, Loss: 0.4163248050476435\n",
      "Epoch 150, Loss: 0.41585523352100656\n",
      "Epoch 151, Loss: 0.4150874569671523\n",
      "Epoch 152, Loss: 0.41430397909520034\n",
      "Epoch 153, Loss: 0.4137818266910164\n",
      "Epoch 154, Loss: 0.41334907681851296\n",
      "Epoch 155, Loss: 0.4132238387846268\n",
      "Epoch 156, Loss: 0.4127766779475209\n",
      "Epoch 157, Loss: 0.4121490387111802\n",
      "Epoch 158, Loss: 0.41127414041180876\n",
      "Epoch 159, Loss: 0.41048795819944794\n",
      "Epoch 160, Loss: 0.4097714208260293\n",
      "Epoch 161, Loss: 0.40930889338443455\n",
      "Epoch 162, Loss: 0.4092413188978342\n",
      "Epoch 163, Loss: 0.40995525703293056\n",
      "Epoch 164, Loss: 0.4105502098521527\n",
      "Epoch 165, Loss: 0.4078528621767233\n",
      "Epoch 166, Loss: 0.40699049513143054\n",
      "Epoch 167, Loss: 0.4082379850989443\n",
      "Epoch 168, Loss: 0.40664803739125954\n",
      "Epoch 169, Loss: 0.4054157972212143\n",
      "Epoch 170, Loss: 0.4059943898886857\n",
      "Epoch 171, Loss: 0.4053915564055301\n",
      "Epoch 172, Loss: 0.4040912897897833\n",
      "Epoch 173, Loss: 0.40352708443898033\n",
      "Epoch 174, Loss: 0.4036075594404396\n",
      "Epoch 175, Loss: 0.40337534014152887\n",
      "Epoch 176, Loss: 0.40213592495009387\n",
      "Epoch 177, Loss: 0.40137838083516664\n",
      "Epoch 178, Loss: 0.4012393051576041\n",
      "Epoch 179, Loss: 0.40114201078902517\n",
      "Epoch 180, Loss: 0.4005625657992072\n",
      "Epoch 181, Loss: 0.39950489606232353\n",
      "Epoch 182, Loss: 0.3988489196019091\n",
      "Epoch 183, Loss: 0.3987735191572176\n",
      "Epoch 184, Loss: 0.3987288438332714\n",
      "Epoch 185, Loss: 0.3985928251404539\n",
      "Epoch 186, Loss: 0.3974430539468516\n",
      "Epoch 187, Loss: 0.3966699551130807\n",
      "Epoch 188, Loss: 0.3958168235481233\n",
      "Epoch 189, Loss: 0.3951450709537412\n",
      "Epoch 190, Loss: 0.39460640370895406\n",
      "Epoch 191, Loss: 0.3941834871636144\n",
      "Epoch 192, Loss: 0.3943630464256651\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22477198107864482\n",
      "Test R^2 score: 0.4533025026210779\n",
      "Num of epochs: 193\n",
      "Epoch 1, Loss: 0.5956311541996911\n",
      "Epoch 2, Loss: 0.5934656114634358\n",
      "Epoch 3, Loss: 0.5914912426043102\n",
      "Epoch 4, Loss: 0.5895927097082704\n",
      "Epoch 5, Loss: 0.5877698096146066\n",
      "Epoch 6, Loss: 0.5860195865352262\n",
      "Epoch 7, Loss: 0.5843413674779122\n",
      "Epoch 8, Loss: 0.5827334475660123\n",
      "Epoch 9, Loss: 0.5812525820931128\n",
      "Epoch 10, Loss: 0.5798810630558666\n",
      "Epoch 11, Loss: 0.5785695506120914\n",
      "Epoch 12, Loss: 0.5773628727245682\n",
      "Epoch 13, Loss: 0.5762585332325559\n",
      "Epoch 14, Loss: 0.5752384707154682\n",
      "Epoch 15, Loss: 0.5742361883512803\n",
      "Epoch 16, Loss: 0.5733187362795821\n",
      "Epoch 17, Loss: 0.5724181404892649\n",
      "Epoch 18, Loss: 0.5715236866715596\n",
      "Epoch 19, Loss: 0.5706415925219722\n",
      "Epoch 20, Loss: 0.5697744784183181\n",
      "Epoch 21, Loss: 0.5689218628251532\n",
      "Epoch 22, Loss: 0.5680984737217267\n",
      "Epoch 23, Loss: 0.5672952712476035\n",
      "Epoch 24, Loss: 0.5665211265089145\n",
      "Epoch 25, Loss: 0.5657678360548554\n",
      "Epoch 26, Loss: 0.5650238530854352\n",
      "Epoch 27, Loss: 0.5642966611276343\n",
      "Epoch 28, Loss: 0.5635919568461888\n",
      "Epoch 29, Loss: 0.5629068333914966\n",
      "Epoch 30, Loss: 0.5623038797747053\n",
      "Epoch 31, Loss: 0.5616953976250928\n",
      "Epoch 32, Loss: 0.5610980205325569\n",
      "Epoch 33, Loss: 0.5605082747829497\n",
      "Epoch 34, Loss: 0.5598799828939782\n",
      "Epoch 35, Loss: 0.5592430182811137\n",
      "Epoch 36, Loss: 0.5586010325563983\n",
      "Epoch 37, Loss: 0.5579414293474089\n",
      "Epoch 38, Loss: 0.5572403203774727\n",
      "Epoch 39, Loss: 0.5564789922181574\n",
      "Epoch 40, Loss: 0.5556610321874066\n",
      "Epoch 41, Loss: 0.5547629828874304\n",
      "Epoch 42, Loss: 0.553700118993602\n",
      "Epoch 43, Loss: 0.5524213194166585\n",
      "Epoch 44, Loss: 0.5508439589710113\n",
      "Epoch 45, Loss: 0.548875609817809\n",
      "Epoch 46, Loss: 0.5464202352407953\n",
      "Epoch 47, Loss: 0.5433700505626434\n",
      "Epoch 48, Loss: 0.5397069368468297\n",
      "Epoch 49, Loss: 0.5356086711998551\n",
      "Epoch 50, Loss: 0.5315106257491672\n",
      "Epoch 51, Loss: 0.5283664535145318\n",
      "Epoch 52, Loss: 0.5274049511469856\n",
      "Epoch 53, Loss: 0.5276936818209985\n",
      "Epoch 54, Loss: 0.5263152087986404\n",
      "Epoch 55, Loss: 0.523329680995993\n",
      "Epoch 56, Loss: 0.5203801440466463\n",
      "Epoch 57, Loss: 0.5183014332081908\n",
      "Epoch 58, Loss: 0.516856024507977\n",
      "Epoch 59, Loss: 0.5154643241921276\n",
      "Epoch 60, Loss: 0.5137358360936878\n",
      "Epoch 61, Loss: 0.5115971020255579\n",
      "Epoch 62, Loss: 0.5091027813752476\n",
      "Epoch 63, Loss: 0.5065380536722182\n",
      "Epoch 64, Loss: 0.5042621922699864\n",
      "Epoch 65, Loss: 0.5025424392296162\n",
      "Epoch 66, Loss: 0.501222278798744\n",
      "Epoch 67, Loss: 0.4997702458132105\n",
      "Epoch 68, Loss: 0.497753011737489\n",
      "Epoch 69, Loss: 0.4955531351054006\n",
      "Epoch 70, Loss: 0.49381853243686186\n",
      "Epoch 71, Loss: 0.4926314244184148\n",
      "Epoch 72, Loss: 0.4915317375175352\n",
      "Epoch 73, Loss: 0.49010113125008736\n",
      "Epoch 74, Loss: 0.48824255217747553\n",
      "Epoch 75, Loss: 0.486258352399153\n",
      "Epoch 76, Loss: 0.4845835175381302\n",
      "Epoch 77, Loss: 0.4833960793177565\n",
      "Epoch 78, Loss: 0.4822887128762848\n",
      "Epoch 79, Loss: 0.4807765409023888\n",
      "Epoch 80, Loss: 0.47900494838838437\n",
      "Epoch 81, Loss: 0.4774170077935228\n",
      "Epoch 82, Loss: 0.4761271442436153\n",
      "Epoch 83, Loss: 0.47481281331624287\n",
      "Epoch 84, Loss: 0.4732554239837833\n",
      "Epoch 85, Loss: 0.47153555995971946\n",
      "Epoch 86, Loss: 0.4698262099051599\n",
      "Epoch 87, Loss: 0.46819806984002904\n",
      "Epoch 88, Loss: 0.4666037858452565\n",
      "Epoch 89, Loss: 0.4650613291607383\n",
      "Epoch 90, Loss: 0.46360221924485134\n",
      "Epoch 91, Loss: 0.4623315549520372\n",
      "Epoch 92, Loss: 0.4612708421975955\n",
      "Epoch 93, Loss: 0.46031230618329705\n",
      "Epoch 94, Loss: 0.4593068876828088\n",
      "Epoch 95, Loss: 0.4581678066316959\n",
      "Epoch 96, Loss: 0.4570240770086815\n",
      "Epoch 97, Loss: 0.45596503738691635\n",
      "Epoch 98, Loss: 0.45494924201910575\n",
      "Epoch 99, Loss: 0.4540618222803255\n",
      "Epoch 100, Loss: 0.4533979153065235\n",
      "Epoch 101, Loss: 0.45281651289104885\n",
      "Epoch 102, Loss: 0.4521675847326947\n",
      "Epoch 103, Loss: 0.4515377724288838\n",
      "Epoch 104, Loss: 0.45097186456598304\n",
      "Epoch 105, Loss: 0.4503744931404762\n",
      "Epoch 106, Loss: 0.44972977803344044\n",
      "Epoch 107, Loss: 0.44907132922513854\n",
      "Epoch 108, Loss: 0.448422347952561\n",
      "Epoch 109, Loss: 0.4477916439547766\n",
      "Epoch 110, Loss: 0.447123942360335\n",
      "Epoch 111, Loss: 0.44643040929143524\n",
      "Epoch 112, Loss: 0.445767772242176\n",
      "Epoch 113, Loss: 0.44516713296127225\n",
      "Epoch 114, Loss: 0.444593216745383\n",
      "Epoch 115, Loss: 0.4440198339841429\n",
      "Epoch 116, Loss: 0.44343813226075424\n",
      "Epoch 117, Loss: 0.44275740370222433\n",
      "Epoch 118, Loss: 0.4421257130889707\n",
      "Epoch 119, Loss: 0.4415569385791173\n",
      "Epoch 120, Loss: 0.4409918232146763\n",
      "Epoch 121, Loss: 0.4404688815589971\n",
      "Epoch 122, Loss: 0.43991744201627\n",
      "Epoch 123, Loss: 0.4393304272069793\n",
      "Epoch 124, Loss: 0.4387490460257742\n",
      "Epoch 125, Loss: 0.43820542276248947\n",
      "Epoch 126, Loss: 0.43766881887248604\n",
      "Epoch 127, Loss: 0.4371259998095202\n",
      "Epoch 128, Loss: 0.4365545001488236\n",
      "Epoch 129, Loss: 0.43598989014650263\n",
      "Epoch 130, Loss: 0.4353988293214111\n",
      "Epoch 131, Loss: 0.4348249225330607\n",
      "Epoch 132, Loss: 0.4342454703429112\n",
      "Epoch 133, Loss: 0.43363103620342164\n",
      "Epoch 134, Loss: 0.4329755001030646\n",
      "Epoch 135, Loss: 0.4322731940983778\n",
      "Epoch 136, Loss: 0.4316515856425744\n",
      "Epoch 137, Loss: 0.43105962324406255\n",
      "Epoch 138, Loss: 0.43047505078144016\n",
      "Epoch 139, Loss: 0.4298965465772976\n",
      "Epoch 140, Loss: 0.4293125423942853\n",
      "Epoch 141, Loss: 0.42871138935456327\n",
      "Epoch 142, Loss: 0.42809038718426184\n",
      "Epoch 143, Loss: 0.42749629950455464\n",
      "Epoch 144, Loss: 0.42689199542259193\n",
      "Epoch 145, Loss: 0.42629784558830314\n",
      "Epoch 146, Loss: 0.4256998386770762\n",
      "Epoch 147, Loss: 0.42506462124795974\n",
      "Epoch 148, Loss: 0.4244272594269753\n",
      "Epoch 149, Loss: 0.42380634374947296\n",
      "Epoch 150, Loss: 0.4231566634508917\n",
      "Epoch 151, Loss: 0.4225305655951889\n",
      "Epoch 152, Loss: 0.42191551155270257\n",
      "Epoch 153, Loss: 0.42132670482394025\n",
      "Epoch 154, Loss: 0.4207487968794813\n",
      "Epoch 155, Loss: 0.42019314542578434\n",
      "Epoch 156, Loss: 0.4196429901209797\n",
      "Epoch 157, Loss: 0.419102228117745\n",
      "Epoch 158, Loss: 0.4185641851517987\n",
      "Epoch 159, Loss: 0.41803997538117466\n",
      "Epoch 160, Loss: 0.41750539961766664\n",
      "Epoch 161, Loss: 0.4170285640099798\n",
      "Epoch 162, Loss: 0.41663259327169605\n",
      "Epoch 163, Loss: 0.41622274911017426\n",
      "Epoch 164, Loss: 0.41556677087731153\n",
      "Epoch 165, Loss: 0.4149646827020979\n",
      "Epoch 166, Loss: 0.41465276355615965\n",
      "Epoch 167, Loss: 0.41421293728727615\n",
      "Epoch 168, Loss: 0.41353836714855985\n",
      "Epoch 169, Loss: 0.41323847918942963\n",
      "Epoch 170, Loss: 0.41288923986918985\n",
      "Epoch 171, Loss: 0.4122501873966714\n",
      "Epoch 172, Loss: 0.4118500024390536\n",
      "Epoch 173, Loss: 0.4115380399093004\n",
      "Epoch 174, Loss: 0.4109840939581052\n",
      "Epoch 175, Loss: 0.41048064346420843\n",
      "Epoch 176, Loss: 0.41017877426061783\n",
      "Epoch 177, Loss: 0.4096475443789823\n",
      "Epoch 178, Loss: 0.4091122191531004\n",
      "Epoch 179, Loss: 0.4087879426943573\n",
      "Epoch 180, Loss: 0.40837504220920856\n",
      "Epoch 181, Loss: 0.40785512737948176\n",
      "Epoch 182, Loss: 0.40741807564621624\n",
      "Epoch 183, Loss: 0.4070422077717489\n",
      "Epoch 184, Loss: 0.406653772117777\n",
      "Epoch 185, Loss: 0.40618197164956993\n",
      "Epoch 186, Loss: 0.4057135341050153\n",
      "Epoch 187, Loss: 0.4053206450762312\n",
      "Epoch 188, Loss: 0.4049595731997605\n",
      "Epoch 189, Loss: 0.4046242903902645\n",
      "Epoch 190, Loss: 0.4042630388779238\n",
      "Epoch 191, Loss: 0.40386130416751165\n",
      "Epoch 192, Loss: 0.40340819798320654\n",
      "Epoch 193, Loss: 0.40297199938715\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.23046042679845363\n",
      "Test R^2 score: 0.42378533650835953\n",
      "Num of epochs: 194\n",
      "Epoch 1, Loss: 0.6004166030971997\n",
      "Epoch 2, Loss: 0.5985106301506944\n",
      "Epoch 3, Loss: 0.5966442241212992\n",
      "Epoch 4, Loss: 0.5948821367002828\n",
      "Epoch 5, Loss: 0.5932204746305065\n",
      "Epoch 6, Loss: 0.5915820295170199\n",
      "Epoch 7, Loss: 0.58996462057202\n",
      "Epoch 8, Loss: 0.588369409001735\n",
      "Epoch 9, Loss: 0.5867971599010863\n",
      "Epoch 10, Loss: 0.5852482365626867\n",
      "Epoch 11, Loss: 0.583723743673253\n",
      "Epoch 12, Loss: 0.5822260997710234\n",
      "Epoch 13, Loss: 0.5807736783153705\n",
      "Epoch 14, Loss: 0.5793410991062978\n",
      "Epoch 15, Loss: 0.5779280455921464\n",
      "Epoch 16, Loss: 0.576534299496783\n",
      "Epoch 17, Loss: 0.5751669444421837\n",
      "Epoch 18, Loss: 0.573840321514439\n",
      "Epoch 19, Loss: 0.5725301450180785\n",
      "Epoch 20, Loss: 0.5712300066297665\n",
      "Epoch 21, Loss: 0.57002196031229\n",
      "Epoch 22, Loss: 0.5688626921799045\n",
      "Epoch 23, Loss: 0.5677102960908423\n",
      "Epoch 24, Loss: 0.5666001875767664\n",
      "Epoch 25, Loss: 0.5655523506423277\n",
      "Epoch 26, Loss: 0.5645313934655407\n",
      "Epoch 27, Loss: 0.5634810052494915\n",
      "Epoch 28, Loss: 0.562391456091909\n",
      "Epoch 29, Loss: 0.5612606860207657\n",
      "Epoch 30, Loss: 0.5601085317974984\n",
      "Epoch 31, Loss: 0.5589400065239062\n",
      "Epoch 32, Loss: 0.5577349964228688\n",
      "Epoch 33, Loss: 0.5564967990245082\n",
      "Epoch 34, Loss: 0.5551932541002478\n",
      "Epoch 35, Loss: 0.5536963513049321\n",
      "Epoch 36, Loss: 0.5519629443159789\n",
      "Epoch 37, Loss: 0.5497501542740381\n",
      "Epoch 38, Loss: 0.5469291115284155\n",
      "Epoch 39, Loss: 0.5435158148520268\n",
      "Epoch 40, Loss: 0.5396976875090238\n",
      "Epoch 41, Loss: 0.535932659872459\n",
      "Epoch 42, Loss: 0.5330430234109897\n",
      "Epoch 43, Loss: 0.5320177981206702\n",
      "Epoch 44, Loss: 0.5320002643451894\n",
      "Epoch 45, Loss: 0.5301677956913369\n",
      "Epoch 46, Loss: 0.5265249040805234\n",
      "Epoch 47, Loss: 0.5226847231739967\n",
      "Epoch 48, Loss: 0.5197528567251696\n",
      "Epoch 49, Loss: 0.5177380872449158\n",
      "Epoch 50, Loss: 0.5160132304850025\n",
      "Epoch 51, Loss: 0.5140745376058721\n",
      "Epoch 52, Loss: 0.5116856396861336\n",
      "Epoch 53, Loss: 0.5090058317075208\n",
      "Epoch 54, Loss: 0.5065479673245996\n",
      "Epoch 55, Loss: 0.5048182315215308\n",
      "Epoch 56, Loss: 0.5036196522053603\n",
      "Epoch 57, Loss: 0.5020461534317624\n",
      "Epoch 58, Loss: 0.4998831016263657\n",
      "Epoch 59, Loss: 0.4979176073052155\n",
      "Epoch 60, Loss: 0.4965812060443995\n",
      "Epoch 61, Loss: 0.49550076586051134\n",
      "Epoch 62, Loss: 0.49409834488632226\n",
      "Epoch 63, Loss: 0.49235696751253305\n",
      "Epoch 64, Loss: 0.49068674743754004\n",
      "Epoch 65, Loss: 0.48944875375754837\n",
      "Epoch 66, Loss: 0.48835816349800143\n",
      "Epoch 67, Loss: 0.4869148667531997\n",
      "Epoch 68, Loss: 0.4853117559983642\n",
      "Epoch 69, Loss: 0.48398181893056275\n",
      "Epoch 70, Loss: 0.4828736047440688\n",
      "Epoch 71, Loss: 0.48166382262711344\n",
      "Epoch 72, Loss: 0.4802861680883476\n",
      "Epoch 73, Loss: 0.4789993332577487\n",
      "Epoch 74, Loss: 0.47794089543865104\n",
      "Epoch 75, Loss: 0.47685043829163487\n",
      "Epoch 76, Loss: 0.47555427524203914\n",
      "Epoch 77, Loss: 0.4743435433101625\n",
      "Epoch 78, Loss: 0.47330617751489307\n",
      "Epoch 79, Loss: 0.4722158413655382\n",
      "Epoch 80, Loss: 0.4709977933159745\n",
      "Epoch 81, Loss: 0.4698352489710918\n",
      "Epoch 82, Loss: 0.4687927385555905\n",
      "Epoch 83, Loss: 0.46769108375849355\n",
      "Epoch 84, Loss: 0.4665389685244312\n",
      "Epoch 85, Loss: 0.4654862267477633\n",
      "Epoch 86, Loss: 0.4644785977525714\n",
      "Epoch 87, Loss: 0.4634406126076008\n",
      "Epoch 88, Loss: 0.4624837382782712\n",
      "Epoch 89, Loss: 0.4615970031507947\n",
      "Epoch 90, Loss: 0.46072111061338566\n",
      "Epoch 91, Loss: 0.45986770689319806\n",
      "Epoch 92, Loss: 0.45906238298823643\n",
      "Epoch 93, Loss: 0.45820816635649586\n",
      "Epoch 94, Loss: 0.45734464871416325\n",
      "Epoch 95, Loss: 0.4565278565868659\n",
      "Epoch 96, Loss: 0.45566552035625424\n",
      "Epoch 97, Loss: 0.45478959002554403\n",
      "Epoch 98, Loss: 0.45392613457673836\n",
      "Epoch 99, Loss: 0.4530222875004973\n",
      "Epoch 100, Loss: 0.45213525476867683\n",
      "Epoch 101, Loss: 0.4512773695964413\n",
      "Epoch 102, Loss: 0.45039100283022115\n",
      "Epoch 103, Loss: 0.449524800078972\n",
      "Epoch 104, Loss: 0.44863923881554957\n",
      "Epoch 105, Loss: 0.4477600629709795\n",
      "Epoch 106, Loss: 0.44690596599928606\n",
      "Epoch 107, Loss: 0.4460318427211897\n",
      "Epoch 108, Loss: 0.44516765179531637\n",
      "Epoch 109, Loss: 0.44427317081684703\n",
      "Epoch 110, Loss: 0.44339024440497526\n",
      "Epoch 111, Loss: 0.44250269396010367\n",
      "Epoch 112, Loss: 0.4416270927327788\n",
      "Epoch 113, Loss: 0.4407465063801577\n",
      "Epoch 114, Loss: 0.43988461821225866\n",
      "Epoch 115, Loss: 0.4390758505586829\n",
      "Epoch 116, Loss: 0.43831080848718845\n",
      "Epoch 117, Loss: 0.43753353058524636\n",
      "Epoch 118, Loss: 0.43673791246222476\n",
      "Epoch 119, Loss: 0.4359275112580093\n",
      "Epoch 120, Loss: 0.43512486425111097\n",
      "Epoch 121, Loss: 0.4343285391680321\n",
      "Epoch 122, Loss: 0.43354147518629726\n",
      "Epoch 123, Loss: 0.4327912335731369\n",
      "Epoch 124, Loss: 0.43207436772385044\n",
      "Epoch 125, Loss: 0.4313778141905991\n",
      "Epoch 126, Loss: 0.43070556371459606\n",
      "Epoch 127, Loss: 0.4299894832278683\n",
      "Epoch 128, Loss: 0.42920692619199474\n",
      "Epoch 129, Loss: 0.4283254710946587\n",
      "Epoch 130, Loss: 0.4273844467674356\n",
      "Epoch 131, Loss: 0.42646601497488446\n",
      "Epoch 132, Loss: 0.4255714949756567\n",
      "Epoch 133, Loss: 0.4247271236772776\n",
      "Epoch 134, Loss: 0.4239743239865193\n",
      "Epoch 135, Loss: 0.4233456867523168\n",
      "Epoch 136, Loss: 0.42276149786118133\n",
      "Epoch 137, Loss: 0.42190910130887826\n",
      "Epoch 138, Loss: 0.42107957451621947\n",
      "Epoch 139, Loss: 0.42061389412466804\n",
      "Epoch 140, Loss: 0.42002170174593767\n",
      "Epoch 141, Loss: 0.41920200122499346\n",
      "Epoch 142, Loss: 0.41860809626242834\n",
      "Epoch 143, Loss: 0.4180976811423842\n",
      "Epoch 144, Loss: 0.4173565775543417\n",
      "Epoch 145, Loss: 0.41656595642189753\n",
      "Epoch 146, Loss: 0.41595755874794504\n",
      "Epoch 147, Loss: 0.41545731955216375\n",
      "Epoch 148, Loss: 0.41481649377511637\n",
      "Epoch 149, Loss: 0.41402026626836524\n",
      "Epoch 150, Loss: 0.41334803137231424\n",
      "Epoch 151, Loss: 0.41287346825010923\n",
      "Epoch 152, Loss: 0.4123986661594828\n",
      "Epoch 153, Loss: 0.41174320025292604\n",
      "Epoch 154, Loss: 0.41102919552705125\n",
      "Epoch 155, Loss: 0.4104162209729455\n",
      "Epoch 156, Loss: 0.40992061567540206\n",
      "Epoch 157, Loss: 0.40954848173551883\n",
      "Epoch 158, Loss: 0.4092760177514367\n",
      "Epoch 159, Loss: 0.4089728039522882\n",
      "Epoch 160, Loss: 0.40837889177133624\n",
      "Epoch 161, Loss: 0.4074891705039383\n",
      "Epoch 162, Loss: 0.40695049341427075\n",
      "Epoch 163, Loss: 0.4067598957670395\n",
      "Epoch 164, Loss: 0.4064839129836642\n",
      "Epoch 165, Loss: 0.40585761193781933\n",
      "Epoch 166, Loss: 0.40519522406285563\n",
      "Epoch 167, Loss: 0.40488578916744516\n",
      "Epoch 168, Loss: 0.4046520939365417\n",
      "Epoch 169, Loss: 0.4042694893375353\n",
      "Epoch 170, Loss: 0.4036664424270072\n",
      "Epoch 171, Loss: 0.40318364374779236\n",
      "Epoch 172, Loss: 0.4028643970780866\n",
      "Epoch 173, Loss: 0.4026501424116761\n",
      "Epoch 174, Loss: 0.4024790378999954\n",
      "Epoch 175, Loss: 0.4022252917670228\n",
      "Epoch 176, Loss: 0.40172151022296265\n",
      "Epoch 177, Loss: 0.40117902591501675\n",
      "Epoch 178, Loss: 0.40063774112431005\n",
      "Epoch 179, Loss: 0.40033537320639817\n",
      "Epoch 180, Loss: 0.40018355434676356\n",
      "Epoch 181, Loss: 0.400020297846775\n",
      "Epoch 182, Loss: 0.39992512881398595\n",
      "Epoch 183, Loss: 0.39952930755799465\n",
      "Epoch 184, Loss: 0.39898849237191264\n",
      "Epoch 185, Loss: 0.3984641084948917\n",
      "Epoch 186, Loss: 0.39807834519557894\n",
      "Epoch 187, Loss: 0.39787737426025443\n",
      "Epoch 188, Loss: 0.39774945633813324\n",
      "Epoch 189, Loss: 0.39772813892889447\n",
      "Epoch 190, Loss: 0.3977138080423267\n",
      "Epoch 191, Loss: 0.3975415722082847\n",
      "Epoch 192, Loss: 0.3968527074244952\n",
      "Epoch 193, Loss: 0.3960584786565963\n",
      "Epoch 194, Loss: 0.39572147202581687\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.23480618518857962\n",
      "Test R^2 score: 0.40346203394812996\n",
      "Num of epochs: 195\n",
      "Epoch 1, Loss: 0.5667704496526679\n",
      "Epoch 2, Loss: 0.5661142319952098\n",
      "Epoch 3, Loss: 0.5654803897348002\n",
      "Epoch 4, Loss: 0.564869578550541\n",
      "Epoch 5, Loss: 0.5642818996402255\n",
      "Epoch 6, Loss: 0.5637171345792339\n",
      "Epoch 7, Loss: 0.5631773631976779\n",
      "Epoch 8, Loss: 0.5626707612560239\n",
      "Epoch 9, Loss: 0.5621850403524624\n",
      "Epoch 10, Loss: 0.5617202811823788\n",
      "Epoch 11, Loss: 0.5612763499762923\n",
      "Epoch 12, Loss: 0.5608531102108101\n",
      "Epoch 13, Loss: 0.5604505024117743\n",
      "Epoch 14, Loss: 0.5600749032556728\n",
      "Epoch 15, Loss: 0.5597200842338771\n",
      "Epoch 16, Loss: 0.5593839804498546\n",
      "Epoch 17, Loss: 0.5590776868093349\n",
      "Epoch 18, Loss: 0.5588119720808052\n",
      "Epoch 19, Loss: 0.5585602436820433\n",
      "Epoch 20, Loss: 0.5583238016093046\n",
      "Epoch 21, Loss: 0.5581010900077025\n",
      "Epoch 22, Loss: 0.5578916712549322\n",
      "Epoch 23, Loss: 0.5576943045233841\n",
      "Epoch 24, Loss: 0.5575083344097423\n",
      "Epoch 25, Loss: 0.5573326493877719\n",
      "Epoch 26, Loss: 0.5571664301065089\n",
      "Epoch 27, Loss: 0.5570155169604523\n",
      "Epoch 28, Loss: 0.5568741693287144\n",
      "Epoch 29, Loss: 0.5567407618348444\n",
      "Epoch 30, Loss: 0.5566173080111604\n",
      "Epoch 31, Loss: 0.5564977362090591\n",
      "Epoch 32, Loss: 0.5563813525925456\n",
      "Epoch 33, Loss: 0.5562698467871601\n",
      "Epoch 34, Loss: 0.556161265850089\n",
      "Epoch 35, Loss: 0.5560519401608374\n",
      "Epoch 36, Loss: 0.5559389208925046\n",
      "Epoch 37, Loss: 0.5558198465753778\n",
      "Epoch 38, Loss: 0.5556903155783998\n",
      "Epoch 39, Loss: 0.5555430248622227\n",
      "Epoch 40, Loss: 0.5553621836404175\n",
      "Epoch 41, Loss: 0.555110233030591\n",
      "Epoch 42, Loss: 0.5547434281642831\n",
      "Epoch 43, Loss: 0.5542621862459519\n",
      "Epoch 44, Loss: 0.5536642710886343\n",
      "Epoch 45, Loss: 0.5529625088225513\n",
      "Epoch 46, Loss: 0.5522512474460423\n",
      "Epoch 47, Loss: 0.5515367183117021\n",
      "Epoch 48, Loss: 0.5507097130169119\n",
      "Epoch 49, Loss: 0.5496917933935597\n",
      "Epoch 50, Loss: 0.5483712572048745\n",
      "Epoch 51, Loss: 0.5466005181448638\n",
      "Epoch 52, Loss: 0.5441889054786387\n",
      "Epoch 53, Loss: 0.5410391186181802\n",
      "Epoch 54, Loss: 0.5370036905524169\n",
      "Epoch 55, Loss: 0.5322549514898547\n",
      "Epoch 56, Loss: 0.5275040841961441\n",
      "Epoch 57, Loss: 0.5244841573175346\n",
      "Epoch 58, Loss: 0.5244263091690795\n",
      "Epoch 59, Loss: 0.5235828937895186\n",
      "Epoch 60, Loss: 0.5202038935129518\n",
      "Epoch 61, Loss: 0.5164991828989544\n",
      "Epoch 62, Loss: 0.5143333208665498\n",
      "Epoch 63, Loss: 0.5135391411967465\n",
      "Epoch 64, Loss: 0.5126251463332917\n",
      "Epoch 65, Loss: 0.510883931609487\n",
      "Epoch 66, Loss: 0.5083833566920996\n",
      "Epoch 67, Loss: 0.5057024620331146\n",
      "Epoch 68, Loss: 0.5033445554496984\n",
      "Epoch 69, Loss: 0.5012644039377115\n",
      "Epoch 70, Loss: 0.49872133550279085\n",
      "Epoch 71, Loss: 0.4951888263948956\n",
      "Epoch 72, Loss: 0.4910849984263392\n",
      "Epoch 73, Loss: 0.48708286473284595\n",
      "Epoch 74, Loss: 0.4833021742406978\n",
      "Epoch 75, Loss: 0.4793742980852422\n",
      "Epoch 76, Loss: 0.47546474471396877\n",
      "Epoch 77, Loss: 0.47285614830796613\n",
      "Epoch 78, Loss: 0.47308865779245485\n",
      "Epoch 79, Loss: 0.4744183191113976\n",
      "Epoch 80, Loss: 0.4736515631356063\n",
      "Epoch 81, Loss: 0.4716178427010833\n",
      "Epoch 82, Loss: 0.46974770543977945\n",
      "Epoch 83, Loss: 0.4686315068840987\n",
      "Epoch 84, Loss: 0.46813469875459435\n",
      "Epoch 85, Loss: 0.4678216164770262\n",
      "Epoch 86, Loss: 0.4673962117309716\n",
      "Epoch 87, Loss: 0.46679138435741824\n",
      "Epoch 88, Loss: 0.46606408544319083\n",
      "Epoch 89, Loss: 0.4652378271120563\n",
      "Epoch 90, Loss: 0.4644270078664629\n",
      "Epoch 91, Loss: 0.4636892519541262\n",
      "Epoch 92, Loss: 0.46305358207354314\n",
      "Epoch 93, Loss: 0.4624209213955935\n",
      "Epoch 94, Loss: 0.46170195534461234\n",
      "Epoch 95, Loss: 0.46091315641614317\n",
      "Epoch 96, Loss: 0.46020604950577193\n",
      "Epoch 97, Loss: 0.45958504837606107\n",
      "Epoch 98, Loss: 0.459113488400676\n",
      "Epoch 99, Loss: 0.4586435716590448\n",
      "Epoch 100, Loss: 0.45812663019470523\n",
      "Epoch 101, Loss: 0.4575801227064196\n",
      "Epoch 102, Loss: 0.4570293915539638\n",
      "Epoch 103, Loss: 0.45651597539894356\n",
      "Epoch 104, Loss: 0.4560458000673103\n",
      "Epoch 105, Loss: 0.45558518087904326\n",
      "Epoch 106, Loss: 0.4550922375238505\n",
      "Epoch 107, Loss: 0.45454216367982464\n",
      "Epoch 108, Loss: 0.4539677412497562\n",
      "Epoch 109, Loss: 0.45343373731528186\n",
      "Epoch 110, Loss: 0.45294514737016894\n",
      "Epoch 111, Loss: 0.45245020047028545\n",
      "Epoch 112, Loss: 0.4519360663542009\n",
      "Epoch 113, Loss: 0.4513806277114146\n",
      "Epoch 114, Loss: 0.45077568262321555\n",
      "Epoch 115, Loss: 0.45016338706855064\n",
      "Epoch 116, Loss: 0.44956572028239355\n",
      "Epoch 117, Loss: 0.4490255354956305\n",
      "Epoch 118, Loss: 0.4484823576658505\n",
      "Epoch 119, Loss: 0.4479217381153289\n",
      "Epoch 120, Loss: 0.4473682768850271\n",
      "Epoch 121, Loss: 0.4467895839661237\n",
      "Epoch 122, Loss: 0.44620877134245995\n",
      "Epoch 123, Loss: 0.4456114184007255\n",
      "Epoch 124, Loss: 0.44503239974468123\n",
      "Epoch 125, Loss: 0.44449850608759156\n",
      "Epoch 126, Loss: 0.4439652961633666\n",
      "Epoch 127, Loss: 0.44343310847940665\n",
      "Epoch 128, Loss: 0.4428938551734677\n",
      "Epoch 129, Loss: 0.44237280828014397\n",
      "Epoch 130, Loss: 0.4418804861966443\n",
      "Epoch 131, Loss: 0.4414050853342541\n",
      "Epoch 132, Loss: 0.44092890154527\n",
      "Epoch 133, Loss: 0.44046810346314397\n",
      "Epoch 134, Loss: 0.439993242434065\n",
      "Epoch 135, Loss: 0.43951157922865014\n",
      "Epoch 136, Loss: 0.43903329080100145\n",
      "Epoch 137, Loss: 0.43858648676713763\n",
      "Epoch 138, Loss: 0.43816475093379714\n",
      "Epoch 139, Loss: 0.43774817444133646\n",
      "Epoch 140, Loss: 0.4373298893320202\n",
      "Epoch 141, Loss: 0.4368725773603641\n",
      "Epoch 142, Loss: 0.4364157080794893\n",
      "Epoch 143, Loss: 0.4359660163221115\n",
      "Epoch 144, Loss: 0.43552306242710476\n",
      "Epoch 145, Loss: 0.43522678467913106\n",
      "Epoch 146, Loss: 0.4346796819668069\n",
      "Epoch 147, Loss: 0.4341440231632334\n",
      "Epoch 148, Loss: 0.4334248222306703\n",
      "Epoch 149, Loss: 0.4331679616266356\n",
      "Epoch 150, Loss: 0.43294736434230313\n",
      "Epoch 151, Loss: 0.4320165455749145\n",
      "Epoch 152, Loss: 0.4321275786471044\n",
      "Epoch 153, Loss: 0.4318332156160686\n",
      "Epoch 154, Loss: 0.43084657568782114\n",
      "Epoch 155, Loss: 0.43122811261900956\n",
      "Epoch 156, Loss: 0.4299362676264273\n",
      "Epoch 157, Loss: 0.4299328363717134\n",
      "Epoch 158, Loss: 0.4291319810714491\n",
      "Epoch 159, Loss: 0.4288353533073933\n",
      "Epoch 160, Loss: 0.4284577545342151\n",
      "Epoch 161, Loss: 0.42783079410557834\n",
      "Epoch 162, Loss: 0.4276780914482566\n",
      "Epoch 163, Loss: 0.42678054295112794\n",
      "Epoch 164, Loss: 0.4266474950042042\n",
      "Epoch 165, Loss: 0.4259580017831616\n",
      "Epoch 166, Loss: 0.42562378587703653\n",
      "Epoch 167, Loss: 0.42527911123129963\n",
      "Epoch 168, Loss: 0.42460357465528525\n",
      "Epoch 169, Loss: 0.42439422069501154\n",
      "Epoch 170, Loss: 0.42378958953197365\n",
      "Epoch 171, Loss: 0.4233503153384733\n",
      "Epoch 172, Loss: 0.4230559385954326\n",
      "Epoch 173, Loss: 0.4223983485487603\n",
      "Epoch 174, Loss: 0.42198128597631646\n",
      "Epoch 175, Loss: 0.42158917175141575\n",
      "Epoch 176, Loss: 0.42096042397883704\n",
      "Epoch 177, Loss: 0.42046941501277074\n",
      "Epoch 178, Loss: 0.4200544458532932\n",
      "Epoch 179, Loss: 0.41951590142330997\n",
      "Epoch 180, Loss: 0.4189305691914747\n",
      "Epoch 181, Loss: 0.4184334034964934\n",
      "Epoch 182, Loss: 0.41804853016613536\n",
      "Epoch 183, Loss: 0.41751541080699917\n",
      "Epoch 184, Loss: 0.41702081014772835\n",
      "Epoch 185, Loss: 0.41649213552892356\n",
      "Epoch 186, Loss: 0.4160091596647238\n",
      "Epoch 187, Loss: 0.41553505375990124\n",
      "Epoch 188, Loss: 0.41508609280871694\n",
      "Epoch 189, Loss: 0.4146417848158468\n",
      "Epoch 190, Loss: 0.41421405249960674\n",
      "Epoch 191, Loss: 0.4138624859804314\n",
      "Epoch 192, Loss: 0.4138027672094796\n",
      "Epoch 193, Loss: 0.4139597063404973\n",
      "Epoch 194, Loss: 0.4145426215816696\n",
      "Epoch 195, Loss: 0.41223164412403596\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22393545909515028\n",
      "Test R^2 score: 0.45903591343772193\n",
      "Num of epochs: 196\n",
      "Epoch 1, Loss: 0.5887496350119202\n",
      "Epoch 2, Loss: 0.5865789335750354\n",
      "Epoch 3, Loss: 0.5844770413826204\n",
      "Epoch 4, Loss: 0.5824387423185544\n",
      "Epoch 5, Loss: 0.580534989491105\n",
      "Epoch 6, Loss: 0.578682836544908\n",
      "Epoch 7, Loss: 0.5768733006180585\n",
      "Epoch 8, Loss: 0.5751121214726619\n",
      "Epoch 9, Loss: 0.5733978216179781\n",
      "Epoch 10, Loss: 0.5717374167114723\n",
      "Epoch 11, Loss: 0.5701406298290853\n",
      "Epoch 12, Loss: 0.5686020742605309\n",
      "Epoch 13, Loss: 0.5671264279275885\n",
      "Epoch 14, Loss: 0.5657199253073649\n",
      "Epoch 15, Loss: 0.5643912680764217\n",
      "Epoch 16, Loss: 0.5631448440357727\n",
      "Epoch 17, Loss: 0.5619897647550105\n",
      "Epoch 18, Loss: 0.5609192093441262\n",
      "Epoch 19, Loss: 0.5599366165803076\n",
      "Epoch 20, Loss: 0.5590407177182402\n",
      "Epoch 21, Loss: 0.5582518431517347\n",
      "Epoch 22, Loss: 0.5575616545006378\n",
      "Epoch 23, Loss: 0.5569731137619978\n",
      "Epoch 24, Loss: 0.5565010565073382\n",
      "Epoch 25, Loss: 0.556171527427868\n",
      "Epoch 26, Loss: 0.5559250096531037\n",
      "Epoch 27, Loss: 0.5557556345058122\n",
      "Epoch 28, Loss: 0.5556194374655649\n",
      "Epoch 29, Loss: 0.5554988461267005\n",
      "Epoch 30, Loss: 0.5553764577773918\n",
      "Epoch 31, Loss: 0.5552479773342455\n",
      "Epoch 32, Loss: 0.5550754963156881\n",
      "Epoch 33, Loss: 0.5547793674955981\n",
      "Epoch 34, Loss: 0.5543145282453196\n",
      "Epoch 35, Loss: 0.5536979660317871\n",
      "Epoch 36, Loss: 0.5529354794494338\n",
      "Epoch 37, Loss: 0.5519684786054851\n",
      "Epoch 38, Loss: 0.5507560074885927\n",
      "Epoch 39, Loss: 0.5492552591835177\n",
      "Epoch 40, Loss: 0.5474037067005596\n",
      "Epoch 41, Loss: 0.5452053194274898\n",
      "Epoch 42, Loss: 0.54265783176252\n",
      "Epoch 43, Loss: 0.5399132249128474\n",
      "Epoch 44, Loss: 0.537072225499712\n",
      "Epoch 45, Loss: 0.5343045327644198\n",
      "Epoch 46, Loss: 0.5314294568058482\n",
      "Epoch 47, Loss: 0.5283288020722856\n",
      "Epoch 48, Loss: 0.5250806496753453\n",
      "Epoch 49, Loss: 0.5217972292030024\n",
      "Epoch 50, Loss: 0.5185215826297224\n",
      "Epoch 51, Loss: 0.5152260074702435\n",
      "Epoch 52, Loss: 0.5120498226872828\n",
      "Epoch 53, Loss: 0.5091635996710042\n",
      "Epoch 54, Loss: 0.5064732130127876\n",
      "Epoch 55, Loss: 0.5039144116117751\n",
      "Epoch 56, Loss: 0.5015326791139567\n",
      "Epoch 57, Loss: 0.49922703063019264\n",
      "Epoch 58, Loss: 0.49689581005735123\n",
      "Epoch 59, Loss: 0.4945123201818051\n",
      "Epoch 60, Loss: 0.4920880353424643\n",
      "Epoch 61, Loss: 0.4896294710725989\n",
      "Epoch 62, Loss: 0.48706923551147446\n",
      "Epoch 63, Loss: 0.4844601925409896\n",
      "Epoch 64, Loss: 0.4818523612932467\n",
      "Epoch 65, Loss: 0.47934203117823937\n",
      "Epoch 66, Loss: 0.4770047996327507\n",
      "Epoch 67, Loss: 0.474826135311799\n",
      "Epoch 68, Loss: 0.4727709764953772\n",
      "Epoch 69, Loss: 0.4707670682789831\n",
      "Epoch 70, Loss: 0.46890628116840183\n",
      "Epoch 71, Loss: 0.46702531787197227\n",
      "Epoch 72, Loss: 0.4651708814211798\n",
      "Epoch 73, Loss: 0.4634503067366642\n",
      "Epoch 74, Loss: 0.46187899498766827\n",
      "Epoch 75, Loss: 0.460436888577203\n",
      "Epoch 76, Loss: 0.4590603704643325\n",
      "Epoch 77, Loss: 0.4577169246964044\n",
      "Epoch 78, Loss: 0.4564078880837\n",
      "Epoch 79, Loss: 0.4551556238811153\n",
      "Epoch 80, Loss: 0.45399685544655866\n",
      "Epoch 81, Loss: 0.45296556035445523\n",
      "Epoch 82, Loss: 0.4520017085095836\n",
      "Epoch 83, Loss: 0.451044882204195\n",
      "Epoch 84, Loss: 0.4500325502438169\n",
      "Epoch 85, Loss: 0.4489841843912129\n",
      "Epoch 86, Loss: 0.44792365098283726\n",
      "Epoch 87, Loss: 0.4468701875867678\n",
      "Epoch 88, Loss: 0.44585805234684467\n",
      "Epoch 89, Loss: 0.4448579509519778\n",
      "Epoch 90, Loss: 0.44384873057488244\n",
      "Epoch 91, Loss: 0.4427794137626274\n",
      "Epoch 92, Loss: 0.44167665621718555\n",
      "Epoch 93, Loss: 0.44059151596649065\n",
      "Epoch 94, Loss: 0.4395462107087047\n",
      "Epoch 95, Loss: 0.43852950628218446\n",
      "Epoch 96, Loss: 0.43756639453629753\n",
      "Epoch 97, Loss: 0.4366295875332341\n",
      "Epoch 98, Loss: 0.43567754726837443\n",
      "Epoch 99, Loss: 0.43474472489208543\n",
      "Epoch 100, Loss: 0.4337679710567959\n",
      "Epoch 101, Loss: 0.43275943596071076\n",
      "Epoch 102, Loss: 0.4317192765466363\n",
      "Epoch 103, Loss: 0.4306361044461027\n",
      "Epoch 104, Loss: 0.4296175986566165\n",
      "Epoch 105, Loss: 0.42862504172470944\n",
      "Epoch 106, Loss: 0.42768385776082135\n",
      "Epoch 107, Loss: 0.4268216711665801\n",
      "Epoch 108, Loss: 0.4260113820393389\n",
      "Epoch 109, Loss: 0.4251378473955704\n",
      "Epoch 110, Loss: 0.42407212507193986\n",
      "Epoch 111, Loss: 0.42319131289302325\n",
      "Epoch 112, Loss: 0.42252837906843865\n",
      "Epoch 113, Loss: 0.4217194694351782\n",
      "Epoch 114, Loss: 0.42078252909027164\n",
      "Epoch 115, Loss: 0.42001611406204087\n",
      "Epoch 116, Loss: 0.4193727851104236\n",
      "Epoch 117, Loss: 0.41856074967402146\n",
      "Epoch 118, Loss: 0.4177363632037832\n",
      "Epoch 119, Loss: 0.41711002444831\n",
      "Epoch 120, Loss: 0.4164327759730279\n",
      "Epoch 121, Loss: 0.4156451837041515\n",
      "Epoch 122, Loss: 0.4149951866744013\n",
      "Epoch 123, Loss: 0.41441177535812534\n",
      "Epoch 124, Loss: 0.4137495585724473\n",
      "Epoch 125, Loss: 0.41307441208364754\n",
      "Epoch 126, Loss: 0.41245488512533807\n",
      "Epoch 127, Loss: 0.41187210846089994\n",
      "Epoch 128, Loss: 0.4112800642520648\n",
      "Epoch 129, Loss: 0.4106740861524099\n",
      "Epoch 130, Loss: 0.41005136874602727\n",
      "Epoch 131, Loss: 0.40944042411019743\n",
      "Epoch 132, Loss: 0.4088400658121701\n",
      "Epoch 133, Loss: 0.40823044753922116\n",
      "Epoch 134, Loss: 0.4076232807341918\n",
      "Epoch 135, Loss: 0.4070176977145601\n",
      "Epoch 136, Loss: 0.4064200668890169\n",
      "Epoch 137, Loss: 0.4058099343932442\n",
      "Epoch 138, Loss: 0.40522548897456195\n",
      "Epoch 139, Loss: 0.4046426298975111\n",
      "Epoch 140, Loss: 0.4040961573567928\n",
      "Epoch 141, Loss: 0.4035634377173119\n",
      "Epoch 142, Loss: 0.4031144510411863\n",
      "Epoch 143, Loss: 0.40271417916809804\n",
      "Epoch 144, Loss: 0.40231365720930046\n",
      "Epoch 145, Loss: 0.4016649204660714\n",
      "Epoch 146, Loss: 0.40092612951364226\n",
      "Epoch 147, Loss: 0.40041710370595995\n",
      "Epoch 148, Loss: 0.40015611060935874\n",
      "Epoch 149, Loss: 0.3998509375167318\n",
      "Epoch 150, Loss: 0.3993070687620083\n",
      "Epoch 151, Loss: 0.39868035114778266\n",
      "Epoch 152, Loss: 0.3981939019925123\n",
      "Epoch 153, Loss: 0.39788533265470083\n",
      "Epoch 154, Loss: 0.3976689761960214\n",
      "Epoch 155, Loss: 0.3974354428824325\n",
      "Epoch 156, Loss: 0.3970510069980493\n",
      "Epoch 157, Loss: 0.39641948225274987\n",
      "Epoch 158, Loss: 0.39583782979854076\n",
      "Epoch 159, Loss: 0.395567411476922\n",
      "Epoch 160, Loss: 0.3954538002338483\n",
      "Epoch 161, Loss: 0.3951435813818856\n",
      "Epoch 162, Loss: 0.39457572082069875\n",
      "Epoch 163, Loss: 0.39406567665289916\n",
      "Epoch 164, Loss: 0.3938095933231472\n",
      "Epoch 165, Loss: 0.3936469109628057\n",
      "Epoch 166, Loss: 0.393336574041357\n",
      "Epoch 167, Loss: 0.3929136370315874\n",
      "Epoch 168, Loss: 0.3925695086240571\n",
      "Epoch 169, Loss: 0.39236590594434884\n",
      "Epoch 170, Loss: 0.39214851823979396\n",
      "Epoch 171, Loss: 0.39181138123026843\n",
      "Epoch 172, Loss: 0.391511921123811\n",
      "Epoch 173, Loss: 0.3913452374994267\n",
      "Epoch 174, Loss: 0.3912418644641205\n",
      "Epoch 175, Loss: 0.39103808495709147\n",
      "Epoch 176, Loss: 0.39081151324217284\n",
      "Epoch 177, Loss: 0.3907018776583655\n",
      "Epoch 178, Loss: 0.39064048736387963\n",
      "Epoch 179, Loss: 0.3903726525604095\n",
      "Epoch 180, Loss: 0.38973539142256636\n",
      "Epoch 181, Loss: 0.38933546839184696\n",
      "Epoch 182, Loss: 0.38919004088638753\n",
      "Epoch 183, Loss: 0.38897869325845025\n",
      "Epoch 184, Loss: 0.38889741344229334\n",
      "Epoch 185, Loss: 0.3887941369455964\n",
      "Epoch 186, Loss: 0.38842458861567936\n",
      "Epoch 187, Loss: 0.38804080664242674\n",
      "Epoch 188, Loss: 0.3879424683805983\n",
      "Epoch 189, Loss: 0.3878164798676831\n",
      "Epoch 190, Loss: 0.3876476306564387\n",
      "Epoch 191, Loss: 0.38761793464635536\n",
      "Epoch 192, Loss: 0.3875380035961147\n",
      "Epoch 193, Loss: 0.38727868127967535\n",
      "Epoch 194, Loss: 0.38704505794136046\n",
      "Epoch 195, Loss: 0.3868889097138208\n",
      "Epoch 196, Loss: 0.38663824765547267\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.243919234765895\n",
      "Test R^2 score: 0.35454473768306227\n",
      "Num of epochs: 197\n",
      "Epoch 1, Loss: 0.6043110022838472\n",
      "Epoch 2, Loss: 0.6026129777726296\n",
      "Epoch 3, Loss: 0.601071491746581\n",
      "Epoch 4, Loss: 0.599540880497227\n",
      "Epoch 5, Loss: 0.5980692165993032\n",
      "Epoch 6, Loss: 0.5966048872742717\n",
      "Epoch 7, Loss: 0.595143915570858\n",
      "Epoch 8, Loss: 0.5936869537611232\n",
      "Epoch 9, Loss: 0.5922342830487095\n",
      "Epoch 10, Loss: 0.590790727363283\n",
      "Epoch 11, Loss: 0.5893525358188724\n",
      "Epoch 12, Loss: 0.5879189113769647\n",
      "Epoch 13, Loss: 0.5864917930783312\n",
      "Epoch 14, Loss: 0.5850678411500158\n",
      "Epoch 15, Loss: 0.5836532062031017\n",
      "Epoch 16, Loss: 0.5822465229675855\n",
      "Epoch 17, Loss: 0.580840101608547\n",
      "Epoch 18, Loss: 0.5794353070193422\n",
      "Epoch 19, Loss: 0.5780298824934481\n",
      "Epoch 20, Loss: 0.5766204897863145\n",
      "Epoch 21, Loss: 0.5752044055265317\n",
      "Epoch 22, Loss: 0.5738073938622672\n",
      "Epoch 23, Loss: 0.5723991368493184\n",
      "Epoch 24, Loss: 0.5709706519513148\n",
      "Epoch 25, Loss: 0.569515638307536\n",
      "Epoch 26, Loss: 0.56803037684268\n",
      "Epoch 27, Loss: 0.5665072910028198\n",
      "Epoch 28, Loss: 0.5649266616097286\n",
      "Epoch 29, Loss: 0.5632548829995929\n",
      "Epoch 30, Loss: 0.5615293817620154\n",
      "Epoch 31, Loss: 0.5596042376448462\n",
      "Epoch 32, Loss: 0.5575423048415966\n",
      "Epoch 33, Loss: 0.5552840181859526\n",
      "Epoch 34, Loss: 0.552802388350507\n",
      "Epoch 35, Loss: 0.5500717463080846\n",
      "Epoch 36, Loss: 0.5470485411904593\n",
      "Epoch 37, Loss: 0.5437277559137149\n",
      "Epoch 38, Loss: 0.540164484563224\n",
      "Epoch 39, Loss: 0.5364946488862821\n",
      "Epoch 40, Loss: 0.5329731315940417\n",
      "Epoch 41, Loss: 0.5301102585635213\n",
      "Epoch 42, Loss: 0.5286713454631567\n",
      "Epoch 43, Loss: 0.5291286637584677\n",
      "Epoch 44, Loss: 0.530114868509793\n",
      "Epoch 45, Loss: 0.5292416927386634\n",
      "Epoch 46, Loss: 0.5262468303032238\n",
      "Epoch 47, Loss: 0.5224512117140171\n",
      "Epoch 48, Loss: 0.5191163435539633\n",
      "Epoch 49, Loss: 0.5167767348513517\n",
      "Epoch 50, Loss: 0.5152634306632842\n",
      "Epoch 51, Loss: 0.5141091751660773\n",
      "Epoch 52, Loss: 0.512881435942427\n",
      "Epoch 53, Loss: 0.5113294445513317\n",
      "Epoch 54, Loss: 0.5093824035012888\n",
      "Epoch 55, Loss: 0.507145458225319\n",
      "Epoch 56, Loss: 0.5049345480644554\n",
      "Epoch 57, Loss: 0.5030479810536383\n",
      "Epoch 58, Loss: 0.5016440542116039\n",
      "Epoch 59, Loss: 0.5005822367983453\n",
      "Epoch 60, Loss: 0.49942199259143377\n",
      "Epoch 61, Loss: 0.4978425298614425\n",
      "Epoch 62, Loss: 0.49602171607700485\n",
      "Epoch 63, Loss: 0.49439658068443615\n",
      "Epoch 64, Loss: 0.49317238677902653\n",
      "Epoch 65, Loss: 0.49221173484113656\n",
      "Epoch 66, Loss: 0.4912111346811312\n",
      "Epoch 67, Loss: 0.4899536179953289\n",
      "Epoch 68, Loss: 0.48845695386086174\n",
      "Epoch 69, Loss: 0.4869040024900582\n",
      "Epoch 70, Loss: 0.48552272549369424\n",
      "Epoch 71, Loss: 0.4843812603699754\n",
      "Epoch 72, Loss: 0.4832884075671997\n",
      "Epoch 73, Loss: 0.4820416454016551\n",
      "Epoch 74, Loss: 0.4806840150761611\n",
      "Epoch 75, Loss: 0.47941127179823256\n",
      "Epoch 76, Loss: 0.47832337234783184\n",
      "Epoch 77, Loss: 0.47730530242168506\n",
      "Epoch 78, Loss: 0.47621813041706285\n",
      "Epoch 79, Loss: 0.47509260655196345\n",
      "Epoch 80, Loss: 0.47402146900524295\n",
      "Epoch 81, Loss: 0.4730821219936038\n",
      "Epoch 82, Loss: 0.47214819660624047\n",
      "Epoch 83, Loss: 0.4711422118759669\n",
      "Epoch 84, Loss: 0.47011258448339055\n",
      "Epoch 85, Loss: 0.4691754159088983\n",
      "Epoch 86, Loss: 0.4682838028999521\n",
      "Epoch 87, Loss: 0.46727927273003067\n",
      "Epoch 88, Loss: 0.4661890006367887\n",
      "Epoch 89, Loss: 0.4651689593930511\n",
      "Epoch 90, Loss: 0.4641833703455881\n",
      "Epoch 91, Loss: 0.46312878111661293\n",
      "Epoch 92, Loss: 0.46206383565397235\n",
      "Epoch 93, Loss: 0.4610851988715324\n",
      "Epoch 94, Loss: 0.46018565007897055\n",
      "Epoch 95, Loss: 0.459234567183554\n",
      "Epoch 96, Loss: 0.4583464389430072\n",
      "Epoch 97, Loss: 0.4574797622185973\n",
      "Epoch 98, Loss: 0.4565543270228138\n",
      "Epoch 99, Loss: 0.45562056927822525\n",
      "Epoch 100, Loss: 0.45473930942013197\n",
      "Epoch 101, Loss: 0.4538174961005782\n",
      "Epoch 102, Loss: 0.4528516734299219\n",
      "Epoch 103, Loss: 0.4518917830108687\n",
      "Epoch 104, Loss: 0.45091881198451444\n",
      "Epoch 105, Loss: 0.44995451670835235\n",
      "Epoch 106, Loss: 0.44904370421891565\n",
      "Epoch 107, Loss: 0.44816307749374407\n",
      "Epoch 108, Loss: 0.4474437642059279\n",
      "Epoch 109, Loss: 0.4469760640443458\n",
      "Epoch 110, Loss: 0.44672339275198425\n",
      "Epoch 111, Loss: 0.4464134026402678\n",
      "Epoch 112, Loss: 0.44583881796674857\n",
      "Epoch 113, Loss: 0.445103529368643\n",
      "Epoch 114, Loss: 0.44434863061905305\n",
      "Epoch 115, Loss: 0.44368206162269314\n",
      "Epoch 116, Loss: 0.44310408649135663\n",
      "Epoch 117, Loss: 0.4425683043182392\n",
      "Epoch 118, Loss: 0.44203256379650635\n",
      "Epoch 119, Loss: 0.44146979558171057\n",
      "Epoch 120, Loss: 0.440944362454506\n",
      "Epoch 121, Loss: 0.4403436073377168\n",
      "Epoch 122, Loss: 0.43971892054141537\n",
      "Epoch 123, Loss: 0.4391055788511944\n",
      "Epoch 124, Loss: 0.4384678625250489\n",
      "Epoch 125, Loss: 0.43783580290527846\n",
      "Epoch 126, Loss: 0.4372270277476334\n",
      "Epoch 127, Loss: 0.4366969845283544\n",
      "Epoch 128, Loss: 0.4362064721326517\n",
      "Epoch 129, Loss: 0.43567226298558154\n",
      "Epoch 130, Loss: 0.43512520670810556\n",
      "Epoch 131, Loss: 0.4345598541029986\n",
      "Epoch 132, Loss: 0.43391492478487653\n",
      "Epoch 133, Loss: 0.43320267026308096\n",
      "Epoch 134, Loss: 0.43259727828324357\n",
      "Epoch 135, Loss: 0.43202704829402666\n",
      "Epoch 136, Loss: 0.4314561164715503\n",
      "Epoch 137, Loss: 0.4308783934226896\n",
      "Epoch 138, Loss: 0.4301912302800148\n",
      "Epoch 139, Loss: 0.42962689405794596\n",
      "Epoch 140, Loss: 0.4291871365353573\n",
      "Epoch 141, Loss: 0.42866357702500885\n",
      "Epoch 142, Loss: 0.42771678174211825\n",
      "Epoch 143, Loss: 0.4271193659709184\n",
      "Epoch 144, Loss: 0.4268942992230745\n",
      "Epoch 145, Loss: 0.426044470242305\n",
      "Epoch 146, Loss: 0.4255437451018675\n",
      "Epoch 147, Loss: 0.4253182825204127\n",
      "Epoch 148, Loss: 0.4245430853369434\n",
      "Epoch 149, Loss: 0.42422090954871955\n",
      "Epoch 150, Loss: 0.42390478117730873\n",
      "Epoch 151, Loss: 0.423202017025116\n",
      "Epoch 152, Loss: 0.4229123818441978\n",
      "Epoch 153, Loss: 0.42256057629473925\n",
      "Epoch 154, Loss: 0.42193528910167705\n",
      "Epoch 155, Loss: 0.42166264805681897\n",
      "Epoch 156, Loss: 0.4212920788766175\n",
      "Epoch 157, Loss: 0.42074435217132905\n",
      "Epoch 158, Loss: 0.420484122084262\n",
      "Epoch 159, Loss: 0.4200995668114815\n",
      "Epoch 160, Loss: 0.4196172096942918\n",
      "Epoch 161, Loss: 0.419333324948378\n",
      "Epoch 162, Loss: 0.4189809681762601\n",
      "Epoch 163, Loss: 0.4184525443941554\n",
      "Epoch 164, Loss: 0.41810776724891696\n",
      "Epoch 165, Loss: 0.4178361593265521\n",
      "Epoch 166, Loss: 0.4174132711304528\n",
      "Epoch 167, Loss: 0.41702559826402463\n",
      "Epoch 168, Loss: 0.41674645573871527\n",
      "Epoch 169, Loss: 0.416473602230017\n",
      "Epoch 170, Loss: 0.416117051346304\n",
      "Epoch 171, Loss: 0.4157402846703124\n",
      "Epoch 172, Loss: 0.41542844570388604\n",
      "Epoch 173, Loss: 0.4151702852931157\n",
      "Epoch 174, Loss: 0.4148883501061674\n",
      "Epoch 175, Loss: 0.4145526683750941\n",
      "Epoch 176, Loss: 0.4141912080349253\n",
      "Epoch 177, Loss: 0.4138548888340924\n",
      "Epoch 178, Loss: 0.41354413243991156\n",
      "Epoch 179, Loss: 0.4132488281281847\n",
      "Epoch 180, Loss: 0.4129987944904034\n",
      "Epoch 181, Loss: 0.4128279725957342\n",
      "Epoch 182, Loss: 0.4128172701921715\n",
      "Epoch 183, Loss: 0.412950191333374\n",
      "Epoch 184, Loss: 0.4126469509314862\n",
      "Epoch 185, Loss: 0.41175783901940105\n",
      "Epoch 186, Loss: 0.411163999412126\n",
      "Epoch 187, Loss: 0.411418081882019\n",
      "Epoch 188, Loss: 0.41113737923810945\n",
      "Epoch 189, Loss: 0.41039492610853906\n",
      "Epoch 190, Loss: 0.41032048524871195\n",
      "Epoch 191, Loss: 0.41035474787787124\n",
      "Epoch 192, Loss: 0.40978811182336505\n",
      "Epoch 193, Loss: 0.40939010635924916\n",
      "Epoch 194, Loss: 0.4094269035282993\n",
      "Epoch 195, Loss: 0.40917451623093365\n",
      "Epoch 196, Loss: 0.40864799752084924\n",
      "Epoch 197, Loss: 0.4084715804611267\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22646867329720388\n",
      "Test R^2 score: 0.44300112475681863\n",
      "Num of epochs: 198\n",
      "Epoch 1, Loss: 0.5663702854708733\n",
      "Epoch 2, Loss: 0.5653915787736629\n",
      "Epoch 3, Loss: 0.5645106725165352\n",
      "Epoch 4, Loss: 0.5636909381183415\n",
      "Epoch 5, Loss: 0.5629152778346701\n",
      "Epoch 6, Loss: 0.5621826283199816\n",
      "Epoch 7, Loss: 0.5614911410124568\n",
      "Epoch 8, Loss: 0.5608384972127233\n",
      "Epoch 9, Loss: 0.5602320940287517\n",
      "Epoch 10, Loss: 0.5596649462715291\n",
      "Epoch 11, Loss: 0.5591987854430717\n",
      "Epoch 12, Loss: 0.5587916257146816\n",
      "Epoch 13, Loss: 0.5584053041797133\n",
      "Epoch 14, Loss: 0.5580454716510582\n",
      "Epoch 15, Loss: 0.5577122061187301\n",
      "Epoch 16, Loss: 0.5574054215695542\n",
      "Epoch 17, Loss: 0.5571190902554004\n",
      "Epoch 18, Loss: 0.5568656600357275\n",
      "Epoch 19, Loss: 0.55663237983888\n",
      "Epoch 20, Loss: 0.5564127405393849\n",
      "Epoch 21, Loss: 0.5561954257210477\n",
      "Epoch 22, Loss: 0.5559971620518139\n",
      "Epoch 23, Loss: 0.5558097661735161\n",
      "Epoch 24, Loss: 0.5556274831092025\n",
      "Epoch 25, Loss: 0.5554377894619175\n",
      "Epoch 26, Loss: 0.5552272856616557\n",
      "Epoch 27, Loss: 0.5549795698151565\n",
      "Epoch 28, Loss: 0.5546812137731106\n",
      "Epoch 29, Loss: 0.5543215982032624\n",
      "Epoch 30, Loss: 0.5538822561644048\n",
      "Epoch 31, Loss: 0.5533379268838573\n",
      "Epoch 32, Loss: 0.5526649242752519\n",
      "Epoch 33, Loss: 0.5518361533934071\n",
      "Epoch 34, Loss: 0.5508134710748515\n",
      "Epoch 35, Loss: 0.5495420814641978\n",
      "Epoch 36, Loss: 0.5480008389421293\n",
      "Epoch 37, Loss: 0.5461994358115703\n",
      "Epoch 38, Loss: 0.5441079572851888\n",
      "Epoch 39, Loss: 0.5416347665441027\n",
      "Epoch 40, Loss: 0.5386864276383593\n",
      "Epoch 41, Loss: 0.5352370486556696\n",
      "Epoch 42, Loss: 0.5312354141925766\n",
      "Epoch 43, Loss: 0.5266450562550289\n",
      "Epoch 44, Loss: 0.5215954894368876\n",
      "Epoch 45, Loss: 0.5165491780653468\n",
      "Epoch 46, Loss: 0.5124648384499985\n",
      "Epoch 47, Loss: 0.5103728671322479\n",
      "Epoch 48, Loss: 0.5092366422662595\n",
      "Epoch 49, Loss: 0.5062910322350123\n",
      "Epoch 50, Loss: 0.5015907909459796\n",
      "Epoch 51, Loss: 0.49680453166649385\n",
      "Epoch 52, Loss: 0.49312852788129785\n",
      "Epoch 53, Loss: 0.49069722427588275\n",
      "Epoch 54, Loss: 0.488953516703047\n",
      "Epoch 55, Loss: 0.4872585878755481\n",
      "Epoch 56, Loss: 0.4851788034894334\n",
      "Epoch 57, Loss: 0.4828492406797448\n",
      "Epoch 58, Loss: 0.4804993751503953\n",
      "Epoch 59, Loss: 0.47844029047654923\n",
      "Epoch 60, Loss: 0.47709955378059593\n",
      "Epoch 61, Loss: 0.47621130901275555\n",
      "Epoch 62, Loss: 0.47522019690767886\n",
      "Epoch 63, Loss: 0.47375093540511976\n",
      "Epoch 64, Loss: 0.47214575067296755\n",
      "Epoch 65, Loss: 0.47081752035993174\n",
      "Epoch 66, Loss: 0.4698421946614956\n",
      "Epoch 67, Loss: 0.46911303449394604\n",
      "Epoch 68, Loss: 0.4684094463496121\n",
      "Epoch 69, Loss: 0.467553471271429\n",
      "Epoch 70, Loss: 0.46644904932298753\n",
      "Epoch 71, Loss: 0.4651833103446895\n",
      "Epoch 72, Loss: 0.4639668728979369\n",
      "Epoch 73, Loss: 0.4629709681066085\n",
      "Epoch 74, Loss: 0.4622087566860159\n",
      "Epoch 75, Loss: 0.46154893311517853\n",
      "Epoch 76, Loss: 0.46081673931415723\n",
      "Epoch 77, Loss: 0.45997057538150116\n",
      "Epoch 78, Loss: 0.45910251801364654\n",
      "Epoch 79, Loss: 0.4584132923113445\n",
      "Epoch 80, Loss: 0.45789685562547067\n",
      "Epoch 81, Loss: 0.4573286833006557\n",
      "Epoch 82, Loss: 0.45672419413957427\n",
      "Epoch 83, Loss: 0.4560924081498389\n",
      "Epoch 84, Loss: 0.4554051873428908\n",
      "Epoch 85, Loss: 0.45474234050363\n",
      "Epoch 86, Loss: 0.454201553985032\n",
      "Epoch 87, Loss: 0.4536514184070008\n",
      "Epoch 88, Loss: 0.4530092124328534\n",
      "Epoch 89, Loss: 0.4523706075703324\n",
      "Epoch 90, Loss: 0.4517835293915709\n",
      "Epoch 91, Loss: 0.4511970413917572\n",
      "Epoch 92, Loss: 0.45062181043091293\n",
      "Epoch 93, Loss: 0.45003587791680955\n",
      "Epoch 94, Loss: 0.4493710467041316\n",
      "Epoch 95, Loss: 0.4487281110201424\n",
      "Epoch 96, Loss: 0.44814748324570985\n",
      "Epoch 97, Loss: 0.44755318405541034\n",
      "Epoch 98, Loss: 0.4469446254722877\n",
      "Epoch 99, Loss: 0.4463197292751487\n",
      "Epoch 100, Loss: 0.4456848963253673\n",
      "Epoch 101, Loss: 0.4450964319830886\n",
      "Epoch 102, Loss: 0.44449741657137115\n",
      "Epoch 103, Loss: 0.44389287636419034\n",
      "Epoch 104, Loss: 0.4432974784766023\n",
      "Epoch 105, Loss: 0.4427109400354573\n",
      "Epoch 106, Loss: 0.44214960818822824\n",
      "Epoch 107, Loss: 0.44158724222158696\n",
      "Epoch 108, Loss: 0.44105301285451887\n",
      "Epoch 109, Loss: 0.44056271660699714\n",
      "Epoch 110, Loss: 0.44006872504671823\n",
      "Epoch 111, Loss: 0.4395730088213203\n",
      "Epoch 112, Loss: 0.43907096352344577\n",
      "Epoch 113, Loss: 0.4385729983169879\n",
      "Epoch 114, Loss: 0.43805038369101773\n",
      "Epoch 115, Loss: 0.4375473575846163\n",
      "Epoch 116, Loss: 0.43705488449961516\n",
      "Epoch 117, Loss: 0.4365316129938681\n",
      "Epoch 118, Loss: 0.4360250576511588\n",
      "Epoch 119, Loss: 0.43551645899743324\n",
      "Epoch 120, Loss: 0.4349955846025283\n",
      "Epoch 121, Loss: 0.43450087088924527\n",
      "Epoch 122, Loss: 0.4340134213510386\n",
      "Epoch 123, Loss: 0.4335087529633026\n",
      "Epoch 124, Loss: 0.43301376868639413\n",
      "Epoch 125, Loss: 0.43252197320058844\n",
      "Epoch 126, Loss: 0.4320181494549427\n",
      "Epoch 127, Loss: 0.43151005975328266\n",
      "Epoch 128, Loss: 0.4309950268296976\n",
      "Epoch 129, Loss: 0.430473995003706\n",
      "Epoch 130, Loss: 0.42994191700634643\n",
      "Epoch 131, Loss: 0.42939698194958736\n",
      "Epoch 132, Loss: 0.42886150036331494\n",
      "Epoch 133, Loss: 0.4283387256287844\n",
      "Epoch 134, Loss: 0.42785055942813116\n",
      "Epoch 135, Loss: 0.4273804894647344\n",
      "Epoch 136, Loss: 0.4269227815474693\n",
      "Epoch 137, Loss: 0.42653238029478346\n",
      "Epoch 138, Loss: 0.42622307068674903\n",
      "Epoch 139, Loss: 0.4258585168567074\n",
      "Epoch 140, Loss: 0.4249907688933511\n",
      "Epoch 141, Loss: 0.4244832894840782\n",
      "Epoch 142, Loss: 0.42420861528911363\n",
      "Epoch 143, Loss: 0.42341674669371726\n",
      "Epoch 144, Loss: 0.42295864238294933\n",
      "Epoch 145, Loss: 0.4227447727315581\n",
      "Epoch 146, Loss: 0.42213447856230124\n",
      "Epoch 147, Loss: 0.4215257930115352\n",
      "Epoch 148, Loss: 0.4212602091720874\n",
      "Epoch 149, Loss: 0.4209117312002577\n",
      "Epoch 150, Loss: 0.42032713740504246\n",
      "Epoch 151, Loss: 0.4198255029140939\n",
      "Epoch 152, Loss: 0.419526095509609\n",
      "Epoch 153, Loss: 0.41917500279380443\n",
      "Epoch 154, Loss: 0.41867220141666284\n",
      "Epoch 155, Loss: 0.4181364917173805\n",
      "Epoch 156, Loss: 0.41776705715163526\n",
      "Epoch 157, Loss: 0.4174676190456694\n",
      "Epoch 158, Loss: 0.41703160119783345\n",
      "Epoch 159, Loss: 0.4164665178554137\n",
      "Epoch 160, Loss: 0.4160017091814564\n",
      "Epoch 161, Loss: 0.41566405865698197\n",
      "Epoch 162, Loss: 0.41538724767701324\n",
      "Epoch 163, Loss: 0.41518571843091356\n",
      "Epoch 164, Loss: 0.4146492956712335\n",
      "Epoch 165, Loss: 0.4140713348885626\n",
      "Epoch 166, Loss: 0.4133955784748998\n",
      "Epoch 167, Loss: 0.4129877357001229\n",
      "Epoch 168, Loss: 0.4127854140100025\n",
      "Epoch 169, Loss: 0.4125301328403652\n",
      "Epoch 170, Loss: 0.4122050928984406\n",
      "Epoch 171, Loss: 0.4114683870302507\n",
      "Epoch 172, Loss: 0.41077436465314704\n",
      "Epoch 173, Loss: 0.41023041190923054\n",
      "Epoch 174, Loss: 0.40994660605523725\n",
      "Epoch 175, Loss: 0.4099789554149492\n",
      "Epoch 176, Loss: 0.40987321079488365\n",
      "Epoch 177, Loss: 0.40950505469419896\n",
      "Epoch 178, Loss: 0.4082519465550154\n",
      "Epoch 179, Loss: 0.4076576969505589\n",
      "Epoch 180, Loss: 0.40771239502679696\n",
      "Epoch 181, Loss: 0.40734828529423106\n",
      "Epoch 182, Loss: 0.40666461840814677\n",
      "Epoch 183, Loss: 0.40597934143119546\n",
      "Epoch 184, Loss: 0.4058830731607878\n",
      "Epoch 185, Loss: 0.40627347438188494\n",
      "Epoch 186, Loss: 0.40558465245603686\n",
      "Epoch 187, Loss: 0.40474501020738124\n",
      "Epoch 188, Loss: 0.40398227042655305\n",
      "Epoch 189, Loss: 0.40406241506175883\n",
      "Epoch 190, Loss: 0.40464581528944626\n",
      "Epoch 191, Loss: 0.4035055367906502\n",
      "Epoch 192, Loss: 0.40242216586778423\n",
      "Epoch 193, Loss: 0.40212995904503696\n",
      "Epoch 194, Loss: 0.402292026046811\n",
      "Epoch 195, Loss: 0.40235171263880043\n",
      "Epoch 196, Loss: 0.40128850977883807\n",
      "Epoch 197, Loss: 0.40045379512516016\n",
      "Epoch 198, Loss: 0.400272817260345\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.23448698642145105\n",
      "Test R^2 score: 0.40541057939775044\n",
      "Num of epochs: 199\n",
      "Epoch 1, Loss: 0.6059700889932615\n",
      "Epoch 2, Loss: 0.6036312893642335\n",
      "Epoch 3, Loss: 0.6013563471700136\n",
      "Epoch 4, Loss: 0.5991372103960023\n",
      "Epoch 5, Loss: 0.5970268176267932\n",
      "Epoch 6, Loss: 0.5949925922285283\n",
      "Epoch 7, Loss: 0.5930081551668114\n",
      "Epoch 8, Loss: 0.5910643522821062\n",
      "Epoch 9, Loss: 0.5891683640201548\n",
      "Epoch 10, Loss: 0.587319663960208\n",
      "Epoch 11, Loss: 0.5855167149569324\n",
      "Epoch 12, Loss: 0.5837407704426255\n",
      "Epoch 13, Loss: 0.5820776901663332\n",
      "Epoch 14, Loss: 0.5804690703728718\n",
      "Epoch 15, Loss: 0.5788970122842266\n",
      "Epoch 16, Loss: 0.5773610402823146\n",
      "Epoch 17, Loss: 0.5758283981419067\n",
      "Epoch 18, Loss: 0.5743124230202425\n",
      "Epoch 19, Loss: 0.5728434747124337\n",
      "Epoch 20, Loss: 0.5714499483410062\n",
      "Epoch 21, Loss: 0.570090028404079\n",
      "Epoch 22, Loss: 0.5687915168532679\n",
      "Epoch 23, Loss: 0.5676451452477909\n",
      "Epoch 24, Loss: 0.566491456035549\n",
      "Epoch 25, Loss: 0.5653460083283216\n",
      "Epoch 26, Loss: 0.5642067922816162\n",
      "Epoch 27, Loss: 0.5630573848983631\n",
      "Epoch 28, Loss: 0.5618072058118115\n",
      "Epoch 29, Loss: 0.5603683134110189\n",
      "Epoch 30, Loss: 0.5589470979535536\n",
      "Epoch 31, Loss: 0.5574702722381212\n",
      "Epoch 32, Loss: 0.5560439006588555\n",
      "Epoch 33, Loss: 0.5547250009674192\n",
      "Epoch 34, Loss: 0.5532654007562148\n",
      "Epoch 35, Loss: 0.5515885084898516\n",
      "Epoch 36, Loss: 0.5497081122944296\n",
      "Epoch 37, Loss: 0.5476185512219621\n",
      "Epoch 38, Loss: 0.5452905043835934\n",
      "Epoch 39, Loss: 0.5427617838110558\n",
      "Epoch 40, Loss: 0.540183187778028\n",
      "Epoch 41, Loss: 0.5377759369341596\n",
      "Epoch 42, Loss: 0.5358078880507594\n",
      "Epoch 43, Loss: 0.5345791398902517\n",
      "Epoch 44, Loss: 0.5340198228814321\n",
      "Epoch 45, Loss: 0.5331060859214004\n",
      "Epoch 46, Loss: 0.531035997258968\n",
      "Epoch 47, Loss: 0.528248385400286\n",
      "Epoch 48, Loss: 0.5255720541434135\n",
      "Epoch 49, Loss: 0.5234495987134432\n",
      "Epoch 50, Loss: 0.5218534842070468\n",
      "Epoch 51, Loss: 0.5204492933289224\n",
      "Epoch 52, Loss: 0.5188997489156684\n",
      "Epoch 53, Loss: 0.5170632734667566\n",
      "Epoch 54, Loss: 0.5150541845075569\n",
      "Epoch 55, Loss: 0.5129624606260239\n",
      "Epoch 56, Loss: 0.51101417666103\n",
      "Epoch 57, Loss: 0.509485657496635\n",
      "Epoch 58, Loss: 0.508420521523585\n",
      "Epoch 59, Loss: 0.5073613730548654\n",
      "Epoch 60, Loss: 0.5058170138852559\n",
      "Epoch 61, Loss: 0.503919527337267\n",
      "Epoch 62, Loss: 0.5021761684409258\n",
      "Epoch 63, Loss: 0.5008210057800603\n",
      "Epoch 64, Loss: 0.4996481342805347\n",
      "Epoch 65, Loss: 0.4983569657129516\n",
      "Epoch 66, Loss: 0.49684169285779817\n",
      "Epoch 67, Loss: 0.4952815157468219\n",
      "Epoch 68, Loss: 0.49390582209239403\n",
      "Epoch 69, Loss: 0.4926977842651973\n",
      "Epoch 70, Loss: 0.49142239154450007\n",
      "Epoch 71, Loss: 0.49001194744725585\n",
      "Epoch 72, Loss: 0.4886466223323353\n",
      "Epoch 73, Loss: 0.4874576336228792\n",
      "Epoch 74, Loss: 0.4863113339141369\n",
      "Epoch 75, Loss: 0.4850574423505781\n",
      "Epoch 76, Loss: 0.48374878488925255\n",
      "Epoch 77, Loss: 0.48255239103430625\n",
      "Epoch 78, Loss: 0.48149003445977245\n",
      "Epoch 79, Loss: 0.48039172105575745\n",
      "Epoch 80, Loss: 0.47921286408622266\n",
      "Epoch 81, Loss: 0.47811581783578144\n",
      "Epoch 82, Loss: 0.47711270261372096\n",
      "Epoch 83, Loss: 0.4760396465561935\n",
      "Epoch 84, Loss: 0.4749017136930647\n",
      "Epoch 85, Loss: 0.47379974884076465\n",
      "Epoch 86, Loss: 0.4727243106484979\n",
      "Epoch 87, Loss: 0.4716162155125932\n",
      "Epoch 88, Loss: 0.47052082314560584\n",
      "Epoch 89, Loss: 0.46949122951773875\n",
      "Epoch 90, Loss: 0.46844820797968645\n",
      "Epoch 91, Loss: 0.46737571165730035\n",
      "Epoch 92, Loss: 0.4663355794557809\n",
      "Epoch 93, Loss: 0.46530231328897903\n",
      "Epoch 94, Loss: 0.4642294182156647\n",
      "Epoch 95, Loss: 0.4631262071107276\n",
      "Epoch 96, Loss: 0.46198430243056215\n",
      "Epoch 97, Loss: 0.46082464549973423\n",
      "Epoch 98, Loss: 0.45966603408578155\n",
      "Epoch 99, Loss: 0.45850251247150253\n",
      "Epoch 100, Loss: 0.4573414556760489\n",
      "Epoch 101, Loss: 0.45613066471290353\n",
      "Epoch 102, Loss: 0.4548461552054769\n",
      "Epoch 103, Loss: 0.45350065773408377\n",
      "Epoch 104, Loss: 0.4521600874188869\n",
      "Epoch 105, Loss: 0.4508876483244072\n",
      "Epoch 106, Loss: 0.4497157788746119\n",
      "Epoch 107, Loss: 0.4487770728814763\n",
      "Epoch 108, Loss: 0.44810836223750017\n",
      "Epoch 109, Loss: 0.4476498115702343\n",
      "Epoch 110, Loss: 0.44724536833222645\n",
      "Epoch 111, Loss: 0.44678659898520706\n",
      "Epoch 112, Loss: 0.44613195613120565\n",
      "Epoch 113, Loss: 0.4453250649001318\n",
      "Epoch 114, Loss: 0.44454200074615974\n",
      "Epoch 115, Loss: 0.44379583377270765\n",
      "Epoch 116, Loss: 0.443168145165566\n",
      "Epoch 117, Loss: 0.44255860732593816\n",
      "Epoch 118, Loss: 0.44203807543719903\n",
      "Epoch 119, Loss: 0.44153709497821175\n",
      "Epoch 120, Loss: 0.44100966403064795\n",
      "Epoch 121, Loss: 0.4404296367501443\n",
      "Epoch 122, Loss: 0.43982490919289263\n",
      "Epoch 123, Loss: 0.4392057443088956\n",
      "Epoch 124, Loss: 0.43860493503356424\n",
      "Epoch 125, Loss: 0.4379146858567368\n",
      "Epoch 126, Loss: 0.437211946617854\n",
      "Epoch 127, Loss: 0.43657984358483853\n",
      "Epoch 128, Loss: 0.436031943861522\n",
      "Epoch 129, Loss: 0.4354792315724197\n",
      "Epoch 130, Loss: 0.43487646055949425\n",
      "Epoch 131, Loss: 0.4342061778167168\n",
      "Epoch 132, Loss: 0.433455608459951\n",
      "Epoch 133, Loss: 0.4327994967824369\n",
      "Epoch 134, Loss: 0.43224537459855705\n",
      "Epoch 135, Loss: 0.43160793128844316\n",
      "Epoch 136, Loss: 0.4310843909900983\n",
      "Epoch 137, Loss: 0.43061025547203474\n",
      "Epoch 138, Loss: 0.4300546118244715\n",
      "Epoch 139, Loss: 0.42917883849552596\n",
      "Epoch 140, Loss: 0.42867374476071435\n",
      "Epoch 141, Loss: 0.42822503988544297\n",
      "Epoch 142, Loss: 0.42731029791025343\n",
      "Epoch 143, Loss: 0.4267587727201994\n",
      "Epoch 144, Loss: 0.42635604137856925\n",
      "Epoch 145, Loss: 0.42557506643681436\n",
      "Epoch 146, Loss: 0.42495928176598\n",
      "Epoch 147, Loss: 0.4245541239203809\n",
      "Epoch 148, Loss: 0.423875058998997\n",
      "Epoch 149, Loss: 0.4232620114910801\n",
      "Epoch 150, Loss: 0.42287644099464455\n",
      "Epoch 151, Loss: 0.4222855512944369\n",
      "Epoch 152, Loss: 0.42159445582839644\n",
      "Epoch 153, Loss: 0.42099967854140957\n",
      "Epoch 154, Loss: 0.420553947076041\n",
      "Epoch 155, Loss: 0.41992565419470373\n",
      "Epoch 156, Loss: 0.4192643273680057\n",
      "Epoch 157, Loss: 0.4186600111590035\n",
      "Epoch 158, Loss: 0.4181308075654055\n",
      "Epoch 159, Loss: 0.4175824492527704\n",
      "Epoch 160, Loss: 0.4170854629433016\n",
      "Epoch 161, Loss: 0.41661504982077563\n",
      "Epoch 162, Loss: 0.41615071140656124\n",
      "Epoch 163, Loss: 0.4156300902951236\n",
      "Epoch 164, Loss: 0.41489057689685577\n",
      "Epoch 165, Loss: 0.41404267029693254\n",
      "Epoch 166, Loss: 0.4134357134895046\n",
      "Epoch 167, Loss: 0.4130469409761472\n",
      "Epoch 168, Loss: 0.412714166386589\n",
      "Epoch 169, Loss: 0.4123171964814195\n",
      "Epoch 170, Loss: 0.4116752471235528\n",
      "Epoch 171, Loss: 0.4110230324213097\n",
      "Epoch 172, Loss: 0.4105421521525853\n",
      "Epoch 173, Loss: 0.41026499078782\n",
      "Epoch 174, Loss: 0.41007509791135766\n",
      "Epoch 175, Loss: 0.4097295630690011\n",
      "Epoch 176, Loss: 0.4092282104855178\n",
      "Epoch 177, Loss: 0.4085279021439996\n",
      "Epoch 178, Loss: 0.40791971689992473\n",
      "Epoch 179, Loss: 0.4074763897041314\n",
      "Epoch 180, Loss: 0.40716651089514744\n",
      "Epoch 181, Loss: 0.4069569378925228\n",
      "Epoch 182, Loss: 0.4067645665498868\n",
      "Epoch 183, Loss: 0.40652401559465495\n",
      "Epoch 184, Loss: 0.40584041048154745\n",
      "Epoch 185, Loss: 0.4050105517684698\n",
      "Epoch 186, Loss: 0.4043717061694275\n",
      "Epoch 187, Loss: 0.40399908994699657\n",
      "Epoch 188, Loss: 0.4038766529152145\n",
      "Epoch 189, Loss: 0.4038311215151331\n",
      "Epoch 190, Loss: 0.40366823277824593\n",
      "Epoch 191, Loss: 0.40313191666694564\n",
      "Epoch 192, Loss: 0.4022804321539152\n",
      "Epoch 193, Loss: 0.40171947008837716\n",
      "Epoch 194, Loss: 0.4014787356516347\n",
      "Epoch 195, Loss: 0.40137000906664866\n",
      "Epoch 196, Loss: 0.40136057901626954\n",
      "Epoch 197, Loss: 0.4010834445082696\n",
      "Epoch 198, Loss: 0.40063247819488107\n",
      "Epoch 199, Loss: 0.39988045172568815\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2282825208514502\n",
      "Test R^2 score: 0.43409763062167195\n",
      "Num of epochs: 200\n",
      "Epoch 1, Loss: 0.5799846124252129\n",
      "Epoch 2, Loss: 0.5781339696239886\n",
      "Epoch 3, Loss: 0.5763602773109302\n",
      "Epoch 4, Loss: 0.5746453964384235\n",
      "Epoch 5, Loss: 0.5732294240437181\n",
      "Epoch 6, Loss: 0.5719682356911246\n",
      "Epoch 7, Loss: 0.5707588278279481\n",
      "Epoch 8, Loss: 0.5695993589431794\n",
      "Epoch 9, Loss: 0.5684795711356198\n",
      "Epoch 10, Loss: 0.5673949983900087\n",
      "Epoch 11, Loss: 0.5663463166196663\n",
      "Epoch 12, Loss: 0.5653359659953867\n",
      "Epoch 13, Loss: 0.5643646276456579\n",
      "Epoch 14, Loss: 0.5634454093796876\n",
      "Epoch 15, Loss: 0.5625784607314008\n",
      "Epoch 16, Loss: 0.561762538258982\n",
      "Epoch 17, Loss: 0.5609880631803751\n",
      "Epoch 18, Loss: 0.5602479995222008\n",
      "Epoch 19, Loss: 0.5595318845965279\n",
      "Epoch 20, Loss: 0.5588394105023156\n",
      "Epoch 21, Loss: 0.5581729878111048\n",
      "Epoch 22, Loss: 0.5575335919305504\n",
      "Epoch 23, Loss: 0.5569344263874902\n",
      "Epoch 24, Loss: 0.5563779512325837\n",
      "Epoch 25, Loss: 0.555826736532105\n",
      "Epoch 26, Loss: 0.5552577995704019\n",
      "Epoch 27, Loss: 0.5546228881599709\n",
      "Epoch 28, Loss: 0.5538577737834854\n",
      "Epoch 29, Loss: 0.5529332965610425\n",
      "Epoch 30, Loss: 0.5518785462746133\n",
      "Epoch 31, Loss: 0.5507198326551737\n",
      "Epoch 32, Loss: 0.5493344723591678\n",
      "Epoch 33, Loss: 0.5477176985502856\n",
      "Epoch 34, Loss: 0.5457713298185461\n",
      "Epoch 35, Loss: 0.5434319969368049\n",
      "Epoch 36, Loss: 0.5407428260253275\n",
      "Epoch 37, Loss: 0.5378214052605673\n",
      "Epoch 38, Loss: 0.5347626902664833\n",
      "Epoch 39, Loss: 0.5319155563061219\n",
      "Epoch 40, Loss: 0.5296967182088728\n",
      "Epoch 41, Loss: 0.5278262438884709\n",
      "Epoch 42, Loss: 0.5252461571586888\n",
      "Epoch 43, Loss: 0.5216646490068183\n",
      "Epoch 44, Loss: 0.5180810176647693\n",
      "Epoch 45, Loss: 0.5154476727827486\n",
      "Epoch 46, Loss: 0.5137825908208349\n",
      "Epoch 47, Loss: 0.5120304701574799\n",
      "Epoch 48, Loss: 0.5097504536793679\n",
      "Epoch 49, Loss: 0.5072032795329973\n",
      "Epoch 50, Loss: 0.5048665794847159\n",
      "Epoch 51, Loss: 0.5029311689336494\n",
      "Epoch 52, Loss: 0.5010038669574002\n",
      "Epoch 53, Loss: 0.49883617612693804\n",
      "Epoch 54, Loss: 0.49682950105418666\n",
      "Epoch 55, Loss: 0.4952044739236467\n",
      "Epoch 56, Loss: 0.49356158258884936\n",
      "Epoch 57, Loss: 0.4916001402842304\n",
      "Epoch 58, Loss: 0.4896876565559298\n",
      "Epoch 59, Loss: 0.4881360868203524\n",
      "Epoch 60, Loss: 0.4865775943048971\n",
      "Epoch 61, Loss: 0.4848721321888527\n",
      "Epoch 62, Loss: 0.48340498794587217\n",
      "Epoch 63, Loss: 0.4821219805582615\n",
      "Epoch 64, Loss: 0.48065980353671584\n",
      "Epoch 65, Loss: 0.4792022139037994\n",
      "Epoch 66, Loss: 0.47793833884954634\n",
      "Epoch 67, Loss: 0.47659067164467384\n",
      "Epoch 68, Loss: 0.4753002585515708\n",
      "Epoch 69, Loss: 0.4740436463199702\n",
      "Epoch 70, Loss: 0.4727453195177811\n",
      "Epoch 71, Loss: 0.47152312466375035\n",
      "Epoch 72, Loss: 0.4702165391679504\n",
      "Epoch 73, Loss: 0.4690477538157618\n",
      "Epoch 74, Loss: 0.46782916539436026\n",
      "Epoch 75, Loss: 0.466704930144614\n",
      "Epoch 76, Loss: 0.4656487074839479\n",
      "Epoch 77, Loss: 0.4645937078825791\n",
      "Epoch 78, Loss: 0.46355646266968636\n",
      "Epoch 79, Loss: 0.46256308898558407\n",
      "Epoch 80, Loss: 0.4615606686059238\n",
      "Epoch 81, Loss: 0.46061790830932053\n",
      "Epoch 82, Loss: 0.45966457530208205\n",
      "Epoch 83, Loss: 0.4587635889041617\n",
      "Epoch 84, Loss: 0.45789067248682785\n",
      "Epoch 85, Loss: 0.4570545288417426\n",
      "Epoch 86, Loss: 0.4562376092508514\n",
      "Epoch 87, Loss: 0.45540456564980564\n",
      "Epoch 88, Loss: 0.4545876803075198\n",
      "Epoch 89, Loss: 0.453785677734109\n",
      "Epoch 90, Loss: 0.45299824224219437\n",
      "Epoch 91, Loss: 0.45225589538114114\n",
      "Epoch 92, Loss: 0.45152470387607024\n",
      "Epoch 93, Loss: 0.4507991853316104\n",
      "Epoch 94, Loss: 0.45009832102816905\n",
      "Epoch 95, Loss: 0.44942424883648396\n",
      "Epoch 96, Loss: 0.44875978990464716\n",
      "Epoch 97, Loss: 0.4480756728771018\n",
      "Epoch 98, Loss: 0.4473935739669623\n",
      "Epoch 99, Loss: 0.4467614676567901\n",
      "Epoch 100, Loss: 0.4461837243570824\n",
      "Epoch 101, Loss: 0.4456083252075589\n",
      "Epoch 102, Loss: 0.4450181356227773\n",
      "Epoch 103, Loss: 0.4444376567067275\n",
      "Epoch 104, Loss: 0.44385856724118117\n",
      "Epoch 105, Loss: 0.44329894069886694\n",
      "Epoch 106, Loss: 0.44273514011977294\n",
      "Epoch 107, Loss: 0.4421893911691939\n",
      "Epoch 108, Loss: 0.44165896043112446\n",
      "Epoch 109, Loss: 0.4411033502575174\n",
      "Epoch 110, Loss: 0.4404675114327697\n",
      "Epoch 111, Loss: 0.4398527235941782\n",
      "Epoch 112, Loss: 0.4392777326043714\n",
      "Epoch 113, Loss: 0.43868632916953093\n",
      "Epoch 114, Loss: 0.43809587906991476\n",
      "Epoch 115, Loss: 0.43738612327811444\n",
      "Epoch 116, Loss: 0.4366031548337149\n",
      "Epoch 117, Loss: 0.43581031735200676\n",
      "Epoch 118, Loss: 0.43515693417945644\n",
      "Epoch 119, Loss: 0.43457401574089255\n",
      "Epoch 120, Loss: 0.4340436851977217\n",
      "Epoch 121, Loss: 0.43352621428879096\n",
      "Epoch 122, Loss: 0.4329867022732177\n",
      "Epoch 123, Loss: 0.43245613079623196\n",
      "Epoch 124, Loss: 0.4319067432424761\n",
      "Epoch 125, Loss: 0.43135441055174273\n",
      "Epoch 126, Loss: 0.4308486681219124\n",
      "Epoch 127, Loss: 0.43033085256874015\n",
      "Epoch 128, Loss: 0.4297871734148815\n",
      "Epoch 129, Loss: 0.42917496717938075\n",
      "Epoch 130, Loss: 0.42861643729413595\n",
      "Epoch 131, Loss: 0.42803110429563995\n",
      "Epoch 132, Loss: 0.4274371433895234\n",
      "Epoch 133, Loss: 0.42690220535291296\n",
      "Epoch 134, Loss: 0.42640568502185333\n",
      "Epoch 135, Loss: 0.4259329359407572\n",
      "Epoch 136, Loss: 0.4254574550680243\n",
      "Epoch 137, Loss: 0.4249724309057624\n",
      "Epoch 138, Loss: 0.4245668468918265\n",
      "Epoch 139, Loss: 0.42415005459635025\n",
      "Epoch 140, Loss: 0.42368118973695146\n",
      "Epoch 141, Loss: 0.423076948398476\n",
      "Epoch 142, Loss: 0.4225914311372527\n",
      "Epoch 143, Loss: 0.42227401231028383\n",
      "Epoch 144, Loss: 0.4219235109765744\n",
      "Epoch 145, Loss: 0.4214045762823387\n",
      "Epoch 146, Loss: 0.42088215170240123\n",
      "Epoch 147, Loss: 0.42052343882554477\n",
      "Epoch 148, Loss: 0.42022089403084506\n",
      "Epoch 149, Loss: 0.4198168601087508\n",
      "Epoch 150, Loss: 0.4193386552186909\n",
      "Epoch 151, Loss: 0.41891486495200764\n",
      "Epoch 152, Loss: 0.4185994817178309\n",
      "Epoch 153, Loss: 0.4182857844064551\n",
      "Epoch 154, Loss: 0.41787633141508934\n",
      "Epoch 155, Loss: 0.41740672034559617\n",
      "Epoch 156, Loss: 0.41695530748430465\n",
      "Epoch 157, Loss: 0.4165652231068759\n",
      "Epoch 158, Loss: 0.41624668134334386\n",
      "Epoch 159, Loss: 0.41597907035588216\n",
      "Epoch 160, Loss: 0.4157615745559595\n",
      "Epoch 161, Loss: 0.41538731942288404\n",
      "Epoch 162, Loss: 0.41481342240737223\n",
      "Epoch 163, Loss: 0.4142625613302351\n",
      "Epoch 164, Loss: 0.4139783521834295\n",
      "Epoch 165, Loss: 0.4138264072952212\n",
      "Epoch 166, Loss: 0.41346807818026277\n",
      "Epoch 167, Loss: 0.41289593450476153\n",
      "Epoch 168, Loss: 0.41238741060645484\n",
      "Epoch 169, Loss: 0.4120836295090483\n",
      "Epoch 170, Loss: 0.41185291500243226\n",
      "Epoch 171, Loss: 0.41147233440222497\n",
      "Epoch 172, Loss: 0.41093244223147357\n",
      "Epoch 173, Loss: 0.41044463055932645\n",
      "Epoch 174, Loss: 0.41011130677081914\n",
      "Epoch 175, Loss: 0.409853614691319\n",
      "Epoch 176, Loss: 0.4096236267462613\n",
      "Epoch 177, Loss: 0.4093434955034951\n",
      "Epoch 178, Loss: 0.40897976308880224\n",
      "Epoch 179, Loss: 0.4084350620596873\n",
      "Epoch 180, Loss: 0.4079125022318428\n",
      "Epoch 181, Loss: 0.4075379678965066\n",
      "Epoch 182, Loss: 0.40732348269842167\n",
      "Epoch 183, Loss: 0.40742835298473884\n",
      "Epoch 184, Loss: 0.40801924803153733\n",
      "Epoch 185, Loss: 0.4081592079886637\n",
      "Epoch 186, Loss: 0.4064206718517063\n",
      "Epoch 187, Loss: 0.40578250395676935\n",
      "Epoch 188, Loss: 0.4063901109435147\n",
      "Epoch 189, Loss: 0.40548790461990036\n",
      "Epoch 190, Loss: 0.4046244008717124\n",
      "Epoch 191, Loss: 0.4050983648292594\n",
      "Epoch 192, Loss: 0.40448588868766894\n",
      "Epoch 193, Loss: 0.40376698511376635\n",
      "Epoch 194, Loss: 0.4038599758830744\n",
      "Epoch 195, Loss: 0.40337696555019004\n",
      "Epoch 196, Loss: 0.40273571365681565\n",
      "Epoch 197, Loss: 0.4027385256356363\n",
      "Epoch 198, Loss: 0.4024608589771353\n",
      "Epoch 199, Loss: 0.4018853548415601\n",
      "Epoch 200, Loss: 0.40159118045254666\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22373628167616852\n",
      "Test R^2 score: 0.4582013876879018\n",
      "Num of epochs: 201\n",
      "Epoch 1, Loss: 0.5661451329774101\n",
      "Epoch 2, Loss: 0.5644940160175697\n",
      "Epoch 3, Loss: 0.5632038481251698\n",
      "Epoch 4, Loss: 0.562037542762345\n",
      "Epoch 5, Loss: 0.5609835741252902\n",
      "Epoch 6, Loss: 0.5600376008812834\n",
      "Epoch 7, Loss: 0.559210403563424\n",
      "Epoch 8, Loss: 0.5584861545041855\n",
      "Epoch 9, Loss: 0.557887130574649\n",
      "Epoch 10, Loss: 0.5573859862848694\n",
      "Epoch 11, Loss: 0.5569922156654616\n",
      "Epoch 12, Loss: 0.5566915120740118\n",
      "Epoch 13, Loss: 0.5564815093050627\n",
      "Epoch 14, Loss: 0.5563427044201309\n",
      "Epoch 15, Loss: 0.5562679716485962\n",
      "Epoch 16, Loss: 0.5562449337160654\n",
      "Epoch 17, Loss: 0.5562412100536764\n",
      "Epoch 18, Loss: 0.5562432995939136\n",
      "Epoch 19, Loss: 0.5562437817943922\n",
      "Epoch 20, Loss: 0.5562281636441788\n",
      "Epoch 21, Loss: 0.5561852449593663\n",
      "Epoch 22, Loss: 0.5561219861031866\n",
      "Epoch 23, Loss: 0.5560307692223023\n",
      "Epoch 24, Loss: 0.555903404995831\n",
      "Epoch 25, Loss: 0.5557363292181273\n",
      "Epoch 26, Loss: 0.5555261799542923\n",
      "Epoch 27, Loss: 0.5552558136678156\n",
      "Epoch 28, Loss: 0.5548911728140176\n",
      "Epoch 29, Loss: 0.5544109729763276\n",
      "Epoch 30, Loss: 0.5538091017482462\n",
      "Epoch 31, Loss: 0.5530856468727442\n",
      "Epoch 32, Loss: 0.5522204864528188\n",
      "Epoch 33, Loss: 0.5511356052547196\n",
      "Epoch 34, Loss: 0.549800947322286\n",
      "Epoch 35, Loss: 0.5481725829990045\n",
      "Epoch 36, Loss: 0.5462048102483061\n",
      "Epoch 37, Loss: 0.5438347640781052\n",
      "Epoch 38, Loss: 0.5409625471498923\n",
      "Epoch 39, Loss: 0.5374979728837933\n",
      "Epoch 40, Loss: 0.5333779017135043\n",
      "Epoch 41, Loss: 0.5286368727903346\n",
      "Epoch 42, Loss: 0.5235306386498335\n",
      "Epoch 43, Loss: 0.5186387333406624\n",
      "Epoch 44, Loss: 0.5151097295118089\n",
      "Epoch 45, Loss: 0.5137600551094589\n",
      "Epoch 46, Loss: 0.512614885107159\n",
      "Epoch 47, Loss: 0.5094960987327292\n",
      "Epoch 48, Loss: 0.5055742675453007\n",
      "Epoch 49, Loss: 0.5025014591195857\n",
      "Epoch 50, Loss: 0.5006859663417338\n",
      "Epoch 51, Loss: 0.49954572545073495\n",
      "Epoch 52, Loss: 0.49820884613968247\n",
      "Epoch 53, Loss: 0.4961820508814102\n",
      "Epoch 54, Loss: 0.4934861443902188\n",
      "Epoch 55, Loss: 0.49069863635437894\n",
      "Epoch 56, Loss: 0.4886107439306987\n",
      "Epoch 57, Loss: 0.4876189202978664\n",
      "Epoch 58, Loss: 0.4869874674723684\n",
      "Epoch 59, Loss: 0.4855717671796835\n",
      "Epoch 60, Loss: 0.48341041318913375\n",
      "Epoch 61, Loss: 0.48146136026931663\n",
      "Epoch 62, Loss: 0.4802243611384081\n",
      "Epoch 63, Loss: 0.4793534864897512\n",
      "Epoch 64, Loss: 0.47826861798847536\n",
      "Epoch 65, Loss: 0.4767880453223185\n",
      "Epoch 66, Loss: 0.4751597380580657\n",
      "Epoch 67, Loss: 0.47373748881042255\n",
      "Epoch 68, Loss: 0.47260402359377696\n",
      "Epoch 69, Loss: 0.4713823949324321\n",
      "Epoch 70, Loss: 0.4699028144452583\n",
      "Epoch 71, Loss: 0.46852658033642325\n",
      "Epoch 72, Loss: 0.4674397913262918\n",
      "Epoch 73, Loss: 0.4663815745818396\n",
      "Epoch 74, Loss: 0.46515082787021095\n",
      "Epoch 75, Loss: 0.4638511895884402\n",
      "Epoch 76, Loss: 0.46263501799774853\n",
      "Epoch 77, Loss: 0.46145369833806404\n",
      "Epoch 78, Loss: 0.4603402907974595\n",
      "Epoch 79, Loss: 0.4594430133528731\n",
      "Epoch 80, Loss: 0.4586659727137513\n",
      "Epoch 81, Loss: 0.45775341785390367\n",
      "Epoch 82, Loss: 0.45689988489911404\n",
      "Epoch 83, Loss: 0.4562730450231782\n",
      "Epoch 84, Loss: 0.4557115787563654\n",
      "Epoch 85, Loss: 0.45507583290145004\n",
      "Epoch 86, Loss: 0.4544340823562703\n",
      "Epoch 87, Loss: 0.45381572299953354\n",
      "Epoch 88, Loss: 0.4531045119816757\n",
      "Epoch 89, Loss: 0.4523750874102114\n",
      "Epoch 90, Loss: 0.45163173276801244\n",
      "Epoch 91, Loss: 0.4508640345516243\n",
      "Epoch 92, Loss: 0.450146041457768\n",
      "Epoch 93, Loss: 0.44948122400525375\n",
      "Epoch 94, Loss: 0.4487865857057561\n",
      "Epoch 95, Loss: 0.44808663056321413\n",
      "Epoch 96, Loss: 0.44740769574474704\n",
      "Epoch 97, Loss: 0.44664337984749836\n",
      "Epoch 98, Loss: 0.44584449979874535\n",
      "Epoch 99, Loss: 0.44505394573800405\n",
      "Epoch 100, Loss: 0.4442371300468363\n",
      "Epoch 101, Loss: 0.44341684380690094\n",
      "Epoch 102, Loss: 0.4426003567531715\n",
      "Epoch 103, Loss: 0.4417960041283778\n",
      "Epoch 104, Loss: 0.44098509893198107\n",
      "Epoch 105, Loss: 0.4401651674991621\n",
      "Epoch 106, Loss: 0.4394086857684729\n",
      "Epoch 107, Loss: 0.4386517147278977\n",
      "Epoch 108, Loss: 0.43790204444171926\n",
      "Epoch 109, Loss: 0.43713859549071493\n",
      "Epoch 110, Loss: 0.4363824501472492\n",
      "Epoch 111, Loss: 0.43559996961273\n",
      "Epoch 112, Loss: 0.43481859979467496\n",
      "Epoch 113, Loss: 0.4340146058521033\n",
      "Epoch 114, Loss: 0.4331932967974147\n",
      "Epoch 115, Loss: 0.4323875558358452\n",
      "Epoch 116, Loss: 0.4315909965603526\n",
      "Epoch 117, Loss: 0.4308287636473356\n",
      "Epoch 118, Loss: 0.430088722867605\n",
      "Epoch 119, Loss: 0.42935127628648045\n",
      "Epoch 120, Loss: 0.42861567244750326\n",
      "Epoch 121, Loss: 0.42787810745581906\n",
      "Epoch 122, Loss: 0.42713680940489446\n",
      "Epoch 123, Loss: 0.4263943449030969\n",
      "Epoch 124, Loss: 0.4256340612379632\n",
      "Epoch 125, Loss: 0.42487595935880446\n",
      "Epoch 126, Loss: 0.424126181856325\n",
      "Epoch 127, Loss: 0.42343439544440525\n",
      "Epoch 128, Loss: 0.4227200803664573\n",
      "Epoch 129, Loss: 0.4219374787018852\n",
      "Epoch 130, Loss: 0.42104547680403825\n",
      "Epoch 131, Loss: 0.420260412682879\n",
      "Epoch 132, Loss: 0.4196023301872176\n",
      "Epoch 133, Loss: 0.4189183508815922\n",
      "Epoch 134, Loss: 0.41814515143674597\n",
      "Epoch 135, Loss: 0.4173288527343145\n",
      "Epoch 136, Loss: 0.41658191017550816\n",
      "Epoch 137, Loss: 0.41593205145313117\n",
      "Epoch 138, Loss: 0.41538247654879085\n",
      "Epoch 139, Loss: 0.4148837707813037\n",
      "Epoch 140, Loss: 0.41424000731912614\n",
      "Epoch 141, Loss: 0.4133206325292182\n",
      "Epoch 142, Loss: 0.4124940821194244\n",
      "Epoch 143, Loss: 0.4120126764467641\n",
      "Epoch 144, Loss: 0.41166248769543795\n",
      "Epoch 145, Loss: 0.41109006029689393\n",
      "Epoch 146, Loss: 0.41024139973647133\n",
      "Epoch 147, Loss: 0.4094339095383172\n",
      "Epoch 148, Loss: 0.40890783415310045\n",
      "Epoch 149, Loss: 0.4085921664964031\n",
      "Epoch 150, Loss: 0.40821361984560495\n",
      "Epoch 151, Loss: 0.40753646877549027\n",
      "Epoch 152, Loss: 0.40667819418489637\n",
      "Epoch 153, Loss: 0.40604677986199395\n",
      "Epoch 154, Loss: 0.40569911799810987\n",
      "Epoch 155, Loss: 0.4054255188697232\n",
      "Epoch 156, Loss: 0.4049803443836751\n",
      "Epoch 157, Loss: 0.4042344897508431\n",
      "Epoch 158, Loss: 0.4034739610372264\n",
      "Epoch 159, Loss: 0.4028711103499525\n",
      "Epoch 160, Loss: 0.4024410315375098\n",
      "Epoch 161, Loss: 0.402216659769272\n",
      "Epoch 162, Loss: 0.4022303115775217\n",
      "Epoch 163, Loss: 0.40240646540162106\n",
      "Epoch 164, Loss: 0.4014970332709475\n",
      "Epoch 165, Loss: 0.40012073259422715\n",
      "Epoch 166, Loss: 0.39971960641189\n",
      "Epoch 167, Loss: 0.4000060677068168\n",
      "Epoch 168, Loss: 0.39947160525503805\n",
      "Epoch 169, Loss: 0.398357981806382\n",
      "Epoch 170, Loss: 0.39829663049056535\n",
      "Epoch 171, Loss: 0.3983826880058806\n",
      "Epoch 172, Loss: 0.3975836449613025\n",
      "Epoch 173, Loss: 0.3968645912968146\n",
      "Epoch 174, Loss: 0.3968962611112905\n",
      "Epoch 175, Loss: 0.39682781209286344\n",
      "Epoch 176, Loss: 0.39611056515968285\n",
      "Epoch 177, Loss: 0.3955527762768261\n",
      "Epoch 178, Loss: 0.39543460121255936\n",
      "Epoch 179, Loss: 0.39534343553204476\n",
      "Epoch 180, Loss: 0.3948303259925162\n",
      "Epoch 181, Loss: 0.39424793533021624\n",
      "Epoch 182, Loss: 0.39395072452910895\n",
      "Epoch 183, Loss: 0.3938184852684085\n",
      "Epoch 184, Loss: 0.39369640212615736\n",
      "Epoch 185, Loss: 0.39340513809826333\n",
      "Epoch 186, Loss: 0.3929787484749394\n",
      "Epoch 187, Loss: 0.3925888287807346\n",
      "Epoch 188, Loss: 0.3922975021140325\n",
      "Epoch 189, Loss: 0.3920894447030095\n",
      "Epoch 190, Loss: 0.391971099848905\n",
      "Epoch 191, Loss: 0.3918813338672855\n",
      "Epoch 192, Loss: 0.39180681742777806\n",
      "Epoch 193, Loss: 0.39180573351687464\n",
      "Epoch 194, Loss: 0.39166282117592627\n",
      "Epoch 195, Loss: 0.3912880610578574\n",
      "Epoch 196, Loss: 0.39066943869540355\n",
      "Epoch 197, Loss: 0.39015797353049875\n",
      "Epoch 198, Loss: 0.389938514215343\n",
      "Epoch 199, Loss: 0.3899559776818409\n",
      "Epoch 200, Loss: 0.39004305406265344\n",
      "Epoch 201, Loss: 0.3899426413195755\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.243067149184573\n",
      "Test R^2 score: 0.3576587982758827\n",
      "Num of epochs: 202\n",
      "Epoch 1, Loss: 0.5592764836939678\n",
      "Epoch 2, Loss: 0.5585703544785817\n",
      "Epoch 3, Loss: 0.5579581479251328\n",
      "Epoch 4, Loss: 0.5574385695974877\n",
      "Epoch 5, Loss: 0.5570110226418852\n",
      "Epoch 6, Loss: 0.5566746483828282\n",
      "Epoch 7, Loss: 0.5564322365978154\n",
      "Epoch 8, Loss: 0.556272713058178\n",
      "Epoch 9, Loss: 0.5561840929140707\n",
      "Epoch 10, Loss: 0.5561570057660998\n",
      "Epoch 11, Loss: 0.5561749300502414\n",
      "Epoch 12, Loss: 0.5562203410096022\n",
      "Epoch 13, Loss: 0.5562766775956183\n",
      "Epoch 14, Loss: 0.5563237944955253\n",
      "Epoch 15, Loss: 0.5563511145766986\n",
      "Epoch 16, Loss: 0.556351864520792\n",
      "Epoch 17, Loss: 0.5563244909064147\n",
      "Epoch 18, Loss: 0.5562721505201711\n",
      "Epoch 19, Loss: 0.5562018555797802\n",
      "Epoch 20, Loss: 0.5561152337799345\n",
      "Epoch 21, Loss: 0.5560193258604288\n",
      "Epoch 22, Loss: 0.5559161105659474\n",
      "Epoch 23, Loss: 0.5558057178755703\n",
      "Epoch 24, Loss: 0.5556876071976595\n",
      "Epoch 25, Loss: 0.5555555240975477\n",
      "Epoch 26, Loss: 0.5554034756751235\n",
      "Epoch 27, Loss: 0.5552233136310979\n",
      "Epoch 28, Loss: 0.5550084595851719\n",
      "Epoch 29, Loss: 0.5547476185201282\n",
      "Epoch 30, Loss: 0.5544261316590199\n",
      "Epoch 31, Loss: 0.5540271105278415\n",
      "Epoch 32, Loss: 0.5535256750342611\n",
      "Epoch 33, Loss: 0.5529035437415335\n",
      "Epoch 34, Loss: 0.5521556938782167\n",
      "Epoch 35, Loss: 0.551280397455047\n",
      "Epoch 36, Loss: 0.5502774795748803\n",
      "Epoch 37, Loss: 0.5491159302144606\n",
      "Epoch 38, Loss: 0.5477426186015917\n",
      "Epoch 39, Loss: 0.5461719080450664\n",
      "Epoch 40, Loss: 0.5444757145894523\n",
      "Epoch 41, Loss: 0.5425325741195538\n",
      "Epoch 42, Loss: 0.5402222196876123\n",
      "Epoch 43, Loss: 0.537448429250733\n",
      "Epoch 44, Loss: 0.5341165564575154\n",
      "Epoch 45, Loss: 0.5301298224498083\n",
      "Epoch 46, Loss: 0.52538481074523\n",
      "Epoch 47, Loss: 0.519909513055708\n",
      "Epoch 48, Loss: 0.5138559338023527\n",
      "Epoch 49, Loss: 0.5074645390829454\n",
      "Epoch 50, Loss: 0.5009415523200946\n",
      "Epoch 51, Loss: 0.4952600637893257\n",
      "Epoch 52, Loss: 0.4920259543624824\n",
      "Epoch 53, Loss: 0.49147884881813764\n",
      "Epoch 54, Loss: 0.4899760169611888\n",
      "Epoch 55, Loss: 0.48645685782470854\n",
      "Epoch 56, Loss: 0.4831601567079277\n",
      "Epoch 57, Loss: 0.48062365446162786\n",
      "Epoch 58, Loss: 0.4783625299429753\n",
      "Epoch 59, Loss: 0.47609977457950176\n",
      "Epoch 60, Loss: 0.4738203955363458\n",
      "Epoch 61, Loss: 0.47167480655774774\n",
      "Epoch 62, Loss: 0.4699230774367019\n",
      "Epoch 63, Loss: 0.4685816621509194\n",
      "Epoch 64, Loss: 0.4674281875003027\n",
      "Epoch 65, Loss: 0.46666303814885146\n",
      "Epoch 66, Loss: 0.46663017967613224\n",
      "Epoch 67, Loss: 0.467067081663247\n",
      "Epoch 68, Loss: 0.46708949346447476\n",
      "Epoch 69, Loss: 0.4662649723440989\n",
      "Epoch 70, Loss: 0.4649253100481603\n",
      "Epoch 71, Loss: 0.4634055802252136\n",
      "Epoch 72, Loss: 0.4621628943929144\n",
      "Epoch 73, Loss: 0.4612154849766731\n",
      "Epoch 74, Loss: 0.4604891843633617\n",
      "Epoch 75, Loss: 0.4594951303886096\n",
      "Epoch 76, Loss: 0.45856771833890714\n",
      "Epoch 77, Loss: 0.45761799439812123\n",
      "Epoch 78, Loss: 0.456721796109785\n",
      "Epoch 79, Loss: 0.4558529131773768\n",
      "Epoch 80, Loss: 0.45502894057992543\n",
      "Epoch 81, Loss: 0.4542346226163135\n",
      "Epoch 82, Loss: 0.4534894037018162\n",
      "Epoch 83, Loss: 0.4527532762822832\n",
      "Epoch 84, Loss: 0.45199419196055846\n",
      "Epoch 85, Loss: 0.4512780465051364\n",
      "Epoch 86, Loss: 0.4506342768937731\n",
      "Epoch 87, Loss: 0.4500372851343042\n",
      "Epoch 88, Loss: 0.44942661949231333\n",
      "Epoch 89, Loss: 0.448756535782677\n",
      "Epoch 90, Loss: 0.448018402551855\n",
      "Epoch 91, Loss: 0.447264558882463\n",
      "Epoch 92, Loss: 0.4464998978447023\n",
      "Epoch 93, Loss: 0.44578161125288807\n",
      "Epoch 94, Loss: 0.44507842018528787\n",
      "Epoch 95, Loss: 0.4443838575743902\n",
      "Epoch 96, Loss: 0.4436506751211948\n",
      "Epoch 97, Loss: 0.44290167756554244\n",
      "Epoch 98, Loss: 0.4421589097394541\n",
      "Epoch 99, Loss: 0.4413999877755544\n",
      "Epoch 100, Loss: 0.44064963319248734\n",
      "Epoch 101, Loss: 0.4398935611632147\n",
      "Epoch 102, Loss: 0.4391452134440171\n",
      "Epoch 103, Loss: 0.43837515968970314\n",
      "Epoch 104, Loss: 0.4375789434871092\n",
      "Epoch 105, Loss: 0.43676957395981425\n",
      "Epoch 106, Loss: 0.4359861818429345\n",
      "Epoch 107, Loss: 0.43521962894239463\n",
      "Epoch 108, Loss: 0.43447741254868405\n",
      "Epoch 109, Loss: 0.4337381174125401\n",
      "Epoch 110, Loss: 0.4330182595169234\n",
      "Epoch 111, Loss: 0.43231753957451874\n",
      "Epoch 112, Loss: 0.43161281651464817\n",
      "Epoch 113, Loss: 0.4309129752524351\n",
      "Epoch 114, Loss: 0.43024586897888906\n",
      "Epoch 115, Loss: 0.4295821320781815\n",
      "Epoch 116, Loss: 0.4289127821850473\n",
      "Epoch 117, Loss: 0.42824337777575444\n",
      "Epoch 118, Loss: 0.427571043419042\n",
      "Epoch 119, Loss: 0.4269057133238915\n",
      "Epoch 120, Loss: 0.42624771744013457\n",
      "Epoch 121, Loss: 0.4256132476853402\n",
      "Epoch 122, Loss: 0.42499736055788706\n",
      "Epoch 123, Loss: 0.42439499314956425\n",
      "Epoch 124, Loss: 0.42380101692947214\n",
      "Epoch 125, Loss: 0.4231606250399012\n",
      "Epoch 126, Loss: 0.42245076767333267\n",
      "Epoch 127, Loss: 0.421727737579741\n",
      "Epoch 128, Loss: 0.4210334968277603\n",
      "Epoch 129, Loss: 0.420345164026008\n",
      "Epoch 130, Loss: 0.4196849243187281\n",
      "Epoch 131, Loss: 0.4190115709527971\n",
      "Epoch 132, Loss: 0.418388352160811\n",
      "Epoch 133, Loss: 0.41790418036999627\n",
      "Epoch 134, Loss: 0.41756821095158797\n",
      "Epoch 135, Loss: 0.4172961804277083\n",
      "Epoch 136, Loss: 0.4158551260232868\n",
      "Epoch 137, Loss: 0.41501186506131393\n",
      "Epoch 138, Loss: 0.414985132640499\n",
      "Epoch 139, Loss: 0.41406136638558155\n",
      "Epoch 140, Loss: 0.4129965935802144\n",
      "Epoch 141, Loss: 0.41272256077919\n",
      "Epoch 142, Loss: 0.4123295923298211\n",
      "Epoch 143, Loss: 0.4113786555857762\n",
      "Epoch 144, Loss: 0.4105268529769887\n",
      "Epoch 145, Loss: 0.41036092102040755\n",
      "Epoch 146, Loss: 0.4100617799501125\n",
      "Epoch 147, Loss: 0.40889717491379307\n",
      "Epoch 148, Loss: 0.4081376858327171\n",
      "Epoch 149, Loss: 0.40803140925371945\n",
      "Epoch 150, Loss: 0.40764695019127983\n",
      "Epoch 151, Loss: 0.4066381067789837\n",
      "Epoch 152, Loss: 0.40584162213413955\n",
      "Epoch 153, Loss: 0.40564427701758526\n",
      "Epoch 154, Loss: 0.4056062917112733\n",
      "Epoch 155, Loss: 0.40476831417224907\n",
      "Epoch 156, Loss: 0.40379916529505416\n",
      "Epoch 157, Loss: 0.4033614130761072\n",
      "Epoch 158, Loss: 0.4031568108065313\n",
      "Epoch 159, Loss: 0.40291332927269746\n",
      "Epoch 160, Loss: 0.40231278679970683\n",
      "Epoch 161, Loss: 0.40142387491023274\n",
      "Epoch 162, Loss: 0.40100809262260023\n",
      "Epoch 163, Loss: 0.4009409959778932\n",
      "Epoch 164, Loss: 0.4007031779252953\n",
      "Epoch 165, Loss: 0.40027026716763514\n",
      "Epoch 166, Loss: 0.3995541464488648\n",
      "Epoch 167, Loss: 0.39889559870902763\n",
      "Epoch 168, Loss: 0.3985832546142866\n",
      "Epoch 169, Loss: 0.39837069979915135\n",
      "Epoch 170, Loss: 0.39826067572423385\n",
      "Epoch 171, Loss: 0.3981985796990253\n",
      "Epoch 172, Loss: 0.3977852887408538\n",
      "Epoch 173, Loss: 0.39704245015950196\n",
      "Epoch 174, Loss: 0.3962813548188785\n",
      "Epoch 175, Loss: 0.3958797824945341\n",
      "Epoch 176, Loss: 0.3957900182548647\n",
      "Epoch 177, Loss: 0.3956219167122159\n",
      "Epoch 178, Loss: 0.39519045306539324\n",
      "Epoch 179, Loss: 0.3945737759172181\n",
      "Epoch 180, Loss: 0.39406282169289586\n",
      "Epoch 181, Loss: 0.39376403314318564\n",
      "Epoch 182, Loss: 0.3935782375814849\n",
      "Epoch 183, Loss: 0.39355480108898405\n",
      "Epoch 184, Loss: 0.39328743542917194\n",
      "Epoch 185, Loss: 0.3928304402299198\n",
      "Epoch 186, Loss: 0.39213438244272564\n",
      "Epoch 187, Loss: 0.3915796820789716\n",
      "Epoch 188, Loss: 0.3909421205743086\n",
      "Epoch 189, Loss: 0.39045669744665396\n",
      "Epoch 190, Loss: 0.3901595394254038\n",
      "Epoch 191, Loss: 0.38994865993494987\n",
      "Epoch 192, Loss: 0.39021756858643786\n",
      "Epoch 193, Loss: 0.3916975365133975\n",
      "Epoch 194, Loss: 0.3949437392886395\n",
      "Epoch 195, Loss: 0.39104286731555293\n",
      "Epoch 196, Loss: 0.3880345088247096\n",
      "Epoch 197, Loss: 0.3901701758866613\n",
      "Epoch 198, Loss: 0.38927604452674963\n",
      "Epoch 199, Loss: 0.38701446863353056\n",
      "Epoch 200, Loss: 0.38811627650017233\n",
      "Epoch 201, Loss: 0.38762608445749935\n",
      "Epoch 202, Loss: 0.3858907485938856\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.23217794717278567\n",
      "Test R^2 score: 0.4173909293350896\n",
      "Num of epochs: 203\n",
      "Epoch 1, Loss: 0.5696463417590683\n",
      "Epoch 2, Loss: 0.5683047868135367\n",
      "Epoch 3, Loss: 0.5671080877865168\n",
      "Epoch 4, Loss: 0.5660654555474498\n",
      "Epoch 5, Loss: 0.5650853243263332\n",
      "Epoch 6, Loss: 0.5641654050165867\n",
      "Epoch 7, Loss: 0.5633049344865023\n",
      "Epoch 8, Loss: 0.5625240797610804\n",
      "Epoch 9, Loss: 0.5618051369655932\n",
      "Epoch 10, Loss: 0.5611369785110373\n",
      "Epoch 11, Loss: 0.5605188289630836\n",
      "Epoch 12, Loss: 0.5599501088176096\n",
      "Epoch 13, Loss: 0.5594298501001488\n",
      "Epoch 14, Loss: 0.5589575749763106\n",
      "Epoch 15, Loss: 0.5585324180384638\n",
      "Epoch 16, Loss: 0.5581505090623184\n",
      "Epoch 17, Loss: 0.5578113491783773\n",
      "Epoch 18, Loss: 0.5575115150494107\n",
      "Epoch 19, Loss: 0.5572407482332449\n",
      "Epoch 20, Loss: 0.5570116646896149\n",
      "Epoch 21, Loss: 0.5568060645817976\n",
      "Epoch 22, Loss: 0.5566289532424895\n",
      "Epoch 23, Loss: 0.5564717890022942\n",
      "Epoch 24, Loss: 0.5563346691199361\n",
      "Epoch 25, Loss: 0.5562093837782509\n",
      "Epoch 26, Loss: 0.5560986473680306\n",
      "Epoch 27, Loss: 0.5559878352999102\n",
      "Epoch 28, Loss: 0.555862257327383\n",
      "Epoch 29, Loss: 0.5557142881947845\n",
      "Epoch 30, Loss: 0.5555832038065991\n",
      "Epoch 31, Loss: 0.5553621836404175\n",
      "Epoch 32, Loss: 0.5550660466941092\n",
      "Epoch 33, Loss: 0.5547502240459442\n",
      "Epoch 34, Loss: 0.5543922659454913\n",
      "Epoch 35, Loss: 0.5539634707316538\n",
      "Epoch 36, Loss: 0.5534416499270383\n",
      "Epoch 37, Loss: 0.552805838666064\n",
      "Epoch 38, Loss: 0.5520341299431593\n",
      "Epoch 39, Loss: 0.5511077021624557\n",
      "Epoch 40, Loss: 0.55001537019754\n",
      "Epoch 41, Loss: 0.5487583156728988\n",
      "Epoch 42, Loss: 0.547322063272322\n",
      "Epoch 43, Loss: 0.5457266603827213\n",
      "Epoch 44, Loss: 0.5439067669399997\n",
      "Epoch 45, Loss: 0.5418079784880987\n",
      "Epoch 46, Loss: 0.5393689984267283\n",
      "Epoch 47, Loss: 0.5364027056200517\n",
      "Epoch 48, Loss: 0.5328146109441293\n",
      "Epoch 49, Loss: 0.5287281936856407\n",
      "Epoch 50, Loss: 0.5243913585216352\n",
      "Epoch 51, Loss: 0.5201928078388537\n",
      "Epoch 52, Loss: 0.5169426813983228\n",
      "Epoch 53, Loss: 0.5152431576944068\n",
      "Epoch 54, Loss: 0.5135566959412918\n",
      "Epoch 55, Loss: 0.5101897130860006\n",
      "Epoch 56, Loss: 0.5057111545056705\n",
      "Epoch 57, Loss: 0.5015474750965975\n",
      "Epoch 58, Loss: 0.4985200167906225\n",
      "Epoch 59, Loss: 0.49620313264549076\n",
      "Epoch 60, Loss: 0.49415360686245985\n",
      "Epoch 61, Loss: 0.49204924321883453\n",
      "Epoch 62, Loss: 0.4897190896649473\n",
      "Epoch 63, Loss: 0.48735133312865275\n",
      "Epoch 64, Loss: 0.48505446246211653\n",
      "Epoch 65, Loss: 0.4825883030014952\n",
      "Epoch 66, Loss: 0.4797880266205817\n",
      "Epoch 67, Loss: 0.47702132478666376\n",
      "Epoch 68, Loss: 0.4748159516291803\n",
      "Epoch 69, Loss: 0.4737583741175143\n",
      "Epoch 70, Loss: 0.4730091038940755\n",
      "Epoch 71, Loss: 0.4719452199414379\n",
      "Epoch 72, Loss: 0.4706375899536958\n",
      "Epoch 73, Loss: 0.46945047493013814\n",
      "Epoch 74, Loss: 0.46860805587580345\n",
      "Epoch 75, Loss: 0.46818094680634337\n",
      "Epoch 76, Loss: 0.4673801911436378\n",
      "Epoch 77, Loss: 0.4661867471850733\n",
      "Epoch 78, Loss: 0.4650473909942017\n",
      "Epoch 79, Loss: 0.4641197079419216\n",
      "Epoch 80, Loss: 0.46311021577864364\n",
      "Epoch 81, Loss: 0.4618845278953474\n",
      "Epoch 82, Loss: 0.4607764787190849\n",
      "Epoch 83, Loss: 0.4600088333494577\n",
      "Epoch 84, Loss: 0.45939525313073537\n",
      "Epoch 85, Loss: 0.4586356441201477\n",
      "Epoch 86, Loss: 0.4577468095852617\n",
      "Epoch 87, Loss: 0.456948688581417\n",
      "Epoch 88, Loss: 0.45628893307263635\n",
      "Epoch 89, Loss: 0.4556521777562374\n",
      "Epoch 90, Loss: 0.45510908357154684\n",
      "Epoch 91, Loss: 0.4545129696660484\n",
      "Epoch 92, Loss: 0.45381291557537806\n",
      "Epoch 93, Loss: 0.4531955992848633\n",
      "Epoch 94, Loss: 0.45271522804038883\n",
      "Epoch 95, Loss: 0.45218149150871517\n",
      "Epoch 96, Loss: 0.4515647828727488\n",
      "Epoch 97, Loss: 0.4509542526601636\n",
      "Epoch 98, Loss: 0.4503625488794099\n",
      "Epoch 99, Loss: 0.44977135876421054\n",
      "Epoch 100, Loss: 0.44913888304222127\n",
      "Epoch 101, Loss: 0.4484509748501219\n",
      "Epoch 102, Loss: 0.447814188552729\n",
      "Epoch 103, Loss: 0.4472430694090006\n",
      "Epoch 104, Loss: 0.4466385088889314\n",
      "Epoch 105, Loss: 0.44600638487761657\n",
      "Epoch 106, Loss: 0.4453792354704609\n",
      "Epoch 107, Loss: 0.44477388367254694\n",
      "Epoch 108, Loss: 0.4441400787967487\n",
      "Epoch 109, Loss: 0.4435008659279078\n",
      "Epoch 110, Loss: 0.4428718844472941\n",
      "Epoch 111, Loss: 0.44225683376386776\n",
      "Epoch 112, Loss: 0.4416134946983438\n",
      "Epoch 113, Loss: 0.44093539012401445\n",
      "Epoch 114, Loss: 0.44027944230902527\n",
      "Epoch 115, Loss: 0.43964398795765236\n",
      "Epoch 116, Loss: 0.43899381582275143\n",
      "Epoch 117, Loss: 0.4383281975011351\n",
      "Epoch 118, Loss: 0.4376704701323506\n",
      "Epoch 119, Loss: 0.4370211467045608\n",
      "Epoch 120, Loss: 0.43636896186504065\n",
      "Epoch 121, Loss: 0.43571773308254524\n",
      "Epoch 122, Loss: 0.4350491575166072\n",
      "Epoch 123, Loss: 0.4343657279911769\n",
      "Epoch 124, Loss: 0.43368139326274113\n",
      "Epoch 125, Loss: 0.4329847234163104\n",
      "Epoch 126, Loss: 0.4322700916406303\n",
      "Epoch 127, Loss: 0.43154158685881194\n",
      "Epoch 128, Loss: 0.43082440563792446\n",
      "Epoch 129, Loss: 0.430105474227848\n",
      "Epoch 130, Loss: 0.42937831158311857\n",
      "Epoch 131, Loss: 0.42867132885903175\n",
      "Epoch 132, Loss: 0.42798175364442864\n",
      "Epoch 133, Loss: 0.42729674992667793\n",
      "Epoch 134, Loss: 0.42663486900840547\n",
      "Epoch 135, Loss: 0.42595147745955597\n",
      "Epoch 136, Loss: 0.42526653220768146\n",
      "Epoch 137, Loss: 0.42458118390758093\n",
      "Epoch 138, Loss: 0.42390657393277564\n",
      "Epoch 139, Loss: 0.42325347406524166\n",
      "Epoch 140, Loss: 0.42277843380396896\n",
      "Epoch 141, Loss: 0.4226502959278009\n",
      "Epoch 142, Loss: 0.42187046119226357\n",
      "Epoch 143, Loss: 0.4206552001801731\n",
      "Epoch 144, Loss: 0.42029379409516837\n",
      "Epoch 145, Loss: 0.4200090362223901\n",
      "Epoch 146, Loss: 0.4189870142244533\n",
      "Epoch 147, Loss: 0.4184617851281073\n",
      "Epoch 148, Loss: 0.41820925629167355\n",
      "Epoch 149, Loss: 0.4174085231604014\n",
      "Epoch 150, Loss: 0.4167524448156014\n",
      "Epoch 151, Loss: 0.4164753733048385\n",
      "Epoch 152, Loss: 0.4158572759724026\n",
      "Epoch 153, Loss: 0.4151767816373157\n",
      "Epoch 154, Loss: 0.41482436068351153\n",
      "Epoch 155, Loss: 0.4143582853050264\n",
      "Epoch 156, Loss: 0.4136920387317622\n",
      "Epoch 157, Loss: 0.41324320295320704\n",
      "Epoch 158, Loss: 0.41288752559195097\n",
      "Epoch 159, Loss: 0.4123778169471569\n",
      "Epoch 160, Loss: 0.4118082654952111\n",
      "Epoch 161, Loss: 0.4113809013743209\n",
      "Epoch 162, Loss: 0.41099861473815325\n",
      "Epoch 163, Loss: 0.41058933463155195\n",
      "Epoch 164, Loss: 0.41003556065328256\n",
      "Epoch 165, Loss: 0.4095019980720708\n",
      "Epoch 166, Loss: 0.40902845551384803\n",
      "Epoch 167, Loss: 0.4086176031965459\n",
      "Epoch 168, Loss: 0.4082718202748008\n",
      "Epoch 169, Loss: 0.4079787262683338\n",
      "Epoch 170, Loss: 0.40776719539573963\n",
      "Epoch 171, Loss: 0.4074922787923602\n",
      "Epoch 172, Loss: 0.4070981049501282\n",
      "Epoch 173, Loss: 0.40641665708247104\n",
      "Epoch 174, Loss: 0.4057610760808783\n",
      "Epoch 175, Loss: 0.4055422890774416\n",
      "Epoch 176, Loss: 0.4054315097884395\n",
      "Epoch 177, Loss: 0.4051650304464435\n",
      "Epoch 178, Loss: 0.4044754997432353\n",
      "Epoch 179, Loss: 0.40387050979654243\n",
      "Epoch 180, Loss: 0.40348853050768524\n",
      "Epoch 181, Loss: 0.4033151215226156\n",
      "Epoch 182, Loss: 0.4033102260556826\n",
      "Epoch 183, Loss: 0.4030341179003194\n",
      "Epoch 184, Loss: 0.40255454013762615\n",
      "Epoch 185, Loss: 0.4018188496958852\n",
      "Epoch 186, Loss: 0.40127891070947574\n",
      "Epoch 187, Loss: 0.40104627193762726\n",
      "Epoch 188, Loss: 0.40094264983796774\n",
      "Epoch 189, Loss: 0.40087840443810896\n",
      "Epoch 190, Loss: 0.4004914691745147\n",
      "Epoch 191, Loss: 0.39990836151774667\n",
      "Epoch 192, Loss: 0.3993012844999839\n",
      "Epoch 193, Loss: 0.39894113312671103\n",
      "Epoch 194, Loss: 0.3988390002883572\n",
      "Epoch 195, Loss: 0.3988531413064713\n",
      "Epoch 196, Loss: 0.39883322791889764\n",
      "Epoch 197, Loss: 0.39848245105369445\n",
      "Epoch 198, Loss: 0.3979795479479685\n",
      "Epoch 199, Loss: 0.39716344849092006\n",
      "Epoch 200, Loss: 0.3966796469301009\n",
      "Epoch 201, Loss: 0.39657292997864496\n",
      "Epoch 202, Loss: 0.39662111677306017\n",
      "Epoch 203, Loss: 0.3967428821016568\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.23156099543139194\n",
      "Test R^2 score: 0.4179970832796602\n",
      "Num of epochs: 204\n",
      "Epoch 1, Loss: 0.5721577877995135\n",
      "Epoch 2, Loss: 0.5704217048498685\n",
      "Epoch 3, Loss: 0.5687729422165478\n",
      "Epoch 4, Loss: 0.5672187765025934\n",
      "Epoch 5, Loss: 0.565786799056246\n",
      "Epoch 6, Loss: 0.5644355955998879\n",
      "Epoch 7, Loss: 0.5631830254147226\n",
      "Epoch 8, Loss: 0.5620305433526049\n",
      "Epoch 9, Loss: 0.5609771990740907\n",
      "Epoch 10, Loss: 0.5600210508153587\n",
      "Epoch 11, Loss: 0.5591605452000169\n",
      "Epoch 12, Loss: 0.5583970317042328\n",
      "Epoch 13, Loss: 0.5577338208613787\n",
      "Epoch 14, Loss: 0.5571715115463863\n",
      "Epoch 15, Loss: 0.5567125508201215\n",
      "Epoch 16, Loss: 0.5563481951418505\n",
      "Epoch 17, Loss: 0.5560692246965044\n",
      "Epoch 18, Loss: 0.5558620160617131\n",
      "Epoch 19, Loss: 0.5557150926270652\n",
      "Epoch 20, Loss: 0.5556203224920679\n",
      "Epoch 21, Loss: 0.5555495159165257\n",
      "Epoch 22, Loss: 0.5554721547812455\n",
      "Epoch 23, Loss: 0.5553486067712106\n",
      "Epoch 24, Loss: 0.5551532616656994\n",
      "Epoch 25, Loss: 0.5548830359303052\n",
      "Epoch 26, Loss: 0.5545015963797124\n",
      "Epoch 27, Loss: 0.5539689850353983\n",
      "Epoch 28, Loss: 0.5532404870630189\n",
      "Epoch 29, Loss: 0.5522510046028059\n",
      "Epoch 30, Loss: 0.5509310309018935\n",
      "Epoch 31, Loss: 0.5491607309791501\n",
      "Epoch 32, Loss: 0.5468470975024692\n",
      "Epoch 33, Loss: 0.54391372561557\n",
      "Epoch 34, Loss: 0.5402616624981132\n",
      "Epoch 35, Loss: 0.5359411122725841\n",
      "Epoch 36, Loss: 0.5311322642741061\n",
      "Epoch 37, Loss: 0.5263914198242825\n",
      "Epoch 38, Loss: 0.5227525699284129\n",
      "Epoch 39, Loss: 0.5213913852492109\n",
      "Epoch 40, Loss: 0.5204888317089927\n",
      "Epoch 41, Loss: 0.517181244319642\n",
      "Epoch 42, Loss: 0.5125740707183631\n",
      "Epoch 43, Loss: 0.5088177048717193\n",
      "Epoch 44, Loss: 0.5066290343053624\n",
      "Epoch 45, Loss: 0.5052709802804481\n",
      "Epoch 46, Loss: 0.5036920491434531\n",
      "Epoch 47, Loss: 0.5013789295564673\n",
      "Epoch 48, Loss: 0.49849457907240136\n",
      "Epoch 49, Loss: 0.4957371879639946\n",
      "Epoch 50, Loss: 0.4939492047127489\n",
      "Epoch 51, Loss: 0.492960504502198\n",
      "Epoch 52, Loss: 0.49147677196030154\n",
      "Epoch 53, Loss: 0.4891214999359568\n",
      "Epoch 54, Loss: 0.486977813501229\n",
      "Epoch 55, Loss: 0.4857628689463538\n",
      "Epoch 56, Loss: 0.48481536659218444\n",
      "Epoch 57, Loss: 0.48327396215894053\n",
      "Epoch 58, Loss: 0.48122383888774783\n",
      "Epoch 59, Loss: 0.47946109398989434\n",
      "Epoch 60, Loss: 0.47838274609424775\n",
      "Epoch 61, Loss: 0.47722156478014743\n",
      "Epoch 62, Loss: 0.47549213526165324\n",
      "Epoch 63, Loss: 0.4739169811891456\n",
      "Epoch 64, Loss: 0.47288194107358295\n",
      "Epoch 65, Loss: 0.471782602017536\n",
      "Epoch 66, Loss: 0.470323464908973\n",
      "Epoch 67, Loss: 0.4690473408190483\n",
      "Epoch 68, Loss: 0.46820110927219805\n",
      "Epoch 69, Loss: 0.46716354844564084\n",
      "Epoch 70, Loss: 0.4658250628535054\n",
      "Epoch 71, Loss: 0.46476171074118444\n",
      "Epoch 72, Loss: 0.46385319738874314\n",
      "Epoch 73, Loss: 0.4627049713608048\n",
      "Epoch 74, Loss: 0.46155432469818575\n",
      "Epoch 75, Loss: 0.46067471206195637\n",
      "Epoch 76, Loss: 0.4597323876409824\n",
      "Epoch 77, Loss: 0.45862938971509787\n",
      "Epoch 78, Loss: 0.4577189105719793\n",
      "Epoch 79, Loss: 0.45682361157225665\n",
      "Epoch 80, Loss: 0.45578741700424036\n",
      "Epoch 81, Loss: 0.45488890614733696\n",
      "Epoch 82, Loss: 0.4540893060814465\n",
      "Epoch 83, Loss: 0.4531941196735224\n",
      "Epoch 84, Loss: 0.4523820870712099\n",
      "Epoch 85, Loss: 0.45163445476915776\n",
      "Epoch 86, Loss: 0.45083913051358926\n",
      "Epoch 87, Loss: 0.45010174753353693\n",
      "Epoch 88, Loss: 0.4493847747503639\n",
      "Epoch 89, Loss: 0.4486503488038702\n",
      "Epoch 90, Loss: 0.4480087736337144\n",
      "Epoch 91, Loss: 0.44734917405891\n",
      "Epoch 92, Loss: 0.44667282132574826\n",
      "Epoch 93, Loss: 0.44595569872862767\n",
      "Epoch 94, Loss: 0.4451807563385583\n",
      "Epoch 95, Loss: 0.4444110681084727\n",
      "Epoch 96, Loss: 0.44374936130638903\n",
      "Epoch 97, Loss: 0.44305121850023865\n",
      "Epoch 98, Loss: 0.4423128624322066\n",
      "Epoch 99, Loss: 0.4414928823882334\n",
      "Epoch 100, Loss: 0.4405330528205611\n",
      "Epoch 101, Loss: 0.43973635553246676\n",
      "Epoch 102, Loss: 0.4390853020662566\n",
      "Epoch 103, Loss: 0.4384234253900711\n",
      "Epoch 104, Loss: 0.43777016404385666\n",
      "Epoch 105, Loss: 0.4371033300777802\n",
      "Epoch 106, Loss: 0.43644626626545796\n",
      "Epoch 107, Loss: 0.4357536919689641\n",
      "Epoch 108, Loss: 0.4350057756106299\n",
      "Epoch 109, Loss: 0.4342649437052123\n",
      "Epoch 110, Loss: 0.43355273147253126\n",
      "Epoch 111, Loss: 0.4328430998138178\n",
      "Epoch 112, Loss: 0.4321524575922392\n",
      "Epoch 113, Loss: 0.43147538763712157\n",
      "Epoch 114, Loss: 0.43079848148831873\n",
      "Epoch 115, Loss: 0.43014058587222614\n",
      "Epoch 116, Loss: 0.42950000139998057\n",
      "Epoch 117, Loss: 0.42886521815410616\n",
      "Epoch 118, Loss: 0.4282269189463668\n",
      "Epoch 119, Loss: 0.427571618455631\n",
      "Epoch 120, Loss: 0.42688993595405994\n",
      "Epoch 121, Loss: 0.4261851363736784\n",
      "Epoch 122, Loss: 0.4254803425431547\n",
      "Epoch 123, Loss: 0.424776887532126\n",
      "Epoch 124, Loss: 0.4240819109674639\n",
      "Epoch 125, Loss: 0.42340388358145564\n",
      "Epoch 126, Loss: 0.42271777144201983\n",
      "Epoch 127, Loss: 0.42203695226303345\n",
      "Epoch 128, Loss: 0.4213566421260034\n",
      "Epoch 129, Loss: 0.4206931549562697\n",
      "Epoch 130, Loss: 0.4199828170201925\n",
      "Epoch 131, Loss: 0.4192321435677663\n",
      "Epoch 132, Loss: 0.4185152313817338\n",
      "Epoch 133, Loss: 0.4178181136160036\n",
      "Epoch 134, Loss: 0.4171746455580314\n",
      "Epoch 135, Loss: 0.41663329070248944\n",
      "Epoch 136, Loss: 0.41621891839311626\n",
      "Epoch 137, Loss: 0.41553727708501925\n",
      "Epoch 138, Loss: 0.4146297635703837\n",
      "Epoch 139, Loss: 0.4140975505460707\n",
      "Epoch 140, Loss: 0.41363993261133286\n",
      "Epoch 141, Loss: 0.4128068021428715\n",
      "Epoch 142, Loss: 0.41210966426604184\n",
      "Epoch 143, Loss: 0.41168380748273664\n",
      "Epoch 144, Loss: 0.41099607681109773\n",
      "Epoch 145, Loss: 0.4101639156533474\n",
      "Epoch 146, Loss: 0.4096466531766515\n",
      "Epoch 147, Loss: 0.4092728683966087\n",
      "Epoch 148, Loss: 0.4085353612664461\n",
      "Epoch 149, Loss: 0.4077034771642552\n",
      "Epoch 150, Loss: 0.4071557694702451\n",
      "Epoch 151, Loss: 0.40679337768340723\n",
      "Epoch 152, Loss: 0.4062846609148029\n",
      "Epoch 153, Loss: 0.40561382292996384\n",
      "Epoch 154, Loss: 0.40487202447337833\n",
      "Epoch 155, Loss: 0.40430400676242084\n",
      "Epoch 156, Loss: 0.40388100654034026\n",
      "Epoch 157, Loss: 0.4035131441466593\n",
      "Epoch 158, Loss: 0.4030753215963359\n",
      "Epoch 159, Loss: 0.40240753927377565\n",
      "Epoch 160, Loss: 0.40154078829362705\n",
      "Epoch 161, Loss: 0.40086515265973527\n",
      "Epoch 162, Loss: 0.4004239324346481\n",
      "Epoch 163, Loss: 0.4001358896636901\n",
      "Epoch 164, Loss: 0.39987284978924653\n",
      "Epoch 165, Loss: 0.3995165332027611\n",
      "Epoch 166, Loss: 0.3988245411860361\n",
      "Epoch 167, Loss: 0.3978654082805286\n",
      "Epoch 168, Loss: 0.3970612524437216\n",
      "Epoch 169, Loss: 0.3966673442924279\n",
      "Epoch 170, Loss: 0.39653484605783046\n",
      "Epoch 171, Loss: 0.3963199706830051\n",
      "Epoch 172, Loss: 0.39578988648278746\n",
      "Epoch 173, Loss: 0.3948169278272007\n",
      "Epoch 174, Loss: 0.3941108238666355\n",
      "Epoch 175, Loss: 0.3937268507676888\n",
      "Epoch 176, Loss: 0.3935094575472495\n",
      "Epoch 177, Loss: 0.393363735928649\n",
      "Epoch 178, Loss: 0.39308725621622903\n",
      "Epoch 179, Loss: 0.39239750213241187\n",
      "Epoch 180, Loss: 0.3915838679932195\n",
      "Epoch 181, Loss: 0.3909696774920321\n",
      "Epoch 182, Loss: 0.3907225868398561\n",
      "Epoch 183, Loss: 0.3907663661741245\n",
      "Epoch 184, Loss: 0.39059141014638\n",
      "Epoch 185, Loss: 0.39008116057956926\n",
      "Epoch 186, Loss: 0.3893894109003278\n",
      "Epoch 187, Loss: 0.38864187383598703\n",
      "Epoch 188, Loss: 0.38817892971475787\n",
      "Epoch 189, Loss: 0.3879875215743314\n",
      "Epoch 190, Loss: 0.3878933379202299\n",
      "Epoch 191, Loss: 0.3879947802952039\n",
      "Epoch 192, Loss: 0.3878369012759231\n",
      "Epoch 193, Loss: 0.387295148908047\n",
      "Epoch 194, Loss: 0.3862641677912286\n",
      "Epoch 195, Loss: 0.3854309178200595\n",
      "Epoch 196, Loss: 0.38517338790061\n",
      "Epoch 197, Loss: 0.3853478649520777\n",
      "Epoch 198, Loss: 0.38530196166961117\n",
      "Epoch 199, Loss: 0.384967344434928\n",
      "Epoch 200, Loss: 0.3840686856882126\n",
      "Epoch 201, Loss: 0.3830403408961385\n",
      "Epoch 202, Loss: 0.3827845699475579\n",
      "Epoch 203, Loss: 0.38309320551264653\n",
      "Epoch 204, Loss: 0.38310289073332426\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2622656706581055\n",
      "Test R^2 score: 0.26115444146566025\n",
      "Num of epochs: 205\n",
      "Epoch 1, Loss: 0.5778600755893628\n",
      "Epoch 2, Loss: 0.5761738405355775\n",
      "Epoch 3, Loss: 0.5745737963358236\n",
      "Epoch 4, Loss: 0.5730615750477063\n",
      "Epoch 5, Loss: 0.5716455635127535\n",
      "Epoch 6, Loss: 0.570520258646614\n",
      "Epoch 7, Loss: 0.5694551948240745\n",
      "Epoch 8, Loss: 0.5684426367948607\n",
      "Epoch 9, Loss: 0.5674743315903648\n",
      "Epoch 10, Loss: 0.5665500589846902\n",
      "Epoch 11, Loss: 0.5656716417081855\n",
      "Epoch 12, Loss: 0.5648344131478915\n",
      "Epoch 13, Loss: 0.5640352807914125\n",
      "Epoch 14, Loss: 0.5632730311456808\n",
      "Epoch 15, Loss: 0.5626080197354967\n",
      "Epoch 16, Loss: 0.5620223772644012\n",
      "Epoch 17, Loss: 0.5614551801245005\n",
      "Epoch 18, Loss: 0.5609047574658828\n",
      "Epoch 19, Loss: 0.560371265084939\n",
      "Epoch 20, Loss: 0.5598540327451731\n",
      "Epoch 21, Loss: 0.5593559826649697\n",
      "Epoch 22, Loss: 0.5588806056025424\n",
      "Epoch 23, Loss: 0.5584239835122679\n",
      "Epoch 24, Loss: 0.5579867766584115\n",
      "Epoch 25, Loss: 0.5575647012089635\n",
      "Epoch 26, Loss: 0.5571477888486385\n",
      "Epoch 27, Loss: 0.5567347932099722\n",
      "Epoch 28, Loss: 0.5563216249021657\n",
      "Epoch 29, Loss: 0.5559086856161444\n",
      "Epoch 30, Loss: 0.5554968879107798\n",
      "Epoch 31, Loss: 0.5550736171423933\n",
      "Epoch 32, Loss: 0.5546106097160208\n",
      "Epoch 33, Loss: 0.5540845038040718\n",
      "Epoch 34, Loss: 0.5534740661224491\n",
      "Epoch 35, Loss: 0.5527493370376538\n",
      "Epoch 36, Loss: 0.5518631016019958\n",
      "Epoch 37, Loss: 0.550771970197271\n",
      "Epoch 38, Loss: 0.5494581251650491\n",
      "Epoch 39, Loss: 0.5478432938602841\n",
      "Epoch 40, Loss: 0.5458270249718085\n",
      "Epoch 41, Loss: 0.5432915311317247\n",
      "Epoch 42, Loss: 0.5401829670949031\n",
      "Epoch 43, Loss: 0.536450206978984\n",
      "Epoch 44, Loss: 0.5321276091533386\n",
      "Epoch 45, Loss: 0.5274026060815362\n",
      "Epoch 46, Loss: 0.5228591114706193\n",
      "Epoch 47, Loss: 0.5195089349758528\n",
      "Epoch 48, Loss: 0.518343981447454\n",
      "Epoch 49, Loss: 0.5177169037946768\n",
      "Epoch 50, Loss: 0.5147563379665474\n",
      "Epoch 51, Loss: 0.5101702607875781\n",
      "Epoch 52, Loss: 0.5061459116423078\n",
      "Epoch 53, Loss: 0.5037601761937814\n",
      "Epoch 54, Loss: 0.5025482805505982\n",
      "Epoch 55, Loss: 0.5013798508867136\n",
      "Epoch 56, Loss: 0.49968991499097154\n",
      "Epoch 57, Loss: 0.49748630766021573\n",
      "Epoch 58, Loss: 0.49519302419392697\n",
      "Epoch 59, Loss: 0.49328560417315\n",
      "Epoch 60, Loss: 0.4919350294444418\n",
      "Epoch 61, Loss: 0.4907872095872629\n",
      "Epoch 62, Loss: 0.4891975959680553\n",
      "Epoch 63, Loss: 0.48716651318304405\n",
      "Epoch 64, Loss: 0.48522018711596865\n",
      "Epoch 65, Loss: 0.4837519268372084\n",
      "Epoch 66, Loss: 0.4825490868755536\n",
      "Epoch 67, Loss: 0.48122003016105575\n",
      "Epoch 68, Loss: 0.47964993929354094\n",
      "Epoch 69, Loss: 0.47803764604916815\n",
      "Epoch 70, Loss: 0.47669297917919357\n",
      "Epoch 71, Loss: 0.47562380097547624\n",
      "Epoch 72, Loss: 0.4744479371843611\n",
      "Epoch 73, Loss: 0.47302134261460543\n",
      "Epoch 74, Loss: 0.4716024710751441\n",
      "Epoch 75, Loss: 0.4703911344876751\n",
      "Epoch 76, Loss: 0.4693037259354491\n",
      "Epoch 77, Loss: 0.4681748835745776\n",
      "Epoch 78, Loss: 0.4670284766085823\n",
      "Epoch 79, Loss: 0.46601155192153215\n",
      "Epoch 80, Loss: 0.4651638019116595\n",
      "Epoch 81, Loss: 0.4643714813776829\n",
      "Epoch 82, Loss: 0.46349658818311196\n",
      "Epoch 83, Loss: 0.46264587241260646\n",
      "Epoch 84, Loss: 0.4619024005087122\n",
      "Epoch 85, Loss: 0.4611341574171425\n",
      "Epoch 86, Loss: 0.46025553864291363\n",
      "Epoch 87, Loss: 0.45943788889449577\n",
      "Epoch 88, Loss: 0.4585979701925143\n",
      "Epoch 89, Loss: 0.4577278306281297\n",
      "Epoch 90, Loss: 0.4567792311722498\n",
      "Epoch 91, Loss: 0.45585462932192145\n",
      "Epoch 92, Loss: 0.4548912319454072\n",
      "Epoch 93, Loss: 0.4539821672886447\n",
      "Epoch 94, Loss: 0.4531277294734435\n",
      "Epoch 95, Loss: 0.4524130489784177\n",
      "Epoch 96, Loss: 0.45172755382908897\n",
      "Epoch 97, Loss: 0.45098070330265577\n",
      "Epoch 98, Loss: 0.4502589910987304\n",
      "Epoch 99, Loss: 0.44939440734402664\n",
      "Epoch 100, Loss: 0.4485757787354039\n",
      "Epoch 101, Loss: 0.4478467805443262\n",
      "Epoch 102, Loss: 0.44707134974981383\n",
      "Epoch 103, Loss: 0.446327708634914\n",
      "Epoch 104, Loss: 0.4455856355612752\n",
      "Epoch 105, Loss: 0.4447962462154488\n",
      "Epoch 106, Loss: 0.4441522742683753\n",
      "Epoch 107, Loss: 0.4435636747080489\n",
      "Epoch 108, Loss: 0.4430186941527381\n",
      "Epoch 109, Loss: 0.4424139858150734\n",
      "Epoch 110, Loss: 0.4417509235530022\n",
      "Epoch 111, Loss: 0.44106330039487013\n",
      "Epoch 112, Loss: 0.44037646460526453\n",
      "Epoch 113, Loss: 0.4397326618797332\n",
      "Epoch 114, Loss: 0.4390564378476019\n",
      "Epoch 115, Loss: 0.4383417784701659\n",
      "Epoch 116, Loss: 0.4376130298654335\n",
      "Epoch 117, Loss: 0.4368854702634889\n",
      "Epoch 118, Loss: 0.43615879813380104\n",
      "Epoch 119, Loss: 0.43547764043968334\n",
      "Epoch 120, Loss: 0.43480480596773613\n",
      "Epoch 121, Loss: 0.4341400245056887\n",
      "Epoch 122, Loss: 0.4334785377090992\n",
      "Epoch 123, Loss: 0.43285446032450975\n",
      "Epoch 124, Loss: 0.43220496936061314\n",
      "Epoch 125, Loss: 0.4315156367309847\n",
      "Epoch 126, Loss: 0.43083051029746294\n",
      "Epoch 127, Loss: 0.4301791932471898\n",
      "Epoch 128, Loss: 0.42946213100539743\n",
      "Epoch 129, Loss: 0.42875558190563057\n",
      "Epoch 130, Loss: 0.42812336691663255\n",
      "Epoch 131, Loss: 0.4274578158440572\n",
      "Epoch 132, Loss: 0.42676717019023974\n",
      "Epoch 133, Loss: 0.4261192764844529\n",
      "Epoch 134, Loss: 0.425480097389271\n",
      "Epoch 135, Loss: 0.4248677174077872\n",
      "Epoch 136, Loss: 0.4242771600235473\n",
      "Epoch 137, Loss: 0.4237441406013688\n",
      "Epoch 138, Loss: 0.4232314343884224\n",
      "Epoch 139, Loss: 0.4225404400911927\n",
      "Epoch 140, Loss: 0.42182252698865325\n",
      "Epoch 141, Loss: 0.42125978469804376\n",
      "Epoch 142, Loss: 0.4207078010773835\n",
      "Epoch 143, Loss: 0.4200773439263519\n",
      "Epoch 144, Loss: 0.41937813264498286\n",
      "Epoch 145, Loss: 0.41877734322736365\n",
      "Epoch 146, Loss: 0.4183297247401727\n",
      "Epoch 147, Loss: 0.4178985822015953\n",
      "Epoch 148, Loss: 0.4173132310489263\n",
      "Epoch 149, Loss: 0.4166826980208846\n",
      "Epoch 150, Loss: 0.4161673971930282\n",
      "Epoch 151, Loss: 0.41577368851602153\n",
      "Epoch 152, Loss: 0.41534624288440986\n",
      "Epoch 153, Loss: 0.414798640009408\n",
      "Epoch 154, Loss: 0.41415925964675776\n",
      "Epoch 155, Loss: 0.4136226945411065\n",
      "Epoch 156, Loss: 0.4131990102129231\n",
      "Epoch 157, Loss: 0.41281853355948045\n",
      "Epoch 158, Loss: 0.4123888559595085\n",
      "Epoch 159, Loss: 0.4118561350795848\n",
      "Epoch 160, Loss: 0.4112692853353776\n",
      "Epoch 161, Loss: 0.4107575686228205\n",
      "Epoch 162, Loss: 0.4103169807485769\n",
      "Epoch 163, Loss: 0.40996761525582476\n",
      "Epoch 164, Loss: 0.40972907209687026\n",
      "Epoch 165, Loss: 0.4094732319568287\n",
      "Epoch 166, Loss: 0.4090356322834898\n",
      "Epoch 167, Loss: 0.4081872453293059\n",
      "Epoch 168, Loss: 0.40763673319653665\n",
      "Epoch 169, Loss: 0.4075604540500495\n",
      "Epoch 170, Loss: 0.40723538103320767\n",
      "Epoch 171, Loss: 0.4065595877716826\n",
      "Epoch 172, Loss: 0.4060348160924087\n",
      "Epoch 173, Loss: 0.4058877540337351\n",
      "Epoch 174, Loss: 0.4056041057947867\n",
      "Epoch 175, Loss: 0.40498858632970747\n",
      "Epoch 176, Loss: 0.4044203454525076\n",
      "Epoch 177, Loss: 0.4041623615088037\n",
      "Epoch 178, Loss: 0.40391767843521253\n",
      "Epoch 179, Loss: 0.40348777342522074\n",
      "Epoch 180, Loss: 0.4029119793712294\n",
      "Epoch 181, Loss: 0.4024787787357853\n",
      "Epoch 182, Loss: 0.4022191789980591\n",
      "Epoch 183, Loss: 0.4020030050960118\n",
      "Epoch 184, Loss: 0.40175131355336774\n",
      "Epoch 185, Loss: 0.40134086429752863\n",
      "Epoch 186, Loss: 0.4008752634531124\n",
      "Epoch 187, Loss: 0.4004105911859121\n",
      "Epoch 188, Loss: 0.40008626395112745\n",
      "Epoch 189, Loss: 0.3998650613809542\n",
      "Epoch 190, Loss: 0.3996910869327082\n",
      "Epoch 191, Loss: 0.399526193263785\n",
      "Epoch 192, Loss: 0.39931093110967336\n",
      "Epoch 193, Loss: 0.3989051430638663\n",
      "Epoch 194, Loss: 0.3983018494610727\n",
      "Epoch 195, Loss: 0.3978699587659287\n",
      "Epoch 196, Loss: 0.39762657519462924\n",
      "Epoch 197, Loss: 0.39745568874183274\n",
      "Epoch 198, Loss: 0.3971774803356463\n",
      "Epoch 199, Loss: 0.39693012455458127\n",
      "Epoch 200, Loss: 0.3966142225691753\n",
      "Epoch 201, Loss: 0.39621238587129864\n",
      "Epoch 202, Loss: 0.3958354770033496\n",
      "Epoch 203, Loss: 0.3956163987283865\n",
      "Epoch 204, Loss: 0.39534109864051825\n",
      "Epoch 205, Loss: 0.3950661536242265\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.23587433963393506\n",
      "Test R^2 score: 0.3960913581088144\n",
      "Num of epochs: 206\n",
      "Epoch 1, Loss: 0.5792890377119012\n",
      "Epoch 2, Loss: 0.5780519748653019\n",
      "Epoch 3, Loss: 0.5768601783675139\n",
      "Epoch 4, Loss: 0.5757151717179495\n",
      "Epoch 5, Loss: 0.5746067319351496\n",
      "Epoch 6, Loss: 0.5735250161974894\n",
      "Epoch 7, Loss: 0.5724871470328723\n",
      "Epoch 8, Loss: 0.5714883570815906\n",
      "Epoch 9, Loss: 0.5705088186075598\n",
      "Epoch 10, Loss: 0.569614165749898\n",
      "Epoch 11, Loss: 0.5687546551692055\n",
      "Epoch 12, Loss: 0.567866895271453\n",
      "Epoch 13, Loss: 0.5670034220203697\n",
      "Epoch 14, Loss: 0.5661516603967187\n",
      "Epoch 15, Loss: 0.5653113733874008\n",
      "Epoch 16, Loss: 0.5644901883849691\n",
      "Epoch 17, Loss: 0.563681315701866\n",
      "Epoch 18, Loss: 0.5629394986538683\n",
      "Epoch 19, Loss: 0.5622237904886547\n",
      "Epoch 20, Loss: 0.5614881952255858\n",
      "Epoch 21, Loss: 0.5608058158572261\n",
      "Epoch 22, Loss: 0.5602390361140352\n",
      "Epoch 23, Loss: 0.5595795795412289\n",
      "Epoch 24, Loss: 0.5589055611571775\n",
      "Epoch 25, Loss: 0.5581572367637698\n",
      "Epoch 26, Loss: 0.557308051204176\n",
      "Epoch 27, Loss: 0.556372541152639\n",
      "Epoch 28, Loss: 0.5554931592339815\n",
      "Epoch 29, Loss: 0.554433603339488\n",
      "Epoch 30, Loss: 0.5531705880640531\n",
      "Epoch 31, Loss: 0.5516570952997899\n",
      "Epoch 32, Loss: 0.5498420336762395\n",
      "Epoch 33, Loss: 0.5476623317146821\n",
      "Epoch 34, Loss: 0.5450535276794495\n",
      "Epoch 35, Loss: 0.5419586171244072\n",
      "Epoch 36, Loss: 0.5383262582241174\n",
      "Epoch 37, Loss: 0.5341559200822578\n",
      "Epoch 38, Loss: 0.5295674663460747\n",
      "Epoch 39, Loss: 0.5249094124251514\n",
      "Epoch 40, Loss: 0.5209393456969262\n",
      "Epoch 41, Loss: 0.5187666005615187\n",
      "Epoch 42, Loss: 0.5185287095511532\n",
      "Epoch 43, Loss: 0.5174324262425325\n",
      "Epoch 44, Loss: 0.5140880740682925\n",
      "Epoch 45, Loss: 0.5102353617387446\n",
      "Epoch 46, Loss: 0.5076964319071059\n",
      "Epoch 47, Loss: 0.5065810898717915\n",
      "Epoch 48, Loss: 0.5059767774635788\n",
      "Epoch 49, Loss: 0.5048094941550715\n",
      "Epoch 50, Loss: 0.5026483730449584\n",
      "Epoch 51, Loss: 0.4998546925641091\n",
      "Epoch 52, Loss: 0.49705255023270223\n",
      "Epoch 53, Loss: 0.4951057056547816\n",
      "Epoch 54, Loss: 0.49418926376581873\n",
      "Epoch 55, Loss: 0.493168126457768\n",
      "Epoch 56, Loss: 0.4909840660908825\n",
      "Epoch 57, Loss: 0.4883934197331693\n",
      "Epoch 58, Loss: 0.4866526030632423\n",
      "Epoch 59, Loss: 0.4857701237172138\n",
      "Epoch 60, Loss: 0.4845447704221137\n",
      "Epoch 61, Loss: 0.4825188543164018\n",
      "Epoch 62, Loss: 0.48043804535798235\n",
      "Epoch 63, Loss: 0.4790227732700053\n",
      "Epoch 64, Loss: 0.47809252036482786\n",
      "Epoch 65, Loss: 0.47683942284618475\n",
      "Epoch 66, Loss: 0.47514506120187355\n",
      "Epoch 67, Loss: 0.47370195965529666\n",
      "Epoch 68, Loss: 0.4726624921906701\n",
      "Epoch 69, Loss: 0.47161811126563413\n",
      "Epoch 70, Loss: 0.4702890402940597\n",
      "Epoch 71, Loss: 0.4689965712222691\n",
      "Epoch 72, Loss: 0.46802962899053113\n",
      "Epoch 73, Loss: 0.46722142214403556\n",
      "Epoch 74, Loss: 0.4662860165867465\n",
      "Epoch 75, Loss: 0.4654462099844465\n",
      "Epoch 76, Loss: 0.4647399882704895\n",
      "Epoch 77, Loss: 0.46382031655674216\n",
      "Epoch 78, Loss: 0.46296546427616175\n",
      "Epoch 79, Loss: 0.4623930627038489\n",
      "Epoch 80, Loss: 0.46163638521146466\n",
      "Epoch 81, Loss: 0.4606748252742869\n",
      "Epoch 82, Loss: 0.45987511095282585\n",
      "Epoch 83, Loss: 0.45915756204732183\n",
      "Epoch 84, Loss: 0.4584013137109516\n",
      "Epoch 85, Loss: 0.45777869441495916\n",
      "Epoch 86, Loss: 0.45702578875547334\n",
      "Epoch 87, Loss: 0.45617344227015444\n",
      "Epoch 88, Loss: 0.45545421662216656\n",
      "Epoch 89, Loss: 0.4546394198188943\n",
      "Epoch 90, Loss: 0.4537852344284159\n",
      "Epoch 91, Loss: 0.45298878496805123\n",
      "Epoch 92, Loss: 0.45211394736649374\n",
      "Epoch 93, Loss: 0.45143103484301633\n",
      "Epoch 94, Loss: 0.4506971826292199\n",
      "Epoch 95, Loss: 0.44995325825911764\n",
      "Epoch 96, Loss: 0.4492260476224501\n",
      "Epoch 97, Loss: 0.4484914614280344\n",
      "Epoch 98, Loss: 0.4478144214799204\n",
      "Epoch 99, Loss: 0.44707599934585335\n",
      "Epoch 100, Loss: 0.44640238719172853\n",
      "Epoch 101, Loss: 0.44571212772835583\n",
      "Epoch 102, Loss: 0.4451335413541008\n",
      "Epoch 103, Loss: 0.444507054506798\n",
      "Epoch 104, Loss: 0.4439383268331169\n",
      "Epoch 105, Loss: 0.4433283858035138\n",
      "Epoch 106, Loss: 0.4427900482010075\n",
      "Epoch 107, Loss: 0.44215965115903016\n",
      "Epoch 108, Loss: 0.4415438446024086\n",
      "Epoch 109, Loss: 0.44092719489802146\n",
      "Epoch 110, Loss: 0.4402702533551614\n",
      "Epoch 111, Loss: 0.4396451064483115\n",
      "Epoch 112, Loss: 0.4389962088610198\n",
      "Epoch 113, Loss: 0.4383553760151038\n",
      "Epoch 114, Loss: 0.43770213226084853\n",
      "Epoch 115, Loss: 0.43700031286944224\n",
      "Epoch 116, Loss: 0.43633761280368827\n",
      "Epoch 117, Loss: 0.4357638994430534\n",
      "Epoch 118, Loss: 0.4351855776644501\n",
      "Epoch 119, Loss: 0.4345733471025104\n",
      "Epoch 120, Loss: 0.4339657467913785\n",
      "Epoch 121, Loss: 0.4333355108842179\n",
      "Epoch 122, Loss: 0.43269655692222997\n",
      "Epoch 123, Loss: 0.4320501568263215\n",
      "Epoch 124, Loss: 0.43142639643663133\n",
      "Epoch 125, Loss: 0.4308184219500111\n",
      "Epoch 126, Loss: 0.43019446896371877\n",
      "Epoch 127, Loss: 0.42959801869246295\n",
      "Epoch 128, Loss: 0.4290530462536297\n",
      "Epoch 129, Loss: 0.42871987022878066\n",
      "Epoch 130, Loss: 0.4288468721072224\n",
      "Epoch 131, Loss: 0.4282905585673647\n",
      "Epoch 132, Loss: 0.426962203394358\n",
      "Epoch 133, Loss: 0.4264111190858973\n",
      "Epoch 134, Loss: 0.42644492754281577\n",
      "Epoch 135, Loss: 0.42543256988964\n",
      "Epoch 136, Loss: 0.42474419174017564\n",
      "Epoch 137, Loss: 0.42477964130097834\n",
      "Epoch 138, Loss: 0.42379672729638135\n",
      "Epoch 139, Loss: 0.42307913209015013\n",
      "Epoch 140, Loss: 0.42301722710612905\n",
      "Epoch 141, Loss: 0.4221576520871243\n",
      "Epoch 142, Loss: 0.42137913348994804\n",
      "Epoch 143, Loss: 0.42122798330122324\n",
      "Epoch 144, Loss: 0.42067064462734094\n",
      "Epoch 145, Loss: 0.4198327435668149\n",
      "Epoch 146, Loss: 0.41955548647981405\n",
      "Epoch 147, Loss: 0.4192521720982369\n",
      "Epoch 148, Loss: 0.41850205738947416\n",
      "Epoch 149, Loss: 0.41798602273492275\n",
      "Epoch 150, Loss: 0.41778947425797885\n",
      "Epoch 151, Loss: 0.41731005308020325\n",
      "Epoch 152, Loss: 0.41664806165483503\n",
      "Epoch 153, Loss: 0.4161472201970767\n",
      "Epoch 154, Loss: 0.41585363896864563\n",
      "Epoch 155, Loss: 0.4155355378720288\n",
      "Epoch 156, Loss: 0.41503687240920323\n",
      "Epoch 157, Loss: 0.414467631381876\n",
      "Epoch 158, Loss: 0.41393502990386544\n",
      "Epoch 159, Loss: 0.4134615009287372\n",
      "Epoch 160, Loss: 0.41305116186917107\n",
      "Epoch 161, Loss: 0.4127573640953168\n",
      "Epoch 162, Loss: 0.41271967240530366\n",
      "Epoch 163, Loss: 0.4129887820583797\n",
      "Epoch 164, Loss: 0.4132634315904142\n",
      "Epoch 165, Loss: 0.4118849337513012\n",
      "Epoch 166, Loss: 0.41050903044256865\n",
      "Epoch 167, Loss: 0.4105928730989048\n",
      "Epoch 168, Loss: 0.4108210307955867\n",
      "Epoch 169, Loss: 0.40973349082486826\n",
      "Epoch 170, Loss: 0.4089146304119049\n",
      "Epoch 171, Loss: 0.40909014612064115\n",
      "Epoch 172, Loss: 0.4088081001846289\n",
      "Epoch 173, Loss: 0.4077613849687678\n",
      "Epoch 174, Loss: 0.40738828452924514\n",
      "Epoch 175, Loss: 0.40751021498181095\n",
      "Epoch 176, Loss: 0.4070282414301355\n",
      "Epoch 177, Loss: 0.4062375837042552\n",
      "Epoch 178, Loss: 0.4055681926229602\n",
      "Epoch 179, Loss: 0.4053892958158506\n",
      "Epoch 180, Loss: 0.4053274831009813\n",
      "Epoch 181, Loss: 0.4049747883343351\n",
      "Epoch 182, Loss: 0.40437528061893874\n",
      "Epoch 183, Loss: 0.40364715411882784\n",
      "Epoch 184, Loss: 0.40313341368537275\n",
      "Epoch 185, Loss: 0.402872959716488\n",
      "Epoch 186, Loss: 0.40268772199128167\n",
      "Epoch 187, Loss: 0.40267909990637885\n",
      "Epoch 188, Loss: 0.4026729940264401\n",
      "Epoch 189, Loss: 0.4026874074549482\n",
      "Epoch 190, Loss: 0.40187041207359925\n",
      "Epoch 191, Loss: 0.40076072149516573\n",
      "Epoch 192, Loss: 0.3999733029337465\n",
      "Epoch 193, Loss: 0.39985861440191733\n",
      "Epoch 194, Loss: 0.3999687391224945\n",
      "Epoch 195, Loss: 0.3998035127131464\n",
      "Epoch 196, Loss: 0.39926553216936933\n",
      "Epoch 197, Loss: 0.3984130777092173\n",
      "Epoch 198, Loss: 0.397705227996442\n",
      "Epoch 199, Loss: 0.3973408735608426\n",
      "Epoch 200, Loss: 0.39728832948933746\n",
      "Epoch 201, Loss: 0.3976098421368164\n",
      "Epoch 202, Loss: 0.39819300386657375\n",
      "Epoch 203, Loss: 0.3987419610722897\n",
      "Epoch 204, Loss: 0.3973209406358347\n",
      "Epoch 205, Loss: 0.39554503465857616\n",
      "Epoch 206, Loss: 0.395141262163895\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2345499208116914\n",
      "Test R^2 score: 0.4068294317118875\n",
      "Num of epochs: 207\n",
      "Epoch 1, Loss: 0.5704226975253363\n",
      "Epoch 2, Loss: 0.5690942581758497\n",
      "Epoch 3, Loss: 0.5677749408062959\n",
      "Epoch 4, Loss: 0.5665044765144033\n",
      "Epoch 5, Loss: 0.5653038082435179\n",
      "Epoch 6, Loss: 0.5641617864578938\n",
      "Epoch 7, Loss: 0.5630835314436948\n",
      "Epoch 8, Loss: 0.5620718757257178\n",
      "Epoch 9, Loss: 0.5611299678678604\n",
      "Epoch 10, Loss: 0.5602616970351066\n",
      "Epoch 11, Loss: 0.5594695368323753\n",
      "Epoch 12, Loss: 0.5587559711214051\n",
      "Epoch 13, Loss: 0.5580929198235138\n",
      "Epoch 14, Loss: 0.5575072652830899\n",
      "Epoch 15, Loss: 0.557011183153887\n",
      "Epoch 16, Loss: 0.5566422311860051\n",
      "Epoch 17, Loss: 0.5563550249883643\n",
      "Epoch 18, Loss: 0.5561767519182309\n",
      "Epoch 19, Loss: 0.5560757899994897\n",
      "Epoch 20, Loss: 0.5559870312622485\n",
      "Epoch 21, Loss: 0.555944656832057\n",
      "Epoch 22, Loss: 0.5559318178946856\n",
      "Epoch 23, Loss: 0.5559265642982909\n",
      "Epoch 24, Loss: 0.5559186302014667\n",
      "Epoch 25, Loss: 0.5559004027933884\n",
      "Epoch 26, Loss: 0.5558485050170675\n",
      "Epoch 27, Loss: 0.5557485291654177\n",
      "Epoch 28, Loss: 0.5555949779934419\n",
      "Epoch 29, Loss: 0.5553842118070454\n",
      "Epoch 30, Loss: 0.5551192792525961\n",
      "Epoch 31, Loss: 0.5548009890657533\n",
      "Epoch 32, Loss: 0.5544319907551019\n",
      "Epoch 33, Loss: 0.5540219464551298\n",
      "Epoch 34, Loss: 0.5536107640420316\n",
      "Epoch 35, Loss: 0.5532178886996\n",
      "Epoch 36, Loss: 0.5527633012407414\n",
      "Epoch 37, Loss: 0.5522223213671377\n",
      "Epoch 38, Loss: 0.5515835917387178\n",
      "Epoch 39, Loss: 0.5508092237362329\n",
      "Epoch 40, Loss: 0.549894173151068\n",
      "Epoch 41, Loss: 0.5487928005810474\n",
      "Epoch 42, Loss: 0.5474440202878907\n",
      "Epoch 43, Loss: 0.5458081056380168\n",
      "Epoch 44, Loss: 0.5437815777609001\n",
      "Epoch 45, Loss: 0.5412452843793228\n",
      "Epoch 46, Loss: 0.5381338440880528\n",
      "Epoch 47, Loss: 0.5343623433092144\n",
      "Epoch 48, Loss: 0.529985521811539\n",
      "Epoch 49, Loss: 0.5252217017679981\n",
      "Epoch 50, Loss: 0.5203000740194186\n",
      "Epoch 51, Loss: 0.5156799344941192\n",
      "Epoch 52, Loss: 0.5118739351440831\n",
      "Epoch 53, Loss: 0.5093434950089912\n",
      "Epoch 54, Loss: 0.5074645390829454\n",
      "Epoch 55, Loss: 0.5044353280274139\n",
      "Epoch 56, Loss: 0.4997879711246123\n",
      "Epoch 57, Loss: 0.4943194763023145\n",
      "Epoch 58, Loss: 0.4891023369795102\n",
      "Epoch 59, Loss: 0.4847419179672507\n",
      "Epoch 60, Loss: 0.48100543867771833\n",
      "Epoch 61, Loss: 0.4777818776279439\n",
      "Epoch 62, Loss: 0.47537615337929046\n",
      "Epoch 63, Loss: 0.4743016662255122\n",
      "Epoch 64, Loss: 0.4741166465228556\n",
      "Epoch 65, Loss: 0.47297342550778926\n",
      "Epoch 66, Loss: 0.4706224079491309\n",
      "Epoch 67, Loss: 0.46931358471495\n",
      "Epoch 68, Loss: 0.468550035422583\n",
      "Epoch 69, Loss: 0.4671676950498964\n",
      "Epoch 70, Loss: 0.4655359227786584\n",
      "Epoch 71, Loss: 0.464492633188342\n",
      "Epoch 72, Loss: 0.4641040077013417\n",
      "Epoch 73, Loss: 0.46370127069736405\n",
      "Epoch 74, Loss: 0.4630629625095442\n",
      "Epoch 75, Loss: 0.4621131419578889\n",
      "Epoch 76, Loss: 0.4609418965792703\n",
      "Epoch 77, Loss: 0.45985617122795935\n",
      "Epoch 78, Loss: 0.4591493026175609\n",
      "Epoch 79, Loss: 0.45847735706919296\n",
      "Epoch 80, Loss: 0.4575554539471837\n",
      "Epoch 81, Loss: 0.45660504413797803\n",
      "Epoch 82, Loss: 0.455892448238868\n",
      "Epoch 83, Loss: 0.45534214661585365\n",
      "Epoch 84, Loss: 0.4547217615072539\n",
      "Epoch 85, Loss: 0.4541765212672669\n",
      "Epoch 86, Loss: 0.4537599652880089\n",
      "Epoch 87, Loss: 0.4530890713621235\n",
      "Epoch 88, Loss: 0.45246271535686655\n",
      "Epoch 89, Loss: 0.45196328378402567\n",
      "Epoch 90, Loss: 0.4513091501899571\n",
      "Epoch 91, Loss: 0.45064958669329686\n",
      "Epoch 92, Loss: 0.4501434759719544\n",
      "Epoch 93, Loss: 0.4495802710001358\n",
      "Epoch 94, Loss: 0.4490542566741399\n",
      "Epoch 95, Loss: 0.4485838508377383\n",
      "Epoch 96, Loss: 0.44800059138518705\n",
      "Epoch 97, Loss: 0.44741392384000594\n",
      "Epoch 98, Loss: 0.4469069329436547\n",
      "Epoch 99, Loss: 0.446386397617636\n",
      "Epoch 100, Loss: 0.445848710992209\n",
      "Epoch 101, Loss: 0.44535235176454807\n",
      "Epoch 102, Loss: 0.4448354072713023\n",
      "Epoch 103, Loss: 0.44430154520595055\n",
      "Epoch 104, Loss: 0.44377865900256114\n",
      "Epoch 105, Loss: 0.44320842509107233\n",
      "Epoch 106, Loss: 0.44262351925291704\n",
      "Epoch 107, Loss: 0.4420623966272471\n",
      "Epoch 108, Loss: 0.4414961056694142\n",
      "Epoch 109, Loss: 0.4409541456350558\n",
      "Epoch 110, Loss: 0.44039064221587665\n",
      "Epoch 111, Loss: 0.43984029033377586\n",
      "Epoch 112, Loss: 0.43926667390656815\n",
      "Epoch 113, Loss: 0.43871083617325973\n",
      "Epoch 114, Loss: 0.4381231060068765\n",
      "Epoch 115, Loss: 0.43757029377393547\n",
      "Epoch 116, Loss: 0.43701497508279635\n",
      "Epoch 117, Loss: 0.43642089800045664\n",
      "Epoch 118, Loss: 0.4358973440181699\n",
      "Epoch 119, Loss: 0.4353292118049496\n",
      "Epoch 120, Loss: 0.4347333280866572\n",
      "Epoch 121, Loss: 0.4341483135273666\n",
      "Epoch 122, Loss: 0.43356754464355596\n",
      "Epoch 123, Loss: 0.43295908349602735\n",
      "Epoch 124, Loss: 0.43235679695011753\n",
      "Epoch 125, Loss: 0.4317925820051827\n",
      "Epoch 126, Loss: 0.43124418047419893\n",
      "Epoch 127, Loss: 0.43071348637642487\n",
      "Epoch 128, Loss: 0.4302128614536807\n",
      "Epoch 129, Loss: 0.42969115862589247\n",
      "Epoch 130, Loss: 0.42910015538314394\n",
      "Epoch 131, Loss: 0.42848533307705544\n",
      "Epoch 132, Loss: 0.42791766763970596\n",
      "Epoch 133, Loss: 0.42738345308694264\n",
      "Epoch 134, Loss: 0.4268397202441529\n",
      "Epoch 135, Loss: 0.42628047269257135\n",
      "Epoch 136, Loss: 0.42561928704638685\n",
      "Epoch 137, Loss: 0.4249639804386456\n",
      "Epoch 138, Loss: 0.42435189154720143\n",
      "Epoch 139, Loss: 0.4237483604365675\n",
      "Epoch 140, Loss: 0.42319393613465045\n",
      "Epoch 141, Loss: 0.4226239408882001\n",
      "Epoch 142, Loss: 0.4220697342049142\n",
      "Epoch 143, Loss: 0.4215112283405744\n",
      "Epoch 144, Loss: 0.4209092176433161\n",
      "Epoch 145, Loss: 0.4202381096564208\n",
      "Epoch 146, Loss: 0.41960712435808944\n",
      "Epoch 147, Loss: 0.41902494229526327\n",
      "Epoch 148, Loss: 0.41849680547964824\n",
      "Epoch 149, Loss: 0.4179975018460854\n",
      "Epoch 150, Loss: 0.41751894411062795\n",
      "Epoch 151, Loss: 0.41700603453182833\n",
      "Epoch 152, Loss: 0.41642023388712174\n",
      "Epoch 153, Loss: 0.41582475680461856\n",
      "Epoch 154, Loss: 0.41525225381050085\n",
      "Epoch 155, Loss: 0.4146725461170957\n",
      "Epoch 156, Loss: 0.4141028942341869\n",
      "Epoch 157, Loss: 0.41354778975494655\n",
      "Epoch 158, Loss: 0.41303510781531594\n",
      "Epoch 159, Loss: 0.4127203222911905\n",
      "Epoch 160, Loss: 0.4131143258082114\n",
      "Epoch 161, Loss: 0.4127006447371301\n",
      "Epoch 162, Loss: 0.411874785705418\n",
      "Epoch 163, Loss: 0.4105617698341226\n",
      "Epoch 164, Loss: 0.411120869877623\n",
      "Epoch 165, Loss: 0.4110569827356362\n",
      "Epoch 166, Loss: 0.4093081834734114\n",
      "Epoch 167, Loss: 0.4104089412672132\n",
      "Epoch 168, Loss: 0.4093798964695355\n",
      "Epoch 169, Loss: 0.40847260190793405\n",
      "Epoch 170, Loss: 0.4092354201642522\n",
      "Epoch 171, Loss: 0.40735587575736\n",
      "Epoch 172, Loss: 0.40791471230828097\n",
      "Epoch 173, Loss: 0.40695389874788085\n",
      "Epoch 174, Loss: 0.4065552261780881\n",
      "Epoch 175, Loss: 0.4066715437597951\n",
      "Epoch 176, Loss: 0.40555029914481844\n",
      "Epoch 177, Loss: 0.40603622900993463\n",
      "Epoch 178, Loss: 0.4051663728413732\n",
      "Epoch 179, Loss: 0.4047899050370759\n",
      "Epoch 180, Loss: 0.4048700002141929\n",
      "Epoch 181, Loss: 0.40392511202010317\n",
      "Epoch 182, Loss: 0.4039389643157855\n",
      "Epoch 183, Loss: 0.4036033690070946\n",
      "Epoch 184, Loss: 0.4029477594772703\n",
      "Epoch 185, Loss: 0.4030238948865791\n",
      "Epoch 186, Loss: 0.40251122849955634\n",
      "Epoch 187, Loss: 0.4020141251286332\n",
      "Epoch 188, Loss: 0.4020033757687215\n",
      "Epoch 189, Loss: 0.4015101528558604\n",
      "Epoch 190, Loss: 0.4010341775698576\n",
      "Epoch 191, Loss: 0.4009542452495997\n",
      "Epoch 192, Loss: 0.4007407169778\n",
      "Epoch 193, Loss: 0.4002616674651452\n",
      "Epoch 194, Loss: 0.3997957229541006\n",
      "Epoch 195, Loss: 0.39954446841599656\n",
      "Epoch 196, Loss: 0.3993980945482489\n",
      "Epoch 197, Loss: 0.3991501362881242\n",
      "Epoch 198, Loss: 0.39890758981864466\n",
      "Epoch 199, Loss: 0.39855476598487416\n",
      "Epoch 200, Loss: 0.39825096625829265\n",
      "Epoch 201, Loss: 0.39784739309082223\n",
      "Epoch 202, Loss: 0.39744485358609766\n",
      "Epoch 203, Loss: 0.39709375089941235\n",
      "Epoch 204, Loss: 0.3968772820534765\n",
      "Epoch 205, Loss: 0.3968507361316426\n",
      "Epoch 206, Loss: 0.3970666190002356\n",
      "Epoch 207, Loss: 0.397500432182173\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22838435836749268\n",
      "Test R^2 score: 0.43336570239206884\n",
      "Num of epochs: 208\n",
      "Epoch 1, Loss: 0.5643983702187964\n",
      "Epoch 2, Loss: 0.5630375360016352\n",
      "Epoch 3, Loss: 0.5618369114815699\n",
      "Epoch 4, Loss: 0.5607898464697216\n",
      "Epoch 5, Loss: 0.5599019930005393\n",
      "Epoch 6, Loss: 0.5591449285717084\n",
      "Epoch 7, Loss: 0.5585103272786961\n",
      "Epoch 8, Loss: 0.5579709936485164\n",
      "Epoch 9, Loss: 0.5575266696127487\n",
      "Epoch 10, Loss: 0.557159128798604\n",
      "Epoch 11, Loss: 0.5568551704138612\n",
      "Epoch 12, Loss: 0.5566234117489987\n",
      "Epoch 13, Loss: 0.5564499110054948\n",
      "Epoch 14, Loss: 0.5563216516873205\n",
      "Epoch 15, Loss: 0.5562351289111432\n",
      "Epoch 16, Loss: 0.5561854860848238\n",
      "Epoch 17, Loss: 0.556168955353046\n",
      "Epoch 18, Loss: 0.5561778503945759\n",
      "Epoch 19, Loss: 0.5562051508535716\n",
      "Epoch 20, Loss: 0.556254256157183\n",
      "Epoch 21, Loss: 0.556302446400298\n",
      "Epoch 22, Loss: 0.5563282675810552\n",
      "Epoch 23, Loss: 0.556349346847336\n",
      "Epoch 24, Loss: 0.5563618815342535\n",
      "Epoch 25, Loss: 0.5563604620219235\n",
      "Epoch 26, Loss: 0.5563443918184271\n",
      "Epoch 27, Loss: 0.556314794645601\n",
      "Epoch 28, Loss: 0.556273275595616\n",
      "Epoch 29, Loss: 0.5562209303900121\n",
      "Epoch 30, Loss: 0.556158399004706\n",
      "Epoch 31, Loss: 0.5560869106419853\n",
      "Epoch 32, Loss: 0.5560064618469281\n",
      "Epoch 33, Loss: 0.5559144754772131\n",
      "Epoch 34, Loss: 0.5558063076956492\n",
      "Epoch 35, Loss: 0.5556770685212428\n",
      "Epoch 36, Loss: 0.5555138678274673\n",
      "Epoch 37, Loss: 0.5553008167710112\n",
      "Epoch 38, Loss: 0.5550185276925453\n",
      "Epoch 39, Loss: 0.5546404052943712\n",
      "Epoch 40, Loss: 0.5541534808270439\n",
      "Epoch 41, Loss: 0.5535318128632164\n",
      "Epoch 42, Loss: 0.5527254245424286\n",
      "Epoch 43, Loss: 0.5517485761291356\n",
      "Epoch 44, Loss: 0.5505770040804285\n",
      "Epoch 45, Loss: 0.5491546799688244\n",
      "Epoch 46, Loss: 0.5474199849277519\n",
      "Epoch 47, Loss: 0.5452649803552431\n",
      "Epoch 48, Loss: 0.5424935436304069\n",
      "Epoch 49, Loss: 0.5390311245840448\n",
      "Epoch 50, Loss: 0.5347935637928455\n",
      "Epoch 51, Loss: 0.5298761667579355\n",
      "Epoch 52, Loss: 0.5245852057938895\n",
      "Epoch 53, Loss: 0.5196981520487243\n",
      "Epoch 54, Loss: 0.5167600392241662\n",
      "Epoch 55, Loss: 0.5168936179704524\n",
      "Epoch 56, Loss: 0.5162678958848305\n",
      "Epoch 57, Loss: 0.5127990036512863\n",
      "Epoch 58, Loss: 0.5085988338937115\n",
      "Epoch 59, Loss: 0.5055285222414474\n",
      "Epoch 60, Loss: 0.5035741140222494\n",
      "Epoch 61, Loss: 0.5019563608028151\n",
      "Epoch 62, Loss: 0.5004576436411399\n",
      "Epoch 63, Loss: 0.49873070239735173\n",
      "Epoch 64, Loss: 0.4967787961374314\n",
      "Epoch 65, Loss: 0.4948016182417377\n",
      "Epoch 66, Loss: 0.4929370924371307\n",
      "Epoch 67, Loss: 0.49113280203863335\n",
      "Epoch 68, Loss: 0.4891923872095685\n",
      "Epoch 69, Loss: 0.48737403513795025\n",
      "Epoch 70, Loss: 0.4859530676405694\n",
      "Epoch 71, Loss: 0.4847786359862209\n",
      "Epoch 72, Loss: 0.4834450439180151\n",
      "Epoch 73, Loss: 0.48171692280232575\n",
      "Epoch 74, Loss: 0.4798297975450081\n",
      "Epoch 75, Loss: 0.4779980565763813\n",
      "Epoch 76, Loss: 0.4764275594307566\n",
      "Epoch 77, Loss: 0.47502544987411643\n",
      "Epoch 78, Loss: 0.47357199366884517\n",
      "Epoch 79, Loss: 0.4720812365807177\n",
      "Epoch 80, Loss: 0.4705179570467448\n",
      "Epoch 81, Loss: 0.46889928983552004\n",
      "Epoch 82, Loss: 0.46736786846750666\n",
      "Epoch 83, Loss: 0.4661292565095922\n",
      "Epoch 84, Loss: 0.46503537499809466\n",
      "Epoch 85, Loss: 0.4638615497447284\n",
      "Epoch 86, Loss: 0.462671235964915\n",
      "Epoch 87, Loss: 0.4615140315843695\n",
      "Epoch 88, Loss: 0.46045271385702924\n",
      "Epoch 89, Loss: 0.45951964637713855\n",
      "Epoch 90, Loss: 0.45869844336631244\n",
      "Epoch 91, Loss: 0.4579020298720598\n",
      "Epoch 92, Loss: 0.4570304837994796\n",
      "Epoch 93, Loss: 0.45617808075616806\n",
      "Epoch 94, Loss: 0.4554205985159851\n",
      "Epoch 95, Loss: 0.45464551607293446\n",
      "Epoch 96, Loss: 0.4539571717107207\n",
      "Epoch 97, Loss: 0.4533590172873543\n",
      "Epoch 98, Loss: 0.45283856052991905\n",
      "Epoch 99, Loss: 0.4522899134458594\n",
      "Epoch 100, Loss: 0.45175707627767103\n",
      "Epoch 101, Loss: 0.45125027590502814\n",
      "Epoch 102, Loss: 0.45070115010792117\n",
      "Epoch 103, Loss: 0.45005776378977375\n",
      "Epoch 104, Loss: 0.44936617215203883\n",
      "Epoch 105, Loss: 0.4486769352673544\n",
      "Epoch 106, Loss: 0.4479532744359403\n",
      "Epoch 107, Loss: 0.44721593122651543\n",
      "Epoch 108, Loss: 0.44645462471007136\n",
      "Epoch 109, Loss: 0.4457727529984176\n",
      "Epoch 110, Loss: 0.44520418623351043\n",
      "Epoch 111, Loss: 0.44462646376460285\n",
      "Epoch 112, Loss: 0.4440843142172146\n",
      "Epoch 113, Loss: 0.44353486675689924\n",
      "Epoch 114, Loss: 0.44292302442289755\n",
      "Epoch 115, Loss: 0.44227585331083724\n",
      "Epoch 116, Loss: 0.4416391382845261\n",
      "Epoch 117, Loss: 0.4410454786415523\n",
      "Epoch 118, Loss: 0.4404578358521667\n",
      "Epoch 119, Loss: 0.43981310193897605\n",
      "Epoch 120, Loss: 0.4392259307187494\n",
      "Epoch 121, Loss: 0.43866346831856323\n",
      "Epoch 122, Loss: 0.43807832776763717\n",
      "Epoch 123, Loss: 0.43750115803156586\n",
      "Epoch 124, Loss: 0.43693770309288554\n",
      "Epoch 125, Loss: 0.43638528434088447\n",
      "Epoch 126, Loss: 0.4358576021160111\n",
      "Epoch 127, Loss: 0.4353498689011858\n",
      "Epoch 128, Loss: 0.43482404866412505\n",
      "Epoch 129, Loss: 0.4342623015557157\n",
      "Epoch 130, Loss: 0.43369271463507325\n",
      "Epoch 131, Loss: 0.4331788148241876\n",
      "Epoch 132, Loss: 0.4326573303749204\n",
      "Epoch 133, Loss: 0.4321250958463272\n",
      "Epoch 134, Loss: 0.43157682335665126\n",
      "Epoch 135, Loss: 0.431028441168932\n",
      "Epoch 136, Loss: 0.4305113091174082\n",
      "Epoch 137, Loss: 0.43019065874506546\n",
      "Epoch 138, Loss: 0.4300619227989391\n",
      "Epoch 139, Loss: 0.42943957719118664\n",
      "Epoch 140, Loss: 0.42828380883171624\n",
      "Epoch 141, Loss: 0.4282422643019616\n",
      "Epoch 142, Loss: 0.4274254471481955\n",
      "Epoch 143, Loss: 0.4265654804838246\n",
      "Epoch 144, Loss: 0.4266221727824649\n",
      "Epoch 145, Loss: 0.42566241784665027\n",
      "Epoch 146, Loss: 0.42513220427795745\n",
      "Epoch 147, Loss: 0.42496867905936025\n",
      "Epoch 148, Loss: 0.42384162564903\n",
      "Epoch 149, Loss: 0.42343307577264133\n",
      "Epoch 150, Loss: 0.42298878123802564\n",
      "Epoch 151, Loss: 0.42199802370987183\n",
      "Epoch 152, Loss: 0.42166862031549407\n",
      "Epoch 153, Loss: 0.42128514627149405\n",
      "Epoch 154, Loss: 0.4205366203621153\n",
      "Epoch 155, Loss: 0.42002736030879495\n",
      "Epoch 156, Loss: 0.419826585470602\n",
      "Epoch 157, Loss: 0.4193294515761106\n",
      "Epoch 158, Loss: 0.4186238832011779\n",
      "Epoch 159, Loss: 0.4183335539385352\n",
      "Epoch 160, Loss: 0.418063215472122\n",
      "Epoch 161, Loss: 0.41740607775625854\n",
      "Epoch 162, Loss: 0.4167969936953432\n",
      "Epoch 163, Loss: 0.41645029132107814\n",
      "Epoch 164, Loss: 0.4162057254201769\n",
      "Epoch 165, Loss: 0.41592318443580323\n",
      "Epoch 166, Loss: 0.41529377021778596\n",
      "Epoch 167, Loss: 0.41461168612362015\n",
      "Epoch 168, Loss: 0.414141935250369\n",
      "Epoch 169, Loss: 0.41380154285751714\n",
      "Epoch 170, Loss: 0.413459951204928\n",
      "Epoch 171, Loss: 0.4129690090471625\n",
      "Epoch 172, Loss: 0.41242168217672737\n",
      "Epoch 173, Loss: 0.411806076314653\n",
      "Epoch 174, Loss: 0.41124991880723333\n",
      "Epoch 175, Loss: 0.410816660037176\n",
      "Epoch 176, Loss: 0.41055131686608853\n",
      "Epoch 177, Loss: 0.4109171938502444\n",
      "Epoch 178, Loss: 0.4113820061528962\n",
      "Epoch 179, Loss: 0.41138131793052557\n",
      "Epoch 180, Loss: 0.4085754084071719\n",
      "Epoch 181, Loss: 0.4098462340977351\n",
      "Epoch 182, Loss: 0.40986515796405315\n",
      "Epoch 183, Loss: 0.40724573616245213\n",
      "Epoch 184, Loss: 0.4096276282725849\n",
      "Epoch 185, Loss: 0.4078313603917924\n",
      "Epoch 186, Loss: 0.40667577586107917\n",
      "Epoch 187, Loss: 0.4076578979926758\n",
      "Epoch 188, Loss: 0.4048871324881936\n",
      "Epoch 189, Loss: 0.40600497852993744\n",
      "Epoch 190, Loss: 0.4039107796509091\n",
      "Epoch 191, Loss: 0.4045340538001408\n",
      "Epoch 192, Loss: 0.4040577683610603\n",
      "Epoch 193, Loss: 0.40244129072602836\n",
      "Epoch 194, Loss: 0.4034294738089339\n",
      "Epoch 195, Loss: 0.40129365270605927\n",
      "Epoch 196, Loss: 0.40148424729409965\n",
      "Epoch 197, Loss: 0.4007772300473992\n",
      "Epoch 198, Loss: 0.3995790210878363\n",
      "Epoch 199, Loss: 0.39990215743995583\n",
      "Epoch 200, Loss: 0.3985315473674011\n",
      "Epoch 201, Loss: 0.3984010156121101\n",
      "Epoch 202, Loss: 0.3984551893309201\n",
      "Epoch 203, Loss: 0.3967781857428324\n",
      "Epoch 204, Loss: 0.3973432549440913\n",
      "Epoch 205, Loss: 0.3974593628798278\n",
      "Epoch 206, Loss: 0.39522830835569966\n",
      "Epoch 207, Loss: 0.3964860850330176\n",
      "Epoch 208, Loss: 0.39635670302285897\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22402066778104124\n",
      "Test R^2 score: 0.4543082081546044\n",
      "Num of epochs: 209\n",
      "Epoch 1, Loss: 0.5848062912657367\n",
      "Epoch 2, Loss: 0.5831702691319695\n",
      "Epoch 3, Loss: 0.5815993633199221\n",
      "Epoch 4, Loss: 0.5801372305302683\n",
      "Epoch 5, Loss: 0.5787055734674836\n",
      "Epoch 6, Loss: 0.5773211122444274\n",
      "Epoch 7, Loss: 0.5759767363539285\n",
      "Epoch 8, Loss: 0.5746792354684384\n",
      "Epoch 9, Loss: 0.5734735181343233\n",
      "Epoch 10, Loss: 0.5723047080380735\n",
      "Epoch 11, Loss: 0.5711776233457405\n",
      "Epoch 12, Loss: 0.5700898192979633\n",
      "Epoch 13, Loss: 0.5690562377451053\n",
      "Epoch 14, Loss: 0.5680666035098828\n",
      "Epoch 15, Loss: 0.5671122918827114\n",
      "Epoch 16, Loss: 0.5661940341517259\n",
      "Epoch 17, Loss: 0.5653116896978321\n",
      "Epoch 18, Loss: 0.564464872561374\n",
      "Epoch 19, Loss: 0.563651971604408\n",
      "Epoch 20, Loss: 0.5628717042071254\n",
      "Epoch 21, Loss: 0.5621239676844589\n",
      "Epoch 22, Loss: 0.5614137227224373\n",
      "Epoch 23, Loss: 0.5607357438001902\n",
      "Epoch 24, Loss: 0.5601092767106934\n",
      "Epoch 25, Loss: 0.5595730287176386\n",
      "Epoch 26, Loss: 0.5590701172737805\n",
      "Epoch 27, Loss: 0.5585762768126646\n",
      "Epoch 28, Loss: 0.5581068037255742\n",
      "Epoch 29, Loss: 0.557658953864548\n",
      "Epoch 30, Loss: 0.5572291692705549\n",
      "Epoch 31, Loss: 0.5568124606275614\n",
      "Epoch 32, Loss: 0.5564004748118889\n",
      "Epoch 33, Loss: 0.5559875940887338\n",
      "Epoch 34, Loss: 0.5555648581070367\n",
      "Epoch 35, Loss: 0.5551212656436235\n",
      "Epoch 36, Loss: 0.5546470412422067\n",
      "Epoch 37, Loss: 0.5541262406348847\n",
      "Epoch 38, Loss: 0.5535460265216069\n",
      "Epoch 39, Loss: 0.5528918739467528\n",
      "Epoch 40, Loss: 0.552144844898995\n",
      "Epoch 41, Loss: 0.5512950475715601\n",
      "Epoch 42, Loss: 0.5503196405210706\n",
      "Epoch 43, Loss: 0.5491892213873661\n",
      "Epoch 44, Loss: 0.5478884162678809\n",
      "Epoch 45, Loss: 0.546370573376292\n",
      "Epoch 46, Loss: 0.5445786902889606\n",
      "Epoch 47, Loss: 0.5424397862765632\n",
      "Epoch 48, Loss: 0.5398719073624564\n",
      "Epoch 49, Loss: 0.5368345077485617\n",
      "Epoch 50, Loss: 0.5332893329838237\n",
      "Epoch 51, Loss: 0.5293939649209092\n",
      "Epoch 52, Loss: 0.5256675926124547\n",
      "Epoch 53, Loss: 0.5228498205897627\n",
      "Epoch 54, Loss: 0.5208692029681223\n",
      "Epoch 55, Loss: 0.5181335060608613\n",
      "Epoch 56, Loss: 0.5144372032441817\n",
      "Epoch 57, Loss: 0.5109309473113328\n",
      "Epoch 58, Loss: 0.5085009383265147\n",
      "Epoch 59, Loss: 0.5066961488909036\n",
      "Epoch 60, Loss: 0.504208791827729\n",
      "Epoch 61, Loss: 0.5007290888860917\n",
      "Epoch 62, Loss: 0.49686616553843854\n",
      "Epoch 63, Loss: 0.49341557198542474\n",
      "Epoch 64, Loss: 0.49057599813101893\n",
      "Epoch 65, Loss: 0.4874990071995725\n",
      "Epoch 66, Loss: 0.483862636671333\n",
      "Epoch 67, Loss: 0.48074587141655595\n",
      "Epoch 68, Loss: 0.47914124677099307\n",
      "Epoch 69, Loss: 0.47791858717885327\n",
      "Epoch 70, Loss: 0.47610827201927575\n",
      "Epoch 71, Loss: 0.47454979605006675\n",
      "Epoch 72, Loss: 0.4733193845047983\n",
      "Epoch 73, Loss: 0.47152835479642347\n",
      "Epoch 74, Loss: 0.4691339668608229\n",
      "Epoch 75, Loss: 0.46713230419394447\n",
      "Epoch 76, Loss: 0.4660278753571441\n",
      "Epoch 77, Loss: 0.4655471256599193\n",
      "Epoch 78, Loss: 0.46505796481395933\n",
      "Epoch 79, Loss: 0.46376243613192203\n",
      "Epoch 80, Loss: 0.4622585471834571\n",
      "Epoch 81, Loss: 0.46129324488036344\n",
      "Epoch 82, Loss: 0.4610266195232905\n",
      "Epoch 83, Loss: 0.4607157577948429\n",
      "Epoch 84, Loss: 0.45963701962920034\n",
      "Epoch 85, Loss: 0.45844773107552395\n",
      "Epoch 86, Loss: 0.45779622280100823\n",
      "Epoch 87, Loss: 0.4573070965236922\n",
      "Epoch 88, Loss: 0.45625883838506026\n",
      "Epoch 89, Loss: 0.45513941798203483\n",
      "Epoch 90, Loss: 0.454435393977935\n",
      "Epoch 91, Loss: 0.4539355230822788\n",
      "Epoch 92, Loss: 0.4531263154109409\n",
      "Epoch 93, Loss: 0.4521661676675246\n",
      "Epoch 94, Loss: 0.45140094639087797\n",
      "Epoch 95, Loss: 0.4508256120190961\n",
      "Epoch 96, Loss: 0.45007830772932544\n",
      "Epoch 97, Loss: 0.44918400173966727\n",
      "Epoch 98, Loss: 0.4483608180287243\n",
      "Epoch 99, Loss: 0.44763591380637613\n",
      "Epoch 100, Loss: 0.44678693250361756\n",
      "Epoch 101, Loss: 0.44587723576739396\n",
      "Epoch 102, Loss: 0.44501773380990556\n",
      "Epoch 103, Loss: 0.44424420761814504\n",
      "Epoch 104, Loss: 0.4432877638200085\n",
      "Epoch 105, Loss: 0.4422941645376377\n",
      "Epoch 106, Loss: 0.44140660446287794\n",
      "Epoch 107, Loss: 0.4404350162023039\n",
      "Epoch 108, Loss: 0.43943688256658875\n",
      "Epoch 109, Loss: 0.4385717921507355\n",
      "Epoch 110, Loss: 0.43769583406293877\n",
      "Epoch 111, Loss: 0.43678618850421597\n",
      "Epoch 112, Loss: 0.43594692657560746\n",
      "Epoch 113, Loss: 0.43509705584360014\n",
      "Epoch 114, Loss: 0.4342784801800259\n",
      "Epoch 115, Loss: 0.43365612096936457\n",
      "Epoch 116, Loss: 0.43308549596241525\n",
      "Epoch 117, Loss: 0.4323510067974909\n",
      "Epoch 118, Loss: 0.431020697155374\n",
      "Epoch 119, Loss: 0.4302220227678209\n",
      "Epoch 120, Loss: 0.42983316206709865\n",
      "Epoch 121, Loss: 0.42892841566722095\n",
      "Epoch 122, Loss: 0.4278855252688995\n",
      "Epoch 123, Loss: 0.4272836200037663\n",
      "Epoch 124, Loss: 0.42671267971329263\n",
      "Epoch 125, Loss: 0.42595020056951666\n",
      "Epoch 126, Loss: 0.425089545493522\n",
      "Epoch 127, Loss: 0.42433742387734796\n",
      "Epoch 128, Loss: 0.4237515956150948\n",
      "Epoch 129, Loss: 0.4231000879129847\n",
      "Epoch 130, Loss: 0.4224999531909533\n",
      "Epoch 131, Loss: 0.421851899256313\n",
      "Epoch 132, Loss: 0.42128152075654757\n",
      "Epoch 133, Loss: 0.4206873105334483\n",
      "Epoch 134, Loss: 0.4202942195448094\n",
      "Epoch 135, Loss: 0.4199433077288383\n",
      "Epoch 136, Loss: 0.4197304400180163\n",
      "Epoch 137, Loss: 0.41859157896315424\n",
      "Epoch 138, Loss: 0.4174807899875409\n",
      "Epoch 139, Loss: 0.41710820248087666\n",
      "Epoch 140, Loss: 0.4169967436709064\n",
      "Epoch 141, Loss: 0.4165120274958345\n",
      "Epoch 142, Loss: 0.41543640863014963\n",
      "Epoch 143, Loss: 0.41473566073163864\n",
      "Epoch 144, Loss: 0.4146371668300421\n",
      "Epoch 145, Loss: 0.4142654029765887\n",
      "Epoch 146, Loss: 0.41367161492329635\n",
      "Epoch 147, Loss: 0.4126771929220854\n",
      "Epoch 148, Loss: 0.41227066355032266\n",
      "Epoch 149, Loss: 0.4123908975120658\n",
      "Epoch 150, Loss: 0.4119748623699868\n",
      "Epoch 151, Loss: 0.41123993626487465\n",
      "Epoch 152, Loss: 0.4101389381751564\n",
      "Epoch 153, Loss: 0.40984554329645956\n",
      "Epoch 154, Loss: 0.4099807000269739\n",
      "Epoch 155, Loss: 0.40951920946825887\n",
      "Epoch 156, Loss: 0.4087030917266565\n",
      "Epoch 157, Loss: 0.40777896217033577\n",
      "Epoch 158, Loss: 0.40738199318603974\n",
      "Epoch 159, Loss: 0.40746823464954995\n",
      "Epoch 160, Loss: 0.40744899831370895\n",
      "Epoch 161, Loss: 0.4072935566122527\n",
      "Epoch 162, Loss: 0.4062020750387675\n",
      "Epoch 163, Loss: 0.405309542231183\n",
      "Epoch 164, Loss: 0.4047941199990908\n",
      "Epoch 165, Loss: 0.40469882168637183\n",
      "Epoch 166, Loss: 0.40494249918790237\n",
      "Epoch 167, Loss: 0.4047613746642267\n",
      "Epoch 168, Loss: 0.4045958772430868\n",
      "Epoch 169, Loss: 0.4032400758010453\n",
      "Epoch 170, Loss: 0.4025562799094903\n",
      "Epoch 171, Loss: 0.40260421321945944\n",
      "Epoch 172, Loss: 0.402706667726759\n",
      "Epoch 173, Loss: 0.40255268930823984\n",
      "Epoch 174, Loss: 0.40169107404857624\n",
      "Epoch 175, Loss: 0.400914886383965\n",
      "Epoch 176, Loss: 0.40042512326369334\n",
      "Epoch 177, Loss: 0.40028817331457406\n",
      "Epoch 178, Loss: 0.4004483065110796\n",
      "Epoch 179, Loss: 0.4006211524338234\n",
      "Epoch 180, Loss: 0.40088329243089943\n",
      "Epoch 181, Loss: 0.40004302031916406\n",
      "Epoch 182, Loss: 0.3989447375571391\n",
      "Epoch 183, Loss: 0.3982272621938774\n",
      "Epoch 184, Loss: 0.398358449386835\n",
      "Epoch 185, Loss: 0.39888971508884197\n",
      "Epoch 186, Loss: 0.39859785331309755\n",
      "Epoch 187, Loss: 0.3979307018254744\n",
      "Epoch 188, Loss: 0.39696242728667663\n",
      "Epoch 189, Loss: 0.39648441258322253\n",
      "Epoch 190, Loss: 0.396483510584899\n",
      "Epoch 191, Loss: 0.3966580654094629\n",
      "Epoch 192, Loss: 0.39715459391667146\n",
      "Epoch 193, Loss: 0.3968779391082307\n",
      "Epoch 194, Loss: 0.3964566376102417\n",
      "Epoch 195, Loss: 0.39532579542878626\n",
      "Epoch 196, Loss: 0.3945958679461404\n",
      "Epoch 197, Loss: 0.39453410157032404\n",
      "Epoch 198, Loss: 0.3948089453238414\n",
      "Epoch 199, Loss: 0.39521217128490116\n",
      "Epoch 200, Loss: 0.39491732752263664\n",
      "Epoch 201, Loss: 0.3943334593560401\n",
      "Epoch 202, Loss: 0.39343623420929846\n",
      "Epoch 203, Loss: 0.39276575946938347\n",
      "Epoch 204, Loss: 0.39250647427145563\n",
      "Epoch 205, Loss: 0.3925949586514001\n",
      "Epoch 206, Loss: 0.39320784209916226\n",
      "Epoch 207, Loss: 0.3937398129613764\n",
      "Epoch 208, Loss: 0.39456701588686255\n",
      "Epoch 209, Loss: 0.39287282785463906\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22826640831274844\n",
      "Test R^2 score: 0.4352530508413614\n",
      "Num of epochs: 210\n",
      "Epoch 1, Loss: 0.5803791125823701\n",
      "Epoch 2, Loss: 0.5789602792420504\n",
      "Epoch 3, Loss: 0.5775732036119301\n",
      "Epoch 4, Loss: 0.5762193304659234\n",
      "Epoch 5, Loss: 0.574908951102056\n",
      "Epoch 6, Loss: 0.5736391684751853\n",
      "Epoch 7, Loss: 0.5724049421377642\n",
      "Epoch 8, Loss: 0.571205928655051\n",
      "Epoch 9, Loss: 0.5700455916307962\n",
      "Epoch 10, Loss: 0.5689249010808364\n",
      "Epoch 11, Loss: 0.5678449577162089\n",
      "Epoch 12, Loss: 0.5668066516876943\n",
      "Epoch 13, Loss: 0.5658089480906439\n",
      "Epoch 14, Loss: 0.5648368138564096\n",
      "Epoch 15, Loss: 0.5639119441336047\n",
      "Epoch 16, Loss: 0.5630381711771679\n",
      "Epoch 17, Loss: 0.5622124996850333\n",
      "Epoch 18, Loss: 0.5614240740890943\n",
      "Epoch 19, Loss: 0.5606773038640159\n",
      "Epoch 20, Loss: 0.5599739256817141\n",
      "Epoch 21, Loss: 0.5593129842894407\n",
      "Epoch 22, Loss: 0.5587211943674868\n",
      "Epoch 23, Loss: 0.5582043817931777\n",
      "Epoch 24, Loss: 0.5577338208613787\n",
      "Epoch 25, Loss: 0.5572804304279578\n",
      "Epoch 26, Loss: 0.5568444397543832\n",
      "Epoch 27, Loss: 0.5564200516413483\n",
      "Epoch 28, Loss: 0.555997939274077\n",
      "Epoch 29, Loss: 0.5555666283325245\n",
      "Epoch 30, Loss: 0.555116729145587\n",
      "Epoch 31, Loss: 0.5546405664924255\n",
      "Epoch 32, Loss: 0.5541211043775306\n",
      "Epoch 33, Loss: 0.5535255404319863\n",
      "Epoch 34, Loss: 0.5528558658218632\n",
      "Epoch 35, Loss: 0.5521070877099068\n",
      "Epoch 36, Loss: 0.5512248478122951\n",
      "Epoch 37, Loss: 0.5501824769840882\n",
      "Epoch 38, Loss: 0.5489394322808347\n",
      "Epoch 39, Loss: 0.5474760022848253\n",
      "Epoch 40, Loss: 0.5457699100638841\n",
      "Epoch 41, Loss: 0.5437937992915317\n",
      "Epoch 42, Loss: 0.5415317813726056\n",
      "Epoch 43, Loss: 0.5389633916886101\n",
      "Epoch 44, Loss: 0.5361539075693214\n",
      "Epoch 45, Loss: 0.5333061817330936\n",
      "Epoch 46, Loss: 0.530823396048761\n",
      "Epoch 47, Loss: 0.5283155458697143\n",
      "Epoch 48, Loss: 0.5250357808681116\n",
      "Epoch 49, Loss: 0.521356974266132\n",
      "Epoch 50, Loss: 0.5182201218574519\n",
      "Epoch 51, Loss: 0.5159360352096236\n",
      "Epoch 52, Loss: 0.5138802051526469\n",
      "Epoch 53, Loss: 0.5117289709570102\n",
      "Epoch 54, Loss: 0.5097790712651304\n",
      "Epoch 55, Loss: 0.5083795755751194\n",
      "Epoch 56, Loss: 0.5069491750534183\n",
      "Epoch 57, Loss: 0.5050294762686401\n",
      "Epoch 58, Loss: 0.5031553780524656\n",
      "Epoch 59, Loss: 0.5015854138045296\n",
      "Epoch 60, Loss: 0.4998530082405677\n",
      "Epoch 61, Loss: 0.4978812147897602\n",
      "Epoch 62, Loss: 0.49618640545023857\n",
      "Epoch 63, Loss: 0.4947164746086917\n",
      "Epoch 64, Loss: 0.493052811868702\n",
      "Epoch 65, Loss: 0.4914167363635376\n",
      "Epoch 66, Loss: 0.49002614861414007\n",
      "Epoch 67, Loss: 0.4886329757369343\n",
      "Epoch 68, Loss: 0.48712396423958015\n",
      "Epoch 69, Loss: 0.485675450408345\n",
      "Epoch 70, Loss: 0.48429162323059993\n",
      "Epoch 71, Loss: 0.48281370304784915\n",
      "Epoch 72, Loss: 0.4813488908203539\n",
      "Epoch 73, Loss: 0.4800160764445795\n",
      "Epoch 74, Loss: 0.4786827574038131\n",
      "Epoch 75, Loss: 0.4773218952176878\n",
      "Epoch 76, Loss: 0.47610817812574224\n",
      "Epoch 77, Loss: 0.474907643976743\n",
      "Epoch 78, Loss: 0.4736741667321945\n",
      "Epoch 79, Loss: 0.4725295283158359\n",
      "Epoch 80, Loss: 0.47137777961330213\n",
      "Epoch 81, Loss: 0.4702791544350257\n",
      "Epoch 82, Loss: 0.4692484430806544\n",
      "Epoch 83, Loss: 0.46815020015915576\n",
      "Epoch 84, Loss: 0.4670743875500443\n",
      "Epoch 85, Loss: 0.46601291089734453\n",
      "Epoch 86, Loss: 0.4649663491019489\n",
      "Epoch 87, Loss: 0.46395739832616745\n",
      "Epoch 88, Loss: 0.46289802899455057\n",
      "Epoch 89, Loss: 0.46184223092356735\n",
      "Epoch 90, Loss: 0.460770528260478\n",
      "Epoch 91, Loss: 0.45971525721765705\n",
      "Epoch 92, Loss: 0.458678642876669\n",
      "Epoch 93, Loss: 0.4576917586742504\n",
      "Epoch 94, Loss: 0.4567175872923661\n",
      "Epoch 95, Loss: 0.4557610655020378\n",
      "Epoch 96, Loss: 0.4547971750497524\n",
      "Epoch 97, Loss: 0.4538461438563531\n",
      "Epoch 98, Loss: 0.4528977712265162\n",
      "Epoch 99, Loss: 0.4519448532626796\n",
      "Epoch 100, Loss: 0.4510326748745304\n",
      "Epoch 101, Loss: 0.45013521666347966\n",
      "Epoch 102, Loss: 0.44920808530670375\n",
      "Epoch 103, Loss: 0.4482893077542333\n",
      "Epoch 104, Loss: 0.4473318359142195\n",
      "Epoch 105, Loss: 0.44638539616387385\n",
      "Epoch 106, Loss: 0.4454901324237917\n",
      "Epoch 107, Loss: 0.4446407236949756\n",
      "Epoch 108, Loss: 0.44380541979233923\n",
      "Epoch 109, Loss: 0.4430797888500609\n",
      "Epoch 110, Loss: 0.4423568246378573\n",
      "Epoch 111, Loss: 0.44171978777995285\n",
      "Epoch 112, Loss: 0.4411397821701203\n",
      "Epoch 113, Loss: 0.44060313326097733\n",
      "Epoch 114, Loss: 0.43974336999858255\n",
      "Epoch 115, Loss: 0.4386930377369917\n",
      "Epoch 116, Loss: 0.43793981447693\n",
      "Epoch 117, Loss: 0.4373542338454071\n",
      "Epoch 118, Loss: 0.43647980952021703\n",
      "Epoch 119, Loss: 0.4356080598150774\n",
      "Epoch 120, Loss: 0.4350500823107774\n",
      "Epoch 121, Loss: 0.4344216939130464\n",
      "Epoch 122, Loss: 0.43345911496041917\n",
      "Epoch 123, Loss: 0.43261389806456996\n",
      "Epoch 124, Loss: 0.43205260556851005\n",
      "Epoch 125, Loss: 0.4314325271169539\n",
      "Epoch 126, Loss: 0.43052821709206357\n",
      "Epoch 127, Loss: 0.42973129742831817\n",
      "Epoch 128, Loss: 0.4291525545238212\n",
      "Epoch 129, Loss: 0.4286701643547964\n",
      "Epoch 130, Loss: 0.4278942836948427\n",
      "Epoch 131, Loss: 0.42700577434838766\n",
      "Epoch 132, Loss: 0.426309992212543\n",
      "Epoch 133, Loss: 0.42589609539609413\n",
      "Epoch 134, Loss: 0.4255073086080647\n",
      "Epoch 135, Loss: 0.42490412107432163\n",
      "Epoch 136, Loss: 0.4240169192550693\n",
      "Epoch 137, Loss: 0.4235309138843095\n",
      "Epoch 138, Loss: 0.4233466547117816\n",
      "Epoch 139, Loss: 0.42280893793741336\n",
      "Epoch 140, Loss: 0.42175787606768367\n",
      "Epoch 141, Loss: 0.42141622747222746\n",
      "Epoch 142, Loss: 0.4214076526520907\n",
      "Epoch 143, Loss: 0.4206225382660564\n",
      "Epoch 144, Loss: 0.419643132157511\n",
      "Epoch 145, Loss: 0.41937059988564607\n",
      "Epoch 146, Loss: 0.41921380249470813\n",
      "Epoch 147, Loss: 0.4185140208159638\n",
      "Epoch 148, Loss: 0.41773308143964777\n",
      "Epoch 149, Loss: 0.41742223143807783\n",
      "Epoch 150, Loss: 0.41728382498727207\n",
      "Epoch 151, Loss: 0.4166537302711085\n",
      "Epoch 152, Loss: 0.4158568997321097\n",
      "Epoch 153, Loss: 0.4153812568530814\n",
      "Epoch 154, Loss: 0.4154086991403432\n",
      "Epoch 155, Loss: 0.4150406242790009\n",
      "Epoch 156, Loss: 0.4142264455442331\n",
      "Epoch 157, Loss: 0.4133260223135606\n",
      "Epoch 158, Loss: 0.4131591227025957\n",
      "Epoch 159, Loss: 0.4129824677872488\n",
      "Epoch 160, Loss: 0.41248535794945473\n",
      "Epoch 161, Loss: 0.4115919688861596\n",
      "Epoch 162, Loss: 0.4110980347627913\n",
      "Epoch 163, Loss: 0.410815716962872\n",
      "Epoch 164, Loss: 0.4106794562439548\n",
      "Epoch 165, Loss: 0.41025044404121463\n",
      "Epoch 166, Loss: 0.40966218528257076\n",
      "Epoch 167, Loss: 0.40903393828576534\n",
      "Epoch 168, Loss: 0.40852232139119643\n",
      "Epoch 169, Loss: 0.4082279654067693\n",
      "Epoch 170, Loss: 0.4080071412295987\n",
      "Epoch 171, Loss: 0.40796627127202295\n",
      "Epoch 172, Loss: 0.40765683795130636\n",
      "Epoch 173, Loss: 0.4072531090003595\n",
      "Epoch 174, Loss: 0.4066623099313892\n",
      "Epoch 175, Loss: 0.40603177004569235\n",
      "Epoch 176, Loss: 0.40549687120827455\n",
      "Epoch 177, Loss: 0.4051667222311049\n",
      "Epoch 178, Loss: 0.40514318372295144\n",
      "Epoch 179, Loss: 0.40520735971812716\n",
      "Epoch 180, Loss: 0.40559756634403454\n",
      "Epoch 181, Loss: 0.40582482390063\n",
      "Epoch 182, Loss: 0.40479172723128015\n",
      "Epoch 183, Loss: 0.4031579011605797\n",
      "Epoch 184, Loss: 0.40298993339342265\n",
      "Epoch 185, Loss: 0.40358581301822494\n",
      "Epoch 186, Loss: 0.4031775824681665\n",
      "Epoch 187, Loss: 0.4020055997978028\n",
      "Epoch 188, Loss: 0.40150766629136286\n",
      "Epoch 189, Loss: 0.4017116618412066\n",
      "Epoch 190, Loss: 0.4016851386331298\n",
      "Epoch 191, Loss: 0.4011754601308167\n",
      "Epoch 192, Loss: 0.4003746215599384\n",
      "Epoch 193, Loss: 0.40005056314966314\n",
      "Epoch 194, Loss: 0.3999583073583664\n",
      "Epoch 195, Loss: 0.40000591869743746\n",
      "Epoch 196, Loss: 0.3999046726182284\n",
      "Epoch 197, Loss: 0.39944877566934117\n",
      "Epoch 198, Loss: 0.3989323180093845\n",
      "Epoch 199, Loss: 0.3982783542017461\n",
      "Epoch 200, Loss: 0.39797327635894025\n",
      "Epoch 201, Loss: 0.3976691822879477\n",
      "Epoch 202, Loss: 0.3975204123348221\n",
      "Epoch 203, Loss: 0.3974936656927043\n",
      "Epoch 204, Loss: 0.39755830813954945\n",
      "Epoch 205, Loss: 0.3981646557255887\n",
      "Epoch 206, Loss: 0.3986304694727849\n",
      "Epoch 207, Loss: 0.39806574888096946\n",
      "Epoch 208, Loss: 0.39625061360019864\n",
      "Epoch 209, Loss: 0.3955506101458669\n",
      "Epoch 210, Loss: 0.39590072894644734\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.24137192151038653\n",
      "Test R^2 score: 0.36795626383129904\n",
      "Num of epochs: 211\n",
      "Epoch 1, Loss: 0.5700025369353473\n",
      "Epoch 2, Loss: 0.5683021909910809\n",
      "Epoch 3, Loss: 0.5667609583952526\n",
      "Epoch 4, Loss: 0.5653496456647481\n",
      "Epoch 5, Loss: 0.5640555436822857\n",
      "Epoch 6, Loss: 0.5628604528744393\n",
      "Epoch 7, Loss: 0.5617677638034108\n",
      "Epoch 8, Loss: 0.5607784736502927\n",
      "Epoch 9, Loss: 0.5598928377529709\n",
      "Epoch 10, Loss: 0.5591064714312074\n",
      "Epoch 11, Loss: 0.5584211816522175\n",
      "Epoch 12, Loss: 0.5578349100948662\n",
      "Epoch 13, Loss: 0.5573453758479114\n",
      "Epoch 14, Loss: 0.556948927779107\n",
      "Epoch 15, Loss: 0.5566489503472123\n",
      "Epoch 16, Loss: 0.5564376996564973\n",
      "Epoch 17, Loss: 0.5562923211703482\n",
      "Epoch 18, Loss: 0.556203516614538\n",
      "Epoch 19, Loss: 0.5561632485195601\n",
      "Epoch 20, Loss: 0.5561623375641943\n",
      "Epoch 21, Loss: 0.5561906568611455\n",
      "Epoch 22, Loss: 0.5562386650902212\n",
      "Epoch 23, Loss: 0.5562922675972128\n",
      "Epoch 24, Loss: 0.5563452756916826\n",
      "Epoch 25, Loss: 0.5563886373250266\n",
      "Epoch 26, Loss: 0.5564159810030243\n",
      "Epoch 27, Loss: 0.5564214710016566\n",
      "Epoch 28, Loss: 0.5563987340207921\n",
      "Epoch 29, Loss: 0.5563427312042708\n",
      "Epoch 30, Loss: 0.5562546311946485\n",
      "Epoch 31, Loss: 0.5561410100651166\n",
      "Epoch 32, Loss: 0.5560229170110578\n",
      "Epoch 33, Loss: 0.5558913692828904\n",
      "Epoch 34, Loss: 0.555732870283242\n",
      "Epoch 35, Loss: 0.5555484430202199\n",
      "Epoch 36, Loss: 0.5553396984474385\n",
      "Epoch 37, Loss: 0.5551134542541404\n",
      "Epoch 38, Loss: 0.55486324373816\n",
      "Epoch 39, Loss: 0.5545819947818659\n",
      "Epoch 40, Loss: 0.5542544434041956\n",
      "Epoch 41, Loss: 0.5538614865658092\n",
      "Epoch 42, Loss: 0.553383597576667\n",
      "Epoch 43, Loss: 0.552799450174188\n",
      "Epoch 44, Loss: 0.5520756978880503\n",
      "Epoch 45, Loss: 0.5511958678692069\n",
      "Epoch 46, Loss: 0.5501367572341956\n",
      "Epoch 47, Loss: 0.5488416459668168\n",
      "Epoch 48, Loss: 0.5472543762924293\n",
      "Epoch 49, Loss: 0.5452815410493652\n",
      "Epoch 50, Loss: 0.5428156465341469\n",
      "Epoch 51, Loss: 0.5397575707110062\n",
      "Epoch 52, Loss: 0.5360009981580237\n",
      "Epoch 53, Loss: 0.5314408969099885\n",
      "Epoch 54, Loss: 0.5259505340901294\n",
      "Epoch 55, Loss: 0.5195469961433261\n",
      "Epoch 56, Loss: 0.5125453475335373\n",
      "Epoch 57, Loss: 0.5059703278096701\n",
      "Epoch 58, Loss: 0.5019478704867698\n",
      "Epoch 59, Loss: 0.5003418052139498\n",
      "Epoch 60, Loss: 0.49653877362463256\n",
      "Epoch 61, Loss: 0.49049558937352866\n",
      "Epoch 62, Loss: 0.4852299374752281\n",
      "Epoch 63, Loss: 0.48278492228439585\n",
      "Epoch 64, Loss: 0.4830689357240514\n",
      "Epoch 65, Loss: 0.4845742000622236\n",
      "Epoch 66, Loss: 0.4852260373550357\n",
      "Epoch 67, Loss: 0.48403120145342476\n",
      "Epoch 68, Loss: 0.4813952158771815\n",
      "Epoch 69, Loss: 0.47853927553858533\n",
      "Epoch 70, Loss: 0.4761306650981945\n",
      "Epoch 71, Loss: 0.4754272603546665\n",
      "Epoch 72, Loss: 0.4755219058066144\n",
      "Epoch 73, Loss: 0.4752581522291053\n",
      "Epoch 74, Loss: 0.4741000515543715\n",
      "Epoch 75, Loss: 0.47254898493521236\n",
      "Epoch 76, Loss: 0.47109870591727826\n",
      "Epoch 77, Loss: 0.4701042322482365\n",
      "Epoch 78, Loss: 0.4693567640467577\n",
      "Epoch 79, Loss: 0.4686202187486296\n",
      "Epoch 80, Loss: 0.4677587040948165\n",
      "Epoch 81, Loss: 0.4668324349238231\n",
      "Epoch 82, Loss: 0.4658614326417535\n",
      "Epoch 83, Loss: 0.46502239737355827\n",
      "Epoch 84, Loss: 0.4644460339081081\n",
      "Epoch 85, Loss: 0.4640372195566651\n",
      "Epoch 86, Loss: 0.4635498889093859\n",
      "Epoch 87, Loss: 0.46285463346115613\n",
      "Epoch 88, Loss: 0.4620439536315881\n",
      "Epoch 89, Loss: 0.46130926689603713\n",
      "Epoch 90, Loss: 0.46074043522623254\n",
      "Epoch 91, Loss: 0.4602381686752171\n",
      "Epoch 92, Loss: 0.45969405804279767\n",
      "Epoch 93, Loss: 0.45907228317898535\n",
      "Epoch 94, Loss: 0.4584386950102185\n",
      "Epoch 95, Loss: 0.45782847848550945\n",
      "Epoch 96, Loss: 0.4572126892409838\n",
      "Epoch 97, Loss: 0.45663828135362977\n",
      "Epoch 98, Loss: 0.4560930942479719\n",
      "Epoch 99, Loss: 0.45553760498852086\n",
      "Epoch 100, Loss: 0.4549838774832399\n",
      "Epoch 101, Loss: 0.4544334593346534\n",
      "Epoch 102, Loss: 0.4538648419032712\n",
      "Epoch 103, Loss: 0.4533022172267302\n",
      "Epoch 104, Loss: 0.45275204206856084\n",
      "Epoch 105, Loss: 0.4521706660102377\n",
      "Epoch 106, Loss: 0.45158974588424733\n",
      "Epoch 107, Loss: 0.4510509279311961\n",
      "Epoch 108, Loss: 0.450514277004392\n",
      "Epoch 109, Loss: 0.4499777311537102\n",
      "Epoch 110, Loss: 0.44941653997408987\n",
      "Epoch 111, Loss: 0.44883691896965167\n",
      "Epoch 112, Loss: 0.4482737843798304\n",
      "Epoch 113, Loss: 0.4476994738257671\n",
      "Epoch 114, Loss: 0.44713890579393806\n",
      "Epoch 115, Loss: 0.4465773171168337\n",
      "Epoch 116, Loss: 0.44600503176258444\n",
      "Epoch 117, Loss: 0.4454424317184462\n",
      "Epoch 118, Loss: 0.44485624262985285\n",
      "Epoch 119, Loss: 0.4442685589689271\n",
      "Epoch 120, Loss: 0.4436677876731062\n",
      "Epoch 121, Loss: 0.44307057389436316\n",
      "Epoch 122, Loss: 0.4424473292313378\n",
      "Epoch 123, Loss: 0.4418166118230283\n",
      "Epoch 124, Loss: 0.44118583712498843\n",
      "Epoch 125, Loss: 0.44055757547809155\n",
      "Epoch 126, Loss: 0.43992137122392133\n",
      "Epoch 127, Loss: 0.4392781566286531\n",
      "Epoch 128, Loss: 0.43859999178965986\n",
      "Epoch 129, Loss: 0.4379163021620889\n",
      "Epoch 130, Loss: 0.4371976488856403\n",
      "Epoch 131, Loss: 0.4364437738902054\n",
      "Epoch 132, Loss: 0.4357017618027693\n",
      "Epoch 133, Loss: 0.4349834407197692\n",
      "Epoch 134, Loss: 0.4342960992687123\n",
      "Epoch 135, Loss: 0.4336631135187798\n",
      "Epoch 136, Loss: 0.4330523263697234\n",
      "Epoch 137, Loss: 0.4324596970858843\n",
      "Epoch 138, Loss: 0.4318532463203907\n",
      "Epoch 139, Loss: 0.4312563087167787\n",
      "Epoch 140, Loss: 0.43055623406524246\n",
      "Epoch 141, Loss: 0.42988131226932536\n",
      "Epoch 142, Loss: 0.42926243651719437\n",
      "Epoch 143, Loss: 0.4287013615470694\n",
      "Epoch 144, Loss: 0.4281236279597886\n",
      "Epoch 145, Loss: 0.4275306495197753\n",
      "Epoch 146, Loss: 0.42692555637822627\n",
      "Epoch 147, Loss: 0.42636070718353375\n",
      "Epoch 148, Loss: 0.4259563226102288\n",
      "Epoch 149, Loss: 0.42532648070576595\n",
      "Epoch 150, Loss: 0.4245625123498927\n",
      "Epoch 151, Loss: 0.42385335047316636\n",
      "Epoch 152, Loss: 0.4234115733412356\n",
      "Epoch 153, Loss: 0.4230283407305847\n",
      "Epoch 154, Loss: 0.4222848102682316\n",
      "Epoch 155, Loss: 0.42157715420600406\n",
      "Epoch 156, Loss: 0.4211445595514982\n",
      "Epoch 157, Loss: 0.42081859565964663\n",
      "Epoch 158, Loss: 0.42044186001815426\n",
      "Epoch 159, Loss: 0.4197004222229694\n",
      "Epoch 160, Loss: 0.41914949576597704\n",
      "Epoch 161, Loss: 0.4187728242205145\n",
      "Epoch 162, Loss: 0.41849924451037435\n",
      "Epoch 163, Loss: 0.4181262993899285\n",
      "Epoch 164, Loss: 0.41742549779720295\n",
      "Epoch 165, Loss: 0.4167440779619336\n",
      "Epoch 166, Loss: 0.4162219614889855\n",
      "Epoch 167, Loss: 0.4158527252336382\n",
      "Epoch 168, Loss: 0.4156212706147572\n",
      "Epoch 169, Loss: 0.4154516704788809\n",
      "Epoch 170, Loss: 0.4154554006692186\n",
      "Epoch 171, Loss: 0.41448506799360174\n",
      "Epoch 172, Loss: 0.41374349001231747\n",
      "Epoch 173, Loss: 0.41350476471048137\n",
      "Epoch 174, Loss: 0.41333319656628736\n",
      "Epoch 175, Loss: 0.41313236056882163\n",
      "Epoch 176, Loss: 0.4122192995531752\n",
      "Epoch 177, Loss: 0.41192125483275444\n",
      "Epoch 178, Loss: 0.4121913014916995\n",
      "Epoch 179, Loss: 0.4116701433997632\n",
      "Epoch 180, Loss: 0.41073739796819514\n",
      "Epoch 181, Loss: 0.4104294003610613\n",
      "Epoch 182, Loss: 0.4104894646920074\n",
      "Epoch 183, Loss: 0.4105636027056072\n",
      "Epoch 184, Loss: 0.40926482195803254\n",
      "Epoch 185, Loss: 0.4096592207691861\n",
      "Epoch 186, Loss: 0.41036961773129477\n",
      "Epoch 187, Loss: 0.4086851349671919\n",
      "Epoch 188, Loss: 0.40869188023839376\n",
      "Epoch 189, Loss: 0.40946346084310103\n",
      "Epoch 190, Loss: 0.4070740375251358\n",
      "Epoch 191, Loss: 0.40848918182121147\n",
      "Epoch 192, Loss: 0.4077017593568516\n",
      "Epoch 193, Loss: 0.40680057556919014\n",
      "Epoch 194, Loss: 0.40806290622970826\n",
      "Epoch 195, Loss: 0.4057336974309286\n",
      "Epoch 196, Loss: 0.4065264164938358\n",
      "Epoch 197, Loss: 0.40527112109889596\n",
      "Epoch 198, Loss: 0.40555331206499534\n",
      "Epoch 199, Loss: 0.4054445939411494\n",
      "Epoch 200, Loss: 0.40437154034368333\n",
      "Epoch 201, Loss: 0.40488385698595036\n",
      "Epoch 202, Loss: 0.40366876803635277\n",
      "Epoch 203, Loss: 0.40404393857849774\n",
      "Epoch 204, Loss: 0.40332025708066543\n",
      "Epoch 205, Loss: 0.4030938979282488\n",
      "Epoch 206, Loss: 0.4029234811265094\n",
      "Epoch 207, Loss: 0.4023753588954229\n",
      "Epoch 208, Loss: 0.40228456228506576\n",
      "Epoch 209, Loss: 0.40206493976338437\n",
      "Epoch 210, Loss: 0.4015500100119296\n",
      "Epoch 211, Loss: 0.40165666596769456\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22220478232004276\n",
      "Test R^2 score: 0.4653397661339861\n",
      "Num of epochs: 212\n",
      "Epoch 1, Loss: 0.5870815552232653\n",
      "Epoch 2, Loss: 0.5848077691333146\n",
      "Epoch 3, Loss: 0.5826558851229159\n",
      "Epoch 4, Loss: 0.5806556934583754\n",
      "Epoch 5, Loss: 0.5787360081309884\n",
      "Epoch 6, Loss: 0.5768984335441172\n",
      "Epoch 7, Loss: 0.5751413731307821\n",
      "Epoch 8, Loss: 0.5734665543682196\n",
      "Epoch 9, Loss: 0.5719881915027327\n",
      "Epoch 10, Loss: 0.5705809026937229\n",
      "Epoch 11, Loss: 0.5692342467794148\n",
      "Epoch 12, Loss: 0.5679417022603346\n",
      "Epoch 13, Loss: 0.5667044019289504\n",
      "Epoch 14, Loss: 0.5655239995068054\n",
      "Epoch 15, Loss: 0.564399505497211\n",
      "Epoch 16, Loss: 0.5633177111884162\n",
      "Epoch 17, Loss: 0.5622741987754836\n",
      "Epoch 18, Loss: 0.5612888808259757\n",
      "Epoch 19, Loss: 0.5603659201504807\n",
      "Epoch 20, Loss: 0.5595382228524433\n",
      "Epoch 21, Loss: 0.5587856256618629\n",
      "Epoch 22, Loss: 0.5580920120178875\n",
      "Epoch 23, Loss: 0.5574671715534898\n",
      "Epoch 24, Loss: 0.5568904115490183\n",
      "Epoch 25, Loss: 0.5563228838030467\n",
      "Epoch 26, Loss: 0.5557619890163088\n",
      "Epoch 27, Loss: 0.5551963943237939\n",
      "Epoch 28, Loss: 0.5546141293852954\n",
      "Epoch 29, Loss: 0.5539835909503149\n",
      "Epoch 30, Loss: 0.5532736691610292\n",
      "Epoch 31, Loss: 0.5524672007426534\n",
      "Epoch 32, Loss: 0.5515428782747052\n",
      "Epoch 33, Loss: 0.5504385240341056\n",
      "Epoch 34, Loss: 0.5490866761375279\n",
      "Epoch 35, Loss: 0.5474175350582818\n",
      "Epoch 36, Loss: 0.5453872607555924\n",
      "Epoch 37, Loss: 0.5430347759252876\n",
      "Epoch 38, Loss: 0.5404902637585799\n",
      "Epoch 39, Loss: 0.5379449344607478\n",
      "Epoch 40, Loss: 0.535685924505904\n",
      "Epoch 41, Loss: 0.5340804822114238\n",
      "Epoch 42, Loss: 0.5331113966964964\n",
      "Epoch 43, Loss: 0.5316961602796803\n",
      "Epoch 44, Loss: 0.5291986127907297\n",
      "Epoch 45, Loss: 0.5262178056886166\n",
      "Epoch 46, Loss: 0.5235832068492577\n",
      "Epoch 47, Loss: 0.5216248569502041\n",
      "Epoch 48, Loss: 0.5200436582027707\n",
      "Epoch 49, Loss: 0.5184011573309106\n",
      "Epoch 50, Loss: 0.5164671580627728\n",
      "Epoch 51, Loss: 0.5142606254874492\n",
      "Epoch 52, Loss: 0.5119534893200499\n",
      "Epoch 53, Loss: 0.5098898725255393\n",
      "Epoch 54, Loss: 0.5081875809704735\n",
      "Epoch 55, Loss: 0.5066492107902094\n",
      "Epoch 56, Loss: 0.5048350859464992\n",
      "Epoch 57, Loss: 0.5027362340316249\n",
      "Epoch 58, Loss: 0.500747509324064\n",
      "Epoch 59, Loss: 0.49900605830258893\n",
      "Epoch 60, Loss: 0.49726201465911246\n",
      "Epoch 61, Loss: 0.4953116462050339\n",
      "Epoch 62, Loss: 0.49321334139428774\n",
      "Epoch 63, Loss: 0.49118305832485165\n",
      "Epoch 64, Loss: 0.48932316813750926\n",
      "Epoch 65, Loss: 0.48738184683061186\n",
      "Epoch 66, Loss: 0.48522000285532474\n",
      "Epoch 67, Loss: 0.4831041924016566\n",
      "Epoch 68, Loss: 0.48122241448942427\n",
      "Epoch 69, Loss: 0.4794064384904186\n",
      "Epoch 70, Loss: 0.47748560694028125\n",
      "Epoch 71, Loss: 0.475660079409324\n",
      "Epoch 72, Loss: 0.4740253827244125\n",
      "Epoch 73, Loss: 0.47234775785057564\n",
      "Epoch 74, Loss: 0.47060404324320604\n",
      "Epoch 75, Loss: 0.46907396247881994\n",
      "Epoch 76, Loss: 0.4676307030406254\n",
      "Epoch 77, Loss: 0.46596067541091496\n",
      "Epoch 78, Loss: 0.4642006568888019\n",
      "Epoch 79, Loss: 0.4625860250217525\n",
      "Epoch 80, Loss: 0.4610240499414787\n",
      "Epoch 81, Loss: 0.45950881540063293\n",
      "Epoch 82, Loss: 0.4581354772610889\n",
      "Epoch 83, Loss: 0.4570476822466622\n",
      "Epoch 84, Loss: 0.4564020112652807\n",
      "Epoch 85, Loss: 0.4562124106194509\n",
      "Epoch 86, Loss: 0.45588058317743935\n",
      "Epoch 87, Loss: 0.4552508505279623\n",
      "Epoch 88, Loss: 0.4542582415933737\n",
      "Epoch 89, Loss: 0.45304460470015895\n",
      "Epoch 90, Loss: 0.4519089132327691\n",
      "Epoch 91, Loss: 0.45103179936998966\n",
      "Epoch 92, Loss: 0.45029157159737876\n",
      "Epoch 93, Loss: 0.4497431141048951\n",
      "Epoch 94, Loss: 0.4491406248407502\n",
      "Epoch 95, Loss: 0.44856081340420095\n",
      "Epoch 96, Loss: 0.4478017434094759\n",
      "Epoch 97, Loss: 0.44696316216195164\n",
      "Epoch 98, Loss: 0.4460155725871657\n",
      "Epoch 99, Loss: 0.4451266118282626\n",
      "Epoch 100, Loss: 0.44436675583157453\n",
      "Epoch 101, Loss: 0.4436777962788086\n",
      "Epoch 102, Loss: 0.44300703929406127\n",
      "Epoch 103, Loss: 0.4423588963121629\n",
      "Epoch 104, Loss: 0.4417597106628358\n",
      "Epoch 105, Loss: 0.4410013857114737\n",
      "Epoch 106, Loss: 0.44031096759364335\n",
      "Epoch 107, Loss: 0.43962605782501707\n",
      "Epoch 108, Loss: 0.43894184463895014\n",
      "Epoch 109, Loss: 0.4382878770514219\n",
      "Epoch 110, Loss: 0.4375926668937871\n",
      "Epoch 111, Loss: 0.43694201718061937\n",
      "Epoch 112, Loss: 0.4362735587811657\n",
      "Epoch 113, Loss: 0.43556351907856933\n",
      "Epoch 114, Loss: 0.4348296174066911\n",
      "Epoch 115, Loss: 0.43413583703084074\n",
      "Epoch 116, Loss: 0.4334684998662322\n",
      "Epoch 117, Loss: 0.4327758601410336\n",
      "Epoch 118, Loss: 0.4320761438260253\n",
      "Epoch 119, Loss: 0.43131369728482716\n",
      "Epoch 120, Loss: 0.43056291356858023\n",
      "Epoch 121, Loss: 0.42975458141700945\n",
      "Epoch 122, Loss: 0.4290015033226527\n",
      "Epoch 123, Loss: 0.42828709673169896\n",
      "Epoch 124, Loss: 0.4275961177810274\n",
      "Epoch 125, Loss: 0.42689534640100196\n",
      "Epoch 126, Loss: 0.42619931406277395\n",
      "Epoch 127, Loss: 0.42548538567742145\n",
      "Epoch 128, Loss: 0.42482455853870466\n",
      "Epoch 129, Loss: 0.42416363282545777\n",
      "Epoch 130, Loss: 0.4234981922698819\n",
      "Epoch 131, Loss: 0.4229468575241917\n",
      "Epoch 132, Loss: 0.42288008807304256\n",
      "Epoch 133, Loss: 0.42332741830227766\n",
      "Epoch 134, Loss: 0.42113173318803687\n",
      "Epoch 135, Loss: 0.42085511942769577\n",
      "Epoch 136, Loss: 0.42064884157899796\n",
      "Epoch 137, Loss: 0.4189126061964323\n",
      "Epoch 138, Loss: 0.41948419871823694\n",
      "Epoch 139, Loss: 0.41777636654947453\n",
      "Epoch 140, Loss: 0.417953597890421\n",
      "Epoch 141, Loss: 0.41707036806445436\n",
      "Epoch 142, Loss: 0.4162850022706358\n",
      "Epoch 143, Loss: 0.4162009278717862\n",
      "Epoch 144, Loss: 0.41495744688111297\n",
      "Epoch 145, Loss: 0.41509458282715694\n",
      "Epoch 146, Loss: 0.4139377478037661\n",
      "Epoch 147, Loss: 0.41374480457443785\n",
      "Epoch 148, Loss: 0.4130404472103465\n",
      "Epoch 149, Loss: 0.4122779826700752\n",
      "Epoch 150, Loss: 0.41211969805619864\n",
      "Epoch 151, Loss: 0.41116575711653147\n",
      "Epoch 152, Loss: 0.4109672521111817\n",
      "Epoch 153, Loss: 0.41045702850368804\n",
      "Epoch 154, Loss: 0.40974471017938596\n",
      "Epoch 155, Loss: 0.40960454620361336\n",
      "Epoch 156, Loss: 0.40895516875149174\n",
      "Epoch 157, Loss: 0.40840554580084854\n",
      "Epoch 158, Loss: 0.4081659254436271\n",
      "Epoch 159, Loss: 0.4075454634188725\n",
      "Epoch 160, Loss: 0.4070316461132853\n",
      "Epoch 161, Loss: 0.4067448206784572\n",
      "Epoch 162, Loss: 0.40615115430382115\n",
      "Epoch 163, Loss: 0.40559967881858683\n",
      "Epoch 164, Loss: 0.4052856443474147\n",
      "Epoch 165, Loss: 0.4047835917149254\n",
      "Epoch 166, Loss: 0.40419683278299623\n",
      "Epoch 167, Loss: 0.40377964344978984\n",
      "Epoch 168, Loss: 0.4034788175858347\n",
      "Epoch 169, Loss: 0.4031034352944235\n",
      "Epoch 170, Loss: 0.40249190334208673\n",
      "Epoch 171, Loss: 0.40194202478205276\n",
      "Epoch 172, Loss: 0.40156301654233256\n",
      "Epoch 173, Loss: 0.40126407533242936\n",
      "Epoch 174, Loss: 0.40096275577103535\n",
      "Epoch 175, Loss: 0.400513644044375\n",
      "Epoch 176, Loss: 0.4000316778692808\n",
      "Epoch 177, Loss: 0.3994407365095116\n",
      "Epoch 178, Loss: 0.3989313655168265\n",
      "Epoch 179, Loss: 0.3984847321283786\n",
      "Epoch 180, Loss: 0.39809973742881954\n",
      "Epoch 181, Loss: 0.39779171313255623\n",
      "Epoch 182, Loss: 0.39759992938856575\n",
      "Epoch 183, Loss: 0.3977337212782916\n",
      "Epoch 184, Loss: 0.3978990394456059\n",
      "Epoch 185, Loss: 0.3978130645927744\n",
      "Epoch 186, Loss: 0.3963410630568545\n",
      "Epoch 187, Loss: 0.39535779580414215\n",
      "Epoch 188, Loss: 0.3956320673415275\n",
      "Epoch 189, Loss: 0.3956422742052447\n",
      "Epoch 190, Loss: 0.39477216333545756\n",
      "Epoch 191, Loss: 0.3937817053670001\n",
      "Epoch 192, Loss: 0.39359054212788674\n",
      "Epoch 193, Loss: 0.3934265003681632\n",
      "Epoch 194, Loss: 0.3929715059763922\n",
      "Epoch 195, Loss: 0.39239176791705965\n",
      "Epoch 196, Loss: 0.39173493052518493\n",
      "Epoch 197, Loss: 0.3913496924557397\n",
      "Epoch 198, Loss: 0.39161801957631376\n",
      "Epoch 199, Loss: 0.39165684792541383\n",
      "Epoch 200, Loss: 0.39136067732363056\n",
      "Epoch 201, Loss: 0.39043106987208964\n",
      "Epoch 202, Loss: 0.38952996309988214\n",
      "Epoch 203, Loss: 0.388873618210214\n",
      "Epoch 204, Loss: 0.3886959317684119\n",
      "Epoch 205, Loss: 0.3889488115389853\n",
      "Epoch 206, Loss: 0.3887575141450384\n",
      "Epoch 207, Loss: 0.38779173451911453\n",
      "Epoch 208, Loss: 0.3869835303545301\n",
      "Epoch 209, Loss: 0.38651441705248735\n",
      "Epoch 210, Loss: 0.3862287518912833\n",
      "Epoch 211, Loss: 0.3855156921638984\n",
      "Epoch 212, Loss: 0.3853874410253771\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.23879486736455105\n",
      "Test R^2 score: 0.3810121475380822\n",
      "Num of epochs: 213\n",
      "Epoch 1, Loss: 0.5808957435494653\n",
      "Epoch 2, Loss: 0.579208081180353\n",
      "Epoch 3, Loss: 0.5775260658078956\n",
      "Epoch 4, Loss: 0.5759282000945287\n",
      "Epoch 5, Loss: 0.5744031493269965\n",
      "Epoch 6, Loss: 0.572949726422457\n",
      "Epoch 7, Loss: 0.571586622685394\n",
      "Epoch 8, Loss: 0.5702998800057183\n",
      "Epoch 9, Loss: 0.5690741485124122\n",
      "Epoch 10, Loss: 0.5679182982567094\n",
      "Epoch 11, Loss: 0.5668415107213843\n",
      "Epoch 12, Loss: 0.5658358365379474\n",
      "Epoch 13, Loss: 0.5649144752301624\n",
      "Epoch 14, Loss: 0.5640563626364947\n",
      "Epoch 15, Loss: 0.5632474754249828\n",
      "Epoch 16, Loss: 0.5624885293002926\n",
      "Epoch 17, Loss: 0.5618561928033945\n",
      "Epoch 18, Loss: 0.5612641374383465\n",
      "Epoch 19, Loss: 0.5607146434071227\n",
      "Epoch 20, Loss: 0.5602653939763453\n",
      "Epoch 21, Loss: 0.5598157307892637\n",
      "Epoch 22, Loss: 0.5593796916317385\n",
      "Epoch 23, Loss: 0.5589606140759383\n",
      "Epoch 24, Loss: 0.5585536542253696\n",
      "Epoch 25, Loss: 0.5581473587615402\n",
      "Epoch 26, Loss: 0.5577279162991439\n",
      "Epoch 27, Loss: 0.5572569530287743\n",
      "Epoch 28, Loss: 0.5566935196222682\n",
      "Epoch 29, Loss: 0.556032939950556\n",
      "Epoch 30, Loss: 0.5552518686780955\n",
      "Epoch 31, Loss: 0.5543388022869653\n",
      "Epoch 32, Loss: 0.5532765778864364\n",
      "Epoch 33, Loss: 0.5520441713178657\n",
      "Epoch 34, Loss: 0.5506882014033633\n",
      "Epoch 35, Loss: 0.5491704450177278\n",
      "Epoch 36, Loss: 0.5474176983832543\n",
      "Epoch 37, Loss: 0.545402888810551\n",
      "Epoch 38, Loss: 0.5431666116610079\n",
      "Epoch 39, Loss: 0.5407787865001489\n",
      "Epoch 40, Loss: 0.5384019868533472\n",
      "Epoch 41, Loss: 0.5362070723559883\n",
      "Epoch 42, Loss: 0.534308967079783\n",
      "Epoch 43, Loss: 0.532635397017515\n",
      "Epoch 44, Loss: 0.5307483267827372\n",
      "Epoch 45, Loss: 0.5281162960983025\n",
      "Epoch 46, Loss: 0.5248809384261948\n",
      "Epoch 47, Loss: 0.5216832156902874\n",
      "Epoch 48, Loss: 0.5189684063385483\n",
      "Epoch 49, Loss: 0.516896846729298\n",
      "Epoch 50, Loss: 0.5152937663266283\n",
      "Epoch 51, Loss: 0.5138739706858221\n",
      "Epoch 52, Loss: 0.5123962401980233\n",
      "Epoch 53, Loss: 0.5108516714352672\n",
      "Epoch 54, Loss: 0.5092521800245947\n",
      "Epoch 55, Loss: 0.5075151012785905\n",
      "Epoch 56, Loss: 0.5055795138426322\n",
      "Epoch 57, Loss: 0.503506464908163\n",
      "Epoch 58, Loss: 0.5014592572488846\n",
      "Epoch 59, Loss: 0.49963769601300456\n",
      "Epoch 60, Loss: 0.4980923052244547\n",
      "Epoch 61, Loss: 0.4967455599384358\n",
      "Epoch 62, Loss: 0.49548583442444427\n",
      "Epoch 63, Loss: 0.49425749470995917\n",
      "Epoch 64, Loss: 0.49308451398093844\n",
      "Epoch 65, Loss: 0.49185352499104823\n",
      "Epoch 66, Loss: 0.4905420227102413\n",
      "Epoch 67, Loss: 0.489176608292751\n",
      "Epoch 68, Loss: 0.48778562187030916\n",
      "Epoch 69, Loss: 0.48644316511446783\n",
      "Epoch 70, Loss: 0.4851551387608283\n",
      "Epoch 71, Loss: 0.48393220042977947\n",
      "Epoch 72, Loss: 0.4827578837789586\n",
      "Epoch 73, Loss: 0.48155415447907846\n",
      "Epoch 74, Loss: 0.48031950392670303\n",
      "Epoch 75, Loss: 0.47908671029882977\n",
      "Epoch 76, Loss: 0.4778402272045238\n",
      "Epoch 77, Loss: 0.47657389705350034\n",
      "Epoch 78, Loss: 0.47532695321925855\n",
      "Epoch 79, Loss: 0.4741843090088274\n",
      "Epoch 80, Loss: 0.473147035007525\n",
      "Epoch 81, Loss: 0.47213449921670503\n",
      "Epoch 82, Loss: 0.47108730292772\n",
      "Epoch 83, Loss: 0.46996207885755786\n",
      "Epoch 84, Loss: 0.46874858538096276\n",
      "Epoch 85, Loss: 0.467498555181178\n",
      "Epoch 86, Loss: 0.466239996053639\n",
      "Epoch 87, Loss: 0.46498275729994326\n",
      "Epoch 88, Loss: 0.4637414862321661\n",
      "Epoch 89, Loss: 0.46249519229658304\n",
      "Epoch 90, Loss: 0.46115963642541463\n",
      "Epoch 91, Loss: 0.4596967485121177\n",
      "Epoch 92, Loss: 0.458156016758302\n",
      "Epoch 93, Loss: 0.4566166129867937\n",
      "Epoch 94, Loss: 0.45525576026536035\n",
      "Epoch 95, Loss: 0.4542296854388376\n",
      "Epoch 96, Loss: 0.45366076332806543\n",
      "Epoch 97, Loss: 0.4534315190620772\n",
      "Epoch 98, Loss: 0.4530463808191521\n",
      "Epoch 99, Loss: 0.4522508212810121\n",
      "Epoch 100, Loss: 0.45123300509798175\n",
      "Epoch 101, Loss: 0.4502909759364874\n",
      "Epoch 102, Loss: 0.44948109139759324\n",
      "Epoch 103, Loss: 0.44884546775943335\n",
      "Epoch 104, Loss: 0.4482882773113476\n",
      "Epoch 105, Loss: 0.44768145025932865\n",
      "Epoch 106, Loss: 0.44698683199699113\n",
      "Epoch 107, Loss: 0.44627842796560135\n",
      "Epoch 108, Loss: 0.4455129272756007\n",
      "Epoch 109, Loss: 0.44469134191701803\n",
      "Epoch 110, Loss: 0.44387548714011854\n",
      "Epoch 111, Loss: 0.44311494853533306\n",
      "Epoch 112, Loss: 0.44240923669982674\n",
      "Epoch 113, Loss: 0.4417413098161071\n",
      "Epoch 114, Loss: 0.441112961007864\n",
      "Epoch 115, Loss: 0.4405046048275491\n",
      "Epoch 116, Loss: 0.4398957799353971\n",
      "Epoch 117, Loss: 0.4392520359689059\n",
      "Epoch 118, Loss: 0.43858173018219343\n",
      "Epoch 119, Loss: 0.4379155705719843\n",
      "Epoch 120, Loss: 0.43726374854931954\n",
      "Epoch 121, Loss: 0.43663555983893476\n",
      "Epoch 122, Loss: 0.4360081236043123\n",
      "Epoch 123, Loss: 0.4353619341087612\n",
      "Epoch 124, Loss: 0.434684704072957\n",
      "Epoch 125, Loss: 0.4339895418067278\n",
      "Epoch 126, Loss: 0.433280969475904\n",
      "Epoch 127, Loss: 0.4325863932721365\n",
      "Epoch 128, Loss: 0.43189606508921\n",
      "Epoch 129, Loss: 0.4312469966065133\n",
      "Epoch 130, Loss: 0.4306063797223441\n",
      "Epoch 131, Loss: 0.4299593845580946\n",
      "Epoch 132, Loss: 0.4292192161510312\n",
      "Epoch 133, Loss: 0.4284258439796915\n",
      "Epoch 134, Loss: 0.42774195207129256\n",
      "Epoch 135, Loss: 0.42703606374953706\n",
      "Epoch 136, Loss: 0.4263358922037268\n",
      "Epoch 137, Loss: 0.4256978434492153\n",
      "Epoch 138, Loss: 0.4251036545628021\n",
      "Epoch 139, Loss: 0.42451112622978115\n",
      "Epoch 140, Loss: 0.42367987083389874\n",
      "Epoch 141, Loss: 0.42296128468289707\n",
      "Epoch 142, Loss: 0.422448457276946\n",
      "Epoch 143, Loss: 0.4219377082560877\n",
      "Epoch 144, Loss: 0.42123307734606913\n",
      "Epoch 145, Loss: 0.42057672937828217\n",
      "Epoch 146, Loss: 0.42006789041927756\n",
      "Epoch 147, Loss: 0.4195637617531211\n",
      "Epoch 148, Loss: 0.4189762913203113\n",
      "Epoch 149, Loss: 0.4183685315979562\n",
      "Epoch 150, Loss: 0.4178117653348822\n",
      "Epoch 151, Loss: 0.417285556913541\n",
      "Epoch 152, Loss: 0.4168194272233172\n",
      "Epoch 153, Loss: 0.4163404817155836\n",
      "Epoch 154, Loss: 0.4157401592216273\n",
      "Epoch 155, Loss: 0.41506320658748425\n",
      "Epoch 156, Loss: 0.4144600633045843\n",
      "Epoch 157, Loss: 0.41398870062381415\n",
      "Epoch 158, Loss: 0.41354539358668074\n",
      "Epoch 159, Loss: 0.41303929275240464\n",
      "Epoch 160, Loss: 0.4124444078785205\n",
      "Epoch 161, Loss: 0.4118386414359618\n",
      "Epoch 162, Loss: 0.4113186848744509\n",
      "Epoch 163, Loss: 0.4108915005890821\n",
      "Epoch 164, Loss: 0.4105118436231564\n",
      "Epoch 165, Loss: 0.4101412815814067\n",
      "Epoch 166, Loss: 0.40974898327252696\n",
      "Epoch 167, Loss: 0.4091579094601616\n",
      "Epoch 168, Loss: 0.40852928820150464\n",
      "Epoch 169, Loss: 0.4080573738934195\n",
      "Epoch 170, Loss: 0.40776951588903615\n",
      "Epoch 171, Loss: 0.4075239454149638\n",
      "Epoch 172, Loss: 0.4071083537637789\n",
      "Epoch 173, Loss: 0.40655452978486295\n",
      "Epoch 174, Loss: 0.40597227580445383\n",
      "Epoch 175, Loss: 0.4056032240772393\n",
      "Epoch 176, Loss: 0.40538148473822017\n",
      "Epoch 177, Loss: 0.40506457726420203\n",
      "Epoch 178, Loss: 0.40464008893105163\n",
      "Epoch 179, Loss: 0.40408771282816686\n",
      "Epoch 180, Loss: 0.40362166260573784\n",
      "Epoch 181, Loss: 0.4032728892379366\n",
      "Epoch 182, Loss: 0.40297175902906857\n",
      "Epoch 183, Loss: 0.4026672581154909\n",
      "Epoch 184, Loss: 0.40230087866657555\n",
      "Epoch 185, Loss: 0.40189121314488074\n",
      "Epoch 186, Loss: 0.4013907432604982\n",
      "Epoch 187, Loss: 0.4009338787269139\n",
      "Epoch 188, Loss: 0.40054688544633293\n",
      "Epoch 189, Loss: 0.400254873197245\n",
      "Epoch 190, Loss: 0.4000600054555415\n",
      "Epoch 191, Loss: 0.3999110815935751\n",
      "Epoch 192, Loss: 0.39984689404949775\n",
      "Epoch 193, Loss: 0.3993338058908837\n",
      "Epoch 194, Loss: 0.39854237167381124\n",
      "Epoch 195, Loss: 0.39802601079194877\n",
      "Epoch 196, Loss: 0.39795099737787915\n",
      "Epoch 197, Loss: 0.3978051422109949\n",
      "Epoch 198, Loss: 0.3972024287817995\n",
      "Epoch 199, Loss: 0.3965880911335219\n",
      "Epoch 200, Loss: 0.3961592595629367\n",
      "Epoch 201, Loss: 0.3959403416231307\n",
      "Epoch 202, Loss: 0.3957749959554715\n",
      "Epoch 203, Loss: 0.3954719809796194\n",
      "Epoch 204, Loss: 0.3950632304574242\n",
      "Epoch 205, Loss: 0.39460640370895406\n",
      "Epoch 206, Loss: 0.39420707528104726\n",
      "Epoch 207, Loss: 0.3938999034486833\n",
      "Epoch 208, Loss: 0.39368584201001544\n",
      "Epoch 209, Loss: 0.39346232880533694\n",
      "Epoch 210, Loss: 0.393229082457005\n",
      "Epoch 211, Loss: 0.39302170777731216\n",
      "Epoch 212, Loss: 0.39278573387318777\n",
      "Epoch 213, Loss: 0.3926157957004346\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.23906810696320066\n",
      "Test R^2 score: 0.38394629414458303\n",
      "Num of epochs: 214\n",
      "Epoch 1, Loss: 0.5603338228796947\n",
      "Epoch 2, Loss: 0.5592794411301689\n",
      "Epoch 3, Loss: 0.5583949235376602\n",
      "Epoch 4, Loss: 0.5576878651522961\n",
      "Epoch 5, Loss: 0.5571609474483489\n",
      "Epoch 6, Loss: 0.5567683558562077\n",
      "Epoch 7, Loss: 0.5564929967167106\n",
      "Epoch 8, Loss: 0.5563187053125624\n",
      "Epoch 9, Loss: 0.5562139113645622\n",
      "Epoch 10, Loss: 0.5561633021051233\n",
      "Epoch 11, Loss: 0.5561465295717128\n",
      "Epoch 12, Loss: 0.5561433411255554\n",
      "Epoch 13, Loss: 0.5561379287633362\n",
      "Epoch 14, Loss: 0.5561200300814731\n",
      "Epoch 15, Loss: 0.5560825428016943\n",
      "Epoch 16, Loss: 0.5560195938575452\n",
      "Epoch 17, Loss: 0.5559271807943166\n",
      "Epoch 18, Loss: 0.55580177678898\n",
      "Epoch 19, Loss: 0.5556408922563754\n",
      "Epoch 20, Loss: 0.5554443085734893\n",
      "Epoch 21, Loss: 0.5552116657560252\n",
      "Epoch 22, Loss: 0.5549423008644611\n",
      "Epoch 23, Loss: 0.5546366439931373\n",
      "Epoch 24, Loss: 0.5542960867899693\n",
      "Epoch 25, Loss: 0.5539208876985233\n",
      "Epoch 26, Loss: 0.553508041857542\n",
      "Epoch 27, Loss: 0.5530569799809251\n",
      "Epoch 28, Loss: 0.5525522909404652\n",
      "Epoch 29, Loss: 0.5519701253833577\n",
      "Epoch 30, Loss: 0.5512791540693016\n",
      "Epoch 31, Loss: 0.5504524385762607\n",
      "Epoch 32, Loss: 0.5494694339800226\n",
      "Epoch 33, Loss: 0.5483305769805659\n",
      "Epoch 34, Loss: 0.5470225543824054\n",
      "Epoch 35, Loss: 0.5455114531813818\n",
      "Epoch 36, Loss: 0.5437539823978206\n",
      "Epoch 37, Loss: 0.5417305254584758\n",
      "Epoch 38, Loss: 0.5393494933938904\n",
      "Epoch 39, Loss: 0.5364785946720289\n",
      "Epoch 40, Loss: 0.5329843987745625\n",
      "Epoch 41, Loss: 0.5287566014141547\n",
      "Epoch 42, Loss: 0.5237108911557083\n",
      "Epoch 43, Loss: 0.5178513003945218\n",
      "Epoch 44, Loss: 0.5113867345082267\n",
      "Epoch 45, Loss: 0.5052455875255015\n",
      "Epoch 46, Loss: 0.5006613827461267\n",
      "Epoch 47, Loss: 0.49909636679377695\n",
      "Epoch 48, Loss: 0.49992832027667483\n",
      "Epoch 49, Loss: 0.4985171472657418\n",
      "Epoch 50, Loss: 0.49449207036205095\n",
      "Epoch 51, Loss: 0.490159047939303\n",
      "Epoch 52, Loss: 0.4872443213369237\n",
      "Epoch 53, Loss: 0.4857992644112437\n",
      "Epoch 54, Loss: 0.4848780173591101\n",
      "Epoch 55, Loss: 0.4835571336826866\n",
      "Epoch 56, Loss: 0.4815357115644873\n",
      "Epoch 57, Loss: 0.4789300019688961\n",
      "Epoch 58, Loss: 0.47627775096390174\n",
      "Epoch 59, Loss: 0.47408430465513357\n",
      "Epoch 60, Loss: 0.47290048515543387\n",
      "Epoch 61, Loss: 0.47237558149719383\n",
      "Epoch 62, Loss: 0.4715436656368301\n",
      "Epoch 63, Loss: 0.4701416497389723\n",
      "Epoch 64, Loss: 0.46857770296395995\n",
      "Epoch 65, Loss: 0.4671334685144183\n",
      "Epoch 66, Loss: 0.4660069473622588\n",
      "Epoch 67, Loss: 0.4646238880960062\n",
      "Epoch 68, Loss: 0.46335948264249877\n",
      "Epoch 69, Loss: 0.46263972053515434\n",
      "Epoch 70, Loss: 0.4619975105379583\n",
      "Epoch 71, Loss: 0.46112779148442956\n",
      "Epoch 72, Loss: 0.4601203496429059\n",
      "Epoch 73, Loss: 0.45926750054133997\n",
      "Epoch 74, Loss: 0.4586938953393035\n",
      "Epoch 75, Loss: 0.4581832387109681\n",
      "Epoch 76, Loss: 0.45746538132874076\n",
      "Epoch 77, Loss: 0.4566912731475765\n",
      "Epoch 78, Loss: 0.4561282472283191\n",
      "Epoch 79, Loss: 0.4556799089968599\n",
      "Epoch 80, Loss: 0.4551495835680032\n",
      "Epoch 81, Loss: 0.45451839553422413\n",
      "Epoch 82, Loss: 0.4538643658431522\n",
      "Epoch 83, Loss: 0.45320388501910275\n",
      "Epoch 84, Loss: 0.45255431049524897\n",
      "Epoch 85, Loss: 0.4519915875130969\n",
      "Epoch 86, Loss: 0.45145633531887314\n",
      "Epoch 87, Loss: 0.45088548364235226\n",
      "Epoch 88, Loss: 0.4502922830801885\n",
      "Epoch 89, Loss: 0.4497374483936604\n",
      "Epoch 90, Loss: 0.44921122005620084\n",
      "Epoch 91, Loss: 0.4486989538439429\n",
      "Epoch 92, Loss: 0.44816909559787343\n",
      "Epoch 93, Loss: 0.44762392975935705\n",
      "Epoch 94, Loss: 0.4471013462932865\n",
      "Epoch 95, Loss: 0.44654618416965713\n",
      "Epoch 96, Loss: 0.4459611618832394\n",
      "Epoch 97, Loss: 0.44539892462261\n",
      "Epoch 98, Loss: 0.4448442339450681\n",
      "Epoch 99, Loss: 0.4442499098447623\n",
      "Epoch 100, Loss: 0.44363843227225214\n",
      "Epoch 101, Loss: 0.4430266152453141\n",
      "Epoch 102, Loss: 0.4424023655492319\n",
      "Epoch 103, Loss: 0.4417668785212624\n",
      "Epoch 104, Loss: 0.4411273851857136\n",
      "Epoch 105, Loss: 0.44048496753706495\n",
      "Epoch 106, Loss: 0.4398280938785524\n",
      "Epoch 107, Loss: 0.4391856248293597\n",
      "Epoch 108, Loss: 0.43854933306893723\n",
      "Epoch 109, Loss: 0.43789437094182776\n",
      "Epoch 110, Loss: 0.43724797005833776\n",
      "Epoch 111, Loss: 0.43658672104465474\n",
      "Epoch 112, Loss: 0.43589392550235884\n",
      "Epoch 113, Loss: 0.4351695354905976\n",
      "Epoch 114, Loss: 0.4344018502478774\n",
      "Epoch 115, Loss: 0.433646551130539\n",
      "Epoch 116, Loss: 0.43290106972302056\n",
      "Epoch 117, Loss: 0.432134785585225\n",
      "Epoch 118, Loss: 0.4313508178512162\n",
      "Epoch 119, Loss: 0.4305845433734901\n",
      "Epoch 120, Loss: 0.4298266792304943\n",
      "Epoch 121, Loss: 0.4290823923932756\n",
      "Epoch 122, Loss: 0.428365824830169\n",
      "Epoch 123, Loss: 0.4276821853639731\n",
      "Epoch 124, Loss: 0.4270524289029375\n",
      "Epoch 125, Loss: 0.4265712443702577\n",
      "Epoch 126, Loss: 0.4263138545917577\n",
      "Epoch 127, Loss: 0.42538988868222294\n",
      "Epoch 128, Loss: 0.4242296558193656\n",
      "Epoch 129, Loss: 0.4238097367055255\n",
      "Epoch 130, Loss: 0.42322909304541284\n",
      "Epoch 131, Loss: 0.4222081599626543\n",
      "Epoch 132, Loss: 0.4216834445801897\n",
      "Epoch 133, Loss: 0.42125345290945065\n",
      "Epoch 134, Loss: 0.4203831645173855\n",
      "Epoch 135, Loss: 0.41974155191572937\n",
      "Epoch 136, Loss: 0.41934352347304377\n",
      "Epoch 137, Loss: 0.4186594416784348\n",
      "Epoch 138, Loss: 0.41797220816919645\n",
      "Epoch 139, Loss: 0.41749703000776855\n",
      "Epoch 140, Loss: 0.41699806584451676\n",
      "Epoch 141, Loss: 0.4162953112687085\n",
      "Epoch 142, Loss: 0.4156505433457952\n",
      "Epoch 143, Loss: 0.41513683289477193\n",
      "Epoch 144, Loss: 0.41466350842478816\n",
      "Epoch 145, Loss: 0.41413407336933666\n",
      "Epoch 146, Loss: 0.41353894368131194\n",
      "Epoch 147, Loss: 0.41289734198845773\n",
      "Epoch 148, Loss: 0.4122693262156366\n",
      "Epoch 149, Loss: 0.4116734553979405\n",
      "Epoch 150, Loss: 0.4111303660122893\n",
      "Epoch 151, Loss: 0.41065913660881\n",
      "Epoch 152, Loss: 0.4104491323452372\n",
      "Epoch 153, Loss: 0.4109261870186804\n",
      "Epoch 154, Loss: 0.41198186121982555\n",
      "Epoch 155, Loss: 0.40937978727147784\n",
      "Epoch 156, Loss: 0.40803135447425204\n",
      "Epoch 157, Loss: 0.409267042936523\n",
      "Epoch 158, Loss: 0.4072119986950975\n",
      "Epoch 159, Loss: 0.4068615235530112\n",
      "Epoch 160, Loss: 0.4071442591791225\n",
      "Epoch 161, Loss: 0.40546883158600266\n",
      "Epoch 162, Loss: 0.405741666993828\n",
      "Epoch 163, Loss: 0.40562635015959486\n",
      "Epoch 164, Loss: 0.4041537155783341\n",
      "Epoch 165, Loss: 0.40464830098249743\n",
      "Epoch 166, Loss: 0.40415161398093774\n",
      "Epoch 167, Loss: 0.40286236273119247\n",
      "Epoch 168, Loss: 0.4034147175177914\n",
      "Epoch 169, Loss: 0.40260152984518927\n",
      "Epoch 170, Loss: 0.4016658664763989\n",
      "Epoch 171, Loss: 0.40201636763127546\n",
      "Epoch 172, Loss: 0.4013343296384537\n",
      "Epoch 173, Loss: 0.4004275793374148\n",
      "Epoch 174, Loss: 0.4007519092193073\n",
      "Epoch 175, Loss: 0.4001394833318292\n",
      "Epoch 176, Loss: 0.399211375099339\n",
      "Epoch 177, Loss: 0.39931882361699317\n",
      "Epoch 178, Loss: 0.3990697892612892\n",
      "Epoch 179, Loss: 0.3980145921428312\n",
      "Epoch 180, Loss: 0.3977791264717288\n",
      "Epoch 181, Loss: 0.39783276685344915\n",
      "Epoch 182, Loss: 0.39712604032193505\n",
      "Epoch 183, Loss: 0.3963892592418954\n",
      "Epoch 184, Loss: 0.39624303604047456\n",
      "Epoch 185, Loss: 0.3960527221980077\n",
      "Epoch 186, Loss: 0.39554450724354745\n",
      "Epoch 187, Loss: 0.39494179619747755\n",
      "Epoch 188, Loss: 0.3945660717393273\n",
      "Epoch 189, Loss: 0.3944554019952167\n",
      "Epoch 190, Loss: 0.3942927215460207\n",
      "Epoch 191, Loss: 0.39394775526039294\n",
      "Epoch 192, Loss: 0.3933231628781436\n",
      "Epoch 193, Loss: 0.3927418761090018\n",
      "Epoch 194, Loss: 0.39228094059276997\n",
      "Epoch 195, Loss: 0.39194752923941223\n",
      "Epoch 196, Loss: 0.3917394951651646\n",
      "Epoch 197, Loss: 0.3917331236738324\n",
      "Epoch 198, Loss: 0.39214352136975567\n",
      "Epoch 199, Loss: 0.39263118556122567\n",
      "Epoch 200, Loss: 0.39297046319728407\n",
      "Epoch 201, Loss: 0.39118217785346476\n",
      "Epoch 202, Loss: 0.3896762579831217\n",
      "Epoch 203, Loss: 0.3896897564159614\n",
      "Epoch 204, Loss: 0.39017109248016507\n",
      "Epoch 205, Loss: 0.3897978226205992\n",
      "Epoch 206, Loss: 0.3885665060631117\n",
      "Epoch 207, Loss: 0.3882752508241117\n",
      "Epoch 208, Loss: 0.38872226790961467\n",
      "Epoch 209, Loss: 0.3884198315653871\n",
      "Epoch 210, Loss: 0.38761835751812956\n",
      "Epoch 211, Loss: 0.38692095315681146\n",
      "Epoch 212, Loss: 0.38674568313675006\n",
      "Epoch 213, Loss: 0.3868484664840251\n",
      "Epoch 214, Loss: 0.3869047584551158\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.23407379672099096\n",
      "Test R^2 score: 0.40612950883717674\n",
      "Num of epochs: 215\n",
      "Epoch 1, Loss: 0.5576305220791645\n",
      "Epoch 2, Loss: 0.55721200094307\n",
      "Epoch 3, Loss: 0.5568728046395369\n",
      "Epoch 4, Loss: 0.5566222070692005\n",
      "Epoch 5, Loss: 0.5564435643509745\n",
      "Epoch 6, Loss: 0.5563255623060808\n",
      "Epoch 7, Loss: 0.5562544972527256\n",
      "Epoch 8, Loss: 0.5562180638521507\n",
      "Epoch 9, Loss: 0.5562057134593409\n",
      "Epoch 10, Loss: 0.5562066511343585\n",
      "Epoch 11, Loss: 0.5562130540729413\n",
      "Epoch 12, Loss: 0.556218787185528\n",
      "Epoch 13, Loss: 0.556220046319163\n",
      "Epoch 14, Loss: 0.5562146614936466\n",
      "Epoch 15, Loss: 0.5562020699071244\n",
      "Epoch 16, Loss: 0.5561802616765055\n",
      "Epoch 17, Loss: 0.5561499055536024\n",
      "Epoch 18, Loss: 0.5561098747348707\n",
      "Epoch 19, Loss: 0.5560595775800575\n",
      "Epoch 20, Loss: 0.5559983144844359\n",
      "Epoch 21, Loss: 0.5559252776956874\n",
      "Epoch 22, Loss: 0.5558329561862305\n",
      "Epoch 23, Loss: 0.555707638176662\n",
      "Epoch 24, Loss: 0.5555575625727746\n",
      "Epoch 25, Loss: 0.5553823336783102\n",
      "Epoch 26, Loss: 0.5551772306317657\n",
      "Epoch 27, Loss: 0.5549416832743123\n",
      "Epoch 28, Loss: 0.5546759483316572\n",
      "Epoch 29, Loss: 0.5543632903039689\n",
      "Epoch 30, Loss: 0.553971917008696\n",
      "Epoch 31, Loss: 0.5534784007023414\n",
      "Epoch 32, Loss: 0.5528655688408364\n",
      "Epoch 33, Loss: 0.5521206363335402\n",
      "Epoch 34, Loss: 0.5512168190067668\n",
      "Epoch 35, Loss: 0.5501057425632115\n",
      "Epoch 36, Loss: 0.5487375150663638\n",
      "Epoch 37, Loss: 0.5470638766415801\n",
      "Epoch 38, Loss: 0.5449992572709368\n",
      "Epoch 39, Loss: 0.5424534939463798\n",
      "Epoch 40, Loss: 0.5393652411381431\n",
      "Epoch 41, Loss: 0.5357253118924343\n",
      "Epoch 42, Loss: 0.5315677870409565\n",
      "Epoch 43, Loss: 0.5269829257374318\n",
      "Epoch 44, Loss: 0.5222240445711701\n",
      "Epoch 45, Loss: 0.5178965614612758\n",
      "Epoch 46, Loss: 0.5148549253787739\n",
      "Epoch 47, Loss: 0.5135233559223115\n",
      "Epoch 48, Loss: 0.5123952805134251\n",
      "Epoch 49, Loss: 0.509849687565686\n",
      "Epoch 50, Loss: 0.5064306678522973\n",
      "Epoch 51, Loss: 0.5034403162379615\n",
      "Epoch 52, Loss: 0.5015967621791565\n",
      "Epoch 53, Loss: 0.5004070830188436\n",
      "Epoch 54, Loss: 0.49882949972299345\n",
      "Epoch 55, Loss: 0.4964550084658932\n",
      "Epoch 56, Loss: 0.49350395953359144\n",
      "Epoch 57, Loss: 0.4907005343029455\n",
      "Epoch 58, Loss: 0.48874788493603677\n",
      "Epoch 59, Loss: 0.4873162614139778\n",
      "Epoch 60, Loss: 0.4855488428028401\n",
      "Epoch 61, Loss: 0.4830470031066853\n",
      "Epoch 62, Loss: 0.4803437946625559\n",
      "Epoch 63, Loss: 0.47836108144941397\n",
      "Epoch 64, Loss: 0.47696045378631896\n",
      "Epoch 65, Loss: 0.4755799686754469\n",
      "Epoch 66, Loss: 0.4737700116150811\n",
      "Epoch 67, Loss: 0.471841077658927\n",
      "Epoch 68, Loss: 0.47042534573806793\n",
      "Epoch 69, Loss: 0.46927071894885275\n",
      "Epoch 70, Loss: 0.46776700264281584\n",
      "Epoch 71, Loss: 0.46607358113257935\n",
      "Epoch 72, Loss: 0.46478772827570436\n",
      "Epoch 73, Loss: 0.4637075530982614\n",
      "Epoch 74, Loss: 0.4623535839503362\n",
      "Epoch 75, Loss: 0.46101207453167475\n",
      "Epoch 76, Loss: 0.46003132988137596\n",
      "Epoch 77, Loss: 0.45913640203216666\n",
      "Epoch 78, Loss: 0.45803221289864093\n",
      "Epoch 79, Loss: 0.45701755600978794\n",
      "Epoch 80, Loss: 0.4562353719691723\n",
      "Epoch 81, Loss: 0.4553859799066852\n",
      "Epoch 82, Loss: 0.4544552809775777\n",
      "Epoch 83, Loss: 0.4537447604357647\n",
      "Epoch 84, Loss: 0.45311372019441326\n",
      "Epoch 85, Loss: 0.4523459511869698\n",
      "Epoch 86, Loss: 0.4516061616532562\n",
      "Epoch 87, Loss: 0.4508250501169073\n",
      "Epoch 88, Loss: 0.4497526064962078\n",
      "Epoch 89, Loss: 0.4486121186601697\n",
      "Epoch 90, Loss: 0.4475004420997524\n",
      "Epoch 91, Loss: 0.446263936543759\n",
      "Epoch 92, Loss: 0.4451862624747125\n",
      "Epoch 93, Loss: 0.4442532640615241\n",
      "Epoch 94, Loss: 0.443262097950412\n",
      "Epoch 95, Loss: 0.44237528409299326\n",
      "Epoch 96, Loss: 0.44134254333421896\n",
      "Epoch 97, Loss: 0.44038218307592253\n",
      "Epoch 98, Loss: 0.439279920565272\n",
      "Epoch 99, Loss: 0.4382428436315188\n",
      "Epoch 100, Loss: 0.43715131011338115\n",
      "Epoch 101, Loss: 0.43628033860417914\n",
      "Epoch 102, Loss: 0.43536785535073025\n",
      "Epoch 103, Loss: 0.4345096674404437\n",
      "Epoch 104, Loss: 0.4335551201735469\n",
      "Epoch 105, Loss: 0.4325307583207689\n",
      "Epoch 106, Loss: 0.43164166066317355\n",
      "Epoch 107, Loss: 0.4307584940171942\n",
      "Epoch 108, Loss: 0.4298756620929452\n",
      "Epoch 109, Loss: 0.42909133475281436\n",
      "Epoch 110, Loss: 0.42825607813136646\n",
      "Epoch 111, Loss: 0.427362358622603\n",
      "Epoch 112, Loss: 0.42653676468903995\n",
      "Epoch 113, Loss: 0.4257785552053305\n",
      "Epoch 114, Loss: 0.42502937075161124\n",
      "Epoch 115, Loss: 0.4242598448742347\n",
      "Epoch 116, Loss: 0.42352444013109686\n",
      "Epoch 117, Loss: 0.4228331141158666\n",
      "Epoch 118, Loss: 0.42227955247352505\n",
      "Epoch 119, Loss: 0.421674928201\n",
      "Epoch 120, Loss: 0.42087029099669554\n",
      "Epoch 121, Loss: 0.4199014348222929\n",
      "Epoch 122, Loss: 0.41920681774718666\n",
      "Epoch 123, Loss: 0.418801325172042\n",
      "Epoch 124, Loss: 0.4184528470803884\n",
      "Epoch 125, Loss: 0.4178017790794842\n",
      "Epoch 126, Loss: 0.41679243534086785\n",
      "Epoch 127, Loss: 0.41602925381252837\n",
      "Epoch 128, Loss: 0.4156343745845114\n",
      "Epoch 129, Loss: 0.41533388325313964\n",
      "Epoch 130, Loss: 0.41478369542153076\n",
      "Epoch 131, Loss: 0.4138847725387596\n",
      "Epoch 132, Loss: 0.4130421969295133\n",
      "Epoch 133, Loss: 0.4125087303624914\n",
      "Epoch 134, Loss: 0.41218819248699473\n",
      "Epoch 135, Loss: 0.4118780417901626\n",
      "Epoch 136, Loss: 0.41136650275927866\n",
      "Epoch 137, Loss: 0.4106438780789618\n",
      "Epoch 138, Loss: 0.40981185623195177\n",
      "Epoch 139, Loss: 0.40918094389001064\n",
      "Epoch 140, Loss: 0.40878012365345384\n",
      "Epoch 141, Loss: 0.4085677494215444\n",
      "Epoch 142, Loss: 0.4086138470523043\n",
      "Epoch 143, Loss: 0.40852233962907486\n",
      "Epoch 144, Loss: 0.40780169081704565\n",
      "Epoch 145, Loss: 0.40635525733679473\n",
      "Epoch 146, Loss: 0.40576693351323384\n",
      "Epoch 147, Loss: 0.40601099759977755\n",
      "Epoch 148, Loss: 0.4057021298130934\n",
      "Epoch 149, Loss: 0.4046537878656984\n",
      "Epoch 150, Loss: 0.4037865813781437\n",
      "Epoch 151, Loss: 0.40372081388324954\n",
      "Epoch 152, Loss: 0.4037080614257888\n",
      "Epoch 153, Loss: 0.403027203991743\n",
      "Epoch 154, Loss: 0.40207589131058263\n",
      "Epoch 155, Loss: 0.40150911369645087\n",
      "Epoch 156, Loss: 0.4014216847791426\n",
      "Epoch 157, Loss: 0.4015025817757207\n",
      "Epoch 158, Loss: 0.4011701113950897\n",
      "Epoch 159, Loss: 0.40043686390423316\n",
      "Epoch 160, Loss: 0.3995327015515851\n",
      "Epoch 161, Loss: 0.3990307486560321\n",
      "Epoch 162, Loss: 0.39893734190308866\n",
      "Epoch 163, Loss: 0.39893536223505593\n",
      "Epoch 164, Loss: 0.3987632242838023\n",
      "Epoch 165, Loss: 0.39820670006703696\n",
      "Epoch 166, Loss: 0.3974774144012063\n",
      "Epoch 167, Loss: 0.3968793470790412\n",
      "Epoch 168, Loss: 0.39652398573974973\n",
      "Epoch 169, Loss: 0.39639792415910674\n",
      "Epoch 170, Loss: 0.3964363031418878\n",
      "Epoch 171, Loss: 0.3966581593263697\n",
      "Epoch 172, Loss: 0.39675202754848093\n",
      "Epoch 173, Loss: 0.396502903096658\n",
      "Epoch 174, Loss: 0.3953158442540499\n",
      "Epoch 175, Loss: 0.3942339693050513\n",
      "Epoch 176, Loss: 0.39400280602419285\n",
      "Epoch 177, Loss: 0.3943230485628299\n",
      "Epoch 178, Loss: 0.39442160943060944\n",
      "Epoch 179, Loss: 0.39366983097103697\n",
      "Epoch 180, Loss: 0.39272301880000854\n",
      "Epoch 181, Loss: 0.3921760283840341\n",
      "Epoch 182, Loss: 0.39213747944185645\n",
      "Epoch 183, Loss: 0.39231334126351736\n",
      "Epoch 184, Loss: 0.39239558440746447\n",
      "Epoch 185, Loss: 0.3921309434150303\n",
      "Epoch 186, Loss: 0.3914080591217079\n",
      "Epoch 187, Loss: 0.3905426701569079\n",
      "Epoch 188, Loss: 0.3899774715751456\n",
      "Epoch 189, Loss: 0.3898010719805207\n",
      "Epoch 190, Loss: 0.3898942406319733\n",
      "Epoch 191, Loss: 0.390144185745531\n",
      "Epoch 192, Loss: 0.39031770062856885\n",
      "Epoch 193, Loss: 0.3902006323720304\n",
      "Epoch 194, Loss: 0.3896363717794812\n",
      "Epoch 195, Loss: 0.38867747240492884\n",
      "Epoch 196, Loss: 0.38779363658562216\n",
      "Epoch 197, Loss: 0.3875297365776578\n",
      "Epoch 198, Loss: 0.38779246460635197\n",
      "Epoch 199, Loss: 0.3881075418695378\n",
      "Epoch 200, Loss: 0.38808959206644383\n",
      "Epoch 201, Loss: 0.3877605700401821\n",
      "Epoch 202, Loss: 0.38690081077346783\n",
      "Epoch 203, Loss: 0.38608257871897544\n",
      "Epoch 204, Loss: 0.3857620813575575\n",
      "Epoch 205, Loss: 0.38590733336879585\n",
      "Epoch 206, Loss: 0.38633379416168107\n",
      "Epoch 207, Loss: 0.38667017699092443\n",
      "Epoch 208, Loss: 0.38694715979337585\n",
      "Epoch 209, Loss: 0.38599866235703856\n",
      "Epoch 210, Loss: 0.38485515346815996\n",
      "Epoch 211, Loss: 0.38415895841496034\n",
      "Epoch 212, Loss: 0.38434785343854555\n",
      "Epoch 213, Loss: 0.3850327934195191\n",
      "Epoch 214, Loss: 0.3852228072345718\n",
      "Epoch 215, Loss: 0.38456341227264046\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.23805524523374444\n",
      "Test R^2 score: 0.38584155163007455\n",
      "Num of epochs: 216\n",
      "Epoch 1, Loss: 0.5670109119273543\n",
      "Epoch 2, Loss: 0.5659928227077391\n",
      "Epoch 3, Loss: 0.5650414697231226\n",
      "Epoch 4, Loss: 0.5641657747950001\n",
      "Epoch 5, Loss: 0.5633408831009583\n",
      "Epoch 6, Loss: 0.5625663824118036\n",
      "Epoch 7, Loss: 0.5618416854605746\n",
      "Epoch 8, Loss: 0.5611723756104172\n",
      "Epoch 9, Loss: 0.5605675298095323\n",
      "Epoch 10, Loss: 0.5600138665509041\n",
      "Epoch 11, Loss: 0.559508927791366\n",
      "Epoch 12, Loss: 0.5590425835564695\n",
      "Epoch 13, Loss: 0.5586131966146908\n",
      "Epoch 14, Loss: 0.5582195709347194\n",
      "Epoch 15, Loss: 0.5578604199425047\n",
      "Epoch 16, Loss: 0.5575490398819835\n",
      "Epoch 17, Loss: 0.557280216515346\n",
      "Epoch 18, Loss: 0.5570367039738503\n",
      "Epoch 19, Loss: 0.5568187227936561\n",
      "Epoch 20, Loss: 0.5566272667068324\n",
      "Epoch 21, Loss: 0.5564618275241219\n",
      "Epoch 22, Loss: 0.5563223481008924\n",
      "Epoch 23, Loss: 0.5562205821198454\n",
      "Epoch 24, Loss: 0.5561343115612012\n",
      "Epoch 25, Loss: 0.5560546199690011\n",
      "Epoch 26, Loss: 0.5559777043403967\n",
      "Epoch 27, Loss: 0.5559061927407242\n",
      "Epoch 28, Loss: 0.555834725557878\n",
      "Epoch 29, Loss: 0.5557576990593848\n",
      "Epoch 30, Loss: 0.5556666637286022\n",
      "Epoch 31, Loss: 0.5555465386241741\n",
      "Epoch 32, Loss: 0.5553902754364652\n",
      "Epoch 33, Loss: 0.5551851484838739\n",
      "Epoch 34, Loss: 0.5549186439855112\n",
      "Epoch 35, Loss: 0.5545776688276667\n",
      "Epoch 36, Loss: 0.5541420255885595\n",
      "Epoch 37, Loss: 0.5535765523497606\n",
      "Epoch 38, Loss: 0.552846000911328\n",
      "Epoch 39, Loss: 0.5519322752473641\n",
      "Epoch 40, Loss: 0.5507547358630904\n",
      "Epoch 41, Loss: 0.5492373803832908\n",
      "Epoch 42, Loss: 0.5473042029997442\n",
      "Epoch 43, Loss: 0.5448835626075084\n",
      "Epoch 44, Loss: 0.5418908651684733\n",
      "Epoch 45, Loss: 0.5382580490538119\n",
      "Epoch 46, Loss: 0.534012400429579\n",
      "Epoch 47, Loss: 0.5293368785422744\n",
      "Epoch 48, Loss: 0.5247327237749702\n",
      "Epoch 49, Loss: 0.5211905462448404\n",
      "Epoch 50, Loss: 0.5197416754198603\n",
      "Epoch 51, Loss: 0.5194032841313106\n",
      "Epoch 52, Loss: 0.5172547391763793\n",
      "Epoch 53, Loss: 0.5134468310872866\n",
      "Epoch 54, Loss: 0.5099151508956917\n",
      "Epoch 55, Loss: 0.5077236684717213\n",
      "Epoch 56, Loss: 0.5064966613418488\n",
      "Epoch 57, Loss: 0.5055078883399845\n",
      "Epoch 58, Loss: 0.5038939777624571\n",
      "Epoch 59, Loss: 0.5015512780095748\n",
      "Epoch 60, Loss: 0.4988632542272381\n",
      "Epoch 61, Loss: 0.4964700758320774\n",
      "Epoch 62, Loss: 0.49490568620780084\n",
      "Epoch 63, Loss: 0.4939461577963695\n",
      "Epoch 64, Loss: 0.4926017350203842\n",
      "Epoch 65, Loss: 0.4904692493738778\n",
      "Epoch 66, Loss: 0.4881935498633523\n",
      "Epoch 67, Loss: 0.48649572831814125\n",
      "Epoch 68, Loss: 0.485402908525881\n",
      "Epoch 69, Loss: 0.4843821986494123\n",
      "Epoch 70, Loss: 0.48302863261650253\n",
      "Epoch 71, Loss: 0.48138620814645633\n",
      "Epoch 72, Loss: 0.4797740193477291\n",
      "Epoch 73, Loss: 0.4783888045433107\n",
      "Epoch 74, Loss: 0.47701965355420733\n",
      "Epoch 75, Loss: 0.4754378854021135\n",
      "Epoch 76, Loss: 0.4738922666957504\n",
      "Epoch 77, Loss: 0.4727077140848882\n",
      "Epoch 78, Loss: 0.4716945669540219\n",
      "Epoch 79, Loss: 0.4705190813196497\n",
      "Epoch 80, Loss: 0.4691624892807138\n",
      "Epoch 81, Loss: 0.4679139629001692\n",
      "Epoch 82, Loss: 0.46681401688133556\n",
      "Epoch 83, Loss: 0.4656283224870565\n",
      "Epoch 84, Loss: 0.4643411724404896\n",
      "Epoch 85, Loss: 0.4631390126485555\n",
      "Epoch 86, Loss: 0.4620022840711767\n",
      "Epoch 87, Loss: 0.46077605830877133\n",
      "Epoch 88, Loss: 0.45951363100104825\n",
      "Epoch 89, Loss: 0.458405994666682\n",
      "Epoch 90, Loss: 0.45741620927619736\n",
      "Epoch 91, Loss: 0.4564907431692818\n",
      "Epoch 92, Loss: 0.4558464408026767\n",
      "Epoch 93, Loss: 0.4554566704013572\n",
      "Epoch 94, Loss: 0.45518176490829887\n",
      "Epoch 95, Loss: 0.45480828204917795\n",
      "Epoch 96, Loss: 0.45415845945216266\n",
      "Epoch 97, Loss: 0.45335693014255773\n",
      "Epoch 98, Loss: 0.45258863537313815\n",
      "Epoch 99, Loss: 0.45202129051083517\n",
      "Epoch 100, Loss: 0.4514983346090937\n",
      "Epoch 101, Loss: 0.45102603421274245\n",
      "Epoch 102, Loss: 0.45059442929656446\n",
      "Epoch 103, Loss: 0.4501785804800198\n",
      "Epoch 104, Loss: 0.44971324406908025\n",
      "Epoch 105, Loss: 0.4491960602710684\n",
      "Epoch 106, Loss: 0.4486284773089445\n",
      "Epoch 107, Loss: 0.4480548874555162\n",
      "Epoch 108, Loss: 0.44747368583351954\n",
      "Epoch 109, Loss: 0.4468681534996283\n",
      "Epoch 110, Loss: 0.446285974003562\n",
      "Epoch 111, Loss: 0.4457699450621449\n",
      "Epoch 112, Loss: 0.4452792540069185\n",
      "Epoch 113, Loss: 0.444722772246214\n",
      "Epoch 114, Loss: 0.44412127329354967\n",
      "Epoch 115, Loss: 0.44348522534322665\n",
      "Epoch 116, Loss: 0.442854505604701\n",
      "Epoch 117, Loss: 0.44224354149570055\n",
      "Epoch 118, Loss: 0.4416178305935019\n",
      "Epoch 119, Loss: 0.4410223684141687\n",
      "Epoch 120, Loss: 0.4404732963811829\n",
      "Epoch 121, Loss: 0.4398877008408872\n",
      "Epoch 122, Loss: 0.4392818541030437\n",
      "Epoch 123, Loss: 0.4386648101101859\n",
      "Epoch 124, Loss: 0.43805960220181783\n",
      "Epoch 125, Loss: 0.43742742958364306\n",
      "Epoch 126, Loss: 0.43680566799679216\n",
      "Epoch 127, Loss: 0.4362046957675372\n",
      "Epoch 128, Loss: 0.4356187667017611\n",
      "Epoch 129, Loss: 0.43501968295411086\n",
      "Epoch 130, Loss: 0.43434673944656643\n",
      "Epoch 131, Loss: 0.43371820811530465\n",
      "Epoch 132, Loss: 0.43315638572955495\n",
      "Epoch 133, Loss: 0.43264956385446013\n",
      "Epoch 134, Loss: 0.4321593365488341\n",
      "Epoch 135, Loss: 0.4316567638021057\n",
      "Epoch 136, Loss: 0.4311140827556379\n",
      "Epoch 137, Loss: 0.4305100803646064\n",
      "Epoch 138, Loss: 0.42999986218849456\n",
      "Epoch 139, Loss: 0.429506489167358\n",
      "Epoch 140, Loss: 0.42901883549789216\n",
      "Epoch 141, Loss: 0.4284370781571574\n",
      "Epoch 142, Loss: 0.4278309856681525\n",
      "Epoch 143, Loss: 0.4274146744699076\n",
      "Epoch 144, Loss: 0.42698877923882655\n",
      "Epoch 145, Loss: 0.4264549385249999\n",
      "Epoch 146, Loss: 0.42597472318578394\n",
      "Epoch 147, Loss: 0.4255394380191682\n",
      "Epoch 148, Loss: 0.4250715447961002\n",
      "Epoch 149, Loss: 0.4245688649832969\n",
      "Epoch 150, Loss: 0.4240599319166602\n",
      "Epoch 151, Loss: 0.4235828234741837\n",
      "Epoch 152, Loss: 0.42311035412638087\n",
      "Epoch 153, Loss: 0.42264846258692756\n",
      "Epoch 154, Loss: 0.42219420119246776\n",
      "Epoch 155, Loss: 0.4217441673859132\n",
      "Epoch 156, Loss: 0.421233696409821\n",
      "Epoch 157, Loss: 0.4206989284578808\n",
      "Epoch 158, Loss: 0.4201437785211756\n",
      "Epoch 159, Loss: 0.41959062862904367\n",
      "Epoch 160, Loss: 0.4190417447735689\n",
      "Epoch 161, Loss: 0.41860017587158654\n",
      "Epoch 162, Loss: 0.41827792916246126\n",
      "Epoch 163, Loss: 0.4177276415020908\n",
      "Epoch 164, Loss: 0.4169242142390554\n",
      "Epoch 165, Loss: 0.4162616450024014\n",
      "Epoch 166, Loss: 0.41595942157897364\n",
      "Epoch 167, Loss: 0.4156104788000256\n",
      "Epoch 168, Loss: 0.41485408475542324\n",
      "Epoch 169, Loss: 0.4141642967184458\n",
      "Epoch 170, Loss: 0.4137098862255831\n",
      "Epoch 171, Loss: 0.41330581476656203\n",
      "Epoch 172, Loss: 0.41267350983697576\n",
      "Epoch 173, Loss: 0.412011916944226\n",
      "Epoch 174, Loss: 0.4116176727261363\n",
      "Epoch 175, Loss: 0.4111970683647362\n",
      "Epoch 176, Loss: 0.41074782806165877\n",
      "Epoch 177, Loss: 0.4100999702714985\n",
      "Epoch 178, Loss: 0.40955161077890284\n",
      "Epoch 179, Loss: 0.40907257061853397\n",
      "Epoch 180, Loss: 0.40859213002687905\n",
      "Epoch 181, Loss: 0.4081950939793867\n",
      "Epoch 182, Loss: 0.40784789330079974\n",
      "Epoch 183, Loss: 0.4073874066732352\n",
      "Epoch 184, Loss: 0.4068892840911977\n",
      "Epoch 185, Loss: 0.4062288718965021\n",
      "Epoch 186, Loss: 0.4056781081301264\n",
      "Epoch 187, Loss: 0.4051404068243859\n",
      "Epoch 188, Loss: 0.40468832774427443\n",
      "Epoch 189, Loss: 0.40431454753489954\n",
      "Epoch 190, Loss: 0.4038811172251131\n",
      "Epoch 191, Loss: 0.4036444776778888\n",
      "Epoch 192, Loss: 0.40352019744084516\n",
      "Epoch 193, Loss: 0.40284074253720076\n",
      "Epoch 194, Loss: 0.40188663403533226\n",
      "Epoch 195, Loss: 0.40127595853172365\n",
      "Epoch 196, Loss: 0.4010201134607943\n",
      "Epoch 197, Loss: 0.40076174400407966\n",
      "Epoch 198, Loss: 0.4006631249543927\n",
      "Epoch 199, Loss: 0.40021829385523694\n",
      "Epoch 200, Loss: 0.3994296754056628\n",
      "Epoch 201, Loss: 0.39847515900604696\n",
      "Epoch 202, Loss: 0.3982872212060756\n",
      "Epoch 203, Loss: 0.3986220213024279\n",
      "Epoch 204, Loss: 0.39788093215038767\n",
      "Epoch 205, Loss: 0.39701223703953825\n",
      "Epoch 206, Loss: 0.39611314203167625\n",
      "Epoch 207, Loss: 0.39603082431652037\n",
      "Epoch 208, Loss: 0.3963009076254147\n",
      "Epoch 209, Loss: 0.3952447840776541\n",
      "Epoch 210, Loss: 0.39436584253455315\n",
      "Epoch 211, Loss: 0.3938940208682416\n",
      "Epoch 212, Loss: 0.3938229690029603\n",
      "Epoch 213, Loss: 0.3938559805824839\n",
      "Epoch 214, Loss: 0.3937235959600549\n",
      "Epoch 215, Loss: 0.39345070196397675\n",
      "Epoch 216, Loss: 0.3920743756313177\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2309668701081789\n",
      "Test R^2 score: 0.42195950327200743\n",
      "Num of epochs: 217\n",
      "Epoch 1, Loss: 0.5574126127204647\n",
      "Epoch 2, Loss: 0.556953770410659\n",
      "Epoch 3, Loss: 0.556596319208849\n",
      "Epoch 4, Loss: 0.5563465345390466\n",
      "Epoch 5, Loss: 0.55620198953438\n",
      "Epoch 6, Loss: 0.5561459669060721\n",
      "Epoch 7, Loss: 0.5561575952136284\n",
      "Epoch 8, Loss: 0.5562046150380241\n",
      "Epoch 9, Loss: 0.5562532917739679\n",
      "Epoch 10, Loss: 0.556278820577065\n",
      "Epoch 11, Loss: 0.5562702753893729\n",
      "Epoch 12, Loss: 0.556227949326889\n",
      "Epoch 13, Loss: 0.5561589348647791\n",
      "Epoch 14, Loss: 0.5560722527846551\n",
      "Epoch 15, Loss: 0.5559766322703878\n",
      "Epoch 16, Loss: 0.5558774568534756\n",
      "Epoch 17, Loss: 0.5557779151917266\n",
      "Epoch 18, Loss: 0.555675620443216\n",
      "Epoch 19, Loss: 0.5555644557822755\n",
      "Epoch 20, Loss: 0.5554349457102679\n",
      "Epoch 21, Loss: 0.5552772825083141\n",
      "Epoch 22, Loss: 0.5550838182923797\n",
      "Epoch 23, Loss: 0.5548475867278154\n",
      "Epoch 24, Loss: 0.554561546962009\n",
      "Epoch 25, Loss: 0.5542119633893896\n",
      "Epoch 26, Loss: 0.5537841048835738\n",
      "Epoch 27, Loss: 0.5532708142860374\n",
      "Epoch 28, Loss: 0.5526699122928728\n",
      "Epoch 29, Loss: 0.5519578419218566\n",
      "Epoch 30, Loss: 0.5511100004356525\n",
      "Epoch 31, Loss: 0.5501001624455409\n",
      "Epoch 32, Loss: 0.5488970567306387\n",
      "Epoch 33, Loss: 0.5474806020949579\n",
      "Epoch 34, Loss: 0.5458622956296763\n",
      "Epoch 35, Loss: 0.5439930591824168\n",
      "Epoch 36, Loss: 0.5418106462396541\n",
      "Epoch 37, Loss: 0.5392636186562795\n",
      "Epoch 38, Loss: 0.536350088093504\n",
      "Epoch 39, Loss: 0.5330649955047936\n",
      "Epoch 40, Loss: 0.529353374548418\n",
      "Epoch 41, Loss: 0.5251831722877928\n",
      "Epoch 42, Loss: 0.5205721072912166\n",
      "Epoch 43, Loss: 0.5156179196420689\n",
      "Epoch 44, Loss: 0.5105946256551969\n",
      "Epoch 45, Loss: 0.5060315225850527\n",
      "Epoch 46, Loss: 0.5027132327740418\n",
      "Epoch 47, Loss: 0.5012432674897606\n",
      "Epoch 48, Loss: 0.5005245735221895\n",
      "Epoch 49, Loss: 0.49826605966547777\n",
      "Epoch 50, Loss: 0.4943288512458655\n",
      "Epoch 51, Loss: 0.4902412748421155\n",
      "Epoch 52, Loss: 0.4871562662933991\n",
      "Epoch 53, Loss: 0.485185898076098\n",
      "Epoch 54, Loss: 0.48398526725040236\n",
      "Epoch 55, Loss: 0.4829173921635038\n",
      "Epoch 56, Loss: 0.481411404605299\n",
      "Epoch 57, Loss: 0.47930671538780656\n",
      "Epoch 58, Loss: 0.476877842990905\n",
      "Epoch 59, Loss: 0.4745848064578366\n",
      "Epoch 60, Loss: 0.4728576766906519\n",
      "Epoch 61, Loss: 0.4716824043780126\n",
      "Epoch 62, Loss: 0.47072800693198863\n",
      "Epoch 63, Loss: 0.46954148546382884\n",
      "Epoch 64, Loss: 0.46805263143255516\n",
      "Epoch 65, Loss: 0.4666098694922139\n",
      "Epoch 66, Loss: 0.4655991835125748\n",
      "Epoch 67, Loss: 0.46477825440679177\n",
      "Epoch 68, Loss: 0.46400123667038345\n",
      "Epoch 69, Loss: 0.46323419045647185\n",
      "Epoch 70, Loss: 0.4623780772882028\n",
      "Epoch 71, Loss: 0.4615165661507351\n",
      "Epoch 72, Loss: 0.4604695417787639\n",
      "Epoch 73, Loss: 0.45930078841240785\n",
      "Epoch 74, Loss: 0.4582627812906393\n",
      "Epoch 75, Loss: 0.45738599328640506\n",
      "Epoch 76, Loss: 0.456532230352905\n",
      "Epoch 77, Loss: 0.4557308051670229\n",
      "Epoch 78, Loss: 0.45506627145154505\n",
      "Epoch 79, Loss: 0.4544671012797625\n",
      "Epoch 80, Loss: 0.4537711633523105\n",
      "Epoch 81, Loss: 0.4530199192143446\n",
      "Epoch 82, Loss: 0.45223576338898586\n",
      "Epoch 83, Loss: 0.45145824971335424\n",
      "Epoch 84, Loss: 0.45081794364643324\n",
      "Epoch 85, Loss: 0.45024992307485445\n",
      "Epoch 86, Loss: 0.44966761512611547\n",
      "Epoch 87, Loss: 0.4490524315816951\n",
      "Epoch 88, Loss: 0.44841360832662036\n",
      "Epoch 89, Loss: 0.44782006160849974\n",
      "Epoch 90, Loss: 0.44724468532003814\n",
      "Epoch 91, Loss: 0.44664990217800726\n",
      "Epoch 92, Loss: 0.446050684598832\n",
      "Epoch 93, Loss: 0.44544892145540754\n",
      "Epoch 94, Loss: 0.4448637290517222\n",
      "Epoch 95, Loss: 0.4442487861764841\n",
      "Epoch 96, Loss: 0.44364901253190425\n",
      "Epoch 97, Loss: 0.44306050112318207\n",
      "Epoch 98, Loss: 0.4425158269120782\n",
      "Epoch 99, Loss: 0.4419254018211707\n",
      "Epoch 100, Loss: 0.4413352166468916\n",
      "Epoch 101, Loss: 0.440701419885857\n",
      "Epoch 102, Loss: 0.44001594953456274\n",
      "Epoch 103, Loss: 0.43928583987773645\n",
      "Epoch 104, Loss: 0.43857857042224974\n",
      "Epoch 105, Loss: 0.4378848426838619\n",
      "Epoch 106, Loss: 0.4371610929627324\n",
      "Epoch 107, Loss: 0.4364402572269414\n",
      "Epoch 108, Loss: 0.43575512821092893\n",
      "Epoch 109, Loss: 0.4350686634067197\n",
      "Epoch 110, Loss: 0.4343976309939151\n",
      "Epoch 111, Loss: 0.4337454521864226\n",
      "Epoch 112, Loss: 0.43308616689787927\n",
      "Epoch 113, Loss: 0.4324349736518794\n",
      "Epoch 114, Loss: 0.43179166748926406\n",
      "Epoch 115, Loss: 0.4311542273336634\n",
      "Epoch 116, Loss: 0.4305236137584017\n",
      "Epoch 117, Loss: 0.4298779325715201\n",
      "Epoch 118, Loss: 0.4292363138844168\n",
      "Epoch 119, Loss: 0.42859589025816247\n",
      "Epoch 120, Loss: 0.42798419084719425\n",
      "Epoch 121, Loss: 0.42748807321608917\n",
      "Epoch 122, Loss: 0.4270373722870028\n",
      "Epoch 123, Loss: 0.4262998205306257\n",
      "Epoch 124, Loss: 0.42540784088130973\n",
      "Epoch 125, Loss: 0.4249394345604867\n",
      "Epoch 126, Loss: 0.42440754533899644\n",
      "Epoch 127, Loss: 0.423574978515574\n",
      "Epoch 128, Loss: 0.4230220178009687\n",
      "Epoch 129, Loss: 0.42258652977564193\n",
      "Epoch 130, Loss: 0.42188941083242915\n",
      "Epoch 131, Loss: 0.42123551822072675\n",
      "Epoch 132, Loss: 0.42081595761085305\n",
      "Epoch 133, Loss: 0.4202878377549732\n",
      "Epoch 134, Loss: 0.41957967254963563\n",
      "Epoch 135, Loss: 0.4190515770224676\n",
      "Epoch 136, Loss: 0.41866672029363283\n",
      "Epoch 137, Loss: 0.41806544317372024\n",
      "Epoch 138, Loss: 0.41739779540513844\n",
      "Epoch 139, Loss: 0.4168533880359407\n",
      "Epoch 140, Loss: 0.4164536010844806\n",
      "Epoch 141, Loss: 0.4159410078443902\n",
      "Epoch 142, Loss: 0.415263306120341\n",
      "Epoch 143, Loss: 0.4146086671491453\n",
      "Epoch 144, Loss: 0.414063921512107\n",
      "Epoch 145, Loss: 0.41354551970114617\n",
      "Epoch 146, Loss: 0.4131017370787246\n",
      "Epoch 147, Loss: 0.41260533071750366\n",
      "Epoch 148, Loss: 0.4120476482138623\n",
      "Epoch 149, Loss: 0.4112754266351406\n",
      "Epoch 150, Loss: 0.4105002822352286\n",
      "Epoch 151, Loss: 0.40995847384151907\n",
      "Epoch 152, Loss: 0.4096000897047943\n",
      "Epoch 153, Loss: 0.40931377171406086\n",
      "Epoch 154, Loss: 0.40888281638809465\n",
      "Epoch 155, Loss: 0.4080187550013712\n",
      "Epoch 156, Loss: 0.40713208975751664\n",
      "Epoch 157, Loss: 0.4065766671752244\n",
      "Epoch 158, Loss: 0.4063501968066008\n",
      "Epoch 159, Loss: 0.40614772389511566\n",
      "Epoch 160, Loss: 0.4055215834225174\n",
      "Epoch 161, Loss: 0.4046154517766864\n",
      "Epoch 162, Loss: 0.40397815765217604\n",
      "Epoch 163, Loss: 0.40372269626687474\n",
      "Epoch 164, Loss: 0.4034879396141761\n",
      "Epoch 165, Loss: 0.40296841249011767\n",
      "Epoch 166, Loss: 0.40222964474283496\n",
      "Epoch 167, Loss: 0.4015136414427794\n",
      "Epoch 168, Loss: 0.4010984723207307\n",
      "Epoch 169, Loss: 0.40094829892655004\n",
      "Epoch 170, Loss: 0.4007042005810477\n",
      "Epoch 171, Loss: 0.400226447708044\n",
      "Epoch 172, Loss: 0.39936998119394607\n",
      "Epoch 173, Loss: 0.39871890284618083\n",
      "Epoch 174, Loss: 0.3983993512010462\n",
      "Epoch 175, Loss: 0.39824593370592326\n",
      "Epoch 176, Loss: 0.39812586321654825\n",
      "Epoch 177, Loss: 0.39756895279981186\n",
      "Epoch 178, Loss: 0.39679899088578385\n",
      "Epoch 179, Loss: 0.39615523483725257\n",
      "Epoch 180, Loss: 0.3957718709443551\n",
      "Epoch 181, Loss: 0.39551811675789034\n",
      "Epoch 182, Loss: 0.39538802228401493\n",
      "Epoch 183, Loss: 0.39513790587310593\n",
      "Epoch 184, Loss: 0.3945363677042283\n",
      "Epoch 185, Loss: 0.3939674049730293\n",
      "Epoch 186, Loss: 0.3934158383163903\n",
      "Epoch 187, Loss: 0.3929393112652977\n",
      "Epoch 188, Loss: 0.3926465178929494\n",
      "Epoch 189, Loss: 0.39251290913631565\n",
      "Epoch 190, Loss: 0.3924674452201027\n",
      "Epoch 191, Loss: 0.3923828056643055\n",
      "Epoch 192, Loss: 0.3923246979578764\n",
      "Epoch 193, Loss: 0.3916705444157504\n",
      "Epoch 194, Loss: 0.39069794927356155\n",
      "Epoch 195, Loss: 0.3901400034817526\n",
      "Epoch 196, Loss: 0.3899101774081035\n",
      "Epoch 197, Loss: 0.38975630488504875\n",
      "Epoch 198, Loss: 0.3898292447069137\n",
      "Epoch 199, Loss: 0.3898521407147498\n",
      "Epoch 200, Loss: 0.38919199355021394\n",
      "Epoch 201, Loss: 0.3887267529261571\n",
      "Epoch 202, Loss: 0.3880049576381161\n",
      "Epoch 203, Loss: 0.3874873028490018\n",
      "Epoch 204, Loss: 0.38740974882687096\n",
      "Epoch 205, Loss: 0.38732569681300794\n",
      "Epoch 206, Loss: 0.3872555369220796\n",
      "Epoch 207, Loss: 0.3874067678888873\n",
      "Epoch 208, Loss: 0.38760151917639163\n",
      "Epoch 209, Loss: 0.38686177469921584\n",
      "Epoch 210, Loss: 0.385909765999936\n",
      "Epoch 211, Loss: 0.38516139477742783\n",
      "Epoch 212, Loss: 0.38482253142765604\n",
      "Epoch 213, Loss: 0.385015338864624\n",
      "Epoch 214, Loss: 0.385264020625062\n",
      "Epoch 215, Loss: 0.3849685056611153\n",
      "Epoch 216, Loss: 0.3844480414113573\n",
      "Epoch 217, Loss: 0.3836901199890154\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.23954670053225563\n",
      "Test R^2 score: 0.3776987965636249\n",
      "Num of epochs: 218\n",
      "Epoch 1, Loss: 0.5944134870036172\n",
      "Epoch 2, Loss: 0.5923933793561494\n",
      "Epoch 3, Loss: 0.5902469343342513\n",
      "Epoch 4, Loss: 0.5881024356125445\n",
      "Epoch 5, Loss: 0.5859873432576252\n",
      "Epoch 6, Loss: 0.5839368105499173\n",
      "Epoch 7, Loss: 0.5819035844511851\n",
      "Epoch 8, Loss: 0.5799019799769833\n",
      "Epoch 9, Loss: 0.5779398286528531\n",
      "Epoch 10, Loss: 0.576027415641374\n",
      "Epoch 11, Loss: 0.5741619938418953\n",
      "Epoch 12, Loss: 0.572347042814713\n",
      "Epoch 13, Loss: 0.5705870920982962\n",
      "Epoch 14, Loss: 0.5688860311375348\n",
      "Epoch 15, Loss: 0.5673299426660325\n",
      "Epoch 16, Loss: 0.5658944547176918\n",
      "Epoch 17, Loss: 0.5645066866161909\n",
      "Epoch 18, Loss: 0.5631686845489068\n",
      "Epoch 19, Loss: 0.5620383646570123\n",
      "Epoch 20, Loss: 0.5609913303398923\n",
      "Epoch 21, Loss: 0.5599539940958734\n",
      "Epoch 22, Loss: 0.5589522431826536\n",
      "Epoch 23, Loss: 0.5579970046650057\n",
      "Epoch 24, Loss: 0.5570781928742806\n",
      "Epoch 25, Loss: 0.5561865041689366\n",
      "Epoch 26, Loss: 0.555304493070891\n",
      "Epoch 27, Loss: 0.5544150314585985\n",
      "Epoch 28, Loss: 0.5535156874565784\n",
      "Epoch 29, Loss: 0.552570413055387\n",
      "Epoch 30, Loss: 0.5515111591337596\n",
      "Epoch 31, Loss: 0.5502904775134936\n",
      "Epoch 32, Loss: 0.5488737365666415\n",
      "Epoch 33, Loss: 0.5472324565499508\n",
      "Epoch 34, Loss: 0.5453363298603513\n",
      "Epoch 35, Loss: 0.5431367079215854\n",
      "Epoch 36, Loss: 0.5406267166110442\n",
      "Epoch 37, Loss: 0.5379250730787943\n",
      "Epoch 38, Loss: 0.5352879661465207\n",
      "Epoch 39, Loss: 0.5330573081703964\n",
      "Epoch 40, Loss: 0.531273757178973\n",
      "Epoch 41, Loss: 0.5294310902826828\n",
      "Epoch 42, Loss: 0.5267083189685933\n",
      "Epoch 43, Loss: 0.5231462209082144\n",
      "Epoch 44, Loss: 0.5196430401527857\n",
      "Epoch 45, Loss: 0.5168494223063074\n",
      "Epoch 46, Loss: 0.5147299656723272\n",
      "Epoch 47, Loss: 0.5129050561482769\n",
      "Epoch 48, Loss: 0.5109012275909531\n",
      "Epoch 49, Loss: 0.5086258756508629\n",
      "Epoch 50, Loss: 0.5062340486627225\n",
      "Epoch 51, Loss: 0.5040805426512096\n",
      "Epoch 52, Loss: 0.5024248570866943\n",
      "Epoch 53, Loss: 0.5010443747507404\n",
      "Epoch 54, Loss: 0.49945612474051176\n",
      "Epoch 55, Loss: 0.4976902601277387\n",
      "Epoch 56, Loss: 0.4961387433651995\n",
      "Epoch 57, Loss: 0.49484716572620047\n",
      "Epoch 58, Loss: 0.4935211701630373\n",
      "Epoch 59, Loss: 0.4919908978610762\n",
      "Epoch 60, Loss: 0.49042657678757745\n",
      "Epoch 61, Loss: 0.4891015143874673\n",
      "Epoch 62, Loss: 0.4879535948995308\n",
      "Epoch 63, Loss: 0.4865990768679036\n",
      "Epoch 64, Loss: 0.4850487483979819\n",
      "Epoch 65, Loss: 0.4836959077720731\n",
      "Epoch 66, Loss: 0.4825713817884298\n",
      "Epoch 67, Loss: 0.48134621302457387\n",
      "Epoch 68, Loss: 0.4799536448188791\n",
      "Epoch 69, Loss: 0.4786494165341065\n",
      "Epoch 70, Loss: 0.47752801613230367\n",
      "Epoch 71, Loss: 0.47638988495541246\n",
      "Epoch 72, Loss: 0.4752093631722634\n",
      "Epoch 73, Loss: 0.4740876363780378\n",
      "Epoch 74, Loss: 0.47294050134205795\n",
      "Epoch 75, Loss: 0.47187291012231714\n",
      "Epoch 76, Loss: 0.47092119286141376\n",
      "Epoch 77, Loss: 0.4699491263056269\n",
      "Epoch 78, Loss: 0.46892183651008307\n",
      "Epoch 79, Loss: 0.4680449746898316\n",
      "Epoch 80, Loss: 0.4672029397001601\n",
      "Epoch 81, Loss: 0.46626364606160775\n",
      "Epoch 82, Loss: 0.4653793583086169\n",
      "Epoch 83, Loss: 0.4645131001036709\n",
      "Epoch 84, Loss: 0.4636157830238298\n",
      "Epoch 85, Loss: 0.4627531145156916\n",
      "Epoch 86, Loss: 0.4618726393209584\n",
      "Epoch 87, Loss: 0.4610426023237913\n",
      "Epoch 88, Loss: 0.46024877204192466\n",
      "Epoch 89, Loss: 0.4594429160535628\n",
      "Epoch 90, Loss: 0.45869698150540594\n",
      "Epoch 91, Loss: 0.45794986447739305\n",
      "Epoch 92, Loss: 0.45718635470285324\n",
      "Epoch 93, Loss: 0.456433859450066\n",
      "Epoch 94, Loss: 0.4556811516308715\n",
      "Epoch 95, Loss: 0.4549593135961644\n",
      "Epoch 96, Loss: 0.45421708801196425\n",
      "Epoch 97, Loss: 0.45347833011863325\n",
      "Epoch 98, Loss: 0.4527479609112291\n",
      "Epoch 99, Loss: 0.45201944443245706\n",
      "Epoch 100, Loss: 0.4512984193307188\n",
      "Epoch 101, Loss: 0.450557819310922\n",
      "Epoch 102, Loss: 0.44984985469320965\n",
      "Epoch 103, Loss: 0.4491383190298213\n",
      "Epoch 104, Loss: 0.44842871148937924\n",
      "Epoch 105, Loss: 0.44771967666560963\n",
      "Epoch 106, Loss: 0.4469917324963599\n",
      "Epoch 107, Loss: 0.4462475913915092\n",
      "Epoch 108, Loss: 0.44551026821504897\n",
      "Epoch 109, Loss: 0.44480259462760174\n",
      "Epoch 110, Loss: 0.44411421053938505\n",
      "Epoch 111, Loss: 0.44343448624450393\n",
      "Epoch 112, Loss: 0.44274442936964664\n",
      "Epoch 113, Loss: 0.4420636775398724\n",
      "Epoch 114, Loss: 0.4413923750865676\n",
      "Epoch 115, Loss: 0.4407561418156245\n",
      "Epoch 116, Loss: 0.44014595518033606\n",
      "Epoch 117, Loss: 0.4395367352102366\n",
      "Epoch 118, Loss: 0.43894209924825184\n",
      "Epoch 119, Loss: 0.43836088290080116\n",
      "Epoch 120, Loss: 0.4377474255499742\n",
      "Epoch 121, Loss: 0.43713264710192745\n",
      "Epoch 122, Loss: 0.4365410001153212\n",
      "Epoch 123, Loss: 0.4358800460527719\n",
      "Epoch 124, Loss: 0.4351659400450037\n",
      "Epoch 125, Loss: 0.43452227037596414\n",
      "Epoch 126, Loss: 0.43389098830508205\n",
      "Epoch 127, Loss: 0.4331542700418226\n",
      "Epoch 128, Loss: 0.43256911792165437\n",
      "Epoch 129, Loss: 0.4318934947027163\n",
      "Epoch 130, Loss: 0.43115065024573623\n",
      "Epoch 131, Loss: 0.430482458460591\n",
      "Epoch 132, Loss: 0.42974438724214536\n",
      "Epoch 133, Loss: 0.4291427106405565\n",
      "Epoch 134, Loss: 0.4286087192336944\n",
      "Epoch 135, Loss: 0.42802842366567334\n",
      "Epoch 136, Loss: 0.42747433914444927\n",
      "Epoch 137, Loss: 0.4269233225536235\n",
      "Epoch 138, Loss: 0.42639142682683223\n",
      "Epoch 139, Loss: 0.4258879431640705\n",
      "Epoch 140, Loss: 0.42520030224193656\n",
      "Epoch 141, Loss: 0.42455047367335935\n",
      "Epoch 142, Loss: 0.4238989810341469\n",
      "Epoch 143, Loss: 0.42326102573524105\n",
      "Epoch 144, Loss: 0.4226451308220974\n",
      "Epoch 145, Loss: 0.4220086521791659\n",
      "Epoch 146, Loss: 0.42133216902653964\n",
      "Epoch 147, Loss: 0.42119660404145914\n",
      "Epoch 148, Loss: 0.4219024967133743\n",
      "Epoch 149, Loss: 0.42041238923759117\n",
      "Epoch 150, Loss: 0.41905573743445684\n",
      "Epoch 151, Loss: 0.4197176946996402\n",
      "Epoch 152, Loss: 0.41801662705630405\n",
      "Epoch 153, Loss: 0.41833102489052354\n",
      "Epoch 154, Loss: 0.4174332084452295\n",
      "Epoch 155, Loss: 0.4170178622129641\n",
      "Epoch 156, Loss: 0.4166862026244182\n",
      "Epoch 157, Loss: 0.4157550515081881\n",
      "Epoch 158, Loss: 0.4157934715025907\n",
      "Epoch 159, Loss: 0.4147412836286768\n",
      "Epoch 160, Loss: 0.41488441727728975\n",
      "Epoch 161, Loss: 0.41404556743620213\n",
      "Epoch 162, Loss: 0.4138011287376511\n",
      "Epoch 163, Loss: 0.41350505300038315\n",
      "Epoch 164, Loss: 0.412735359642736\n",
      "Epoch 165, Loss: 0.4127228315632055\n",
      "Epoch 166, Loss: 0.4120894332327557\n",
      "Epoch 167, Loss: 0.41166478623155056\n",
      "Epoch 168, Loss: 0.4115487755794893\n",
      "Epoch 169, Loss: 0.41089630573182817\n",
      "Epoch 170, Loss: 0.4106505730328521\n",
      "Epoch 171, Loss: 0.4104058913770541\n",
      "Epoch 172, Loss: 0.40984559783344465\n",
      "Epoch 173, Loss: 0.409554812565991\n",
      "Epoch 174, Loss: 0.4093390543640914\n",
      "Epoch 175, Loss: 0.40883766027608315\n",
      "Epoch 176, Loss: 0.40841773200556125\n",
      "Epoch 177, Loss: 0.408221577496502\n",
      "Epoch 178, Loss: 0.4078484413415556\n",
      "Epoch 179, Loss: 0.40737518964741387\n",
      "Epoch 180, Loss: 0.40699181319890565\n",
      "Epoch 181, Loss: 0.4067169953234028\n",
      "Epoch 182, Loss: 0.40638695755764215\n",
      "Epoch 183, Loss: 0.4059773226932458\n",
      "Epoch 184, Loss: 0.4055509054049456\n",
      "Epoch 185, Loss: 0.405179061012114\n",
      "Epoch 186, Loss: 0.40480617565252175\n",
      "Epoch 187, Loss: 0.40444394445140963\n",
      "Epoch 188, Loss: 0.4041365706489116\n",
      "Epoch 189, Loss: 0.40384660055324456\n",
      "Epoch 190, Loss: 0.40381673045880484\n",
      "Epoch 191, Loss: 0.4045363928393178\n",
      "Epoch 192, Loss: 0.40594250706028695\n",
      "Epoch 193, Loss: 0.40458120032526407\n",
      "Epoch 194, Loss: 0.402071295773801\n",
      "Epoch 195, Loss: 0.4036636738269834\n",
      "Epoch 196, Loss: 0.40256666285970283\n",
      "Epoch 197, Loss: 0.40131971909250547\n",
      "Epoch 198, Loss: 0.40217436771249454\n",
      "Epoch 199, Loss: 0.40048555318800405\n",
      "Epoch 200, Loss: 0.4005187597167362\n",
      "Epoch 201, Loss: 0.4006893067367536\n",
      "Epoch 202, Loss: 0.3992629756431294\n",
      "Epoch 203, Loss: 0.3995721965659229\n",
      "Epoch 204, Loss: 0.39921723531596176\n",
      "Epoch 205, Loss: 0.398276315136968\n",
      "Epoch 206, Loss: 0.3984973525925003\n",
      "Epoch 207, Loss: 0.39799718275223256\n",
      "Epoch 208, Loss: 0.3972465443037717\n",
      "Epoch 209, Loss: 0.39746260584075727\n",
      "Epoch 210, Loss: 0.396853270649226\n",
      "Epoch 211, Loss: 0.3961511724558453\n",
      "Epoch 212, Loss: 0.39629483507820523\n",
      "Epoch 213, Loss: 0.39567961552365244\n",
      "Epoch 214, Loss: 0.39513503980447245\n",
      "Epoch 215, Loss: 0.3950170604123996\n",
      "Epoch 216, Loss: 0.3947084991837018\n",
      "Epoch 217, Loss: 0.39417484917457857\n",
      "Epoch 218, Loss: 0.39375451554630747\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.23272771078925683\n",
      "Test R^2 score: 0.4148512807221184\n",
      "Num of epochs: 219\n",
      "Epoch 1, Loss: 0.5643266846431693\n",
      "Epoch 2, Loss: 0.5633021304510303\n",
      "Epoch 3, Loss: 0.5623540159042556\n",
      "Epoch 4, Loss: 0.5615754741938244\n",
      "Epoch 5, Loss: 0.5609123819406967\n",
      "Epoch 6, Loss: 0.5603295147381996\n",
      "Epoch 7, Loss: 0.5598073726826824\n",
      "Epoch 8, Loss: 0.5593256656905855\n",
      "Epoch 9, Loss: 0.5588845783028016\n",
      "Epoch 10, Loss: 0.5584818321097349\n",
      "Epoch 11, Loss: 0.5581162819603315\n",
      "Epoch 12, Loss: 0.5577820435658917\n",
      "Epoch 13, Loss: 0.5574639104700112\n",
      "Epoch 14, Loss: 0.557198041258845\n",
      "Epoch 15, Loss: 0.5569515230067771\n",
      "Epoch 16, Loss: 0.556727245350573\n",
      "Epoch 17, Loss: 0.5565248335483906\n",
      "Epoch 18, Loss: 0.5563430258297247\n",
      "Epoch 19, Loss: 0.5561822442782607\n",
      "Epoch 20, Loss: 0.5560404704359653\n",
      "Epoch 21, Loss: 0.5559006172369577\n",
      "Epoch 22, Loss: 0.55572723941296\n",
      "Epoch 23, Loss: 0.5554759640768437\n",
      "Epoch 24, Loss: 0.555196609039285\n",
      "Epoch 25, Loss: 0.5549008939510012\n",
      "Epoch 26, Loss: 0.5545406953206623\n",
      "Epoch 27, Loss: 0.5541173933347379\n",
      "Epoch 28, Loss: 0.5536176276595705\n",
      "Epoch 29, Loss: 0.553028500215728\n",
      "Epoch 30, Loss: 0.5523448150926651\n",
      "Epoch 31, Loss: 0.5515617089630592\n",
      "Epoch 32, Loss: 0.5506415764936364\n",
      "Epoch 33, Loss: 0.54955612716355\n",
      "Epoch 34, Loss: 0.5483073414301497\n",
      "Epoch 35, Loss: 0.5468787056933601\n",
      "Epoch 36, Loss: 0.5452005091003593\n",
      "Epoch 37, Loss: 0.5432205713993504\n",
      "Epoch 38, Loss: 0.5408825762372163\n",
      "Epoch 39, Loss: 0.5381444217309482\n",
      "Epoch 40, Loss: 0.5349586288998425\n",
      "Epoch 41, Loss: 0.5312901089056848\n",
      "Epoch 42, Loss: 0.5271271437379061\n",
      "Epoch 43, Loss: 0.5226050917787242\n",
      "Epoch 44, Loss: 0.5181384526382607\n",
      "Epoch 45, Loss: 0.5146159500204714\n",
      "Epoch 46, Loss: 0.5132856766554861\n",
      "Epoch 47, Loss: 0.51355144408889\n",
      "Epoch 48, Loss: 0.5121628966831513\n",
      "Epoch 49, Loss: 0.5086655128115112\n",
      "Epoch 50, Loss: 0.5047401211826618\n",
      "Epoch 51, Loss: 0.5017273985367695\n",
      "Epoch 52, Loss: 0.4999342517539809\n",
      "Epoch 53, Loss: 0.49864585611367107\n",
      "Epoch 54, Loss: 0.49713188344646736\n",
      "Epoch 55, Loss: 0.49493088687679687\n",
      "Epoch 56, Loss: 0.4919189598526134\n",
      "Epoch 57, Loss: 0.48812002953649697\n",
      "Epoch 58, Loss: 0.48397184329553966\n",
      "Epoch 59, Loss: 0.4800173181648178\n",
      "Epoch 60, Loss: 0.4768174693200798\n",
      "Epoch 61, Loss: 0.4747378171579971\n",
      "Epoch 62, Loss: 0.4741587913604474\n",
      "Epoch 63, Loss: 0.47479905156910146\n",
      "Epoch 64, Loss: 0.47458243587946025\n",
      "Epoch 65, Loss: 0.47292036763674217\n",
      "Epoch 66, Loss: 0.47082429331425296\n",
      "Epoch 67, Loss: 0.469242536543368\n",
      "Epoch 68, Loss: 0.46820032952446566\n",
      "Epoch 69, Loss: 0.46752166343413437\n",
      "Epoch 70, Loss: 0.46699808484752786\n",
      "Epoch 71, Loss: 0.46640893944966483\n",
      "Epoch 72, Loss: 0.4657271989891596\n",
      "Epoch 73, Loss: 0.46485439256297795\n",
      "Epoch 74, Loss: 0.4639334701564516\n",
      "Epoch 75, Loss: 0.4630476608771717\n",
      "Epoch 76, Loss: 0.4621043387982633\n",
      "Epoch 77, Loss: 0.46106802175389644\n",
      "Epoch 78, Loss: 0.4600904569885645\n",
      "Epoch 79, Loss: 0.4594442458090198\n",
      "Epoch 80, Loss: 0.4589654634516085\n",
      "Epoch 81, Loss: 0.45848286602532595\n",
      "Epoch 82, Loss: 0.4580048192949235\n",
      "Epoch 83, Loss: 0.45741917375635144\n",
      "Epoch 84, Loss: 0.45668092978901303\n",
      "Epoch 85, Loss: 0.4559830439817775\n",
      "Epoch 86, Loss: 0.45528050453595786\n",
      "Epoch 87, Loss: 0.4545724375800424\n",
      "Epoch 88, Loss: 0.45392982763093215\n",
      "Epoch 89, Loss: 0.4533044854211289\n",
      "Epoch 90, Loss: 0.45271060344702085\n",
      "Epoch 91, Loss: 0.4521167159024241\n",
      "Epoch 92, Loss: 0.45148778977153114\n",
      "Epoch 93, Loss: 0.45090831968834616\n",
      "Epoch 94, Loss: 0.45035958758008604\n",
      "Epoch 95, Loss: 0.44988079214010895\n",
      "Epoch 96, Loss: 0.4493832328530341\n",
      "Epoch 97, Loss: 0.44885378399868997\n",
      "Epoch 98, Loss: 0.44833181976868824\n",
      "Epoch 99, Loss: 0.44781997842127874\n",
      "Epoch 100, Loss: 0.4473436279243412\n",
      "Epoch 101, Loss: 0.44680345802907034\n",
      "Epoch 102, Loss: 0.44625725831078045\n",
      "Epoch 103, Loss: 0.44574335236013146\n",
      "Epoch 104, Loss: 0.44527309644940205\n",
      "Epoch 105, Loss: 0.44481840663760036\n",
      "Epoch 106, Loss: 0.44435411353191956\n",
      "Epoch 107, Loss: 0.44389222176288223\n",
      "Epoch 108, Loss: 0.44347800125645376\n",
      "Epoch 109, Loss: 0.4430625190589568\n",
      "Epoch 110, Loss: 0.44263743973611713\n",
      "Epoch 111, Loss: 0.4421920870485737\n",
      "Epoch 112, Loss: 0.4417469600201566\n",
      "Epoch 113, Loss: 0.44130617880957135\n",
      "Epoch 114, Loss: 0.4408517240691547\n",
      "Epoch 115, Loss: 0.44041248296388413\n",
      "Epoch 116, Loss: 0.439985402201038\n",
      "Epoch 117, Loss: 0.43956334745102216\n",
      "Epoch 118, Loss: 0.4391469609486035\n",
      "Epoch 119, Loss: 0.4387298396225366\n",
      "Epoch 120, Loss: 0.4383041450653927\n",
      "Epoch 121, Loss: 0.43787402105371726\n",
      "Epoch 122, Loss: 0.43744027206887703\n",
      "Epoch 123, Loss: 0.4369905946197354\n",
      "Epoch 124, Loss: 0.4365082467186088\n",
      "Epoch 125, Loss: 0.4360103792368145\n",
      "Epoch 126, Loss: 0.43551355071944664\n",
      "Epoch 127, Loss: 0.43500539880449696\n",
      "Epoch 128, Loss: 0.43448497491522753\n",
      "Epoch 129, Loss: 0.43396531757638074\n",
      "Epoch 130, Loss: 0.43344764997373514\n",
      "Epoch 131, Loss: 0.43293975790830214\n",
      "Epoch 132, Loss: 0.4324420720925677\n",
      "Epoch 133, Loss: 0.4319342740644548\n",
      "Epoch 134, Loss: 0.43142197538492605\n",
      "Epoch 135, Loss: 0.43092642683445925\n",
      "Epoch 136, Loss: 0.4304523423351268\n",
      "Epoch 137, Loss: 0.4300219707919674\n",
      "Epoch 138, Loss: 0.4296094303301026\n",
      "Epoch 139, Loss: 0.4290215620388734\n",
      "Epoch 140, Loss: 0.42836465949542457\n",
      "Epoch 141, Loss: 0.4277828311036827\n",
      "Epoch 142, Loss: 0.4273057993996355\n",
      "Epoch 143, Loss: 0.4268660244479828\n",
      "Epoch 144, Loss: 0.42626664727667557\n",
      "Epoch 145, Loss: 0.4256600898752636\n",
      "Epoch 146, Loss: 0.4251301012336008\n",
      "Epoch 147, Loss: 0.42464696652829015\n",
      "Epoch 148, Loss: 0.4241626667303761\n",
      "Epoch 149, Loss: 0.42366115955362116\n",
      "Epoch 150, Loss: 0.4231455531967433\n",
      "Epoch 151, Loss: 0.4225973902701186\n",
      "Epoch 152, Loss: 0.4220483918082423\n",
      "Epoch 153, Loss: 0.4215095668048682\n",
      "Epoch 154, Loss: 0.4209866707848275\n",
      "Epoch 155, Loss: 0.42046455979430003\n",
      "Epoch 156, Loss: 0.4199419593443683\n",
      "Epoch 157, Loss: 0.4194246586479621\n",
      "Epoch 158, Loss: 0.41892293945896636\n",
      "Epoch 159, Loss: 0.4185403320300082\n",
      "Epoch 160, Loss: 0.41854697187880213\n",
      "Epoch 161, Loss: 0.4191694749216058\n",
      "Epoch 162, Loss: 0.4176907729106685\n",
      "Epoch 163, Loss: 0.4164943358561675\n",
      "Epoch 164, Loss: 0.41705511185664645\n",
      "Epoch 165, Loss: 0.41583835603869723\n",
      "Epoch 166, Loss: 0.4151834034968159\n",
      "Epoch 167, Loss: 0.41530905524806505\n",
      "Epoch 168, Loss: 0.41408643113562393\n",
      "Epoch 169, Loss: 0.4137465513149029\n",
      "Epoch 170, Loss: 0.41370163793361775\n",
      "Epoch 171, Loss: 0.41252745984895683\n",
      "Epoch 172, Loss: 0.4123635976856387\n",
      "Epoch 173, Loss: 0.41214034339289773\n",
      "Epoch 174, Loss: 0.410947182399848\n",
      "Epoch 175, Loss: 0.41079712707551264\n",
      "Epoch 176, Loss: 0.41053142645577206\n",
      "Epoch 177, Loss: 0.40935104897009283\n",
      "Epoch 178, Loss: 0.4089210257158267\n",
      "Epoch 179, Loss: 0.40894678812091423\n",
      "Epoch 180, Loss: 0.40795982447502893\n",
      "Epoch 181, Loss: 0.4071631988335293\n",
      "Epoch 182, Loss: 0.40714363699195383\n",
      "Epoch 183, Loss: 0.40652551844923723\n",
      "Epoch 184, Loss: 0.40561773543472474\n",
      "Epoch 185, Loss: 0.4051227703156711\n",
      "Epoch 186, Loss: 0.4048703866644554\n",
      "Epoch 187, Loss: 0.40414444265842936\n",
      "Epoch 188, Loss: 0.40344315844762807\n",
      "Epoch 189, Loss: 0.4031367034100398\n",
      "Epoch 190, Loss: 0.4027232815151644\n",
      "Epoch 191, Loss: 0.4023843948426467\n",
      "Epoch 192, Loss: 0.4016301020260491\n",
      "Epoch 193, Loss: 0.4009586491882662\n",
      "Epoch 194, Loss: 0.40050514258251263\n",
      "Epoch 195, Loss: 0.39998131276228877\n",
      "Epoch 196, Loss: 0.3997087394254725\n",
      "Epoch 197, Loss: 0.3997200537600596\n",
      "Epoch 198, Loss: 0.39938052160180193\n",
      "Epoch 199, Loss: 0.3991646582580138\n",
      "Epoch 200, Loss: 0.39846362234015514\n",
      "Epoch 201, Loss: 0.397249901534465\n",
      "Epoch 202, Loss: 0.39668704711157365\n",
      "Epoch 203, Loss: 0.396256705627502\n",
      "Epoch 204, Loss: 0.39637961671438926\n",
      "Epoch 205, Loss: 0.3968534020682148\n",
      "Epoch 206, Loss: 0.39697607210198194\n",
      "Epoch 207, Loss: 0.3964220759112477\n",
      "Epoch 208, Loss: 0.39390684515890323\n",
      "Epoch 209, Loss: 0.39453591447848874\n",
      "Epoch 210, Loss: 0.3954119342397491\n",
      "Epoch 211, Loss: 0.39351826160813136\n",
      "Epoch 212, Loss: 0.39286387657612065\n",
      "Epoch 213, Loss: 0.393263337459032\n",
      "Epoch 214, Loss: 0.3936767767381294\n",
      "Epoch 215, Loss: 0.3907872435282877\n",
      "Epoch 216, Loss: 0.3933483936705181\n",
      "Epoch 217, Loss: 0.3932218256216722\n",
      "Epoch 218, Loss: 0.3917536832481714\n",
      "Epoch 219, Loss: 0.39091846886287646\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.23639548443917774\n",
      "Test R^2 score: 0.39520305393383737\n",
      "Num of epochs: 220\n",
      "Epoch 1, Loss: 0.5620684027568121\n",
      "Epoch 2, Loss: 0.5610241336918323\n",
      "Epoch 3, Loss: 0.560116060695982\n",
      "Epoch 4, Loss: 0.55940078910326\n",
      "Epoch 5, Loss: 0.5588262380949163\n",
      "Epoch 6, Loss: 0.5584155512052248\n",
      "Epoch 7, Loss: 0.558034443445121\n",
      "Epoch 8, Loss: 0.5576843916017511\n",
      "Epoch 9, Loss: 0.557368020742231\n",
      "Epoch 10, Loss: 0.5570895609891546\n",
      "Epoch 11, Loss: 0.5568474903868429\n",
      "Epoch 12, Loss: 0.5566413745540458\n",
      "Epoch 13, Loss: 0.5564717890022942\n",
      "Epoch 14, Loss: 0.5563341869982339\n",
      "Epoch 15, Loss: 0.5562284851199586\n",
      "Epoch 16, Loss: 0.5561501466943818\n",
      "Epoch 17, Loss: 0.5560953246670728\n",
      "Epoch 18, Loss: 0.5560589344330101\n",
      "Epoch 19, Loss: 0.5560350034744957\n",
      "Epoch 20, Loss: 0.556017771474606\n",
      "Epoch 21, Loss: 0.5560011285540565\n",
      "Epoch 22, Loss: 0.5559786155982789\n",
      "Epoch 23, Loss: 0.5559435310915788\n",
      "Epoch 24, Loss: 0.5558848286079988\n",
      "Epoch 25, Loss: 0.5557997123991368\n",
      "Epoch 26, Loss: 0.555643413139907\n",
      "Epoch 27, Loss: 0.5554516860766003\n",
      "Epoch 28, Loss: 0.5552221327516685\n",
      "Epoch 29, Loss: 0.5549311841366221\n",
      "Epoch 30, Loss: 0.5545828814639633\n",
      "Epoch 31, Loss: 0.5541770090366598\n",
      "Epoch 32, Loss: 0.5537037520976821\n",
      "Epoch 33, Loss: 0.5531472864348743\n",
      "Epoch 34, Loss: 0.5525105700625308\n",
      "Epoch 35, Loss: 0.551778040152246\n",
      "Epoch 36, Loss: 0.5508986814588028\n",
      "Epoch 37, Loss: 0.5498105687424814\n",
      "Epoch 38, Loss: 0.5484482343009037\n",
      "Epoch 39, Loss: 0.5467499453749977\n",
      "Epoch 40, Loss: 0.5447014256774723\n",
      "Epoch 41, Loss: 0.5424569276771507\n",
      "Epoch 42, Loss: 0.5399176959611695\n",
      "Epoch 43, Loss: 0.5370581862592594\n",
      "Epoch 44, Loss: 0.5340005131301129\n",
      "Epoch 45, Loss: 0.5308688142567457\n",
      "Epoch 46, Loss: 0.5276825558219453\n",
      "Epoch 47, Loss: 0.524373939158443\n",
      "Epoch 48, Loss: 0.5206758324581149\n",
      "Epoch 49, Loss: 0.5165717651773226\n",
      "Epoch 50, Loss: 0.512003782837647\n",
      "Epoch 51, Loss: 0.5072634443021473\n",
      "Epoch 52, Loss: 0.5029918743315238\n",
      "Epoch 53, Loss: 0.49994225466585024\n",
      "Epoch 54, Loss: 0.4978990223151156\n",
      "Epoch 55, Loss: 0.49513638852299424\n",
      "Epoch 56, Loss: 0.49089985395360575\n",
      "Epoch 57, Loss: 0.4863673734339036\n",
      "Epoch 58, Loss: 0.4826252157422749\n",
      "Epoch 59, Loss: 0.4801422963968473\n",
      "Epoch 60, Loss: 0.47834651839407866\n",
      "Epoch 61, Loss: 0.476597065531933\n",
      "Epoch 62, Loss: 0.47453511602982945\n",
      "Epoch 63, Loss: 0.47199205752939777\n",
      "Epoch 64, Loss: 0.4690259598001517\n",
      "Epoch 65, Loss: 0.4662755984471386\n",
      "Epoch 66, Loss: 0.46417820191332226\n",
      "Epoch 67, Loss: 0.4625766993408706\n",
      "Epoch 68, Loss: 0.46131459667709757\n",
      "Epoch 69, Loss: 0.46047041551944384\n",
      "Epoch 70, Loss: 0.4600904246011035\n",
      "Epoch 71, Loss: 0.4597101682082763\n",
      "Epoch 72, Loss: 0.45915726996786044\n",
      "Epoch 73, Loss: 0.4583035228166854\n",
      "Epoch 74, Loss: 0.45721997334108894\n",
      "Epoch 75, Loss: 0.4560378763829318\n",
      "Epoch 76, Loss: 0.4549228255877618\n",
      "Epoch 77, Loss: 0.45401311853965914\n",
      "Epoch 78, Loss: 0.4532137487909258\n",
      "Epoch 79, Loss: 0.4525165254251941\n",
      "Epoch 80, Loss: 0.45181006340924423\n",
      "Epoch 81, Loss: 0.4511953240448208\n",
      "Epoch 82, Loss: 0.4506269690090975\n",
      "Epoch 83, Loss: 0.4500907395854195\n",
      "Epoch 84, Loss: 0.4495183360366673\n",
      "Epoch 85, Loss: 0.4489567365713851\n",
      "Epoch 86, Loss: 0.44843691915547573\n",
      "Epoch 87, Loss: 0.447886057480579\n",
      "Epoch 88, Loss: 0.4473130146890845\n",
      "Epoch 89, Loss: 0.44668763307510984\n",
      "Epoch 90, Loss: 0.44608504225053597\n",
      "Epoch 91, Loss: 0.44544765027726335\n",
      "Epoch 92, Loss: 0.44483291165246247\n",
      "Epoch 93, Loss: 0.4442273688511717\n",
      "Epoch 94, Loss: 0.4436373070551908\n",
      "Epoch 95, Loss: 0.4430360833718533\n",
      "Epoch 96, Loss: 0.44243414372619233\n",
      "Epoch 97, Loss: 0.4418314514660891\n",
      "Epoch 98, Loss: 0.441207739829828\n",
      "Epoch 99, Loss: 0.4405743008387519\n",
      "Epoch 100, Loss: 0.43994215140665943\n",
      "Epoch 101, Loss: 0.4392919626356477\n",
      "Epoch 102, Loss: 0.43864441103747304\n",
      "Epoch 103, Loss: 0.43797793849270905\n",
      "Epoch 104, Loss: 0.437313721373094\n",
      "Epoch 105, Loss: 0.43662655015785473\n",
      "Epoch 106, Loss: 0.4359379539350655\n",
      "Epoch 107, Loss: 0.4352669949924748\n",
      "Epoch 108, Loss: 0.4345429315406259\n",
      "Epoch 109, Loss: 0.4338320515443085\n",
      "Epoch 110, Loss: 0.4331935203870304\n",
      "Epoch 111, Loss: 0.4325231617861094\n",
      "Epoch 112, Loss: 0.431884765625\n",
      "Epoch 113, Loss: 0.4312590038354768\n",
      "Epoch 114, Loss: 0.4306360525420869\n",
      "Epoch 115, Loss: 0.43003933113998294\n",
      "Epoch 116, Loss: 0.42944219696425434\n",
      "Epoch 117, Loss: 0.4288531960226284\n",
      "Epoch 118, Loss: 0.4282578526716128\n",
      "Epoch 119, Loss: 0.4276743981800292\n",
      "Epoch 120, Loss: 0.4271091437875566\n",
      "Epoch 121, Loss: 0.4265809380036251\n",
      "Epoch 122, Loss: 0.42609651075755034\n",
      "Epoch 123, Loss: 0.4256428834964399\n",
      "Epoch 124, Loss: 0.4251026029713045\n",
      "Epoch 125, Loss: 0.4244162877634962\n",
      "Epoch 126, Loss: 0.4238515399143028\n",
      "Epoch 127, Loss: 0.42344317555582905\n",
      "Epoch 128, Loss: 0.42305021487227074\n",
      "Epoch 129, Loss: 0.422531993884779\n",
      "Epoch 130, Loss: 0.42196682531119434\n",
      "Epoch 131, Loss: 0.4214247667588852\n",
      "Epoch 132, Loss: 0.4210158182194334\n",
      "Epoch 133, Loss: 0.4205860828744136\n",
      "Epoch 134, Loss: 0.420078390361524\n",
      "Epoch 135, Loss: 0.4194207505912135\n",
      "Epoch 136, Loss: 0.4188675174642464\n",
      "Epoch 137, Loss: 0.41839572452950935\n",
      "Epoch 138, Loss: 0.41791994041588126\n",
      "Epoch 139, Loss: 0.4174025791969544\n",
      "Epoch 140, Loss: 0.41681027520473024\n",
      "Epoch 141, Loss: 0.4161944833167614\n",
      "Epoch 142, Loss: 0.4155888764020856\n",
      "Epoch 143, Loss: 0.4151283257927552\n",
      "Epoch 144, Loss: 0.4148023760722482\n",
      "Epoch 145, Loss: 0.41443840094180634\n",
      "Epoch 146, Loss: 0.41414720640510255\n",
      "Epoch 147, Loss: 0.4134998997880752\n",
      "Epoch 148, Loss: 0.4126915999686506\n",
      "Epoch 149, Loss: 0.412210117699971\n",
      "Epoch 150, Loss: 0.4119576269692696\n",
      "Epoch 151, Loss: 0.4115433987274031\n",
      "Epoch 152, Loss: 0.4108432465873217\n",
      "Epoch 153, Loss: 0.4102140113485386\n",
      "Epoch 154, Loss: 0.40981116537272694\n",
      "Epoch 155, Loss: 0.40956383564948234\n",
      "Epoch 156, Loss: 0.40945192444219\n",
      "Epoch 157, Loss: 0.40913928066846444\n",
      "Epoch 158, Loss: 0.40828366374876435\n",
      "Epoch 159, Loss: 0.4075888981710617\n",
      "Epoch 160, Loss: 0.40728936751644385\n",
      "Epoch 161, Loss: 0.40694414037701065\n",
      "Epoch 162, Loss: 0.40663035633559275\n",
      "Epoch 163, Loss: 0.4061496500639985\n",
      "Epoch 164, Loss: 0.4055408928109722\n",
      "Epoch 165, Loss: 0.4050762937940298\n",
      "Epoch 166, Loss: 0.4046758451219542\n",
      "Epoch 167, Loss: 0.4043205180603346\n",
      "Epoch 168, Loss: 0.40408481804738916\n",
      "Epoch 169, Loss: 0.40398435446215925\n",
      "Epoch 170, Loss: 0.403844700298034\n",
      "Epoch 171, Loss: 0.4034354204970824\n",
      "Epoch 172, Loss: 0.40259827275997684\n",
      "Epoch 173, Loss: 0.40190799040818337\n",
      "Epoch 174, Loss: 0.4017152599597077\n",
      "Epoch 175, Loss: 0.40166942790706084\n",
      "Epoch 176, Loss: 0.4012682530597931\n",
      "Epoch 177, Loss: 0.4005839741629441\n",
      "Epoch 178, Loss: 0.3999784441444564\n",
      "Epoch 179, Loss: 0.3996958776018043\n",
      "Epoch 180, Loss: 0.39962419797490517\n",
      "Epoch 181, Loss: 0.3994823667886303\n",
      "Epoch 182, Loss: 0.3989916295366262\n",
      "Epoch 183, Loss: 0.39841328341623344\n",
      "Epoch 184, Loss: 0.39802621669900795\n",
      "Epoch 185, Loss: 0.39744086062550277\n",
      "Epoch 186, Loss: 0.3970036605983286\n",
      "Epoch 187, Loss: 0.39688492259439717\n",
      "Epoch 188, Loss: 0.3967104112455646\n",
      "Epoch 189, Loss: 0.39651568058992265\n",
      "Epoch 190, Loss: 0.3966224505152907\n",
      "Epoch 191, Loss: 0.39644583153002383\n",
      "Epoch 192, Loss: 0.3958836970998527\n",
      "Epoch 193, Loss: 0.3948119836006453\n",
      "Epoch 194, Loss: 0.3948406290611042\n",
      "Epoch 195, Loss: 0.3949749972180404\n",
      "Epoch 196, Loss: 0.39450507502077564\n",
      "Epoch 197, Loss: 0.39441890816716874\n",
      "Epoch 198, Loss: 0.393670152712274\n",
      "Epoch 199, Loss: 0.39295601568198224\n",
      "Epoch 200, Loss: 0.3933197721302769\n",
      "Epoch 201, Loss: 0.39277211420945035\n",
      "Epoch 202, Loss: 0.3926354361686182\n",
      "Epoch 203, Loss: 0.3925175216736492\n",
      "Epoch 204, Loss: 0.3916761940784822\n",
      "Epoch 205, Loss: 0.39160304651906697\n",
      "Epoch 206, Loss: 0.3910513268024278\n",
      "Epoch 207, Loss: 0.39061639776294793\n",
      "Epoch 208, Loss: 0.39056922514410836\n",
      "Epoch 209, Loss: 0.3901800482492223\n",
      "Epoch 210, Loss: 0.3901957060296082\n",
      "Epoch 211, Loss: 0.39069520319470846\n",
      "Epoch 212, Loss: 0.39066873305604777\n",
      "Epoch 213, Loss: 0.3909879905241731\n",
      "Epoch 214, Loss: 0.3901009286594167\n",
      "Epoch 215, Loss: 0.38828743559363976\n",
      "Epoch 216, Loss: 0.38851636142841184\n",
      "Epoch 217, Loss: 0.3889596726602721\n",
      "Epoch 218, Loss: 0.38907412699289123\n",
      "Epoch 219, Loss: 0.3874534602058586\n",
      "Epoch 220, Loss: 0.3863860153471824\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.24425667937004308\n",
      "Test R^2 score: 0.35091698735781485\n",
      "Num of epochs: 221\n",
      "Epoch 1, Loss: 0.5717153409703516\n",
      "Epoch 2, Loss: 0.5701156955972606\n",
      "Epoch 3, Loss: 0.5685303158976492\n",
      "Epoch 4, Loss: 0.5670398719701827\n",
      "Epoch 5, Loss: 0.5656632120702828\n",
      "Epoch 6, Loss: 0.5644011424062537\n",
      "Epoch 7, Loss: 0.5632380306260615\n",
      "Epoch 8, Loss: 0.5621731391247253\n",
      "Epoch 9, Loss: 0.5612030973143695\n",
      "Epoch 10, Loss: 0.5603274670297025\n",
      "Epoch 11, Loss: 0.5595450403921044\n",
      "Epoch 12, Loss: 0.5588539691176929\n",
      "Epoch 13, Loss: 0.5582525104649048\n",
      "Epoch 14, Loss: 0.5577365994572714\n",
      "Epoch 15, Loss: 0.5573002169894938\n",
      "Epoch 16, Loss: 0.556941222289614\n",
      "Epoch 17, Loss: 0.5566522429742891\n",
      "Epoch 18, Loss: 0.5564263985640568\n",
      "Epoch 19, Loss: 0.5562539882731242\n",
      "Epoch 20, Loss: 0.5561189314909183\n",
      "Epoch 21, Loss: 0.5560046394209469\n",
      "Epoch 22, Loss: 0.5559077206334369\n",
      "Epoch 23, Loss: 0.5558233585873387\n",
      "Epoch 24, Loss: 0.555727909757652\n",
      "Epoch 25, Loss: 0.5556091388717017\n",
      "Epoch 26, Loss: 0.5554687478538974\n",
      "Epoch 27, Loss: 0.5553038222150641\n",
      "Epoch 28, Loss: 0.555090958985825\n",
      "Epoch 29, Loss: 0.5548265309778623\n",
      "Epoch 30, Loss: 0.5545071590776658\n",
      "Epoch 31, Loss: 0.5541205665467818\n",
      "Epoch 32, Loss: 0.5536494414342644\n",
      "Epoch 33, Loss: 0.5530819558243378\n",
      "Epoch 34, Loss: 0.5523891112007105\n",
      "Epoch 35, Loss: 0.551537799011942\n",
      "Epoch 36, Loss: 0.5505221142809595\n",
      "Epoch 37, Loss: 0.5492595727977918\n",
      "Epoch 38, Loss: 0.5477008306231982\n",
      "Epoch 39, Loss: 0.5458308742797826\n",
      "Epoch 40, Loss: 0.5436487399557922\n",
      "Epoch 41, Loss: 0.5412968754897893\n",
      "Epoch 42, Loss: 0.5388572412660367\n",
      "Epoch 43, Loss: 0.5364780669301865\n",
      "Epoch 44, Loss: 0.5342216963350642\n",
      "Epoch 45, Loss: 0.5319348016777351\n",
      "Epoch 46, Loss: 0.5294474144850412\n",
      "Epoch 47, Loss: 0.5267334125823796\n",
      "Epoch 48, Loss: 0.5238528240846836\n",
      "Epoch 49, Loss: 0.5207523823453312\n",
      "Epoch 50, Loss: 0.5175158769134658\n",
      "Epoch 51, Loss: 0.5140513479768154\n",
      "Epoch 52, Loss: 0.5102576442745855\n",
      "Epoch 53, Loss: 0.5060731885171603\n",
      "Epoch 54, Loss: 0.5014809491655152\n",
      "Epoch 55, Loss: 0.49649438675360946\n",
      "Epoch 56, Loss: 0.4911999862390541\n",
      "Epoch 57, Loss: 0.4861788539762555\n",
      "Epoch 58, Loss: 0.48174310724705033\n",
      "Epoch 59, Loss: 0.47842873543473424\n",
      "Epoch 60, Loss: 0.476174102477574\n",
      "Epoch 61, Loss: 0.47435884181813537\n",
      "Epoch 62, Loss: 0.47292414867963545\n",
      "Epoch 63, Loss: 0.4720471769068461\n",
      "Epoch 64, Loss: 0.47191943913060275\n",
      "Epoch 65, Loss: 0.47198337548284236\n",
      "Epoch 66, Loss: 0.4716170054106197\n",
      "Epoch 67, Loss: 0.4708667328333863\n",
      "Epoch 68, Loss: 0.470097575711684\n",
      "Epoch 69, Loss: 0.46901055088355476\n",
      "Epoch 70, Loss: 0.46760183224853413\n",
      "Epoch 71, Loss: 0.4665070755443438\n",
      "Epoch 72, Loss: 0.4656095527800411\n",
      "Epoch 73, Loss: 0.46457459166418064\n",
      "Epoch 74, Loss: 0.4636531617165311\n",
      "Epoch 75, Loss: 0.46309779557033115\n",
      "Epoch 76, Loss: 0.4626860830627206\n",
      "Epoch 77, Loss: 0.46218715603230787\n",
      "Epoch 78, Loss: 0.46165292790291224\n",
      "Epoch 79, Loss: 0.461044832437951\n",
      "Epoch 80, Loss: 0.46028003031672454\n",
      "Epoch 81, Loss: 0.45941889871017827\n",
      "Epoch 82, Loss: 0.4586927420824305\n",
      "Epoch 83, Loss: 0.4580643543732092\n",
      "Epoch 84, Loss: 0.45735554723247873\n",
      "Epoch 85, Loss: 0.4565818239701029\n",
      "Epoch 86, Loss: 0.45572693052197394\n",
      "Epoch 87, Loss: 0.4549109352364773\n",
      "Epoch 88, Loss: 0.4542130692280617\n",
      "Epoch 89, Loss: 0.45362178930017244\n",
      "Epoch 90, Loss: 0.45309337966033475\n",
      "Epoch 91, Loss: 0.4525434115961914\n",
      "Epoch 92, Loss: 0.45201108753691194\n",
      "Epoch 93, Loss: 0.45149536425723164\n",
      "Epoch 94, Loss: 0.45093741662123155\n",
      "Epoch 95, Loss: 0.4504206790474812\n",
      "Epoch 96, Loss: 0.4499400443296457\n",
      "Epoch 97, Loss: 0.44946522792392857\n",
      "Epoch 98, Loss: 0.44901609410623405\n",
      "Epoch 99, Loss: 0.4485394026449176\n",
      "Epoch 100, Loss: 0.44807208122516373\n",
      "Epoch 101, Loss: 0.44762043435187265\n",
      "Epoch 102, Loss: 0.4471540186868536\n",
      "Epoch 103, Loss: 0.44666603244314196\n",
      "Epoch 104, Loss: 0.44617320420393336\n",
      "Epoch 105, Loss: 0.4456993397076384\n",
      "Epoch 106, Loss: 0.44521325661890315\n",
      "Epoch 107, Loss: 0.44474868886903396\n",
      "Epoch 108, Loss: 0.4442639135318964\n",
      "Epoch 109, Loss: 0.44378614681398504\n",
      "Epoch 110, Loss: 0.4432607700752079\n",
      "Epoch 111, Loss: 0.4426794341883564\n",
      "Epoch 112, Loss: 0.442019096226304\n",
      "Epoch 113, Loss: 0.44132733272536073\n",
      "Epoch 114, Loss: 0.44077056076681576\n",
      "Epoch 115, Loss: 0.44019869818059487\n",
      "Epoch 116, Loss: 0.43961504178541166\n",
      "Epoch 117, Loss: 0.43908553962396957\n",
      "Epoch 118, Loss: 0.43856345082571774\n",
      "Epoch 119, Loss: 0.437982327389943\n",
      "Epoch 120, Loss: 0.43737692464190797\n",
      "Epoch 121, Loss: 0.4368257606437722\n",
      "Epoch 122, Loss: 0.4362918486921591\n",
      "Epoch 123, Loss: 0.43574086817016305\n",
      "Epoch 124, Loss: 0.43521447605432007\n",
      "Epoch 125, Loss: 0.4347287692808282\n",
      "Epoch 126, Loss: 0.4342634682211117\n",
      "Epoch 127, Loss: 0.43379059181132734\n",
      "Epoch 128, Loss: 0.4333285474360103\n",
      "Epoch 129, Loss: 0.4328703817506193\n",
      "Epoch 130, Loss: 0.43240821561802867\n",
      "Epoch 131, Loss: 0.4319387588692382\n",
      "Epoch 132, Loss: 0.4314498479767939\n",
      "Epoch 133, Loss: 0.4309137360214899\n",
      "Epoch 134, Loss: 0.430330714059837\n",
      "Epoch 135, Loss: 0.42975690454547555\n",
      "Epoch 136, Loss: 0.42921605690137965\n",
      "Epoch 137, Loss: 0.42852295944905755\n",
      "Epoch 138, Loss: 0.4279155782848559\n",
      "Epoch 139, Loss: 0.4274120771330628\n",
      "Epoch 140, Loss: 0.42687117338908936\n",
      "Epoch 141, Loss: 0.42624030608399605\n",
      "Epoch 142, Loss: 0.42564951757432595\n",
      "Epoch 143, Loss: 0.4251842863574606\n",
      "Epoch 144, Loss: 0.42469221358108006\n",
      "Epoch 145, Loss: 0.424119822592239\n",
      "Epoch 146, Loss: 0.4235821198963829\n",
      "Epoch 147, Loss: 0.42312192312837654\n",
      "Epoch 148, Loss: 0.42266131343382235\n",
      "Epoch 149, Loss: 0.42211285702831125\n",
      "Epoch 150, Loss: 0.4215319262842826\n",
      "Epoch 151, Loss: 0.42101480950768344\n",
      "Epoch 152, Loss: 0.4205448054631771\n",
      "Epoch 153, Loss: 0.42013783778785113\n",
      "Epoch 154, Loss: 0.4197799620246879\n",
      "Epoch 155, Loss: 0.4193419777195736\n",
      "Epoch 156, Loss: 0.4187108163862803\n",
      "Epoch 157, Loss: 0.4180653897090209\n",
      "Epoch 158, Loss: 0.4176428941788275\n",
      "Epoch 159, Loss: 0.41733049520897586\n",
      "Epoch 160, Loss: 0.4168916889378834\n",
      "Epoch 161, Loss: 0.4162797760838192\n",
      "Epoch 162, Loss: 0.41566301903326175\n",
      "Epoch 163, Loss: 0.4151264233368063\n",
      "Epoch 164, Loss: 0.41469399861789696\n",
      "Epoch 165, Loss: 0.4144721973284165\n",
      "Epoch 166, Loss: 0.4146610648001956\n",
      "Epoch 167, Loss: 0.41443004130401345\n",
      "Epoch 168, Loss: 0.41320600635939764\n",
      "Epoch 169, Loss: 0.41248640558209804\n",
      "Epoch 170, Loss: 0.41280342704280043\n",
      "Epoch 171, Loss: 0.411990071605292\n",
      "Epoch 172, Loss: 0.4112584699031006\n",
      "Epoch 173, Loss: 0.41138894264566567\n",
      "Epoch 174, Loss: 0.4106805084833947\n",
      "Epoch 175, Loss: 0.41000543273838747\n",
      "Epoch 176, Loss: 0.40995941888783277\n",
      "Epoch 177, Loss: 0.409386539296596\n",
      "Epoch 178, Loss: 0.4088113989197728\n",
      "Epoch 179, Loss: 0.4086852990426773\n",
      "Epoch 180, Loss: 0.4082633891178925\n",
      "Epoch 181, Loss: 0.4076276491775688\n",
      "Epoch 182, Loss: 0.40735914967249653\n",
      "Epoch 183, Loss: 0.40717267747953145\n",
      "Epoch 184, Loss: 0.4067081655501908\n",
      "Epoch 185, Loss: 0.4060860449723056\n",
      "Epoch 186, Loss: 0.4058206380030779\n",
      "Epoch 187, Loss: 0.40560631008026954\n",
      "Epoch 188, Loss: 0.40530757530473493\n",
      "Epoch 189, Loss: 0.4046194291766893\n",
      "Epoch 190, Loss: 0.4041638547104746\n",
      "Epoch 191, Loss: 0.40384717247296514\n",
      "Epoch 192, Loss: 0.40367297624777776\n",
      "Epoch 193, Loss: 0.4035268259478758\n",
      "Epoch 194, Loss: 0.40315250480325077\n",
      "Epoch 195, Loss: 0.4026978795325637\n",
      "Epoch 196, Loss: 0.4018797745428443\n",
      "Epoch 197, Loss: 0.4015167774338733\n",
      "Epoch 198, Loss: 0.40120963092599005\n",
      "Epoch 199, Loss: 0.4012194730608198\n",
      "Epoch 200, Loss: 0.4008317331862415\n",
      "Epoch 201, Loss: 0.40027972290429165\n",
      "Epoch 202, Loss: 0.399743576112702\n",
      "Epoch 203, Loss: 0.39908433282405337\n",
      "Epoch 204, Loss: 0.3988200015922999\n",
      "Epoch 205, Loss: 0.3984913883044534\n",
      "Epoch 206, Loss: 0.3984383601759059\n",
      "Epoch 207, Loss: 0.3980460581523087\n",
      "Epoch 208, Loss: 0.39777669150624756\n",
      "Epoch 209, Loss: 0.397685950318632\n",
      "Epoch 210, Loss: 0.3967359148949415\n",
      "Epoch 211, Loss: 0.39618793925140483\n",
      "Epoch 212, Loss: 0.39539763246366755\n",
      "Epoch 213, Loss: 0.39558490896557413\n",
      "Epoch 214, Loss: 0.3953002196504102\n",
      "Epoch 215, Loss: 0.395607189362117\n",
      "Epoch 216, Loss: 0.3959371238291217\n",
      "Epoch 217, Loss: 0.3945936587989069\n",
      "Epoch 218, Loss: 0.39345513308084495\n",
      "Epoch 219, Loss: 0.39346439281781165\n",
      "Epoch 220, Loss: 0.39416528479083196\n",
      "Epoch 221, Loss: 0.39272981057095635\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.23571595452809818\n",
      "Test R^2 score: 0.399840421473604\n",
      "Num of epochs: 222\n",
      "Epoch 1, Loss: 0.5602220930190297\n",
      "Epoch 2, Loss: 0.5592225277206327\n",
      "Epoch 3, Loss: 0.5583777643668614\n",
      "Epoch 4, Loss: 0.5576778185161284\n",
      "Epoch 5, Loss: 0.5571226743170709\n",
      "Epoch 6, Loss: 0.5567080005225724\n",
      "Epoch 7, Loss: 0.5564255951601211\n",
      "Epoch 8, Loss: 0.5562583815553961\n",
      "Epoch 9, Loss: 0.5561882724158611\n",
      "Epoch 10, Loss: 0.5561945951922075\n",
      "Epoch 11, Loss: 0.5562480947911927\n",
      "Epoch 12, Loss: 0.5563229909434158\n",
      "Epoch 13, Loss: 0.5563961362147194\n",
      "Epoch 14, Loss: 0.5564477151247791\n",
      "Epoch 15, Loss: 0.5564689237566806\n",
      "Epoch 16, Loss: 0.5564566057102925\n",
      "Epoch 17, Loss: 0.556411588965117\n",
      "Epoch 18, Loss: 0.5563391956866534\n",
      "Epoch 19, Loss: 0.556249059183418\n",
      "Epoch 20, Loss: 0.5561444128742025\n",
      "Epoch 21, Loss: 0.5560308496197961\n",
      "Epoch 22, Loss: 0.5559124919204895\n",
      "Epoch 23, Loss: 0.5557900337938612\n",
      "Epoch 24, Loss: 0.5556630434586712\n",
      "Epoch 25, Loss: 0.5555284063010342\n",
      "Epoch 26, Loss: 0.5553764041159097\n",
      "Epoch 27, Loss: 0.5551983804389187\n",
      "Epoch 28, Loss: 0.5549884570699886\n",
      "Epoch 29, Loss: 0.5547400704845132\n",
      "Epoch 30, Loss: 0.5544322595194919\n",
      "Epoch 31, Loss: 0.5540402894535731\n",
      "Epoch 32, Loss: 0.5535457842463963\n",
      "Epoch 33, Loss: 0.5529310058664271\n",
      "Epoch 34, Loss: 0.5521735591456328\n",
      "Epoch 35, Loss: 0.5512267130736069\n",
      "Epoch 36, Loss: 0.5500389399615397\n",
      "Epoch 37, Loss: 0.5485742056246271\n",
      "Epoch 38, Loss: 0.5468058951176594\n",
      "Epoch 39, Loss: 0.5447184959079696\n",
      "Epoch 40, Loss: 0.5423020035819426\n",
      "Epoch 41, Loss: 0.5395859926911832\n",
      "Epoch 42, Loss: 0.5366161787035345\n",
      "Epoch 43, Loss: 0.533359211303811\n",
      "Epoch 44, Loss: 0.5297749179958294\n",
      "Epoch 45, Loss: 0.5257938071759366\n",
      "Epoch 46, Loss: 0.5213959865457304\n",
      "Epoch 47, Loss: 0.516638655313394\n",
      "Epoch 48, Loss: 0.5117077425872115\n",
      "Epoch 49, Loss: 0.5070550992320525\n",
      "Epoch 50, Loss: 0.5033902328058211\n",
      "Epoch 51, Loss: 0.5009145716930786\n",
      "Epoch 52, Loss: 0.49842607610639633\n",
      "Epoch 53, Loss: 0.4944406284748774\n",
      "Epoch 54, Loss: 0.4895417232957669\n",
      "Epoch 55, Loss: 0.48525213992449334\n",
      "Epoch 56, Loss: 0.4826711404515802\n",
      "Epoch 57, Loss: 0.4806366758825767\n",
      "Epoch 58, Loss: 0.47781860033311285\n",
      "Epoch 59, Loss: 0.4746105523742389\n",
      "Epoch 60, Loss: 0.472006674577913\n",
      "Epoch 61, Loss: 0.47017264647209933\n",
      "Epoch 62, Loss: 0.468593412312039\n",
      "Epoch 63, Loss: 0.46699106494700043\n",
      "Epoch 64, Loss: 0.46538851576284396\n",
      "Epoch 65, Loss: 0.4639550055647294\n",
      "Epoch 66, Loss: 0.4626236318615955\n",
      "Epoch 67, Loss: 0.46110849926328845\n",
      "Epoch 68, Loss: 0.45970225906277545\n",
      "Epoch 69, Loss: 0.45869855706640994\n",
      "Epoch 70, Loss: 0.45754563492247796\n",
      "Epoch 71, Loss: 0.4558891306288258\n",
      "Epoch 72, Loss: 0.4545811899183017\n",
      "Epoch 73, Loss: 0.45351340649018634\n",
      "Epoch 74, Loss: 0.4522814956545237\n",
      "Epoch 75, Loss: 0.45125009428430135\n",
      "Epoch 76, Loss: 0.4502371646517332\n",
      "Epoch 77, Loss: 0.4489619308764182\n",
      "Epoch 78, Loss: 0.44796012697146687\n",
      "Epoch 79, Loss: 0.4467521451920984\n",
      "Epoch 80, Loss: 0.44561315726745615\n",
      "Epoch 81, Loss: 0.44459670243664134\n",
      "Epoch 82, Loss: 0.44350745127223284\n",
      "Epoch 83, Loss: 0.4425274105257003\n",
      "Epoch 84, Loss: 0.44148579446202924\n",
      "Epoch 85, Loss: 0.44053701036249227\n",
      "Epoch 86, Loss: 0.43950069593867036\n",
      "Epoch 87, Loss: 0.43846529667916123\n",
      "Epoch 88, Loss: 0.4374843151823165\n",
      "Epoch 89, Loss: 0.43645729400158984\n",
      "Epoch 90, Loss: 0.4355806927745373\n",
      "Epoch 91, Loss: 0.43465265072648723\n",
      "Epoch 92, Loss: 0.43366867998857017\n",
      "Epoch 93, Loss: 0.4328066581028846\n",
      "Epoch 94, Loss: 0.431929409723546\n",
      "Epoch 95, Loss: 0.4310071966561721\n",
      "Epoch 96, Loss: 0.43012880724835223\n",
      "Epoch 97, Loss: 0.42928361117253805\n",
      "Epoch 98, Loss: 0.4284500336152766\n",
      "Epoch 99, Loss: 0.42763157484502445\n",
      "Epoch 100, Loss: 0.4268398598858783\n",
      "Epoch 101, Loss: 0.42606466817283173\n",
      "Epoch 102, Loss: 0.4252763957354077\n",
      "Epoch 103, Loss: 0.4244730038185752\n",
      "Epoch 104, Loss: 0.42366778949088035\n",
      "Epoch 105, Loss: 0.4228755248154178\n",
      "Epoch 106, Loss: 0.4220831675339298\n",
      "Epoch 107, Loss: 0.42127193509843774\n",
      "Epoch 108, Loss: 0.4204735791153377\n",
      "Epoch 109, Loss: 0.4197582369604522\n",
      "Epoch 110, Loss: 0.419518263489745\n",
      "Epoch 111, Loss: 0.4206592915969613\n",
      "Epoch 112, Loss: 0.41926779262158814\n",
      "Epoch 113, Loss: 0.41684096584910274\n",
      "Epoch 114, Loss: 0.41787659885946177\n",
      "Epoch 115, Loss: 0.41570408219326016\n",
      "Epoch 116, Loss: 0.4156420646835569\n",
      "Epoch 117, Loss: 0.4149786153419706\n",
      "Epoch 118, Loss: 0.41368460054789175\n",
      "Epoch 119, Loss: 0.41399213804851664\n",
      "Epoch 120, Loss: 0.41218531844434486\n",
      "Epoch 121, Loss: 0.412341174702699\n",
      "Epoch 122, Loss: 0.41131772483726564\n",
      "Epoch 123, Loss: 0.4105601184280549\n",
      "Epoch 124, Loss: 0.4105099923710031\n",
      "Epoch 125, Loss: 0.4090549943612758\n",
      "Epoch 126, Loss: 0.4091227453118984\n",
      "Epoch 127, Loss: 0.4082773862028895\n",
      "Epoch 128, Loss: 0.40745550804993397\n",
      "Epoch 129, Loss: 0.4073921251270475\n",
      "Epoch 130, Loss: 0.40652982537976434\n",
      "Epoch 131, Loss: 0.4058061706211531\n",
      "Epoch 132, Loss: 0.40565265240920567\n",
      "Epoch 133, Loss: 0.4048930945703308\n",
      "Epoch 134, Loss: 0.4041072197910378\n",
      "Epoch 135, Loss: 0.4038718011505664\n",
      "Epoch 136, Loss: 0.4032561687605443\n",
      "Epoch 137, Loss: 0.4024739471438836\n",
      "Epoch 138, Loss: 0.4019666033710255\n",
      "Epoch 139, Loss: 0.40163295884710265\n",
      "Epoch 140, Loss: 0.4011873459548999\n",
      "Epoch 141, Loss: 0.4005294931151032\n",
      "Epoch 142, Loss: 0.3998947981237811\n",
      "Epoch 143, Loss: 0.3992931863923788\n",
      "Epoch 144, Loss: 0.3988828600949148\n",
      "Epoch 145, Loss: 0.3985339216359464\n",
      "Epoch 146, Loss: 0.39833166549378674\n",
      "Epoch 147, Loss: 0.39827124549030385\n",
      "Epoch 148, Loss: 0.3985005123202143\n",
      "Epoch 149, Loss: 0.39841939847629704\n",
      "Epoch 150, Loss: 0.3970429943499006\n",
      "Epoch 151, Loss: 0.3956694661141569\n",
      "Epoch 152, Loss: 0.395498449897622\n",
      "Epoch 153, Loss: 0.39599882188414637\n",
      "Epoch 154, Loss: 0.39545346110318835\n",
      "Epoch 155, Loss: 0.3943236909790794\n",
      "Epoch 156, Loss: 0.3935799981017059\n",
      "Epoch 157, Loss: 0.3936186518407082\n",
      "Epoch 158, Loss: 0.3937996605937032\n",
      "Epoch 159, Loss: 0.39330836839504735\n",
      "Epoch 160, Loss: 0.39244749258617967\n",
      "Epoch 161, Loss: 0.3916725798255196\n",
      "Epoch 162, Loss: 0.3915136909356405\n",
      "Epoch 163, Loss: 0.391668794335342\n",
      "Epoch 164, Loss: 0.3915295237350071\n",
      "Epoch 165, Loss: 0.39108874449992026\n",
      "Epoch 166, Loss: 0.3903060946461985\n",
      "Epoch 167, Loss: 0.3896015875240583\n",
      "Epoch 168, Loss: 0.38923674898249394\n",
      "Epoch 169, Loss: 0.38917181555155234\n",
      "Epoch 170, Loss: 0.389277556550755\n",
      "Epoch 171, Loss: 0.38942924587004235\n",
      "Epoch 172, Loss: 0.38948478225709365\n",
      "Epoch 173, Loss: 0.3890136672784023\n",
      "Epoch 174, Loss: 0.3880010979602459\n",
      "Epoch 175, Loss: 0.3871355026773971\n",
      "Epoch 176, Loss: 0.38681183282372733\n",
      "Epoch 177, Loss: 0.38692518947108906\n",
      "Epoch 178, Loss: 0.3871298252404854\n",
      "Epoch 179, Loss: 0.3871191822276294\n",
      "Epoch 180, Loss: 0.38669169938239734\n",
      "Epoch 181, Loss: 0.38590065320758643\n",
      "Epoch 182, Loss: 0.38513692377904174\n",
      "Epoch 183, Loss: 0.3846986973834909\n",
      "Epoch 184, Loss: 0.3846272253543025\n",
      "Epoch 185, Loss: 0.3848047769058677\n",
      "Epoch 186, Loss: 0.3852099452785327\n",
      "Epoch 187, Loss: 0.3854792024380507\n",
      "Epoch 188, Loss: 0.3853344464452356\n",
      "Epoch 189, Loss: 0.3842032141722809\n",
      "Epoch 190, Loss: 0.38300163112322927\n",
      "Epoch 191, Loss: 0.38261760888848073\n",
      "Epoch 192, Loss: 0.382998538063038\n",
      "Epoch 193, Loss: 0.3833680500847094\n",
      "Epoch 194, Loss: 0.38314662676285477\n",
      "Epoch 195, Loss: 0.38234045157434277\n",
      "Epoch 196, Loss: 0.38134216617241884\n",
      "Epoch 197, Loss: 0.3809533027832197\n",
      "Epoch 198, Loss: 0.38104622976672614\n",
      "Epoch 199, Loss: 0.3812705339311393\n",
      "Epoch 200, Loss: 0.3815080254211825\n",
      "Epoch 201, Loss: 0.38169411369329265\n",
      "Epoch 202, Loss: 0.3811156168940255\n",
      "Epoch 203, Loss: 0.3802419891441552\n",
      "Epoch 204, Loss: 0.3792520695003104\n",
      "Epoch 205, Loss: 0.37871224067231624\n",
      "Epoch 206, Loss: 0.37867777119951834\n",
      "Epoch 207, Loss: 0.37887895623447526\n",
      "Epoch 208, Loss: 0.37929261555818927\n",
      "Epoch 209, Loss: 0.37940401632463494\n",
      "Epoch 210, Loss: 0.37933777294985666\n",
      "Epoch 211, Loss: 0.3784405117088324\n",
      "Epoch 212, Loss: 0.37735242892881565\n",
      "Epoch 213, Loss: 0.37643487912474904\n",
      "Epoch 214, Loss: 0.3760607538460097\n",
      "Epoch 215, Loss: 0.37622416876521675\n",
      "Epoch 216, Loss: 0.3768914720785043\n",
      "Epoch 217, Loss: 0.378313840260283\n",
      "Epoch 218, Loss: 0.37897003266218204\n",
      "Epoch 219, Loss: 0.3780217415924948\n",
      "Epoch 220, Loss: 0.37544025962327215\n",
      "Epoch 221, Loss: 0.37387639833199665\n",
      "Epoch 222, Loss: 0.3749100060560575\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.24894567760207245\n",
      "Test R^2 score: 0.32771900913772467\n",
      "Num of epochs: 223\n",
      "Epoch 1, Loss: 0.5642099087491752\n",
      "Epoch 2, Loss: 0.5632310196785076\n",
      "Epoch 3, Loss: 0.5623106902829964\n",
      "Epoch 4, Loss: 0.5614506151828357\n",
      "Epoch 5, Loss: 0.5606525600637877\n",
      "Epoch 6, Loss: 0.5598918530226585\n",
      "Epoch 7, Loss: 0.5591967868888621\n",
      "Epoch 8, Loss: 0.5585700610279629\n",
      "Epoch 9, Loss: 0.5580847495197162\n",
      "Epoch 10, Loss: 0.5576474904713531\n",
      "Epoch 11, Loss: 0.5572652959080607\n",
      "Epoch 12, Loss: 0.5569395366995764\n",
      "Epoch 13, Loss: 0.5566706599113246\n",
      "Epoch 14, Loss: 0.5564595245763705\n",
      "Epoch 15, Loss: 0.5563130000152586\n",
      "Epoch 16, Loss: 0.5562045614564409\n",
      "Epoch 17, Loss: 0.5561347402678684\n",
      "Epoch 18, Loss: 0.5560974415514297\n",
      "Epoch 19, Loss: 0.5560745841333239\n",
      "Epoch 20, Loss: 0.5560820068680072\n",
      "Epoch 21, Loss: 0.5561021308235239\n",
      "Epoch 22, Loss: 0.5561170290484829\n",
      "Epoch 23, Loss: 0.5561085617609539\n",
      "Epoch 24, Loss: 0.5560777193799158\n",
      "Epoch 25, Loss: 0.5560092758753133\n",
      "Epoch 26, Loss: 0.5558978562696789\n",
      "Epoch 27, Loss: 0.5557383938434186\n",
      "Epoch 28, Loss: 0.555524141363908\n",
      "Epoch 29, Loss: 0.5552464476260921\n",
      "Epoch 30, Loss: 0.5548935896871857\n",
      "Epoch 31, Loss: 0.5544455363181751\n",
      "Epoch 32, Loss: 0.5538854307235506\n",
      "Epoch 33, Loss: 0.5532146833742565\n",
      "Epoch 34, Loss: 0.5523133308634909\n",
      "Epoch 35, Loss: 0.5511861624917221\n",
      "Epoch 36, Loss: 0.5498236319223844\n",
      "Epoch 37, Loss: 0.5481331385548733\n",
      "Epoch 38, Loss: 0.5461021138916428\n",
      "Epoch 39, Loss: 0.5436252220628767\n",
      "Epoch 40, Loss: 0.540701351397113\n",
      "Epoch 41, Loss: 0.5374027352710304\n",
      "Epoch 42, Loss: 0.5340167813628856\n",
      "Epoch 43, Loss: 0.5310991297396362\n",
      "Epoch 44, Loss: 0.529493541708762\n",
      "Epoch 45, Loss: 0.5289332699882076\n",
      "Epoch 46, Loss: 0.5275904608173599\n",
      "Epoch 47, Loss: 0.5248330713737628\n",
      "Epoch 48, Loss: 0.5218130497510899\n",
      "Epoch 49, Loss: 0.5196608761719078\n",
      "Epoch 50, Loss: 0.5185294567227269\n",
      "Epoch 51, Loss: 0.5174362276008407\n",
      "Epoch 52, Loss: 0.5157851924011753\n",
      "Epoch 53, Loss: 0.5135971130966592\n",
      "Epoch 54, Loss: 0.5112236190089261\n",
      "Epoch 55, Loss: 0.5091160988033078\n",
      "Epoch 56, Loss: 0.5074950766676949\n",
      "Epoch 57, Loss: 0.5059674710873748\n",
      "Epoch 58, Loss: 0.5039978239848831\n",
      "Epoch 59, Loss: 0.5017574834469867\n",
      "Epoch 60, Loss: 0.49974722731328236\n",
      "Epoch 61, Loss: 0.49823257873672655\n",
      "Epoch 62, Loss: 0.49676952742105457\n",
      "Epoch 63, Loss: 0.49492453414094245\n",
      "Epoch 64, Loss: 0.4928097197866058\n",
      "Epoch 65, Loss: 0.49083473861387383\n",
      "Epoch 66, Loss: 0.48907555632789457\n",
      "Epoch 67, Loss: 0.48709962922283606\n",
      "Epoch 68, Loss: 0.4851240396173137\n",
      "Epoch 69, Loss: 0.48341418924580765\n",
      "Epoch 70, Loss: 0.48171050407090604\n",
      "Epoch 71, Loss: 0.4798190834167183\n",
      "Epoch 72, Loss: 0.47807380364772084\n",
      "Epoch 73, Loss: 0.4765153767785587\n",
      "Epoch 74, Loss: 0.4746630445990212\n",
      "Epoch 75, Loss: 0.47251038625695524\n",
      "Epoch 76, Loss: 0.4703193144447176\n",
      "Epoch 77, Loss: 0.4680015788082244\n",
      "Epoch 78, Loss: 0.46573516579335383\n",
      "Epoch 79, Loss: 0.4638380503287268\n",
      "Epoch 80, Loss: 0.46205208069302195\n",
      "Epoch 81, Loss: 0.4605728905652732\n",
      "Epoch 82, Loss: 0.4597598889818733\n",
      "Epoch 83, Loss: 0.45940983309346534\n",
      "Epoch 84, Loss: 0.4591886836719846\n",
      "Epoch 85, Loss: 0.45851138478416453\n",
      "Epoch 86, Loss: 0.45739809621090294\n",
      "Epoch 87, Loss: 0.45610882521490315\n",
      "Epoch 88, Loss: 0.454818586087811\n",
      "Epoch 89, Loss: 0.4539758323610125\n",
      "Epoch 90, Loss: 0.4532231027362172\n",
      "Epoch 91, Loss: 0.4525470665432546\n",
      "Epoch 92, Loss: 0.451671439364978\n",
      "Epoch 93, Loss: 0.4507592035518695\n",
      "Epoch 94, Loss: 0.44992951264930847\n",
      "Epoch 95, Loss: 0.44921306108935993\n",
      "Epoch 96, Loss: 0.4484356564473926\n",
      "Epoch 97, Loss: 0.44762740849494387\n",
      "Epoch 98, Loss: 0.44680449189632065\n",
      "Epoch 99, Loss: 0.4459937389387624\n",
      "Epoch 100, Loss: 0.44515570172228913\n",
      "Epoch 101, Loss: 0.44428742531684384\n",
      "Epoch 102, Loss: 0.44337369248719277\n",
      "Epoch 103, Loss: 0.4424313988015028\n",
      "Epoch 104, Loss: 0.44157494216311255\n",
      "Epoch 105, Loss: 0.44075977617955514\n",
      "Epoch 106, Loss: 0.4399314819977856\n",
      "Epoch 107, Loss: 0.4391355256953708\n",
      "Epoch 108, Loss: 0.43838717562667906\n",
      "Epoch 109, Loss: 0.4377920844677332\n",
      "Epoch 110, Loss: 0.4375798118543811\n",
      "Epoch 111, Loss: 0.4368941676419573\n",
      "Epoch 112, Loss: 0.4355168524688458\n",
      "Epoch 113, Loss: 0.43518987488060973\n",
      "Epoch 114, Loss: 0.4345415770213326\n",
      "Epoch 115, Loss: 0.4334327123772226\n",
      "Epoch 116, Loss: 0.43312071006819214\n",
      "Epoch 117, Loss: 0.4321430441057686\n",
      "Epoch 118, Loss: 0.43144955440869137\n",
      "Epoch 119, Loss: 0.4310406446222007\n",
      "Epoch 120, Loss: 0.4300926379285251\n",
      "Epoch 121, Loss: 0.4295284670520714\n",
      "Epoch 122, Loss: 0.4289207727026834\n",
      "Epoch 123, Loss: 0.42804927643535545\n",
      "Epoch 124, Loss: 0.4274811539483471\n",
      "Epoch 125, Loss: 0.4268492157774173\n",
      "Epoch 126, Loss: 0.42603728269577024\n",
      "Epoch 127, Loss: 0.42540861149533665\n",
      "Epoch 128, Loss: 0.424885761811539\n",
      "Epoch 129, Loss: 0.4242528729563486\n",
      "Epoch 130, Loss: 0.42352400033449017\n",
      "Epoch 131, Loss: 0.4227759313452546\n",
      "Epoch 132, Loss: 0.4221135983563828\n",
      "Epoch 133, Loss: 0.42148978695651895\n",
      "Epoch 134, Loss: 0.4209059252150371\n",
      "Epoch 135, Loss: 0.4204196729480086\n",
      "Epoch 136, Loss: 0.42008071379301065\n",
      "Epoch 137, Loss: 0.419899784660375\n",
      "Epoch 138, Loss: 0.4189695337936503\n",
      "Epoch 139, Loss: 0.41775405574886687\n",
      "Epoch 140, Loss: 0.41710700569401615\n",
      "Epoch 141, Loss: 0.4170289927907824\n",
      "Epoch 142, Loss: 0.4166463986076685\n",
      "Epoch 143, Loss: 0.4154904771670659\n",
      "Epoch 144, Loss: 0.4146404012223834\n",
      "Epoch 145, Loss: 0.41443716049007845\n",
      "Epoch 146, Loss: 0.4141440581125627\n",
      "Epoch 147, Loss: 0.4132906900059691\n",
      "Epoch 148, Loss: 0.4121876863677303\n",
      "Epoch 149, Loss: 0.4116398636236587\n",
      "Epoch 150, Loss: 0.41143954109382147\n",
      "Epoch 151, Loss: 0.4108891795943462\n",
      "Epoch 152, Loss: 0.41004424609461654\n",
      "Epoch 153, Loss: 0.40917442518687874\n",
      "Epoch 154, Loss: 0.40874425256987224\n",
      "Epoch 155, Loss: 0.4086192442196002\n",
      "Epoch 156, Loss: 0.40823063004836463\n",
      "Epoch 157, Loss: 0.4076000120440454\n",
      "Epoch 158, Loss: 0.4066895161460473\n",
      "Epoch 159, Loss: 0.4059519958550867\n",
      "Epoch 160, Loss: 0.4055013728018593\n",
      "Epoch 161, Loss: 0.4052480482858094\n",
      "Epoch 162, Loss: 0.40510206161008333\n",
      "Epoch 163, Loss: 0.4046686646780329\n",
      "Epoch 164, Loss: 0.40418767145311607\n",
      "Epoch 165, Loss: 0.4032770276800062\n",
      "Epoch 166, Loss: 0.4024430680142302\n",
      "Epoch 167, Loss: 0.4019311066612699\n",
      "Epoch 168, Loss: 0.4016456102389427\n",
      "Epoch 169, Loss: 0.4015215463201314\n",
      "Epoch 170, Loss: 0.4013338098314589\n",
      "Epoch 171, Loss: 0.40141127221279616\n",
      "Epoch 172, Loss: 0.40070985303121687\n",
      "Epoch 173, Loss: 0.39996695083939554\n",
      "Epoch 174, Loss: 0.398924959478384\n",
      "Epoch 175, Loss: 0.3984930710279893\n",
      "Epoch 176, Loss: 0.3986068627426089\n",
      "Epoch 177, Loss: 0.3986841074393601\n",
      "Epoch 178, Loss: 0.3991578826488631\n",
      "Epoch 179, Loss: 0.39774301253174754\n",
      "Epoch 180, Loss: 0.39651718379735457\n",
      "Epoch 181, Loss: 0.3960570865795097\n",
      "Epoch 182, Loss: 0.39621834685678714\n",
      "Epoch 183, Loss: 0.39626272235266186\n",
      "Epoch 184, Loss: 0.3950533103881904\n",
      "Epoch 185, Loss: 0.39411978463310376\n",
      "Epoch 186, Loss: 0.3937914682683195\n",
      "Epoch 187, Loss: 0.3938071905715676\n",
      "Epoch 188, Loss: 0.39412097560571335\n",
      "Epoch 189, Loss: 0.3934768334710362\n",
      "Epoch 190, Loss: 0.3927802519204774\n",
      "Epoch 191, Loss: 0.39155816196799964\n",
      "Epoch 192, Loss: 0.3908902412165947\n",
      "Epoch 193, Loss: 0.390871008654675\n",
      "Epoch 194, Loss: 0.3909134562696732\n",
      "Epoch 195, Loss: 0.39122861002382014\n",
      "Epoch 196, Loss: 0.3902628364150268\n",
      "Epoch 197, Loss: 0.38915726530181105\n",
      "Epoch 198, Loss: 0.38818324826782974\n",
      "Epoch 199, Loss: 0.38797221636596707\n",
      "Epoch 200, Loss: 0.38823796497293667\n",
      "Epoch 201, Loss: 0.38812954124459936\n",
      "Epoch 202, Loss: 0.3883796820418197\n",
      "Epoch 203, Loss: 0.3869560553972917\n",
      "Epoch 204, Loss: 0.3857830557118487\n",
      "Epoch 205, Loss: 0.38485978034672097\n",
      "Epoch 206, Loss: 0.3847479646763993\n",
      "Epoch 207, Loss: 0.3857026285095295\n",
      "Epoch 208, Loss: 0.38610239714723343\n",
      "Epoch 209, Loss: 0.3870262310763748\n",
      "Epoch 210, Loss: 0.38360628235772054\n",
      "Epoch 211, Loss: 0.3823849567677043\n",
      "Epoch 212, Loss: 0.38319836845906735\n",
      "Epoch 213, Loss: 0.3826749320900091\n",
      "Epoch 214, Loss: 0.3818145511813758\n",
      "Epoch 215, Loss: 0.3804846069039467\n",
      "Epoch 216, Loss: 0.3803302121014839\n",
      "Epoch 217, Loss: 0.38098404628913296\n",
      "Epoch 218, Loss: 0.3808896175017065\n",
      "Epoch 219, Loss: 0.3810783148185629\n",
      "Epoch 220, Loss: 0.37892219667207505\n",
      "Epoch 221, Loss: 0.37782219040577647\n",
      "Epoch 222, Loss: 0.3775770528420164\n",
      "Epoch 223, Loss: 0.37818637775361175\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2381528840175885\n",
      "Test R^2 score: 0.3902910916348128\n",
      "Num of epochs: 224\n",
      "Epoch 1, Loss: 0.5664952701462056\n",
      "Epoch 2, Loss: 0.5648331732175181\n",
      "Epoch 3, Loss: 0.563326334637086\n",
      "Epoch 4, Loss: 0.561978204094101\n",
      "Epoch 5, Loss: 0.5607845852408045\n",
      "Epoch 6, Loss: 0.5597374152284738\n",
      "Epoch 7, Loss: 0.558844236752002\n",
      "Epoch 8, Loss: 0.5580963374314516\n",
      "Epoch 9, Loss: 0.5574832093913508\n",
      "Epoch 10, Loss: 0.5569940883658347\n",
      "Epoch 11, Loss: 0.5566171206146414\n",
      "Epoch 12, Loss: 0.5563391956866534\n",
      "Epoch 13, Loss: 0.5561469314753933\n",
      "Epoch 14, Loss: 0.5560324843663165\n",
      "Epoch 15, Loss: 0.5560313856027914\n",
      "Epoch 16, Loss: 0.55605242252726\n",
      "Epoch 17, Loss: 0.556076218751274\n",
      "Epoch 18, Loss: 0.5560972807756853\n",
      "Epoch 19, Loss: 0.5560965572842607\n",
      "Epoch 20, Loss: 0.556061641005146\n",
      "Epoch 21, Loss: 0.5559830646594328\n",
      "Epoch 22, Loss: 0.555851909616808\n",
      "Epoch 23, Loss: 0.55566277528959\n",
      "Epoch 24, Loss: 0.5554047366571153\n",
      "Epoch 25, Loss: 0.5550685164970958\n",
      "Epoch 26, Loss: 0.5546466382516875\n",
      "Epoch 27, Loss: 0.5541421600410887\n",
      "Epoch 28, Loss: 0.553574668088127\n",
      "Epoch 29, Loss: 0.5529116289052547\n",
      "Epoch 30, Loss: 0.5520850097582813\n",
      "Epoch 31, Loss: 0.5510381275440733\n",
      "Epoch 32, Loss: 0.5497593158003743\n",
      "Epoch 33, Loss: 0.5482372211683902\n",
      "Epoch 34, Loss: 0.546467929289965\n",
      "Epoch 35, Loss: 0.5444686809916995\n",
      "Epoch 36, Loss: 0.542119329162942\n",
      "Epoch 37, Loss: 0.5393192398582046\n",
      "Epoch 38, Loss: 0.5360223208110545\n",
      "Epoch 39, Loss: 0.5322207669283792\n",
      "Epoch 40, Loss: 0.5280116619859606\n",
      "Epoch 41, Loss: 0.523389187761037\n",
      "Epoch 42, Loss: 0.5183562852872341\n",
      "Epoch 43, Loss: 0.5132157363770603\n",
      "Epoch 44, Loss: 0.5086085022927076\n",
      "Epoch 45, Loss: 0.5056779455089249\n",
      "Epoch 46, Loss: 0.5051549476915889\n",
      "Epoch 47, Loss: 0.504977130749761\n",
      "Epoch 48, Loss: 0.5024482867452843\n",
      "Epoch 49, Loss: 0.4982282719599768\n",
      "Epoch 50, Loss: 0.49421343059734396\n",
      "Epoch 51, Loss: 0.4915046496341146\n",
      "Epoch 52, Loss: 0.49007998463250335\n",
      "Epoch 53, Loss: 0.4892414569976291\n",
      "Epoch 54, Loss: 0.4882221491332186\n",
      "Epoch 55, Loss: 0.4866887176702229\n",
      "Epoch 56, Loss: 0.48462485975450914\n",
      "Epoch 57, Loss: 0.48223046895666255\n",
      "Epoch 58, Loss: 0.4798958782424834\n",
      "Epoch 59, Loss: 0.4779737245688029\n",
      "Epoch 60, Loss: 0.4766972929640198\n",
      "Epoch 61, Loss: 0.47578139469539155\n",
      "Epoch 62, Loss: 0.4746627306675641\n",
      "Epoch 63, Loss: 0.4730288558035476\n",
      "Epoch 64, Loss: 0.4711468927575474\n",
      "Epoch 65, Loss: 0.46956620681296796\n",
      "Epoch 66, Loss: 0.46842310951426774\n",
      "Epoch 67, Loss: 0.4675433363437486\n",
      "Epoch 68, Loss: 0.46666535316293783\n",
      "Epoch 69, Loss: 0.465555831712913\n",
      "Epoch 70, Loss: 0.46420675597975614\n",
      "Epoch 71, Loss: 0.46283728054759615\n",
      "Epoch 72, Loss: 0.4616867377064589\n",
      "Epoch 73, Loss: 0.46080220386649484\n",
      "Epoch 74, Loss: 0.4601204629916369\n",
      "Epoch 75, Loss: 0.45944129439535775\n",
      "Epoch 76, Loss: 0.45869733884961333\n",
      "Epoch 77, Loss: 0.4579186749291342\n",
      "Epoch 78, Loss: 0.4571461166405065\n",
      "Epoch 79, Loss: 0.45645948656540913\n",
      "Epoch 80, Loss: 0.4558426815529604\n",
      "Epoch 81, Loss: 0.4551851858834198\n",
      "Epoch 82, Loss: 0.45447765895964426\n",
      "Epoch 83, Loss: 0.4537935914887958\n",
      "Epoch 84, Loss: 0.4531749007273277\n",
      "Epoch 85, Loss: 0.4526042412193363\n",
      "Epoch 86, Loss: 0.45202437278561003\n",
      "Epoch 87, Loss: 0.4514071689066871\n",
      "Epoch 88, Loss: 0.4507526580364035\n",
      "Epoch 89, Loss: 0.45008540932432534\n",
      "Epoch 90, Loss: 0.44942383438488\n",
      "Epoch 91, Loss: 0.4487266996970469\n",
      "Epoch 92, Loss: 0.4479905795688551\n",
      "Epoch 93, Loss: 0.44728106676123386\n",
      "Epoch 94, Loss: 0.4466337546486918\n",
      "Epoch 95, Loss: 0.4459970132188902\n",
      "Epoch 96, Loss: 0.4453946422642641\n",
      "Epoch 97, Loss: 0.4448095292011861\n",
      "Epoch 98, Loss: 0.4442039712976118\n",
      "Epoch 99, Loss: 0.44359026371041743\n",
      "Epoch 100, Loss: 0.44297200560004146\n",
      "Epoch 101, Loss: 0.44235470242485003\n",
      "Epoch 102, Loss: 0.44172559006222095\n",
      "Epoch 103, Loss: 0.44106840184476603\n",
      "Epoch 104, Loss: 0.44041857314200916\n",
      "Epoch 105, Loss: 0.4397832520585119\n",
      "Epoch 106, Loss: 0.4391741566529024\n",
      "Epoch 107, Loss: 0.43855266292978273\n",
      "Epoch 108, Loss: 0.4379213381910401\n",
      "Epoch 109, Loss: 0.43725979546032534\n",
      "Epoch 110, Loss: 0.43660207974492937\n",
      "Epoch 111, Loss: 0.43595480525626557\n",
      "Epoch 112, Loss: 0.4353220064065864\n",
      "Epoch 113, Loss: 0.43468912622077654\n",
      "Epoch 114, Loss: 0.43406311611848614\n",
      "Epoch 115, Loss: 0.43345115653858524\n",
      "Epoch 116, Loss: 0.4328427899775312\n",
      "Epoch 117, Loss: 0.43223155036458116\n",
      "Epoch 118, Loss: 0.4316008018661648\n",
      "Epoch 119, Loss: 0.43096966615814203\n",
      "Epoch 120, Loss: 0.43033860899616433\n",
      "Epoch 121, Loss: 0.4297145488201585\n",
      "Epoch 122, Loss: 0.42909114375290786\n",
      "Epoch 123, Loss: 0.42847213524429917\n",
      "Epoch 124, Loss: 0.42787260495740576\n",
      "Epoch 125, Loss: 0.42726433415304227\n",
      "Epoch 126, Loss: 0.4266263990784446\n",
      "Epoch 127, Loss: 0.42598712388579507\n",
      "Epoch 128, Loss: 0.42535762536265287\n",
      "Epoch 129, Loss: 0.4247211242569001\n",
      "Epoch 130, Loss: 0.42407785257141195\n",
      "Epoch 131, Loss: 0.4234430347939557\n",
      "Epoch 132, Loss: 0.4228093784778116\n",
      "Epoch 133, Loss: 0.4221701119637869\n",
      "Epoch 134, Loss: 0.42153341098242514\n",
      "Epoch 135, Loss: 0.42090394266515574\n",
      "Epoch 136, Loss: 0.42025523593325426\n",
      "Epoch 137, Loss: 0.4196075682600291\n",
      "Epoch 138, Loss: 0.4189676843463043\n",
      "Epoch 139, Loss: 0.41832074824941085\n",
      "Epoch 140, Loss: 0.41767061599131267\n",
      "Epoch 141, Loss: 0.4170245620345622\n",
      "Epoch 142, Loss: 0.41637475000154656\n",
      "Epoch 143, Loss: 0.41572039162016966\n",
      "Epoch 144, Loss: 0.4150618962009371\n",
      "Epoch 145, Loss: 0.41439500090140985\n",
      "Epoch 146, Loss: 0.41371053455597173\n",
      "Epoch 147, Loss: 0.41301080908843235\n",
      "Epoch 148, Loss: 0.41230275828146434\n",
      "Epoch 149, Loss: 0.4115691237036116\n",
      "Epoch 150, Loss: 0.41086645853943704\n",
      "Epoch 151, Loss: 0.4102668249851682\n",
      "Epoch 152, Loss: 0.40981041997067813\n",
      "Epoch 153, Loss: 0.4093583656891786\n",
      "Epoch 154, Loss: 0.4082211942187073\n",
      "Epoch 155, Loss: 0.407548589559414\n",
      "Epoch 156, Loss: 0.4073084284690275\n",
      "Epoch 157, Loss: 0.4065390805441767\n",
      "Epoch 158, Loss: 0.40578804894686843\n",
      "Epoch 159, Loss: 0.40545986437754306\n",
      "Epoch 160, Loss: 0.4049986493712145\n",
      "Epoch 161, Loss: 0.40424291278238883\n",
      "Epoch 162, Loss: 0.4037727238546355\n",
      "Epoch 163, Loss: 0.4033870318556731\n",
      "Epoch 164, Loss: 0.4027090728833229\n",
      "Epoch 165, Loss: 0.402115284765324\n",
      "Epoch 166, Loss: 0.4017523891767237\n",
      "Epoch 167, Loss: 0.4012859290071291\n",
      "Epoch 168, Loss: 0.40063391016485833\n",
      "Epoch 169, Loss: 0.40007244586545243\n",
      "Epoch 170, Loss: 0.39967356415195576\n",
      "Epoch 171, Loss: 0.3993241598337881\n",
      "Epoch 172, Loss: 0.3988797033959708\n",
      "Epoch 173, Loss: 0.39831284835778646\n",
      "Epoch 174, Loss: 0.397755600335372\n",
      "Epoch 175, Loss: 0.3973635992506868\n",
      "Epoch 176, Loss: 0.39705417823567446\n",
      "Epoch 177, Loss: 0.39673277867300916\n",
      "Epoch 178, Loss: 0.39637147771232123\n",
      "Epoch 179, Loss: 0.39594316422792364\n",
      "Epoch 180, Loss: 0.39549104631467025\n",
      "Epoch 181, Loss: 0.3950080068295835\n",
      "Epoch 182, Loss: 0.3945642400866659\n",
      "Epoch 183, Loss: 0.3942402247848021\n",
      "Epoch 184, Loss: 0.3940463343669193\n",
      "Epoch 185, Loss: 0.3939093418749011\n",
      "Epoch 186, Loss: 0.3937325087704073\n",
      "Epoch 187, Loss: 0.393303784076082\n",
      "Epoch 188, Loss: 0.3926440700732207\n",
      "Epoch 189, Loss: 0.39219506397020215\n",
      "Epoch 190, Loss: 0.3920644749549564\n",
      "Epoch 191, Loss: 0.391902855243585\n",
      "Epoch 192, Loss: 0.39149260491539994\n",
      "Epoch 193, Loss: 0.3909562994799617\n",
      "Epoch 194, Loss: 0.39065227413328496\n",
      "Epoch 195, Loss: 0.39051369034828204\n",
      "Epoch 196, Loss: 0.390294621946152\n",
      "Epoch 197, Loss: 0.3899829929262666\n",
      "Epoch 198, Loss: 0.38970247051786217\n",
      "Epoch 199, Loss: 0.3895696115712189\n",
      "Epoch 200, Loss: 0.3893463761354141\n",
      "Epoch 201, Loss: 0.3887269062591412\n",
      "Epoch 202, Loss: 0.3883320074850105\n",
      "Epoch 203, Loss: 0.38825832583262637\n",
      "Epoch 204, Loss: 0.3879523974324282\n",
      "Epoch 205, Loss: 0.38754079127188057\n",
      "Epoch 206, Loss: 0.38745474858787426\n",
      "Epoch 207, Loss: 0.3873383153955019\n",
      "Epoch 208, Loss: 0.38689867323147314\n",
      "Epoch 209, Loss: 0.3867092709391063\n",
      "Epoch 210, Loss: 0.3868262594268716\n",
      "Epoch 211, Loss: 0.38674454651151974\n",
      "Epoch 212, Loss: 0.38638171527250986\n",
      "Epoch 213, Loss: 0.38621810333866985\n",
      "Epoch 214, Loss: 0.38549147558621033\n",
      "Epoch 215, Loss: 0.3850350767728299\n",
      "Epoch 216, Loss: 0.3852003904046054\n",
      "Epoch 217, Loss: 0.38514079281507196\n",
      "Epoch 218, Loss: 0.3848909861251245\n",
      "Epoch 219, Loss: 0.3845853237866561\n",
      "Epoch 220, Loss: 0.3840689378762185\n",
      "Epoch 221, Loss: 0.3837613005946818\n",
      "Epoch 222, Loss: 0.3838082811042654\n",
      "Epoch 223, Loss: 0.3837075765750506\n",
      "Epoch 224, Loss: 0.3834088021430595\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.23079814975698437\n",
      "Test R^2 score: 0.4230159746055679\n",
      "Num of epochs: 225\n",
      "Epoch 1, Loss: 0.6193660000975786\n",
      "Epoch 2, Loss: 0.6170630993596268\n",
      "Epoch 3, Loss: 0.6148325501019287\n",
      "Epoch 4, Loss: 0.6127091430231543\n",
      "Epoch 5, Loss: 0.6106498050629727\n",
      "Epoch 6, Loss: 0.6087610379653751\n",
      "Epoch 7, Loss: 0.6069455256865894\n",
      "Epoch 8, Loss: 0.6051840081855303\n",
      "Epoch 9, Loss: 0.603470538285392\n",
      "Epoch 10, Loss: 0.6018024808109275\n",
      "Epoch 11, Loss: 0.600208914665021\n",
      "Epoch 12, Loss: 0.598666739319193\n",
      "Epoch 13, Loss: 0.597201953834792\n",
      "Epoch 14, Loss: 0.5957972217722974\n",
      "Epoch 15, Loss: 0.5944471031522663\n",
      "Epoch 16, Loss: 0.5931376763165982\n",
      "Epoch 17, Loss: 0.5918404843216972\n",
      "Epoch 18, Loss: 0.5905567432502071\n",
      "Epoch 19, Loss: 0.5893007267241089\n",
      "Epoch 20, Loss: 0.588054824153021\n",
      "Epoch 21, Loss: 0.5868124215315623\n",
      "Epoch 22, Loss: 0.585668323994685\n",
      "Epoch 23, Loss: 0.5845497482052584\n",
      "Epoch 24, Loss: 0.5834372263306526\n",
      "Epoch 25, Loss: 0.5823260591162172\n",
      "Epoch 26, Loss: 0.581209434611425\n",
      "Epoch 27, Loss: 0.5800817984005506\n",
      "Epoch 28, Loss: 0.5789328935800871\n",
      "Epoch 29, Loss: 0.5777488206317375\n",
      "Epoch 30, Loss: 0.5765137773308375\n",
      "Epoch 31, Loss: 0.5752349218127351\n",
      "Epoch 32, Loss: 0.5739444155196973\n",
      "Epoch 33, Loss: 0.5726403841784617\n",
      "Epoch 34, Loss: 0.5712953746479545\n",
      "Epoch 35, Loss: 0.5698468907413271\n",
      "Epoch 36, Loss: 0.5681492787493622\n",
      "Epoch 37, Loss: 0.5661623199317741\n",
      "Epoch 38, Loss: 0.563905073689465\n",
      "Epoch 39, Loss: 0.5613907101543056\n",
      "Epoch 40, Loss: 0.5587070056835879\n",
      "Epoch 41, Loss: 0.5560426143277515\n",
      "Epoch 42, Loss: 0.5536322966745275\n",
      "Epoch 43, Loss: 0.5517397717252492\n",
      "Epoch 44, Loss: 0.5505741352225031\n",
      "Epoch 45, Loss: 0.5498957719445728\n",
      "Epoch 46, Loss: 0.5488401527037116\n",
      "Epoch 47, Loss: 0.5467892715834577\n",
      "Epoch 48, Loss: 0.5438402988828711\n",
      "Epoch 49, Loss: 0.5406116671378954\n",
      "Epoch 50, Loss: 0.5376452460433672\n",
      "Epoch 51, Loss: 0.5350243343184606\n",
      "Epoch 52, Loss: 0.5326630928224422\n",
      "Epoch 53, Loss: 0.5303907176899995\n",
      "Epoch 54, Loss: 0.5280370323007685\n",
      "Epoch 55, Loss: 0.5255898307165618\n",
      "Epoch 56, Loss: 0.5232088529043415\n",
      "Epoch 57, Loss: 0.5210418538069462\n",
      "Epoch 58, Loss: 0.5191066699265111\n",
      "Epoch 59, Loss: 0.5172108912868619\n",
      "Epoch 60, Loss: 0.5151345492493563\n",
      "Epoch 61, Loss: 0.512943287780169\n",
      "Epoch 62, Loss: 0.5108960359413233\n",
      "Epoch 63, Loss: 0.5090839314969541\n",
      "Epoch 64, Loss: 0.5075157178596422\n",
      "Epoch 65, Loss: 0.5060558453056727\n",
      "Epoch 66, Loss: 0.5046152848581114\n",
      "Epoch 67, Loss: 0.5033696296638454\n",
      "Epoch 68, Loss: 0.5023387511198929\n",
      "Epoch 69, Loss: 0.5012037866174605\n",
      "Epoch 70, Loss: 0.4999182306423015\n",
      "Epoch 71, Loss: 0.49877499481900206\n",
      "Epoch 72, Loss: 0.4977835763310183\n",
      "Epoch 73, Loss: 0.4966554840586994\n",
      "Epoch 74, Loss: 0.495382550096598\n",
      "Epoch 75, Loss: 0.4942161592794916\n",
      "Epoch 76, Loss: 0.49316442508495334\n",
      "Epoch 77, Loss: 0.4919703019481199\n",
      "Epoch 78, Loss: 0.4907566798926848\n",
      "Epoch 79, Loss: 0.48970154762202683\n",
      "Epoch 80, Loss: 0.4886085481418626\n",
      "Epoch 81, Loss: 0.48742892835417045\n",
      "Epoch 82, Loss: 0.4863764727356201\n",
      "Epoch 83, Loss: 0.4853586085093983\n",
      "Epoch 84, Loss: 0.48424255960033313\n",
      "Epoch 85, Loss: 0.48323941167765455\n",
      "Epoch 86, Loss: 0.4822617237965893\n",
      "Epoch 87, Loss: 0.48121642268074066\n",
      "Epoch 88, Loss: 0.4802581046233253\n",
      "Epoch 89, Loss: 0.47928911869703067\n",
      "Epoch 90, Loss: 0.4783207554968967\n",
      "Epoch 91, Loss: 0.4774066764947997\n",
      "Epoch 92, Loss: 0.4764371456939088\n",
      "Epoch 93, Loss: 0.4755440914849065\n",
      "Epoch 94, Loss: 0.47462320503837824\n",
      "Epoch 95, Loss: 0.4737266054391067\n",
      "Epoch 96, Loss: 0.47285469870332836\n",
      "Epoch 97, Loss: 0.4719703521135547\n",
      "Epoch 98, Loss: 0.47113713559709475\n",
      "Epoch 99, Loss: 0.4703106332025834\n",
      "Epoch 100, Loss: 0.46952442729137706\n",
      "Epoch 101, Loss: 0.4687185912735711\n",
      "Epoch 102, Loss: 0.4679453778679477\n",
      "Epoch 103, Loss: 0.4671590509332619\n",
      "Epoch 104, Loss: 0.46638472170322137\n",
      "Epoch 105, Loss: 0.4656205298702033\n",
      "Epoch 106, Loss: 0.46485514586769\n",
      "Epoch 107, Loss: 0.46411185788802123\n",
      "Epoch 108, Loss: 0.46336538377492364\n",
      "Epoch 109, Loss: 0.46263931792252144\n",
      "Epoch 110, Loss: 0.4619130785812641\n",
      "Epoch 111, Loss: 0.4611988781302059\n",
      "Epoch 112, Loss: 0.4605069816983749\n",
      "Epoch 113, Loss: 0.45980566688221347\n",
      "Epoch 114, Loss: 0.4591191195478271\n",
      "Epoch 115, Loss: 0.45844205917764486\n",
      "Epoch 116, Loss: 0.45774833958698097\n",
      "Epoch 117, Loss: 0.45704518810439654\n",
      "Epoch 118, Loss: 0.45634741853544125\n",
      "Epoch 119, Loss: 0.4556503954430761\n",
      "Epoch 120, Loss: 0.45494452549660935\n",
      "Epoch 121, Loss: 0.4542311452743103\n",
      "Epoch 122, Loss: 0.45351649505242636\n",
      "Epoch 123, Loss: 0.452801457356662\n",
      "Epoch 124, Loss: 0.45208349235227163\n",
      "Epoch 125, Loss: 0.4513570397299732\n",
      "Epoch 126, Loss: 0.45062043810690006\n",
      "Epoch 127, Loss: 0.4498708387290006\n",
      "Epoch 128, Loss: 0.44911672013971954\n",
      "Epoch 129, Loss: 0.4483560820513608\n",
      "Epoch 130, Loss: 0.4475849460981612\n",
      "Epoch 131, Loss: 0.44680205730188277\n",
      "Epoch 132, Loss: 0.4460100432791868\n",
      "Epoch 133, Loss: 0.4452250545374226\n",
      "Epoch 134, Loss: 0.44448502942225265\n",
      "Epoch 135, Loss: 0.44378305768736176\n",
      "Epoch 136, Loss: 0.44313196408135475\n",
      "Epoch 137, Loss: 0.44220061265893507\n",
      "Epoch 138, Loss: 0.44121305913529046\n",
      "Epoch 139, Loss: 0.4404507143537306\n",
      "Epoch 140, Loss: 0.43979341683099\n",
      "Epoch 141, Loss: 0.43895236836698404\n",
      "Epoch 142, Loss: 0.4379964804333758\n",
      "Epoch 143, Loss: 0.4372408985196165\n",
      "Epoch 144, Loss: 0.43653622124235075\n",
      "Epoch 145, Loss: 0.43565928287324673\n",
      "Epoch 146, Loss: 0.434807136384125\n",
      "Epoch 147, Loss: 0.43409054450664797\n",
      "Epoch 148, Loss: 0.4333544921599915\n",
      "Epoch 149, Loss: 0.4325181145816012\n",
      "Epoch 150, Loss: 0.43169231881997416\n",
      "Epoch 151, Loss: 0.43095810036663856\n",
      "Epoch 152, Loss: 0.4302496440748552\n",
      "Epoch 153, Loss: 0.42941889603742645\n",
      "Epoch 154, Loss: 0.4285522028039369\n",
      "Epoch 155, Loss: 0.4277273726216744\n",
      "Epoch 156, Loss: 0.4269668102252449\n",
      "Epoch 157, Loss: 0.42623757923185557\n",
      "Epoch 158, Loss: 0.4254783112638549\n",
      "Epoch 159, Loss: 0.4246809856035865\n",
      "Epoch 160, Loss: 0.42384788361651343\n",
      "Epoch 161, Loss: 0.4230247653808809\n",
      "Epoch 162, Loss: 0.4222149891801952\n",
      "Epoch 163, Loss: 0.4214256860920592\n",
      "Epoch 164, Loss: 0.4206307216952319\n",
      "Epoch 165, Loss: 0.4198434800891413\n",
      "Epoch 166, Loss: 0.41904969237780204\n",
      "Epoch 167, Loss: 0.4182511382865579\n",
      "Epoch 168, Loss: 0.4175005277755965\n",
      "Epoch 169, Loss: 0.41707783518523067\n",
      "Epoch 170, Loss: 0.4177682520476367\n",
      "Epoch 171, Loss: 0.4183484073344621\n",
      "Epoch 172, Loss: 0.41486570440270465\n",
      "Epoch 173, Loss: 0.41482423495783816\n",
      "Epoch 174, Loss: 0.41495771620673544\n",
      "Epoch 175, Loss: 0.41247249713880296\n",
      "Epoch 176, Loss: 0.4136665358302401\n",
      "Epoch 177, Loss: 0.41156170146172405\n",
      "Epoch 178, Loss: 0.4113961506787271\n",
      "Epoch 179, Loss: 0.410949974450903\n",
      "Epoch 180, Loss: 0.40939259964479197\n",
      "Epoch 181, Loss: 0.4098993132401926\n",
      "Epoch 182, Loss: 0.40821750743296936\n",
      "Epoch 183, Loss: 0.4082302650299961\n",
      "Epoch 184, Loss: 0.4075574194058112\n",
      "Epoch 185, Loss: 0.40651395365683063\n",
      "Epoch 186, Loss: 0.4066170904584641\n",
      "Epoch 187, Loss: 0.40539240182607394\n",
      "Epoch 188, Loss: 0.40514362508255986\n",
      "Epoch 189, Loss: 0.4047080819040043\n",
      "Epoch 190, Loss: 0.4036980769485564\n",
      "Epoch 191, Loss: 0.40364357322142164\n",
      "Epoch 192, Loss: 0.4028835749161887\n",
      "Epoch 193, Loss: 0.40211750817545966\n",
      "Epoch 194, Loss: 0.40201505178413416\n",
      "Epoch 195, Loss: 0.40158316562778645\n",
      "Epoch 196, Loss: 0.40061347156309124\n",
      "Epoch 197, Loss: 0.40025513380142846\n",
      "Epoch 198, Loss: 0.40015024552314504\n",
      "Epoch 199, Loss: 0.3994789723673932\n",
      "Epoch 200, Loss: 0.3987469126244011\n",
      "Epoch 201, Loss: 0.3983593471397664\n",
      "Epoch 202, Loss: 0.3982420423207152\n",
      "Epoch 203, Loss: 0.39800944428404705\n",
      "Epoch 204, Loss: 0.3972770209164236\n",
      "Epoch 205, Loss: 0.39661230644763096\n",
      "Epoch 206, Loss: 0.39612410765716205\n",
      "Epoch 207, Loss: 0.3958210964151825\n",
      "Epoch 208, Loss: 0.3957113990031632\n",
      "Epoch 209, Loss: 0.39561086183448846\n",
      "Epoch 210, Loss: 0.39543993332079364\n",
      "Epoch 211, Loss: 0.39480150993912577\n",
      "Epoch 212, Loss: 0.3939730784324495\n",
      "Epoch 213, Loss: 0.39320229023754416\n",
      "Epoch 214, Loss: 0.3928926451079842\n",
      "Epoch 215, Loss: 0.392866436814318\n",
      "Epoch 216, Loss: 0.3928691108230664\n",
      "Epoch 217, Loss: 0.39310780182837557\n",
      "Epoch 218, Loss: 0.3928393353724045\n",
      "Epoch 219, Loss: 0.3917621654223402\n",
      "Epoch 220, Loss: 0.39060584975030954\n",
      "Epoch 221, Loss: 0.390394180767179\n",
      "Epoch 222, Loss: 0.3906060214200648\n",
      "Epoch 223, Loss: 0.39064548438721547\n",
      "Epoch 224, Loss: 0.3905051238179313\n",
      "Epoch 225, Loss: 0.3893702955558778\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2506282795670237\n",
      "Test R^2 score: 0.3210242131452251\n",
      "Num of epochs: 226\n",
      "Epoch 1, Loss: 0.5978034841652266\n",
      "Epoch 2, Loss: 0.5949027766608099\n",
      "Epoch 3, Loss: 0.5921467417276162\n",
      "Epoch 4, Loss: 0.5895025011418858\n",
      "Epoch 5, Loss: 0.5870046942326594\n",
      "Epoch 6, Loss: 0.5845456185368292\n",
      "Epoch 7, Loss: 0.582128401463134\n",
      "Epoch 8, Loss: 0.5798085931940546\n",
      "Epoch 9, Loss: 0.5776181705750519\n",
      "Epoch 10, Loss: 0.5754781134675097\n",
      "Epoch 11, Loss: 0.5733868807868885\n",
      "Epoch 12, Loss: 0.5713464170177839\n",
      "Epoch 13, Loss: 0.5693653550571616\n",
      "Epoch 14, Loss: 0.5674889312622572\n",
      "Epoch 15, Loss: 0.5657372832156495\n",
      "Epoch 16, Loss: 0.564090097233059\n",
      "Epoch 17, Loss: 0.5625216956722963\n",
      "Epoch 18, Loss: 0.5610221947616125\n",
      "Epoch 19, Loss: 0.5596038648522329\n",
      "Epoch 20, Loss: 0.5582906260691991\n",
      "Epoch 21, Loss: 0.5571740255047694\n",
      "Epoch 22, Loss: 0.5561061233725981\n",
      "Epoch 23, Loss: 0.5550510128736725\n",
      "Epoch 24, Loss: 0.5540061311830102\n",
      "Epoch 25, Loss: 0.5529584935755073\n",
      "Epoch 26, Loss: 0.5518787892817426\n",
      "Epoch 27, Loss: 0.5506686643419137\n",
      "Epoch 28, Loss: 0.5493985127439668\n",
      "Epoch 29, Loss: 0.548006766735191\n",
      "Epoch 30, Loss: 0.5463430542326395\n",
      "Epoch 31, Loss: 0.5443265390559988\n",
      "Epoch 32, Loss: 0.5418911951498244\n",
      "Epoch 33, Loss: 0.5390386437928448\n",
      "Epoch 34, Loss: 0.5359489250633549\n",
      "Epoch 35, Loss: 0.5329486952525476\n",
      "Epoch 36, Loss: 0.5304854164258256\n",
      "Epoch 37, Loss: 0.5287438913988987\n",
      "Epoch 38, Loss: 0.5268516222200872\n",
      "Epoch 39, Loss: 0.5241178958483236\n",
      "Epoch 40, Loss: 0.5206919446404517\n",
      "Epoch 41, Loss: 0.517510204537073\n",
      "Epoch 42, Loss: 0.515062111608958\n",
      "Epoch 43, Loss: 0.5131428245951927\n",
      "Epoch 44, Loss: 0.5112733139840712\n",
      "Epoch 45, Loss: 0.5091442252373232\n",
      "Epoch 46, Loss: 0.5067597848354976\n",
      "Epoch 47, Loss: 0.5044121679156567\n",
      "Epoch 48, Loss: 0.5024880553481778\n",
      "Epoch 49, Loss: 0.5010505904145203\n",
      "Epoch 50, Loss: 0.4995733914752823\n",
      "Epoch 51, Loss: 0.49775564617401474\n",
      "Epoch 52, Loss: 0.4960001308985122\n",
      "Epoch 53, Loss: 0.4946702071906745\n",
      "Epoch 54, Loss: 0.4935193887397665\n",
      "Epoch 55, Loss: 0.492125371008964\n",
      "Epoch 56, Loss: 0.4904635832029222\n",
      "Epoch 57, Loss: 0.48883672018056007\n",
      "Epoch 58, Loss: 0.48743780913173806\n",
      "Epoch 59, Loss: 0.4860209525226728\n",
      "Epoch 60, Loss: 0.48435360338267264\n",
      "Epoch 61, Loss: 0.48266726596421416\n",
      "Epoch 62, Loss: 0.48120296793408474\n",
      "Epoch 63, Loss: 0.4797885080162602\n",
      "Epoch 64, Loss: 0.47834544366975446\n",
      "Epoch 65, Loss: 0.4769232588281356\n",
      "Epoch 66, Loss: 0.47557696073547323\n",
      "Epoch 67, Loss: 0.4742698082625501\n",
      "Epoch 68, Loss: 0.4729073385615453\n",
      "Epoch 69, Loss: 0.4715952353367826\n",
      "Epoch 70, Loss: 0.47031763523884856\n",
      "Epoch 71, Loss: 0.46894388957286365\n",
      "Epoch 72, Loss: 0.46760442941813635\n",
      "Epoch 73, Loss: 0.46642967369775123\n",
      "Epoch 74, Loss: 0.4652838987292621\n",
      "Epoch 75, Loss: 0.46415521613858374\n",
      "Epoch 76, Loss: 0.46317533597877875\n",
      "Epoch 77, Loss: 0.46211804327811623\n",
      "Epoch 78, Loss: 0.46096615783053607\n",
      "Epoch 79, Loss: 0.45992598026206627\n",
      "Epoch 80, Loss: 0.45889443672932745\n",
      "Epoch 81, Loss: 0.45790074445147877\n",
      "Epoch 82, Loss: 0.45694720481758966\n",
      "Epoch 83, Loss: 0.45593961125617766\n",
      "Epoch 84, Loss: 0.4549931295368737\n",
      "Epoch 85, Loss: 0.4540972637670355\n",
      "Epoch 86, Loss: 0.45330266100478817\n",
      "Epoch 87, Loss: 0.45255261476233594\n",
      "Epoch 88, Loss: 0.4517715069401722\n",
      "Epoch 89, Loss: 0.4510001479135935\n",
      "Epoch 90, Loss: 0.4502261269174809\n",
      "Epoch 91, Loss: 0.44953857315139467\n",
      "Epoch 92, Loss: 0.44885537751197463\n",
      "Epoch 93, Loss: 0.4481492787731257\n",
      "Epoch 94, Loss: 0.4474120087932077\n",
      "Epoch 95, Loss: 0.44669130257674217\n",
      "Epoch 96, Loss: 0.44599442386669574\n",
      "Epoch 97, Loss: 0.44531377156393975\n",
      "Epoch 98, Loss: 0.44459611590396697\n",
      "Epoch 99, Loss: 0.443872348279023\n",
      "Epoch 100, Loss: 0.4431865540164723\n",
      "Epoch 101, Loss: 0.44251779682125786\n",
      "Epoch 102, Loss: 0.44184323850920876\n",
      "Epoch 103, Loss: 0.4412111002874053\n",
      "Epoch 104, Loss: 0.4406202627157311\n",
      "Epoch 105, Loss: 0.4400000326741813\n",
      "Epoch 106, Loss: 0.4393740943204789\n",
      "Epoch 107, Loss: 0.43875335928454173\n",
      "Epoch 108, Loss: 0.43815983673231784\n",
      "Epoch 109, Loss: 0.43756991917619514\n",
      "Epoch 110, Loss: 0.43693998803003437\n",
      "Epoch 111, Loss: 0.43621087885333837\n",
      "Epoch 112, Loss: 0.4354030559852217\n",
      "Epoch 113, Loss: 0.4345918628621207\n",
      "Epoch 114, Loss: 0.4336020494646204\n",
      "Epoch 115, Loss: 0.4326726735787421\n",
      "Epoch 116, Loss: 0.43194407157772824\n",
      "Epoch 117, Loss: 0.4312900828655297\n",
      "Epoch 118, Loss: 0.43067253952160556\n",
      "Epoch 119, Loss: 0.4300117309766585\n",
      "Epoch 120, Loss: 0.42935651689418924\n",
      "Epoch 121, Loss: 0.42873742232488676\n",
      "Epoch 122, Loss: 0.4280139758254749\n",
      "Epoch 123, Loss: 0.4272384555678841\n",
      "Epoch 124, Loss: 0.4265474023347938\n",
      "Epoch 125, Loss: 0.42603548141814745\n",
      "Epoch 126, Loss: 0.42561377285057234\n",
      "Epoch 127, Loss: 0.42471956299033237\n",
      "Epoch 128, Loss: 0.4237076724413621\n",
      "Epoch 129, Loss: 0.42333139589321905\n",
      "Epoch 130, Loss: 0.42292237074376837\n",
      "Epoch 131, Loss: 0.42200690432636057\n",
      "Epoch 132, Loss: 0.4213774537518898\n",
      "Epoch 133, Loss: 0.42109541034548087\n",
      "Epoch 134, Loss: 0.420388127014531\n",
      "Epoch 135, Loss: 0.41959467715650095\n",
      "Epoch 136, Loss: 0.4192072620730142\n",
      "Epoch 137, Loss: 0.4187631633454615\n",
      "Epoch 138, Loss: 0.4179901046288928\n",
      "Epoch 139, Loss: 0.41736305771999826\n",
      "Epoch 140, Loss: 0.4169721040199851\n",
      "Epoch 141, Loss: 0.41641903512304185\n",
      "Epoch 142, Loss: 0.4156806205876551\n",
      "Epoch 143, Loss: 0.4149935529104669\n",
      "Epoch 144, Loss: 0.4145362411123779\n",
      "Epoch 145, Loss: 0.41416334327743387\n",
      "Epoch 146, Loss: 0.41377165314177794\n",
      "Epoch 147, Loss: 0.41322937407254795\n",
      "Epoch 148, Loss: 0.41258310145602295\n",
      "Epoch 149, Loss: 0.4119948639352801\n",
      "Epoch 150, Loss: 0.41155288511267646\n",
      "Epoch 151, Loss: 0.4112502992623119\n",
      "Epoch 152, Loss: 0.41093498055153505\n",
      "Epoch 153, Loss: 0.4105490302438541\n",
      "Epoch 154, Loss: 0.4100177712775911\n",
      "Epoch 155, Loss: 0.4094123088055534\n",
      "Epoch 156, Loss: 0.40886734578785666\n",
      "Epoch 157, Loss: 0.4084160719302043\n",
      "Epoch 158, Loss: 0.40804904785980023\n",
      "Epoch 159, Loss: 0.4078078295268525\n",
      "Epoch 160, Loss: 0.4077665741590729\n",
      "Epoch 161, Loss: 0.4080407946939006\n",
      "Epoch 162, Loss: 0.40812180361584094\n",
      "Epoch 163, Loss: 0.4069904219053345\n",
      "Epoch 164, Loss: 0.40576125970073124\n",
      "Epoch 165, Loss: 0.4059761665024446\n",
      "Epoch 166, Loss: 0.406079623368166\n",
      "Epoch 167, Loss: 0.4049715687344367\n",
      "Epoch 168, Loss: 0.4044474629976098\n",
      "Epoch 169, Loss: 0.40474554404149743\n",
      "Epoch 170, Loss: 0.40425562993731307\n",
      "Epoch 171, Loss: 0.40340878899351734\n",
      "Epoch 172, Loss: 0.4032722980284597\n",
      "Epoch 173, Loss: 0.40335053337613275\n",
      "Epoch 174, Loss: 0.4028117411734312\n",
      "Epoch 175, Loss: 0.402159658000348\n",
      "Epoch 176, Loss: 0.4019557415253323\n",
      "Epoch 177, Loss: 0.40191872378165666\n",
      "Epoch 178, Loss: 0.40151148891400645\n",
      "Epoch 179, Loss: 0.40093192750027074\n",
      "Epoch 180, Loss: 0.40055970134403224\n",
      "Epoch 181, Loss: 0.4003996499137701\n",
      "Epoch 182, Loss: 0.4002330376868735\n",
      "Epoch 183, Loss: 0.39992468169520945\n",
      "Epoch 184, Loss: 0.3995490370734408\n",
      "Epoch 185, Loss: 0.39914425641997164\n",
      "Epoch 186, Loss: 0.3988017119236994\n",
      "Epoch 187, Loss: 0.3985288739614789\n",
      "Epoch 188, Loss: 0.39830452439077535\n",
      "Epoch 189, Loss: 0.39814573713039997\n",
      "Epoch 190, Loss: 0.3980959007611738\n",
      "Epoch 191, Loss: 0.39831150157042544\n",
      "Epoch 192, Loss: 0.398829267539425\n",
      "Epoch 193, Loss: 0.39918658953757413\n",
      "Epoch 194, Loss: 0.39794785200949157\n",
      "Epoch 195, Loss: 0.3965132190754467\n",
      "Epoch 196, Loss: 0.39686292044211113\n",
      "Epoch 197, Loss: 0.3975373740590027\n",
      "Epoch 198, Loss: 0.39664251246293464\n",
      "Epoch 199, Loss: 0.39554797310086226\n",
      "Epoch 200, Loss: 0.3958537531487968\n",
      "Epoch 201, Loss: 0.3960909841467242\n",
      "Epoch 202, Loss: 0.3951524810188927\n",
      "Epoch 203, Loss: 0.39456248395808885\n",
      "Epoch 204, Loss: 0.39479562192091383\n",
      "Epoch 205, Loss: 0.39465496276457057\n",
      "Epoch 206, Loss: 0.39401791479922793\n",
      "Epoch 207, Loss: 0.3936233839181752\n",
      "Epoch 208, Loss: 0.3935421925115968\n",
      "Epoch 209, Loss: 0.39330313999392985\n",
      "Epoch 210, Loss: 0.3929708613496337\n",
      "Epoch 211, Loss: 0.3926300469978603\n",
      "Epoch 212, Loss: 0.3924285262020932\n",
      "Epoch 213, Loss: 0.39229043696341265\n",
      "Epoch 214, Loss: 0.39220002218977823\n",
      "Epoch 215, Loss: 0.3920746796788422\n",
      "Epoch 216, Loss: 0.3918341614161289\n",
      "Epoch 217, Loss: 0.39145412190384643\n",
      "Epoch 218, Loss: 0.3911337019676793\n",
      "Epoch 219, Loss: 0.39084096660493706\n",
      "Epoch 220, Loss: 0.39057885851140495\n",
      "Epoch 221, Loss: 0.3903668886014407\n",
      "Epoch 222, Loss: 0.39014113021476265\n",
      "Epoch 223, Loss: 0.38990473146074867\n",
      "Epoch 224, Loss: 0.3896992394545869\n",
      "Epoch 225, Loss: 0.3894745861939381\n",
      "Epoch 226, Loss: 0.38926844603871763\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2299973829496464\n",
      "Test R^2 score: 0.42595985676762416\n",
      "Num of epochs: 227\n",
      "Epoch 1, Loss: 0.5770890000360039\n",
      "Epoch 2, Loss: 0.574733762678486\n",
      "Epoch 3, Loss: 0.5725221286894739\n",
      "Epoch 4, Loss: 0.5704457114380866\n",
      "Epoch 5, Loss: 0.5685190454998443\n",
      "Epoch 6, Loss: 0.5667354284902849\n",
      "Epoch 7, Loss: 0.5651104277748822\n",
      "Epoch 8, Loss: 0.5636965687419114\n",
      "Epoch 9, Loss: 0.5624038031231744\n",
      "Epoch 10, Loss: 0.5612564115434194\n",
      "Epoch 11, Loss: 0.5602022500616372\n",
      "Epoch 12, Loss: 0.5592718743252837\n",
      "Epoch 13, Loss: 0.558516010130081\n",
      "Epoch 14, Loss: 0.5578772210793425\n",
      "Epoch 15, Loss: 0.5573393869616922\n",
      "Epoch 16, Loss: 0.5569006864486987\n",
      "Epoch 17, Loss: 0.5565521169868792\n",
      "Epoch 18, Loss: 0.5562911961334222\n",
      "Epoch 19, Loss: 0.5561140012041428\n",
      "Epoch 20, Loss: 0.5560043982170606\n",
      "Epoch 21, Loss: 0.5559567717996002\n",
      "Epoch 22, Loss: 0.5559516792569109\n",
      "Epoch 23, Loss: 0.5559706018380691\n",
      "Epoch 24, Loss: 0.5559919626749363\n",
      "Epoch 25, Loss: 0.5560061402427773\n",
      "Epoch 26, Loss: 0.5560095438772739\n",
      "Epoch 27, Loss: 0.5559847263478406\n",
      "Epoch 28, Loss: 0.5559245539804145\n",
      "Epoch 29, Loss: 0.5558112675215503\n",
      "Epoch 30, Loss: 0.5556454512926987\n",
      "Epoch 31, Loss: 0.5554370651114642\n",
      "Epoch 32, Loss: 0.5551823839585107\n",
      "Epoch 33, Loss: 0.5548786586134695\n",
      "Epoch 34, Loss: 0.554523390012636\n",
      "Epoch 35, Loss: 0.5541126603745347\n",
      "Epoch 36, Loss: 0.5536413401304443\n",
      "Epoch 37, Loss: 0.553102161992037\n",
      "Epoch 38, Loss: 0.5524772612177572\n",
      "Epoch 39, Loss: 0.5517456323410166\n",
      "Epoch 40, Loss: 0.5508783674178306\n",
      "Epoch 41, Loss: 0.5498672368463532\n",
      "Epoch 42, Loss: 0.5487071273844145\n",
      "Epoch 43, Loss: 0.5473550869058658\n",
      "Epoch 44, Loss: 0.5457379919121161\n",
      "Epoch 45, Loss: 0.5437815777609001\n",
      "Epoch 46, Loss: 0.5414202997936031\n",
      "Epoch 47, Loss: 0.5385348460382254\n",
      "Epoch 48, Loss: 0.5350479239096012\n",
      "Epoch 49, Loss: 0.5309081660761593\n",
      "Epoch 50, Loss: 0.525950619085727\n",
      "Epoch 51, Loss: 0.5201849302782751\n",
      "Epoch 52, Loss: 0.5138093887585704\n",
      "Epoch 53, Loss: 0.5071424612095552\n",
      "Epoch 54, Loss: 0.501247518633173\n",
      "Epoch 55, Loss: 0.4980982735235364\n",
      "Epoch 56, Loss: 0.498416882868834\n",
      "Epoch 57, Loss: 0.49730141893702573\n",
      "Epoch 58, Loss: 0.4927667055641609\n",
      "Epoch 59, Loss: 0.48700988047092025\n",
      "Epoch 60, Loss: 0.4824192958253186\n",
      "Epoch 61, Loss: 0.4800532180123213\n",
      "Epoch 62, Loss: 0.4786346910222358\n",
      "Epoch 63, Loss: 0.47712875556717\n",
      "Epoch 64, Loss: 0.47518659741256875\n",
      "Epoch 65, Loss: 0.4724159417994984\n",
      "Epoch 66, Loss: 0.47073292934666644\n",
      "Epoch 67, Loss: 0.46989247649486415\n",
      "Epoch 68, Loss: 0.4686810283781283\n",
      "Epoch 69, Loss: 0.4669901395886045\n",
      "Epoch 70, Loss: 0.4655288328159365\n",
      "Epoch 71, Loss: 0.4648592008699552\n",
      "Epoch 72, Loss: 0.46462772061831975\n",
      "Epoch 73, Loss: 0.4643442050277726\n",
      "Epoch 74, Loss: 0.46395031635887424\n",
      "Epoch 75, Loss: 0.46353547131402273\n",
      "Epoch 76, Loss: 0.46309924353923065\n",
      "Epoch 77, Loss: 0.4626006654782834\n",
      "Epoch 78, Loss: 0.46196661039346065\n",
      "Epoch 79, Loss: 0.46121695500917614\n",
      "Epoch 80, Loss: 0.46041193595745833\n",
      "Epoch 81, Loss: 0.4596134987451104\n",
      "Epoch 82, Loss: 0.4588666074915895\n",
      "Epoch 83, Loss: 0.4581808808399788\n",
      "Epoch 84, Loss: 0.4575692458200666\n",
      "Epoch 85, Loss: 0.4569794063018224\n",
      "Epoch 86, Loss: 0.4563886412214656\n",
      "Epoch 87, Loss: 0.4557837390014355\n",
      "Epoch 88, Loss: 0.45520170113848213\n",
      "Epoch 89, Loss: 0.4546295542023441\n",
      "Epoch 90, Loss: 0.45407081417865225\n",
      "Epoch 91, Loss: 0.4535204050106253\n",
      "Epoch 92, Loss: 0.4529869263848753\n",
      "Epoch 93, Loss: 0.4524508591571567\n",
      "Epoch 94, Loss: 0.4519150628075454\n",
      "Epoch 95, Loss: 0.451378432380981\n",
      "Epoch 96, Loss: 0.45084274969943855\n",
      "Epoch 97, Loss: 0.4502772424252012\n",
      "Epoch 98, Loss: 0.4496948207394528\n",
      "Epoch 99, Loss: 0.44911401605804346\n",
      "Epoch 100, Loss: 0.44852121349335555\n",
      "Epoch 101, Loss: 0.4479050209690192\n",
      "Epoch 102, Loss: 0.44729327653590145\n",
      "Epoch 103, Loss: 0.4466509697626771\n",
      "Epoch 104, Loss: 0.44600311066628967\n",
      "Epoch 105, Loss: 0.44535091301394125\n",
      "Epoch 106, Loss: 0.4446748886947248\n",
      "Epoch 107, Loss: 0.44399694569606835\n",
      "Epoch 108, Loss: 0.4433182684709829\n",
      "Epoch 109, Loss: 0.44264210224265316\n",
      "Epoch 110, Loss: 0.4419774941814257\n",
      "Epoch 111, Loss: 0.44129500210946765\n",
      "Epoch 112, Loss: 0.4406047566139807\n",
      "Epoch 113, Loss: 0.4399429812387266\n",
      "Epoch 114, Loss: 0.4393015282140419\n",
      "Epoch 115, Loss: 0.43869150921165795\n",
      "Epoch 116, Loss: 0.4380780726563148\n",
      "Epoch 117, Loss: 0.4374519730501091\n",
      "Epoch 118, Loss: 0.43681037569477826\n",
      "Epoch 119, Loss: 0.43617266871321864\n",
      "Epoch 120, Loss: 0.4355343359266988\n",
      "Epoch 121, Loss: 0.43490066830199314\n",
      "Epoch 122, Loss: 0.43428192856815157\n",
      "Epoch 123, Loss: 0.4336701918569155\n",
      "Epoch 124, Loss: 0.4330632168740092\n",
      "Epoch 125, Loss: 0.4324630049224604\n",
      "Epoch 126, Loss: 0.4318715509147213\n",
      "Epoch 127, Loss: 0.4312879407474402\n",
      "Epoch 128, Loss: 0.4307187277079747\n",
      "Epoch 129, Loss: 0.43014694273080695\n",
      "Epoch 130, Loss: 0.4295601569391691\n",
      "Epoch 131, Loss: 0.42896501315774893\n",
      "Epoch 132, Loss: 0.42836742498614533\n",
      "Epoch 133, Loss: 0.42779328101759406\n",
      "Epoch 134, Loss: 0.42722549824801404\n",
      "Epoch 135, Loss: 0.4266653244393565\n",
      "Epoch 136, Loss: 0.42611268469016916\n",
      "Epoch 137, Loss: 0.42554504071984145\n",
      "Epoch 138, Loss: 0.4249764632271152\n",
      "Epoch 139, Loss: 0.4244140407318236\n",
      "Epoch 140, Loss: 0.42389803191225545\n",
      "Epoch 141, Loss: 0.4234701833745054\n",
      "Epoch 142, Loss: 0.4230623138512985\n",
      "Epoch 143, Loss: 0.4224322135990722\n",
      "Epoch 144, Loss: 0.4216948583788343\n",
      "Epoch 145, Loss: 0.42113422772518533\n",
      "Epoch 146, Loss: 0.4208040773338326\n",
      "Epoch 147, Loss: 0.4204715590877534\n",
      "Epoch 148, Loss: 0.4198470292923364\n",
      "Epoch 149, Loss: 0.41913874146677316\n",
      "Epoch 150, Loss: 0.418709837709839\n",
      "Epoch 151, Loss: 0.4183638657044813\n",
      "Epoch 152, Loss: 0.4178659544412763\n",
      "Epoch 153, Loss: 0.41724727430990427\n",
      "Epoch 154, Loss: 0.41681606673983884\n",
      "Epoch 155, Loss: 0.4165281621884499\n",
      "Epoch 156, Loss: 0.416182113071815\n",
      "Epoch 157, Loss: 0.41564444876462486\n",
      "Epoch 158, Loss: 0.41496935090674253\n",
      "Epoch 159, Loss: 0.4144134833300996\n",
      "Epoch 160, Loss: 0.413999030808913\n",
      "Epoch 161, Loss: 0.41361017532504657\n",
      "Epoch 162, Loss: 0.41326658659162596\n",
      "Epoch 163, Loss: 0.4127752520024148\n",
      "Epoch 164, Loss: 0.4122222998781951\n",
      "Epoch 165, Loss: 0.41156939524650843\n",
      "Epoch 166, Loss: 0.4110330746109252\n",
      "Epoch 167, Loss: 0.4106376366144226\n",
      "Epoch 168, Loss: 0.4104043119607425\n",
      "Epoch 169, Loss: 0.4101899814359189\n",
      "Epoch 170, Loss: 0.4098128379772678\n",
      "Epoch 171, Loss: 0.4091085221853147\n",
      "Epoch 172, Loss: 0.40822519124087503\n",
      "Epoch 173, Loss: 0.4077798026412429\n",
      "Epoch 174, Loss: 0.4078265374058742\n",
      "Epoch 175, Loss: 0.4077813556807527\n",
      "Epoch 176, Loss: 0.40710443728330775\n",
      "Epoch 177, Loss: 0.406042210917975\n",
      "Epoch 178, Loss: 0.40563496470150867\n",
      "Epoch 179, Loss: 0.4057166559969955\n",
      "Epoch 180, Loss: 0.40552160179535063\n",
      "Epoch 181, Loss: 0.4047133838815342\n",
      "Epoch 182, Loss: 0.4038251991040517\n",
      "Epoch 183, Loss: 0.40351286718233004\n",
      "Epoch 184, Loss: 0.40348038718029994\n",
      "Epoch 185, Loss: 0.40334957284522904\n",
      "Epoch 186, Loss: 0.40288788379375023\n",
      "Epoch 187, Loss: 0.4020399965475661\n",
      "Epoch 188, Loss: 0.4013330301197043\n",
      "Epoch 189, Loss: 0.4010799150269075\n",
      "Epoch 190, Loss: 0.40113558433289026\n",
      "Epoch 191, Loss: 0.40131849378747636\n",
      "Epoch 192, Loss: 0.4009876173514343\n",
      "Epoch 193, Loss: 0.40022587061433534\n",
      "Epoch 194, Loss: 0.39916503156646976\n",
      "Epoch 195, Loss: 0.39869702058970063\n",
      "Epoch 196, Loss: 0.39874113892183594\n",
      "Epoch 197, Loss: 0.3988340685604241\n",
      "Epoch 198, Loss: 0.39832132179047836\n",
      "Epoch 199, Loss: 0.3974541515923903\n",
      "Epoch 200, Loss: 0.39679191200200425\n",
      "Epoch 201, Loss: 0.39649533035852597\n",
      "Epoch 202, Loss: 0.39652037809422613\n",
      "Epoch 203, Loss: 0.3968652483725798\n",
      "Epoch 204, Loss: 0.3969333530690521\n",
      "Epoch 205, Loss: 0.3963442963696625\n",
      "Epoch 206, Loss: 0.39505340468659916\n",
      "Epoch 207, Loss: 0.3943111069878826\n",
      "Epoch 208, Loss: 0.39441558350984485\n",
      "Epoch 209, Loss: 0.39462545422179574\n",
      "Epoch 210, Loss: 0.3943894953111742\n",
      "Epoch 211, Loss: 0.3933554777011036\n",
      "Epoch 212, Loss: 0.3925716342674128\n",
      "Epoch 213, Loss: 0.3924535677105785\n",
      "Epoch 214, Loss: 0.39273626074747053\n",
      "Epoch 215, Loss: 0.39281947749578633\n",
      "Epoch 216, Loss: 0.3919776575487079\n",
      "Epoch 217, Loss: 0.39104341985519175\n",
      "Epoch 218, Loss: 0.39045662111981544\n",
      "Epoch 219, Loss: 0.3903746183945021\n",
      "Epoch 220, Loss: 0.39050462775473843\n",
      "Epoch 221, Loss: 0.39056544803624504\n",
      "Epoch 222, Loss: 0.39046068550321095\n",
      "Epoch 223, Loss: 0.3897581782483135\n",
      "Epoch 224, Loss: 0.38884407331132403\n",
      "Epoch 225, Loss: 0.3880180149701404\n",
      "Epoch 226, Loss: 0.38757162739575024\n",
      "Epoch 227, Loss: 0.38744788357758086\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2356682689062614\n",
      "Test R^2 score: 0.4026784426081279\n",
      "Num of epochs: 228\n",
      "Epoch 1, Loss: 0.5846638888510929\n",
      "Epoch 2, Loss: 0.5822555314682064\n",
      "Epoch 3, Loss: 0.579944813626819\n",
      "Epoch 4, Loss: 0.5777988286977339\n",
      "Epoch 5, Loss: 0.5757520536269328\n",
      "Epoch 6, Loss: 0.5737829046433812\n",
      "Epoch 7, Loss: 0.5718939032843818\n",
      "Epoch 8, Loss: 0.5700898715744994\n",
      "Epoch 9, Loss: 0.5683799294232182\n",
      "Epoch 10, Loss: 0.5668014725985676\n",
      "Epoch 11, Loss: 0.565316487051008\n",
      "Epoch 12, Loss: 0.563932660658428\n",
      "Epoch 13, Loss: 0.5626471115171047\n",
      "Epoch 14, Loss: 0.5616701150141207\n",
      "Epoch 15, Loss: 0.5608242823856224\n",
      "Epoch 16, Loss: 0.5600410598364856\n",
      "Epoch 17, Loss: 0.559321349783816\n",
      "Epoch 18, Loss: 0.5586661178554686\n",
      "Epoch 19, Loss: 0.5580825333709398\n",
      "Epoch 20, Loss: 0.5575760594046838\n",
      "Epoch 21, Loss: 0.5571319820710312\n",
      "Epoch 22, Loss: 0.556752859479107\n",
      "Epoch 23, Loss: 0.556454570528555\n",
      "Epoch 24, Loss: 0.5561824050294446\n",
      "Epoch 25, Loss: 0.5559520276955289\n",
      "Epoch 26, Loss: 0.5557548569446862\n",
      "Epoch 27, Loss: 0.5555797439183838\n",
      "Epoch 28, Loss: 0.5554116585923775\n",
      "Epoch 29, Loss: 0.5552302378281216\n",
      "Epoch 30, Loss: 0.5550202459646256\n",
      "Epoch 31, Loss: 0.554772276511458\n",
      "Epoch 32, Loss: 0.5544593234264653\n",
      "Epoch 33, Loss: 0.5540494338300608\n",
      "Epoch 34, Loss: 0.5535052689557386\n",
      "Epoch 35, Loss: 0.5527791251140045\n",
      "Epoch 36, Loss: 0.5518260812301111\n",
      "Epoch 37, Loss: 0.5506057459639846\n",
      "Epoch 38, Loss: 0.5490721027921891\n",
      "Epoch 39, Loss: 0.5471682988168707\n",
      "Epoch 40, Loss: 0.5448443449918027\n",
      "Epoch 41, Loss: 0.542056930386706\n",
      "Epoch 42, Loss: 0.538851434049444\n",
      "Epoch 43, Loss: 0.5353900927567853\n",
      "Epoch 44, Loss: 0.531996398994262\n",
      "Epoch 45, Loss: 0.5291123860471246\n",
      "Epoch 46, Loss: 0.5270627721412379\n",
      "Epoch 47, Loss: 0.5254006650738233\n",
      "Epoch 48, Loss: 0.5230706195982807\n",
      "Epoch 49, Loss: 0.5200489877587344\n",
      "Epoch 50, Loss: 0.5172668384652422\n",
      "Epoch 51, Loss: 0.5152684626318523\n",
      "Epoch 52, Loss: 0.5136763423826947\n",
      "Epoch 53, Loss: 0.5119109047767212\n",
      "Epoch 54, Loss: 0.5096750873244699\n",
      "Epoch 55, Loss: 0.5071748985563079\n",
      "Epoch 56, Loss: 0.5049756553182954\n",
      "Epoch 57, Loss: 0.5035309687866797\n",
      "Epoch 58, Loss: 0.5024304625095064\n",
      "Epoch 59, Loss: 0.5007280770814978\n",
      "Epoch 60, Loss: 0.49842141224121456\n",
      "Epoch 61, Loss: 0.4963367647907869\n",
      "Epoch 62, Loss: 0.49480140743371537\n",
      "Epoch 63, Loss: 0.493443627008397\n",
      "Epoch 64, Loss: 0.49178621797172745\n",
      "Epoch 65, Loss: 0.4898903692228573\n",
      "Epoch 66, Loss: 0.48822739876384386\n",
      "Epoch 67, Loss: 0.48692279292181906\n",
      "Epoch 68, Loss: 0.48560969590039277\n",
      "Epoch 69, Loss: 0.4840823027498624\n",
      "Epoch 70, Loss: 0.48260692182589204\n",
      "Epoch 71, Loss: 0.4812990163636514\n",
      "Epoch 72, Loss: 0.4799279837178421\n",
      "Epoch 73, Loss: 0.47844038391240756\n",
      "Epoch 74, Loss: 0.47697827696968914\n",
      "Epoch 75, Loss: 0.4756364736789697\n",
      "Epoch 76, Loss: 0.4741744415096088\n",
      "Epoch 77, Loss: 0.4727078716998188\n",
      "Epoch 78, Loss: 0.47141184023689897\n",
      "Epoch 79, Loss: 0.4701244548621005\n",
      "Epoch 80, Loss: 0.4687557379053519\n",
      "Epoch 81, Loss: 0.4673237241575853\n",
      "Epoch 82, Loss: 0.4660226154682421\n",
      "Epoch 83, Loss: 0.46463641182793936\n",
      "Epoch 84, Loss: 0.4631680329339154\n",
      "Epoch 85, Loss: 0.46201444345661363\n",
      "Epoch 86, Loss: 0.4609938279988253\n",
      "Epoch 87, Loss: 0.46028071017275424\n",
      "Epoch 88, Loss: 0.45987893444679073\n",
      "Epoch 89, Loss: 0.45956209226455563\n",
      "Epoch 90, Loss: 0.4592830903368825\n",
      "Epoch 91, Loss: 0.45874832251759184\n",
      "Epoch 92, Loss: 0.4580284227886603\n",
      "Epoch 93, Loss: 0.45723944592483784\n",
      "Epoch 94, Loss: 0.45648212537418464\n",
      "Epoch 95, Loss: 0.4558491376366366\n",
      "Epoch 96, Loss: 0.4552719783882315\n",
      "Epoch 97, Loss: 0.4547975354581217\n",
      "Epoch 98, Loss: 0.4543663811423729\n",
      "Epoch 99, Loss: 0.4538948162693878\n",
      "Epoch 100, Loss: 0.4534235496925186\n",
      "Epoch 101, Loss: 0.45285558912819524\n",
      "Epoch 102, Loss: 0.4523049695351513\n",
      "Epoch 103, Loss: 0.4517070024269769\n",
      "Epoch 104, Loss: 0.45112465945807306\n",
      "Epoch 105, Loss: 0.450570337151967\n",
      "Epoch 106, Loss: 0.4500275007427762\n",
      "Epoch 107, Loss: 0.44951964542710304\n",
      "Epoch 108, Loss: 0.4490257014233703\n",
      "Epoch 109, Loss: 0.4485449672151717\n",
      "Epoch 110, Loss: 0.44803765976732185\n",
      "Epoch 111, Loss: 0.4475178403068658\n",
      "Epoch 112, Loss: 0.4469749305605561\n",
      "Epoch 113, Loss: 0.44643539934386406\n",
      "Epoch 114, Loss: 0.4459076635247551\n",
      "Epoch 115, Loss: 0.44540971397573653\n",
      "Epoch 116, Loss: 0.4449220585341238\n",
      "Epoch 117, Loss: 0.4444278663864697\n",
      "Epoch 118, Loss: 0.44390007691486894\n",
      "Epoch 119, Loss: 0.44335987914472647\n",
      "Epoch 120, Loss: 0.44282677879813986\n",
      "Epoch 121, Loss: 0.4423218405096999\n",
      "Epoch 122, Loss: 0.4418415353936578\n",
      "Epoch 123, Loss: 0.44136003235421506\n",
      "Epoch 124, Loss: 0.44087719227089217\n",
      "Epoch 125, Loss: 0.44039417808822334\n",
      "Epoch 126, Loss: 0.4398908681346148\n",
      "Epoch 127, Loss: 0.4393971555883865\n",
      "Epoch 128, Loss: 0.43889344921573004\n",
      "Epoch 129, Loss: 0.43841718853690614\n",
      "Epoch 130, Loss: 0.4379498859361817\n",
      "Epoch 131, Loss: 0.43746147667352325\n",
      "Epoch 132, Loss: 0.4369374473155954\n",
      "Epoch 133, Loss: 0.43637244495505995\n",
      "Epoch 134, Loss: 0.4357864849806068\n",
      "Epoch 135, Loss: 0.4352284623228721\n",
      "Epoch 136, Loss: 0.4346783964354277\n",
      "Epoch 137, Loss: 0.434107965267501\n",
      "Epoch 138, Loss: 0.4335367319919055\n",
      "Epoch 139, Loss: 0.43294579832269803\n",
      "Epoch 140, Loss: 0.4323587959133752\n",
      "Epoch 141, Loss: 0.43174676755215297\n",
      "Epoch 142, Loss: 0.43112320763715023\n",
      "Epoch 143, Loss: 0.4305157222147515\n",
      "Epoch 144, Loss: 0.42997149705678167\n",
      "Epoch 145, Loss: 0.4294847703738226\n",
      "Epoch 146, Loss: 0.42914463776775413\n",
      "Epoch 147, Loss: 0.4290427833133355\n",
      "Epoch 148, Loss: 0.4285019906308241\n",
      "Epoch 149, Loss: 0.4275321656668944\n",
      "Epoch 150, Loss: 0.427441605656564\n",
      "Epoch 151, Loss: 0.42696499541901106\n",
      "Epoch 152, Loss: 0.4262022858983537\n",
      "Epoch 153, Loss: 0.4261952233846124\n",
      "Epoch 154, Loss: 0.42557331572430573\n",
      "Epoch 155, Loss: 0.42494569389409326\n",
      "Epoch 156, Loss: 0.42483616854773043\n",
      "Epoch 157, Loss: 0.42420501475991823\n",
      "Epoch 158, Loss: 0.42367769023851265\n",
      "Epoch 159, Loss: 0.42355756429898295\n",
      "Epoch 160, Loss: 0.4231400243720311\n",
      "Epoch 161, Loss: 0.4226339542339576\n",
      "Epoch 162, Loss: 0.4224575224238827\n",
      "Epoch 163, Loss: 0.42213557284723113\n",
      "Epoch 164, Loss: 0.42159961613396935\n",
      "Epoch 165, Loss: 0.4213012219594424\n",
      "Epoch 166, Loss: 0.4210689049010394\n",
      "Epoch 167, Loss: 0.42061747225392176\n",
      "Epoch 168, Loss: 0.4201735341243353\n",
      "Epoch 169, Loss: 0.4198939824266584\n",
      "Epoch 170, Loss: 0.4195833837982016\n",
      "Epoch 171, Loss: 0.41911017457502986\n",
      "Epoch 172, Loss: 0.4186969189664201\n",
      "Epoch 173, Loss: 0.41836753431212037\n",
      "Epoch 174, Loss: 0.41805597981543713\n",
      "Epoch 175, Loss: 0.41775098814353756\n",
      "Epoch 176, Loss: 0.4174178941020307\n",
      "Epoch 177, Loss: 0.4171060589795894\n",
      "Epoch 178, Loss: 0.4167943659441433\n",
      "Epoch 179, Loss: 0.41637328269670776\n",
      "Epoch 180, Loss: 0.4158698350363776\n",
      "Epoch 181, Loss: 0.41537094310647094\n",
      "Epoch 182, Loss: 0.4148804844111312\n",
      "Epoch 183, Loss: 0.41439406597066203\n",
      "Epoch 184, Loss: 0.41397765027984423\n",
      "Epoch 185, Loss: 0.4135722010539625\n",
      "Epoch 186, Loss: 0.4133232102609334\n",
      "Epoch 187, Loss: 0.41356973296596017\n",
      "Epoch 188, Loss: 0.4148508520290696\n",
      "Epoch 189, Loss: 0.4148129194911889\n",
      "Epoch 190, Loss: 0.41192630118379686\n",
      "Epoch 191, Loss: 0.4128336756182101\n",
      "Epoch 192, Loss: 0.4127914064087642\n",
      "Epoch 193, Loss: 0.41088914332869936\n",
      "Epoch 194, Loss: 0.4122433376884316\n",
      "Epoch 195, Loss: 0.41074659460354485\n",
      "Epoch 196, Loss: 0.4103632994711315\n",
      "Epoch 197, Loss: 0.4108119809164682\n",
      "Epoch 198, Loss: 0.4092553189467388\n",
      "Epoch 199, Loss: 0.41014413361591096\n",
      "Epoch 200, Loss: 0.40894329006778274\n",
      "Epoch 201, Loss: 0.40869995618693483\n",
      "Epoch 202, Loss: 0.4088574873026063\n",
      "Epoch 203, Loss: 0.40761258790327776\n",
      "Epoch 204, Loss: 0.407969467238428\n",
      "Epoch 205, Loss: 0.40728537960354605\n",
      "Epoch 206, Loss: 0.40670477647844333\n",
      "Epoch 207, Loss: 0.4068895587572447\n",
      "Epoch 208, Loss: 0.40606052308249413\n",
      "Epoch 209, Loss: 0.40587259148087806\n",
      "Epoch 210, Loss: 0.4057229180726072\n",
      "Epoch 211, Loss: 0.40509420820953485\n",
      "Epoch 212, Loss: 0.404878612446841\n",
      "Epoch 213, Loss: 0.40477593460898686\n",
      "Epoch 214, Loss: 0.4040753222833297\n",
      "Epoch 215, Loss: 0.40383809545794647\n",
      "Epoch 216, Loss: 0.4037300411700253\n",
      "Epoch 217, Loss: 0.40314167490929975\n",
      "Epoch 218, Loss: 0.40263289644775724\n",
      "Epoch 219, Loss: 0.40230352700659916\n",
      "Epoch 220, Loss: 0.40211317251430784\n",
      "Epoch 221, Loss: 0.4016098439847197\n",
      "Epoch 222, Loss: 0.4010748993947003\n",
      "Epoch 223, Loss: 0.40060605092099566\n",
      "Epoch 224, Loss: 0.40014395209692943\n",
      "Epoch 225, Loss: 0.39978319938695484\n",
      "Epoch 226, Loss: 0.39960657903713\n",
      "Epoch 227, Loss: 0.3994925312291788\n",
      "Epoch 228, Loss: 0.3995696606482957\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22559209204658143\n",
      "Test R^2 score: 0.4506397259326806\n",
      "Num of epochs: 229\n",
      "Epoch 1, Loss: 0.5650455045942687\n",
      "Epoch 2, Loss: 0.5638262425650641\n",
      "Epoch 3, Loss: 0.5627037844802991\n",
      "Epoch 4, Loss: 0.5616533742750496\n",
      "Epoch 5, Loss: 0.5606774101722947\n",
      "Epoch 6, Loss: 0.5597844271753096\n",
      "Epoch 7, Loss: 0.5589769289599091\n",
      "Epoch 8, Loss: 0.5582846473229615\n",
      "Epoch 9, Loss: 0.5576973237879583\n",
      "Epoch 10, Loss: 0.5572068129020289\n",
      "Epoch 11, Loss: 0.5568060378199455\n",
      "Epoch 12, Loss: 0.5564977629857373\n",
      "Epoch 13, Loss: 0.5562925086762813\n",
      "Epoch 14, Loss: 0.5561738315681286\n",
      "Epoch 15, Loss: 0.5561225755878334\n",
      "Epoch 16, Loss: 0.5561284436054753\n",
      "Epoch 17, Loss: 0.5561832891601256\n",
      "Epoch 18, Loss: 0.5562478001154572\n",
      "Epoch 19, Loss: 0.5563021517533526\n",
      "Epoch 20, Loss: 0.5563297407450635\n",
      "Epoch 21, Loss: 0.5563224284562485\n",
      "Epoch 22, Loss: 0.5562829457931082\n",
      "Epoch 23, Loss: 0.5562022306525785\n",
      "Epoch 24, Loss: 0.5560800239088739\n",
      "Epoch 25, Loss: 0.5559200776464941\n",
      "Epoch 26, Loss: 0.5557250138627837\n",
      "Epoch 27, Loss: 0.5554951442880542\n",
      "Epoch 28, Loss: 0.5552265073606092\n",
      "Epoch 29, Loss: 0.5549167911340166\n",
      "Epoch 30, Loss: 0.5545386531074477\n",
      "Epoch 31, Loss: 0.5541044313815706\n",
      "Epoch 32, Loss: 0.553590980197697\n",
      "Epoch 33, Loss: 0.5530464989512297\n",
      "Epoch 34, Loss: 0.5524445977202261\n",
      "Epoch 35, Loss: 0.5517558410069175\n",
      "Epoch 36, Loss: 0.5509557244742659\n",
      "Epoch 37, Loss: 0.5500349575550842\n",
      "Epoch 38, Loss: 0.5489748015518348\n",
      "Epoch 39, Loss: 0.5477459647666812\n",
      "Epoch 40, Loss: 0.5463086056205533\n",
      "Epoch 41, Loss: 0.5446368877119491\n",
      "Epoch 42, Loss: 0.5426795793214726\n",
      "Epoch 43, Loss: 0.5403440142167533\n",
      "Epoch 44, Loss: 0.5375151332676551\n",
      "Epoch 45, Loss: 0.5341017141392864\n",
      "Epoch 46, Loss: 0.5300498476968674\n",
      "Epoch 47, Loss: 0.5253322242696467\n",
      "Epoch 48, Loss: 0.519966402160527\n",
      "Epoch 49, Loss: 0.513990238293674\n",
      "Epoch 50, Loss: 0.5076864232764872\n",
      "Epoch 51, Loss: 0.5017830230212124\n",
      "Epoch 52, Loss: 0.49801870528197795\n",
      "Epoch 53, Loss: 0.4977904014687337\n",
      "Epoch 54, Loss: 0.49725077712553045\n",
      "Epoch 55, Loss: 0.49375107076987523\n",
      "Epoch 56, Loss: 0.489780778502899\n",
      "Epoch 57, Loss: 0.4873367635379639\n",
      "Epoch 58, Loss: 0.4863892022811521\n",
      "Epoch 59, Loss: 0.48548742960047825\n",
      "Epoch 60, Loss: 0.48364675289934517\n",
      "Epoch 61, Loss: 0.4808208756951407\n",
      "Epoch 62, Loss: 0.47775357348963565\n",
      "Epoch 63, Loss: 0.47518401032540825\n",
      "Epoch 64, Loss: 0.47362128174893603\n",
      "Epoch 65, Loss: 0.4733085544854432\n",
      "Epoch 66, Loss: 0.4738993415869803\n",
      "Epoch 67, Loss: 0.47438544810955696\n",
      "Epoch 68, Loss: 0.47386291262989483\n",
      "Epoch 69, Loss: 0.4724533181366562\n",
      "Epoch 70, Loss: 0.47083190485926074\n",
      "Epoch 71, Loss: 0.4695612721675284\n",
      "Epoch 72, Loss: 0.46888618080539557\n",
      "Epoch 73, Loss: 0.46843389343033787\n",
      "Epoch 74, Loss: 0.467865379392554\n",
      "Epoch 75, Loss: 0.4673413409314802\n",
      "Epoch 76, Loss: 0.4667757420564451\n",
      "Epoch 77, Loss: 0.4659844515175279\n",
      "Epoch 78, Loss: 0.46500539773966587\n",
      "Epoch 79, Loss: 0.46403672182046496\n",
      "Epoch 80, Loss: 0.46313568259929155\n",
      "Epoch 81, Loss: 0.4624105611874604\n",
      "Epoch 82, Loss: 0.4619482564064777\n",
      "Epoch 83, Loss: 0.4616157584692079\n",
      "Epoch 84, Loss: 0.46128638043925335\n",
      "Epoch 85, Loss: 0.46087240309018546\n",
      "Epoch 86, Loss: 0.4602899690644343\n",
      "Epoch 87, Loss: 0.45959257046825763\n",
      "Epoch 88, Loss: 0.4590162387907035\n",
      "Epoch 89, Loss: 0.4585357096399357\n",
      "Epoch 90, Loss: 0.45801283908843\n",
      "Epoch 91, Loss: 0.4574447945342707\n",
      "Epoch 92, Loss: 0.4568976182466021\n",
      "Epoch 93, Loss: 0.456397440354193\n",
      "Epoch 94, Loss: 0.4558949650303815\n",
      "Epoch 95, Loss: 0.45538182418782225\n",
      "Epoch 96, Loss: 0.4548765399085991\n",
      "Epoch 97, Loss: 0.4543611502340349\n",
      "Epoch 98, Loss: 0.4538798785797129\n",
      "Epoch 99, Loss: 0.45342001683439953\n",
      "Epoch 100, Loss: 0.4529429596226718\n",
      "Epoch 101, Loss: 0.45247508170082185\n",
      "Epoch 102, Loss: 0.45198688957940947\n",
      "Epoch 103, Loss: 0.4514917172984975\n",
      "Epoch 104, Loss: 0.4510084409420765\n",
      "Epoch 105, Loss: 0.45053134384096083\n",
      "Epoch 106, Loss: 0.4500451985813266\n",
      "Epoch 107, Loss: 0.44953466170802675\n",
      "Epoch 108, Loss: 0.44901564609161027\n",
      "Epoch 109, Loss: 0.448465661417371\n",
      "Epoch 110, Loss: 0.4478951899976064\n",
      "Epoch 111, Loss: 0.4473404467770865\n",
      "Epoch 112, Loss: 0.446855715355546\n",
      "Epoch 113, Loss: 0.4463959947689234\n",
      "Epoch 114, Loss: 0.4459309382714427\n",
      "Epoch 115, Loss: 0.44546723605366656\n",
      "Epoch 116, Loss: 0.4450247654827823\n",
      "Epoch 117, Loss: 0.4445814020596964\n",
      "Epoch 118, Loss: 0.44413388866996134\n",
      "Epoch 119, Loss: 0.4436966037861425\n",
      "Epoch 120, Loss: 0.44326053475513655\n",
      "Epoch 121, Loss: 0.44285142680348866\n",
      "Epoch 122, Loss: 0.4424270203587751\n",
      "Epoch 123, Loss: 0.44201454513985877\n",
      "Epoch 124, Loss: 0.4416251525921832\n",
      "Epoch 125, Loss: 0.44123394734303717\n",
      "Epoch 126, Loss: 0.4408366317331172\n",
      "Epoch 127, Loss: 0.4404322926514035\n",
      "Epoch 128, Loss: 0.44004949158603496\n",
      "Epoch 129, Loss: 0.4396667639337239\n",
      "Epoch 130, Loss: 0.43927905555877667\n",
      "Epoch 131, Loss: 0.4388694956658939\n",
      "Epoch 132, Loss: 0.4384775480331526\n",
      "Epoch 133, Loss: 0.43807371873350925\n",
      "Epoch 134, Loss: 0.4376778411442253\n",
      "Epoch 135, Loss: 0.4372736481541692\n",
      "Epoch 136, Loss: 0.4368632996920179\n",
      "Epoch 137, Loss: 0.4364230832118734\n",
      "Epoch 138, Loss: 0.4359412695608927\n",
      "Epoch 139, Loss: 0.43546402147433927\n",
      "Epoch 140, Loss: 0.4350385051160956\n",
      "Epoch 141, Loss: 0.4346263035054445\n",
      "Epoch 142, Loss: 0.43419680885537426\n",
      "Epoch 143, Loss: 0.43377449804706475\n",
      "Epoch 144, Loss: 0.43335810263463964\n",
      "Epoch 145, Loss: 0.4329523721252193\n",
      "Epoch 146, Loss: 0.4325508428468166\n",
      "Epoch 147, Loss: 0.43215031974883933\n",
      "Epoch 148, Loss: 0.4317240051932694\n",
      "Epoch 149, Loss: 0.4312659143192809\n",
      "Epoch 150, Loss: 0.4307127598501867\n",
      "Epoch 151, Loss: 0.430081395025061\n",
      "Epoch 152, Loss: 0.42946228714305973\n",
      "Epoch 153, Loss: 0.4288130966502627\n",
      "Epoch 154, Loss: 0.42814652952649584\n",
      "Epoch 155, Loss: 0.4275445386205658\n",
      "Epoch 156, Loss: 0.42701692374994815\n",
      "Epoch 157, Loss: 0.4265113136125864\n",
      "Epoch 158, Loss: 0.42601223900724505\n",
      "Epoch 159, Loss: 0.4255097774935461\n",
      "Epoch 160, Loss: 0.4250295811063566\n",
      "Epoch 161, Loss: 0.4245670925730401\n",
      "Epoch 162, Loss: 0.4241240913905297\n",
      "Epoch 163, Loss: 0.4236655736613237\n",
      "Epoch 164, Loss: 0.4231947459911967\n",
      "Epoch 165, Loss: 0.42275367290924815\n",
      "Epoch 166, Loss: 0.42235768926369527\n",
      "Epoch 167, Loss: 0.42201560820849576\n",
      "Epoch 168, Loss: 0.42180926199294927\n",
      "Epoch 169, Loss: 0.42163858147084066\n",
      "Epoch 170, Loss: 0.4210735231258695\n",
      "Epoch 171, Loss: 0.4202245109664193\n",
      "Epoch 172, Loss: 0.4201026527376876\n",
      "Epoch 173, Loss: 0.419922886337127\n",
      "Epoch 174, Loss: 0.41910297477115155\n",
      "Epoch 175, Loss: 0.4188270846629515\n",
      "Epoch 176, Loss: 0.41868150848392993\n",
      "Epoch 177, Loss: 0.4179344876230579\n",
      "Epoch 178, Loss: 0.4176253574875618\n",
      "Epoch 179, Loss: 0.41745717836966434\n",
      "Epoch 180, Loss: 0.41676302828730816\n",
      "Epoch 181, Loss: 0.41644037976414994\n",
      "Epoch 182, Loss: 0.41624070288897563\n",
      "Epoch 183, Loss: 0.4156012105228392\n",
      "Epoch 184, Loss: 0.41512060822872016\n",
      "Epoch 185, Loss: 0.4148976163500988\n",
      "Epoch 186, Loss: 0.41446243620829815\n",
      "Epoch 187, Loss: 0.4138715951710951\n",
      "Epoch 188, Loss: 0.41353706994692885\n",
      "Epoch 189, Loss: 0.41327805256463007\n",
      "Epoch 190, Loss: 0.412813407873849\n",
      "Epoch 191, Loss: 0.41220932241172253\n",
      "Epoch 192, Loss: 0.4118210565902845\n",
      "Epoch 193, Loss: 0.41153637431648626\n",
      "Epoch 194, Loss: 0.4111838592226636\n",
      "Epoch 195, Loss: 0.41065102661656605\n",
      "Epoch 196, Loss: 0.4101426440207459\n",
      "Epoch 197, Loss: 0.40967775317250665\n",
      "Epoch 198, Loss: 0.4092817520636003\n",
      "Epoch 199, Loss: 0.4089497760176031\n",
      "Epoch 200, Loss: 0.4087155971864871\n",
      "Epoch 201, Loss: 0.4086173479257007\n",
      "Epoch 202, Loss: 0.4084462076322781\n",
      "Epoch 203, Loss: 0.4077464382699021\n",
      "Epoch 204, Loss: 0.4068894855129836\n",
      "Epoch 205, Loss: 0.4064306994354208\n",
      "Epoch 206, Loss: 0.40637667221621754\n",
      "Epoch 207, Loss: 0.40613451563382735\n",
      "Epoch 208, Loss: 0.40547204723744784\n",
      "Epoch 209, Loss: 0.40466236787620113\n",
      "Epoch 210, Loss: 0.4041978834655044\n",
      "Epoch 211, Loss: 0.40406525468587984\n",
      "Epoch 212, Loss: 0.4039646202425778\n",
      "Epoch 213, Loss: 0.403607836339789\n",
      "Epoch 214, Loss: 0.4028928768560307\n",
      "Epoch 215, Loss: 0.40210062847923184\n",
      "Epoch 216, Loss: 0.4016235906242007\n",
      "Epoch 217, Loss: 0.40145737500250395\n",
      "Epoch 218, Loss: 0.4013084869897037\n",
      "Epoch 219, Loss: 0.4010183298661468\n",
      "Epoch 220, Loss: 0.4005058867001664\n",
      "Epoch 221, Loss: 0.39987829040552064\n",
      "Epoch 222, Loss: 0.39928993963951964\n",
      "Epoch 223, Loss: 0.3988508436586453\n",
      "Epoch 224, Loss: 0.39857037516460586\n",
      "Epoch 225, Loss: 0.3985131509805421\n",
      "Epoch 226, Loss: 0.39861493741095655\n",
      "Epoch 227, Loss: 0.3985132818521469\n",
      "Epoch 228, Loss: 0.39799151049598064\n",
      "Epoch 229, Loss: 0.39705136352898684\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.23662362861065245\n",
      "Test R^2 score: 0.39587104482612445\n",
      "Num of epochs: 230\n",
      "Epoch 1, Loss: 0.6022216603874543\n",
      "Epoch 2, Loss: 0.5995712019607873\n",
      "Epoch 3, Loss: 0.5971801956185177\n",
      "Epoch 4, Loss: 0.5948324124954477\n",
      "Epoch 5, Loss: 0.59253455286638\n",
      "Epoch 6, Loss: 0.5902874269507118\n",
      "Epoch 7, Loss: 0.588092604504019\n",
      "Epoch 8, Loss: 0.585952275407782\n",
      "Epoch 9, Loss: 0.5838749760762697\n",
      "Epoch 10, Loss: 0.5819632215234726\n",
      "Epoch 11, Loss: 0.5801051740408716\n",
      "Epoch 12, Loss: 0.5783056286278176\n",
      "Epoch 13, Loss: 0.5766279064595595\n",
      "Epoch 14, Loss: 0.5749514051303269\n",
      "Epoch 15, Loss: 0.5733105750289168\n",
      "Epoch 16, Loss: 0.5717853705203563\n",
      "Epoch 17, Loss: 0.5703334281948433\n",
      "Epoch 18, Loss: 0.5689631659983341\n",
      "Epoch 19, Loss: 0.5677069626071259\n",
      "Epoch 20, Loss: 0.5665441937021891\n",
      "Epoch 21, Loss: 0.5655480295573407\n",
      "Epoch 22, Loss: 0.5646413997289405\n",
      "Epoch 23, Loss: 0.5638304182748353\n",
      "Epoch 24, Loss: 0.5630620956004483\n",
      "Epoch 25, Loss: 0.5623473914077017\n",
      "Epoch 26, Loss: 0.5616709374464461\n",
      "Epoch 27, Loss: 0.5610172013214282\n",
      "Epoch 28, Loss: 0.5603684463696379\n",
      "Epoch 29, Loss: 0.5597091955157802\n",
      "Epoch 30, Loss: 0.5590427967947278\n",
      "Epoch 31, Loss: 0.558327164426098\n",
      "Epoch 32, Loss: 0.55754316008933\n",
      "Epoch 33, Loss: 0.556684418678857\n",
      "Epoch 34, Loss: 0.5557501379296891\n",
      "Epoch 35, Loss: 0.5547312061122709\n",
      "Epoch 36, Loss: 0.5535747757603932\n",
      "Epoch 37, Loss: 0.5522394829176458\n",
      "Epoch 38, Loss: 0.5507177762731479\n",
      "Epoch 39, Loss: 0.5489723043334852\n",
      "Epoch 40, Loss: 0.5469695145813548\n",
      "Epoch 41, Loss: 0.5447038604065179\n",
      "Epoch 42, Loss: 0.5422454791990781\n",
      "Epoch 43, Loss: 0.5397273124407453\n",
      "Epoch 44, Loss: 0.5372842122665622\n",
      "Epoch 45, Loss: 0.5350049494131154\n",
      "Epoch 46, Loss: 0.5327240744681762\n",
      "Epoch 47, Loss: 0.5302190594690521\n",
      "Epoch 48, Loss: 0.5275201008117193\n",
      "Epoch 49, Loss: 0.5250978469493564\n",
      "Epoch 50, Loss: 0.5232154318193877\n",
      "Epoch 51, Loss: 0.5217872625825752\n",
      "Epoch 52, Loss: 0.52040935107552\n",
      "Epoch 53, Loss: 0.518707080582256\n",
      "Epoch 54, Loss: 0.516514242540875\n",
      "Epoch 55, Loss: 0.5138754205685776\n",
      "Epoch 56, Loss: 0.511049575645973\n",
      "Epoch 57, Loss: 0.5082961493582487\n",
      "Epoch 58, Loss: 0.5058320969697946\n",
      "Epoch 59, Loss: 0.5037236141460101\n",
      "Epoch 60, Loss: 0.5018727575895728\n",
      "Epoch 61, Loss: 0.5001066213413927\n",
      "Epoch 62, Loss: 0.4985477696241951\n",
      "Epoch 63, Loss: 0.49677252702456953\n",
      "Epoch 64, Loss: 0.49485127608632035\n",
      "Epoch 65, Loss: 0.4930453620298695\n",
      "Epoch 66, Loss: 0.4915063019316475\n",
      "Epoch 67, Loss: 0.4901985976093672\n",
      "Epoch 68, Loss: 0.4889002728973114\n",
      "Epoch 69, Loss: 0.48740983642737856\n",
      "Epoch 70, Loss: 0.48563903032259936\n",
      "Epoch 71, Loss: 0.48375502256008857\n",
      "Epoch 72, Loss: 0.4820037759775437\n",
      "Epoch 73, Loss: 0.48048538861501655\n",
      "Epoch 74, Loss: 0.47891713638751693\n",
      "Epoch 75, Loss: 0.47716922909895465\n",
      "Epoch 76, Loss: 0.47532229782730434\n",
      "Epoch 77, Loss: 0.4735047157338772\n",
      "Epoch 78, Loss: 0.4718900097108195\n",
      "Epoch 79, Loss: 0.47039832539219784\n",
      "Epoch 80, Loss: 0.46870698731489957\n",
      "Epoch 81, Loss: 0.46694031111757306\n",
      "Epoch 82, Loss: 0.4653929823578305\n",
      "Epoch 83, Loss: 0.46402148441199426\n",
      "Epoch 84, Loss: 0.4626541177326243\n",
      "Epoch 85, Loss: 0.4612535266172816\n",
      "Epoch 86, Loss: 0.45996017617974577\n",
      "Epoch 87, Loss: 0.45887505061254014\n",
      "Epoch 88, Loss: 0.45776803383338444\n",
      "Epoch 89, Loss: 0.4565755087939825\n",
      "Epoch 90, Loss: 0.4555337941230261\n",
      "Epoch 91, Loss: 0.45465131727103525\n",
      "Epoch 92, Loss: 0.4537711140945682\n",
      "Epoch 93, Loss: 0.45284714894647654\n",
      "Epoch 94, Loss: 0.45204141557262045\n",
      "Epoch 95, Loss: 0.4513433056418266\n",
      "Epoch 96, Loss: 0.4505890719234875\n",
      "Epoch 97, Loss: 0.4498979658108824\n",
      "Epoch 98, Loss: 0.44930631364656565\n",
      "Epoch 99, Loss: 0.44871655464392474\n",
      "Epoch 100, Loss: 0.44809860223566184\n",
      "Epoch 101, Loss: 0.4475234175793725\n",
      "Epoch 102, Loss: 0.44698386500187437\n",
      "Epoch 103, Loss: 0.4464530059394548\n",
      "Epoch 104, Loss: 0.44594645966348734\n",
      "Epoch 105, Loss: 0.4454586391579351\n",
      "Epoch 106, Loss: 0.4449049774792642\n",
      "Epoch 107, Loss: 0.4442875091654908\n",
      "Epoch 108, Loss: 0.4435394862336257\n",
      "Epoch 109, Loss: 0.4427424604688309\n",
      "Epoch 110, Loss: 0.44199435123549485\n",
      "Epoch 111, Loss: 0.44136286834621047\n",
      "Epoch 112, Loss: 0.4407691746747671\n",
      "Epoch 113, Loss: 0.44006298557206486\n",
      "Epoch 114, Loss: 0.4392931668245297\n",
      "Epoch 115, Loss: 0.43856523462546265\n",
      "Epoch 116, Loss: 0.43783730038439495\n",
      "Epoch 117, Loss: 0.4370846991097949\n",
      "Epoch 118, Loss: 0.43624684832726995\n",
      "Epoch 119, Loss: 0.43529696629201253\n",
      "Epoch 120, Loss: 0.4344153653058327\n",
      "Epoch 121, Loss: 0.4336088023279374\n",
      "Epoch 122, Loss: 0.4329019991060794\n",
      "Epoch 123, Loss: 0.4322234659131426\n",
      "Epoch 124, Loss: 0.4315104568779174\n",
      "Epoch 125, Loss: 0.430836390057732\n",
      "Epoch 126, Loss: 0.43009294974600415\n",
      "Epoch 127, Loss: 0.42933048675550567\n",
      "Epoch 128, Loss: 0.42861535955530566\n",
      "Epoch 129, Loss: 0.4278583956468565\n",
      "Epoch 130, Loss: 0.427162519727788\n",
      "Epoch 131, Loss: 0.4264591839490991\n",
      "Epoch 132, Loss: 0.4257478088405401\n",
      "Epoch 133, Loss: 0.42506076504566825\n",
      "Epoch 134, Loss: 0.4244291377473285\n",
      "Epoch 135, Loss: 0.4238710161998914\n",
      "Epoch 136, Loss: 0.4231825099499314\n",
      "Epoch 137, Loss: 0.42229583730960757\n",
      "Epoch 138, Loss: 0.4215988032133101\n",
      "Epoch 139, Loss: 0.4210644635719107\n",
      "Epoch 140, Loss: 0.4204837322649073\n",
      "Epoch 141, Loss: 0.4197774061931353\n",
      "Epoch 142, Loss: 0.4191916215203999\n",
      "Epoch 143, Loss: 0.4186481942784708\n",
      "Epoch 144, Loss: 0.4180951863081799\n",
      "Epoch 145, Loss: 0.41744595212071567\n",
      "Epoch 146, Loss: 0.41687899980813775\n",
      "Epoch 147, Loss: 0.4163372068440025\n",
      "Epoch 148, Loss: 0.4158107629255498\n",
      "Epoch 149, Loss: 0.4151938475158497\n",
      "Epoch 150, Loss: 0.4145582398371558\n",
      "Epoch 151, Loss: 0.4139676075289887\n",
      "Epoch 152, Loss: 0.4134831423949929\n",
      "Epoch 153, Loss: 0.4130953343542334\n",
      "Epoch 154, Loss: 0.4127697828255059\n",
      "Epoch 155, Loss: 0.4122049302239862\n",
      "Epoch 156, Loss: 0.41138781977487465\n",
      "Epoch 157, Loss: 0.41082097638809145\n",
      "Epoch 158, Loss: 0.4105827112645451\n",
      "Epoch 159, Loss: 0.41012077178100953\n",
      "Epoch 160, Loss: 0.4093601493471394\n",
      "Epoch 161, Loss: 0.40891125962742075\n",
      "Epoch 162, Loss: 0.40865605610469996\n",
      "Epoch 163, Loss: 0.40812682392361244\n",
      "Epoch 164, Loss: 0.4074160274623622\n",
      "Epoch 165, Loss: 0.4069180497747463\n",
      "Epoch 166, Loss: 0.40653554344681125\n",
      "Epoch 167, Loss: 0.4061788533340074\n",
      "Epoch 168, Loss: 0.40560631008026954\n",
      "Epoch 169, Loss: 0.4049694897791878\n",
      "Epoch 170, Loss: 0.40438233730021234\n",
      "Epoch 171, Loss: 0.4038669862238446\n",
      "Epoch 172, Loss: 0.40353941796496345\n",
      "Epoch 173, Loss: 0.40330904374532617\n",
      "Epoch 174, Loss: 0.403465318821371\n",
      "Epoch 175, Loss: 0.40320628034321243\n",
      "Epoch 176, Loss: 0.4019866024864106\n",
      "Epoch 177, Loss: 0.40113944764834286\n",
      "Epoch 178, Loss: 0.4011234926579994\n",
      "Epoch 179, Loss: 0.40087425981958213\n",
      "Epoch 180, Loss: 0.39994211895709614\n",
      "Epoch 181, Loss: 0.39955181553752406\n",
      "Epoch 182, Loss: 0.3995373635836909\n",
      "Epoch 183, Loss: 0.39892686449181647\n",
      "Epoch 184, Loss: 0.3982525938731443\n",
      "Epoch 185, Loss: 0.39771967159166566\n",
      "Epoch 186, Loss: 0.3974654926160874\n",
      "Epoch 187, Loss: 0.3972168531458838\n",
      "Epoch 188, Loss: 0.39658846686729876\n",
      "Epoch 189, Loss: 0.3960978874577327\n",
      "Epoch 190, Loss: 0.3956778643454223\n",
      "Epoch 191, Loss: 0.3953098131171426\n",
      "Epoch 192, Loss: 0.39511661727494535\n",
      "Epoch 193, Loss: 0.3948568756614938\n",
      "Epoch 194, Loss: 0.3947506096492744\n",
      "Epoch 195, Loss: 0.39471973033883256\n",
      "Epoch 196, Loss: 0.39432546706561666\n",
      "Epoch 197, Loss: 0.3934969611226275\n",
      "Epoch 198, Loss: 0.39295180646343036\n",
      "Epoch 199, Loss: 0.3925384767163363\n",
      "Epoch 200, Loss: 0.39240766022211504\n",
      "Epoch 201, Loss: 0.3925489727981999\n",
      "Epoch 202, Loss: 0.39233730768150465\n",
      "Epoch 203, Loss: 0.3919354392477932\n",
      "Epoch 204, Loss: 0.39113164470486467\n",
      "Epoch 205, Loss: 0.39052065409305775\n",
      "Epoch 206, Loss: 0.39040460090896556\n",
      "Epoch 207, Loss: 0.39041624213039205\n",
      "Epoch 208, Loss: 0.39025132425976733\n",
      "Epoch 209, Loss: 0.38987518825936185\n",
      "Epoch 210, Loss: 0.3894632994337656\n",
      "Epoch 211, Loss: 0.38893354415904735\n",
      "Epoch 212, Loss: 0.38856571990653693\n",
      "Epoch 213, Loss: 0.3885132930953345\n",
      "Epoch 214, Loss: 0.3883961989035074\n",
      "Epoch 215, Loss: 0.388397867815616\n",
      "Epoch 216, Loss: 0.3887145627603812\n",
      "Epoch 217, Loss: 0.388791415746775\n",
      "Epoch 218, Loss: 0.3876922761043919\n",
      "Epoch 219, Loss: 0.3872893199093729\n",
      "Epoch 220, Loss: 0.38700330264508287\n",
      "Epoch 221, Loss: 0.3868433048533242\n",
      "Epoch 222, Loss: 0.38705701194776515\n",
      "Epoch 223, Loss: 0.3862561821365661\n",
      "Epoch 224, Loss: 0.3859116966486566\n",
      "Epoch 225, Loss: 0.3858113287273446\n",
      "Epoch 226, Loss: 0.3852511020263416\n",
      "Epoch 227, Loss: 0.38511192886967416\n",
      "Epoch 228, Loss: 0.38504738342699885\n",
      "Epoch 229, Loss: 0.3845252239711509\n",
      "Epoch 230, Loss: 0.3843758831169094\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2472174284982355\n",
      "Test R^2 score: 0.3377325520607548\n",
      "Num of epochs: 231\n",
      "Epoch 1, Loss: 0.5707278633369686\n",
      "Epoch 2, Loss: 0.5693059425893494\n",
      "Epoch 3, Loss: 0.5679844934099706\n",
      "Epoch 4, Loss: 0.5667374004600773\n",
      "Epoch 5, Loss: 0.565584652341548\n",
      "Epoch 6, Loss: 0.5645348512823437\n",
      "Epoch 7, Loss: 0.563541904409456\n",
      "Epoch 8, Loss: 0.5625975047480295\n",
      "Epoch 9, Loss: 0.5617249765700946\n",
      "Epoch 10, Loss: 0.5609277368402512\n",
      "Epoch 11, Loss: 0.560211480050159\n",
      "Epoch 12, Loss: 0.5595734015307953\n",
      "Epoch 13, Loss: 0.5590125161477504\n",
      "Epoch 14, Loss: 0.5585296167223744\n",
      "Epoch 15, Loss: 0.5581241047201633\n",
      "Epoch 16, Loss: 0.55780125133809\n",
      "Epoch 17, Loss: 0.5575260816126816\n",
      "Epoch 18, Loss: 0.5572888264331161\n",
      "Epoch 19, Loss: 0.5570826866509453\n",
      "Epoch 20, Loss: 0.5569008469925021\n",
      "Epoch 21, Loss: 0.5567448033337389\n",
      "Epoch 22, Loss: 0.5566034940415294\n",
      "Epoch 23, Loss: 0.556477171339682\n",
      "Epoch 24, Loss: 0.5563739606341508\n",
      "Epoch 25, Loss: 0.55628198145963\n",
      "Epoch 26, Loss: 0.5561985870775468\n",
      "Epoch 27, Loss: 0.5561213698231151\n",
      "Epoch 28, Loss: 0.5560495283224477\n",
      "Epoch 29, Loss: 0.5559866828455673\n",
      "Epoch 30, Loss: 0.5559258405846929\n",
      "Epoch 31, Loss: 0.5558625790147799\n",
      "Epoch 32, Loss: 0.5557919373555816\n",
      "Epoch 33, Loss: 0.5557081476566718\n",
      "Epoch 34, Loss: 0.5556075028795852\n",
      "Epoch 35, Loss: 0.5554912546484058\n",
      "Epoch 36, Loss: 0.5553497068856186\n",
      "Epoch 37, Loss: 0.555171191516112\n",
      "Epoch 38, Loss: 0.554946892491408\n",
      "Epoch 39, Loss: 0.5546626770482793\n",
      "Epoch 40, Loss: 0.5542983718432485\n",
      "Epoch 41, Loss: 0.5538282051576052\n",
      "Epoch 42, Loss: 0.553233430223862\n",
      "Epoch 43, Loss: 0.5524975704122435\n",
      "Epoch 44, Loss: 0.5516091205464617\n",
      "Epoch 45, Loss: 0.5505378131058418\n",
      "Epoch 46, Loss: 0.5492223498035171\n",
      "Epoch 47, Loss: 0.5476134083489095\n",
      "Epoch 48, Loss: 0.5455862937385847\n",
      "Epoch 49, Loss: 0.5430651791796569\n",
      "Epoch 50, Loss: 0.5399777755314156\n",
      "Epoch 51, Loss: 0.5363314734769066\n",
      "Epoch 52, Loss: 0.5322489602511935\n",
      "Epoch 53, Loss: 0.5278832960332777\n",
      "Epoch 54, Loss: 0.5234780651714572\n",
      "Epoch 55, Loss: 0.519548114703659\n",
      "Epoch 56, Loss: 0.516416520147881\n",
      "Epoch 57, Loss: 0.5136648837581952\n",
      "Epoch 58, Loss: 0.5102193574297227\n",
      "Epoch 59, Loss: 0.5060367641418276\n",
      "Epoch 60, Loss: 0.5019528875090634\n",
      "Epoch 61, Loss: 0.4988026438443018\n",
      "Epoch 62, Loss: 0.4962722277047272\n",
      "Epoch 63, Loss: 0.4933897351900434\n",
      "Epoch 64, Loss: 0.4896321644340415\n",
      "Epoch 65, Loss: 0.48544734263052775\n",
      "Epoch 66, Loss: 0.48156690319506373\n",
      "Epoch 67, Loss: 0.47840958023581687\n",
      "Epoch 68, Loss: 0.4758725409157386\n",
      "Epoch 69, Loss: 0.4730903271627449\n",
      "Epoch 70, Loss: 0.4701134244532869\n",
      "Epoch 71, Loss: 0.467718897688172\n",
      "Epoch 72, Loss: 0.46566486764010556\n",
      "Epoch 73, Loss: 0.4633678599770447\n",
      "Epoch 74, Loss: 0.4612722151402364\n",
      "Epoch 75, Loss: 0.4598730047773175\n",
      "Epoch 76, Loss: 0.4587750870811883\n",
      "Epoch 77, Loss: 0.45802446997960455\n",
      "Epoch 78, Loss: 0.4575556004981953\n",
      "Epoch 79, Loss: 0.4567497560284344\n",
      "Epoch 80, Loss: 0.4562559153552213\n",
      "Epoch 81, Loss: 0.45557147613026666\n",
      "Epoch 82, Loss: 0.45471622336989076\n",
      "Epoch 83, Loss: 0.45356060334032866\n",
      "Epoch 84, Loss: 0.4523610712928561\n",
      "Epoch 85, Loss: 0.4512742326892333\n",
      "Epoch 86, Loss: 0.4500453144675923\n",
      "Epoch 87, Loss: 0.44911959009816715\n",
      "Epoch 88, Loss: 0.4481321710946496\n",
      "Epoch 89, Loss: 0.4473644963555862\n",
      "Epoch 90, Loss: 0.44643354685599385\n",
      "Epoch 91, Loss: 0.44559887829550365\n",
      "Epoch 92, Loss: 0.44471922052929624\n",
      "Epoch 93, Loss: 0.4439939251593681\n",
      "Epoch 94, Loss: 0.44316130259408065\n",
      "Epoch 95, Loss: 0.44248398724910126\n",
      "Epoch 96, Loss: 0.44155778224986825\n",
      "Epoch 97, Loss: 0.44074327761694376\n",
      "Epoch 98, Loss: 0.4398281277580631\n",
      "Epoch 99, Loss: 0.43887589585645526\n",
      "Epoch 100, Loss: 0.4381552795688892\n",
      "Epoch 101, Loss: 0.43734798174490863\n",
      "Epoch 102, Loss: 0.4364598033701222\n",
      "Epoch 103, Loss: 0.43569656331561096\n",
      "Epoch 104, Loss: 0.4349371915175633\n",
      "Epoch 105, Loss: 0.43410945844304494\n",
      "Epoch 106, Loss: 0.4333454142622647\n",
      "Epoch 107, Loss: 0.43265181977610007\n",
      "Epoch 108, Loss: 0.43199326277486144\n",
      "Epoch 109, Loss: 0.43133050471227874\n",
      "Epoch 110, Loss: 0.4307198866736669\n",
      "Epoch 111, Loss: 0.43006784771550755\n",
      "Epoch 112, Loss: 0.4293099044752445\n",
      "Epoch 113, Loss: 0.42853599924145697\n",
      "Epoch 114, Loss: 0.4278500892504436\n",
      "Epoch 115, Loss: 0.4272596084637056\n",
      "Epoch 116, Loss: 0.42669064410023383\n",
      "Epoch 117, Loss: 0.4261153773717717\n",
      "Epoch 118, Loss: 0.4254320445007259\n",
      "Epoch 119, Loss: 0.42469566963315375\n",
      "Epoch 120, Loss: 0.42398910278023666\n",
      "Epoch 121, Loss: 0.42334547556086677\n",
      "Epoch 122, Loss: 0.42276981611973335\n",
      "Epoch 123, Loss: 0.4222929438418155\n",
      "Epoch 124, Loss: 0.42195407691456904\n",
      "Epoch 125, Loss: 0.4217691465315656\n",
      "Epoch 126, Loss: 0.42144251660649923\n",
      "Epoch 127, Loss: 0.42018768414265384\n",
      "Epoch 128, Loss: 0.41929576238914956\n",
      "Epoch 129, Loss: 0.4192917109754806\n",
      "Epoch 130, Loss: 0.4188403195863495\n",
      "Epoch 131, Loss: 0.4178301144569634\n",
      "Epoch 132, Loss: 0.4173178908357107\n",
      "Epoch 133, Loss: 0.41717162727135143\n",
      "Epoch 134, Loss: 0.41647376323713015\n",
      "Epoch 135, Loss: 0.41568271766817266\n",
      "Epoch 136, Loss: 0.4152726895875774\n",
      "Epoch 137, Loss: 0.4149736061090707\n",
      "Epoch 138, Loss: 0.4143477482990128\n",
      "Epoch 139, Loss: 0.41361163441865667\n",
      "Epoch 140, Loss: 0.413119934703113\n",
      "Epoch 141, Loss: 0.4128236050379088\n",
      "Epoch 142, Loss: 0.41240592880912913\n",
      "Epoch 143, Loss: 0.411804321343322\n",
      "Epoch 144, Loss: 0.4111737482346083\n",
      "Epoch 145, Loss: 0.4107421504958023\n",
      "Epoch 146, Loss: 0.41043077999705513\n",
      "Epoch 147, Loss: 0.41020195116018915\n",
      "Epoch 148, Loss: 0.40967971730350794\n",
      "Epoch 149, Loss: 0.40899541160462705\n",
      "Epoch 150, Loss: 0.40832172842792047\n",
      "Epoch 151, Loss: 0.4077707400809662\n",
      "Epoch 152, Loss: 0.40738213949745034\n",
      "Epoch 153, Loss: 0.4071538297619474\n",
      "Epoch 154, Loss: 0.40708346334017365\n",
      "Epoch 155, Loss: 0.40721840244231833\n",
      "Epoch 156, Loss: 0.40704738782642674\n",
      "Epoch 157, Loss: 0.406038265804469\n",
      "Epoch 158, Loss: 0.40482054993949196\n",
      "Epoch 159, Loss: 0.40470093885222835\n",
      "Epoch 160, Loss: 0.40491488118565405\n",
      "Epoch 161, Loss: 0.40438016319221426\n",
      "Epoch 162, Loss: 0.40329596420574826\n",
      "Epoch 163, Loss: 0.4028106313858904\n",
      "Epoch 164, Loss: 0.4028880317372259\n",
      "Epoch 165, Loss: 0.40278308917888056\n",
      "Epoch 166, Loss: 0.4020775775629227\n",
      "Epoch 167, Loss: 0.4012304848236109\n",
      "Epoch 168, Loss: 0.4008361570585299\n",
      "Epoch 169, Loss: 0.40079647057615364\n",
      "Epoch 170, Loss: 0.40086193722530744\n",
      "Epoch 171, Loss: 0.4005398914017789\n",
      "Epoch 172, Loss: 0.3997307713269413\n",
      "Epoch 173, Loss: 0.39889063032434846\n",
      "Epoch 174, Loss: 0.39844583988811133\n",
      "Epoch 175, Loss: 0.39825468918361945\n",
      "Epoch 176, Loss: 0.39821564350654254\n",
      "Epoch 177, Loss: 0.3980797863532667\n",
      "Epoch 178, Loss: 0.39763187790923904\n",
      "Epoch 179, Loss: 0.3969529112988148\n",
      "Epoch 180, Loss: 0.3961767497183101\n",
      "Epoch 181, Loss: 0.39557616973537174\n",
      "Epoch 182, Loss: 0.39513703851242366\n",
      "Epoch 183, Loss: 0.3949466633398463\n",
      "Epoch 184, Loss: 0.39502056861995855\n",
      "Epoch 185, Loss: 0.3958238822243725\n",
      "Epoch 186, Loss: 0.3964632526653116\n",
      "Epoch 187, Loss: 0.3952627293915377\n",
      "Epoch 188, Loss: 0.3927855821246614\n",
      "Epoch 189, Loss: 0.3924447017943854\n",
      "Epoch 190, Loss: 0.39381538256988885\n",
      "Epoch 191, Loss: 0.3933846269550206\n",
      "Epoch 192, Loss: 0.39104252435952236\n",
      "Epoch 193, Loss: 0.39022948268691376\n",
      "Epoch 194, Loss: 0.39130790144895045\n",
      "Epoch 195, Loss: 0.39138137068264833\n",
      "Epoch 196, Loss: 0.390070101477635\n",
      "Epoch 197, Loss: 0.3881295604407172\n",
      "Epoch 198, Loss: 0.38768845174950267\n",
      "Epoch 199, Loss: 0.3880785530052032\n",
      "Epoch 200, Loss: 0.38810779143314106\n",
      "Epoch 201, Loss: 0.38768433908455857\n",
      "Epoch 202, Loss: 0.386135046127103\n",
      "Epoch 203, Loss: 0.38498290457484\n",
      "Epoch 204, Loss: 0.38438830779074074\n",
      "Epoch 205, Loss: 0.3844102874313109\n",
      "Epoch 206, Loss: 0.3850024119214888\n",
      "Epoch 207, Loss: 0.38637315354635704\n",
      "Epoch 208, Loss: 0.3870613815165799\n",
      "Epoch 209, Loss: 0.3851693837864929\n",
      "Epoch 210, Loss: 0.3820393403489648\n",
      "Epoch 211, Loss: 0.3813531853229838\n",
      "Epoch 212, Loss: 0.3837444677482226\n",
      "Epoch 213, Loss: 0.3848025309101749\n",
      "Epoch 214, Loss: 0.38173369773051125\n",
      "Epoch 215, Loss: 0.3793207830875133\n",
      "Epoch 216, Loss: 0.37998778552577295\n",
      "Epoch 217, Loss: 0.3813592613496063\n",
      "Epoch 218, Loss: 0.37948012399077136\n",
      "Epoch 219, Loss: 0.3777197123919475\n",
      "Epoch 220, Loss: 0.3771505876318844\n",
      "Epoch 221, Loss: 0.3775593522762639\n",
      "Epoch 222, Loss: 0.3795162678223545\n",
      "Epoch 223, Loss: 0.3808106220048169\n",
      "Epoch 224, Loss: 0.3792829901906851\n",
      "Epoch 225, Loss: 0.37561108549118866\n",
      "Epoch 226, Loss: 0.3747171885267244\n",
      "Epoch 227, Loss: 0.37590424473809825\n",
      "Epoch 228, Loss: 0.37624999173059803\n",
      "Epoch 229, Loss: 0.37551080167424494\n",
      "Epoch 230, Loss: 0.3742850163348231\n",
      "Epoch 231, Loss: 0.3730520078295953\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.23916333092910644\n",
      "Test R^2 score: 0.38191294363558187\n",
      "Num of epochs: 232\n",
      "Epoch 1, Loss: 0.5568746777414745\n",
      "Epoch 2, Loss: 0.5566058499365678\n",
      "Epoch 3, Loss: 0.5564033671912071\n",
      "Epoch 4, Loss: 0.5562642213525054\n",
      "Epoch 5, Loss: 0.5561838249962181\n",
      "Epoch 6, Loss: 0.5561505485954483\n",
      "Epoch 7, Loss: 0.5561503074548433\n",
      "Epoch 8, Loss: 0.556165499108773\n",
      "Epoch 9, Loss: 0.5561777968104142\n",
      "Epoch 10, Loss: 0.556176483996842\n",
      "Epoch 11, Loss: 0.5561527188561893\n",
      "Epoch 12, Loss: 0.5561040065212899\n",
      "Epoch 13, Loss: 0.5560313320045152\n",
      "Epoch 14, Loss: 0.5559373126745311\n",
      "Epoch 15, Loss: 0.5558233585873387\n",
      "Epoch 16, Loss: 0.5556880898803422\n",
      "Epoch 17, Loss: 0.5555277625390379\n",
      "Epoch 18, Loss: 0.5553431866635282\n",
      "Epoch 19, Loss: 0.5551391965274416\n",
      "Epoch 20, Loss: 0.5548958722799564\n",
      "Epoch 21, Loss: 0.5545988952360213\n",
      "Epoch 22, Loss: 0.554217018144094\n",
      "Epoch 23, Loss: 0.553743929948109\n",
      "Epoch 24, Loss: 0.5531540211106323\n",
      "Epoch 25, Loss: 0.5524288182125057\n",
      "Epoch 26, Loss: 0.5515585210294631\n",
      "Epoch 27, Loss: 0.5505505071731045\n",
      "Epoch 28, Loss: 0.5493693279628864\n",
      "Epoch 29, Loss: 0.5478823240079131\n",
      "Epoch 30, Loss: 0.5460888525398045\n",
      "Epoch 31, Loss: 0.5439606258626973\n",
      "Epoch 32, Loss: 0.5414362350021076\n",
      "Epoch 33, Loss: 0.53835443627574\n",
      "Epoch 34, Loss: 0.5345840457912503\n",
      "Epoch 35, Loss: 0.5301074476009978\n",
      "Epoch 36, Loss: 0.5248950478689902\n",
      "Epoch 37, Loss: 0.5190537918986371\n",
      "Epoch 38, Loss: 0.5128856487279714\n",
      "Epoch 39, Loss: 0.5070403464137622\n",
      "Epoch 40, Loss: 0.5032552017534329\n",
      "Epoch 41, Loss: 0.503097595037127\n",
      "Epoch 42, Loss: 0.5029962588203344\n",
      "Epoch 43, Loss: 0.49954436821010445\n",
      "Epoch 44, Loss: 0.49484218205696506\n",
      "Epoch 45, Loss: 0.49132516795472725\n",
      "Epoch 46, Loss: 0.48957173523117475\n",
      "Epoch 47, Loss: 0.48892994324331374\n",
      "Epoch 48, Loss: 0.48819828091478523\n",
      "Epoch 49, Loss: 0.486647045554287\n",
      "Epoch 50, Loss: 0.4843079459015266\n",
      "Epoch 51, Loss: 0.48164481155791156\n",
      "Epoch 52, Loss: 0.47927753748354085\n",
      "Epoch 53, Loss: 0.4777051640685612\n",
      "Epoch 54, Loss: 0.4767972336801664\n",
      "Epoch 55, Loss: 0.4758618786022141\n",
      "Epoch 56, Loss: 0.4743414542558991\n",
      "Epoch 57, Loss: 0.47240720445713535\n",
      "Epoch 58, Loss: 0.4706566815395516\n",
      "Epoch 59, Loss: 0.46936757413270125\n",
      "Epoch 60, Loss: 0.4684236821178223\n",
      "Epoch 61, Loss: 0.4675025553811964\n",
      "Epoch 62, Loss: 0.46639371564370735\n",
      "Epoch 63, Loss: 0.46516540362007686\n",
      "Epoch 64, Loss: 0.46407013318498314\n",
      "Epoch 65, Loss: 0.4631818667980206\n",
      "Epoch 66, Loss: 0.4623963658753064\n",
      "Epoch 67, Loss: 0.4614609639313105\n",
      "Epoch 68, Loss: 0.46036341849764256\n",
      "Epoch 69, Loss: 0.4594150227349425\n",
      "Epoch 70, Loss: 0.45868889245750893\n",
      "Epoch 71, Loss: 0.45794278722318943\n",
      "Epoch 72, Loss: 0.4570252181739218\n",
      "Epoch 73, Loss: 0.4561159799300195\n",
      "Epoch 74, Loss: 0.45544778765799515\n",
      "Epoch 75, Loss: 0.4548471544112787\n",
      "Epoch 76, Loss: 0.45405209179558015\n",
      "Epoch 77, Loss: 0.4533173383083511\n",
      "Epoch 78, Loss: 0.4527584434872047\n",
      "Epoch 79, Loss: 0.4520639295266648\n",
      "Epoch 80, Loss: 0.45125352855475737\n",
      "Epoch 81, Loss: 0.450623017411229\n",
      "Epoch 82, Loss: 0.449999801980081\n",
      "Epoch 83, Loss: 0.44920755455330075\n",
      "Epoch 84, Loss: 0.4485477245587337\n",
      "Epoch 85, Loss: 0.44788515919015676\n",
      "Epoch 86, Loss: 0.4470994632361511\n",
      "Epoch 87, Loss: 0.4464284733363453\n",
      "Epoch 88, Loss: 0.44565727874035804\n",
      "Epoch 89, Loss: 0.44486863619054323\n",
      "Epoch 90, Loss: 0.444132009806823\n",
      "Epoch 91, Loss: 0.4433022684970763\n",
      "Epoch 92, Loss: 0.44252808398228183\n",
      "Epoch 93, Loss: 0.4416966622291477\n",
      "Epoch 94, Loss: 0.440845960987258\n",
      "Epoch 95, Loss: 0.4400271079263522\n",
      "Epoch 96, Loss: 0.43917561563872226\n",
      "Epoch 97, Loss: 0.43835761956947966\n",
      "Epoch 98, Loss: 0.43753433092840477\n",
      "Epoch 99, Loss: 0.4367623752648731\n",
      "Epoch 100, Loss: 0.4359939401931664\n",
      "Epoch 101, Loss: 0.4352476349349515\n",
      "Epoch 102, Loss: 0.43454414888980597\n",
      "Epoch 103, Loss: 0.43385463461177115\n",
      "Epoch 104, Loss: 0.4332020683034903\n",
      "Epoch 105, Loss: 0.43253466850315064\n",
      "Epoch 106, Loss: 0.43188133259945793\n",
      "Epoch 107, Loss: 0.4312211496958284\n",
      "Epoch 108, Loss: 0.4305653880733046\n",
      "Epoch 109, Loss: 0.4299254365524291\n",
      "Epoch 110, Loss: 0.4292688931621326\n",
      "Epoch 111, Loss: 0.428612126322555\n",
      "Epoch 112, Loss: 0.4279580946477096\n",
      "Epoch 113, Loss: 0.4272964360686857\n",
      "Epoch 114, Loss: 0.426644770754566\n",
      "Epoch 115, Loss: 0.42598490263038674\n",
      "Epoch 116, Loss: 0.42532147072238297\n",
      "Epoch 117, Loss: 0.4246608446751161\n",
      "Epoch 118, Loss: 0.42401082192749007\n",
      "Epoch 119, Loss: 0.4233606986746516\n",
      "Epoch 120, Loss: 0.4226936062929163\n",
      "Epoch 121, Loss: 0.4220426897280155\n",
      "Epoch 122, Loss: 0.42143065399239565\n",
      "Epoch 123, Loss: 0.4208739554593635\n",
      "Epoch 124, Loss: 0.42029824356803047\n",
      "Epoch 125, Loss: 0.41956079616964975\n",
      "Epoch 126, Loss: 0.4186764367807661\n",
      "Epoch 127, Loss: 0.418006467454331\n",
      "Epoch 128, Loss: 0.41749276483285586\n",
      "Epoch 129, Loss: 0.4168277568155587\n",
      "Epoch 130, Loss: 0.41603450105494727\n",
      "Epoch 131, Loss: 0.41536459329858205\n",
      "Epoch 132, Loss: 0.4148323531659691\n",
      "Epoch 133, Loss: 0.4142790713828816\n",
      "Epoch 134, Loss: 0.4136256666734337\n",
      "Epoch 135, Loss: 0.4128830143020484\n",
      "Epoch 136, Loss: 0.4121861499304421\n",
      "Epoch 137, Loss: 0.4115350527000002\n",
      "Epoch 138, Loss: 0.4109399664917235\n",
      "Epoch 139, Loss: 0.4104188895609084\n",
      "Epoch 140, Loss: 0.40998498883330997\n",
      "Epoch 141, Loss: 0.409495411701604\n",
      "Epoch 142, Loss: 0.4088309174100954\n",
      "Epoch 143, Loss: 0.40798099077226635\n",
      "Epoch 144, Loss: 0.40728901994760697\n",
      "Epoch 145, Loss: 0.4067912530922669\n",
      "Epoch 146, Loss: 0.4063569441661881\n",
      "Epoch 147, Loss: 0.4059459942640375\n",
      "Epoch 148, Loss: 0.4054068655957525\n",
      "Epoch 149, Loss: 0.4047903651879016\n",
      "Epoch 150, Loss: 0.4041265967585614\n",
      "Epoch 151, Loss: 0.403557437528819\n",
      "Epoch 152, Loss: 0.403086245692228\n",
      "Epoch 153, Loss: 0.40271551123173904\n",
      "Epoch 154, Loss: 0.4025274801647091\n",
      "Epoch 155, Loss: 0.4024940506276262\n",
      "Epoch 156, Loss: 0.402252890688489\n",
      "Epoch 157, Loss: 0.4011606766457328\n",
      "Epoch 158, Loss: 0.40020541117387537\n",
      "Epoch 159, Loss: 0.40004372804757793\n",
      "Epoch 160, Loss: 0.4000255129545575\n",
      "Epoch 161, Loss: 0.3994929228813465\n",
      "Epoch 162, Loss: 0.3984780945387109\n",
      "Epoch 163, Loss: 0.39803598780244587\n",
      "Epoch 164, Loss: 0.39802885604369687\n",
      "Epoch 165, Loss: 0.39761418942671173\n",
      "Epoch 166, Loss: 0.3968193443201963\n",
      "Epoch 167, Loss: 0.39621949391310635\n",
      "Epoch 168, Loss: 0.396030579745715\n",
      "Epoch 169, Loss: 0.39592299157035665\n",
      "Epoch 170, Loss: 0.3954710955118823\n",
      "Epoch 171, Loss: 0.394791205849626\n",
      "Epoch 172, Loss: 0.3941496523833687\n",
      "Epoch 173, Loss: 0.39372034112551413\n",
      "Epoch 174, Loss: 0.3934923979353285\n",
      "Epoch 175, Loss: 0.39336939915420577\n",
      "Epoch 176, Loss: 0.39340011931162056\n",
      "Epoch 177, Loss: 0.39304720434828266\n",
      "Epoch 178, Loss: 0.39247530449485424\n",
      "Epoch 179, Loss: 0.3915657921338341\n",
      "Epoch 180, Loss: 0.3909273693927981\n",
      "Epoch 181, Loss: 0.39070941013039856\n",
      "Epoch 182, Loss: 0.39068713647645165\n",
      "Epoch 183, Loss: 0.3905612512068884\n",
      "Epoch 184, Loss: 0.3901218989186972\n",
      "Epoch 185, Loss: 0.3895061873824748\n",
      "Epoch 186, Loss: 0.38880124646671865\n",
      "Epoch 187, Loss: 0.3884276960122349\n",
      "Epoch 188, Loss: 0.38834238703178425\n",
      "Epoch 189, Loss: 0.3882832525190144\n",
      "Epoch 190, Loss: 0.3884214620125736\n",
      "Epoch 191, Loss: 0.3883655049882555\n",
      "Epoch 192, Loss: 0.3877661613856918\n",
      "Epoch 193, Loss: 0.3867442960682233\n",
      "Epoch 194, Loss: 0.3860308375986732\n",
      "Epoch 195, Loss: 0.3857276237732333\n",
      "Epoch 196, Loss: 0.38575978299342295\n",
      "Epoch 197, Loss: 0.38601207707590285\n",
      "Epoch 198, Loss: 0.3859897446888343\n",
      "Epoch 199, Loss: 0.3855310948938894\n",
      "Epoch 200, Loss: 0.3843993752977116\n",
      "Epoch 201, Loss: 0.3837354588627075\n",
      "Epoch 202, Loss: 0.3836035243574043\n",
      "Epoch 203, Loss: 0.38374594332138207\n",
      "Epoch 204, Loss: 0.38377011473185835\n",
      "Epoch 205, Loss: 0.38302715277972205\n",
      "Epoch 206, Loss: 0.38225181546849807\n",
      "Epoch 207, Loss: 0.3818107069806716\n",
      "Epoch 208, Loss: 0.38160579604464506\n",
      "Epoch 209, Loss: 0.3816240898618769\n",
      "Epoch 210, Loss: 0.3815913868497377\n",
      "Epoch 211, Loss: 0.38144820251776373\n",
      "Epoch 212, Loss: 0.38076029735925065\n",
      "Epoch 213, Loss: 0.3802319567234882\n",
      "Epoch 214, Loss: 0.37962868238841785\n",
      "Epoch 215, Loss: 0.37924872975774787\n",
      "Epoch 216, Loss: 0.37917632869664475\n",
      "Epoch 217, Loss: 0.3791874697326678\n",
      "Epoch 218, Loss: 0.3793332162059632\n",
      "Epoch 219, Loss: 0.37952680994281573\n",
      "Epoch 220, Loss: 0.3796342168712179\n",
      "Epoch 221, Loss: 0.37848010137602184\n",
      "Epoch 222, Loss: 0.3774224359203759\n",
      "Epoch 223, Loss: 0.37685450316278496\n",
      "Epoch 224, Loss: 0.37691948300786166\n",
      "Epoch 225, Loss: 0.3773370872525377\n",
      "Epoch 226, Loss: 0.3772331146685609\n",
      "Epoch 227, Loss: 0.376648339898935\n",
      "Epoch 228, Loss: 0.3756849074235383\n",
      "Epoch 229, Loss: 0.37510482991774435\n",
      "Epoch 230, Loss: 0.3748251189308077\n",
      "Epoch 231, Loss: 0.3748829380745502\n",
      "Epoch 232, Loss: 0.3751968423473618\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.24785227855595693\n",
      "Test R^2 score: 0.338444406968685\n",
      "Num of epochs: 233\n",
      "Epoch 1, Loss: 0.5648092446663432\n",
      "Epoch 2, Loss: 0.563802641294936\n",
      "Epoch 3, Loss: 0.5628886469661312\n",
      "Epoch 4, Loss: 0.562013283071984\n",
      "Epoch 5, Loss: 0.5611828110882741\n",
      "Epoch 6, Loss: 0.560401844575516\n",
      "Epoch 7, Loss: 0.5596766079642058\n",
      "Epoch 8, Loss: 0.5590103303333518\n",
      "Epoch 9, Loss: 0.558407946008968\n",
      "Epoch 10, Loss: 0.5578730275202367\n",
      "Epoch 11, Loss: 0.557408549330607\n",
      "Epoch 12, Loss: 0.5570168010448109\n",
      "Epoch 13, Loss: 0.5566999704949913\n",
      "Epoch 14, Loss: 0.5564307101453613\n",
      "Epoch 15, Loss: 0.5562332268661291\n",
      "Epoch 16, Loss: 0.556099665611124\n",
      "Epoch 17, Loss: 0.5560192722609899\n",
      "Epoch 18, Loss: 0.5559758818201516\n",
      "Epoch 19, Loss: 0.5559506071367164\n",
      "Epoch 20, Loss: 0.5559234550035687\n",
      "Epoch 21, Loss: 0.5558786363407687\n",
      "Epoch 22, Loss: 0.5558029028165716\n",
      "Epoch 23, Loss: 0.5556848719878712\n",
      "Epoch 24, Loss: 0.5555176500131112\n",
      "Epoch 25, Loss: 0.5552922296983707\n",
      "Epoch 26, Loss: 0.5549885913174598\n",
      "Epoch 27, Loss: 0.5545817529592296\n",
      "Epoch 28, Loss: 0.5540534949606323\n",
      "Epoch 29, Loss: 0.55340691618201\n",
      "Epoch 30, Loss: 0.5526744419131147\n",
      "Epoch 31, Loss: 0.5518436601408552\n",
      "Epoch 32, Loss: 0.5509054165746803\n",
      "Epoch 33, Loss: 0.5498344996011064\n",
      "Epoch 34, Loss: 0.5485862932211788\n",
      "Epoch 35, Loss: 0.5471186503825615\n",
      "Epoch 36, Loss: 0.5453839820858346\n",
      "Epoch 37, Loss: 0.5433042847975378\n",
      "Epoch 38, Loss: 0.5407797784793543\n",
      "Epoch 39, Loss: 0.5376844899023346\n",
      "Epoch 40, Loss: 0.5339508124228779\n",
      "Epoch 41, Loss: 0.5296373855604741\n",
      "Epoch 42, Loss: 0.5250104074354842\n",
      "Epoch 43, Loss: 0.5205961513884093\n",
      "Epoch 44, Loss: 0.517307657073284\n",
      "Epoch 45, Loss: 0.5155064417624339\n",
      "Epoch 46, Loss: 0.5134037028523544\n",
      "Epoch 47, Loss: 0.509799210768381\n",
      "Epoch 48, Loss: 0.5059919441339532\n",
      "Epoch 49, Loss: 0.5035316198396529\n",
      "Epoch 50, Loss: 0.5023511206766931\n",
      "Epoch 51, Loss: 0.5010639136828445\n",
      "Epoch 52, Loss: 0.49869475766236343\n",
      "Epoch 53, Loss: 0.4957846632346147\n",
      "Epoch 54, Loss: 0.49340743301233353\n",
      "Epoch 55, Loss: 0.4918791092406508\n",
      "Epoch 56, Loss: 0.49014311773178326\n",
      "Epoch 57, Loss: 0.4877958708133611\n",
      "Epoch 58, Loss: 0.48577147343007104\n",
      "Epoch 59, Loss: 0.48458916021284\n",
      "Epoch 60, Loss: 0.4836969243980042\n",
      "Epoch 61, Loss: 0.4823728219858204\n",
      "Epoch 62, Loss: 0.4806203680472532\n",
      "Epoch 63, Loss: 0.47892699951226014\n",
      "Epoch 64, Loss: 0.477488431216197\n",
      "Epoch 65, Loss: 0.4759455893437104\n",
      "Epoch 66, Loss: 0.47423958206296857\n",
      "Epoch 67, Loss: 0.4728673195685357\n",
      "Epoch 68, Loss: 0.47199062105635714\n",
      "Epoch 69, Loss: 0.470820384635214\n",
      "Epoch 70, Loss: 0.46941438321761875\n",
      "Epoch 71, Loss: 0.46832699763208446\n",
      "Epoch 72, Loss: 0.4672223789374464\n",
      "Epoch 73, Loss: 0.4658609848340099\n",
      "Epoch 74, Loss: 0.4648322416531854\n",
      "Epoch 75, Loss: 0.4640037897649921\n",
      "Epoch 76, Loss: 0.46298432508386417\n",
      "Epoch 77, Loss: 0.46226144837437544\n",
      "Epoch 78, Loss: 0.4616102223400307\n",
      "Epoch 79, Loss: 0.4609345743118799\n",
      "Epoch 80, Loss: 0.46034828608904294\n",
      "Epoch 81, Loss: 0.4593071634457802\n",
      "Epoch 82, Loss: 0.45823941749657104\n",
      "Epoch 83, Loss: 0.4573238446928356\n",
      "Epoch 84, Loss: 0.4559790571019203\n",
      "Epoch 85, Loss: 0.45464953103430933\n",
      "Epoch 86, Loss: 0.45355513315997803\n",
      "Epoch 87, Loss: 0.45257577825379364\n",
      "Epoch 88, Loss: 0.4518761690475516\n",
      "Epoch 89, Loss: 0.45116419599859703\n",
      "Epoch 90, Loss: 0.4505987779815771\n",
      "Epoch 91, Loss: 0.4500420530855742\n",
      "Epoch 92, Loss: 0.449512816665439\n",
      "Epoch 93, Loss: 0.44879043726312495\n",
      "Epoch 94, Loss: 0.44812231185404766\n",
      "Epoch 95, Loss: 0.4474675085217165\n",
      "Epoch 96, Loss: 0.44689606303480217\n",
      "Epoch 97, Loss: 0.4463037701276348\n",
      "Epoch 98, Loss: 0.44562922474381983\n",
      "Epoch 99, Loss: 0.4449962530353399\n",
      "Epoch 100, Loss: 0.444380169018863\n",
      "Epoch 101, Loss: 0.4438242890404223\n",
      "Epoch 102, Loss: 0.44322753828252376\n",
      "Epoch 103, Loss: 0.44260690499554917\n",
      "Epoch 104, Loss: 0.44200706102914933\n",
      "Epoch 105, Loss: 0.44137048154412495\n",
      "Epoch 106, Loss: 0.44075555017214824\n",
      "Epoch 107, Loss: 0.44012262843608174\n",
      "Epoch 108, Loss: 0.43948192925891044\n",
      "Epoch 109, Loss: 0.43890820096411737\n",
      "Epoch 110, Loss: 0.4383493761503963\n",
      "Epoch 111, Loss: 0.43776800257615167\n",
      "Epoch 112, Loss: 0.43721884821637863\n",
      "Epoch 113, Loss: 0.43668255050298016\n",
      "Epoch 114, Loss: 0.436118738380412\n",
      "Epoch 115, Loss: 0.43555327269640864\n",
      "Epoch 116, Loss: 0.43502677347288565\n",
      "Epoch 117, Loss: 0.43452381356743836\n",
      "Epoch 118, Loss: 0.4339286953893952\n",
      "Epoch 119, Loss: 0.4332855607102757\n",
      "Epoch 120, Loss: 0.4326199946947491\n",
      "Epoch 121, Loss: 0.43198645016273246\n",
      "Epoch 122, Loss: 0.43141194150182965\n",
      "Epoch 123, Loss: 0.4308978633342504\n",
      "Epoch 124, Loss: 0.4304646832781156\n",
      "Epoch 125, Loss: 0.4299452788720487\n",
      "Epoch 126, Loss: 0.42937904036729574\n",
      "Epoch 127, Loss: 0.428459354346864\n",
      "Epoch 128, Loss: 0.42772559588058195\n",
      "Epoch 129, Loss: 0.42726701957682905\n",
      "Epoch 130, Loss: 0.42678722917444095\n",
      "Epoch 131, Loss: 0.4260854072159725\n",
      "Epoch 132, Loss: 0.4250921745481422\n",
      "Epoch 133, Loss: 0.4243021305259549\n",
      "Epoch 134, Loss: 0.42382353679089607\n",
      "Epoch 135, Loss: 0.4232874643201255\n",
      "Epoch 136, Loss: 0.42266455693287497\n",
      "Epoch 137, Loss: 0.42201191834934837\n",
      "Epoch 138, Loss: 0.42149919089650323\n",
      "Epoch 139, Loss: 0.4210819985867883\n",
      "Epoch 140, Loss: 0.4206495677750803\n",
      "Epoch 141, Loss: 0.42020775578234876\n",
      "Epoch 142, Loss: 0.419521655607001\n",
      "Epoch 143, Loss: 0.4188419917108928\n",
      "Epoch 144, Loss: 0.4183230458219353\n",
      "Epoch 145, Loss: 0.4179591953219388\n",
      "Epoch 146, Loss: 0.4176827459354461\n",
      "Epoch 147, Loss: 0.41735620266564644\n",
      "Epoch 148, Loss: 0.4169620619172233\n",
      "Epoch 149, Loss: 0.4161560466342196\n",
      "Epoch 150, Loss: 0.41541431292737835\n",
      "Epoch 151, Loss: 0.41499217048980647\n",
      "Epoch 152, Loss: 0.4147809112140482\n",
      "Epoch 153, Loss: 0.41450426539399526\n",
      "Epoch 154, Loss: 0.4138861766597598\n",
      "Epoch 155, Loss: 0.41314886168505804\n",
      "Epoch 156, Loss: 0.4125963199751845\n",
      "Epoch 157, Loss: 0.41224852468112105\n",
      "Epoch 158, Loss: 0.4120030198102296\n",
      "Epoch 159, Loss: 0.41168688410111626\n",
      "Epoch 160, Loss: 0.41130370441626285\n",
      "Epoch 161, Loss: 0.4106636541860389\n",
      "Epoch 162, Loss: 0.40998800550919473\n",
      "Epoch 163, Loss: 0.40940946987135945\n",
      "Epoch 164, Loss: 0.4090093107737637\n",
      "Epoch 165, Loss: 0.4087399507448003\n",
      "Epoch 166, Loss: 0.40854526399853647\n",
      "Epoch 167, Loss: 0.4084451861194635\n",
      "Epoch 168, Loss: 0.4081634611727162\n",
      "Epoch 169, Loss: 0.40748525768362737\n",
      "Epoch 170, Loss: 0.40648704728819496\n",
      "Epoch 171, Loss: 0.4057959623611115\n",
      "Epoch 172, Loss: 0.40557886587211145\n",
      "Epoch 173, Loss: 0.40543329234532444\n",
      "Epoch 174, Loss: 0.4050942633861822\n",
      "Epoch 175, Loss: 0.40441091283667696\n",
      "Epoch 176, Loss: 0.4036643198353541\n",
      "Epoch 177, Loss: 0.40306221598743686\n",
      "Epoch 178, Loss: 0.40262192304111116\n",
      "Epoch 179, Loss: 0.4023364538623764\n",
      "Epoch 180, Loss: 0.40231312014828435\n",
      "Epoch 181, Loss: 0.402868632185485\n",
      "Epoch 182, Loss: 0.40362166260573784\n",
      "Epoch 183, Loss: 0.40312853449373526\n",
      "Epoch 184, Loss: 0.400638150253737\n",
      "Epoch 185, Loss: 0.40009132922148655\n",
      "Epoch 186, Loss: 0.40127894784364876\n",
      "Epoch 187, Loss: 0.4002442255098002\n",
      "Epoch 188, Loss: 0.398704701006089\n",
      "Epoch 189, Loss: 0.399466140448483\n",
      "Epoch 190, Loss: 0.3993882261841233\n",
      "Epoch 191, Loss: 0.39788177480391723\n",
      "Epoch 192, Loss: 0.39769724726358535\n",
      "Epoch 193, Loss: 0.3982774936802689\n",
      "Epoch 194, Loss: 0.3973186903839299\n",
      "Epoch 195, Loss: 0.3963557443407752\n",
      "Epoch 196, Loss: 0.3966637379507462\n",
      "Epoch 197, Loss: 0.3966592863275173\n",
      "Epoch 198, Loss: 0.3957315259647086\n",
      "Epoch 199, Loss: 0.39509819388641765\n",
      "Epoch 200, Loss: 0.3954210727849474\n",
      "Epoch 201, Loss: 0.3951842503339398\n",
      "Epoch 202, Loss: 0.3943818631005746\n",
      "Epoch 203, Loss: 0.39393512143375203\n",
      "Epoch 204, Loss: 0.39405660121172215\n",
      "Epoch 205, Loss: 0.39402999762040264\n",
      "Epoch 206, Loss: 0.39335543981892634\n",
      "Epoch 207, Loss: 0.39280604867789054\n",
      "Epoch 208, Loss: 0.3924985396910794\n",
      "Epoch 209, Loss: 0.39247735471455863\n",
      "Epoch 210, Loss: 0.392431943636297\n",
      "Epoch 211, Loss: 0.3920933021402389\n",
      "Epoch 212, Loss: 0.3917421578472569\n",
      "Epoch 213, Loss: 0.3912486057744154\n",
      "Epoch 214, Loss: 0.3908116085640791\n",
      "Epoch 215, Loss: 0.3905927644780205\n",
      "Epoch 216, Loss: 0.39032310263753406\n",
      "Epoch 217, Loss: 0.38997898087958255\n",
      "Epoch 218, Loss: 0.38973000038468214\n",
      "Epoch 219, Loss: 0.38963206933235034\n",
      "Epoch 220, Loss: 0.39012690258448335\n",
      "Epoch 221, Loss: 0.3920129912082398\n",
      "Epoch 222, Loss: 0.3946561521221477\n",
      "Epoch 223, Loss: 0.3941031484489733\n",
      "Epoch 224, Loss: 0.389606406638658\n",
      "Epoch 225, Loss: 0.388916686129905\n",
      "Epoch 226, Loss: 0.39146953840123816\n",
      "Epoch 227, Loss: 0.38954046373912293\n",
      "Epoch 228, Loss: 0.38798986435093624\n",
      "Epoch 229, Loss: 0.38921712843634887\n",
      "Epoch 230, Loss: 0.38886447907466914\n",
      "Epoch 231, Loss: 0.3869910774434515\n",
      "Epoch 232, Loss: 0.3884683775962534\n",
      "Epoch 233, Loss: 0.3880412482538585\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.24622471540759344\n",
      "Test R^2 score: 0.3473407474707202\n",
      "Num of epochs: 234\n",
      "Epoch 1, Loss: 0.5637145176313145\n",
      "Epoch 2, Loss: 0.5627530641324083\n",
      "Epoch 3, Loss: 0.5618586062372477\n",
      "Epoch 4, Loss: 0.561033111117016\n",
      "Epoch 5, Loss: 0.5602794368113916\n",
      "Epoch 6, Loss: 0.5595981930482689\n",
      "Epoch 7, Loss: 0.5589902311027651\n",
      "Epoch 8, Loss: 0.5584580583422525\n",
      "Epoch 9, Loss: 0.5579994347904447\n",
      "Epoch 10, Loss: 0.5576134195551193\n",
      "Epoch 11, Loss: 0.5573018747505923\n",
      "Epoch 12, Loss: 0.5570489556921406\n",
      "Epoch 13, Loss: 0.5568450284742295\n",
      "Epoch 14, Loss: 0.5566841242340854\n",
      "Epoch 15, Loss: 0.5565602830160495\n",
      "Epoch 16, Loss: 0.5564679597454937\n",
      "Epoch 17, Loss: 0.5564019210034274\n",
      "Epoch 18, Loss: 0.5563570873176932\n",
      "Epoch 19, Loss: 0.5563283479355562\n",
      "Epoch 20, Loss: 0.5563115268069194\n",
      "Epoch 21, Loss: 0.5563026874749554\n",
      "Epoch 22, Loss: 0.5562981873974575\n",
      "Epoch 23, Loss: 0.5562944373050682\n",
      "Epoch 24, Loss: 0.5562888121190835\n",
      "Epoch 25, Loss: 0.55627954383144\n",
      "Epoch 26, Loss: 0.5562659625645492\n",
      "Epoch 27, Loss: 0.5562486037761867\n",
      "Epoch 28, Loss: 0.5562257525699079\n",
      "Epoch 29, Loss: 0.5561950774349109\n",
      "Epoch 30, Loss: 0.5561584257977219\n",
      "Epoch 31, Loss: 0.5561110805245127\n",
      "Epoch 32, Loss: 0.55605242252726\n",
      "Epoch 33, Loss: 0.555983841901403\n",
      "Epoch 34, Loss: 0.5559057370526109\n",
      "Epoch 35, Loss: 0.5558217768442402\n",
      "Epoch 36, Loss: 0.5557304302464581\n",
      "Epoch 37, Loss: 0.5556320154371511\n",
      "Epoch 38, Loss: 0.5555194472128672\n",
      "Epoch 39, Loss: 0.5553886119694972\n",
      "Epoch 40, Loss: 0.555228224989052\n",
      "Epoch 41, Loss: 0.5550248637944828\n",
      "Epoch 42, Loss: 0.5547635469557545\n",
      "Epoch 43, Loss: 0.5544432249955116\n",
      "Epoch 44, Loss: 0.5540662160577748\n",
      "Epoch 45, Loss: 0.5536485532572394\n",
      "Epoch 46, Loss: 0.5531643923509367\n",
      "Epoch 47, Loss: 0.552573595151128\n",
      "Epoch 48, Loss: 0.5518560811533691\n",
      "Epoch 49, Loss: 0.5509770633731744\n",
      "Epoch 50, Loss: 0.5498987527336103\n",
      "Epoch 51, Loss: 0.548625487797786\n",
      "Epoch 52, Loss: 0.5470988224313202\n",
      "Epoch 53, Loss: 0.5452032149145926\n",
      "Epoch 54, Loss: 0.5429627946485877\n",
      "Epoch 55, Loss: 0.5404913114066404\n",
      "Epoch 56, Loss: 0.5375378928023822\n",
      "Epoch 57, Loss: 0.5337640515695632\n",
      "Epoch 58, Loss: 0.5289198880712314\n",
      "Epoch 59, Loss: 0.5230306496072858\n",
      "Epoch 60, Loss: 0.5164814396539522\n",
      "Epoch 61, Loss: 0.5106561125074696\n",
      "Epoch 62, Loss: 0.5080036390485858\n",
      "Epoch 63, Loss: 0.5088985566918386\n",
      "Epoch 64, Loss: 0.507720528123383\n",
      "Epoch 65, Loss: 0.5034684341843558\n",
      "Epoch 66, Loss: 0.4991458959057858\n",
      "Epoch 67, Loss: 0.4963158087971391\n",
      "Epoch 68, Loss: 0.4946546933832076\n",
      "Epoch 69, Loss: 0.49314220115627544\n",
      "Epoch 70, Loss: 0.49111726751281803\n",
      "Epoch 71, Loss: 0.488387012471624\n",
      "Epoch 72, Loss: 0.48520788756443295\n",
      "Epoch 73, Loss: 0.4820472714622598\n",
      "Epoch 74, Loss: 0.4793553827292917\n",
      "Epoch 75, Loss: 0.47732753008117634\n",
      "Epoch 76, Loss: 0.47562167054964716\n",
      "Epoch 77, Loss: 0.47378416494309783\n",
      "Epoch 78, Loss: 0.4719646690761534\n",
      "Epoch 79, Loss: 0.47059093420441583\n",
      "Epoch 80, Loss: 0.4696740737742248\n",
      "Epoch 81, Loss: 0.4688813661241278\n",
      "Epoch 82, Loss: 0.4678575603364685\n",
      "Epoch 83, Loss: 0.46654115639557864\n",
      "Epoch 84, Loss: 0.46511446659121725\n",
      "Epoch 85, Loss: 0.46387701726838204\n",
      "Epoch 86, Loss: 0.4630388272124971\n",
      "Epoch 87, Loss: 0.4625430029131093\n",
      "Epoch 88, Loss: 0.46213589073846717\n",
      "Epoch 89, Loss: 0.4615607008902186\n",
      "Epoch 90, Loss: 0.4607957363341605\n",
      "Epoch 91, Loss: 0.45998695121791905\n",
      "Epoch 92, Loss: 0.4592193813520818\n",
      "Epoch 93, Loss: 0.45861073971004274\n",
      "Epoch 94, Loss: 0.45802466518085244\n",
      "Epoch 95, Loss: 0.4573977378516559\n",
      "Epoch 96, Loss: 0.4567274567449195\n",
      "Epoch 97, Loss: 0.45603148832271156\n",
      "Epoch 98, Loss: 0.45537025669191944\n",
      "Epoch 99, Loss: 0.45470508135071963\n",
      "Epoch 100, Loss: 0.45400955744799854\n",
      "Epoch 101, Loss: 0.45334098864091915\n",
      "Epoch 102, Loss: 0.45272003361760993\n",
      "Epoch 103, Loss: 0.4521036640846076\n",
      "Epoch 104, Loss: 0.45145389280378356\n",
      "Epoch 105, Loss: 0.4507507571744563\n",
      "Epoch 106, Loss: 0.4500692195107303\n",
      "Epoch 107, Loss: 0.4494282275524362\n",
      "Epoch 108, Loss: 0.448824651586839\n",
      "Epoch 109, Loss: 0.4482280089020395\n",
      "Epoch 110, Loss: 0.4476328346027004\n",
      "Epoch 111, Loss: 0.44703061788781606\n",
      "Epoch 112, Loss: 0.4464393045633804\n",
      "Epoch 113, Loss: 0.4458629986736229\n",
      "Epoch 114, Loss: 0.44525945916427817\n",
      "Epoch 115, Loss: 0.44465179954155226\n",
      "Epoch 116, Loss: 0.4440378887220666\n",
      "Epoch 117, Loss: 0.44342136369827145\n",
      "Epoch 118, Loss: 0.4427922019802103\n",
      "Epoch 119, Loss: 0.4421341557222072\n",
      "Epoch 120, Loss: 0.4414836680619779\n",
      "Epoch 121, Loss: 0.4408223332539199\n",
      "Epoch 122, Loss: 0.44015203211899295\n",
      "Epoch 123, Loss: 0.4394522603344358\n",
      "Epoch 124, Loss: 0.43875531212397584\n",
      "Epoch 125, Loss: 0.4380799944912873\n",
      "Epoch 126, Loss: 0.4374036853222076\n",
      "Epoch 127, Loss: 0.4367247763612028\n",
      "Epoch 128, Loss: 0.43603804396199614\n",
      "Epoch 129, Loss: 0.4353543014063705\n",
      "Epoch 130, Loss: 0.43465923299690773\n",
      "Epoch 131, Loss: 0.43397010759168897\n",
      "Epoch 132, Loss: 0.4332784245010621\n",
      "Epoch 133, Loss: 0.43256722327493424\n",
      "Epoch 134, Loss: 0.43184434389984083\n",
      "Epoch 135, Loss: 0.4311455351312452\n",
      "Epoch 136, Loss: 0.43044683812584517\n",
      "Epoch 137, Loss: 0.42973322191601404\n",
      "Epoch 138, Loss: 0.4290319123169586\n",
      "Epoch 139, Loss: 0.42836638140683875\n",
      "Epoch 140, Loss: 0.42770112139193833\n",
      "Epoch 141, Loss: 0.42699120466031765\n",
      "Epoch 142, Loss: 0.42629623766390307\n",
      "Epoch 143, Loss: 0.42562194783913115\n",
      "Epoch 144, Loss: 0.4249472367968963\n",
      "Epoch 145, Loss: 0.42423819116265055\n",
      "Epoch 146, Loss: 0.423499370995587\n",
      "Epoch 147, Loss: 0.4227867341067589\n",
      "Epoch 148, Loss: 0.4221117979859505\n",
      "Epoch 149, Loss: 0.4214732765242616\n",
      "Epoch 150, Loss: 0.42081880811923256\n",
      "Epoch 151, Loss: 0.4201416859739459\n",
      "Epoch 152, Loss: 0.4194605044879061\n",
      "Epoch 153, Loss: 0.41877253955703303\n",
      "Epoch 154, Loss: 0.41805854617105614\n",
      "Epoch 155, Loss: 0.41735331065582165\n",
      "Epoch 156, Loss: 0.4166660149887075\n",
      "Epoch 157, Loss: 0.4159949749760015\n",
      "Epoch 158, Loss: 0.41532536224816025\n",
      "Epoch 159, Loss: 0.4146899022461822\n",
      "Epoch 160, Loss: 0.41419126199971235\n",
      "Epoch 161, Loss: 0.414019312495667\n",
      "Epoch 162, Loss: 0.41333312446386433\n",
      "Epoch 163, Loss: 0.4120494021488329\n",
      "Epoch 164, Loss: 0.411532662916948\n",
      "Epoch 165, Loss: 0.41131247176393565\n",
      "Epoch 166, Loss: 0.4102659714488085\n",
      "Epoch 167, Loss: 0.4095943416592059\n",
      "Epoch 168, Loss: 0.40936395324478897\n",
      "Epoch 169, Loss: 0.4083583664357101\n",
      "Epoch 170, Loss: 0.40780576503059335\n",
      "Epoch 171, Loss: 0.4074816739460785\n",
      "Epoch 172, Loss: 0.4065211748177679\n",
      "Epoch 173, Loss: 0.4059176185678718\n",
      "Epoch 174, Loss: 0.40557798409969303\n",
      "Epoch 175, Loss: 0.40485124773203307\n",
      "Epoch 176, Loss: 0.40397225584000734\n",
      "Epoch 177, Loss: 0.40356275462342966\n",
      "Epoch 178, Loss: 0.4031228420288523\n",
      "Epoch 179, Loss: 0.40227583895377644\n",
      "Epoch 180, Loss: 0.4015496760298522\n",
      "Epoch 181, Loss: 0.40113749742163507\n",
      "Epoch 182, Loss: 0.4005842531523128\n",
      "Epoch 183, Loss: 0.3998274960182547\n",
      "Epoch 184, Loss: 0.3991021241640259\n",
      "Epoch 185, Loss: 0.3985438672370732\n",
      "Epoch 186, Loss: 0.39810550171850523\n",
      "Epoch 187, Loss: 0.397590541094773\n",
      "Epoch 188, Loss: 0.3969481438345083\n",
      "Epoch 189, Loss: 0.3961946340142176\n",
      "Epoch 190, Loss: 0.3954561929807953\n",
      "Epoch 191, Loss: 0.39476591628483076\n",
      "Epoch 192, Loss: 0.39413940686584903\n",
      "Epoch 193, Loss: 0.3935378191719303\n",
      "Epoch 194, Loss: 0.3930193191662269\n",
      "Epoch 195, Loss: 0.3927961474757538\n",
      "Epoch 196, Loss: 0.39312772094925097\n",
      "Epoch 197, Loss: 0.39420433474692307\n",
      "Epoch 198, Loss: 0.39205083023501996\n",
      "Epoch 199, Loss: 0.39009987820694547\n",
      "Epoch 200, Loss: 0.39085972409458647\n",
      "Epoch 201, Loss: 0.3900833188824134\n",
      "Epoch 202, Loss: 0.3885750386358155\n",
      "Epoch 203, Loss: 0.3885224788451669\n",
      "Epoch 204, Loss: 0.38839347491661513\n",
      "Epoch 205, Loss: 0.38703962943008097\n",
      "Epoch 206, Loss: 0.38650421973783494\n",
      "Epoch 207, Loss: 0.38652733197980194\n",
      "Epoch 208, Loss: 0.3857506280289468\n",
      "Epoch 209, Loss: 0.3848593350846759\n",
      "Epoch 210, Loss: 0.38439544065135395\n",
      "Epoch 211, Loss: 0.38420234151818733\n",
      "Epoch 212, Loss: 0.38346763915208115\n",
      "Epoch 213, Loss: 0.38269126685140686\n",
      "Epoch 214, Loss: 0.3821568226140482\n",
      "Epoch 215, Loss: 0.3817879532032516\n",
      "Epoch 216, Loss: 0.3814480657912746\n",
      "Epoch 217, Loss: 0.3806149798986381\n",
      "Epoch 218, Loss: 0.37996072632093614\n",
      "Epoch 219, Loss: 0.3793501269499563\n",
      "Epoch 220, Loss: 0.37885555439442187\n",
      "Epoch 221, Loss: 0.37853805113377764\n",
      "Epoch 222, Loss: 0.3781361373333065\n",
      "Epoch 223, Loss: 0.3779706710949537\n",
      "Epoch 224, Loss: 0.37738413703195606\n",
      "Epoch 225, Loss: 0.376670632724784\n",
      "Epoch 226, Loss: 0.37565636810105396\n",
      "Epoch 227, Loss: 0.37491694166336326\n",
      "Epoch 228, Loss: 0.3745286482623927\n",
      "Epoch 229, Loss: 0.3743351168077659\n",
      "Epoch 230, Loss: 0.3741282025017575\n",
      "Epoch 231, Loss: 0.37373661766845023\n",
      "Epoch 232, Loss: 0.37320068943122525\n",
      "Epoch 233, Loss: 0.37200594768332756\n",
      "Epoch 234, Loss: 0.37114863742679494\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.23801012330578142\n",
      "Test R^2 score: 0.3884575038012872\n",
      "Num of epochs: 235\n",
      "Epoch 1, Loss: 0.5778039350024419\n",
      "Epoch 2, Loss: 0.5764730151445644\n",
      "Epoch 3, Loss: 0.5752210368441888\n",
      "Epoch 4, Loss: 0.5740026209984064\n",
      "Epoch 5, Loss: 0.5728202709830064\n",
      "Epoch 6, Loss: 0.5718213853561624\n",
      "Epoch 7, Loss: 0.5709028715626403\n",
      "Epoch 8, Loss: 0.5699815704478322\n",
      "Epoch 9, Loss: 0.5690681783192788\n",
      "Epoch 10, Loss: 0.5681909265655094\n",
      "Epoch 11, Loss: 0.567348748397556\n",
      "Epoch 12, Loss: 0.5665415109069943\n",
      "Epoch 13, Loss: 0.5657607247654692\n",
      "Epoch 14, Loss: 0.5649898577514058\n",
      "Epoch 15, Loss: 0.5642336250315615\n",
      "Epoch 16, Loss: 0.5634911864182942\n",
      "Epoch 17, Loss: 0.5627744058343973\n",
      "Epoch 18, Loss: 0.5620756137827752\n",
      "Epoch 19, Loss: 0.5613885070562074\n",
      "Epoch 20, Loss: 0.5606939408643871\n",
      "Epoch 21, Loss: 0.5600050324401211\n",
      "Epoch 22, Loss: 0.5593163678006423\n",
      "Epoch 23, Loss: 0.5586017261282464\n",
      "Epoch 24, Loss: 0.5578637588414632\n",
      "Epoch 25, Loss: 0.5571063586260243\n",
      "Epoch 26, Loss: 0.5563159196348038\n",
      "Epoch 27, Loss: 0.555425368062241\n",
      "Epoch 28, Loss: 0.5543649299678941\n",
      "Epoch 29, Loss: 0.5531193231840906\n",
      "Epoch 30, Loss: 0.551697125093452\n",
      "Epoch 31, Loss: 0.5502349362579694\n",
      "Epoch 32, Loss: 0.5486390952391881\n",
      "Epoch 33, Loss: 0.5466963339912079\n",
      "Epoch 34, Loss: 0.5443008329407183\n",
      "Epoch 35, Loss: 0.5414680764922897\n",
      "Epoch 36, Loss: 0.5382714202824901\n",
      "Epoch 37, Loss: 0.5350748543201439\n",
      "Epoch 38, Loss: 0.5325706839324927\n",
      "Epoch 39, Loss: 0.5313704017632243\n",
      "Epoch 40, Loss: 0.5306667885203118\n",
      "Epoch 41, Loss: 0.5286088814685328\n",
      "Epoch 42, Loss: 0.5251378582290713\n",
      "Epoch 43, Loss: 0.5215598633952664\n",
      "Epoch 44, Loss: 0.5188749369724854\n",
      "Epoch 45, Loss: 0.5169698920088305\n",
      "Epoch 46, Loss: 0.5153608801658733\n",
      "Epoch 47, Loss: 0.5135977223761732\n",
      "Epoch 48, Loss: 0.5114880981123356\n",
      "Epoch 49, Loss: 0.5091860754316917\n",
      "Epoch 50, Loss: 0.5070188041770026\n",
      "Epoch 51, Loss: 0.5053636338425107\n",
      "Epoch 52, Loss: 0.5042241003357287\n",
      "Epoch 53, Loss: 0.5029642333971192\n",
      "Epoch 54, Loss: 0.5011649864954303\n",
      "Epoch 55, Loss: 0.4992193296664936\n",
      "Epoch 56, Loss: 0.4976360496601239\n",
      "Epoch 57, Loss: 0.49643099578185074\n",
      "Epoch 58, Loss: 0.49526126728980374\n",
      "Epoch 59, Loss: 0.4938513470708495\n",
      "Epoch 60, Loss: 0.49224945465588527\n",
      "Epoch 61, Loss: 0.4907251766007261\n",
      "Epoch 62, Loss: 0.4894848447173904\n",
      "Epoch 63, Loss: 0.48837799639694324\n",
      "Epoch 64, Loss: 0.48708673468914954\n",
      "Epoch 65, Loss: 0.48563936784225065\n",
      "Epoch 66, Loss: 0.48432656015172304\n",
      "Epoch 67, Loss: 0.4831983980828062\n",
      "Epoch 68, Loss: 0.48211603083735044\n",
      "Epoch 69, Loss: 0.48098716060549424\n",
      "Epoch 70, Loss: 0.4798471415035594\n",
      "Epoch 71, Loss: 0.47887304542519005\n",
      "Epoch 72, Loss: 0.47799621730069847\n",
      "Epoch 73, Loss: 0.47700887630708955\n",
      "Epoch 74, Loss: 0.4759634035691929\n",
      "Epoch 75, Loss: 0.4750272535988267\n",
      "Epoch 76, Loss: 0.4741437221041901\n",
      "Epoch 77, Loss: 0.47317035553396636\n",
      "Epoch 78, Loss: 0.4721422158824951\n",
      "Epoch 79, Loss: 0.47119001477288064\n",
      "Epoch 80, Loss: 0.47026852373613276\n",
      "Epoch 81, Loss: 0.46931442611488067\n",
      "Epoch 82, Loss: 0.4683865091514791\n",
      "Epoch 83, Loss: 0.4675049459226369\n",
      "Epoch 84, Loss: 0.46662238782329857\n",
      "Epoch 85, Loss: 0.46567710738513907\n",
      "Epoch 86, Loss: 0.4647630092478629\n",
      "Epoch 87, Loss: 0.46387655148340506\n",
      "Epoch 88, Loss: 0.46298786542286813\n",
      "Epoch 89, Loss: 0.4621228639338156\n",
      "Epoch 90, Loss: 0.46129922089886155\n",
      "Epoch 91, Loss: 0.46044887894651265\n",
      "Epoch 92, Loss: 0.4596083923982955\n",
      "Epoch 93, Loss: 0.458783158369469\n",
      "Epoch 94, Loss: 0.45793772732612026\n",
      "Epoch 95, Loss: 0.4570936176750778\n",
      "Epoch 96, Loss: 0.45620938930319\n",
      "Epoch 97, Loss: 0.4552915506511429\n",
      "Epoch 98, Loss: 0.4543844510896601\n",
      "Epoch 99, Loss: 0.4534180942907412\n",
      "Epoch 100, Loss: 0.4524209867431479\n",
      "Epoch 101, Loss: 0.4514261990394519\n",
      "Epoch 102, Loss: 0.4504104563572834\n",
      "Epoch 103, Loss: 0.44937406425750037\n",
      "Epoch 104, Loss: 0.4483484046765139\n",
      "Epoch 105, Loss: 0.4473306700206265\n",
      "Epoch 106, Loss: 0.44629941298086995\n",
      "Epoch 107, Loss: 0.4452999514769282\n",
      "Epoch 108, Loss: 0.44428573157078716\n",
      "Epoch 109, Loss: 0.44317204555215933\n",
      "Epoch 110, Loss: 0.4421053557374177\n",
      "Epoch 111, Loss: 0.4409547032191191\n",
      "Epoch 112, Loss: 0.43980569895095994\n",
      "Epoch 113, Loss: 0.4387610347425233\n",
      "Epoch 114, Loss: 0.437766096391052\n",
      "Epoch 115, Loss: 0.4368147422098743\n",
      "Epoch 116, Loss: 0.4360823653787671\n",
      "Epoch 117, Loss: 0.43519768166674\n",
      "Epoch 118, Loss: 0.4342135218428754\n",
      "Epoch 119, Loss: 0.4332899111608763\n",
      "Epoch 120, Loss: 0.4325574915496347\n",
      "Epoch 121, Loss: 0.43171004345591996\n",
      "Epoch 122, Loss: 0.4307001838327639\n",
      "Epoch 123, Loss: 0.4299307568100743\n",
      "Epoch 124, Loss: 0.4290727205441427\n",
      "Epoch 125, Loss: 0.4281108192545626\n",
      "Epoch 126, Loss: 0.4271446412750243\n",
      "Epoch 127, Loss: 0.4262138758591202\n",
      "Epoch 128, Loss: 0.42549939407009635\n",
      "Epoch 129, Loss: 0.42484918120189596\n",
      "Epoch 130, Loss: 0.42438790055949566\n",
      "Epoch 131, Loss: 0.42374909890340684\n",
      "Epoch 132, Loss: 0.4227111089786693\n",
      "Epoch 133, Loss: 0.42174273642824067\n",
      "Epoch 134, Loss: 0.42132525476475036\n",
      "Epoch 135, Loss: 0.42090422588713905\n",
      "Epoch 136, Loss: 0.4199280316988256\n",
      "Epoch 137, Loss: 0.41903038317152375\n",
      "Epoch 138, Loss: 0.41845968416991064\n",
      "Epoch 139, Loss: 0.4180242198607609\n",
      "Epoch 140, Loss: 0.4173060180962794\n",
      "Epoch 141, Loss: 0.41652524654192696\n",
      "Epoch 142, Loss: 0.4158400939851785\n",
      "Epoch 143, Loss: 0.4153380091506281\n",
      "Epoch 144, Loss: 0.414942956904932\n",
      "Epoch 145, Loss: 0.41467495373947394\n",
      "Epoch 146, Loss: 0.4144891484143483\n",
      "Epoch 147, Loss: 0.41420664167747856\n",
      "Epoch 148, Loss: 0.41322517303019135\n",
      "Epoch 149, Loss: 0.4122004837640388\n",
      "Epoch 150, Loss: 0.4119621845640358\n",
      "Epoch 151, Loss: 0.4119757123658453\n",
      "Epoch 152, Loss: 0.4113602722589396\n",
      "Epoch 153, Loss: 0.41040033616173976\n",
      "Epoch 154, Loss: 0.4101167568993336\n",
      "Epoch 155, Loss: 0.41013377900103\n",
      "Epoch 156, Loss: 0.4096746069060013\n",
      "Epoch 157, Loss: 0.40882295339540137\n",
      "Epoch 158, Loss: 0.408353330729103\n",
      "Epoch 159, Loss: 0.4083069299738081\n",
      "Epoch 160, Loss: 0.4082939557953649\n",
      "Epoch 161, Loss: 0.40766657926223726\n",
      "Epoch 162, Loss: 0.40690812575213564\n",
      "Epoch 163, Loss: 0.40641995689570387\n",
      "Epoch 164, Loss: 0.406280626463032\n",
      "Epoch 165, Loss: 0.40618424617052795\n",
      "Epoch 166, Loss: 0.40584722139080104\n",
      "Epoch 167, Loss: 0.40527928359629495\n",
      "Epoch 168, Loss: 0.4045340353824558\n",
      "Epoch 169, Loss: 0.40392398684606495\n",
      "Epoch 170, Loss: 0.4035554066755832\n",
      "Epoch 171, Loss: 0.403358956395312\n",
      "Epoch 172, Loss: 0.4033332249973614\n",
      "Epoch 173, Loss: 0.4033248568595188\n",
      "Epoch 174, Loss: 0.4033067899566083\n",
      "Epoch 175, Loss: 0.4024986043159502\n",
      "Epoch 176, Loss: 0.4015070168130248\n",
      "Epoch 177, Loss: 0.4009133624974973\n",
      "Epoch 178, Loss: 0.40091224745494874\n",
      "Epoch 179, Loss: 0.4011288605893836\n",
      "Epoch 180, Loss: 0.4008247998764061\n",
      "Epoch 181, Loss: 0.40017644224271\n",
      "Epoch 182, Loss: 0.3992897530437255\n",
      "Epoch 183, Loss: 0.39887901228103423\n",
      "Epoch 184, Loss: 0.3989168350542642\n",
      "Epoch 185, Loss: 0.3990467499781656\n",
      "Epoch 186, Loss: 0.39899667135681055\n",
      "Epoch 187, Loss: 0.39828303091639494\n",
      "Epoch 188, Loss: 0.39743716756990044\n",
      "Epoch 189, Loss: 0.3967195950018713\n",
      "Epoch 190, Loss: 0.3964965141956129\n",
      "Epoch 191, Loss: 0.39656813915863537\n",
      "Epoch 192, Loss: 0.3967159327932469\n",
      "Epoch 193, Loss: 0.39690913857040466\n",
      "Epoch 194, Loss: 0.39624897776210105\n",
      "Epoch 195, Loss: 0.39521758180145367\n",
      "Epoch 196, Loss: 0.3942774910240826\n",
      "Epoch 197, Loss: 0.3940320397507586\n",
      "Epoch 198, Loss: 0.3943085561299022\n",
      "Epoch 199, Loss: 0.3945058115699113\n",
      "Epoch 200, Loss: 0.3947422671886381\n",
      "Epoch 201, Loss: 0.3936179325599525\n",
      "Epoch 202, Loss: 0.39256512444828545\n",
      "Epoch 203, Loss: 0.3918559515732907\n",
      "Epoch 204, Loss: 0.3918822654707679\n",
      "Epoch 205, Loss: 0.3924618639004347\n",
      "Epoch 206, Loss: 0.39252572160618904\n",
      "Epoch 207, Loss: 0.3922434846654232\n",
      "Epoch 208, Loss: 0.39072199570901034\n",
      "Epoch 209, Loss: 0.3898300283153823\n",
      "Epoch 210, Loss: 0.38994994007290623\n",
      "Epoch 211, Loss: 0.39054719149993933\n",
      "Epoch 212, Loss: 0.3911088617006071\n",
      "Epoch 213, Loss: 0.3900738833819676\n",
      "Epoch 214, Loss: 0.3886731785124577\n",
      "Epoch 215, Loss: 0.38755915098030574\n",
      "Epoch 216, Loss: 0.3879581972638924\n",
      "Epoch 217, Loss: 0.3885364200588937\n",
      "Epoch 218, Loss: 0.38819846838516797\n",
      "Epoch 219, Loss: 0.387347452069834\n",
      "Epoch 220, Loss: 0.38601682519562075\n",
      "Epoch 221, Loss: 0.3855493570574452\n",
      "Epoch 222, Loss: 0.38566111424896676\n",
      "Epoch 223, Loss: 0.38566441778094945\n",
      "Epoch 224, Loss: 0.38618521057477584\n",
      "Epoch 225, Loss: 0.3862965523650125\n",
      "Epoch 226, Loss: 0.38577152575214596\n",
      "Epoch 227, Loss: 0.3844296106450872\n",
      "Epoch 228, Loss: 0.3835420080277006\n",
      "Epoch 229, Loss: 0.3826709213030004\n",
      "Epoch 230, Loss: 0.38287545679073254\n",
      "Epoch 231, Loss: 0.3832661218219681\n",
      "Epoch 232, Loss: 0.38364413487954957\n",
      "Epoch 233, Loss: 0.38512649653341163\n",
      "Epoch 234, Loss: 0.38470586322305567\n",
      "Epoch 235, Loss: 0.3828912770706101\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2520899851525806\n",
      "Test R^2 score: 0.31708969533120923\n",
      "Num of epochs: 236\n",
      "Epoch 1, Loss: 0.5642020911369665\n",
      "Epoch 2, Loss: 0.5629622361576304\n",
      "Epoch 3, Loss: 0.5618342857758265\n",
      "Epoch 4, Loss: 0.5608213065257426\n",
      "Epoch 5, Loss: 0.5599301231588989\n",
      "Epoch 6, Loss: 0.5591562546681166\n",
      "Epoch 7, Loss: 0.5584943989786206\n",
      "Epoch 8, Loss: 0.5579400939761456\n",
      "Epoch 9, Loss: 0.5574891432744236\n",
      "Epoch 10, Loss: 0.5571255362005052\n",
      "Epoch 11, Loss: 0.5568319962120196\n",
      "Epoch 12, Loss: 0.5566235991433996\n",
      "Epoch 13, Loss: 0.5564841067125926\n",
      "Epoch 14, Loss: 0.5563796653063448\n",
      "Epoch 15, Loss: 0.5563017767479237\n",
      "Epoch 16, Loss: 0.5562457105921261\n",
      "Epoch 17, Loss: 0.5562060349480965\n",
      "Epoch 18, Loss: 0.5561693036555412\n",
      "Epoch 19, Loss: 0.5561364550912323\n",
      "Epoch 20, Loss: 0.556104837185422\n",
      "Epoch 21, Loss: 0.5560722259874872\n",
      "Epoch 22, Loss: 0.5560343335000302\n",
      "Epoch 23, Loss: 0.5559895773775217\n",
      "Epoch 24, Loss: 0.555933318913108\n",
      "Epoch 25, Loss: 0.5558620696763155\n",
      "Epoch 26, Loss: 0.555772150719653\n",
      "Epoch 27, Loss: 0.5556574386979573\n",
      "Epoch 28, Loss: 0.5555193130936831\n",
      "Epoch 29, Loss: 0.5553474529903436\n",
      "Epoch 30, Loss: 0.5551284058553783\n",
      "Epoch 31, Loss: 0.5548478821471944\n",
      "Epoch 32, Loss: 0.5544913038977032\n",
      "Epoch 33, Loss: 0.5540493800400521\n",
      "Epoch 34, Loss: 0.5535056727772538\n",
      "Epoch 35, Loss: 0.552851984566591\n",
      "Epoch 36, Loss: 0.5520731877048511\n",
      "Epoch 37, Loss: 0.5511665079029886\n",
      "Epoch 38, Loss: 0.5501107537856936\n",
      "Epoch 39, Loss: 0.5488852746063076\n",
      "Epoch 40, Loss: 0.5475169909466645\n",
      "Epoch 41, Loss: 0.5459361873669886\n",
      "Epoch 42, Loss: 0.5440771740945369\n",
      "Epoch 43, Loss: 0.54184001814091\n",
      "Epoch 44, Loss: 0.5389472174730039\n",
      "Epoch 45, Loss: 0.5350013285914529\n",
      "Epoch 46, Loss: 0.5300291563057592\n",
      "Epoch 47, Loss: 0.5241000409177762\n",
      "Epoch 48, Loss: 0.5174980821435745\n",
      "Epoch 49, Loss: 0.5111131360381322\n",
      "Epoch 50, Loss: 0.5069927641805574\n",
      "Epoch 51, Loss: 0.5072845355347944\n",
      "Epoch 52, Loss: 0.5078372949268964\n",
      "Epoch 53, Loss: 0.5042982720459868\n",
      "Epoch 54, Loss: 0.4988116507322832\n",
      "Epoch 55, Loss: 0.49412400892463726\n",
      "Epoch 56, Loss: 0.4912741982467311\n",
      "Epoch 57, Loss: 0.4897407843320047\n",
      "Epoch 58, Loss: 0.48870431501139566\n",
      "Epoch 59, Loss: 0.487244199006812\n",
      "Epoch 60, Loss: 0.48508760885047264\n",
      "Epoch 61, Loss: 0.4823174923545357\n",
      "Epoch 62, Loss: 0.4793330159509021\n",
      "Epoch 63, Loss: 0.47664650973914174\n",
      "Epoch 64, Loss: 0.47468231959275503\n",
      "Epoch 65, Loss: 0.47348680900399037\n",
      "Epoch 66, Loss: 0.47257331246593015\n",
      "Epoch 67, Loss: 0.47147996990481605\n",
      "Epoch 68, Loss: 0.4702910839793816\n",
      "Epoch 69, Loss: 0.4692473792743207\n",
      "Epoch 70, Loss: 0.46826109821489287\n",
      "Epoch 71, Loss: 0.467158652215536\n",
      "Epoch 72, Loss: 0.4660472197266478\n",
      "Epoch 73, Loss: 0.4651316544575241\n",
      "Epoch 74, Loss: 0.46431776148369197\n",
      "Epoch 75, Loss: 0.46347728203525945\n",
      "Epoch 76, Loss: 0.4625518138317584\n",
      "Epoch 77, Loss: 0.46171342875711036\n",
      "Epoch 78, Loss: 0.4609540677729981\n",
      "Epoch 79, Loss: 0.46020295726985605\n",
      "Epoch 80, Loss: 0.4594521431798098\n",
      "Epoch 81, Loss: 0.45868509153031867\n",
      "Epoch 82, Loss: 0.45789399186637403\n",
      "Epoch 83, Loss: 0.45707873562343737\n",
      "Epoch 84, Loss: 0.4563327080735344\n",
      "Epoch 85, Loss: 0.4556388347655055\n",
      "Epoch 86, Loss: 0.45495985401594774\n",
      "Epoch 87, Loss: 0.4542823021635063\n",
      "Epoch 88, Loss: 0.4535966753101533\n",
      "Epoch 89, Loss: 0.4529536021747015\n",
      "Epoch 90, Loss: 0.45238027540463394\n",
      "Epoch 91, Loss: 0.45183933312515456\n",
      "Epoch 92, Loss: 0.45129376370934776\n",
      "Epoch 93, Loss: 0.4507545093029427\n",
      "Epoch 94, Loss: 0.45021503926581097\n",
      "Epoch 95, Loss: 0.4496869342633387\n",
      "Epoch 96, Loss: 0.4491789592866728\n",
      "Epoch 97, Loss: 0.4486781972964103\n",
      "Epoch 98, Loss: 0.44814186386342025\n",
      "Epoch 99, Loss: 0.44757119614039925\n",
      "Epoch 100, Loss: 0.4469972996651502\n",
      "Epoch 101, Loss: 0.4464273384622169\n",
      "Epoch 102, Loss: 0.445867159561424\n",
      "Epoch 103, Loss: 0.44530338144168563\n",
      "Epoch 104, Loss: 0.44472474913296517\n",
      "Epoch 105, Loss: 0.4441169618393977\n",
      "Epoch 106, Loss: 0.4434949188747729\n",
      "Epoch 107, Loss: 0.4428511407935463\n",
      "Epoch 108, Loss: 0.4421792983248167\n",
      "Epoch 109, Loss: 0.44146086768442544\n",
      "Epoch 110, Loss: 0.44073090328967457\n",
      "Epoch 111, Loss: 0.44003525218846257\n",
      "Epoch 112, Loss: 0.4393829120070123\n",
      "Epoch 113, Loss: 0.43874974226332697\n",
      "Epoch 114, Loss: 0.4381039231818018\n",
      "Epoch 115, Loss: 0.4374895264870529\n",
      "Epoch 116, Loss: 0.436866505967329\n",
      "Epoch 117, Loss: 0.4362480950792143\n",
      "Epoch 118, Loss: 0.4356215032439909\n",
      "Epoch 119, Loss: 0.4349934778601497\n",
      "Epoch 120, Loss: 0.43435366941812037\n",
      "Epoch 121, Loss: 0.433720991005582\n",
      "Epoch 122, Loss: 0.43307009856805245\n",
      "Epoch 123, Loss: 0.43240709563846197\n",
      "Epoch 124, Loss: 0.43175342863717203\n",
      "Epoch 125, Loss: 0.4311237260905286\n",
      "Epoch 126, Loss: 0.4305008040330935\n",
      "Epoch 127, Loss: 0.42988961408088133\n",
      "Epoch 128, Loss: 0.42929220223074843\n",
      "Epoch 129, Loss: 0.4286897519379646\n",
      "Epoch 130, Loss: 0.42806779590660826\n",
      "Epoch 131, Loss: 0.42744686967732276\n",
      "Epoch 132, Loss: 0.42685087398306865\n",
      "Epoch 133, Loss: 0.4262814339880025\n",
      "Epoch 134, Loss: 0.4257144000568949\n",
      "Epoch 135, Loss: 0.4251316609924953\n",
      "Epoch 136, Loss: 0.42454698134034147\n",
      "Epoch 137, Loss: 0.4239623037553804\n",
      "Epoch 138, Loss: 0.4233603291026499\n",
      "Epoch 139, Loss: 0.4227474163682562\n",
      "Epoch 140, Loss: 0.42213177813735286\n",
      "Epoch 141, Loss: 0.42150914258193617\n",
      "Epoch 142, Loss: 0.4209022079263492\n",
      "Epoch 143, Loss: 0.4203027993539875\n",
      "Epoch 144, Loss: 0.41970329805977485\n",
      "Epoch 145, Loss: 0.41908749032944026\n",
      "Epoch 146, Loss: 0.418464580454439\n",
      "Epoch 147, Loss: 0.4178363019772856\n",
      "Epoch 148, Loss: 0.41721468490438557\n",
      "Epoch 149, Loss: 0.4166793721963947\n",
      "Epoch 150, Loss: 0.4164265675982595\n",
      "Epoch 151, Loss: 0.4162966893619535\n",
      "Epoch 152, Loss: 0.4150507487727448\n",
      "Epoch 153, Loss: 0.41454973883436\n",
      "Epoch 154, Loss: 0.4143460760191546\n",
      "Epoch 155, Loss: 0.4132927451310828\n",
      "Epoch 156, Loss: 0.4131033783245162\n",
      "Epoch 157, Loss: 0.4125090374101093\n",
      "Epoch 158, Loss: 0.4116472301579475\n",
      "Epoch 159, Loss: 0.4115248236069331\n",
      "Epoch 160, Loss: 0.4107124190850815\n",
      "Epoch 161, Loss: 0.4100405575300815\n",
      "Epoch 162, Loss: 0.4098724291500659\n",
      "Epoch 163, Loss: 0.40907113176160587\n",
      "Epoch 164, Loss: 0.40846716632233954\n",
      "Epoch 165, Loss: 0.4082395181449074\n",
      "Epoch 166, Loss: 0.40764044351225354\n",
      "Epoch 167, Loss: 0.4069111469285559\n",
      "Epoch 168, Loss: 0.406585628077453\n",
      "Epoch 169, Loss: 0.40630243036419705\n",
      "Epoch 170, Loss: 0.40555417551969997\n",
      "Epoch 171, Loss: 0.40495666625290117\n",
      "Epoch 172, Loss: 0.40465770965272846\n",
      "Epoch 173, Loss: 0.4042957508605956\n",
      "Epoch 174, Loss: 0.4036159401766114\n",
      "Epoch 175, Loss: 0.4029986412673839\n",
      "Epoch 176, Loss: 0.40260750726824807\n",
      "Epoch 177, Loss: 0.4022888034966923\n",
      "Epoch 178, Loss: 0.4018594549266434\n",
      "Epoch 179, Loss: 0.40126026892074024\n",
      "Epoch 180, Loss: 0.4006737987000704\n",
      "Epoch 181, Loss: 0.40011726910464507\n",
      "Epoch 182, Loss: 0.3996444075247648\n",
      "Epoch 183, Loss: 0.39925230150270047\n",
      "Epoch 184, Loss: 0.39904869175189733\n",
      "Epoch 185, Loss: 0.3991596932223485\n",
      "Epoch 186, Loss: 0.39952380624340583\n",
      "Epoch 187, Loss: 0.3985979280809854\n",
      "Epoch 188, Loss: 0.39720970667986416\n",
      "Epoch 189, Loss: 0.3968438459168398\n",
      "Epoch 190, Loss: 0.39712624669562235\n",
      "Epoch 191, Loss: 0.39661931339615175\n",
      "Epoch 192, Loss: 0.3955046665396197\n",
      "Epoch 193, Loss: 0.39552414471848646\n",
      "Epoch 194, Loss: 0.39576076377742514\n",
      "Epoch 195, Loss: 0.3948198339467419\n",
      "Epoch 196, Loss: 0.39397748476289757\n",
      "Epoch 197, Loss: 0.39395110277829376\n",
      "Epoch 198, Loss: 0.3937436353078242\n",
      "Epoch 199, Loss: 0.3932078231509624\n",
      "Epoch 200, Loss: 0.3925218114745389\n",
      "Epoch 201, Loss: 0.3921485562385617\n",
      "Epoch 202, Loss: 0.3920870694149006\n",
      "Epoch 203, Loss: 0.3917684223344626\n",
      "Epoch 204, Loss: 0.3912949919805927\n",
      "Epoch 205, Loss: 0.39070153440301575\n",
      "Epoch 206, Loss: 0.39023406493639534\n",
      "Epoch 207, Loss: 0.38981437495986987\n",
      "Epoch 208, Loss: 0.3894682350403213\n",
      "Epoch 209, Loss: 0.3893671765467617\n",
      "Epoch 210, Loss: 0.3896262944175212\n",
      "Epoch 211, Loss: 0.38994187704430944\n",
      "Epoch 212, Loss: 0.3891318393489779\n",
      "Epoch 213, Loss: 0.38845025266427247\n",
      "Epoch 214, Loss: 0.3873392579255604\n",
      "Epoch 215, Loss: 0.38698247143997344\n",
      "Epoch 216, Loss: 0.3874445375620863\n",
      "Epoch 217, Loss: 0.38716215664955483\n",
      "Epoch 218, Loss: 0.3866720075005511\n",
      "Epoch 219, Loss: 0.3856841031538314\n",
      "Epoch 220, Loss: 0.38507141509878534\n",
      "Epoch 221, Loss: 0.3848526948113127\n",
      "Epoch 222, Loss: 0.3850507889725048\n",
      "Epoch 223, Loss: 0.38497462139456595\n",
      "Epoch 224, Loss: 0.3837706000859544\n",
      "Epoch 225, Loss: 0.38340122340429506\n",
      "Epoch 226, Loss: 0.3825781942051612\n",
      "Epoch 227, Loss: 0.38208590859544017\n",
      "Epoch 228, Loss: 0.3822610932094594\n",
      "Epoch 229, Loss: 0.3824704841682297\n",
      "Epoch 230, Loss: 0.38312768611619746\n",
      "Epoch 231, Loss: 0.38281680124163026\n",
      "Epoch 232, Loss: 0.38142835713179474\n",
      "Epoch 233, Loss: 0.37933655520469284\n",
      "Epoch 234, Loss: 0.38023587566931577\n",
      "Epoch 235, Loss: 0.3801794977444952\n",
      "Epoch 236, Loss: 0.3792790221109338\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.25137952954463705\n",
      "Test R^2 score: 0.31499618861969986\n",
      "Num of epochs: 237\n",
      "Epoch 1, Loss: 0.5567134876414707\n",
      "Epoch 2, Loss: 0.5564165701762038\n",
      "Epoch 3, Loss: 0.5562411296865875\n",
      "Epoch 4, Loss: 0.5561616677431205\n",
      "Epoch 5, Loss: 0.5561528260293398\n",
      "Epoch 6, Loss: 0.5561845215823664\n",
      "Epoch 7, Loss: 0.5562137774128335\n",
      "Epoch 8, Loss: 0.5562102410755289\n",
      "Epoch 9, Loss: 0.556169678750292\n",
      "Epoch 10, Loss: 0.5561028007163094\n",
      "Epoch 11, Loss: 0.5560224614186058\n",
      "Epoch 12, Loss: 0.5559379023549949\n",
      "Epoch 13, Loss: 0.555853464466446\n",
      "Epoch 14, Loss: 0.5557691746199709\n",
      "Epoch 15, Loss: 0.5556803132749718\n",
      "Epoch 16, Loss: 0.5555744333503696\n",
      "Epoch 17, Loss: 0.5554351335056371\n",
      "Epoch 18, Loss: 0.5552368935640216\n",
      "Epoch 19, Loss: 0.5549707361187171\n",
      "Epoch 20, Loss: 0.5546334737337157\n",
      "Epoch 21, Loss: 0.5542242506650654\n",
      "Epoch 22, Loss: 0.5537374446384141\n",
      "Epoch 23, Loss: 0.5531574961712531\n",
      "Epoch 24, Loss: 0.5524537954817549\n",
      "Epoch 25, Loss: 0.5515802688546163\n",
      "Epoch 26, Loss: 0.5504709817287262\n",
      "Epoch 27, Loss: 0.5490793759439851\n",
      "Epoch 28, Loss: 0.5473964929501098\n",
      "Epoch 29, Loss: 0.5453862498345188\n",
      "Epoch 30, Loss: 0.5431149512306249\n",
      "Epoch 31, Loss: 0.5405441598593839\n",
      "Epoch 32, Loss: 0.5376230176717491\n",
      "Epoch 33, Loss: 0.5343133734699159\n",
      "Epoch 34, Loss: 0.5305810531372296\n",
      "Epoch 35, Loss: 0.5264312195623481\n",
      "Epoch 36, Loss: 0.5218861778569809\n",
      "Epoch 37, Loss: 0.5170731005961267\n",
      "Epoch 38, Loss: 0.5120268905868482\n",
      "Epoch 39, Loss: 0.5067344078729006\n",
      "Epoch 40, Loss: 0.5012982620159668\n",
      "Epoch 41, Loss: 0.4959687052850449\n",
      "Epoch 42, Loss: 0.4911954206135554\n",
      "Epoch 43, Loss: 0.4874739114187431\n",
      "Epoch 44, Loss: 0.48482008450599556\n",
      "Epoch 45, Loss: 0.4826702451544738\n",
      "Epoch 46, Loss: 0.4803857033763281\n",
      "Epoch 47, Loss: 0.4781691873614057\n",
      "Epoch 48, Loss: 0.4767696837025971\n",
      "Epoch 49, Loss: 0.4759695084667042\n",
      "Epoch 50, Loss: 0.475242741573998\n",
      "Epoch 51, Loss: 0.4742219858829006\n",
      "Epoch 52, Loss: 0.4728952701982645\n",
      "Epoch 53, Loss: 0.47210688230369996\n",
      "Epoch 54, Loss: 0.47162116025245776\n",
      "Epoch 55, Loss: 0.4706802362599043\n",
      "Epoch 56, Loss: 0.4692936446826625\n",
      "Epoch 57, Loss: 0.46780752165342665\n",
      "Epoch 58, Loss: 0.46656774539643386\n",
      "Epoch 59, Loss: 0.4654951100026\n",
      "Epoch 60, Loss: 0.46443002385084886\n",
      "Epoch 61, Loss: 0.4634672026527043\n",
      "Epoch 62, Loss: 0.4626662599871458\n",
      "Epoch 63, Loss: 0.462019942490031\n",
      "Epoch 64, Loss: 0.46137015194078174\n",
      "Epoch 65, Loss: 0.4605875141309959\n",
      "Epoch 66, Loss: 0.45975476805541365\n",
      "Epoch 67, Loss: 0.4590201019017885\n",
      "Epoch 68, Loss: 0.45838653913089666\n",
      "Epoch 69, Loss: 0.4577173641942003\n",
      "Epoch 70, Loss: 0.45697361835421335\n",
      "Epoch 71, Loss: 0.45625547444965375\n",
      "Epoch 72, Loss: 0.45554035271725185\n",
      "Epoch 73, Loss: 0.45481843865488214\n",
      "Epoch 74, Loss: 0.4540910617065451\n",
      "Epoch 75, Loss: 0.45329593854246436\n",
      "Epoch 76, Loss: 0.4525402505370883\n",
      "Epoch 77, Loss: 0.4518814616974618\n",
      "Epoch 78, Loss: 0.4512445960949708\n",
      "Epoch 79, Loss: 0.45062718394857365\n",
      "Epoch 80, Loss: 0.44998253285098405\n",
      "Epoch 81, Loss: 0.44933407174006346\n",
      "Epoch 82, Loss: 0.4486862177402077\n",
      "Epoch 83, Loss: 0.4480207972765638\n",
      "Epoch 84, Loss: 0.44733101978902345\n",
      "Epoch 85, Loss: 0.4466442305916618\n",
      "Epoch 86, Loss: 0.4459955264314034\n",
      "Epoch 87, Loss: 0.44535511214514056\n",
      "Epoch 88, Loss: 0.4446985295389568\n",
      "Epoch 89, Loss: 0.44399637515182133\n",
      "Epoch 90, Loss: 0.4432959490205669\n",
      "Epoch 91, Loss: 0.44259271420895835\n",
      "Epoch 92, Loss: 0.441876338352405\n",
      "Epoch 93, Loss: 0.4411751809054579\n",
      "Epoch 94, Loss: 0.44048011305036977\n",
      "Epoch 95, Loss: 0.4397741035624039\n",
      "Epoch 96, Loss: 0.439064464361066\n",
      "Epoch 97, Loss: 0.43838758351692103\n",
      "Epoch 98, Loss: 0.4377309836576764\n",
      "Epoch 99, Loss: 0.43709770507506773\n",
      "Epoch 100, Loss: 0.4365766522701584\n",
      "Epoch 101, Loss: 0.4362937442413246\n",
      "Epoch 102, Loss: 0.4351325009780816\n",
      "Epoch 103, Loss: 0.4343746988034748\n",
      "Epoch 104, Loss: 0.4339536599346967\n",
      "Epoch 105, Loss: 0.4329042709229346\n",
      "Epoch 106, Loss: 0.43218800630905274\n",
      "Epoch 107, Loss: 0.431584384758324\n",
      "Epoch 108, Loss: 0.43049073137214594\n",
      "Epoch 109, Loss: 0.4297781241824789\n",
      "Epoch 110, Loss: 0.4291112850929972\n",
      "Epoch 111, Loss: 0.42800311351361137\n",
      "Epoch 112, Loss: 0.42735695408815366\n",
      "Epoch 113, Loss: 0.426880703129797\n",
      "Epoch 114, Loss: 0.4256316630924427\n",
      "Epoch 115, Loss: 0.4248846746096849\n",
      "Epoch 116, Loss: 0.4245845355758392\n",
      "Epoch 117, Loss: 0.4235618739445036\n",
      "Epoch 118, Loss: 0.4225511607112974\n",
      "Epoch 119, Loss: 0.42206807486785203\n",
      "Epoch 120, Loss: 0.42155705939784177\n",
      "Epoch 121, Loss: 0.42068991396818806\n",
      "Epoch 122, Loss: 0.4197687268990065\n",
      "Epoch 123, Loss: 0.4192766244460719\n",
      "Epoch 124, Loss: 0.4189126061964323\n",
      "Epoch 125, Loss: 0.4180718232454162\n",
      "Epoch 126, Loss: 0.4171615363910638\n",
      "Epoch 127, Loss: 0.4165512541034883\n",
      "Epoch 128, Loss: 0.41614933282990507\n",
      "Epoch 129, Loss: 0.41564025420684353\n",
      "Epoch 130, Loss: 0.41478382115949214\n",
      "Epoch 131, Loss: 0.41398861063849096\n",
      "Epoch 132, Loss: 0.413437461535855\n",
      "Epoch 133, Loss: 0.413055887775135\n",
      "Epoch 134, Loss: 0.41266249649421777\n",
      "Epoch 135, Loss: 0.4120573942116053\n",
      "Epoch 136, Loss: 0.41127526359296906\n",
      "Epoch 137, Loss: 0.4103501361166681\n",
      "Epoch 138, Loss: 0.40958219046189104\n",
      "Epoch 139, Loss: 0.40898291470067466\n",
      "Epoch 140, Loss: 0.40851493498349417\n",
      "Epoch 141, Loss: 0.4082692106496013\n",
      "Epoch 142, Loss: 0.4083119115108475\n",
      "Epoch 143, Loss: 0.4085478171502095\n",
      "Epoch 144, Loss: 0.40723360636448713\n",
      "Epoch 145, Loss: 0.4055223183351978\n",
      "Epoch 146, Loss: 0.40512801169406226\n",
      "Epoch 147, Loss: 0.4054616835608684\n",
      "Epoch 148, Loss: 0.40488733490600215\n",
      "Epoch 149, Loss: 0.4033542831191125\n",
      "Epoch 150, Loss: 0.4030568183490196\n",
      "Epoch 151, Loss: 0.40338954377530933\n",
      "Epoch 152, Loss: 0.4024266092847303\n",
      "Epoch 153, Loss: 0.40127920778276377\n",
      "Epoch 154, Loss: 0.4010876798449067\n",
      "Epoch 155, Loss: 0.401157983615544\n",
      "Epoch 156, Loss: 0.40050536581795393\n",
      "Epoch 157, Loss: 0.39937069011505866\n",
      "Epoch 158, Loss: 0.39891864672179317\n",
      "Epoch 159, Loss: 0.39907053605534143\n",
      "Epoch 160, Loss: 0.3987078404037666\n",
      "Epoch 161, Loss: 0.39777717850053623\n",
      "Epoch 162, Loss: 0.3969033005904201\n",
      "Epoch 163, Loss: 0.396772834063061\n",
      "Epoch 164, Loss: 0.39675696637768637\n",
      "Epoch 165, Loss: 0.39636503030105935\n",
      "Epoch 166, Loss: 0.39552346657750564\n",
      "Epoch 167, Loss: 0.39474273905197543\n",
      "Epoch 168, Loss: 0.3943057974056607\n",
      "Epoch 169, Loss: 0.39416364029830786\n",
      "Epoch 170, Loss: 0.3940765669064261\n",
      "Epoch 171, Loss: 0.39397054429733835\n",
      "Epoch 172, Loss: 0.39364409082004675\n",
      "Epoch 173, Loss: 0.3929517306212411\n",
      "Epoch 174, Loss: 0.3921573338552525\n",
      "Epoch 175, Loss: 0.39151239688046535\n",
      "Epoch 176, Loss: 0.39119217704321047\n",
      "Epoch 177, Loss: 0.3910709315313626\n",
      "Epoch 178, Loss: 0.3912044423669232\n",
      "Epoch 179, Loss: 0.3915207891328039\n",
      "Epoch 180, Loss: 0.39208117863829556\n",
      "Epoch 181, Loss: 0.39137211877328254\n",
      "Epoch 182, Loss: 0.3900071980655756\n",
      "Epoch 183, Loss: 0.38874584241771987\n",
      "Epoch 184, Loss: 0.3887100009333824\n",
      "Epoch 185, Loss: 0.38934321866212385\n",
      "Epoch 186, Loss: 0.3891931613150758\n",
      "Epoch 187, Loss: 0.3881610599911118\n",
      "Epoch 188, Loss: 0.3872142853604559\n",
      "Epoch 189, Loss: 0.3871460105274143\n",
      "Epoch 190, Loss: 0.3875601698705876\n",
      "Epoch 191, Loss: 0.3873167712259413\n",
      "Epoch 192, Loss: 0.38668566860926284\n",
      "Epoch 193, Loss: 0.3858820601269411\n",
      "Epoch 194, Loss: 0.3855104160559138\n",
      "Epoch 195, Loss: 0.38561379915660543\n",
      "Epoch 196, Loss: 0.38580389374305113\n",
      "Epoch 197, Loss: 0.3859906133019367\n",
      "Epoch 198, Loss: 0.3855346894198539\n",
      "Epoch 199, Loss: 0.3849381384443986\n",
      "Epoch 200, Loss: 0.38420685990572323\n",
      "Epoch 201, Loss: 0.3837416524942185\n",
      "Epoch 202, Loss: 0.38360243668985583\n",
      "Epoch 203, Loss: 0.3836884305998308\n",
      "Epoch 204, Loss: 0.38393430412486257\n",
      "Epoch 205, Loss: 0.38409873369351316\n",
      "Epoch 206, Loss: 0.38426111519074685\n",
      "Epoch 207, Loss: 0.3837240615428643\n",
      "Epoch 208, Loss: 0.38296246997006245\n",
      "Epoch 209, Loss: 0.3820877220681058\n",
      "Epoch 210, Loss: 0.3817517707336468\n",
      "Epoch 211, Loss: 0.381937779262455\n",
      "Epoch 212, Loss: 0.38223542294297985\n",
      "Epoch 213, Loss: 0.3824332168346733\n",
      "Epoch 214, Loss: 0.38199093299735404\n",
      "Epoch 215, Loss: 0.38139630152734944\n",
      "Epoch 216, Loss: 0.38066074375762976\n",
      "Epoch 217, Loss: 0.3802267248678528\n",
      "Epoch 218, Loss: 0.3800993157778801\n",
      "Epoch 219, Loss: 0.38019848728059596\n",
      "Epoch 220, Loss: 0.3805198133851605\n",
      "Epoch 221, Loss: 0.38084057492536605\n",
      "Epoch 222, Loss: 0.381385205480211\n",
      "Epoch 223, Loss: 0.3812987116665588\n",
      "Epoch 224, Loss: 0.38104282753699603\n",
      "Epoch 225, Loss: 0.3795649515189328\n",
      "Epoch 226, Loss: 0.3785026603186983\n",
      "Epoch 227, Loss: 0.3783306981021562\n",
      "Epoch 228, Loss: 0.37876681092223236\n",
      "Epoch 229, Loss: 0.37919627229507114\n",
      "Epoch 230, Loss: 0.37887559353798617\n",
      "Epoch 231, Loss: 0.37811568461521666\n",
      "Epoch 232, Loss: 0.3773083569531587\n",
      "Epoch 233, Loss: 0.3770693071226088\n",
      "Epoch 234, Loss: 0.37728231020692915\n",
      "Epoch 235, Loss: 0.37757869064506533\n",
      "Epoch 236, Loss: 0.3778874573289916\n",
      "Epoch 237, Loss: 0.37775939732292246\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2507955719396563\n",
      "Test R^2 score: 0.32309107650398045\n",
      "Num of epochs: 238\n",
      "Epoch 1, Loss: 0.5594417564154308\n",
      "Epoch 2, Loss: 0.5585398081096768\n",
      "Epoch 3, Loss: 0.5578184282431284\n",
      "Epoch 4, Loss: 0.5572657772242088\n",
      "Epoch 5, Loss: 0.5568501128470023\n",
      "Epoch 6, Loss: 0.5565607113946001\n",
      "Epoch 7, Loss: 0.5563697021787508\n",
      "Epoch 8, Loss: 0.556276516871677\n",
      "Epoch 9, Loss: 0.5562333072343598\n",
      "Epoch 10, Loss: 0.556212196779999\n",
      "Epoch 11, Loss: 0.55620413280359\n",
      "Epoch 12, Loss: 0.5561971939396091\n",
      "Epoch 13, Loss: 0.5561908176098981\n",
      "Epoch 14, Loss: 0.5561827801153597\n",
      "Epoch 15, Loss: 0.5561537102070433\n",
      "Epoch 16, Loss: 0.556102425576449\n",
      "Epoch 17, Loss: 0.5560290272737476\n",
      "Epoch 18, Loss: 0.5559255993466174\n",
      "Epoch 19, Loss: 0.5557871650335997\n",
      "Epoch 20, Loss: 0.5556093266081938\n",
      "Epoch 21, Loss: 0.5553893095530258\n",
      "Epoch 22, Loss: 0.5551268221321257\n",
      "Epoch 23, Loss: 0.5548095300252667\n",
      "Epoch 24, Loss: 0.5544244921760936\n",
      "Epoch 25, Loss: 0.553957875674679\n",
      "Epoch 26, Loss: 0.5533876097392589\n",
      "Epoch 27, Loss: 0.5526879766285959\n",
      "Epoch 28, Loss: 0.5518399877879555\n",
      "Epoch 29, Loss: 0.5508310011450277\n",
      "Epoch 30, Loss: 0.5496434031067469\n",
      "Epoch 31, Loss: 0.5482546161782558\n",
      "Epoch 32, Loss: 0.5466876390212098\n",
      "Epoch 33, Loss: 0.5448709279516639\n",
      "Epoch 34, Loss: 0.5427067900017621\n",
      "Epoch 35, Loss: 0.5400798430402378\n",
      "Epoch 36, Loss: 0.536880499885996\n",
      "Epoch 37, Loss: 0.5330289619138606\n",
      "Epoch 38, Loss: 0.5285150588568949\n",
      "Epoch 39, Loss: 0.5234312085584908\n",
      "Epoch 40, Loss: 0.5179536716573719\n",
      "Epoch 41, Loss: 0.5124908911663137\n",
      "Epoch 42, Loss: 0.508195321963644\n",
      "Epoch 43, Loss: 0.5058463547846275\n",
      "Epoch 44, Loss: 0.5038171733814071\n",
      "Epoch 45, Loss: 0.49996437005409244\n",
      "Epoch 46, Loss: 0.4949822928652395\n",
      "Epoch 47, Loss: 0.49042487527604867\n",
      "Epoch 48, Loss: 0.48705517758729866\n",
      "Epoch 49, Loss: 0.48453865055459067\n",
      "Epoch 50, Loss: 0.4822090853385805\n",
      "Epoch 51, Loss: 0.4797157652041853\n",
      "Epoch 52, Loss: 0.47699142914595305\n",
      "Epoch 53, Loss: 0.47441151894287614\n",
      "Epoch 54, Loss: 0.4725196735635885\n",
      "Epoch 55, Loss: 0.4716631489573122\n",
      "Epoch 56, Loss: 0.4714549696253477\n",
      "Epoch 57, Loss: 0.4709364759792239\n",
      "Epoch 58, Loss: 0.46976316947809116\n",
      "Epoch 59, Loss: 0.46829171029984556\n",
      "Epoch 60, Loss: 0.46708172522525243\n",
      "Epoch 61, Loss: 0.46630327311571057\n",
      "Epoch 62, Loss: 0.46558598156472814\n",
      "Epoch 63, Loss: 0.4646090868866731\n",
      "Epoch 64, Loss: 0.46342403726707726\n",
      "Epoch 65, Loss: 0.46211817225952545\n",
      "Epoch 66, Loss: 0.46085584854817657\n",
      "Epoch 67, Loss: 0.4599325572205856\n",
      "Epoch 68, Loss: 0.4592816627813611\n",
      "Epoch 69, Loss: 0.4587024228529545\n",
      "Epoch 70, Loss: 0.45801633652032625\n",
      "Epoch 71, Loss: 0.4571748328654139\n",
      "Epoch 72, Loss: 0.4564359488483739\n",
      "Epoch 73, Loss: 0.45582855957269963\n",
      "Epoch 74, Loss: 0.4552562676018731\n",
      "Epoch 75, Loss: 0.4547056056871553\n",
      "Epoch 76, Loss: 0.45402271857849247\n",
      "Epoch 77, Loss: 0.45342749331558\n",
      "Epoch 78, Loss: 0.4528116918837008\n",
      "Epoch 79, Loss: 0.4522618260753692\n",
      "Epoch 80, Loss: 0.45159972740284215\n",
      "Epoch 81, Loss: 0.4509415306868147\n",
      "Epoch 82, Loss: 0.4502878817964026\n",
      "Epoch 83, Loss: 0.4497215773956334\n",
      "Epoch 84, Loss: 0.44916457803248844\n",
      "Epoch 85, Loss: 0.4486136964238604\n",
      "Epoch 86, Loss: 0.4479923092009536\n",
      "Epoch 87, Loss: 0.44738171665833837\n",
      "Epoch 88, Loss: 0.446788500036812\n",
      "Epoch 89, Loss: 0.4462335664731202\n",
      "Epoch 90, Loss: 0.4456332540617067\n",
      "Epoch 91, Loss: 0.4450093291408447\n",
      "Epoch 92, Loss: 0.4443558405516248\n",
      "Epoch 93, Loss: 0.44374323289036466\n",
      "Epoch 94, Loss: 0.44313468785315424\n",
      "Epoch 95, Loss: 0.4424786663839575\n",
      "Epoch 96, Loss: 0.44183858443532975\n",
      "Epoch 97, Loss: 0.44120030958150963\n",
      "Epoch 98, Loss: 0.4405435216254828\n",
      "Epoch 99, Loss: 0.4399061622855301\n",
      "Epoch 100, Loss: 0.4392966945701417\n",
      "Epoch 101, Loss: 0.4386860404440717\n",
      "Epoch 102, Loss: 0.4380280679686651\n",
      "Epoch 103, Loss: 0.437367998372935\n",
      "Epoch 104, Loss: 0.4367115033799016\n",
      "Epoch 105, Loss: 0.43605680508070793\n",
      "Epoch 106, Loss: 0.43541446948371665\n",
      "Epoch 107, Loss: 0.4348081645050317\n",
      "Epoch 108, Loss: 0.4344824712891782\n",
      "Epoch 109, Loss: 0.43478170675334465\n",
      "Epoch 110, Loss: 0.43340519078525674\n",
      "Epoch 111, Loss: 0.4324240500956263\n",
      "Epoch 112, Loss: 0.43254884477107663\n",
      "Epoch 113, Loss: 0.43131050155391143\n",
      "Epoch 114, Loss: 0.4309043646363207\n",
      "Epoch 115, Loss: 0.43061068803122027\n",
      "Epoch 116, Loss: 0.42951356662000434\n",
      "Epoch 117, Loss: 0.4295106003489003\n",
      "Epoch 118, Loss: 0.4285984456538338\n",
      "Epoch 119, Loss: 0.42799536698498736\n",
      "Epoch 120, Loss: 0.427666001102443\n",
      "Epoch 121, Loss: 0.4266646783317986\n",
      "Epoch 122, Loss: 0.42639493900000947\n",
      "Epoch 123, Loss: 0.4256808136238595\n",
      "Epoch 124, Loss: 0.4249815824669302\n",
      "Epoch 125, Loss: 0.4246206125914822\n",
      "Epoch 126, Loss: 0.4238009817687216\n",
      "Epoch 127, Loss: 0.42322647002169517\n",
      "Epoch 128, Loss: 0.422835404789945\n",
      "Epoch 129, Loss: 0.4220083696983949\n",
      "Epoch 130, Loss: 0.4213314616903903\n",
      "Epoch 131, Loss: 0.4208526232361772\n",
      "Epoch 132, Loss: 0.42020071663271125\n",
      "Epoch 133, Loss: 0.41942691464596205\n",
      "Epoch 134, Loss: 0.4186867580768841\n",
      "Epoch 135, Loss: 0.418112632015442\n",
      "Epoch 136, Loss: 0.4176265349486938\n",
      "Epoch 137, Loss: 0.41711520450831807\n",
      "Epoch 138, Loss: 0.41677836669327256\n",
      "Epoch 139, Loss: 0.4161572282525699\n",
      "Epoch 140, Loss: 0.4156211989092718\n",
      "Epoch 141, Loss: 0.41451812363887797\n",
      "Epoch 142, Loss: 0.4136408332222143\n",
      "Epoch 143, Loss: 0.41303732655879477\n",
      "Epoch 144, Loss: 0.41267186688154534\n",
      "Epoch 145, Loss: 0.41259691588205577\n",
      "Epoch 146, Loss: 0.41223590951207484\n",
      "Epoch 147, Loss: 0.4117468011844157\n",
      "Epoch 148, Loss: 0.41029282975241016\n",
      "Epoch 149, Loss: 0.4095475903176212\n",
      "Epoch 150, Loss: 0.4095466079364663\n",
      "Epoch 151, Loss: 0.40905371937023116\n",
      "Epoch 152, Loss: 0.4081582952824474\n",
      "Epoch 153, Loss: 0.4071696399451859\n",
      "Epoch 154, Loss: 0.4067582289256656\n",
      "Epoch 155, Loss: 0.4067165007146189\n",
      "Epoch 156, Loss: 0.4062793611039962\n",
      "Epoch 157, Loss: 0.40555614125014966\n",
      "Epoch 158, Loss: 0.4043753358936831\n",
      "Epoch 159, Loss: 0.40364473609365004\n",
      "Epoch 160, Loss: 0.403434737186442\n",
      "Epoch 161, Loss: 0.4033542461760019\n",
      "Epoch 162, Loss: 0.40321369008733815\n",
      "Epoch 163, Loss: 0.40215274758458575\n",
      "Epoch 164, Loss: 0.40110716553243314\n",
      "Epoch 165, Loss: 0.4003535183715388\n",
      "Epoch 166, Loss: 0.4000626500061927\n",
      "Epoch 167, Loss: 0.40007941083621373\n",
      "Epoch 168, Loss: 0.39977939751216063\n",
      "Epoch 169, Loss: 0.3993527241734411\n",
      "Epoch 170, Loss: 0.39834040038305374\n",
      "Epoch 171, Loss: 0.3974927847285373\n",
      "Epoch 172, Loss: 0.39694934509075325\n",
      "Epoch 173, Loss: 0.3967099980654366\n",
      "Epoch 174, Loss: 0.39665782122540105\n",
      "Epoch 175, Loss: 0.39648373608467224\n",
      "Epoch 176, Loss: 0.3962868071407779\n",
      "Epoch 177, Loss: 0.3954691926915266\n",
      "Epoch 178, Loss: 0.39457230307131025\n",
      "Epoch 179, Loss: 0.3938955719108411\n",
      "Epoch 180, Loss: 0.3936306333505211\n",
      "Epoch 181, Loss: 0.39365932692151756\n",
      "Epoch 182, Loss: 0.39370366913832466\n",
      "Epoch 183, Loss: 0.3938342064931077\n",
      "Epoch 184, Loss: 0.3929598646126352\n",
      "Epoch 185, Loss: 0.39195853536976477\n",
      "Epoch 186, Loss: 0.3910808954629618\n",
      "Epoch 187, Loss: 0.39078009387504575\n",
      "Epoch 188, Loss: 0.3908882017330785\n",
      "Epoch 189, Loss: 0.39098017757687076\n",
      "Epoch 190, Loss: 0.39091206493012537\n",
      "Epoch 191, Loss: 0.3899906539102793\n",
      "Epoch 192, Loss: 0.38900499110341846\n",
      "Epoch 193, Loss: 0.38835568242302243\n",
      "Epoch 194, Loss: 0.3881849372888503\n",
      "Epoch 195, Loss: 0.3882538929748395\n",
      "Epoch 196, Loss: 0.3882675559931426\n",
      "Epoch 197, Loss: 0.38830929046635587\n",
      "Epoch 198, Loss: 0.3876735767642185\n",
      "Epoch 199, Loss: 0.3868949758336557\n",
      "Epoch 200, Loss: 0.385970403064063\n",
      "Epoch 201, Loss: 0.38542854015859623\n",
      "Epoch 202, Loss: 0.3852406391910189\n",
      "Epoch 203, Loss: 0.38532508801690857\n",
      "Epoch 204, Loss: 0.38576490118056245\n",
      "Epoch 205, Loss: 0.3860693208383097\n",
      "Epoch 206, Loss: 0.3863277770871099\n",
      "Epoch 207, Loss: 0.3849680605248242\n",
      "Epoch 208, Loss: 0.3836431832713564\n",
      "Epoch 209, Loss: 0.38295941550412826\n",
      "Epoch 210, Loss: 0.38320039054058297\n",
      "Epoch 211, Loss: 0.38368328471337504\n",
      "Epoch 212, Loss: 0.3833641825923161\n",
      "Epoch 213, Loss: 0.38251435093978975\n",
      "Epoch 214, Loss: 0.38163517896344934\n",
      "Epoch 215, Loss: 0.38143046672974207\n",
      "Epoch 216, Loss: 0.38174339792604495\n",
      "Epoch 217, Loss: 0.3818362887251622\n",
      "Epoch 218, Loss: 0.38148568326001947\n",
      "Epoch 219, Loss: 0.38073697201737833\n",
      "Epoch 220, Loss: 0.3800498967602056\n",
      "Epoch 221, Loss: 0.37965552976412636\n",
      "Epoch 222, Loss: 0.3795643822698531\n",
      "Epoch 223, Loss: 0.3796444809643982\n",
      "Epoch 224, Loss: 0.37974384972901526\n",
      "Epoch 225, Loss: 0.379807825213839\n",
      "Epoch 226, Loss: 0.3794403833987559\n",
      "Epoch 227, Loss: 0.3789433923194303\n",
      "Epoch 228, Loss: 0.37821265773031726\n",
      "Epoch 229, Loss: 0.37763910680015317\n",
      "Epoch 230, Loss: 0.3772958966036854\n",
      "Epoch 231, Loss: 0.37708315805392467\n",
      "Epoch 232, Loss: 0.3770050250282623\n",
      "Epoch 233, Loss: 0.37715574363139076\n",
      "Epoch 234, Loss: 0.37767852401861934\n",
      "Epoch 235, Loss: 0.3782400586699547\n",
      "Epoch 236, Loss: 0.37880404558866326\n",
      "Epoch 237, Loss: 0.3776356146860174\n",
      "Epoch 238, Loss: 0.3761363098824978\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2588189478056786\n",
      "Test R^2 score: 0.28054367098416394\n",
      "Num of epochs: 239\n",
      "Epoch 1, Loss: 0.5765135705546673\n",
      "Epoch 2, Loss: 0.5749737194523877\n",
      "Epoch 3, Loss: 0.5734958899599315\n",
      "Epoch 4, Loss: 0.5720795989788705\n",
      "Epoch 5, Loss: 0.5707288815889333\n",
      "Epoch 6, Loss: 0.5694414829420082\n",
      "Epoch 7, Loss: 0.5681786266150569\n",
      "Epoch 8, Loss: 0.5669739870415001\n",
      "Epoch 9, Loss: 0.5658257502280399\n",
      "Epoch 10, Loss: 0.5647588515683527\n",
      "Epoch 11, Loss: 0.5637537177104969\n",
      "Epoch 12, Loss: 0.5628927766863369\n",
      "Epoch 13, Loss: 0.5621024422287629\n",
      "Epoch 14, Loss: 0.5613530174050595\n",
      "Epoch 15, Loss: 0.5606462344057532\n",
      "Epoch 16, Loss: 0.5599786623227486\n",
      "Epoch 17, Loss: 0.5593520932328986\n",
      "Epoch 18, Loss: 0.5587679451315872\n",
      "Epoch 19, Loss: 0.5582362811824012\n",
      "Epoch 20, Loss: 0.5577406604571373\n",
      "Epoch 21, Loss: 0.5572878905789324\n",
      "Epoch 22, Loss: 0.5568903847912196\n",
      "Epoch 23, Loss: 0.5565359987678241\n",
      "Epoch 24, Loss: 0.5562182245929825\n",
      "Epoch 25, Loss: 0.5559291374945651\n",
      "Epoch 26, Loss: 0.5556682459132395\n",
      "Epoch 27, Loss: 0.5554249119796439\n",
      "Epoch 28, Loss: 0.5551830818011634\n",
      "Epoch 29, Loss: 0.5549193421598319\n",
      "Epoch 30, Loss: 0.554600372993696\n",
      "Epoch 31, Loss: 0.5541980894640202\n",
      "Epoch 32, Loss: 0.5536764359531908\n",
      "Epoch 33, Loss: 0.5529997764693872\n",
      "Epoch 34, Loss: 0.5521371803175159\n",
      "Epoch 35, Loss: 0.55105427136875\n",
      "Epoch 36, Loss: 0.5497156209947164\n",
      "Epoch 37, Loss: 0.5480888247323823\n",
      "Epoch 38, Loss: 0.5461435057931047\n",
      "Epoch 39, Loss: 0.5438194471712773\n",
      "Epoch 40, Loss: 0.5410761609965354\n",
      "Epoch 41, Loss: 0.5379490340689269\n",
      "Epoch 42, Loss: 0.5346732082719873\n",
      "Epoch 43, Loss: 0.5317311632364776\n",
      "Epoch 44, Loss: 0.5296334466951649\n",
      "Epoch 45, Loss: 0.5279865162330653\n",
      "Epoch 46, Loss: 0.5256174158190988\n",
      "Epoch 47, Loss: 0.5223739979504542\n",
      "Epoch 48, Loss: 0.5191737500968359\n",
      "Epoch 49, Loss: 0.516651028606676\n",
      "Epoch 50, Loss: 0.5147948662990224\n",
      "Epoch 51, Loss: 0.5131115486249761\n",
      "Epoch 52, Loss: 0.5111933916085649\n",
      "Epoch 53, Loss: 0.5089860121260785\n",
      "Epoch 54, Loss: 0.5067307908906321\n",
      "Epoch 55, Loss: 0.5048231609825015\n",
      "Epoch 56, Loss: 0.5033931633566502\n",
      "Epoch 57, Loss: 0.50199070652494\n",
      "Epoch 58, Loss: 0.5001388297463059\n",
      "Epoch 59, Loss: 0.4980760453601374\n",
      "Epoch 60, Loss: 0.4963349034059532\n",
      "Epoch 61, Loss: 0.4949871998634701\n",
      "Epoch 62, Loss: 0.4936255835459417\n",
      "Epoch 63, Loss: 0.4920182618322466\n",
      "Epoch 64, Loss: 0.4903197954995405\n",
      "Epoch 65, Loss: 0.48882156994414694\n",
      "Epoch 66, Loss: 0.4875684800100967\n",
      "Epoch 67, Loss: 0.48625766289662226\n",
      "Epoch 68, Loss: 0.48478570569150453\n",
      "Epoch 69, Loss: 0.4833689979296988\n",
      "Epoch 70, Loss: 0.4821440634258257\n",
      "Epoch 71, Loss: 0.4809333291966641\n",
      "Epoch 72, Loss: 0.4795916545432147\n",
      "Epoch 73, Loss: 0.4782433650039601\n",
      "Epoch 74, Loss: 0.4770702096502783\n",
      "Epoch 75, Loss: 0.4759684596821895\n",
      "Epoch 76, Loss: 0.47474354546826186\n",
      "Epoch 77, Loss: 0.4735260518670527\n",
      "Epoch 78, Loss: 0.47245498975185246\n",
      "Epoch 79, Loss: 0.47132239225857236\n",
      "Epoch 80, Loss: 0.4701111264188747\n",
      "Epoch 81, Loss: 0.4690758843898136\n",
      "Epoch 82, Loss: 0.46806549320494023\n",
      "Epoch 83, Loss: 0.46693400838652177\n",
      "Epoch 84, Loss: 0.46588083189969853\n",
      "Epoch 85, Loss: 0.46482264046060645\n",
      "Epoch 86, Loss: 0.4636820855498783\n",
      "Epoch 87, Loss: 0.4626842151243376\n",
      "Epoch 88, Loss: 0.4616430991947832\n",
      "Epoch 89, Loss: 0.4606969820091405\n",
      "Epoch 90, Loss: 0.4597664845214692\n",
      "Epoch 91, Loss: 0.4588196966305516\n",
      "Epoch 92, Loss: 0.4579086359006537\n",
      "Epoch 93, Loss: 0.4570116055171071\n",
      "Epoch 94, Loss: 0.45617045336157347\n",
      "Epoch 95, Loss: 0.4553244092139136\n",
      "Epoch 96, Loss: 0.4545394099169575\n",
      "Epoch 97, Loss: 0.45373584417850577\n",
      "Epoch 98, Loss: 0.45299506790958266\n",
      "Epoch 99, Loss: 0.452228217779687\n",
      "Epoch 100, Loss: 0.45147815233369276\n",
      "Epoch 101, Loss: 0.4507670547392331\n",
      "Epoch 102, Loss: 0.45000064637879467\n",
      "Epoch 103, Loss: 0.44933582936328487\n",
      "Epoch 104, Loss: 0.4486361997125257\n",
      "Epoch 105, Loss: 0.4479903799954909\n",
      "Epoch 106, Loss: 0.4473540705890357\n",
      "Epoch 107, Loss: 0.4466468328578675\n",
      "Epoch 108, Loss: 0.4459907319256332\n",
      "Epoch 109, Loss: 0.44539454189599653\n",
      "Epoch 110, Loss: 0.44477319686504424\n",
      "Epoch 111, Loss: 0.4441801363934604\n",
      "Epoch 112, Loss: 0.44367700701776724\n",
      "Epoch 113, Loss: 0.44317386123765706\n",
      "Epoch 114, Loss: 0.44262170130985273\n",
      "Epoch 115, Loss: 0.442133801842614\n",
      "Epoch 116, Loss: 0.4416961224498259\n",
      "Epoch 117, Loss: 0.4412832341902907\n",
      "Epoch 118, Loss: 0.44087653319197956\n",
      "Epoch 119, Loss: 0.44046874623807786\n",
      "Epoch 120, Loss: 0.44006735367462485\n",
      "Epoch 121, Loss: 0.43965461350402874\n",
      "Epoch 122, Loss: 0.4391983989396296\n",
      "Epoch 123, Loss: 0.438726256372017\n",
      "Epoch 124, Loss: 0.4381704472575443\n",
      "Epoch 125, Loss: 0.4376116678233217\n",
      "Epoch 126, Loss: 0.43716370054938625\n",
      "Epoch 127, Loss: 0.4367873825436399\n",
      "Epoch 128, Loss: 0.43644916832829683\n",
      "Epoch 129, Loss: 0.4360255873635094\n",
      "Epoch 130, Loss: 0.4354787011954869\n",
      "Epoch 131, Loss: 0.43496871002611465\n",
      "Epoch 132, Loss: 0.4345915542725915\n",
      "Epoch 133, Loss: 0.4342132301432707\n",
      "Epoch 134, Loss: 0.43373514567727606\n",
      "Epoch 135, Loss: 0.4331822547666589\n",
      "Epoch 136, Loss: 0.43266392578061125\n",
      "Epoch 137, Loss: 0.43215802627982935\n",
      "Epoch 138, Loss: 0.43161999752416935\n",
      "Epoch 139, Loss: 0.4310197810017092\n",
      "Epoch 140, Loss: 0.4303382973566867\n",
      "Epoch 141, Loss: 0.4296152227475116\n",
      "Epoch 142, Loss: 0.42890710187872555\n",
      "Epoch 143, Loss: 0.4282877577879072\n",
      "Epoch 144, Loss: 0.4276981599709293\n",
      "Epoch 145, Loss: 0.4271221918555774\n",
      "Epoch 146, Loss: 0.426508326461477\n",
      "Epoch 147, Loss: 0.4258675444062045\n",
      "Epoch 148, Loss: 0.42523695777278314\n",
      "Epoch 149, Loss: 0.4245905720215673\n",
      "Epoch 150, Loss: 0.42388722231856596\n",
      "Epoch 151, Loss: 0.42320921751428675\n",
      "Epoch 152, Loss: 0.4225888570479552\n",
      "Epoch 153, Loss: 0.4220071691530085\n",
      "Epoch 154, Loss: 0.42146841519237044\n",
      "Epoch 155, Loss: 0.42095925584289445\n",
      "Epoch 156, Loss: 0.4204860534566428\n",
      "Epoch 157, Loss: 0.4200011777293632\n",
      "Epoch 158, Loss: 0.41942243816564023\n",
      "Epoch 159, Loss: 0.41876540511533195\n",
      "Epoch 160, Loss: 0.41800874893030826\n",
      "Epoch 161, Loss: 0.41728657464005736\n",
      "Epoch 162, Loss: 0.416653265340185\n",
      "Epoch 163, Loss: 0.41616757622144424\n",
      "Epoch 164, Loss: 0.41572300823789093\n",
      "Epoch 165, Loss: 0.41528035050207973\n",
      "Epoch 166, Loss: 0.41490632571241043\n",
      "Epoch 167, Loss: 0.41459348209297975\n",
      "Epoch 168, Loss: 0.4143286875049766\n",
      "Epoch 169, Loss: 0.4137513233002306\n",
      "Epoch 170, Loss: 0.4129538719507952\n",
      "Epoch 171, Loss: 0.41219258485308286\n",
      "Epoch 172, Loss: 0.41184197016996504\n",
      "Epoch 173, Loss: 0.4116223064870832\n",
      "Epoch 174, Loss: 0.41112036244440625\n",
      "Epoch 175, Loss: 0.4103806926077995\n",
      "Epoch 176, Loss: 0.40981400152422653\n",
      "Epoch 177, Loss: 0.4095226298286972\n",
      "Epoch 178, Loss: 0.4093167933368341\n",
      "Epoch 179, Loss: 0.40891627024295846\n",
      "Epoch 180, Loss: 0.40828961272932635\n",
      "Epoch 181, Loss: 0.40755018004276666\n",
      "Epoch 182, Loss: 0.407019692987245\n",
      "Epoch 183, Loss: 0.4067149802468131\n",
      "Epoch 184, Loss: 0.4065217429747334\n",
      "Epoch 185, Loss: 0.40636150957148953\n",
      "Epoch 186, Loss: 0.40603162324768305\n",
      "Epoch 187, Loss: 0.4054854240737591\n",
      "Epoch 188, Loss: 0.4047702837191637\n",
      "Epoch 189, Loss: 0.40422768853165403\n",
      "Epoch 190, Loss: 0.4040085506195306\n",
      "Epoch 191, Loss: 0.40389515549790156\n",
      "Epoch 192, Loss: 0.40372444945941605\n",
      "Epoch 193, Loss: 0.40329117935295206\n",
      "Epoch 194, Loss: 0.4027355656573865\n",
      "Epoch 195, Loss: 0.40207867084362797\n",
      "Epoch 196, Loss: 0.4015704380542163\n",
      "Epoch 197, Loss: 0.40129684611506317\n",
      "Epoch 198, Loss: 0.40113985626607074\n",
      "Epoch 199, Loss: 0.40101056370531524\n",
      "Epoch 200, Loss: 0.40070468401740394\n",
      "Epoch 201, Loss: 0.4002878010535602\n",
      "Epoch 202, Loss: 0.39969026673457686\n",
      "Epoch 203, Loss: 0.3991292483638003\n",
      "Epoch 204, Loss: 0.39874293270245864\n",
      "Epoch 205, Loss: 0.3984702601708961\n",
      "Epoch 206, Loss: 0.39829475987516905\n",
      "Epoch 207, Loss: 0.39819021592106874\n",
      "Epoch 208, Loss: 0.398425232941523\n",
      "Epoch 209, Loss: 0.3984756077512939\n",
      "Epoch 210, Loss: 0.3985275279041567\n",
      "Epoch 211, Loss: 0.3978048800018084\n",
      "Epoch 212, Loss: 0.39673775530105937\n",
      "Epoch 213, Loss: 0.3962233299461828\n",
      "Epoch 214, Loss: 0.3964508305533104\n",
      "Epoch 215, Loss: 0.39644654568006693\n",
      "Epoch 216, Loss: 0.39599496486140723\n",
      "Epoch 217, Loss: 0.3953625259108018\n",
      "Epoch 218, Loss: 0.39488640464622826\n",
      "Epoch 219, Loss: 0.39492366650757027\n",
      "Epoch 220, Loss: 0.39515197193489254\n",
      "Epoch 221, Loss: 0.39510577454538576\n",
      "Epoch 222, Loss: 0.39483523224918393\n",
      "Epoch 223, Loss: 0.3941042260412613\n",
      "Epoch 224, Loss: 0.3933028179524582\n",
      "Epoch 225, Loss: 0.39321610342731417\n",
      "Epoch 226, Loss: 0.39337780860962523\n",
      "Epoch 227, Loss: 0.3935400531783516\n",
      "Epoch 228, Loss: 0.3933691718691318\n",
      "Epoch 229, Loss: 0.39271271709083166\n",
      "Epoch 230, Loss: 0.3919134443915637\n",
      "Epoch 231, Loss: 0.391961253589257\n",
      "Epoch 232, Loss: 0.3920888746351757\n",
      "Epoch 233, Loss: 0.39212606032388986\n",
      "Epoch 234, Loss: 0.3918382495397018\n",
      "Epoch 235, Loss: 0.39113276858126184\n",
      "Epoch 236, Loss: 0.3906973390354844\n",
      "Epoch 237, Loss: 0.3906522359889737\n",
      "Epoch 238, Loss: 0.3906924189561659\n",
      "Epoch 239, Loss: 0.39071129799303495\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2377750851923821\n",
      "Test R^2 score: 0.3895534226880654\n",
      "Num of epochs: 240\n",
      "Epoch 1, Loss: 0.5925307806284857\n",
      "Epoch 2, Loss: 0.5903343787513421\n",
      "Epoch 3, Loss: 0.588210896291074\n",
      "Epoch 4, Loss: 0.5861562701942834\n",
      "Epoch 5, Loss: 0.5842466754059717\n",
      "Epoch 6, Loss: 0.5825295843134648\n",
      "Epoch 7, Loss: 0.5808799673302718\n",
      "Epoch 8, Loss: 0.5792731662870871\n",
      "Epoch 9, Loss: 0.577719056169457\n",
      "Epoch 10, Loss: 0.5762175461076765\n",
      "Epoch 11, Loss: 0.5747844737857492\n",
      "Epoch 12, Loss: 0.5733971199557408\n",
      "Epoch 13, Loss: 0.5720473253939633\n",
      "Epoch 14, Loss: 0.5707364792577827\n",
      "Epoch 15, Loss: 0.5694798439802886\n",
      "Epoch 16, Loss: 0.5682764418878178\n",
      "Epoch 17, Loss: 0.5671065637939497\n",
      "Epoch 18, Loss: 0.5659835816890063\n",
      "Epoch 19, Loss: 0.5649095425732187\n",
      "Epoch 20, Loss: 0.5638802865452217\n",
      "Epoch 21, Loss: 0.5629052186089382\n",
      "Epoch 22, Loss: 0.5619833746025736\n",
      "Epoch 23, Loss: 0.5611036240620598\n",
      "Epoch 24, Loss: 0.5602752878285796\n",
      "Epoch 25, Loss: 0.5595439751570078\n",
      "Epoch 26, Loss: 0.5588713536340864\n",
      "Epoch 27, Loss: 0.5582600110100665\n",
      "Epoch 28, Loss: 0.557714877949351\n",
      "Epoch 29, Loss: 0.5572024270976976\n",
      "Epoch 30, Loss: 0.5567103024424515\n",
      "Epoch 31, Loss: 0.5562606049716148\n",
      "Epoch 32, Loss: 0.5559307993441621\n",
      "Epoch 33, Loss: 0.5556232725702301\n",
      "Epoch 34, Loss: 0.5553345197477563\n",
      "Epoch 35, Loss: 0.555047818134371\n",
      "Epoch 36, Loss: 0.5547552738961876\n",
      "Epoch 37, Loss: 0.5544319907551019\n",
      "Epoch 38, Loss: 0.5540622894923568\n",
      "Epoch 39, Loss: 0.5536200231766398\n",
      "Epoch 40, Loss: 0.5530851080350963\n",
      "Epoch 41, Loss: 0.552406834044366\n",
      "Epoch 42, Loss: 0.5515688412223454\n",
      "Epoch 43, Loss: 0.5505338884415896\n",
      "Epoch 44, Loss: 0.5492523834218475\n",
      "Epoch 45, Loss: 0.5476793368666147\n",
      "Epoch 46, Loss: 0.545736490156685\n",
      "Epoch 47, Loss: 0.5433540349460703\n",
      "Epoch 48, Loss: 0.5404348182227877\n",
      "Epoch 49, Loss: 0.5368850239449654\n",
      "Epoch 50, Loss: 0.5326742826382036\n",
      "Epoch 51, Loss: 0.5278002423251551\n",
      "Epoch 52, Loss: 0.5223665241248482\n",
      "Epoch 53, Loss: 0.5166724864826777\n",
      "Epoch 54, Loss: 0.5111026112165269\n",
      "Epoch 55, Loss: 0.5060672406576057\n",
      "Epoch 56, Loss: 0.5014045181315829\n",
      "Epoch 57, Loss: 0.49627143201021484\n",
      "Epoch 58, Loss: 0.4903169539609741\n",
      "Epoch 59, Loss: 0.4846221846862047\n",
      "Epoch 60, Loss: 0.480374924097147\n",
      "Epoch 61, Loss: 0.4784420034643866\n",
      "Epoch 62, Loss: 0.4786908510088098\n",
      "Epoch 63, Loss: 0.47837662526959274\n",
      "Epoch 64, Loss: 0.47521721804701716\n",
      "Epoch 65, Loss: 0.47129754170687843\n",
      "Epoch 66, Loss: 0.4708710683481782\n",
      "Epoch 67, Loss: 0.47073251782844\n",
      "Epoch 68, Loss: 0.46753610152827946\n",
      "Epoch 69, Loss: 0.4654401431428031\n",
      "Epoch 70, Loss: 0.4656238741509056\n",
      "Epoch 71, Loss: 0.4661361455354645\n",
      "Epoch 72, Loss: 0.4656566116303955\n",
      "Epoch 73, Loss: 0.46437491487525373\n",
      "Epoch 74, Loss: 0.46312397093150187\n",
      "Epoch 75, Loss: 0.46243103969519544\n",
      "Epoch 76, Loss: 0.4619540465391049\n",
      "Epoch 77, Loss: 0.46093575428777606\n",
      "Epoch 78, Loss: 0.4592486817689353\n",
      "Epoch 79, Loss: 0.4577115367446824\n",
      "Epoch 80, Loss: 0.4568604207093612\n",
      "Epoch 81, Loss: 0.45628749614949976\n",
      "Epoch 82, Loss: 0.45543826673518273\n",
      "Epoch 83, Loss: 0.45438448388382946\n",
      "Epoch 84, Loss: 0.45369761558677163\n",
      "Epoch 85, Loss: 0.4533545636045501\n",
      "Epoch 86, Loss: 0.4525245601617142\n",
      "Epoch 87, Loss: 0.4515052323508158\n",
      "Epoch 88, Loss: 0.4508658523107506\n",
      "Epoch 89, Loss: 0.45019638822679403\n",
      "Epoch 90, Loss: 0.4492495484782366\n",
      "Epoch 91, Loss: 0.448503455518724\n",
      "Epoch 92, Loss: 0.4480079920026077\n",
      "Epoch 93, Loss: 0.44727180510003484\n",
      "Epoch 94, Loss: 0.4465721284430296\n",
      "Epoch 95, Loss: 0.4460785617681254\n",
      "Epoch 96, Loss: 0.4453840532873579\n",
      "Epoch 97, Loss: 0.44465060986475213\n",
      "Epoch 98, Loss: 0.4441701391071236\n",
      "Epoch 99, Loss: 0.44343003369552086\n",
      "Epoch 100, Loss: 0.4428186354013558\n",
      "Epoch 101, Loss: 0.4422674470751759\n",
      "Epoch 102, Loss: 0.44153873177155617\n",
      "Epoch 103, Loss: 0.44104221828079626\n",
      "Epoch 104, Loss: 0.44030166084696276\n",
      "Epoch 105, Loss: 0.43972025911236096\n",
      "Epoch 106, Loss: 0.43904089348461783\n",
      "Epoch 107, Loss: 0.43842111419597585\n",
      "Epoch 108, Loss: 0.43781313589132936\n",
      "Epoch 109, Loss: 0.43720456775127164\n",
      "Epoch 110, Loss: 0.43661209673944956\n",
      "Epoch 111, Loss: 0.4360329861816538\n",
      "Epoch 112, Loss: 0.4354498374508528\n",
      "Epoch 113, Loss: 0.4349016448068555\n",
      "Epoch 114, Loss: 0.43428239178238087\n",
      "Epoch 115, Loss: 0.4337688814060693\n",
      "Epoch 116, Loss: 0.433131581651407\n",
      "Epoch 117, Loss: 0.43260074007272575\n",
      "Epoch 118, Loss: 0.4319773262683209\n",
      "Epoch 119, Loss: 0.4313822011520669\n",
      "Epoch 120, Loss: 0.43081696925023455\n",
      "Epoch 121, Loss: 0.4302184898833985\n",
      "Epoch 122, Loss: 0.4296840840984162\n",
      "Epoch 123, Loss: 0.42911125036736236\n",
      "Epoch 124, Loss: 0.4284870023391955\n",
      "Epoch 125, Loss: 0.42796244702636754\n",
      "Epoch 126, Loss: 0.4274328379549015\n",
      "Epoch 127, Loss: 0.42681797048772346\n",
      "Epoch 128, Loss: 0.42623782395006793\n",
      "Epoch 129, Loss: 0.42570643686401877\n",
      "Epoch 130, Loss: 0.4251502374562472\n",
      "Epoch 131, Loss: 0.42457397158930077\n",
      "Epoch 132, Loss: 0.42399518284782806\n",
      "Epoch 133, Loss: 0.42345735707474363\n",
      "Epoch 134, Loss: 0.42291516537078827\n",
      "Epoch 135, Loss: 0.422521272778355\n",
      "Epoch 136, Loss: 0.4221926129340002\n",
      "Epoch 137, Loss: 0.42223995811803694\n",
      "Epoch 138, Loss: 0.42091343049785496\n",
      "Epoch 139, Loss: 0.4200592348641315\n",
      "Epoch 140, Loss: 0.41989094819911843\n",
      "Epoch 141, Loss: 0.4195322224980454\n",
      "Epoch 142, Loss: 0.41899242002896087\n",
      "Epoch 143, Loss: 0.41799892780061493\n",
      "Epoch 144, Loss: 0.4175837874140136\n",
      "Epoch 145, Loss: 0.417603984206932\n",
      "Epoch 146, Loss: 0.416906468606315\n",
      "Epoch 147, Loss: 0.41614374686216615\n",
      "Epoch 148, Loss: 0.41539677183300094\n",
      "Epoch 149, Loss: 0.4151591407752764\n",
      "Epoch 150, Loss: 0.4152082031270212\n",
      "Epoch 151, Loss: 0.41434028592277455\n",
      "Epoch 152, Loss: 0.4135309081836119\n",
      "Epoch 153, Loss: 0.41307654043200265\n",
      "Epoch 154, Loss: 0.4128275935946133\n",
      "Epoch 155, Loss: 0.4126067211351658\n",
      "Epoch 156, Loss: 0.4117421869197937\n",
      "Epoch 157, Loss: 0.4111253098915535\n",
      "Epoch 158, Loss: 0.410583854483466\n",
      "Epoch 159, Loss: 0.41020245972950925\n",
      "Epoch 160, Loss: 0.40988617133935895\n",
      "Epoch 161, Loss: 0.40951542520640094\n",
      "Epoch 162, Loss: 0.40938910540092743\n",
      "Epoch 163, Loss: 0.4089112414068886\n",
      "Epoch 164, Loss: 0.4085551847270125\n",
      "Epoch 165, Loss: 0.4076999501688882\n",
      "Epoch 166, Loss: 0.40702273164061653\n",
      "Epoch 167, Loss: 0.40629289473978303\n",
      "Epoch 168, Loss: 0.4058568042016507\n",
      "Epoch 169, Loss: 0.4056195355416099\n",
      "Epoch 170, Loss: 0.4055945353830676\n",
      "Epoch 171, Loss: 0.406043697206611\n",
      "Epoch 172, Loss: 0.4054698789724167\n",
      "Epoch 173, Loss: 0.4048664853401088\n",
      "Epoch 174, Loss: 0.4033013586435245\n",
      "Epoch 175, Loss: 0.4031010694571929\n",
      "Epoch 176, Loss: 0.4039879692240866\n",
      "Epoch 177, Loss: 0.4034143296730724\n",
      "Epoch 178, Loss: 0.4019653244317437\n",
      "Epoch 179, Loss: 0.40134062296257994\n",
      "Epoch 180, Loss: 0.4015414006074427\n",
      "Epoch 181, Loss: 0.4019128288037295\n",
      "Epoch 182, Loss: 0.40028620032725576\n",
      "Epoch 183, Loss: 0.3998808429979179\n",
      "Epoch 184, Loss: 0.40004153036051593\n",
      "Epoch 185, Loss: 0.39991845924035047\n",
      "Epoch 186, Loss: 0.39897090138425784\n",
      "Epoch 187, Loss: 0.39811761019808606\n",
      "Epoch 188, Loss: 0.39777028560279376\n",
      "Epoch 189, Loss: 0.39820941305631163\n",
      "Epoch 190, Loss: 0.3973737616386209\n",
      "Epoch 191, Loss: 0.39673116360294186\n",
      "Epoch 192, Loss: 0.3960231672973397\n",
      "Epoch 193, Loss: 0.3958995997859265\n",
      "Epoch 194, Loss: 0.39565946709066374\n",
      "Epoch 195, Loss: 0.3954956429575475\n",
      "Epoch 196, Loss: 0.3953616967328485\n",
      "Epoch 197, Loss: 0.39486953660204965\n",
      "Epoch 198, Loss: 0.3941236411027986\n",
      "Epoch 199, Loss: 0.39364098674694104\n",
      "Epoch 200, Loss: 0.3930728129936915\n",
      "Epoch 201, Loss: 0.3925650295521646\n",
      "Epoch 202, Loss: 0.39213609244526987\n",
      "Epoch 203, Loss: 0.3917822290271224\n",
      "Epoch 204, Loss: 0.39151645030371496\n",
      "Epoch 205, Loss: 0.39136402793253877\n",
      "Epoch 206, Loss: 0.3917374791223983\n",
      "Epoch 207, Loss: 0.3938590262105746\n",
      "Epoch 208, Loss: 0.39318593737052654\n",
      "Epoch 209, Loss: 0.3922728115168796\n",
      "Epoch 210, Loss: 0.3893326552926217\n",
      "Epoch 211, Loss: 0.3899480294176953\n",
      "Epoch 212, Loss: 0.3922215830670433\n",
      "Epoch 213, Loss: 0.3888151968473239\n",
      "Epoch 214, Loss: 0.38860886029421854\n",
      "Epoch 215, Loss: 0.39115435019142447\n",
      "Epoch 216, Loss: 0.3883154878929636\n",
      "Epoch 217, Loss: 0.3872115338173152\n",
      "Epoch 218, Loss: 0.38924329532515944\n",
      "Epoch 219, Loss: 0.3874649401155227\n",
      "Epoch 220, Loss: 0.3862700122599373\n",
      "Epoch 221, Loss: 0.3862198974088602\n",
      "Epoch 222, Loss: 0.3869417299086565\n",
      "Epoch 223, Loss: 0.38683723792321995\n",
      "Epoch 224, Loss: 0.38517075718298166\n",
      "Epoch 225, Loss: 0.3852503864625531\n",
      "Epoch 226, Loss: 0.38656840629043665\n",
      "Epoch 227, Loss: 0.38514622874502824\n",
      "Epoch 228, Loss: 0.3837370703814681\n",
      "Epoch 229, Loss: 0.384556553770332\n",
      "Epoch 230, Loss: 0.3846855854882354\n",
      "Epoch 231, Loss: 0.38472668213483685\n",
      "Epoch 232, Loss: 0.38255936174456323\n",
      "Epoch 233, Loss: 0.3839644014552054\n",
      "Epoch 234, Loss: 0.38552226303991266\n",
      "Epoch 235, Loss: 0.3831589940720087\n",
      "Epoch 236, Loss: 0.38199348809149275\n",
      "Epoch 237, Loss: 0.3849194214457937\n",
      "Epoch 238, Loss: 0.3823493958973393\n",
      "Epoch 239, Loss: 0.38134662076098813\n",
      "Epoch 240, Loss: 0.38122541004363736\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.23402834670262582\n",
      "Test R^2 score: 0.4109461631124342\n",
      "Num of epochs: 241\n",
      "Epoch 1, Loss: 0.569434025004928\n",
      "Epoch 2, Loss: 0.5678750297954467\n",
      "Epoch 3, Loss: 0.5664160102792544\n",
      "Epoch 4, Loss: 0.5651475271533175\n",
      "Epoch 5, Loss: 0.5640461916692583\n",
      "Epoch 6, Loss: 0.5630281935453941\n",
      "Epoch 7, Loss: 0.5620843093086896\n",
      "Epoch 8, Loss: 0.5612416762943313\n",
      "Epoch 9, Loss: 0.5605044465173625\n",
      "Epoch 10, Loss: 0.5598086769814172\n",
      "Epoch 11, Loss: 0.5591748023211146\n",
      "Epoch 12, Loss: 0.5586056207849371\n",
      "Epoch 13, Loss: 0.5581022380958961\n",
      "Epoch 14, Loss: 0.5576637636096969\n",
      "Epoch 15, Loss: 0.5572895483766981\n",
      "Epoch 16, Loss: 0.5569774211111612\n",
      "Epoch 17, Loss: 0.5567243546539161\n",
      "Epoch 18, Loss: 0.5565265471697614\n",
      "Epoch 19, Loss: 0.5563795313945222\n",
      "Epoch 20, Loss: 0.5562780705344977\n",
      "Epoch 21, Loss: 0.5562172601472949\n",
      "Epoch 22, Loss: 0.5561891565372152\n",
      "Epoch 23, Loss: 0.5561872007517294\n",
      "Epoch 24, Loss: 0.5562018823707027\n",
      "Epoch 25, Loss: 0.5562270652671959\n",
      "Epoch 26, Loss: 0.5562556759405404\n",
      "Epoch 27, Loss: 0.5562815528664365\n",
      "Epoch 28, Loss: 0.5562993659927017\n",
      "Epoch 29, Loss: 0.5563047499983096\n",
      "Epoch 30, Loss: 0.5562946248102881\n",
      "Epoch 31, Loss: 0.556266792986835\n",
      "Epoch 32, Loss: 0.5562203142195687\n",
      "Epoch 33, Loss: 0.5561538441732394\n",
      "Epoch 34, Loss: 0.5560641599812384\n",
      "Epoch 35, Loss: 0.5559486237089061\n",
      "Epoch 36, Loss: 0.5558114551897694\n",
      "Epoch 37, Loss: 0.5556579750411416\n",
      "Epoch 38, Loss: 0.5554817047969176\n",
      "Epoch 39, Loss: 0.5552778728897008\n",
      "Epoch 40, Loss: 0.5550379921822756\n",
      "Epoch 41, Loss: 0.5547493644923884\n",
      "Epoch 42, Loss: 0.554394281819677\n",
      "Epoch 43, Loss: 0.5539375393185392\n",
      "Epoch 44, Loss: 0.5533551615503854\n",
      "Epoch 45, Loss: 0.5526243444049279\n",
      "Epoch 46, Loss: 0.5517302379638326\n",
      "Epoch 47, Loss: 0.5506506961278101\n",
      "Epoch 48, Loss: 0.5493488217432239\n",
      "Epoch 49, Loss: 0.5478008063156862\n",
      "Epoch 50, Loss: 0.5459771824582323\n",
      "Epoch 51, Loss: 0.5438269001744609\n",
      "Epoch 52, Loss: 0.5412564619528745\n",
      "Epoch 53, Loss: 0.5381592633086757\n",
      "Epoch 54, Loss: 0.534442732238318\n",
      "Epoch 55, Loss: 0.5300507191915377\n",
      "Epoch 56, Loss: 0.5249981743917059\n",
      "Epoch 57, Loss: 0.5193941609489576\n",
      "Epoch 58, Loss: 0.5135815327035235\n",
      "Epoch 59, Loss: 0.5084310725578971\n",
      "Epoch 60, Loss: 0.5053832711489542\n",
      "Epoch 61, Loss: 0.5050529031142706\n",
      "Epoch 62, Loss: 0.5036642099504034\n",
      "Epoch 63, Loss: 0.498952274511367\n",
      "Epoch 64, Loss: 0.4929565446312979\n",
      "Epoch 65, Loss: 0.48806277155615196\n",
      "Epoch 66, Loss: 0.48532245633142496\n",
      "Epoch 67, Loss: 0.4840578456036762\n",
      "Epoch 68, Loss: 0.4828740367746485\n",
      "Epoch 69, Loss: 0.4815628496350722\n",
      "Epoch 70, Loss: 0.48068612306541725\n",
      "Epoch 71, Loss: 0.4797122861938493\n",
      "Epoch 72, Loss: 0.4785296068289743\n",
      "Epoch 73, Loss: 0.47771347698875666\n",
      "Epoch 74, Loss: 0.4768052342829202\n",
      "Epoch 75, Loss: 0.4755499040868456\n",
      "Epoch 76, Loss: 0.4738878173211656\n",
      "Epoch 77, Loss: 0.472724531301639\n",
      "Epoch 78, Loss: 0.47217140867130153\n",
      "Epoch 79, Loss: 0.47196781054139764\n",
      "Epoch 80, Loss: 0.47167381140798303\n",
      "Epoch 81, Loss: 0.4710348709282104\n",
      "Epoch 82, Loss: 0.4698865146286575\n",
      "Epoch 83, Loss: 0.4684866006221539\n",
      "Epoch 84, Loss: 0.4673155771715135\n",
      "Epoch 85, Loss: 0.46659077200342597\n",
      "Epoch 86, Loss: 0.46619921295164224\n",
      "Epoch 87, Loss: 0.4657402049666089\n",
      "Epoch 88, Loss: 0.4650240476348019\n",
      "Epoch 89, Loss: 0.46409895076230345\n",
      "Epoch 90, Loss: 0.4631925475453291\n",
      "Epoch 91, Loss: 0.46243637265891463\n",
      "Epoch 92, Loss: 0.4617388596649504\n",
      "Epoch 93, Loss: 0.4610627376012305\n",
      "Epoch 94, Loss: 0.4605583635989027\n",
      "Epoch 95, Loss: 0.4601459009791067\n",
      "Epoch 96, Loss: 0.4595885014207391\n",
      "Epoch 97, Loss: 0.45888672459503516\n",
      "Epoch 98, Loss: 0.4582333853145074\n",
      "Epoch 99, Loss: 0.4576653865841224\n",
      "Epoch 100, Loss: 0.4570567458124534\n",
      "Epoch 101, Loss: 0.45620929131421956\n",
      "Epoch 102, Loss: 0.45532362377792585\n",
      "Epoch 103, Loss: 0.4546674422464207\n",
      "Epoch 104, Loss: 0.4540298569373211\n",
      "Epoch 105, Loss: 0.4534682092185611\n",
      "Epoch 106, Loss: 0.4530454927605259\n",
      "Epoch 107, Loss: 0.45243836041023655\n",
      "Epoch 108, Loss: 0.45185503080572303\n",
      "Epoch 109, Loss: 0.4513545801703875\n",
      "Epoch 110, Loss: 0.4507591374360268\n",
      "Epoch 111, Loss: 0.450245058037866\n",
      "Epoch 112, Loss: 0.4498273955562544\n",
      "Epoch 113, Loss: 0.4493094974576158\n",
      "Epoch 114, Loss: 0.4488697852711112\n",
      "Epoch 115, Loss: 0.448411514778768\n",
      "Epoch 116, Loss: 0.4479393029222576\n",
      "Epoch 117, Loss: 0.4475545158425189\n",
      "Epoch 118, Loss: 0.44712115957302756\n",
      "Epoch 119, Loss: 0.4467254441764767\n",
      "Epoch 120, Loss: 0.44631879444542233\n",
      "Epoch 121, Loss: 0.44593503169423876\n",
      "Epoch 122, Loss: 0.44553766079544876\n",
      "Epoch 123, Loss: 0.44509104191184506\n",
      "Epoch 124, Loss: 0.44461094656401584\n",
      "Epoch 125, Loss: 0.4441323620942669\n",
      "Epoch 126, Loss: 0.44359894720232923\n",
      "Epoch 127, Loss: 0.4431737267426901\n",
      "Epoch 128, Loss: 0.4427103173454557\n",
      "Epoch 129, Loss: 0.4422846805286102\n",
      "Epoch 130, Loss: 0.4418637596923722\n",
      "Epoch 131, Loss: 0.44141961811719244\n",
      "Epoch 132, Loss: 0.441006673716956\n",
      "Epoch 133, Loss: 0.4405401053384596\n",
      "Epoch 134, Loss: 0.4400778843482707\n",
      "Epoch 135, Loss: 0.4396474959415503\n",
      "Epoch 136, Loss: 0.4391890177235695\n",
      "Epoch 137, Loss: 0.43866623682082684\n",
      "Epoch 138, Loss: 0.43814789958429945\n",
      "Epoch 139, Loss: 0.43768376510074625\n",
      "Epoch 140, Loss: 0.43724146083892934\n",
      "Epoch 141, Loss: 0.4368094887410658\n",
      "Epoch 142, Loss: 0.43639716726562916\n",
      "Epoch 143, Loss: 0.43604809100027675\n",
      "Epoch 144, Loss: 0.4356686545873662\n",
      "Epoch 145, Loss: 0.4352768030749435\n",
      "Epoch 146, Loss: 0.434663929660177\n",
      "Epoch 147, Loss: 0.4341134058938843\n",
      "Epoch 148, Loss: 0.4336905672047639\n",
      "Epoch 149, Loss: 0.43334264615334317\n",
      "Epoch 150, Loss: 0.43301987689275634\n",
      "Epoch 151, Loss: 0.43246996507929464\n",
      "Epoch 152, Loss: 0.43193508478261367\n",
      "Epoch 153, Loss: 0.4314339086666887\n",
      "Epoch 154, Loss: 0.4309935228642165\n",
      "Epoch 155, Loss: 0.4305719116994111\n",
      "Epoch 156, Loss: 0.4300773412712918\n",
      "Epoch 157, Loss: 0.42990838355652244\n",
      "Epoch 158, Loss: 0.42944433093977646\n",
      "Epoch 159, Loss: 0.4286599617719707\n",
      "Epoch 160, Loss: 0.42747559405256064\n",
      "Epoch 161, Loss: 0.4271614732048306\n",
      "Epoch 162, Loss: 0.42707451563160487\n",
      "Epoch 163, Loss: 0.4260294304686234\n",
      "Epoch 164, Loss: 0.42527271664879746\n",
      "Epoch 165, Loss: 0.4250370836908656\n",
      "Epoch 166, Loss: 0.4246674063717036\n",
      "Epoch 167, Loss: 0.42397312900803613\n",
      "Epoch 168, Loss: 0.4233733695195633\n",
      "Epoch 169, Loss: 0.4230105869724637\n",
      "Epoch 170, Loss: 0.4226650857618823\n",
      "Epoch 171, Loss: 0.42229954233088296\n",
      "Epoch 172, Loss: 0.4217634053454345\n",
      "Epoch 173, Loss: 0.42115770395730917\n",
      "Epoch 174, Loss: 0.42063507904061603\n",
      "Epoch 175, Loss: 0.42018607056814483\n",
      "Epoch 176, Loss: 0.41984184744559633\n",
      "Epoch 177, Loss: 0.4196424042197801\n",
      "Epoch 178, Loss: 0.41977303994490023\n",
      "Epoch 179, Loss: 0.420368950183495\n",
      "Epoch 180, Loss: 0.4188867452449544\n",
      "Epoch 181, Loss: 0.4176682969912935\n",
      "Epoch 182, Loss: 0.4174836632678858\n",
      "Epoch 183, Loss: 0.4176629097261652\n",
      "Epoch 184, Loss: 0.41718570051626663\n",
      "Epoch 185, Loss: 0.41601078944015174\n",
      "Epoch 186, Loss: 0.4158330704867208\n",
      "Epoch 187, Loss: 0.4161374267505642\n",
      "Epoch 188, Loss: 0.4152737481298461\n",
      "Epoch 189, Loss: 0.4142935126432725\n",
      "Epoch 190, Loss: 0.41395691659099704\n",
      "Epoch 191, Loss: 0.4140284542266041\n",
      "Epoch 192, Loss: 0.41385406070070646\n",
      "Epoch 193, Loss: 0.41270044615152734\n",
      "Epoch 194, Loss: 0.4120665433058384\n",
      "Epoch 195, Loss: 0.4120782596358075\n",
      "Epoch 196, Loss: 0.41188229275095023\n",
      "Epoch 197, Loss: 0.41142824119268895\n",
      "Epoch 198, Loss: 0.41043201440427657\n",
      "Epoch 199, Loss: 0.4099413899363484\n",
      "Epoch 200, Loss: 0.4097692025813032\n",
      "Epoch 201, Loss: 0.40955190185149065\n",
      "Epoch 202, Loss: 0.4092125708720515\n",
      "Epoch 203, Loss: 0.40856849709075077\n",
      "Epoch 204, Loss: 0.4079232602598022\n",
      "Epoch 205, Loss: 0.40718177164868746\n",
      "Epoch 206, Loss: 0.406667989493522\n",
      "Epoch 207, Loss: 0.40638308912643617\n",
      "Epoch 208, Loss: 0.4063970593062586\n",
      "Epoch 209, Loss: 0.40702657568768164\n",
      "Epoch 210, Loss: 0.407428773582039\n",
      "Epoch 211, Loss: 0.4076443182886766\n",
      "Epoch 212, Loss: 0.40447625497691325\n",
      "Epoch 213, Loss: 0.40416955094766666\n",
      "Epoch 214, Loss: 0.4058076210545321\n",
      "Epoch 215, Loss: 0.4037941834393608\n",
      "Epoch 216, Loss: 0.4026593202200779\n",
      "Epoch 217, Loss: 0.40352701058439594\n",
      "Epoch 218, Loss: 0.4026726979814231\n",
      "Epoch 219, Loss: 0.4014245059627361\n",
      "Epoch 220, Loss: 0.4009050181871931\n",
      "Epoch 221, Loss: 0.40129036643886684\n",
      "Epoch 222, Loss: 0.4011690713548613\n",
      "Epoch 223, Loss: 0.4002321255211328\n",
      "Epoch 224, Loss: 0.39914677637407175\n",
      "Epoch 225, Loss: 0.3991865335443521\n",
      "Epoch 226, Loss: 0.39927579543111086\n",
      "Epoch 227, Loss: 0.39936388068920614\n",
      "Epoch 228, Loss: 0.3979894325204876\n",
      "Epoch 229, Loss: 0.3971708396580873\n",
      "Epoch 230, Loss: 0.39660817360494083\n",
      "Epoch 231, Loss: 0.3968563120489596\n",
      "Epoch 232, Loss: 0.39631301484121906\n",
      "Epoch 233, Loss: 0.39576857647820696\n",
      "Epoch 234, Loss: 0.39499829285892546\n",
      "Epoch 235, Loss: 0.39425929299132045\n",
      "Epoch 236, Loss: 0.3933993238754067\n",
      "Epoch 237, Loss: 0.3927217856446396\n",
      "Epoch 238, Loss: 0.39221402264766414\n",
      "Epoch 239, Loss: 0.39179238405249545\n",
      "Epoch 240, Loss: 0.39261382211114426\n",
      "Epoch 241, Loss: 0.39658200419674094\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.231493253265298\n",
      "Test R^2 score: 0.42164490564423357\n",
      "Num of epochs: 242\n",
      "Epoch 1, Loss: 0.5793395815725629\n",
      "Epoch 2, Loss: 0.5780254742295197\n",
      "Epoch 3, Loss: 0.5767489630578636\n",
      "Epoch 4, Loss: 0.5755354388931148\n",
      "Epoch 5, Loss: 0.574403071501019\n",
      "Epoch 6, Loss: 0.5733537191779179\n",
      "Epoch 7, Loss: 0.572327307804177\n",
      "Epoch 8, Loss: 0.5713349413585772\n",
      "Epoch 9, Loss: 0.5703707364801004\n",
      "Epoch 10, Loss: 0.5694250753514956\n",
      "Epoch 11, Loss: 0.568501248300435\n",
      "Epoch 12, Loss: 0.5676641767868716\n",
      "Epoch 13, Loss: 0.5668777870774231\n",
      "Epoch 14, Loss: 0.5661126263614517\n",
      "Epoch 15, Loss: 0.5653629823647675\n",
      "Epoch 16, Loss: 0.564629603058279\n",
      "Epoch 17, Loss: 0.5639139788259958\n",
      "Epoch 18, Loss: 0.5632136903582223\n",
      "Epoch 19, Loss: 0.562528556522719\n",
      "Epoch 20, Loss: 0.5618719992806799\n",
      "Epoch 21, Loss: 0.561231719825934\n",
      "Epoch 22, Loss: 0.5606084650210322\n",
      "Epoch 23, Loss: 0.5599979011888002\n",
      "Epoch 24, Loss: 0.5593934104063513\n",
      "Epoch 25, Loss: 0.5587880523576509\n",
      "Epoch 26, Loss: 0.5581840132797802\n",
      "Epoch 27, Loss: 0.5575974923578929\n",
      "Epoch 28, Loss: 0.5570114506737872\n",
      "Epoch 29, Loss: 0.5564128476624516\n",
      "Epoch 30, Loss: 0.5556476771615491\n",
      "Epoch 31, Loss: 0.554582478426822\n",
      "Epoch 32, Loss: 0.5531499264375427\n",
      "Epoch 33, Loss: 0.5513946418264575\n",
      "Epoch 34, Loss: 0.5494998337413061\n",
      "Epoch 35, Loss: 0.5475071931392594\n",
      "Epoch 36, Loss: 0.5451822786685737\n",
      "Epoch 37, Loss: 0.5425296627232616\n",
      "Epoch 38, Loss: 0.5396297069147226\n",
      "Epoch 39, Loss: 0.5366895109649615\n",
      "Epoch 40, Loss: 0.5340085217388849\n",
      "Epoch 41, Loss: 0.5320863591583337\n",
      "Epoch 42, Loss: 0.5311000556268449\n",
      "Epoch 43, Loss: 0.5300556670050859\n",
      "Epoch 44, Loss: 0.5276645391127749\n",
      "Epoch 45, Loss: 0.5241226153620835\n",
      "Epoch 46, Loss: 0.5205035468923332\n",
      "Epoch 47, Loss: 0.5178391284346203\n",
      "Epoch 48, Loss: 0.5163112466425426\n",
      "Epoch 49, Loss: 0.5149383307541828\n",
      "Epoch 50, Loss: 0.5132431445790409\n",
      "Epoch 51, Loss: 0.5111009785378019\n",
      "Epoch 52, Loss: 0.5087461252088399\n",
      "Epoch 53, Loss: 0.5066380344109932\n",
      "Epoch 54, Loss: 0.5051827637274489\n",
      "Epoch 55, Loss: 0.5041288135704971\n",
      "Epoch 56, Loss: 0.5026235889641746\n",
      "Epoch 57, Loss: 0.500586999601085\n",
      "Epoch 58, Loss: 0.4986888114423345\n",
      "Epoch 59, Loss: 0.49728075830007024\n",
      "Epoch 60, Loss: 0.49605370908130475\n",
      "Epoch 61, Loss: 0.49458193767814534\n",
      "Epoch 62, Loss: 0.4928102791735549\n",
      "Epoch 63, Loss: 0.4910878051776672\n",
      "Epoch 64, Loss: 0.4897307586551006\n",
      "Epoch 65, Loss: 0.48851364708796985\n",
      "Epoch 66, Loss: 0.4869989265336067\n",
      "Epoch 67, Loss: 0.48528997080352043\n",
      "Epoch 68, Loss: 0.4838015638267818\n",
      "Epoch 69, Loss: 0.4825443621980317\n",
      "Epoch 70, Loss: 0.4811785502465473\n",
      "Epoch 71, Loss: 0.47959514996376557\n",
      "Epoch 72, Loss: 0.4780228237604711\n",
      "Epoch 73, Loss: 0.4765928602709953\n",
      "Epoch 74, Loss: 0.4750988167320263\n",
      "Epoch 75, Loss: 0.4734119647602322\n",
      "Epoch 76, Loss: 0.47175229542431035\n",
      "Epoch 77, Loss: 0.47013250562928927\n",
      "Epoch 78, Loss: 0.4683298135039171\n",
      "Epoch 79, Loss: 0.4664680088630473\n",
      "Epoch 80, Loss: 0.4646954981225252\n",
      "Epoch 81, Loss: 0.46281052552290775\n",
      "Epoch 82, Loss: 0.4608660335418656\n",
      "Epoch 83, Loss: 0.4590875387926454\n",
      "Epoch 84, Loss: 0.45742425567763206\n",
      "Epoch 85, Loss: 0.4561690977299146\n",
      "Epoch 86, Loss: 0.45553601849474196\n",
      "Epoch 87, Loss: 0.4550734261855475\n",
      "Epoch 88, Loss: 0.4543748095012197\n",
      "Epoch 89, Loss: 0.4533577847226913\n",
      "Epoch 90, Loss: 0.45215731914851814\n",
      "Epoch 91, Loss: 0.45103330259372115\n",
      "Epoch 92, Loss: 0.450009802208211\n",
      "Epoch 93, Loss: 0.44913395620409235\n",
      "Epoch 94, Loss: 0.44841814431343613\n",
      "Epoch 95, Loss: 0.4478080824895649\n",
      "Epoch 96, Loss: 0.44722136232669896\n",
      "Epoch 97, Loss: 0.4465394601023746\n",
      "Epoch 98, Loss: 0.44577425724271663\n",
      "Epoch 99, Loss: 0.44495995269015387\n",
      "Epoch 100, Loss: 0.44417230296838134\n",
      "Epoch 101, Loss: 0.44337696931184933\n",
      "Epoch 102, Loss: 0.44253385883039387\n",
      "Epoch 103, Loss: 0.4417316284029531\n",
      "Epoch 104, Loss: 0.44095646044913045\n",
      "Epoch 105, Loss: 0.44017381700066566\n",
      "Epoch 106, Loss: 0.43941729929380685\n",
      "Epoch 107, Loss: 0.4387127552363342\n",
      "Epoch 108, Loss: 0.43802466608185747\n",
      "Epoch 109, Loss: 0.4373824608813221\n",
      "Epoch 110, Loss: 0.4367276936333518\n",
      "Epoch 111, Loss: 0.4359228794831929\n",
      "Epoch 112, Loss: 0.4350934597990623\n",
      "Epoch 113, Loss: 0.4343467909071587\n",
      "Epoch 114, Loss: 0.4336572720847607\n",
      "Epoch 115, Loss: 0.43301163509541635\n",
      "Epoch 116, Loss: 0.4324050796679316\n",
      "Epoch 117, Loss: 0.431813339270128\n",
      "Epoch 118, Loss: 0.4310647739462701\n",
      "Epoch 119, Loss: 0.430113875646835\n",
      "Epoch 120, Loss: 0.42923393586481257\n",
      "Epoch 121, Loss: 0.4286416417037069\n",
      "Epoch 122, Loss: 0.42827718076613325\n",
      "Epoch 123, Loss: 0.4276092381085624\n",
      "Epoch 124, Loss: 0.42662049622370085\n",
      "Epoch 125, Loss: 0.4257229056324574\n",
      "Epoch 126, Loss: 0.4252936870161576\n",
      "Epoch 127, Loss: 0.42486291245192986\n",
      "Epoch 128, Loss: 0.4239959736016568\n",
      "Epoch 129, Loss: 0.42314115127210145\n",
      "Epoch 130, Loss: 0.4225900912023147\n",
      "Epoch 131, Loss: 0.42227537089207284\n",
      "Epoch 132, Loss: 0.422114269080659\n",
      "Epoch 133, Loss: 0.42132254915316264\n",
      "Epoch 134, Loss: 0.42034312565630744\n",
      "Epoch 135, Loss: 0.41961760031863476\n",
      "Epoch 136, Loss: 0.4192992451520658\n",
      "Epoch 137, Loss: 0.4191874980047774\n",
      "Epoch 138, Loss: 0.41870793373275356\n",
      "Epoch 139, Loss: 0.41822796208203034\n",
      "Epoch 140, Loss: 0.41684718592561987\n",
      "Epoch 141, Loss: 0.41626934141180594\n",
      "Epoch 142, Loss: 0.41640559799400945\n",
      "Epoch 143, Loss: 0.41583711976306775\n",
      "Epoch 144, Loss: 0.41501213435162126\n",
      "Epoch 145, Loss: 0.4141124479289703\n",
      "Epoch 146, Loss: 0.41385382666271014\n",
      "Epoch 147, Loss: 0.41429635407733195\n",
      "Epoch 148, Loss: 0.41432210593281116\n",
      "Epoch 149, Loss: 0.41458341831736756\n",
      "Epoch 150, Loss: 0.41183509558101616\n",
      "Epoch 151, Loss: 0.412593340427918\n",
      "Epoch 152, Loss: 0.4128697688700751\n",
      "Epoch 153, Loss: 0.4103651150730931\n",
      "Epoch 154, Loss: 0.41215990308183476\n",
      "Epoch 155, Loss: 0.41090881697195036\n",
      "Epoch 156, Loss: 0.40943693027447964\n",
      "Epoch 157, Loss: 0.41118617855404144\n",
      "Epoch 158, Loss: 0.4085692629943728\n",
      "Epoch 159, Loss: 0.40876428462508263\n",
      "Epoch 160, Loss: 0.40847645055064\n",
      "Epoch 161, Loss: 0.4069021565739934\n",
      "Epoch 162, Loss: 0.40763342495552096\n",
      "Epoch 163, Loss: 0.4061255814691093\n",
      "Epoch 164, Loss: 0.40637934899679806\n",
      "Epoch 165, Loss: 0.40623659331868084\n",
      "Epoch 166, Loss: 0.40478062828485656\n",
      "Epoch 167, Loss: 0.4054721207377542\n",
      "Epoch 168, Loss: 0.405597915362328\n",
      "Epoch 169, Loss: 0.40369338914208064\n",
      "Epoch 170, Loss: 0.4040306062199765\n",
      "Epoch 171, Loss: 0.4045876457123343\n",
      "Epoch 172, Loss: 0.40262014654243006\n",
      "Epoch 173, Loss: 0.4027018388690554\n",
      "Epoch 174, Loss: 0.40353768243170207\n",
      "Epoch 175, Loss: 0.40167263687743543\n",
      "Epoch 176, Loss: 0.4010937912825417\n",
      "Epoch 177, Loss: 0.4019191686821422\n",
      "Epoch 178, Loss: 0.40117293434783224\n",
      "Epoch 179, Loss: 0.3999590338650398\n",
      "Epoch 180, Loss: 0.39952371300013284\n",
      "Epoch 181, Loss: 0.3998310365552608\n",
      "Epoch 182, Loss: 0.39986593711864277\n",
      "Epoch 183, Loss: 0.39866297083051117\n",
      "Epoch 184, Loss: 0.3979201604613198\n",
      "Epoch 185, Loss: 0.39792911034079065\n",
      "Epoch 186, Loss: 0.3981476645852799\n",
      "Epoch 187, Loss: 0.3984117312606707\n",
      "Epoch 188, Loss: 0.39743259338239206\n",
      "Epoch 189, Loss: 0.396482345500694\n",
      "Epoch 190, Loss: 0.39579436670880236\n",
      "Epoch 191, Loss: 0.39554171946671324\n",
      "Epoch 192, Loss: 0.3956746444168368\n",
      "Epoch 193, Loss: 0.3958936904600045\n",
      "Epoch 194, Loss: 0.3965715960698679\n",
      "Epoch 195, Loss: 0.39557264762033834\n",
      "Epoch 196, Loss: 0.3945605012228819\n",
      "Epoch 197, Loss: 0.3933348881999227\n",
      "Epoch 198, Loss: 0.3930788026359483\n",
      "Epoch 199, Loss: 0.39367068263844407\n",
      "Epoch 200, Loss: 0.39391719129559855\n",
      "Epoch 201, Loss: 0.39415793177676034\n",
      "Epoch 202, Loss: 0.3923677098817422\n",
      "Epoch 203, Loss: 0.39121455525607596\n",
      "Epoch 204, Loss: 0.3910125526513308\n",
      "Epoch 205, Loss: 0.3913151937774954\n",
      "Epoch 206, Loss: 0.3918731394636896\n",
      "Epoch 207, Loss: 0.3910897541946953\n",
      "Epoch 208, Loss: 0.39017783319541227\n",
      "Epoch 209, Loss: 0.38910970516395327\n",
      "Epoch 210, Loss: 0.38893840986338807\n",
      "Epoch 211, Loss: 0.389483271037565\n",
      "Epoch 212, Loss: 0.3894845718344727\n",
      "Epoch 213, Loss: 0.3897703166594426\n",
      "Epoch 214, Loss: 0.3885190078462276\n",
      "Epoch 215, Loss: 0.3874054793473038\n",
      "Epoch 216, Loss: 0.3865391285213887\n",
      "Epoch 217, Loss: 0.3864199707581577\n",
      "Epoch 218, Loss: 0.3866428724660279\n",
      "Epoch 219, Loss: 0.38683365550076404\n",
      "Epoch 220, Loss: 0.38752133479913997\n",
      "Epoch 221, Loss: 0.387088868245663\n",
      "Epoch 222, Loss: 0.38620581469837945\n",
      "Epoch 223, Loss: 0.3844796100401339\n",
      "Epoch 224, Loss: 0.3835690671045618\n",
      "Epoch 225, Loss: 0.3833704988285649\n",
      "Epoch 226, Loss: 0.3838554693723577\n",
      "Epoch 227, Loss: 0.38493000914625713\n",
      "Epoch 228, Loss: 0.3845328968110486\n",
      "Epoch 229, Loss: 0.38405190511418946\n",
      "Epoch 230, Loss: 0.3820177508818544\n",
      "Epoch 231, Loss: 0.38095981545055513\n",
      "Epoch 232, Loss: 0.38096288594878697\n",
      "Epoch 233, Loss: 0.38132465991677356\n",
      "Epoch 234, Loss: 0.382223337634502\n",
      "Epoch 235, Loss: 0.3824922428715824\n",
      "Epoch 236, Loss: 0.38176572500491507\n",
      "Epoch 237, Loss: 0.37971987331193774\n",
      "Epoch 238, Loss: 0.37855511548903087\n",
      "Epoch 239, Loss: 0.3781945338038769\n",
      "Epoch 240, Loss: 0.3780218401394672\n",
      "Epoch 241, Loss: 0.37850405790529734\n",
      "Epoch 242, Loss: 0.3790053601766612\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.24124430612639214\n",
      "Test R^2 score: 0.37606537861073375\n",
      "Num of epochs: 243\n",
      "Epoch 1, Loss: 0.5920359817762801\n",
      "Epoch 2, Loss: 0.5899194580400433\n",
      "Epoch 3, Loss: 0.5878738451619275\n",
      "Epoch 4, Loss: 0.5858963761203418\n",
      "Epoch 5, Loss: 0.5839847577454196\n",
      "Epoch 6, Loss: 0.582161523973539\n",
      "Epoch 7, Loss: 0.5803974184795809\n",
      "Epoch 8, Loss: 0.5787535935902102\n",
      "Epoch 9, Loss: 0.5772185049109666\n",
      "Epoch 10, Loss: 0.5757212282777723\n",
      "Epoch 11, Loss: 0.5742595424565063\n",
      "Epoch 12, Loss: 0.5728344482612285\n",
      "Epoch 13, Loss: 0.5714493225153052\n",
      "Epoch 14, Loss: 0.5701073578068491\n",
      "Epoch 15, Loss: 0.5688103790511918\n",
      "Epoch 16, Loss: 0.5675621340258665\n",
      "Epoch 17, Loss: 0.5663628923329702\n",
      "Epoch 18, Loss: 0.565212860436125\n",
      "Epoch 19, Loss: 0.5641132638337234\n",
      "Epoch 20, Loss: 0.5630646626518485\n",
      "Epoch 21, Loss: 0.5620669446336999\n",
      "Epoch 22, Loss: 0.5611374830615237\n",
      "Epoch 23, Loss: 0.5602854474627641\n",
      "Epoch 24, Loss: 0.5594789653468286\n",
      "Epoch 25, Loss: 0.5587173271867311\n",
      "Epoch 26, Loss: 0.5579975921688292\n",
      "Epoch 27, Loss: 0.5573327563340259\n",
      "Epoch 28, Loss: 0.5567160839666854\n",
      "Epoch 29, Loss: 0.5561291134665655\n",
      "Epoch 30, Loss: 0.5555675670861763\n",
      "Epoch 31, Loss: 0.5550288640927785\n",
      "Epoch 32, Loss: 0.5545156776905237\n",
      "Epoch 33, Loss: 0.5540288049787119\n",
      "Epoch 34, Loss: 0.5535468610242981\n",
      "Epoch 35, Loss: 0.5530530193066758\n",
      "Epoch 36, Loss: 0.5525335209805597\n",
      "Epoch 37, Loss: 0.5519029004571132\n",
      "Epoch 38, Loss: 0.5511643991159344\n",
      "Epoch 39, Loss: 0.5503157143008858\n",
      "Epoch 40, Loss: 0.549332031027784\n",
      "Epoch 41, Loss: 0.5481682336474984\n",
      "Epoch 42, Loss: 0.5467893260876744\n",
      "Epoch 43, Loss: 0.5451874718071867\n",
      "Epoch 44, Loss: 0.5433804714295104\n",
      "Epoch 45, Loss: 0.5413536090222818\n",
      "Epoch 46, Loss: 0.5390510557867237\n",
      "Epoch 47, Loss: 0.5363799256983374\n",
      "Epoch 48, Loss: 0.5332719248446182\n",
      "Epoch 49, Loss: 0.5297577319100769\n",
      "Epoch 50, Loss: 0.5258314134267508\n",
      "Epoch 51, Loss: 0.5214349101748823\n",
      "Epoch 52, Loss: 0.5165747940252851\n",
      "Epoch 53, Loss: 0.5114579154774913\n",
      "Epoch 54, Loss: 0.5063833520238639\n",
      "Epoch 55, Loss: 0.5020876158799421\n",
      "Epoch 56, Loss: 0.49907784062779903\n",
      "Epoch 57, Loss: 0.49689299113012936\n",
      "Epoch 58, Loss: 0.49384638352595017\n",
      "Epoch 59, Loss: 0.4894896393937096\n",
      "Epoch 60, Loss: 0.4863342376692515\n",
      "Epoch 61, Loss: 0.48518357929403333\n",
      "Epoch 62, Loss: 0.4830567664833873\n",
      "Epoch 63, Loss: 0.4798987038589099\n",
      "Epoch 64, Loss: 0.47726295149481\n",
      "Epoch 65, Loss: 0.47549429760611334\n",
      "Epoch 66, Loss: 0.47409981582620325\n",
      "Epoch 67, Loss: 0.4725211714991759\n",
      "Epoch 68, Loss: 0.4708633466736311\n",
      "Epoch 69, Loss: 0.46964004576368396\n",
      "Epoch 70, Loss: 0.4690503906323602\n",
      "Epoch 71, Loss: 0.46878221719017876\n",
      "Epoch 72, Loss: 0.4684625857089324\n",
      "Epoch 73, Loss: 0.4678212023978678\n",
      "Epoch 74, Loss: 0.4669643883625575\n",
      "Epoch 75, Loss: 0.4661425869223073\n",
      "Epoch 76, Loss: 0.46531928606381734\n",
      "Epoch 77, Loss: 0.46432026469924065\n",
      "Epoch 78, Loss: 0.4631645744033279\n",
      "Epoch 79, Loss: 0.46219268525099183\n",
      "Epoch 80, Loss: 0.4614866024885122\n",
      "Epoch 81, Loss: 0.460686211057999\n",
      "Epoch 82, Loss: 0.45988821762824034\n",
      "Epoch 83, Loss: 0.45915741600761434\n",
      "Epoch 84, Loss: 0.4585983763531267\n",
      "Epoch 85, Loss: 0.4579629611765822\n",
      "Epoch 86, Loss: 0.45719287329415\n",
      "Epoch 87, Loss: 0.45638833104486026\n",
      "Epoch 88, Loss: 0.4556743988552179\n",
      "Epoch 89, Loss: 0.4550423833211907\n",
      "Epoch 90, Loss: 0.45445624825380004\n",
      "Epoch 91, Loss: 0.4539118708986379\n",
      "Epoch 92, Loss: 0.45334665862068274\n",
      "Epoch 93, Loss: 0.4526587751460987\n",
      "Epoch 94, Loss: 0.4518578833718932\n",
      "Epoch 95, Loss: 0.45106447270847216\n",
      "Epoch 96, Loss: 0.4503337456948129\n",
      "Epoch 97, Loss: 0.4497400824612703\n",
      "Epoch 98, Loss: 0.44917303764953687\n",
      "Epoch 99, Loss: 0.44865441741537204\n",
      "Epoch 100, Loss: 0.4480943290503988\n",
      "Epoch 101, Loss: 0.4474777484934493\n",
      "Epoch 102, Loss: 0.44688097476299593\n",
      "Epoch 103, Loss: 0.4463501268676598\n",
      "Epoch 104, Loss: 0.44583350371717007\n",
      "Epoch 105, Loss: 0.44535862533205917\n",
      "Epoch 106, Loss: 0.4449272162139444\n",
      "Epoch 107, Loss: 0.44448062092188767\n",
      "Epoch 108, Loss: 0.4440112594044613\n",
      "Epoch 109, Loss: 0.443531557502175\n",
      "Epoch 110, Loss: 0.4430360665547564\n",
      "Epoch 111, Loss: 0.44255988680236785\n",
      "Epoch 112, Loss: 0.4421042266184623\n",
      "Epoch 113, Loss: 0.4416518076910309\n",
      "Epoch 114, Loss: 0.44118923152438433\n",
      "Epoch 115, Loss: 0.4407339799991257\n",
      "Epoch 116, Loss: 0.4402730455989953\n",
      "Epoch 117, Loss: 0.43979109589530496\n",
      "Epoch 118, Loss: 0.4393110427050774\n",
      "Epoch 119, Loss: 0.438831839604316\n",
      "Epoch 120, Loss: 0.43833288884714505\n",
      "Epoch 121, Loss: 0.43783789597125633\n",
      "Epoch 122, Loss: 0.43741027729447646\n",
      "Epoch 123, Loss: 0.4369538679138776\n",
      "Epoch 124, Loss: 0.43644032551193473\n",
      "Epoch 125, Loss: 0.4359462942241325\n",
      "Epoch 126, Loss: 0.43546184855981607\n",
      "Epoch 127, Loss: 0.4349557431771174\n",
      "Epoch 128, Loss: 0.4344064982403726\n",
      "Epoch 129, Loss: 0.4338701071983977\n",
      "Epoch 130, Loss: 0.43334266334662086\n",
      "Epoch 131, Loss: 0.4327741902056726\n",
      "Epoch 132, Loss: 0.4321968154565277\n",
      "Epoch 133, Loss: 0.43163101047492597\n",
      "Epoch 134, Loss: 0.4310518625060529\n",
      "Epoch 135, Loss: 0.43044320323207197\n",
      "Epoch 136, Loss: 0.4298300073299483\n",
      "Epoch 137, Loss: 0.42919071262857655\n",
      "Epoch 138, Loss: 0.4285009473792412\n",
      "Epoch 139, Loss: 0.42788657002097374\n",
      "Epoch 140, Loss: 0.4272950062682485\n",
      "Epoch 141, Loss: 0.42669473002884833\n",
      "Epoch 142, Loss: 0.4261118104392365\n",
      "Epoch 143, Loss: 0.4256245210899762\n",
      "Epoch 144, Loss: 0.4253126593147333\n",
      "Epoch 145, Loss: 0.4246845996412391\n",
      "Epoch 146, Loss: 0.4236485852496916\n",
      "Epoch 147, Loss: 0.4231125200366662\n",
      "Epoch 148, Loss: 0.4228220658443134\n",
      "Epoch 149, Loss: 0.4219875715321611\n",
      "Epoch 150, Loss: 0.42135425500039714\n",
      "Epoch 151, Loss: 0.42109992212078756\n",
      "Epoch 152, Loss: 0.42042670843168906\n",
      "Epoch 153, Loss: 0.4197385343368202\n",
      "Epoch 154, Loss: 0.4194013341148452\n",
      "Epoch 155, Loss: 0.41904018012678906\n",
      "Epoch 156, Loss: 0.418314478840031\n",
      "Epoch 157, Loss: 0.4178265481212035\n",
      "Epoch 158, Loss: 0.4175021338836594\n",
      "Epoch 159, Loss: 0.41694360311527634\n",
      "Epoch 160, Loss: 0.4162550223966836\n",
      "Epoch 161, Loss: 0.41583290923153665\n",
      "Epoch 162, Loss: 0.41543969060263747\n",
      "Epoch 163, Loss: 0.4148158471732706\n",
      "Epoch 164, Loss: 0.41410224651808786\n",
      "Epoch 165, Loss: 0.41353211531991424\n",
      "Epoch 166, Loss: 0.413156291480683\n",
      "Epoch 167, Loss: 0.4127775443421416\n",
      "Epoch 168, Loss: 0.4122598743887047\n",
      "Epoch 169, Loss: 0.41161408876587824\n",
      "Epoch 170, Loss: 0.4109781477228358\n",
      "Epoch 171, Loss: 0.41052607257671075\n",
      "Epoch 172, Loss: 0.4102053113386601\n",
      "Epoch 173, Loss: 0.41006190713596263\n",
      "Epoch 174, Loss: 0.40989595055326006\n",
      "Epoch 175, Loss: 0.4093295530761802\n",
      "Epoch 176, Loss: 0.4082842659501263\n",
      "Epoch 177, Loss: 0.4075793926445243\n",
      "Epoch 178, Loss: 0.407474104111125\n",
      "Epoch 179, Loss: 0.4072412721460906\n",
      "Epoch 180, Loss: 0.4064015692617689\n",
      "Epoch 181, Loss: 0.4055070686241642\n",
      "Epoch 182, Loss: 0.4050898124458139\n",
      "Epoch 183, Loss: 0.4050112324204904\n",
      "Epoch 184, Loss: 0.404893425794542\n",
      "Epoch 185, Loss: 0.4041033295361846\n",
      "Epoch 186, Loss: 0.4029885097952835\n",
      "Epoch 187, Loss: 0.4023068975959606\n",
      "Epoch 188, Loss: 0.40215497078759926\n",
      "Epoch 189, Loss: 0.4021438546496247\n",
      "Epoch 190, Loss: 0.4017383316650537\n",
      "Epoch 191, Loss: 0.40072770235041844\n",
      "Epoch 192, Loss: 0.3997194386561974\n",
      "Epoch 193, Loss: 0.3992171233381064\n",
      "Epoch 194, Loss: 0.3991645462654089\n",
      "Epoch 195, Loss: 0.39939210640175243\n",
      "Epoch 196, Loss: 0.3992985602701352\n",
      "Epoch 197, Loss: 0.39837674070348433\n",
      "Epoch 198, Loss: 0.39688056731636995\n",
      "Epoch 199, Loss: 0.3962815428312273\n",
      "Epoch 200, Loss: 0.3965241172678726\n",
      "Epoch 201, Loss: 0.39648973057329095\n",
      "Epoch 202, Loss: 0.3955649063909913\n",
      "Epoch 203, Loss: 0.3943653513276704\n",
      "Epoch 204, Loss: 0.39383473619853443\n",
      "Epoch 205, Loss: 0.3937410996960069\n",
      "Epoch 206, Loss: 0.3939011707455082\n",
      "Epoch 207, Loss: 0.39391034433975075\n",
      "Epoch 208, Loss: 0.3932834949815804\n",
      "Epoch 209, Loss: 0.3919641428648331\n",
      "Epoch 210, Loss: 0.3910261002241648\n",
      "Epoch 211, Loss: 0.39081547861384064\n",
      "Epoch 212, Loss: 0.3910667591786679\n",
      "Epoch 213, Loss: 0.3916857811984583\n",
      "Epoch 214, Loss: 0.39148114795530925\n",
      "Epoch 215, Loss: 0.39011695248371475\n",
      "Epoch 216, Loss: 0.38858495152432593\n",
      "Epoch 217, Loss: 0.38821792930523036\n",
      "Epoch 218, Loss: 0.38873236870724237\n",
      "Epoch 219, Loss: 0.38902561824894827\n",
      "Epoch 220, Loss: 0.38835071349168687\n",
      "Epoch 221, Loss: 0.3869119026936421\n",
      "Epoch 222, Loss: 0.38614457787363754\n",
      "Epoch 223, Loss: 0.3866563033730774\n",
      "Epoch 224, Loss: 0.3871437396242795\n",
      "Epoch 225, Loss: 0.3859583188823994\n",
      "Epoch 226, Loss: 0.3848564311891381\n",
      "Epoch 227, Loss: 0.3843188136213856\n",
      "Epoch 228, Loss: 0.38391406326509747\n",
      "Epoch 229, Loss: 0.3841821341734853\n",
      "Epoch 230, Loss: 0.38412171912165427\n",
      "Epoch 231, Loss: 0.3832785241535108\n",
      "Epoch 232, Loss: 0.3827566767881993\n",
      "Epoch 233, Loss: 0.3821606243412551\n",
      "Epoch 234, Loss: 0.3813840528793414\n",
      "Epoch 235, Loss: 0.38117621520789374\n",
      "Epoch 236, Loss: 0.38106275165731623\n",
      "Epoch 237, Loss: 0.3808058676668802\n",
      "Epoch 238, Loss: 0.3811241403359201\n",
      "Epoch 239, Loss: 0.382360853678619\n",
      "Epoch 240, Loss: 0.3826484912725932\n",
      "Epoch 241, Loss: 0.38244743846205553\n",
      "Epoch 242, Loss: 0.3801064311167676\n",
      "Epoch 243, Loss: 0.3783553139285309\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2518670425529176\n",
      "Test R^2 score: 0.3096361330408397\n",
      "Num of epochs: 244\n",
      "Epoch 1, Loss: 0.585447513428305\n",
      "Epoch 2, Loss: 0.5835571001793166\n",
      "Epoch 3, Loss: 0.5817459482478938\n",
      "Epoch 4, Loss: 0.5799347928404663\n",
      "Epoch 5, Loss: 0.5781777332071906\n",
      "Epoch 6, Loss: 0.5764768924581655\n",
      "Epoch 7, Loss: 0.5748385244112809\n",
      "Epoch 8, Loss: 0.5732649842494474\n",
      "Epoch 9, Loss: 0.5717544876859925\n",
      "Epoch 10, Loss: 0.5703398554263851\n",
      "Epoch 11, Loss: 0.5691033701331522\n",
      "Epoch 12, Loss: 0.5678624343539845\n",
      "Epoch 13, Loss: 0.5666660107814508\n",
      "Epoch 14, Loss: 0.5655137495364408\n",
      "Epoch 15, Loss: 0.5644107525506875\n",
      "Epoch 16, Loss: 0.5633609064631793\n",
      "Epoch 17, Loss: 0.562391138139026\n",
      "Epoch 18, Loss: 0.5614829936182374\n",
      "Epoch 19, Loss: 0.5606336360338533\n",
      "Epoch 20, Loss: 0.5598462873907609\n",
      "Epoch 21, Loss: 0.5591393853632601\n",
      "Epoch 22, Loss: 0.5585019763170483\n",
      "Epoch 23, Loss: 0.557921238192726\n",
      "Epoch 24, Loss: 0.5574191622009775\n",
      "Epoch 25, Loss: 0.5569959610599114\n",
      "Epoch 26, Loss: 0.5566388581900414\n",
      "Epoch 27, Loss: 0.5563392492552697\n",
      "Epoch 28, Loss: 0.5560915464104094\n",
      "Epoch 29, Loss: 0.5558913692828904\n",
      "Epoch 30, Loss: 0.5557317709273358\n",
      "Epoch 31, Loss: 0.5556035603869879\n",
      "Epoch 32, Loss: 0.5554995972213864\n",
      "Epoch 33, Loss: 0.5554202169899628\n",
      "Epoch 34, Loss: 0.5553373103484038\n",
      "Epoch 35, Loss: 0.5552118804656104\n",
      "Epoch 36, Loss: 0.5550131043614002\n",
      "Epoch 37, Loss: 0.5547116771318221\n",
      "Epoch 38, Loss: 0.5542859517930552\n",
      "Epoch 39, Loss: 0.5537183111867109\n",
      "Epoch 40, Loss: 0.5530012854462871\n",
      "Epoch 41, Loss: 0.5521245227299519\n",
      "Epoch 42, Loss: 0.551090802800491\n",
      "Epoch 43, Loss: 0.5499238178204222\n",
      "Epoch 44, Loss: 0.5486992518392599\n",
      "Epoch 45, Loss: 0.5474106481442622\n",
      "Epoch 46, Loss: 0.5459325844554879\n",
      "Epoch 47, Loss: 0.5441499664096319\n",
      "Epoch 48, Loss: 0.5420312815820416\n",
      "Epoch 49, Loss: 0.5395295151882303\n",
      "Epoch 50, Loss: 0.5366393373423672\n",
      "Epoch 51, Loss: 0.5333908924196316\n",
      "Epoch 52, Loss: 0.5299568425457056\n",
      "Epoch 53, Loss: 0.52644808966701\n",
      "Epoch 54, Loss: 0.5230245811947568\n",
      "Epoch 55, Loss: 0.5200841156160526\n",
      "Epoch 56, Loss: 0.5182162399852305\n",
      "Epoch 57, Loss: 0.5171417700150918\n",
      "Epoch 58, Loss: 0.5156041921405226\n",
      "Epoch 59, Loss: 0.5130431530223342\n",
      "Epoch 60, Loss: 0.5099178686111697\n",
      "Epoch 61, Loss: 0.5069200743590428\n",
      "Epoch 62, Loss: 0.5043968355729975\n",
      "Epoch 63, Loss: 0.5022237026171448\n",
      "Epoch 64, Loss: 0.5001957033536397\n",
      "Epoch 65, Loss: 0.4980882066518382\n",
      "Epoch 66, Loss: 0.4958046949621712\n",
      "Epoch 67, Loss: 0.4933787114815856\n",
      "Epoch 68, Loss: 0.49078163817353004\n",
      "Epoch 69, Loss: 0.4880858831569707\n",
      "Epoch 70, Loss: 0.4854808765587472\n",
      "Epoch 71, Loss: 0.48306008259329647\n",
      "Epoch 72, Loss: 0.48070610200458275\n",
      "Epoch 73, Loss: 0.4782482100661144\n",
      "Epoch 74, Loss: 0.4756162974480033\n",
      "Epoch 75, Loss: 0.4728233735522833\n",
      "Epoch 76, Loss: 0.47015901830333\n",
      "Epoch 77, Loss: 0.46792741761746526\n",
      "Epoch 78, Loss: 0.4663835395382891\n",
      "Epoch 79, Loss: 0.465761544861071\n",
      "Epoch 80, Loss: 0.4656597476513243\n",
      "Epoch 81, Loss: 0.46512154685165924\n",
      "Epoch 82, Loss: 0.46428658248222837\n",
      "Epoch 83, Loss: 0.4630543704880001\n",
      "Epoch 84, Loss: 0.46161913176317937\n",
      "Epoch 85, Loss: 0.4603618162661597\n",
      "Epoch 86, Loss: 0.45946701322003\n",
      "Epoch 87, Loss: 0.4588160104579617\n",
      "Epoch 88, Loss: 0.45813573746633734\n",
      "Epoch 89, Loss: 0.45744448507380486\n",
      "Epoch 90, Loss: 0.45687307571339875\n",
      "Epoch 91, Loss: 0.4562489424654057\n",
      "Epoch 92, Loss: 0.45549154535375935\n",
      "Epoch 93, Loss: 0.45474319248021894\n",
      "Epoch 94, Loss: 0.4540922430579312\n",
      "Epoch 95, Loss: 0.45347877372434575\n",
      "Epoch 96, Loss: 0.45286807635998244\n",
      "Epoch 97, Loss: 0.45234820770544454\n",
      "Epoch 98, Loss: 0.4518711896131583\n",
      "Epoch 99, Loss: 0.45129470474307215\n",
      "Epoch 100, Loss: 0.4506975793786617\n",
      "Epoch 101, Loss: 0.4501054388603742\n",
      "Epoch 102, Loss: 0.4495045126188818\n",
      "Epoch 103, Loss: 0.4489155782918068\n",
      "Epoch 104, Loss: 0.4483799442213277\n",
      "Epoch 105, Loss: 0.44781864742364075\n",
      "Epoch 106, Loss: 0.4472451517674992\n",
      "Epoch 107, Loss: 0.4466652484623376\n",
      "Epoch 108, Loss: 0.44603558443398605\n",
      "Epoch 109, Loss: 0.44537128930442427\n",
      "Epoch 110, Loss: 0.4447109442486828\n",
      "Epoch 111, Loss: 0.44405622795985566\n",
      "Epoch 112, Loss: 0.44341123168435287\n",
      "Epoch 113, Loss: 0.4427894256222548\n",
      "Epoch 114, Loss: 0.4421275499230974\n",
      "Epoch 115, Loss: 0.44144377084788095\n",
      "Epoch 116, Loss: 0.44074971821538494\n",
      "Epoch 117, Loss: 0.4400512354996073\n",
      "Epoch 118, Loss: 0.43935079442793856\n",
      "Epoch 119, Loss: 0.4386488442222129\n",
      "Epoch 120, Loss: 0.4379468236926713\n",
      "Epoch 121, Loss: 0.4372068512937283\n",
      "Epoch 122, Loss: 0.43645982044060705\n",
      "Epoch 123, Loss: 0.4357257527013891\n",
      "Epoch 124, Loss: 0.4349774457302253\n",
      "Epoch 125, Loss: 0.4342587672267094\n",
      "Epoch 126, Loss: 0.43369432949566133\n",
      "Epoch 127, Loss: 0.4331249761650222\n",
      "Epoch 128, Loss: 0.43235559067471485\n",
      "Epoch 129, Loss: 0.43138455005797866\n",
      "Epoch 130, Loss: 0.4309942662041332\n",
      "Epoch 131, Loss: 0.4303332591538152\n",
      "Epoch 132, Loss: 0.4295178685440374\n",
      "Epoch 133, Loss: 0.42914085295119203\n",
      "Epoch 134, Loss: 0.4284710919200237\n",
      "Epoch 135, Loss: 0.42783131654876033\n",
      "Epoch 136, Loss: 0.42745342346687437\n",
      "Epoch 137, Loss: 0.4267214272916901\n",
      "Epoch 138, Loss: 0.4261188218812243\n",
      "Epoch 139, Loss: 0.42571602768018146\n",
      "Epoch 140, Loss: 0.425041763974406\n",
      "Epoch 141, Loss: 0.42445309876825066\n",
      "Epoch 142, Loss: 0.42405158625525197\n",
      "Epoch 143, Loss: 0.42349103188054876\n",
      "Epoch 144, Loss: 0.42282985428905157\n",
      "Epoch 145, Loss: 0.422316814358228\n",
      "Epoch 146, Loss: 0.42189100023233683\n",
      "Epoch 147, Loss: 0.4213977869730677\n",
      "Epoch 148, Loss: 0.42088551512527717\n",
      "Epoch 149, Loss: 0.42030201937857226\n",
      "Epoch 150, Loss: 0.4197213159715193\n",
      "Epoch 151, Loss: 0.4192324812350385\n",
      "Epoch 152, Loss: 0.41879682421441117\n",
      "Epoch 153, Loss: 0.4184117331630249\n",
      "Epoch 154, Loss: 0.418073462801188\n",
      "Epoch 155, Loss: 0.4176215217957009\n",
      "Epoch 156, Loss: 0.4169622406044392\n",
      "Epoch 157, Loss: 0.4163470492765889\n",
      "Epoch 158, Loss: 0.4158905271034227\n",
      "Epoch 159, Loss: 0.41561314988989995\n",
      "Epoch 160, Loss: 0.41549662780196617\n",
      "Epoch 161, Loss: 0.41511249565789143\n",
      "Epoch 162, Loss: 0.41444050430799\n",
      "Epoch 163, Loss: 0.4137333695449059\n",
      "Epoch 164, Loss: 0.4133961552067886\n",
      "Epoch 165, Loss: 0.41323341280261594\n",
      "Epoch 166, Loss: 0.4129322207889827\n",
      "Epoch 167, Loss: 0.41227275990407347\n",
      "Epoch 168, Loss: 0.4116278633113079\n",
      "Epoch 169, Loss: 0.4113617393329205\n",
      "Epoch 170, Loss: 0.41108088946987037\n",
      "Epoch 171, Loss: 0.4108173673414833\n",
      "Epoch 172, Loss: 0.41014427894197886\n",
      "Epoch 173, Loss: 0.4096116583114973\n",
      "Epoch 174, Loss: 0.4092473813965294\n",
      "Epoch 175, Loss: 0.40901501239328963\n",
      "Epoch 176, Loss: 0.4088147158531343\n",
      "Epoch 177, Loss: 0.4086496201896513\n",
      "Epoch 178, Loss: 0.4083508675891249\n",
      "Epoch 179, Loss: 0.4078177681944374\n",
      "Epoch 180, Loss: 0.4072282823119222\n",
      "Epoch 181, Loss: 0.40672496393756824\n",
      "Epoch 182, Loss: 0.4065096832144957\n",
      "Epoch 183, Loss: 0.40651483339903494\n",
      "Epoch 184, Loss: 0.40634390772653856\n",
      "Epoch 185, Loss: 0.4058673597180038\n",
      "Epoch 186, Loss: 0.4051530038605745\n",
      "Epoch 187, Loss: 0.40466520329032224\n",
      "Epoch 188, Loss: 0.4044987639772559\n",
      "Epoch 189, Loss: 0.40448435983493136\n",
      "Epoch 190, Loss: 0.4043895596767685\n",
      "Epoch 191, Loss: 0.40411621701424544\n",
      "Epoch 192, Loss: 0.40347434882462396\n",
      "Epoch 193, Loss: 0.40291314435495545\n",
      "Epoch 194, Loss: 0.40265393568446317\n",
      "Epoch 195, Loss: 0.4026104126709341\n",
      "Epoch 196, Loss: 0.4025855772785927\n",
      "Epoch 197, Loss: 0.40231213862112664\n",
      "Epoch 198, Loss: 0.4018310687790967\n",
      "Epoch 199, Loss: 0.4012718180194161\n",
      "Epoch 200, Loss: 0.40085273685137207\n",
      "Epoch 201, Loss: 0.40066089347336614\n",
      "Epoch 202, Loss: 0.4005297907442349\n",
      "Epoch 203, Loss: 0.40056137537876485\n",
      "Epoch 204, Loss: 0.40070103963665177\n",
      "Epoch 205, Loss: 0.400526554015552\n",
      "Epoch 206, Loss: 0.39992330307583507\n",
      "Epoch 207, Loss: 0.3991968361649866\n",
      "Epoch 208, Loss: 0.39892193385011676\n",
      "Epoch 209, Loss: 0.3989380329169757\n",
      "Epoch 210, Loss: 0.3991605891732007\n",
      "Epoch 211, Loss: 0.39903226106049394\n",
      "Epoch 212, Loss: 0.39848428339340686\n",
      "Epoch 213, Loss: 0.3978199380207747\n",
      "Epoch 214, Loss: 0.39759085966326574\n",
      "Epoch 215, Loss: 0.3976705125150842\n",
      "Epoch 216, Loss: 0.397669201023572\n",
      "Epoch 217, Loss: 0.3974260881971886\n",
      "Epoch 218, Loss: 0.39692182790275937\n",
      "Epoch 219, Loss: 0.39651983318658024\n",
      "Epoch 220, Loss: 0.3963129772417425\n",
      "Epoch 221, Loss: 0.39630974367341587\n",
      "Epoch 222, Loss: 0.39641489632228377\n",
      "Epoch 223, Loss: 0.39658136543869943\n",
      "Epoch 224, Loss: 0.3965153423674651\n",
      "Epoch 225, Loss: 0.3956751716583992\n",
      "Epoch 226, Loss: 0.3949669047265086\n",
      "Epoch 227, Loss: 0.3947388320065418\n",
      "Epoch 228, Loss: 0.39480009455814985\n",
      "Epoch 229, Loss: 0.3949313448441241\n",
      "Epoch 230, Loss: 0.39481139859264347\n",
      "Epoch 231, Loss: 0.39448815289780015\n",
      "Epoch 232, Loss: 0.3939009059375534\n",
      "Epoch 233, Loss: 0.3934401541901399\n",
      "Epoch 234, Loss: 0.39313209885099426\n",
      "Epoch 235, Loss: 0.3930006457935007\n",
      "Epoch 236, Loss: 0.3931152692478986\n",
      "Epoch 237, Loss: 0.3932311476937555\n",
      "Epoch 238, Loss: 0.3935849956645883\n",
      "Epoch 239, Loss: 0.393484502170895\n",
      "Epoch 240, Loss: 0.3933349260840792\n",
      "Epoch 241, Loss: 0.392299971088279\n",
      "Epoch 242, Loss: 0.39156069268786037\n",
      "Epoch 243, Loss: 0.39143590681521406\n",
      "Epoch 244, Loss: 0.39181387228336767\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2391218570397806\n",
      "Test R^2 score: 0.3817562913058017\n",
      "Num of epochs: 245\n",
      "Epoch 1, Loss: 0.5578094257943206\n",
      "Epoch 2, Loss: 0.5573997808620924\n",
      "Epoch 3, Loss: 0.5570449431503227\n",
      "Epoch 4, Loss: 0.5567488715678968\n",
      "Epoch 5, Loss: 0.5565150604506516\n",
      "Epoch 6, Loss: 0.5563411241535936\n",
      "Epoch 7, Loss: 0.556214072106594\n",
      "Epoch 8, Loss: 0.5561272110589613\n",
      "Epoch 9, Loss: 0.5560694122776654\n",
      "Epoch 10, Loss: 0.5560172890781223\n",
      "Epoch 11, Loss: 0.5559928203074607\n",
      "Epoch 12, Loss: 0.5559682700533701\n",
      "Epoch 13, Loss: 0.5559328096394547\n",
      "Epoch 14, Loss: 0.5558796817933227\n",
      "Epoch 15, Loss: 0.5558071388046978\n",
      "Epoch 16, Loss: 0.5557023020158625\n",
      "Epoch 17, Loss: 0.5555601374781596\n",
      "Epoch 18, Loss: 0.5553746601149201\n",
      "Epoch 19, Loss: 0.5551395454760222\n",
      "Epoch 20, Loss: 0.5548504872021818\n",
      "Epoch 21, Loss: 0.554503450618564\n",
      "Epoch 22, Loss: 0.5540905547636972\n",
      "Epoch 23, Loss: 0.5536069419122405\n",
      "Epoch 24, Loss: 0.5530371493817969\n",
      "Epoch 25, Loss: 0.5523768910092721\n",
      "Epoch 26, Loss: 0.5516005030175364\n",
      "Epoch 27, Loss: 0.5506990249617537\n",
      "Epoch 28, Loss: 0.5496729799730844\n",
      "Epoch 29, Loss: 0.548503195802877\n",
      "Epoch 30, Loss: 0.54714250833841\n",
      "Epoch 31, Loss: 0.5455624769815857\n",
      "Epoch 32, Loss: 0.5437420888303325\n",
      "Epoch 33, Loss: 0.5416828819439846\n",
      "Epoch 34, Loss: 0.539408420751752\n",
      "Epoch 35, Loss: 0.536974498113052\n",
      "Epoch 36, Loss: 0.534307042758768\n",
      "Epoch 37, Loss: 0.5313151543998219\n",
      "Epoch 38, Loss: 0.5279940516180143\n",
      "Epoch 39, Loss: 0.5243257416242053\n",
      "Epoch 40, Loss: 0.5203204077042412\n",
      "Epoch 41, Loss: 0.5161826845852752\n",
      "Epoch 42, Loss: 0.512277109245153\n",
      "Epoch 43, Loss: 0.5092450695838517\n",
      "Epoch 44, Loss: 0.5075781061173362\n",
      "Epoch 45, Loss: 0.5063551899451604\n",
      "Epoch 46, Loss: 0.503877298868926\n",
      "Epoch 47, Loss: 0.5002379447288942\n",
      "Epoch 48, Loss: 0.49648085081949117\n",
      "Epoch 49, Loss: 0.4932979288746343\n",
      "Epoch 50, Loss: 0.4907463105986592\n",
      "Epoch 51, Loss: 0.4885904935039622\n",
      "Epoch 52, Loss: 0.48642956392004105\n",
      "Epoch 53, Loss: 0.4838896442405731\n",
      "Epoch 54, Loss: 0.48093518822345505\n",
      "Epoch 55, Loss: 0.47773208305701176\n",
      "Epoch 56, Loss: 0.47461218499501706\n",
      "Epoch 57, Loss: 0.47168022455852254\n",
      "Epoch 58, Loss: 0.46920519026383983\n",
      "Epoch 59, Loss: 0.4672041835804176\n",
      "Epoch 60, Loss: 0.46537610832961507\n",
      "Epoch 61, Loss: 0.4638961301106439\n",
      "Epoch 62, Loss: 0.4632210176112965\n",
      "Epoch 63, Loss: 0.4631068694340579\n",
      "Epoch 64, Loss: 0.4627972601236597\n",
      "Epoch 65, Loss: 0.46247002852473423\n",
      "Epoch 66, Loss: 0.46203855163666724\n",
      "Epoch 67, Loss: 0.460756767530618\n",
      "Epoch 68, Loss: 0.45934059442403863\n",
      "Epoch 69, Loss: 0.4583138132995991\n",
      "Epoch 70, Loss: 0.45736473501925506\n",
      "Epoch 71, Loss: 0.4565587821302535\n",
      "Epoch 72, Loss: 0.4561000205141802\n",
      "Epoch 73, Loss: 0.45584537840916045\n",
      "Epoch 74, Loss: 0.4553217419986936\n",
      "Epoch 75, Loss: 0.45468563131885686\n",
      "Epoch 76, Loss: 0.4541859374055535\n",
      "Epoch 77, Loss: 0.45366434358073954\n",
      "Epoch 78, Loss: 0.45300284745203545\n",
      "Epoch 79, Loss: 0.4523384733007601\n",
      "Epoch 80, Loss: 0.4517847332682586\n",
      "Epoch 81, Loss: 0.4511756731674373\n",
      "Epoch 82, Loss: 0.45053387404367806\n",
      "Epoch 83, Loss: 0.45004415560359234\n",
      "Epoch 84, Loss: 0.4496023281947109\n",
      "Epoch 85, Loss: 0.4490693714728404\n",
      "Epoch 86, Loss: 0.44862555438602914\n",
      "Epoch 87, Loss: 0.4482591081471524\n",
      "Epoch 88, Loss: 0.447750012496275\n",
      "Epoch 89, Loss: 0.4473218424419602\n",
      "Epoch 90, Loss: 0.4468383080417685\n",
      "Epoch 91, Loss: 0.4462877436311629\n",
      "Epoch 92, Loss: 0.44587350943583315\n",
      "Epoch 93, Loss: 0.4453735811605452\n",
      "Epoch 94, Loss: 0.4448936734794267\n",
      "Epoch 95, Loss: 0.4444384949090556\n",
      "Epoch 96, Loss: 0.4438751178634947\n",
      "Epoch 97, Loss: 0.4433260161499896\n",
      "Epoch 98, Loss: 0.44273875823845793\n",
      "Epoch 99, Loss: 0.44209170500150946\n",
      "Epoch 100, Loss: 0.44149696633213625\n",
      "Epoch 101, Loss: 0.4408642471046963\n",
      "Epoch 102, Loss: 0.4402991056875468\n",
      "Epoch 103, Loss: 0.4396856074505969\n",
      "Epoch 104, Loss: 0.43911341782586655\n",
      "Epoch 105, Loss: 0.4385401248527238\n",
      "Epoch 106, Loss: 0.43791087475523727\n",
      "Epoch 107, Loss: 0.43730624199915097\n",
      "Epoch 108, Loss: 0.4367030924001629\n",
      "Epoch 109, Loss: 0.4361290056444305\n",
      "Epoch 110, Loss: 0.43554761056880675\n",
      "Epoch 111, Loss: 0.4349655068906487\n",
      "Epoch 112, Loss: 0.4344220026232351\n",
      "Epoch 113, Loss: 0.4338245293186413\n",
      "Epoch 114, Loss: 0.4332297575789825\n",
      "Epoch 115, Loss: 0.43262841616970626\n",
      "Epoch 116, Loss: 0.43199417686401026\n",
      "Epoch 117, Loss: 0.4313492114898578\n",
      "Epoch 118, Loss: 0.4306934718602471\n",
      "Epoch 119, Loss: 0.42999404029819205\n",
      "Epoch 120, Loss: 0.42930914086407596\n",
      "Epoch 121, Loss: 0.4286542954967303\n",
      "Epoch 122, Loss: 0.4280078484013932\n",
      "Epoch 123, Loss: 0.4273630385430646\n",
      "Epoch 124, Loss: 0.42669420619403303\n",
      "Epoch 125, Loss: 0.42601054255890225\n",
      "Epoch 126, Loss: 0.425336430427856\n",
      "Epoch 127, Loss: 0.4246679327066095\n",
      "Epoch 128, Loss: 0.42400381077097565\n",
      "Epoch 129, Loss: 0.42335124808925273\n",
      "Epoch 130, Loss: 0.42272806456520595\n",
      "Epoch 131, Loss: 0.4223643043814378\n",
      "Epoch 132, Loss: 0.4229644378058992\n",
      "Epoch 133, Loss: 0.42322506168010576\n",
      "Epoch 134, Loss: 0.42038426336108875\n",
      "Epoch 135, Loss: 0.4215912217690772\n",
      "Epoch 136, Loss: 0.4199339576579734\n",
      "Epoch 137, Loss: 0.419693694108032\n",
      "Epoch 138, Loss: 0.4191484470117507\n",
      "Epoch 139, Loss: 0.418215188790068\n",
      "Epoch 140, Loss: 0.41820257544949074\n",
      "Epoch 141, Loss: 0.4170605427018514\n",
      "Epoch 142, Loss: 0.417289752787586\n",
      "Epoch 143, Loss: 0.41591383355819744\n",
      "Epoch 144, Loss: 0.416173233479724\n",
      "Epoch 145, Loss: 0.4149076006758825\n",
      "Epoch 146, Loss: 0.4150238393347863\n",
      "Epoch 147, Loss: 0.41402627678538323\n",
      "Epoch 148, Loss: 0.41375528490661556\n",
      "Epoch 149, Loss: 0.4132256418181508\n",
      "Epoch 150, Loss: 0.4125361831285703\n",
      "Epoch 151, Loss: 0.41241644316483705\n",
      "Epoch 152, Loss: 0.41149663344520643\n",
      "Epoch 153, Loss: 0.41131513453707713\n",
      "Epoch 154, Loss: 0.41077884468776077\n",
      "Epoch 155, Loss: 0.4101081274957374\n",
      "Epoch 156, Loss: 0.40994835080493064\n",
      "Epoch 157, Loss: 0.4092319791970642\n",
      "Epoch 158, Loss: 0.4087184409402798\n",
      "Epoch 159, Loss: 0.4084771254273777\n",
      "Epoch 160, Loss: 0.4078081583836987\n",
      "Epoch 161, Loss: 0.4073088857745909\n",
      "Epoch 162, Loss: 0.4070871420942087\n",
      "Epoch 163, Loss: 0.4065277177386118\n",
      "Epoch 164, Loss: 0.40590759666431525\n",
      "Epoch 165, Loss: 0.40560449154561096\n",
      "Epoch 166, Loss: 0.40532071860399266\n",
      "Epoch 167, Loss: 0.4047945985509557\n",
      "Epoch 168, Loss: 0.40421135776574385\n",
      "Epoch 169, Loss: 0.40380547555736634\n",
      "Epoch 170, Loss: 0.40356389926657776\n",
      "Epoch 171, Loss: 0.40327277838622566\n",
      "Epoch 172, Loss: 0.4028901399258513\n",
      "Epoch 173, Loss: 0.402383135747414\n",
      "Epoch 174, Loss: 0.4018795335315197\n",
      "Epoch 175, Loss: 0.40141927190902293\n",
      "Epoch 176, Loss: 0.40101385226546227\n",
      "Epoch 177, Loss: 0.40062546704721824\n",
      "Epoch 178, Loss: 0.40026194667916704\n",
      "Epoch 179, Loss: 0.3999858950571852\n",
      "Epoch 180, Loss: 0.3999857832945196\n",
      "Epoch 181, Loss: 0.40082691891680267\n",
      "Epoch 182, Loss: 0.4034966736707227\n",
      "Epoch 183, Loss: 0.40137361024790014\n",
      "Epoch 184, Loss: 0.39816935248777774\n",
      "Epoch 185, Loss: 0.3995660432085321\n",
      "Epoch 186, Loss: 0.39939303914075475\n",
      "Epoch 187, Loss: 0.3973599054770187\n",
      "Epoch 188, Loss: 0.39835598055584154\n",
      "Epoch 189, Loss: 0.3976071812721376\n",
      "Epoch 190, Loss: 0.3964426178389098\n",
      "Epoch 191, Loss: 0.39717519175309407\n",
      "Epoch 192, Loss: 0.39618728105232387\n",
      "Epoch 193, Loss: 0.3955823474870677\n",
      "Epoch 194, Loss: 0.39597097521796343\n",
      "Epoch 195, Loss: 0.39520915493689546\n",
      "Epoch 196, Loss: 0.39467219865969094\n",
      "Epoch 197, Loss: 0.39486638555642856\n",
      "Epoch 198, Loss: 0.3944652237739454\n",
      "Epoch 199, Loss: 0.39379430627562145\n",
      "Epoch 200, Loss: 0.39365374357390537\n",
      "Epoch 201, Loss: 0.3935855635654461\n",
      "Epoch 202, Loss: 0.39309773764516054\n",
      "Epoch 203, Loss: 0.392635587975174\n",
      "Epoch 204, Loss: 0.3924960150182305\n",
      "Epoch 205, Loss: 0.39234879660997296\n",
      "Epoch 206, Loss: 0.39193612359689883\n",
      "Epoch 207, Loss: 0.39149056856991804\n",
      "Epoch 208, Loss: 0.3912424928962608\n",
      "Epoch 209, Loss: 0.39111076668491757\n",
      "Epoch 210, Loss: 0.39091557185867415\n",
      "Epoch 211, Loss: 0.3906384847220817\n",
      "Epoch 212, Loss: 0.39028946771155304\n",
      "Epoch 213, Loss: 0.38993595386020674\n",
      "Epoch 214, Loss: 0.3896297937966595\n",
      "Epoch 215, Loss: 0.3893199865258564\n",
      "Epoch 216, Loss: 0.38901778504208284\n",
      "Epoch 217, Loss: 0.38875559762929507\n",
      "Epoch 218, Loss: 0.38858161529994567\n",
      "Epoch 219, Loss: 0.38859164306044897\n",
      "Epoch 220, Loss: 0.38928701135249305\n",
      "Epoch 221, Loss: 0.39112956838234864\n",
      "Epoch 222, Loss: 0.3935312685376168\n",
      "Epoch 223, Loss: 0.3896413243153597\n",
      "Epoch 224, Loss: 0.38702012851153494\n",
      "Epoch 225, Loss: 0.3888740013977884\n",
      "Epoch 226, Loss: 0.3888876043120618\n",
      "Epoch 227, Loss: 0.3863323670434977\n",
      "Epoch 228, Loss: 0.3871799955033332\n",
      "Epoch 229, Loss: 0.38781667198377767\n",
      "Epoch 230, Loss: 0.3859930840129626\n",
      "Epoch 231, Loss: 0.38571367762028225\n",
      "Epoch 232, Loss: 0.3866173967809556\n",
      "Epoch 233, Loss: 0.3864090768145347\n",
      "Epoch 234, Loss: 0.38440377507623663\n",
      "Epoch 235, Loss: 0.38516205247450613\n",
      "Epoch 236, Loss: 0.38560062176824433\n",
      "Epoch 237, Loss: 0.38406920946311657\n",
      "Epoch 238, Loss: 0.3837348569684225\n",
      "Epoch 239, Loss: 0.38401440321588287\n",
      "Epoch 240, Loss: 0.38412069111079106\n",
      "Epoch 241, Loss: 0.38243037244573286\n",
      "Epoch 242, Loss: 0.38262568995486157\n",
      "Epoch 243, Loss: 0.3828347841900171\n",
      "Epoch 244, Loss: 0.3824348922867511\n",
      "Epoch 245, Loss: 0.38162982968355197\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.24632662463899788\n",
      "Test R^2 score: 0.3454226075180372\n",
      "Num of epochs: 246\n",
      "Epoch 1, Loss: 0.5671275840197612\n",
      "Epoch 2, Loss: 0.565761014486413\n",
      "Epoch 3, Loss: 0.5644847504623008\n",
      "Epoch 4, Loss: 0.5633038499083995\n",
      "Epoch 5, Loss: 0.5622153621637453\n",
      "Epoch 6, Loss: 0.5612204090635322\n",
      "Epoch 7, Loss: 0.5603159784484563\n",
      "Epoch 8, Loss: 0.5595259191136076\n",
      "Epoch 9, Loss: 0.5588557022609275\n",
      "Epoch 10, Loss: 0.5583312478192604\n",
      "Epoch 11, Loss: 0.5578769806850863\n",
      "Epoch 12, Loss: 0.5574752707192773\n",
      "Epoch 13, Loss: 0.5571258036654956\n",
      "Epoch 14, Loss: 0.5568304976161138\n",
      "Epoch 15, Loss: 0.5566172812402329\n",
      "Epoch 16, Loss: 0.556443698247387\n",
      "Epoch 17, Loss: 0.5563049375000535\n",
      "Epoch 18, Loss: 0.5562085532702528\n",
      "Epoch 19, Loss: 0.5561494768586254\n",
      "Epoch 20, Loss: 0.5561099551209282\n",
      "Epoch 21, Loss: 0.5560866962702563\n",
      "Epoch 22, Loss: 0.5560771834415801\n",
      "Epoch 23, Loss: 0.5560937169014175\n",
      "Epoch 24, Loss: 0.5560924038893509\n",
      "Epoch 25, Loss: 0.5560814173403549\n",
      "Epoch 26, Loss: 0.556055236323052\n",
      "Epoch 27, Loss: 0.5560040498112623\n",
      "Epoch 28, Loss: 0.5559183085465044\n",
      "Epoch 29, Loss: 0.555795101007118\n",
      "Epoch 30, Loss: 0.555632095892343\n",
      "Epoch 31, Loss: 0.5554445231931454\n",
      "Epoch 32, Loss: 0.5552095991720211\n",
      "Epoch 33, Loss: 0.5549061572579712\n",
      "Epoch 34, Loss: 0.554510222568652\n",
      "Epoch 35, Loss: 0.553995910188748\n",
      "Epoch 36, Loss: 0.5533362841766835\n",
      "Epoch 37, Loss: 0.5525091676253513\n",
      "Epoch 38, Loss: 0.5514755472259456\n",
      "Epoch 39, Loss: 0.5501959105012059\n",
      "Epoch 40, Loss: 0.5486042475639898\n",
      "Epoch 41, Loss: 0.5466133309092962\n",
      "Epoch 42, Loss: 0.544130605371243\n",
      "Epoch 43, Loss: 0.5411000099888528\n",
      "Epoch 44, Loss: 0.5375067333420684\n",
      "Epoch 45, Loss: 0.5334170684298434\n",
      "Epoch 46, Loss: 0.5290488193228036\n",
      "Epoch 47, Loss: 0.5249552855296308\n",
      "Epoch 48, Loss: 0.5221665167801722\n",
      "Epoch 49, Loss: 0.521434138589317\n",
      "Epoch 50, Loss: 0.520742538803425\n",
      "Epoch 51, Loss: 0.5178451712873536\n",
      "Epoch 52, Loss: 0.5137262061797585\n",
      "Epoch 53, Loss: 0.510158460533412\n",
      "Epoch 54, Loss: 0.507971753311314\n",
      "Epoch 55, Loss: 0.5063903849422647\n",
      "Epoch 56, Loss: 0.504621751831048\n",
      "Epoch 57, Loss: 0.5022482394106413\n",
      "Epoch 58, Loss: 0.4993610173393582\n",
      "Epoch 59, Loss: 0.49653073086190164\n",
      "Epoch 60, Loss: 0.49428245710312474\n",
      "Epoch 61, Loss: 0.4927717404633042\n",
      "Epoch 62, Loss: 0.4915404229077922\n",
      "Epoch 63, Loss: 0.4898364667335788\n",
      "Epoch 64, Loss: 0.487660371860146\n",
      "Epoch 65, Loss: 0.48564137761349907\n",
      "Epoch 66, Loss: 0.48410932884490654\n",
      "Epoch 67, Loss: 0.4828726635332532\n",
      "Epoch 68, Loss: 0.48158867115691545\n",
      "Epoch 69, Loss: 0.48003406555271894\n",
      "Epoch 70, Loss: 0.4784657199293533\n",
      "Epoch 71, Loss: 0.4771621870760426\n",
      "Epoch 72, Loss: 0.4761252194987718\n",
      "Epoch 73, Loss: 0.475127686730556\n",
      "Epoch 74, Loss: 0.4739115415957496\n",
      "Epoch 75, Loss: 0.4726100142382522\n",
      "Epoch 76, Loss: 0.47151128949679716\n",
      "Epoch 77, Loss: 0.470619938254524\n",
      "Epoch 78, Loss: 0.46974040940905715\n",
      "Epoch 79, Loss: 0.4688182940006181\n",
      "Epoch 80, Loss: 0.46786238555352366\n",
      "Epoch 81, Loss: 0.4670310291074075\n",
      "Epoch 82, Loss: 0.46624359157136513\n",
      "Epoch 83, Loss: 0.46532408956693705\n",
      "Epoch 84, Loss: 0.4643940232694442\n",
      "Epoch 85, Loss: 0.46359368543171214\n",
      "Epoch 86, Loss: 0.46271036557548945\n",
      "Epoch 87, Loss: 0.4616455846349971\n",
      "Epoch 88, Loss: 0.46073843003212805\n",
      "Epoch 89, Loss: 0.4598832601410432\n",
      "Epoch 90, Loss: 0.4589576226412338\n",
      "Epoch 91, Loss: 0.4580303585139852\n",
      "Epoch 92, Loss: 0.4571786463487096\n",
      "Epoch 93, Loss: 0.4564220737585997\n",
      "Epoch 94, Loss: 0.4557157478173466\n",
      "Epoch 95, Loss: 0.45502636987649614\n",
      "Epoch 96, Loss: 0.4543232038483096\n",
      "Epoch 97, Loss: 0.4536156792880135\n",
      "Epoch 98, Loss: 0.45298855470152294\n",
      "Epoch 99, Loss: 0.45238465633136804\n",
      "Epoch 100, Loss: 0.4518444448247145\n",
      "Epoch 101, Loss: 0.45130543569063364\n",
      "Epoch 102, Loss: 0.45073078937501426\n",
      "Epoch 103, Loss: 0.45015982862464865\n",
      "Epoch 104, Loss: 0.44958739703406825\n",
      "Epoch 105, Loss: 0.4490436212583796\n",
      "Epoch 106, Loss: 0.4484877069791593\n",
      "Epoch 107, Loss: 0.4479214886102691\n",
      "Epoch 108, Loss: 0.4473277552733495\n",
      "Epoch 109, Loss: 0.44671878952127597\n",
      "Epoch 110, Loss: 0.44612243680359265\n",
      "Epoch 111, Loss: 0.44556053682478836\n",
      "Epoch 112, Loss: 0.4449992667685051\n",
      "Epoch 113, Loss: 0.4444317389533128\n",
      "Epoch 114, Loss: 0.4438737918221766\n",
      "Epoch 115, Loss: 0.44333046974366336\n",
      "Epoch 116, Loss: 0.44279883151606636\n",
      "Epoch 117, Loss: 0.44226222468398024\n",
      "Epoch 118, Loss: 0.4416845339034087\n",
      "Epoch 119, Loss: 0.4411130792407472\n",
      "Epoch 120, Loss: 0.4405549034202953\n",
      "Epoch 121, Loss: 0.439995579236754\n",
      "Epoch 122, Loss: 0.4393872699136705\n",
      "Epoch 123, Loss: 0.4387529517343462\n",
      "Epoch 124, Loss: 0.43815456538226477\n",
      "Epoch 125, Loss: 0.4375624101265732\n",
      "Epoch 126, Loss: 0.43694512056916934\n",
      "Epoch 127, Loss: 0.43632029814090795\n",
      "Epoch 128, Loss: 0.43570945681792855\n",
      "Epoch 129, Loss: 0.4351027067106833\n",
      "Epoch 130, Loss: 0.4344793846070682\n",
      "Epoch 131, Loss: 0.43385420528684937\n",
      "Epoch 132, Loss: 0.43319016653067705\n",
      "Epoch 133, Loss: 0.4324805084698465\n",
      "Epoch 134, Loss: 0.4317768106480144\n",
      "Epoch 135, Loss: 0.43106473937800405\n",
      "Epoch 136, Loss: 0.43030228416378286\n",
      "Epoch 137, Loss: 0.4295488827535553\n",
      "Epoch 138, Loss: 0.4288197859309283\n",
      "Epoch 139, Loss: 0.42813467864073984\n",
      "Epoch 140, Loss: 0.427458669912157\n",
      "Epoch 141, Loss: 0.42683661320394506\n",
      "Epoch 142, Loss: 0.4262730968627721\n",
      "Epoch 143, Loss: 0.42558550053399435\n",
      "Epoch 144, Loss: 0.4247181595997555\n",
      "Epoch 145, Loss: 0.4238984713208027\n",
      "Epoch 146, Loss: 0.4233159957205217\n",
      "Epoch 147, Loss: 0.4227266721882008\n",
      "Epoch 148, Loss: 0.421886390956108\n",
      "Epoch 149, Loss: 0.421061296220927\n",
      "Epoch 150, Loss: 0.4203964213432652\n",
      "Epoch 151, Loss: 0.419852956394782\n",
      "Epoch 152, Loss: 0.4192960466974108\n",
      "Epoch 153, Loss: 0.41846940546423844\n",
      "Epoch 154, Loss: 0.4176281405721602\n",
      "Epoch 155, Loss: 0.41689722914100913\n",
      "Epoch 156, Loss: 0.4163132440216467\n",
      "Epoch 157, Loss: 0.4158128414316064\n",
      "Epoch 158, Loss: 0.41537560674535223\n",
      "Epoch 159, Loss: 0.4147801208549701\n",
      "Epoch 160, Loss: 0.4137633700673981\n",
      "Epoch 161, Loss: 0.4128181906458789\n",
      "Epoch 162, Loss: 0.4122569647004625\n",
      "Epoch 163, Loss: 0.4119697623580072\n",
      "Epoch 164, Loss: 0.4115212026281011\n",
      "Epoch 165, Loss: 0.41058095106410986\n",
      "Epoch 166, Loss: 0.4094997237848508\n",
      "Epoch 167, Loss: 0.40880051846042087\n",
      "Epoch 168, Loss: 0.40852192015766514\n",
      "Epoch 169, Loss: 0.40845084089047157\n",
      "Epoch 170, Loss: 0.40766422163047367\n",
      "Epoch 171, Loss: 0.4066320053784731\n",
      "Epoch 172, Loss: 0.40566670284229284\n",
      "Epoch 173, Loss: 0.40527571711990645\n",
      "Epoch 174, Loss: 0.4052143099751871\n",
      "Epoch 175, Loss: 0.40483424276763064\n",
      "Epoch 176, Loss: 0.4041161432673285\n",
      "Epoch 177, Loss: 0.40290262239563285\n",
      "Epoch 178, Loss: 0.402171403582047\n",
      "Epoch 179, Loss: 0.4019352403819543\n",
      "Epoch 180, Loss: 0.40193290474230764\n",
      "Epoch 181, Loss: 0.4021158776758955\n",
      "Epoch 182, Loss: 0.4012330473827332\n",
      "Epoch 183, Loss: 0.39991963294433425\n",
      "Epoch 184, Loss: 0.3987706418509366\n",
      "Epoch 185, Loss: 0.39871126007667995\n",
      "Epoch 186, Loss: 0.39899816521722276\n",
      "Epoch 187, Loss: 0.3980862995722886\n",
      "Epoch 188, Loss: 0.397131330958961\n",
      "Epoch 189, Loss: 0.3961448907285087\n",
      "Epoch 190, Loss: 0.39598965904191297\n",
      "Epoch 191, Loss: 0.3963938266730559\n",
      "Epoch 192, Loss: 0.39585309439405264\n",
      "Epoch 193, Loss: 0.3953052331610854\n",
      "Epoch 194, Loss: 0.39391026868211526\n",
      "Epoch 195, Loss: 0.39338153977438506\n",
      "Epoch 196, Loss: 0.39345411051984314\n",
      "Epoch 197, Loss: 0.39341356572803243\n",
      "Epoch 198, Loss: 0.39368014548566643\n",
      "Epoch 199, Loss: 0.39220148494756424\n",
      "Epoch 200, Loss: 0.39142460047178923\n",
      "Epoch 201, Loss: 0.3907873960527985\n",
      "Epoch 202, Loss: 0.3906984069514939\n",
      "Epoch 203, Loss: 0.39096106378175816\n",
      "Epoch 204, Loss: 0.39036034201501585\n",
      "Epoch 205, Loss: 0.38997850325222794\n",
      "Epoch 206, Loss: 0.3888992143104152\n",
      "Epoch 207, Loss: 0.3883995942688717\n",
      "Epoch 208, Loss: 0.38832239512495303\n",
      "Epoch 209, Loss: 0.3880779578468936\n",
      "Epoch 210, Loss: 0.38833279411472216\n",
      "Epoch 211, Loss: 0.3879488829228282\n",
      "Epoch 212, Loss: 0.38763123566484214\n",
      "Epoch 213, Loss: 0.3867971360111916\n",
      "Epoch 214, Loss: 0.385939883020125\n",
      "Epoch 215, Loss: 0.38550110055343334\n",
      "Epoch 216, Loss: 0.3851615688738226\n",
      "Epoch 217, Loss: 0.3849694539932365\n",
      "Epoch 218, Loss: 0.3850225568640967\n",
      "Epoch 219, Loss: 0.3852951163139599\n",
      "Epoch 220, Loss: 0.3855865744082238\n",
      "Epoch 221, Loss: 0.3860001872190703\n",
      "Epoch 222, Loss: 0.3844406575826935\n",
      "Epoch 223, Loss: 0.383122552145128\n",
      "Epoch 224, Loss: 0.3825891193339296\n",
      "Epoch 225, Loss: 0.3831144037694956\n",
      "Epoch 226, Loss: 0.38374932158593467\n",
      "Epoch 227, Loss: 0.3826353091222288\n",
      "Epoch 228, Loss: 0.3818058284976564\n",
      "Epoch 229, Loss: 0.3810242125009018\n",
      "Epoch 230, Loss: 0.3814164220570091\n",
      "Epoch 231, Loss: 0.3819278108943701\n",
      "Epoch 232, Loss: 0.38128134020205634\n",
      "Epoch 233, Loss: 0.3805937403102491\n",
      "Epoch 234, Loss: 0.3795875441292877\n",
      "Epoch 235, Loss: 0.37980227364386354\n",
      "Epoch 236, Loss: 0.3799642951089886\n",
      "Epoch 237, Loss: 0.37975736767977986\n",
      "Epoch 238, Loss: 0.379684769263475\n",
      "Epoch 239, Loss: 0.3785117937490533\n",
      "Epoch 240, Loss: 0.37820928910970175\n",
      "Epoch 241, Loss: 0.37794537967563246\n",
      "Epoch 242, Loss: 0.37797753082963165\n",
      "Epoch 243, Loss: 0.37838571718663017\n",
      "Epoch 244, Loss: 0.3776643003616599\n",
      "Epoch 245, Loss: 0.37749167992094645\n",
      "Epoch 246, Loss: 0.37671972371960066\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2462898089872655\n",
      "Test R^2 score: 0.34168913945367274\n",
      "Num of epochs: 247\n",
      "Epoch 1, Loss: 0.5706634486804382\n",
      "Epoch 2, Loss: 0.5694273781997372\n",
      "Epoch 3, Loss: 0.5682542316935405\n",
      "Epoch 4, Loss: 0.5671443733654571\n",
      "Epoch 5, Loss: 0.566141579713491\n",
      "Epoch 6, Loss: 0.5653459819707259\n",
      "Epoch 7, Loss: 0.5646018390039107\n",
      "Epoch 8, Loss: 0.5638969083219939\n",
      "Epoch 9, Loss: 0.5632270247221904\n",
      "Epoch 10, Loss: 0.5625914658250734\n",
      "Epoch 11, Loss: 0.5620101809377038\n",
      "Epoch 12, Loss: 0.5614942725527237\n",
      "Epoch 13, Loss: 0.5610113844387874\n",
      "Epoch 14, Loss: 0.5605547967543737\n",
      "Epoch 15, Loss: 0.5601611521571557\n",
      "Epoch 16, Loss: 0.5597567688693266\n",
      "Epoch 17, Loss: 0.5593580072901392\n",
      "Epoch 18, Loss: 0.5589814074722096\n",
      "Epoch 19, Loss: 0.5586535015026854\n",
      "Epoch 20, Loss: 0.5583666626628249\n",
      "Epoch 21, Loss: 0.5580828804791608\n",
      "Epoch 22, Loss: 0.5578114827464683\n",
      "Epoch 23, Loss: 0.5575572447617325\n",
      "Epoch 24, Loss: 0.5573314195043765\n",
      "Epoch 25, Loss: 0.5571412896694938\n",
      "Epoch 26, Loss: 0.5569531015414039\n",
      "Epoch 27, Loss: 0.556772156283523\n",
      "Epoch 28, Loss: 0.5565954625062286\n",
      "Epoch 29, Loss: 0.5564213103195392\n",
      "Epoch 30, Loss: 0.5562473982846569\n",
      "Epoch 31, Loss: 0.5560716364494654\n",
      "Epoch 32, Loss: 0.5558920662355138\n",
      "Epoch 33, Loss: 0.5557044472122927\n",
      "Epoch 34, Loss: 0.5555029234856452\n",
      "Epoch 35, Loss: 0.5552798855488011\n",
      "Epoch 36, Loss: 0.5550280318183272\n",
      "Epoch 37, Loss: 0.5547346444310473\n",
      "Epoch 38, Loss: 0.5543856000693238\n",
      "Epoch 39, Loss: 0.5539672904015532\n",
      "Epoch 40, Loss: 0.5534437500370825\n",
      "Epoch 41, Loss: 0.5527866999253828\n",
      "Epoch 42, Loss: 0.5519540353431402\n",
      "Epoch 43, Loss: 0.5509011969936438\n",
      "Epoch 44, Loss: 0.5495769510146815\n",
      "Epoch 45, Loss: 0.5479210794172044\n",
      "Epoch 46, Loss: 0.5458716588967402\n",
      "Epoch 47, Loss: 0.5433674453146994\n",
      "Epoch 48, Loss: 0.5403402637079993\n",
      "Epoch 49, Loss: 0.5367252710382145\n",
      "Epoch 50, Loss: 0.532497400089418\n",
      "Epoch 51, Loss: 0.5276921287133909\n",
      "Epoch 52, Loss: 0.5225450109414287\n",
      "Epoch 53, Loss: 0.5176446260159872\n",
      "Epoch 54, Loss: 0.5140896972604099\n",
      "Epoch 55, Loss: 0.5128546766828268\n",
      "Epoch 56, Loss: 0.5118320427034371\n",
      "Epoch 57, Loss: 0.5085401456977616\n",
      "Epoch 58, Loss: 0.5037453564602591\n",
      "Epoch 59, Loss: 0.4995400130834004\n",
      "Epoch 60, Loss: 0.49702871631982665\n",
      "Epoch 61, Loss: 0.49530096612251123\n",
      "Epoch 62, Loss: 0.4925696993174511\n",
      "Epoch 63, Loss: 0.4887273810291825\n",
      "Epoch 64, Loss: 0.48469071712446904\n",
      "Epoch 65, Loss: 0.481248548431189\n",
      "Epoch 66, Loss: 0.47905170229434263\n",
      "Epoch 67, Loss: 0.47796540058679593\n",
      "Epoch 68, Loss: 0.47741199823399644\n",
      "Epoch 69, Loss: 0.4767332083961091\n",
      "Epoch 70, Loss: 0.4754103820256117\n",
      "Epoch 71, Loss: 0.4737840705889777\n",
      "Epoch 72, Loss: 0.4723496506676059\n",
      "Epoch 73, Loss: 0.4713710146118192\n",
      "Epoch 74, Loss: 0.47077572527814326\n",
      "Epoch 75, Loss: 0.47035593865117653\n",
      "Epoch 76, Loss: 0.4700008709625534\n",
      "Epoch 77, Loss: 0.4695211266618013\n",
      "Epoch 78, Loss: 0.46872630059413134\n",
      "Epoch 79, Loss: 0.46760231025629256\n",
      "Epoch 80, Loss: 0.46632538610450674\n",
      "Epoch 81, Loss: 0.46516766201957477\n",
      "Epoch 82, Loss: 0.4643212595632112\n",
      "Epoch 83, Loss: 0.4637896342447902\n",
      "Epoch 84, Loss: 0.46333050650939533\n",
      "Epoch 85, Loss: 0.4627604402088795\n",
      "Epoch 86, Loss: 0.46206775390783467\n",
      "Epoch 87, Loss: 0.4613087662164705\n",
      "Epoch 88, Loss: 0.46046086900359395\n",
      "Epoch 89, Loss: 0.4596672011094079\n",
      "Epoch 90, Loss: 0.4590237052786199\n",
      "Epoch 91, Loss: 0.458484864833752\n",
      "Epoch 92, Loss: 0.4579452602072051\n",
      "Epoch 93, Loss: 0.45727952913528674\n",
      "Epoch 94, Loss: 0.4564798566472861\n",
      "Epoch 95, Loss: 0.4556689704012638\n",
      "Epoch 96, Loss: 0.4550207535758038\n",
      "Epoch 97, Loss: 0.4544880032807819\n",
      "Epoch 98, Loss: 0.453910754734607\n",
      "Epoch 99, Loss: 0.45322242873255375\n",
      "Epoch 100, Loss: 0.45253348382072234\n",
      "Epoch 101, Loss: 0.4519158047076927\n",
      "Epoch 102, Loss: 0.45138929338518585\n",
      "Epoch 103, Loss: 0.45091831629097756\n",
      "Epoch 104, Loss: 0.4504074126635979\n",
      "Epoch 105, Loss: 0.4498436437608674\n",
      "Epoch 106, Loss: 0.4492884042890231\n",
      "Epoch 107, Loss: 0.4487816383982239\n",
      "Epoch 108, Loss: 0.44831220956705475\n",
      "Epoch 109, Loss: 0.4478293285681784\n",
      "Epoch 110, Loss: 0.447330070417024\n",
      "Epoch 111, Loss: 0.4468226842334571\n",
      "Epoch 112, Loss: 0.44633867584850523\n",
      "Epoch 113, Loss: 0.44588348524010024\n",
      "Epoch 114, Loss: 0.4454028389297679\n",
      "Epoch 115, Loss: 0.44489362323878634\n",
      "Epoch 116, Loss: 0.4443973876045845\n",
      "Epoch 117, Loss: 0.4439279380852351\n",
      "Epoch 118, Loss: 0.4434560426702277\n",
      "Epoch 119, Loss: 0.44296961722045186\n",
      "Epoch 120, Loss: 0.4424659196208244\n",
      "Epoch 121, Loss: 0.4419512801850852\n",
      "Epoch 122, Loss: 0.4414446822458063\n",
      "Epoch 123, Loss: 0.44092768492612533\n",
      "Epoch 124, Loss: 0.44040876114690414\n",
      "Epoch 125, Loss: 0.43988883564928294\n",
      "Epoch 126, Loss: 0.4393786049283905\n",
      "Epoch 127, Loss: 0.438865030756202\n",
      "Epoch 128, Loss: 0.43835673574639933\n",
      "Epoch 129, Loss: 0.4378568692429843\n",
      "Epoch 130, Loss: 0.4373760729065475\n",
      "Epoch 131, Loss: 0.436892718090903\n",
      "Epoch 132, Loss: 0.4364293997770997\n",
      "Epoch 133, Loss: 0.4359794999813105\n",
      "Epoch 134, Loss: 0.43553250549971906\n",
      "Epoch 135, Loss: 0.43507844171086113\n",
      "Epoch 136, Loss: 0.43461120070218506\n",
      "Epoch 137, Loss: 0.4341184002259012\n",
      "Epoch 138, Loss: 0.4336008982026204\n",
      "Epoch 139, Loss: 0.4330825369525835\n",
      "Epoch 140, Loss: 0.43255599301672887\n",
      "Epoch 141, Loss: 0.43202278860128934\n",
      "Epoch 142, Loss: 0.4314737990072798\n",
      "Epoch 143, Loss: 0.43087925800225957\n",
      "Epoch 144, Loss: 0.430218593792178\n",
      "Epoch 145, Loss: 0.42955084274861166\n",
      "Epoch 146, Loss: 0.42890439198131464\n",
      "Epoch 147, Loss: 0.42831973081480534\n",
      "Epoch 148, Loss: 0.4277484316671705\n",
      "Epoch 149, Loss: 0.42719597222745753\n",
      "Epoch 150, Loss: 0.4266498350509026\n",
      "Epoch 151, Loss: 0.4261115306785592\n",
      "Epoch 152, Loss: 0.4255844676398095\n",
      "Epoch 153, Loss: 0.4250709839052588\n",
      "Epoch 154, Loss: 0.4245641092915432\n",
      "Epoch 155, Loss: 0.424069015323567\n",
      "Epoch 156, Loss: 0.42356876928613085\n",
      "Epoch 157, Loss: 0.423084027745041\n",
      "Epoch 158, Loss: 0.42262409955221864\n",
      "Epoch 159, Loss: 0.4221770300368133\n",
      "Epoch 160, Loss: 0.42181099300140756\n",
      "Epoch 161, Loss: 0.42158823510209753\n",
      "Epoch 162, Loss: 0.42111471332748684\n",
      "Epoch 163, Loss: 0.4204372348549229\n",
      "Epoch 164, Loss: 0.4198899722733196\n",
      "Epoch 165, Loss: 0.41970322705169594\n",
      "Epoch 166, Loss: 0.4192479958642726\n",
      "Epoch 167, Loss: 0.4185997309013628\n",
      "Epoch 168, Loss: 0.4183114509666258\n",
      "Epoch 169, Loss: 0.4181158217034296\n",
      "Epoch 170, Loss: 0.4175507960284409\n",
      "Epoch 171, Loss: 0.4169596138946538\n",
      "Epoch 172, Loss: 0.41672593132385033\n",
      "Epoch 173, Loss: 0.4164802571388115\n",
      "Epoch 174, Loss: 0.41584571986521274\n",
      "Epoch 175, Loss: 0.41545927429296703\n",
      "Epoch 176, Loss: 0.41525830032164673\n",
      "Epoch 177, Loss: 0.41485376148392145\n",
      "Epoch 178, Loss: 0.4143155242560948\n",
      "Epoch 179, Loss: 0.4139867749336279\n",
      "Epoch 180, Loss: 0.4137642704096021\n",
      "Epoch 181, Loss: 0.41340738329543536\n",
      "Epoch 182, Loss: 0.41295554986843896\n",
      "Epoch 183, Loss: 0.412522186058355\n",
      "Epoch 184, Loss: 0.41223921696479343\n",
      "Epoch 185, Loss: 0.41205106566788596\n",
      "Epoch 186, Loss: 0.41189918762524225\n",
      "Epoch 187, Loss: 0.41174046786681157\n",
      "Epoch 188, Loss: 0.4111732771072386\n",
      "Epoch 189, Loss: 0.4105899697433223\n",
      "Epoch 190, Loss: 0.4103745379182443\n",
      "Epoch 191, Loss: 0.4103149288770921\n",
      "Epoch 192, Loss: 0.4099177802615476\n",
      "Epoch 193, Loss: 0.4093818074308297\n",
      "Epoch 194, Loss: 0.4090614421122651\n",
      "Epoch 195, Loss: 0.4089398648617646\n",
      "Epoch 196, Loss: 0.4087942123999994\n",
      "Epoch 197, Loss: 0.4086639139825319\n",
      "Epoch 198, Loss: 0.408271035564082\n",
      "Epoch 199, Loss: 0.40780450440384436\n",
      "Epoch 200, Loss: 0.4074281335424968\n",
      "Epoch 201, Loss: 0.4072451324253958\n",
      "Epoch 202, Loss: 0.4071882490618148\n",
      "Epoch 203, Loss: 0.40714841316908934\n",
      "Epoch 204, Loss: 0.4069313607682146\n",
      "Epoch 205, Loss: 0.40649969423641513\n",
      "Epoch 206, Loss: 0.406055825852509\n",
      "Epoch 207, Loss: 0.4057693388919985\n",
      "Epoch 208, Loss: 0.40566831907005285\n",
      "Epoch 209, Loss: 0.40570372753513606\n",
      "Epoch 210, Loss: 0.4055927167956154\n",
      "Epoch 211, Loss: 0.4052280630425785\n",
      "Epoch 212, Loss: 0.4047535698764475\n",
      "Epoch 213, Loss: 0.40437417512246476\n",
      "Epoch 214, Loss: 0.40413845109603774\n",
      "Epoch 215, Loss: 0.40411664105875694\n",
      "Epoch 216, Loss: 0.40432037064101506\n",
      "Epoch 217, Loss: 0.4045671306093457\n",
      "Epoch 218, Loss: 0.4044322280245426\n",
      "Epoch 219, Loss: 0.4034128706348374\n",
      "Epoch 220, Loss: 0.40288810570894334\n",
      "Epoch 221, Loss: 0.4032550601961009\n",
      "Epoch 222, Loss: 0.40326067689121875\n",
      "Epoch 223, Loss: 0.40271416066718313\n",
      "Epoch 224, Loss: 0.4020482061126201\n",
      "Epoch 225, Loss: 0.40196910563176436\n",
      "Epoch 226, Loss: 0.40210968912874634\n",
      "Epoch 227, Loss: 0.40191725931407984\n",
      "Epoch 228, Loss: 0.4013797544567842\n",
      "Epoch 229, Loss: 0.4010053799879518\n",
      "Epoch 230, Loss: 0.40087210385757616\n",
      "Epoch 231, Loss: 0.4009280621851681\n",
      "Epoch 232, Loss: 0.4008027723456342\n",
      "Epoch 233, Loss: 0.4005053286120557\n",
      "Epoch 234, Loss: 0.4001439893364289\n",
      "Epoch 235, Loss: 0.3997645437625937\n",
      "Epoch 236, Loss: 0.3995211581259858\n",
      "Epoch 237, Loss: 0.3993729661164409\n",
      "Epoch 238, Loss: 0.39921542500344875\n",
      "Epoch 239, Loss: 0.3991750920978716\n",
      "Epoch 240, Loss: 0.39933205207965183\n",
      "Epoch 241, Loss: 0.3995051012071574\n",
      "Epoch 242, Loss: 0.3995329253303691\n",
      "Epoch 243, Loss: 0.39838113573111333\n",
      "Epoch 244, Loss: 0.39759185284575177\n",
      "Epoch 245, Loss: 0.3974106402990436\n",
      "Epoch 246, Loss: 0.3975948511174522\n",
      "Epoch 247, Loss: 0.39796541333157087\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22960294321205035\n",
      "Test R^2 score: 0.42610039423262486\n",
      "Num of epochs: 248\n",
      "Epoch 1, Loss: 0.5872566886040256\n",
      "Epoch 2, Loss: 0.5845758511134\n",
      "Epoch 3, Loss: 0.5819846012955774\n",
      "Epoch 4, Loss: 0.5795818993555023\n",
      "Epoch 5, Loss: 0.5772650741221393\n",
      "Epoch 6, Loss: 0.5750379881542041\n",
      "Epoch 7, Loss: 0.5729098030603973\n",
      "Epoch 8, Loss: 0.5708932662975015\n",
      "Epoch 9, Loss: 0.5689930218468148\n",
      "Epoch 10, Loss: 0.5672023308866813\n",
      "Epoch 11, Loss: 0.5655501901039611\n",
      "Epoch 12, Loss: 0.5640170514931264\n",
      "Epoch 13, Loss: 0.56260598032004\n",
      "Epoch 14, Loss: 0.5613570522428376\n",
      "Epoch 15, Loss: 0.5602391425054776\n",
      "Epoch 16, Loss: 0.559274325554978\n",
      "Epoch 17, Loss: 0.5584324156919833\n",
      "Epoch 18, Loss: 0.5577097480232537\n",
      "Epoch 19, Loss: 0.5571026674689854\n",
      "Epoch 20, Loss: 0.5566176292621889\n",
      "Epoch 21, Loss: 0.556246674988485\n",
      "Epoch 22, Loss: 0.5560132690911486\n",
      "Epoch 23, Loss: 0.5558701922288337\n",
      "Epoch 24, Loss: 0.5557885591993146\n",
      "Epoch 25, Loss: 0.5557513176871949\n",
      "Epoch 26, Loss: 0.5557570287506242\n",
      "Epoch 27, Loss: 0.555766171692427\n",
      "Epoch 28, Loss: 0.5557474030276569\n",
      "Epoch 29, Loss: 0.555686936804349\n",
      "Epoch 30, Loss: 0.5555633292713943\n",
      "Epoch 31, Loss: 0.5553571124771173\n",
      "Epoch 32, Loss: 0.5550448649976532\n",
      "Epoch 33, Loss: 0.5546131352824966\n",
      "Epoch 34, Loss: 0.5540602455157839\n",
      "Epoch 35, Loss: 0.553381766512931\n",
      "Epoch 36, Loss: 0.5525479221274203\n",
      "Epoch 37, Loss: 0.5514937047227291\n",
      "Epoch 38, Loss: 0.5501759226086951\n",
      "Epoch 39, Loss: 0.548552610266684\n",
      "Epoch 40, Loss: 0.546512210946855\n",
      "Epoch 41, Loss: 0.5438994520157615\n",
      "Epoch 42, Loss: 0.5406535069441417\n",
      "Epoch 43, Loss: 0.5367555319719095\n",
      "Epoch 44, Loss: 0.5323486468081788\n",
      "Epoch 45, Loss: 0.5277206204511617\n",
      "Epoch 46, Loss: 0.5230998473233376\n",
      "Epoch 47, Loss: 0.5188417089355848\n",
      "Epoch 48, Loss: 0.5150722372909594\n",
      "Epoch 49, Loss: 0.5112939192227722\n",
      "Epoch 50, Loss: 0.5073739432234378\n",
      "Epoch 51, Loss: 0.5038334106319484\n",
      "Epoch 52, Loss: 0.501149138531767\n",
      "Epoch 53, Loss: 0.4990143896428568\n",
      "Epoch 54, Loss: 0.4963991471677873\n",
      "Epoch 55, Loss: 0.4930002828146489\n",
      "Epoch 56, Loss: 0.4894435628944875\n",
      "Epoch 57, Loss: 0.48624492990748297\n",
      "Epoch 58, Loss: 0.4834783468762914\n",
      "Epoch 59, Loss: 0.48193104288185573\n",
      "Epoch 60, Loss: 0.4821570283331026\n",
      "Epoch 61, Loss: 0.4821630393577599\n",
      "Epoch 62, Loss: 0.4806788535634385\n",
      "Epoch 63, Loss: 0.47871552009521356\n",
      "Epoch 64, Loss: 0.4769005592616076\n",
      "Epoch 65, Loss: 0.47547427203995524\n",
      "Epoch 66, Loss: 0.4747557237831494\n",
      "Epoch 67, Loss: 0.47404669542314565\n",
      "Epoch 68, Loss: 0.47276175716431856\n",
      "Epoch 69, Loss: 0.47106293028672264\n",
      "Epoch 70, Loss: 0.4695376295776611\n",
      "Epoch 71, Loss: 0.4683260430954175\n",
      "Epoch 72, Loss: 0.46746564386981815\n",
      "Epoch 73, Loss: 0.46686668352842176\n",
      "Epoch 74, Loss: 0.4661743769795112\n",
      "Epoch 75, Loss: 0.4652552506305829\n",
      "Epoch 76, Loss: 0.46418399633192436\n",
      "Epoch 77, Loss: 0.46324355115174315\n",
      "Epoch 78, Loss: 0.46254471034372796\n",
      "Epoch 79, Loss: 0.46196194938851665\n",
      "Epoch 80, Loss: 0.4613484474247372\n",
      "Epoch 81, Loss: 0.4606066664174802\n",
      "Epoch 82, Loss: 0.4597543629163919\n",
      "Epoch 83, Loss: 0.4589629147970916\n",
      "Epoch 84, Loss: 0.4583499988502643\n",
      "Epoch 85, Loss: 0.4578389098325762\n",
      "Epoch 86, Loss: 0.4572456215752592\n",
      "Epoch 87, Loss: 0.45654548195539874\n",
      "Epoch 88, Loss: 0.4558887383974712\n",
      "Epoch 89, Loss: 0.4553467935700356\n",
      "Epoch 90, Loss: 0.4548334601865605\n",
      "Epoch 91, Loss: 0.45429271653454156\n",
      "Epoch 92, Loss: 0.45369474174373353\n",
      "Epoch 93, Loss: 0.4530503277253188\n",
      "Epoch 94, Loss: 0.4524438440927014\n",
      "Epoch 95, Loss: 0.4519185909440363\n",
      "Epoch 96, Loss: 0.4513887817024039\n",
      "Epoch 97, Loss: 0.4507853516073081\n",
      "Epoch 98, Loss: 0.45016260917856515\n",
      "Epoch 99, Loss: 0.44958431462395\n",
      "Epoch 100, Loss: 0.4490445006392822\n",
      "Epoch 101, Loss: 0.4484889529280669\n",
      "Epoch 102, Loss: 0.44791761294715937\n",
      "Epoch 103, Loss: 0.44734296171736476\n",
      "Epoch 104, Loss: 0.4467899675097119\n",
      "Epoch 105, Loss: 0.446247858528534\n",
      "Epoch 106, Loss: 0.44565029048445837\n",
      "Epoch 107, Loss: 0.44503576480538026\n",
      "Epoch 108, Loss: 0.44445421929173595\n",
      "Epoch 109, Loss: 0.4438445339785499\n",
      "Epoch 110, Loss: 0.4432209151591063\n",
      "Epoch 111, Loss: 0.44262318259735733\n",
      "Epoch 112, Loss: 0.4420345695697278\n",
      "Epoch 113, Loss: 0.44143269890058356\n",
      "Epoch 114, Loss: 0.440790895250355\n",
      "Epoch 115, Loss: 0.4401726829269798\n",
      "Epoch 116, Loss: 0.43955860143695713\n",
      "Epoch 117, Loss: 0.438915126815339\n",
      "Epoch 118, Loss: 0.4382901719489082\n",
      "Epoch 119, Loss: 0.43765438285083424\n",
      "Epoch 120, Loss: 0.43699451604474915\n",
      "Epoch 121, Loss: 0.4363022484956832\n",
      "Epoch 122, Loss: 0.4356155170355351\n",
      "Epoch 123, Loss: 0.43490063403862483\n",
      "Epoch 124, Loss: 0.4342201107699777\n",
      "Epoch 125, Loss: 0.43353838180453635\n",
      "Epoch 126, Loss: 0.43284173997513264\n",
      "Epoch 127, Loss: 0.43214833706204026\n",
      "Epoch 128, Loss: 0.43145406152049365\n",
      "Epoch 129, Loss: 0.43076224732436824\n",
      "Epoch 130, Loss: 0.4300779649282048\n",
      "Epoch 131, Loss: 0.4294127366087064\n",
      "Epoch 132, Loss: 0.4287513244652935\n",
      "Epoch 133, Loss: 0.428087567690838\n",
      "Epoch 134, Loss: 0.42742549944208813\n",
      "Epoch 135, Loss: 0.42674639444330914\n",
      "Epoch 136, Loss: 0.4260650703729803\n",
      "Epoch 137, Loss: 0.42538748916016617\n",
      "Epoch 138, Loss: 0.4246861785800746\n",
      "Epoch 139, Loss: 0.4239948314012086\n",
      "Epoch 140, Loss: 0.42330580489821484\n",
      "Epoch 141, Loss: 0.4226738113449782\n",
      "Epoch 142, Loss: 0.4221273126908768\n",
      "Epoch 143, Loss: 0.4218491440373113\n",
      "Epoch 144, Loss: 0.4212359957815054\n",
      "Epoch 145, Loss: 0.42012052938142114\n",
      "Epoch 146, Loss: 0.41948402110529714\n",
      "Epoch 147, Loss: 0.4192399987044078\n",
      "Epoch 148, Loss: 0.4184732333844662\n",
      "Epoch 149, Loss: 0.41763697139088507\n",
      "Epoch 150, Loss: 0.41733817190700684\n",
      "Epoch 151, Loss: 0.41682005284224993\n",
      "Epoch 152, Loss: 0.4159194942678369\n",
      "Epoch 153, Loss: 0.4154558669406559\n",
      "Epoch 154, Loss: 0.4151112213237293\n",
      "Epoch 155, Loss: 0.41430928415456536\n",
      "Epoch 156, Loss: 0.41355670770281605\n",
      "Epoch 157, Loss: 0.4131477616311462\n",
      "Epoch 158, Loss: 0.41275099213086397\n",
      "Epoch 159, Loss: 0.4120751859394995\n",
      "Epoch 160, Loss: 0.4112345010219595\n",
      "Epoch 161, Loss: 0.41061150852376194\n",
      "Epoch 162, Loss: 0.41023102941476475\n",
      "Epoch 163, Loss: 0.40980220227773784\n",
      "Epoch 164, Loss: 0.40922551592651524\n",
      "Epoch 165, Loss: 0.4083115465651422\n",
      "Epoch 166, Loss: 0.40750323074908956\n",
      "Epoch 167, Loss: 0.4069958039882883\n",
      "Epoch 168, Loss: 0.4065992064915789\n",
      "Epoch 169, Loss: 0.40625254923680904\n",
      "Epoch 170, Loss: 0.40549540128934203\n",
      "Epoch 171, Loss: 0.40464677274339256\n",
      "Epoch 172, Loss: 0.4037977814524158\n",
      "Epoch 173, Loss: 0.40317549426231286\n",
      "Epoch 174, Loss: 0.40256860616287876\n",
      "Epoch 175, Loss: 0.40210489015985346\n",
      "Epoch 176, Loss: 0.4017898302018805\n",
      "Epoch 177, Loss: 0.4019840818000697\n",
      "Epoch 178, Loss: 0.4024116495855461\n",
      "Epoch 179, Loss: 0.4011393547806194\n",
      "Epoch 180, Loss: 0.39939611716400725\n",
      "Epoch 181, Loss: 0.3989999765154705\n",
      "Epoch 182, Loss: 0.3994069553479747\n",
      "Epoch 183, Loss: 0.39871699683913703\n",
      "Epoch 184, Loss: 0.397158383398459\n",
      "Epoch 185, Loss: 0.39731218333379476\n",
      "Epoch 186, Loss: 0.3980532457555014\n",
      "Epoch 187, Loss: 0.3963112476619659\n",
      "Epoch 188, Loss: 0.39523592422100284\n",
      "Epoch 189, Loss: 0.3956713303109288\n",
      "Epoch 190, Loss: 0.3953077210450331\n",
      "Epoch 191, Loss: 0.3940756972097366\n",
      "Epoch 192, Loss: 0.3933920133625063\n",
      "Epoch 193, Loss: 0.3938238014206343\n",
      "Epoch 194, Loss: 0.3933314975531352\n",
      "Epoch 195, Loss: 0.392200003192888\n",
      "Epoch 196, Loss: 0.39164956195830664\n",
      "Epoch 197, Loss: 0.39180516303624735\n",
      "Epoch 198, Loss: 0.39126848625043936\n",
      "Epoch 199, Loss: 0.39063110346794205\n",
      "Epoch 200, Loss: 0.38971002230683877\n",
      "Epoch 201, Loss: 0.3897132915169316\n",
      "Epoch 202, Loss: 0.3898273716851676\n",
      "Epoch 203, Loss: 0.38949526498558346\n",
      "Epoch 204, Loss: 0.3885889204436095\n",
      "Epoch 205, Loss: 0.3876712512950347\n",
      "Epoch 206, Loss: 0.38735478048864613\n",
      "Epoch 207, Loss: 0.38726304023192526\n",
      "Epoch 208, Loss: 0.38726479098330435\n",
      "Epoch 209, Loss: 0.38781903500395626\n",
      "Epoch 210, Loss: 0.386856382134627\n",
      "Epoch 211, Loss: 0.385813916454499\n",
      "Epoch 212, Loss: 0.38494975142965776\n",
      "Epoch 213, Loss: 0.3843791201611026\n",
      "Epoch 214, Loss: 0.3847901002486806\n",
      "Epoch 215, Loss: 0.38457147182524276\n",
      "Epoch 216, Loss: 0.38457455223462633\n",
      "Epoch 217, Loss: 0.38359888232618244\n",
      "Epoch 218, Loss: 0.3829802320822068\n",
      "Epoch 219, Loss: 0.3820027330984836\n",
      "Epoch 220, Loss: 0.381594549890351\n",
      "Epoch 221, Loss: 0.38140235733239897\n",
      "Epoch 222, Loss: 0.38169020971970113\n",
      "Epoch 223, Loss: 0.3821188812539651\n",
      "Epoch 224, Loss: 0.38207118599876344\n",
      "Epoch 225, Loss: 0.3816974515590488\n",
      "Epoch 226, Loss: 0.3795582186217028\n",
      "Epoch 227, Loss: 0.37915850628815273\n",
      "Epoch 228, Loss: 0.3801982325252946\n",
      "Epoch 229, Loss: 0.38027839363524457\n",
      "Epoch 230, Loss: 0.37891708437187194\n",
      "Epoch 231, Loss: 0.3775642856277199\n",
      "Epoch 232, Loss: 0.377519291075368\n",
      "Epoch 233, Loss: 0.37840200082867925\n",
      "Epoch 234, Loss: 0.3776767091019156\n",
      "Epoch 235, Loss: 0.3768107684043925\n",
      "Epoch 236, Loss: 0.3756865733072887\n",
      "Epoch 237, Loss: 0.3755699832759207\n",
      "Epoch 238, Loss: 0.37566158427535357\n",
      "Epoch 239, Loss: 0.3753363769584576\n",
      "Epoch 240, Loss: 0.3749406290739279\n",
      "Epoch 241, Loss: 0.37442212481666093\n",
      "Epoch 242, Loss: 0.37369150118576644\n",
      "Epoch 243, Loss: 0.37324610478028813\n",
      "Epoch 244, Loss: 0.37304491771564\n",
      "Epoch 245, Loss: 0.37260524712628884\n",
      "Epoch 246, Loss: 0.3724796516505907\n",
      "Epoch 247, Loss: 0.3725663730514094\n",
      "Epoch 248, Loss: 0.37290958055054085\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2475350426883379\n",
      "Test R^2 score: 0.33497409108269177\n",
      "Num of epochs: 249\n",
      "Epoch 1, Loss: 0.5814218338905384\n",
      "Epoch 2, Loss: 0.5795189573908057\n",
      "Epoch 3, Loss: 0.5776943716523497\n",
      "Epoch 4, Loss: 0.5759328831421902\n",
      "Epoch 5, Loss: 0.5742747221156027\n",
      "Epoch 6, Loss: 0.5727433173590261\n",
      "Epoch 7, Loss: 0.5714059824182741\n",
      "Epoch 8, Loss: 0.5701667390351453\n",
      "Epoch 9, Loss: 0.5689755013677588\n",
      "Epoch 10, Loss: 0.5678349595779512\n",
      "Epoch 11, Loss: 0.5667468395271236\n",
      "Epoch 12, Loss: 0.5657128397562214\n",
      "Epoch 13, Loss: 0.5647422287749522\n",
      "Epoch 14, Loss: 0.5638337482490708\n",
      "Epoch 15, Loss: 0.562986481424649\n",
      "Epoch 16, Loss: 0.5621934691319521\n",
      "Epoch 17, Loss: 0.5614531630618299\n",
      "Epoch 18, Loss: 0.5607713788073304\n",
      "Epoch 19, Loss: 0.560146999947801\n",
      "Epoch 20, Loss: 0.5595914560421054\n",
      "Epoch 21, Loss: 0.559083337240901\n",
      "Epoch 22, Loss: 0.5586074080498082\n",
      "Epoch 23, Loss: 0.5581610544313069\n",
      "Epoch 24, Loss: 0.5577434924527016\n",
      "Epoch 25, Loss: 0.5573825910555633\n",
      "Epoch 26, Loss: 0.5570400478101636\n",
      "Epoch 27, Loss: 0.5567069566255368\n",
      "Epoch 28, Loss: 0.556372701848841\n",
      "Epoch 29, Loss: 0.5560294024631283\n",
      "Epoch 30, Loss: 0.5556672000628823\n",
      "Epoch 31, Loss: 0.5552614493187956\n",
      "Epoch 32, Loss: 0.5547887145634876\n",
      "Epoch 33, Loss: 0.5542342254740852\n",
      "Epoch 34, Loss: 0.5535751795312046\n",
      "Epoch 35, Loss: 0.5527642447552539\n",
      "Epoch 36, Loss: 0.5517693172369431\n",
      "Epoch 37, Loss: 0.5505394912296037\n",
      "Epoch 38, Loss: 0.5490115527777073\n",
      "Epoch 39, Loss: 0.5471463483916381\n",
      "Epoch 40, Loss: 0.5449134798667974\n",
      "Epoch 41, Loss: 0.5423489607788973\n",
      "Epoch 42, Loss: 0.5395664955025691\n",
      "Epoch 43, Loss: 0.5368169647485924\n",
      "Epoch 44, Loss: 0.5345491181403164\n",
      "Epoch 45, Loss: 0.5332207589499796\n",
      "Epoch 46, Loss: 0.5325165125028336\n",
      "Epoch 47, Loss: 0.5311141681926767\n",
      "Epoch 48, Loss: 0.5286355197695949\n",
      "Epoch 49, Loss: 0.5259195381130085\n",
      "Epoch 50, Loss: 0.5237183173436359\n",
      "Epoch 51, Loss: 0.5221481385112086\n",
      "Epoch 52, Loss: 0.5208463158578899\n",
      "Epoch 53, Loss: 0.5194071284431808\n",
      "Epoch 54, Loss: 0.5176378611514715\n",
      "Epoch 55, Loss: 0.5155643369651437\n",
      "Epoch 56, Loss: 0.5133993782197956\n",
      "Epoch 57, Loss: 0.5114678211717649\n",
      "Epoch 58, Loss: 0.509954980050583\n",
      "Epoch 59, Loss: 0.5085525695255044\n",
      "Epoch 60, Loss: 0.5067837197631189\n",
      "Epoch 61, Loss: 0.5047074978294355\n",
      "Epoch 62, Loss: 0.5027293574772681\n",
      "Epoch 63, Loss: 0.5010891020190236\n",
      "Epoch 64, Loss: 0.49954521835027155\n",
      "Epoch 65, Loss: 0.49774953904985575\n",
      "Epoch 66, Loss: 0.49568235806251343\n",
      "Epoch 67, Loss: 0.49374384272635385\n",
      "Epoch 68, Loss: 0.49223993415673367\n",
      "Epoch 69, Loss: 0.49089229555310493\n",
      "Epoch 70, Loss: 0.48929464844939097\n",
      "Epoch 71, Loss: 0.4877272553041121\n",
      "Epoch 72, Loss: 0.48653170143315744\n",
      "Epoch 73, Loss: 0.48538230936763926\n",
      "Epoch 74, Loss: 0.4839558325872732\n",
      "Epoch 75, Loss: 0.4825654067292976\n",
      "Epoch 76, Loss: 0.4814372187740768\n",
      "Epoch 77, Loss: 0.4802249507001043\n",
      "Epoch 78, Loss: 0.47875926763264515\n",
      "Epoch 79, Loss: 0.4774398232533458\n",
      "Epoch 80, Loss: 0.4762221355997517\n",
      "Epoch 81, Loss: 0.474826213767674\n",
      "Epoch 82, Loss: 0.47333937531407344\n",
      "Epoch 83, Loss: 0.47193276386514027\n",
      "Epoch 84, Loss: 0.4703763880378463\n",
      "Epoch 85, Loss: 0.4685448833551349\n",
      "Epoch 86, Loss: 0.46658887179247105\n",
      "Epoch 87, Loss: 0.46446831552418055\n",
      "Epoch 88, Loss: 0.4624362759894247\n",
      "Epoch 89, Loss: 0.4608466818614006\n",
      "Epoch 90, Loss: 0.4599209583831253\n",
      "Epoch 91, Loss: 0.4598198773599985\n",
      "Epoch 92, Loss: 0.45946991582168784\n",
      "Epoch 93, Loss: 0.45827203217843393\n",
      "Epoch 94, Loss: 0.4568057849028788\n",
      "Epoch 95, Loss: 0.45548552585283814\n",
      "Epoch 96, Loss: 0.45446259287899765\n",
      "Epoch 97, Loss: 0.4536398232109708\n",
      "Epoch 98, Loss: 0.4528791813163824\n",
      "Epoch 99, Loss: 0.45211625448094633\n",
      "Epoch 100, Loss: 0.4512209844903117\n",
      "Epoch 101, Loss: 0.4503722763625009\n",
      "Epoch 102, Loss: 0.4495165294030955\n",
      "Epoch 103, Loss: 0.44876980116253695\n",
      "Epoch 104, Loss: 0.448137757347186\n",
      "Epoch 105, Loss: 0.44759336898713986\n",
      "Epoch 106, Loss: 0.4469154519665597\n",
      "Epoch 107, Loss: 0.4461894518917344\n",
      "Epoch 108, Loss: 0.4453273235330028\n",
      "Epoch 109, Loss: 0.44455683321152\n",
      "Epoch 110, Loss: 0.4438329679536814\n",
      "Epoch 111, Loss: 0.44303356080018663\n",
      "Epoch 112, Loss: 0.44214585044084437\n",
      "Epoch 113, Loss: 0.4413609270441336\n",
      "Epoch 114, Loss: 0.4407163985129532\n",
      "Epoch 115, Loss: 0.43999524057046663\n",
      "Epoch 116, Loss: 0.43924818558445744\n",
      "Epoch 117, Loss: 0.4385941141831667\n",
      "Epoch 118, Loss: 0.4379782276849656\n",
      "Epoch 119, Loss: 0.43730964947467\n",
      "Epoch 120, Loss: 0.4365987862024896\n",
      "Epoch 121, Loss: 0.43589948057693756\n",
      "Epoch 122, Loss: 0.43526239042377407\n",
      "Epoch 123, Loss: 0.4345968345521105\n",
      "Epoch 124, Loss: 0.43393480788676947\n",
      "Epoch 125, Loss: 0.4333220653108177\n",
      "Epoch 126, Loss: 0.43274140996357463\n",
      "Epoch 127, Loss: 0.4322066587337654\n",
      "Epoch 128, Loss: 0.4316527593641791\n",
      "Epoch 129, Loss: 0.4308386381801584\n",
      "Epoch 130, Loss: 0.4300372347678971\n",
      "Epoch 131, Loss: 0.4295045463168185\n",
      "Epoch 132, Loss: 0.4289475224827689\n",
      "Epoch 133, Loss: 0.42822952873952685\n",
      "Epoch 134, Loss: 0.4275768983008898\n",
      "Epoch 135, Loss: 0.4270897628331231\n",
      "Epoch 136, Loss: 0.4265536380727595\n",
      "Epoch 137, Loss: 0.4259065041350616\n",
      "Epoch 138, Loss: 0.42530714114342627\n",
      "Epoch 139, Loss: 0.4248038105571947\n",
      "Epoch 140, Loss: 0.4244042273837605\n",
      "Epoch 141, Loss: 0.42393488791807055\n",
      "Epoch 142, Loss: 0.42330821622029624\n",
      "Epoch 143, Loss: 0.4225683342957296\n",
      "Epoch 144, Loss: 0.4219537943972621\n",
      "Epoch 145, Loss: 0.42149284502769235\n",
      "Epoch 146, Loss: 0.42103790309204814\n",
      "Epoch 147, Loss: 0.4204720906749007\n",
      "Epoch 148, Loss: 0.41980917549378727\n",
      "Epoch 149, Loss: 0.4191729765082786\n",
      "Epoch 150, Loss: 0.418629471670412\n",
      "Epoch 151, Loss: 0.41815208264668924\n",
      "Epoch 152, Loss: 0.4177072188092185\n",
      "Epoch 153, Loss: 0.41733488701164523\n",
      "Epoch 154, Loss: 0.416996350591457\n",
      "Epoch 155, Loss: 0.41652546119144673\n",
      "Epoch 156, Loss: 0.41589817663725404\n",
      "Epoch 157, Loss: 0.4151091572530542\n",
      "Epoch 158, Loss: 0.41453020204252716\n",
      "Epoch 159, Loss: 0.41420194688903084\n",
      "Epoch 160, Loss: 0.41388689671996337\n",
      "Epoch 161, Loss: 0.41350398993037446\n",
      "Epoch 162, Loss: 0.41288804889838915\n",
      "Epoch 163, Loss: 0.41214683326320034\n",
      "Epoch 164, Loss: 0.4114996571452496\n",
      "Epoch 165, Loss: 0.4110323495513007\n",
      "Epoch 166, Loss: 0.410736581688836\n",
      "Epoch 167, Loss: 0.4106829757928882\n",
      "Epoch 168, Loss: 0.4107289267234608\n",
      "Epoch 169, Loss: 0.40996650666574597\n",
      "Epoch 170, Loss: 0.40871876906444427\n",
      "Epoch 171, Loss: 0.40767242759224714\n",
      "Epoch 172, Loss: 0.407674620694371\n",
      "Epoch 173, Loss: 0.4077594115973765\n",
      "Epoch 174, Loss: 0.40661009088478206\n",
      "Epoch 175, Loss: 0.405525331463263\n",
      "Epoch 176, Loss: 0.405270587957085\n",
      "Epoch 177, Loss: 0.40515213955089835\n",
      "Epoch 178, Loss: 0.4046620180510042\n",
      "Epoch 179, Loss: 0.40354318441572645\n",
      "Epoch 180, Loss: 0.4028085967674577\n",
      "Epoch 181, Loss: 0.4025833194396808\n",
      "Epoch 182, Loss: 0.40260641542360204\n",
      "Epoch 183, Loss: 0.4026523813721304\n",
      "Epoch 184, Loss: 0.40151044975805483\n",
      "Epoch 185, Loss: 0.4004302958862577\n",
      "Epoch 186, Loss: 0.39981743326821406\n",
      "Epoch 187, Loss: 0.39974489943689884\n",
      "Epoch 188, Loss: 0.39991579510582614\n",
      "Epoch 189, Loss: 0.3994056682124287\n",
      "Epoch 190, Loss: 0.3987328612671321\n",
      "Epoch 191, Loss: 0.39759777441059097\n",
      "Epoch 192, Loss: 0.3968839464155467\n",
      "Epoch 193, Loss: 0.39666163423629036\n",
      "Epoch 194, Loss: 0.3969456474622473\n",
      "Epoch 195, Loss: 0.39749852033255745\n",
      "Epoch 196, Loss: 0.3964379006193886\n",
      "Epoch 197, Loss: 0.3952950552909756\n",
      "Epoch 198, Loss: 0.394094754471337\n",
      "Epoch 199, Loss: 0.39397979192055627\n",
      "Epoch 200, Loss: 0.3940455780510146\n",
      "Epoch 201, Loss: 0.39393939579769727\n",
      "Epoch 202, Loss: 0.39376878239475444\n",
      "Epoch 203, Loss: 0.39247498177411033\n",
      "Epoch 204, Loss: 0.3916666067238349\n",
      "Epoch 205, Loss: 0.39096253117501667\n",
      "Epoch 206, Loss: 0.3907439432254402\n",
      "Epoch 207, Loss: 0.39102808182697407\n",
      "Epoch 208, Loss: 0.39148752354756683\n",
      "Epoch 209, Loss: 0.3928229294623722\n",
      "Epoch 210, Loss: 0.38983839944902127\n",
      "Epoch 211, Loss: 0.38856042768917654\n",
      "Epoch 212, Loss: 0.3890070213074016\n",
      "Epoch 213, Loss: 0.38935579099467205\n",
      "Epoch 214, Loss: 0.3895852747612108\n",
      "Epoch 215, Loss: 0.3874566523086822\n",
      "Epoch 216, Loss: 0.3866175124081293\n",
      "Epoch 217, Loss: 0.38679162697033503\n",
      "Epoch 218, Loss: 0.38737689954717247\n",
      "Epoch 219, Loss: 0.3882206353322414\n",
      "Epoch 220, Loss: 0.38562087070721135\n",
      "Epoch 221, Loss: 0.38499333570954686\n",
      "Epoch 222, Loss: 0.3854019209472401\n",
      "Epoch 223, Loss: 0.38561517097027653\n",
      "Epoch 224, Loss: 0.38523936274434106\n",
      "Epoch 225, Loss: 0.383553041679347\n",
      "Epoch 226, Loss: 0.3833999602666027\n",
      "Epoch 227, Loss: 0.383293686333371\n",
      "Epoch 228, Loss: 0.3842373624794626\n",
      "Epoch 229, Loss: 0.38528506076873403\n",
      "Epoch 230, Loss: 0.3829153662290411\n",
      "Epoch 231, Loss: 0.3822885547826577\n",
      "Epoch 232, Loss: 0.38198307256242114\n",
      "Epoch 233, Loss: 0.38301081289062544\n",
      "Epoch 234, Loss: 0.3823896719882063\n",
      "Epoch 235, Loss: 0.38153354934848127\n",
      "Epoch 236, Loss: 0.3799032485289829\n",
      "Epoch 237, Loss: 0.3799326062358709\n",
      "Epoch 238, Loss: 0.37964400996046105\n",
      "Epoch 239, Loss: 0.380013137075818\n",
      "Epoch 240, Loss: 0.38039974942078747\n",
      "Epoch 241, Loss: 0.38093018484876245\n",
      "Epoch 242, Loss: 0.37997241299652906\n",
      "Epoch 243, Loss: 0.37924087142393786\n",
      "Epoch 244, Loss: 0.37792840607497347\n",
      "Epoch 245, Loss: 0.37741221010265663\n",
      "Epoch 246, Loss: 0.3776866121283256\n",
      "Epoch 247, Loss: 0.3784944321690253\n",
      "Epoch 248, Loss: 0.37994854905004166\n",
      "Epoch 249, Loss: 0.37885958590690233\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2497734043152359\n",
      "Test R^2 score: 0.3230549181895157\n",
      "Num of epochs: 250\n",
      "Epoch 1, Loss: 0.5688980800562737\n",
      "Epoch 2, Loss: 0.56717929045986\n",
      "Epoch 3, Loss: 0.5656428487079671\n",
      "Epoch 4, Loss: 0.5642247777599428\n",
      "Epoch 5, Loss: 0.5629713150207376\n",
      "Epoch 6, Loss: 0.5619201850756447\n",
      "Epoch 7, Loss: 0.5609787928436825\n",
      "Epoch 8, Loss: 0.5601410676183539\n",
      "Epoch 9, Loss: 0.5593974327405598\n",
      "Epoch 10, Loss: 0.5587368761778615\n",
      "Epoch 11, Loss: 0.5582138850654592\n",
      "Epoch 12, Loss: 0.5577808413884747\n",
      "Epoch 13, Loss: 0.5574021333915746\n",
      "Epoch 14, Loss: 0.5570762134611543\n",
      "Epoch 15, Loss: 0.5568061448673463\n",
      "Epoch 16, Loss: 0.5565846197497336\n",
      "Epoch 17, Loss: 0.5564085359427317\n",
      "Epoch 18, Loss: 0.5562726594831543\n",
      "Epoch 19, Loss: 0.5561721168600061\n",
      "Epoch 20, Loss: 0.5561020504363353\n",
      "Epoch 21, Loss: 0.5560559062723324\n",
      "Epoch 22, Loss: 0.5560233190040876\n",
      "Epoch 23, Loss: 0.5560105890836857\n",
      "Epoch 24, Loss: 0.5560039962103509\n",
      "Epoch 25, Loss: 0.555997564063465\n",
      "Epoch 26, Loss: 0.5559847799506097\n",
      "Epoch 27, Loss: 0.555958674790422\n",
      "Epoch 28, Loss: 0.5559128135788174\n",
      "Epoch 29, Loss: 0.5558422855369272\n",
      "Epoch 30, Loss: 0.5557434079014785\n",
      "Epoch 31, Loss: 0.5556146368426982\n",
      "Epoch 32, Loss: 0.5554480107509352\n",
      "Epoch 33, Loss: 0.5552407313109567\n",
      "Epoch 34, Loss: 0.55498990694096\n",
      "Epoch 35, Loss: 0.5546920668722926\n",
      "Epoch 36, Loss: 0.55433885604889\n",
      "Epoch 37, Loss: 0.5539247076620605\n",
      "Epoch 38, Loss: 0.553462004504092\n",
      "Epoch 39, Loss: 0.5529078019424966\n",
      "Epoch 40, Loss: 0.5522126610144822\n",
      "Epoch 41, Loss: 0.5513426172212076\n",
      "Epoch 42, Loss: 0.5502957036814385\n",
      "Epoch 43, Loss: 0.5491527533999738\n",
      "Epoch 44, Loss: 0.5479141988323996\n",
      "Epoch 45, Loss: 0.5464873438571127\n",
      "Epoch 46, Loss: 0.5447740525217865\n",
      "Epoch 47, Loss: 0.5426573649493011\n",
      "Epoch 48, Loss: 0.5400280252884324\n",
      "Epoch 49, Loss: 0.5368140223538487\n",
      "Epoch 50, Loss: 0.5329676237292931\n",
      "Epoch 51, Loss: 0.5284109831055502\n",
      "Epoch 52, Loss: 0.5230718160869209\n",
      "Epoch 53, Loss: 0.5170060072702962\n",
      "Epoch 54, Loss: 0.5103346181305589\n",
      "Epoch 55, Loss: 0.5032338824242355\n",
      "Epoch 56, Loss: 0.4960342732016961\n",
      "Epoch 57, Loss: 0.4893595576377174\n",
      "Epoch 58, Loss: 0.48429514626645054\n",
      "Epoch 59, Loss: 0.4818578349419465\n",
      "Epoch 60, Loss: 0.4810310268120306\n",
      "Epoch 61, Loss: 0.48031506755492553\n",
      "Epoch 62, Loss: 0.48046054678016065\n",
      "Epoch 63, Loss: 0.48078383992079915\n",
      "Epoch 64, Loss: 0.4794592603266365\n",
      "Epoch 65, Loss: 0.4769181659705359\n",
      "Epoch 66, Loss: 0.4744483925909857\n",
      "Epoch 67, Loss: 0.47223034104523637\n",
      "Epoch 68, Loss: 0.4710819571871013\n",
      "Epoch 69, Loss: 0.47045550025873206\n",
      "Epoch 70, Loss: 0.4701598898840868\n",
      "Epoch 71, Loss: 0.4701732644843433\n",
      "Epoch 72, Loss: 0.4698928570369474\n",
      "Epoch 73, Loss: 0.4690750266784423\n",
      "Epoch 74, Loss: 0.46791424951356464\n",
      "Epoch 75, Loss: 0.46662725774656694\n",
      "Epoch 76, Loss: 0.4653343368745346\n",
      "Epoch 77, Loss: 0.46431087757134715\n",
      "Epoch 78, Loss: 0.4634716556126961\n",
      "Epoch 79, Loss: 0.46280266936149733\n",
      "Epoch 80, Loss: 0.4623058182090531\n",
      "Epoch 81, Loss: 0.46190201338362025\n",
      "Epoch 82, Loss: 0.4614397965174754\n",
      "Epoch 83, Loss: 0.46083854970974647\n",
      "Epoch 84, Loss: 0.4601019220064956\n",
      "Epoch 85, Loss: 0.4593588741871595\n",
      "Epoch 86, Loss: 0.4586448225081989\n",
      "Epoch 87, Loss: 0.45803083024412716\n",
      "Epoch 88, Loss: 0.45760067084899325\n",
      "Epoch 89, Loss: 0.45721304774527016\n",
      "Epoch 90, Loss: 0.4567115676372556\n",
      "Epoch 91, Loss: 0.4561434869676124\n",
      "Epoch 92, Loss: 0.45551873026107276\n",
      "Epoch 93, Loss: 0.45487770284073514\n",
      "Epoch 94, Loss: 0.45426909934994936\n",
      "Epoch 95, Loss: 0.45375873381245846\n",
      "Epoch 96, Loss: 0.45333870419424815\n",
      "Epoch 97, Loss: 0.4529635042937526\n",
      "Epoch 98, Loss: 0.45252757315113007\n",
      "Epoch 99, Loss: 0.4520118952120623\n",
      "Epoch 100, Loss: 0.45147320151509207\n",
      "Epoch 101, Loss: 0.4509787373182642\n",
      "Epoch 102, Loss: 0.4505283505762606\n",
      "Epoch 103, Loss: 0.45006177001436226\n",
      "Epoch 104, Loss: 0.4495776857133918\n",
      "Epoch 105, Loss: 0.44909015971181976\n",
      "Epoch 106, Loss: 0.4485732208784316\n",
      "Epoch 107, Loss: 0.44803363544355634\n",
      "Epoch 108, Loss: 0.44754419438876797\n",
      "Epoch 109, Loss: 0.4471363063915231\n",
      "Epoch 110, Loss: 0.4467221085221008\n",
      "Epoch 111, Loss: 0.4462346350538436\n",
      "Epoch 112, Loss: 0.4456656879078102\n",
      "Epoch 113, Loss: 0.44510731236281914\n",
      "Epoch 114, Loss: 0.44461538728688477\n",
      "Epoch 115, Loss: 0.44410785228695154\n",
      "Epoch 116, Loss: 0.4435799675896848\n",
      "Epoch 117, Loss: 0.4430945357435381\n",
      "Epoch 118, Loss: 0.44260540682010746\n",
      "Epoch 119, Loss: 0.4420973338745444\n",
      "Epoch 120, Loss: 0.441612161865986\n",
      "Epoch 121, Loss: 0.44114952723890577\n",
      "Epoch 122, Loss: 0.44065159453628683\n",
      "Epoch 123, Loss: 0.4401296028897592\n",
      "Epoch 124, Loss: 0.4396494109161189\n",
      "Epoch 125, Loss: 0.4391726467671248\n",
      "Epoch 126, Loss: 0.43864972745673203\n",
      "Epoch 127, Loss: 0.4381498041083518\n",
      "Epoch 128, Loss: 0.4376435044491598\n",
      "Epoch 129, Loss: 0.4371060232352712\n",
      "Epoch 130, Loss: 0.4366031548337149\n",
      "Epoch 131, Loss: 0.4360874909266473\n",
      "Epoch 132, Loss: 0.4355344385672363\n",
      "Epoch 133, Loss: 0.43506128243965236\n",
      "Epoch 134, Loss: 0.43454735513118603\n",
      "Epoch 135, Loss: 0.4340628929768068\n",
      "Epoch 136, Loss: 0.4335509786044209\n",
      "Epoch 137, Loss: 0.433018156279963\n",
      "Epoch 138, Loss: 0.4324765116592345\n",
      "Epoch 139, Loss: 0.4318952715487034\n",
      "Epoch 140, Loss: 0.4313485378526691\n",
      "Epoch 141, Loss: 0.4307751155578377\n",
      "Epoch 142, Loss: 0.4302073541804048\n",
      "Epoch 143, Loss: 0.4296346805359799\n",
      "Epoch 144, Loss: 0.42907876330488254\n",
      "Epoch 145, Loss: 0.42851278813552374\n",
      "Epoch 146, Loss: 0.42796300412764027\n",
      "Epoch 147, Loss: 0.4274007811489651\n",
      "Epoch 148, Loss: 0.4268485524933531\n",
      "Epoch 149, Loss: 0.4262989466634699\n",
      "Epoch 150, Loss: 0.42574964633508083\n",
      "Epoch 151, Loss: 0.4251914708003825\n",
      "Epoch 152, Loss: 0.42465416006177104\n",
      "Epoch 153, Loss: 0.42408811268381175\n",
      "Epoch 154, Loss: 0.42352400033449017\n",
      "Epoch 155, Loss: 0.42299260348758977\n",
      "Epoch 156, Loss: 0.42245415388032026\n",
      "Epoch 157, Loss: 0.4219179661381874\n",
      "Epoch 158, Loss: 0.4213859761431572\n",
      "Epoch 159, Loss: 0.4208584653633163\n",
      "Epoch 160, Loss: 0.4203356101904383\n",
      "Epoch 161, Loss: 0.41979763943356985\n",
      "Epoch 162, Loss: 0.41927065365552507\n",
      "Epoch 163, Loss: 0.4187330940022296\n",
      "Epoch 164, Loss: 0.41820987983149854\n",
      "Epoch 165, Loss: 0.41767805454294626\n",
      "Epoch 166, Loss: 0.41714824820466956\n",
      "Epoch 167, Loss: 0.4166830913962192\n",
      "Epoch 168, Loss: 0.4162735117323426\n",
      "Epoch 169, Loss: 0.41589590149786393\n",
      "Epoch 170, Loss: 0.4152671097693256\n",
      "Epoch 171, Loss: 0.41468388338100165\n",
      "Epoch 172, Loss: 0.41425570892562474\n",
      "Epoch 173, Loss: 0.4139119900355459\n",
      "Epoch 174, Loss: 0.41349445821445746\n",
      "Epoch 175, Loss: 0.4129354865785904\n",
      "Epoch 176, Loss: 0.41240901810639957\n",
      "Epoch 177, Loss: 0.4120371967764619\n",
      "Epoch 178, Loss: 0.4116214195603137\n",
      "Epoch 179, Loss: 0.4111006626778924\n",
      "Epoch 180, Loss: 0.41050256912900407\n",
      "Epoch 181, Loss: 0.4101650237098711\n",
      "Epoch 182, Loss: 0.4100738079231162\n",
      "Epoch 183, Loss: 0.409590521710876\n",
      "Epoch 184, Loss: 0.4088848207810992\n",
      "Epoch 185, Loss: 0.40838609820004446\n",
      "Epoch 186, Loss: 0.40822044591340423\n",
      "Epoch 187, Loss: 0.40793326917195727\n",
      "Epoch 188, Loss: 0.40729864200690646\n",
      "Epoch 189, Loss: 0.4067269972830777\n",
      "Epoch 190, Loss: 0.4064431831564387\n",
      "Epoch 191, Loss: 0.4061636282730621\n",
      "Epoch 192, Loss: 0.40595562980286987\n",
      "Epoch 193, Loss: 0.40554667993672017\n",
      "Epoch 194, Loss: 0.40489784209146734\n",
      "Epoch 195, Loss: 0.4045443491548023\n",
      "Epoch 196, Loss: 0.4042829796803539\n",
      "Epoch 197, Loss: 0.4040991442438838\n",
      "Epoch 198, Loss: 0.40359810782873684\n",
      "Epoch 199, Loss: 0.4030941566969759\n",
      "Epoch 200, Loss: 0.40268046909099003\n",
      "Epoch 201, Loss: 0.40231556469607965\n",
      "Epoch 202, Loss: 0.4020576570973182\n",
      "Epoch 203, Loss: 0.40187106096464104\n",
      "Epoch 204, Loss: 0.40164397782367856\n",
      "Epoch 205, Loss: 0.4013254928279772\n",
      "Epoch 206, Loss: 0.4009420366097471\n",
      "Epoch 207, Loss: 0.4002797787445927\n",
      "Epoch 208, Loss: 0.3998298812255786\n",
      "Epoch 209, Loss: 0.39963010806892996\n",
      "Epoch 210, Loss: 0.39954959649729294\n",
      "Epoch 211, Loss: 0.39957568342638144\n",
      "Epoch 212, Loss: 0.39922012806634016\n",
      "Epoch 213, Loss: 0.39858454440562496\n",
      "Epoch 214, Loss: 0.3978863063767388\n",
      "Epoch 215, Loss: 0.3976487786690974\n",
      "Epoch 216, Loss: 0.397732278866659\n",
      "Epoch 217, Loss: 0.39752005622456876\n",
      "Epoch 218, Loss: 0.3969804075640934\n",
      "Epoch 219, Loss: 0.39628893164589774\n",
      "Epoch 220, Loss: 0.3960511796033871\n",
      "Epoch 221, Loss: 0.39616102742017223\n",
      "Epoch 222, Loss: 0.3960123870169375\n",
      "Epoch 223, Loss: 0.39557132917348903\n",
      "Epoch 224, Loss: 0.3948343830937388\n",
      "Epoch 225, Loss: 0.3944098786348167\n",
      "Epoch 226, Loss: 0.394379747214061\n",
      "Epoch 227, Loss: 0.39441310888875764\n",
      "Epoch 228, Loss: 0.3943046258867881\n",
      "Epoch 229, Loss: 0.39366916856177986\n",
      "Epoch 230, Loss: 0.3930641885066997\n",
      "Epoch 231, Loss: 0.3926032328761126\n",
      "Epoch 232, Loss: 0.3924771079294205\n",
      "Epoch 233, Loss: 0.39267262702060224\n",
      "Epoch 234, Loss: 0.39252186841848324\n",
      "Epoch 235, Loss: 0.39214690328876056\n",
      "Epoch 236, Loss: 0.3912511384965706\n",
      "Epoch 237, Loss: 0.3908097021215359\n",
      "Epoch 238, Loss: 0.39084952577437976\n",
      "Epoch 239, Loss: 0.3907549832563844\n",
      "Epoch 240, Loss: 0.3906060977177096\n",
      "Epoch 241, Loss: 0.39033054697968045\n",
      "Epoch 242, Loss: 0.38962472637951384\n",
      "Epoch 243, Loss: 0.38903684110175996\n",
      "Epoch 244, Loss: 0.388731410388566\n",
      "Epoch 245, Loss: 0.3889593278674321\n",
      "Epoch 246, Loss: 0.3894453547246842\n",
      "Epoch 247, Loss: 0.38876797815437625\n",
      "Epoch 248, Loss: 0.38806401936225493\n",
      "Epoch 249, Loss: 0.3877104941213428\n",
      "Epoch 250, Loss: 0.3869222433119806\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.23489217589933672\n",
      "Test R^2 score: 0.40133163321805765\n",
      "Num of epochs: 251\n",
      "Epoch 1, Loss: 0.5839575056446029\n",
      "Epoch 2, Loss: 0.5817799377639707\n",
      "Epoch 3, Loss: 0.5796950131569509\n",
      "Epoch 4, Loss: 0.5777255301994603\n",
      "Epoch 5, Loss: 0.5760498952249148\n",
      "Epoch 6, Loss: 0.5745453975907787\n",
      "Epoch 7, Loss: 0.5730828968836147\n",
      "Epoch 8, Loss: 0.5716369352264628\n",
      "Epoch 9, Loss: 0.5702437529215449\n",
      "Epoch 10, Loss: 0.5689074308890744\n",
      "Epoch 11, Loss: 0.5676308121088582\n",
      "Epoch 12, Loss: 0.566416720589508\n",
      "Epoch 13, Loss: 0.5652672990701983\n",
      "Epoch 14, Loss: 0.5641942470050334\n",
      "Epoch 15, Loss: 0.5631960694644604\n",
      "Epoch 16, Loss: 0.5622622729327814\n",
      "Epoch 17, Loss: 0.5613980095139385\n",
      "Epoch 18, Loss: 0.5606525334855419\n",
      "Epoch 19, Loss: 0.5599676721897692\n",
      "Epoch 20, Loss: 0.5593417568025284\n",
      "Epoch 21, Loss: 0.5587751987501467\n",
      "Epoch 22, Loss: 0.5582684723581983\n",
      "Epoch 23, Loss: 0.5578244654122781\n",
      "Epoch 24, Loss: 0.557438997301096\n",
      "Epoch 25, Loss: 0.5571083646793751\n",
      "Epoch 26, Loss: 0.5568308722654683\n",
      "Epoch 27, Loss: 0.5566058231650892\n",
      "Epoch 28, Loss: 0.5564357983039236\n",
      "Epoch 29, Loss: 0.5563122768043797\n",
      "Epoch 30, Loss: 0.556219403357663\n",
      "Epoch 31, Loss: 0.5561607299922617\n",
      "Epoch 32, Loss: 0.556128336427626\n",
      "Epoch 33, Loss: 0.5561187171315326\n",
      "Epoch 34, Loss: 0.5561205123888361\n",
      "Epoch 35, Loss: 0.5561275057985936\n",
      "Epoch 36, Loss: 0.5561347402678684\n",
      "Epoch 37, Loss: 0.5561341775902999\n",
      "Epoch 38, Loss: 0.5561209679009614\n",
      "Epoch 39, Loss: 0.5560891079474433\n",
      "Epoch 40, Loss: 0.5560326183617198\n",
      "Epoch 41, Loss: 0.5559465062578938\n",
      "Epoch 42, Loss: 0.5558278893180808\n",
      "Epoch 43, Loss: 0.5556737164830307\n",
      "Epoch 44, Loss: 0.5554800147780112\n",
      "Epoch 45, Loss: 0.5552453741441699\n",
      "Epoch 46, Loss: 0.5549485304310086\n",
      "Epoch 47, Loss: 0.5545875298044893\n",
      "Epoch 48, Loss: 0.5541527816878183\n",
      "Epoch 49, Loss: 0.5536288245941716\n",
      "Epoch 50, Loss: 0.5530198239693119\n",
      "Epoch 51, Loss: 0.5522909913502002\n",
      "Epoch 52, Loss: 0.5514158015992623\n",
      "Epoch 53, Loss: 0.5503618794631084\n",
      "Epoch 54, Loss: 0.5490893628014248\n",
      "Epoch 55, Loss: 0.547553322951909\n",
      "Epoch 56, Loss: 0.5456955315970217\n",
      "Epoch 57, Loss: 0.5433978573783217\n",
      "Epoch 58, Loss: 0.5404433380708059\n",
      "Epoch 59, Loss: 0.5367318508542704\n",
      "Epoch 60, Loss: 0.5323208786574979\n",
      "Epoch 61, Loss: 0.5270825056841035\n",
      "Epoch 62, Loss: 0.5208107816264284\n",
      "Epoch 63, Loss: 0.5134681326608392\n",
      "Epoch 64, Loss: 0.5056956552808044\n",
      "Epoch 65, Loss: 0.49939557139358354\n",
      "Epoch 66, Loss: 0.4968813253995747\n",
      "Epoch 67, Loss: 0.4949639739788713\n",
      "Epoch 68, Loss: 0.4903859060077743\n",
      "Epoch 69, Loss: 0.4866796548244638\n",
      "Epoch 70, Loss: 0.48687394853314336\n",
      "Epoch 71, Loss: 0.48875123865307196\n",
      "Epoch 72, Loss: 0.4875831190799983\n",
      "Epoch 73, Loss: 0.4845235350731791\n",
      "Epoch 74, Loss: 0.4817508246588466\n",
      "Epoch 75, Loss: 0.48007213691223594\n",
      "Epoch 76, Loss: 0.47945483153476004\n",
      "Epoch 77, Loss: 0.479293378025968\n",
      "Epoch 78, Loss: 0.4789646610900085\n",
      "Epoch 79, Loss: 0.47818799383028016\n",
      "Epoch 80, Loss: 0.4770682730928273\n",
      "Epoch 81, Loss: 0.47585906032964576\n",
      "Epoch 82, Loss: 0.47479586606793023\n",
      "Epoch 83, Loss: 0.4738920308642237\n",
      "Epoch 84, Loss: 0.4730418500310499\n",
      "Epoch 85, Loss: 0.47210710324541433\n",
      "Epoch 86, Loss: 0.47102444709922336\n",
      "Epoch 87, Loss: 0.46994543230556446\n",
      "Epoch 88, Loss: 0.46907801277792355\n",
      "Epoch 89, Loss: 0.46847042647489223\n",
      "Epoch 90, Loss: 0.46787743417818545\n",
      "Epoch 91, Loss: 0.46704707762417824\n",
      "Epoch 92, Loss: 0.46598846471511607\n",
      "Epoch 93, Loss: 0.4649288676573687\n",
      "Epoch 94, Loss: 0.464102578920976\n",
      "Epoch 95, Loss: 0.46349253733449086\n",
      "Epoch 96, Loss: 0.462921656602575\n",
      "Epoch 97, Loss: 0.4622895083979452\n",
      "Epoch 98, Loss: 0.46162410288831246\n",
      "Epoch 99, Loss: 0.46097019855446747\n",
      "Epoch 100, Loss: 0.46040322973169123\n",
      "Epoch 101, Loss: 0.45996011138647447\n",
      "Epoch 102, Loss: 0.45958733419727177\n",
      "Epoch 103, Loss: 0.4592128915273516\n",
      "Epoch 104, Loss: 0.4587434826421719\n",
      "Epoch 105, Loss: 0.4581694165356929\n",
      "Epoch 106, Loss: 0.4575957211430694\n",
      "Epoch 107, Loss: 0.45709563885830085\n",
      "Epoch 108, Loss: 0.45665838241314216\n",
      "Epoch 109, Loss: 0.4561801386609147\n",
      "Epoch 110, Loss: 0.4556588818075329\n",
      "Epoch 111, Loss: 0.45517893317260116\n",
      "Epoch 112, Loss: 0.4547311499706436\n",
      "Epoch 113, Loss: 0.45428574631263297\n",
      "Epoch 114, Loss: 0.45382312729221697\n",
      "Epoch 115, Loss: 0.4533472009628572\n",
      "Epoch 116, Loss: 0.4528261876587874\n",
      "Epoch 117, Loss: 0.45228869444076825\n",
      "Epoch 118, Loss: 0.45180684774738916\n",
      "Epoch 119, Loss: 0.4513410936222087\n",
      "Epoch 120, Loss: 0.45080553184443295\n",
      "Epoch 121, Loss: 0.4502246375473117\n",
      "Epoch 122, Loss: 0.4496581209406144\n",
      "Epoch 123, Loss: 0.44907740152119624\n",
      "Epoch 124, Loss: 0.448479433790614\n",
      "Epoch 125, Loss: 0.4478548491499192\n",
      "Epoch 126, Loss: 0.4471692643622719\n",
      "Epoch 127, Loss: 0.44651413131705914\n",
      "Epoch 128, Loss: 0.44591917573722795\n",
      "Epoch 129, Loss: 0.445269900509624\n",
      "Epoch 130, Loss: 0.44458993212668807\n",
      "Epoch 131, Loss: 0.44396094963034377\n",
      "Epoch 132, Loss: 0.44335097250349376\n",
      "Epoch 133, Loss: 0.4426719613187098\n",
      "Epoch 134, Loss: 0.4419921092843708\n",
      "Epoch 135, Loss: 0.4413655692740263\n",
      "Epoch 136, Loss: 0.4406942008849\n",
      "Epoch 137, Loss: 0.4400164744424916\n",
      "Epoch 138, Loss: 0.4393954769045837\n",
      "Epoch 139, Loss: 0.43869825166667364\n",
      "Epoch 140, Loss: 0.43795267596162757\n",
      "Epoch 141, Loss: 0.4372539679967207\n",
      "Epoch 142, Loss: 0.4364854083468043\n",
      "Epoch 143, Loss: 0.43571190209429106\n",
      "Epoch 144, Loss: 0.4349844341671989\n",
      "Epoch 145, Loss: 0.4342738994430064\n",
      "Epoch 146, Loss: 0.4336364656319743\n",
      "Epoch 147, Loss: 0.43306844697145513\n",
      "Epoch 148, Loss: 0.43255218637531423\n",
      "Epoch 149, Loss: 0.43184196298882216\n",
      "Epoch 150, Loss: 0.43105967509707604\n",
      "Epoch 151, Loss: 0.4304476689543978\n",
      "Epoch 152, Loss: 0.42991164170150875\n",
      "Epoch 153, Loss: 0.42953191888284625\n",
      "Epoch 154, Loss: 0.42900330951387794\n",
      "Epoch 155, Loss: 0.4280645237274834\n",
      "Epoch 156, Loss: 0.4273467375879272\n",
      "Epoch 157, Loss: 0.42699638698956677\n",
      "Epoch 158, Loss: 0.426597512733051\n",
      "Epoch 159, Loss: 0.4258727229141166\n",
      "Epoch 160, Loss: 0.42492283022324845\n",
      "Epoch 161, Loss: 0.42443496575383266\n",
      "Epoch 162, Loss: 0.42426012585592904\n",
      "Epoch 163, Loss: 0.4238896303332188\n",
      "Epoch 164, Loss: 0.42300206208571894\n",
      "Epoch 165, Loss: 0.4219466254572991\n",
      "Epoch 166, Loss: 0.42197733097184065\n",
      "Epoch 167, Loss: 0.42189048809302043\n",
      "Epoch 168, Loss: 0.4206309165368432\n",
      "Epoch 169, Loss: 0.41989666175555523\n",
      "Epoch 170, Loss: 0.4199349334815506\n",
      "Epoch 171, Loss: 0.4189891303207093\n",
      "Epoch 172, Loss: 0.418146220525465\n",
      "Epoch 173, Loss: 0.41801878371196866\n",
      "Epoch 174, Loss: 0.4172112740304098\n",
      "Epoch 175, Loss: 0.4164908117492088\n",
      "Epoch 176, Loss: 0.4163096467948193\n",
      "Epoch 177, Loss: 0.4157408043858902\n",
      "Epoch 178, Loss: 0.4147849348369147\n",
      "Epoch 179, Loss: 0.4144474974743671\n",
      "Epoch 180, Loss: 0.41417789650601505\n",
      "Epoch 181, Loss: 0.41350189981865954\n",
      "Epoch 182, Loss: 0.4127267849896001\n",
      "Epoch 183, Loss: 0.4122267280288374\n",
      "Epoch 184, Loss: 0.41191709471192917\n",
      "Epoch 185, Loss: 0.4115480333246265\n",
      "Epoch 186, Loss: 0.41089675904428097\n",
      "Epoch 187, Loss: 0.4102036403344286\n",
      "Epoch 188, Loss: 0.40966973287318503\n",
      "Epoch 189, Loss: 0.40930026515161766\n",
      "Epoch 190, Loss: 0.40900442881273213\n",
      "Epoch 191, Loss: 0.40866681279026323\n",
      "Epoch 192, Loss: 0.40812249733477374\n",
      "Epoch 193, Loss: 0.40740922449209244\n",
      "Epoch 194, Loss: 0.406712323994236\n",
      "Epoch 195, Loss: 0.4060387979382946\n",
      "Epoch 196, Loss: 0.40541076171994456\n",
      "Epoch 197, Loss: 0.4048102247990815\n",
      "Epoch 198, Loss: 0.40424807341522895\n",
      "Epoch 199, Loss: 0.40369466260670545\n",
      "Epoch 200, Loss: 0.4031878755018064\n",
      "Epoch 201, Loss: 0.4030258914449012\n",
      "Epoch 202, Loss: 0.40434497049608714\n",
      "Epoch 203, Loss: 0.408284503180722\n",
      "Epoch 204, Loss: 0.404964411932118\n",
      "Epoch 205, Loss: 0.4012911648000381\n",
      "Epoch 206, Loss: 0.4044303489433673\n",
      "Epoch 207, Loss: 0.4016308069578079\n",
      "Epoch 208, Loss: 0.4001270822472632\n",
      "Epoch 209, Loss: 0.4013141680595024\n",
      "Epoch 210, Loss: 0.39866203638338743\n",
      "Epoch 211, Loss: 0.39975323068722035\n",
      "Epoch 212, Loss: 0.4002308968864411\n",
      "Epoch 213, Loss: 0.397851569241733\n",
      "Epoch 214, Loss: 0.3983822578580569\n",
      "Epoch 215, Loss: 0.3989063571043726\n",
      "Epoch 216, Loss: 0.3960245406802259\n",
      "Epoch 217, Loss: 0.39728169066465385\n",
      "Epoch 218, Loss: 0.3969442209567636\n",
      "Epoch 219, Loss: 0.39479696183021207\n",
      "Epoch 220, Loss: 0.39692077673087467\n",
      "Epoch 221, Loss: 0.3958447751683721\n",
      "Epoch 222, Loss: 0.3939081880914446\n",
      "Epoch 223, Loss: 0.394894668592813\n",
      "Epoch 224, Loss: 0.39403215320213475\n",
      "Epoch 225, Loss: 0.39234365037121527\n",
      "Epoch 226, Loss: 0.3930633544803405\n",
      "Epoch 227, Loss: 0.39273544499570423\n",
      "Epoch 228, Loss: 0.3909326676848395\n",
      "Epoch 229, Loss: 0.3917937532492626\n",
      "Epoch 230, Loss: 0.3922227798034846\n",
      "Epoch 231, Loss: 0.39081214236632467\n",
      "Epoch 232, Loss: 0.3896432364745302\n",
      "Epoch 233, Loss: 0.39104713518766065\n",
      "Epoch 234, Loss: 0.39047808745516843\n",
      "Epoch 235, Loss: 0.38905909433367997\n",
      "Epoch 236, Loss: 0.38796637833569786\n",
      "Epoch 237, Loss: 0.3893228571284662\n",
      "Epoch 238, Loss: 0.38918069859447735\n",
      "Epoch 239, Loss: 0.3878349994215993\n",
      "Epoch 240, Loss: 0.3864795253149425\n",
      "Epoch 241, Loss: 0.38773714699831335\n",
      "Epoch 242, Loss: 0.3879553357684766\n",
      "Epoch 243, Loss: 0.38634538448030886\n",
      "Epoch 244, Loss: 0.38460376646302313\n",
      "Epoch 245, Loss: 0.3861498067277689\n",
      "Epoch 246, Loss: 0.3868023945679062\n",
      "Epoch 247, Loss: 0.3862123738329015\n",
      "Epoch 248, Loss: 0.38317493875572367\n",
      "Epoch 249, Loss: 0.3844337193677298\n",
      "Epoch 250, Loss: 0.38601809907146223\n",
      "Epoch 251, Loss: 0.3855408927971279\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2376306684103266\n",
      "Test R^2 score: 0.3896531820833876\n",
      "Num of epochs: 252\n",
      "Epoch 1, Loss: 0.5873503372622667\n",
      "Epoch 2, Loss: 0.5857007374841399\n",
      "Epoch 3, Loss: 0.5841017129959487\n",
      "Epoch 4, Loss: 0.5826115883210641\n",
      "Epoch 5, Loss: 0.5812036403503275\n",
      "Epoch 6, Loss: 0.5798267886066659\n",
      "Epoch 7, Loss: 0.5786095212661325\n",
      "Epoch 8, Loss: 0.5773981525563361\n",
      "Epoch 9, Loss: 0.5762038399832882\n",
      "Epoch 10, Loss: 0.5750714413171959\n",
      "Epoch 11, Loss: 0.5739619141297934\n",
      "Epoch 12, Loss: 0.5728762236683425\n",
      "Epoch 13, Loss: 0.5718153917275153\n",
      "Epoch 14, Loss: 0.5707827941305564\n",
      "Epoch 15, Loss: 0.5697738769050855\n",
      "Epoch 16, Loss: 0.5688444080178182\n",
      "Epoch 17, Loss: 0.5679645543422285\n",
      "Epoch 18, Loss: 0.5671019129637269\n",
      "Epoch 19, Loss: 0.5662231149248891\n",
      "Epoch 20, Loss: 0.5653563140540843\n",
      "Epoch 21, Loss: 0.564505472362811\n",
      "Epoch 22, Loss: 0.563674838982903\n",
      "Epoch 23, Loss: 0.5628894411454468\n",
      "Epoch 24, Loss: 0.5621452537469261\n",
      "Epoch 25, Loss: 0.5614220569146668\n",
      "Epoch 26, Loss: 0.5607250608288814\n",
      "Epoch 27, Loss: 0.5600539642116035\n",
      "Epoch 28, Loss: 0.5594073685812332\n",
      "Epoch 29, Loss: 0.5587825322761285\n",
      "Epoch 30, Loss: 0.5581756040437182\n",
      "Epoch 31, Loss: 0.5575841837133307\n",
      "Epoch 32, Loss: 0.5569979140055991\n",
      "Epoch 33, Loss: 0.5563685237325049\n",
      "Epoch 34, Loss: 0.5556868027255899\n",
      "Epoch 35, Loss: 0.5548894809965363\n",
      "Epoch 36, Loss: 0.5539391802426903\n",
      "Epoch 37, Loss: 0.5528259471079406\n",
      "Epoch 38, Loss: 0.5515191566360047\n",
      "Epoch 39, Loss: 0.5500792500446887\n",
      "Epoch 40, Loss: 0.548457607759253\n",
      "Epoch 41, Loss: 0.5465248076592342\n",
      "Epoch 42, Loss: 0.544262504209703\n",
      "Epoch 43, Loss: 0.5416764447968012\n",
      "Epoch 44, Loss: 0.5389198446176662\n",
      "Epoch 45, Loss: 0.5363792033923126\n",
      "Epoch 46, Loss: 0.5346253539220902\n",
      "Epoch 47, Loss: 0.533360468526803\n",
      "Epoch 48, Loss: 0.5313898912136642\n",
      "Epoch 49, Loss: 0.5281367238566151\n",
      "Epoch 50, Loss: 0.5244949818271992\n",
      "Epoch 51, Loss: 0.5216570507581124\n",
      "Epoch 52, Loss: 0.5196370182074487\n",
      "Epoch 53, Loss: 0.5178818297491722\n",
      "Epoch 54, Loss: 0.5159131603172136\n",
      "Epoch 55, Loss: 0.5136241528060065\n",
      "Epoch 56, Loss: 0.5111642118728164\n",
      "Epoch 57, Loss: 0.5088420994036097\n",
      "Epoch 58, Loss: 0.5068923242621094\n",
      "Epoch 59, Loss: 0.5050745587027576\n",
      "Epoch 60, Loss: 0.5029836977502953\n",
      "Epoch 61, Loss: 0.5007855979028448\n",
      "Epoch 62, Loss: 0.49899729382138536\n",
      "Epoch 63, Loss: 0.49765449475707957\n",
      "Epoch 64, Loss: 0.49640154864252545\n",
      "Epoch 65, Loss: 0.49492929117356366\n",
      "Epoch 66, Loss: 0.49330230890271537\n",
      "Epoch 67, Loss: 0.49178330915555296\n",
      "Epoch 68, Loss: 0.4904396113854242\n",
      "Epoch 69, Loss: 0.4890764094315595\n",
      "Epoch 70, Loss: 0.4877465181123777\n",
      "Epoch 71, Loss: 0.4866515773019026\n",
      "Epoch 72, Loss: 0.4855825845318615\n",
      "Epoch 73, Loss: 0.4843002384694828\n",
      "Epoch 74, Loss: 0.4829769724723219\n",
      "Epoch 75, Loss: 0.4818909692901275\n",
      "Epoch 76, Loss: 0.4809151413388284\n",
      "Epoch 77, Loss: 0.47982841559117484\n",
      "Epoch 78, Loss: 0.4787630492491216\n",
      "Epoch 79, Loss: 0.4777577529389938\n",
      "Epoch 80, Loss: 0.4766667674082314\n",
      "Epoch 81, Loss: 0.47561740966936056\n",
      "Epoch 82, Loss: 0.47470198618600107\n",
      "Epoch 83, Loss: 0.4736697467678755\n",
      "Epoch 84, Loss: 0.472536166361104\n",
      "Epoch 85, Loss: 0.4715355915610704\n",
      "Epoch 86, Loss: 0.47057180828505085\n",
      "Epoch 87, Loss: 0.46958532609096465\n",
      "Epoch 88, Loss: 0.46862686447256996\n",
      "Epoch 89, Loss: 0.4675956818384505\n",
      "Epoch 90, Loss: 0.4666024605258174\n",
      "Epoch 91, Loss: 0.46566320364992647\n",
      "Epoch 92, Loss: 0.4646405970203358\n",
      "Epoch 93, Loss: 0.46361861143958505\n",
      "Epoch 94, Loss: 0.4626233902856568\n",
      "Epoch 95, Loss: 0.46163460986301325\n",
      "Epoch 96, Loss: 0.46067673370652834\n",
      "Epoch 97, Loss: 0.45966279233793994\n",
      "Epoch 98, Loss: 0.45864979338151085\n",
      "Epoch 99, Loss: 0.45767354255948894\n",
      "Epoch 100, Loss: 0.4566680410490911\n",
      "Epoch 101, Loss: 0.45564560441992835\n",
      "Epoch 102, Loss: 0.4545839762078532\n",
      "Epoch 103, Loss: 0.4535073607330025\n",
      "Epoch 104, Loss: 0.4524438440927014\n",
      "Epoch 105, Loss: 0.4513691062341743\n",
      "Epoch 106, Loss: 0.45031811079967926\n",
      "Epoch 107, Loss: 0.4493152846397192\n",
      "Epoch 108, Loss: 0.44837889737003206\n",
      "Epoch 109, Loss: 0.44747987971013786\n",
      "Epoch 110, Loss: 0.44661123387570106\n",
      "Epoch 111, Loss: 0.4457404272332042\n",
      "Epoch 112, Loss: 0.4448294278121437\n",
      "Epoch 113, Loss: 0.4439601608726852\n",
      "Epoch 114, Loss: 0.4430955446350744\n",
      "Epoch 115, Loss: 0.44228378770734017\n",
      "Epoch 116, Loss: 0.4414956837753102\n",
      "Epoch 117, Loss: 0.44072618675381586\n",
      "Epoch 118, Loss: 0.43997403954193487\n",
      "Epoch 119, Loss: 0.43921878924618996\n",
      "Epoch 120, Loss: 0.43847375881598594\n",
      "Epoch 121, Loss: 0.437742778990841\n",
      "Epoch 122, Loss: 0.4370153672050041\n",
      "Epoch 123, Loss: 0.4362903459085896\n",
      "Epoch 124, Loss: 0.43557429548087356\n",
      "Epoch 125, Loss: 0.43485012689891034\n",
      "Epoch 126, Loss: 0.43409564208242485\n",
      "Epoch 127, Loss: 0.4333595640086836\n",
      "Epoch 128, Loss: 0.43262660789135843\n",
      "Epoch 129, Loss: 0.43186475363471877\n",
      "Epoch 130, Loss: 0.43109856310069383\n",
      "Epoch 131, Loss: 0.43032962330066704\n",
      "Epoch 132, Loss: 0.4295870229980101\n",
      "Epoch 133, Loss: 0.4288890703161929\n",
      "Epoch 134, Loss: 0.4281680551862544\n",
      "Epoch 135, Loss: 0.42749175066545586\n",
      "Epoch 136, Loss: 0.42679910001780536\n",
      "Epoch 137, Loss: 0.4261288405245609\n",
      "Epoch 138, Loss: 0.4255019680620933\n",
      "Epoch 139, Loss: 0.4249870522714647\n",
      "Epoch 140, Loss: 0.4241630531686728\n",
      "Epoch 141, Loss: 0.42324453158713077\n",
      "Epoch 142, Loss: 0.42267892321907474\n",
      "Epoch 143, Loss: 0.4221540517143356\n",
      "Epoch 144, Loss: 0.4213438752673627\n",
      "Epoch 145, Loss: 0.420502850706573\n",
      "Epoch 146, Loss: 0.41990301400343216\n",
      "Epoch 147, Loss: 0.41925268746039573\n",
      "Epoch 148, Loss: 0.4184937789254072\n",
      "Epoch 149, Loss: 0.4177663081106081\n",
      "Epoch 150, Loss: 0.41717048424584274\n",
      "Epoch 151, Loss: 0.4166235444483838\n",
      "Epoch 152, Loss: 0.41614115079394576\n",
      "Epoch 153, Loss: 0.4156364898240755\n",
      "Epoch 154, Loss: 0.41503299484305506\n",
      "Epoch 155, Loss: 0.41431077675224365\n",
      "Epoch 156, Loss: 0.4136650949414222\n",
      "Epoch 157, Loss: 0.4132046900831541\n",
      "Epoch 158, Loss: 0.41280458216036925\n",
      "Epoch 159, Loss: 0.4123181903314031\n",
      "Epoch 160, Loss: 0.41168210628387863\n",
      "Epoch 161, Loss: 0.4109747938631665\n",
      "Epoch 162, Loss: 0.4104478253802207\n",
      "Epoch 163, Loss: 0.41000585069203566\n",
      "Epoch 164, Loss: 0.40954649878285915\n",
      "Epoch 165, Loss: 0.40891455753037215\n",
      "Epoch 166, Loss: 0.40822152274255336\n",
      "Epoch 167, Loss: 0.4075409661219959\n",
      "Epoch 168, Loss: 0.40696982654287667\n",
      "Epoch 169, Loss: 0.4065173443194382\n",
      "Epoch 170, Loss: 0.4061711124707237\n",
      "Epoch 171, Loss: 0.4060305222609217\n",
      "Epoch 172, Loss: 0.4057341932377952\n",
      "Epoch 173, Loss: 0.4048366168802359\n",
      "Epoch 174, Loss: 0.4038202175695326\n",
      "Epoch 175, Loss: 0.4035099128843227\n",
      "Epoch 176, Loss: 0.4033257620307062\n",
      "Epoch 177, Loss: 0.4027218569744265\n",
      "Epoch 178, Loss: 0.4018999077477673\n",
      "Epoch 179, Loss: 0.4016185075761679\n",
      "Epoch 180, Loss: 0.4015211009790653\n",
      "Epoch 181, Loss: 0.4007254712289977\n",
      "Epoch 182, Loss: 0.4000565041925746\n",
      "Epoch 183, Loss: 0.39959854305200293\n",
      "Epoch 184, Loss: 0.39938373030789914\n",
      "Epoch 185, Loss: 0.3989211494242274\n",
      "Epoch 186, Loss: 0.39826350059183635\n",
      "Epoch 187, Loss: 0.39774093325799065\n",
      "Epoch 188, Loss: 0.39721330806463795\n",
      "Epoch 189, Loss: 0.39686671270894286\n",
      "Epoch 190, Loss: 0.3966559053144683\n",
      "Epoch 191, Loss: 0.3964637036877744\n",
      "Epoch 192, Loss: 0.3964341982205282\n",
      "Epoch 193, Loss: 0.39604749240165676\n",
      "Epoch 194, Loss: 0.3950263212584694\n",
      "Epoch 195, Loss: 0.39427535568055816\n",
      "Epoch 196, Loss: 0.3941536975881691\n",
      "Epoch 197, Loss: 0.3940785898891269\n",
      "Epoch 198, Loss: 0.3937469656388363\n",
      "Epoch 199, Loss: 0.39305658742831373\n",
      "Epoch 200, Loss: 0.39234414410922647\n",
      "Epoch 201, Loss: 0.39204693437128635\n",
      "Epoch 202, Loss: 0.3918407594362986\n",
      "Epoch 203, Loss: 0.3917795476000913\n",
      "Epoch 204, Loss: 0.3915214932364987\n",
      "Epoch 205, Loss: 0.3910060359301138\n",
      "Epoch 206, Loss: 0.3905258815897312\n",
      "Epoch 207, Loss: 0.3899027632575532\n",
      "Epoch 208, Loss: 0.3894070329241164\n",
      "Epoch 209, Loss: 0.3891943865072299\n",
      "Epoch 210, Loss: 0.3890615838587748\n",
      "Epoch 211, Loss: 0.3889757434985216\n",
      "Epoch 212, Loss: 0.38917083917024226\n",
      "Epoch 213, Loss: 0.38918801163712824\n",
      "Epoch 214, Loss: 0.38848210978586917\n",
      "Epoch 215, Loss: 0.3875125098516423\n",
      "Epoch 216, Loss: 0.3867259362063628\n",
      "Epoch 217, Loss: 0.3867400577724564\n",
      "Epoch 218, Loss: 0.38703962943008097\n",
      "Epoch 219, Loss: 0.3867028743683434\n",
      "Epoch 220, Loss: 0.3858759394672253\n",
      "Epoch 221, Loss: 0.38521139589656445\n",
      "Epoch 222, Loss: 0.3849020972492824\n",
      "Epoch 223, Loss: 0.38500368915375677\n",
      "Epoch 224, Loss: 0.38507377561688966\n",
      "Epoch 225, Loss: 0.38466828949821213\n",
      "Epoch 226, Loss: 0.38396554631029667\n",
      "Epoch 227, Loss: 0.3833094699142118\n",
      "Epoch 228, Loss: 0.3829841034518516\n",
      "Epoch 229, Loss: 0.3828628468005984\n",
      "Epoch 230, Loss: 0.3829155024316057\n",
      "Epoch 231, Loss: 0.3830031290113256\n",
      "Epoch 232, Loss: 0.38264455809357945\n",
      "Epoch 233, Loss: 0.382252595119262\n",
      "Epoch 234, Loss: 0.38165509168211253\n",
      "Epoch 235, Loss: 0.3808895979407092\n",
      "Epoch 236, Loss: 0.3805866340819551\n",
      "Epoch 237, Loss: 0.38043935062941614\n",
      "Epoch 238, Loss: 0.3802482984606351\n",
      "Epoch 239, Loss: 0.3801833976337397\n",
      "Epoch 240, Loss: 0.3803459227708865\n",
      "Epoch 241, Loss: 0.38072254950969486\n",
      "Epoch 242, Loss: 0.3802364243185084\n",
      "Epoch 243, Loss: 0.37937057203445645\n",
      "Epoch 244, Loss: 0.3783336520858856\n",
      "Epoch 245, Loss: 0.37769907931426944\n",
      "Epoch 246, Loss: 0.3780330349083093\n",
      "Epoch 247, Loss: 0.37837793938358627\n",
      "Epoch 248, Loss: 0.3784087542980966\n",
      "Epoch 249, Loss: 0.3778528731792792\n",
      "Epoch 250, Loss: 0.3766621865298657\n",
      "Epoch 251, Loss: 0.37571233406924986\n",
      "Epoch 252, Loss: 0.37603894001121035\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.253151316349208\n",
      "Test R^2 score: 0.30314656102370713\n",
      "Num of epochs: 253\n",
      "Epoch 1, Loss: 0.6027879000203046\n",
      "Epoch 2, Loss: 0.6002523348602806\n",
      "Epoch 3, Loss: 0.5980525977660089\n",
      "Epoch 4, Loss: 0.5959762447426589\n",
      "Epoch 5, Loss: 0.5939524957786344\n",
      "Epoch 6, Loss: 0.5919728285073\n",
      "Epoch 7, Loss: 0.5900352621855799\n",
      "Epoch 8, Loss: 0.5881418597473251\n",
      "Epoch 9, Loss: 0.5862875337928343\n",
      "Epoch 10, Loss: 0.5844729366955128\n",
      "Epoch 11, Loss: 0.5826969819730025\n",
      "Epoch 12, Loss: 0.5809094928805054\n",
      "Epoch 13, Loss: 0.5791140678818136\n",
      "Epoch 14, Loss: 0.5773453223345127\n",
      "Epoch 15, Loss: 0.5756125111006869\n",
      "Epoch 16, Loss: 0.5739248912181901\n",
      "Epoch 17, Loss: 0.5722845809973731\n",
      "Epoch 18, Loss: 0.5706962182934522\n",
      "Epoch 19, Loss: 0.56916413896799\n",
      "Epoch 20, Loss: 0.5676918435691263\n",
      "Epoch 21, Loss: 0.5662853769699633\n",
      "Epoch 22, Loss: 0.5649517984843914\n",
      "Epoch 23, Loss: 0.5636909116833564\n",
      "Epoch 24, Loss: 0.5625071790025147\n",
      "Epoch 25, Loss: 0.561429116993455\n",
      "Epoch 26, Loss: 0.56044207400713\n",
      "Epoch 27, Loss: 0.5595341216362258\n",
      "Epoch 28, Loss: 0.5587032184175617\n",
      "Epoch 29, Loss: 0.5579406014176022\n",
      "Epoch 30, Loss: 0.5572297308424263\n",
      "Epoch 31, Loss: 0.5566265974452348\n",
      "Epoch 32, Loss: 0.5560896974669426\n",
      "Epoch 33, Loss: 0.5555758012288026\n",
      "Epoch 34, Loss: 0.5550929991670803\n",
      "Epoch 35, Loss: 0.5546318617304501\n",
      "Epoch 36, Loss: 0.5541289297558727\n",
      "Epoch 37, Loss: 0.5535086610473096\n",
      "Epoch 38, Loss: 0.5527559417722715\n",
      "Epoch 39, Loss: 0.5518130654545889\n",
      "Epoch 40, Loss: 0.550619169154562\n",
      "Epoch 41, Loss: 0.5491350340765496\n",
      "Epoch 42, Loss: 0.5473012080799042\n",
      "Epoch 43, Loss: 0.5450938783949574\n",
      "Epoch 44, Loss: 0.5424903298759868\n",
      "Epoch 45, Loss: 0.5394273159253361\n",
      "Epoch 46, Loss: 0.5359515385693654\n",
      "Epoch 47, Loss: 0.5322468605020583\n",
      "Epoch 48, Loss: 0.528747047794839\n",
      "Epoch 49, Loss: 0.525983454690646\n",
      "Epoch 50, Loss: 0.5242563646354945\n",
      "Epoch 51, Loss: 0.5227027974976519\n",
      "Epoch 52, Loss: 0.5198778416124167\n",
      "Epoch 53, Loss: 0.5162742457573062\n",
      "Epoch 54, Loss: 0.5131633257288934\n",
      "Epoch 55, Loss: 0.5112245808929989\n",
      "Epoch 56, Loss: 0.5098095286671944\n",
      "Epoch 57, Loss: 0.5080829487065495\n",
      "Epoch 58, Loss: 0.5058310953726535\n",
      "Epoch 59, Loss: 0.5033064532786575\n",
      "Epoch 60, Loss: 0.5009769194306112\n",
      "Epoch 61, Loss: 0.4991574639324897\n",
      "Epoch 62, Loss: 0.49742624845599726\n",
      "Epoch 63, Loss: 0.4952813954018259\n",
      "Epoch 64, Loss: 0.4930242207991965\n",
      "Epoch 65, Loss: 0.49121767194920724\n",
      "Epoch 66, Loss: 0.4897706623703709\n",
      "Epoch 67, Loss: 0.48817989060275\n",
      "Epoch 68, Loss: 0.4863129272537502\n",
      "Epoch 69, Loss: 0.48447898548423296\n",
      "Epoch 70, Loss: 0.483090743963798\n",
      "Epoch 71, Loss: 0.4819076515643913\n",
      "Epoch 72, Loss: 0.48047586761412947\n",
      "Epoch 73, Loss: 0.4790528376451544\n",
      "Epoch 74, Loss: 0.47790818877323593\n",
      "Epoch 75, Loss: 0.47671753284620294\n",
      "Epoch 76, Loss: 0.47530908378963493\n",
      "Epoch 77, Loss: 0.47400549943868325\n",
      "Epoch 78, Loss: 0.4729525055378255\n",
      "Epoch 79, Loss: 0.4717556594100807\n",
      "Epoch 80, Loss: 0.4704010179933575\n",
      "Epoch 81, Loss: 0.4691822602078666\n",
      "Epoch 82, Loss: 0.46801638416502145\n",
      "Epoch 83, Loss: 0.46689673277434224\n",
      "Epoch 84, Loss: 0.46594038401478044\n",
      "Epoch 85, Loss: 0.4649776778708409\n",
      "Epoch 86, Loss: 0.463909717417087\n",
      "Epoch 87, Loss: 0.46294607160359774\n",
      "Epoch 88, Loss: 0.46207033380993234\n",
      "Epoch 89, Loss: 0.46112774301252357\n",
      "Epoch 90, Loss: 0.46023289118333166\n",
      "Epoch 91, Loss: 0.459356084421192\n",
      "Epoch 92, Loss: 0.4584609273113526\n",
      "Epoch 93, Loss: 0.45755299513987785\n",
      "Epoch 94, Loss: 0.45652643673589605\n",
      "Epoch 95, Loss: 0.455536803564519\n",
      "Epoch 96, Loss: 0.45454793341459243\n",
      "Epoch 97, Loss: 0.45367961681835955\n",
      "Epoch 98, Loss: 0.4528428053998398\n",
      "Epoch 99, Loss: 0.4521034498470811\n",
      "Epoch 100, Loss: 0.4514514337718646\n",
      "Epoch 101, Loss: 0.45092327320182557\n",
      "Epoch 102, Loss: 0.4504039223156307\n",
      "Epoch 103, Loss: 0.4497505357473002\n",
      "Epoch 104, Loss: 0.44880151030644183\n",
      "Epoch 105, Loss: 0.44776766723652695\n",
      "Epoch 106, Loss: 0.4468201163407573\n",
      "Epoch 107, Loss: 0.44593290980221467\n",
      "Epoch 108, Loss: 0.44503747243839087\n",
      "Epoch 109, Loss: 0.4441526936390231\n",
      "Epoch 110, Loss: 0.4432179061439441\n",
      "Epoch 111, Loss: 0.44233088578059926\n",
      "Epoch 112, Loss: 0.4414821154459474\n",
      "Epoch 113, Loss: 0.44063595426754254\n",
      "Epoch 114, Loss: 0.4398017178875747\n",
      "Epoch 115, Loss: 0.43897115768627215\n",
      "Epoch 116, Loss: 0.43819227964541924\n",
      "Epoch 117, Loss: 0.4374897819415714\n",
      "Epoch 118, Loss: 0.436819569205063\n",
      "Epoch 119, Loss: 0.43624958092961774\n",
      "Epoch 120, Loss: 0.4360001091792906\n",
      "Epoch 121, Loss: 0.43559509489395204\n",
      "Epoch 122, Loss: 0.4344206134256584\n",
      "Epoch 123, Loss: 0.4338610572618842\n",
      "Epoch 124, Loss: 0.4336956866610799\n",
      "Epoch 125, Loss: 0.4326572442723536\n",
      "Epoch 126, Loss: 0.4322647829390583\n",
      "Epoch 127, Loss: 0.4319425536676846\n",
      "Epoch 128, Loss: 0.43101825983660635\n",
      "Epoch 129, Loss: 0.43079422694250163\n",
      "Epoch 130, Loss: 0.4303506588828981\n",
      "Epoch 131, Loss: 0.4295047544797967\n",
      "Epoch 132, Loss: 0.4292394556273429\n",
      "Epoch 133, Loss: 0.4287691359239458\n",
      "Epoch 134, Loss: 0.42797487717608945\n",
      "Epoch 135, Loss: 0.4276195528775689\n",
      "Epoch 136, Loss: 0.42725987003459254\n",
      "Epoch 137, Loss: 0.4265149645466423\n",
      "Epoch 138, Loss: 0.426019374509814\n",
      "Epoch 139, Loss: 0.425718075326445\n",
      "Epoch 140, Loss: 0.4251467150004848\n",
      "Epoch 141, Loss: 0.42452541247620146\n",
      "Epoch 142, Loss: 0.424075902419234\n",
      "Epoch 143, Loss: 0.42375293187727864\n",
      "Epoch 144, Loss: 0.4233928150092629\n",
      "Epoch 145, Loss: 0.42292013339170537\n",
      "Epoch 146, Loss: 0.4223816443183456\n",
      "Epoch 147, Loss: 0.4218234807805245\n",
      "Epoch 148, Loss: 0.4213360063044549\n",
      "Epoch 149, Loss: 0.42093644114405754\n",
      "Epoch 150, Loss: 0.42060921771183557\n",
      "Epoch 151, Loss: 0.4204492672617045\n",
      "Epoch 152, Loss: 0.42055456713948464\n",
      "Epoch 153, Loss: 0.42078854925296055\n",
      "Epoch 154, Loss: 0.419971569580632\n",
      "Epoch 155, Loss: 0.4185120625403928\n",
      "Epoch 156, Loss: 0.41836575343864346\n",
      "Epoch 157, Loss: 0.4186816152559678\n",
      "Epoch 158, Loss: 0.4177194011994508\n",
      "Epoch 159, Loss: 0.4168760866153859\n",
      "Epoch 160, Loss: 0.4171272612954251\n",
      "Epoch 161, Loss: 0.41682346691759575\n",
      "Epoch 162, Loss: 0.41581844976248944\n",
      "Epoch 163, Loss: 0.4154576244206008\n",
      "Epoch 164, Loss: 0.4156302157770305\n",
      "Epoch 165, Loss: 0.4153070998002204\n",
      "Epoch 166, Loss: 0.4142784419267082\n",
      "Epoch 167, Loss: 0.4139370458313289\n",
      "Epoch 168, Loss: 0.41411899685042064\n",
      "Epoch 169, Loss: 0.4137088416911532\n",
      "Epoch 170, Loss: 0.4128325205820456\n",
      "Epoch 171, Loss: 0.4123004633019856\n",
      "Epoch 172, Loss: 0.4122811632840833\n",
      "Epoch 173, Loss: 0.4122909399041929\n",
      "Epoch 174, Loss: 0.4118403419882163\n",
      "Epoch 175, Loss: 0.41110600907400324\n",
      "Epoch 176, Loss: 0.4103987748785397\n",
      "Epoch 177, Loss: 0.410069247509619\n",
      "Epoch 178, Loss: 0.4101032949504093\n",
      "Epoch 179, Loss: 0.4102266886944001\n",
      "Epoch 180, Loss: 0.41009335716883955\n",
      "Epoch 181, Loss: 0.4092569027972781\n",
      "Epoch 182, Loss: 0.4083118567690125\n",
      "Epoch 183, Loss: 0.40784707123828506\n",
      "Epoch 184, Loss: 0.4078589635812654\n",
      "Epoch 185, Loss: 0.40796393363502736\n",
      "Epoch 186, Loss: 0.40777808515536834\n",
      "Epoch 187, Loss: 0.4072988798115773\n",
      "Epoch 188, Loss: 0.4063959409762133\n",
      "Epoch 189, Loss: 0.4057070331469727\n",
      "Epoch 190, Loss: 0.4054920572039201\n",
      "Epoch 191, Loss: 0.40556363665826656\n",
      "Epoch 192, Loss: 0.40581935285042975\n",
      "Epoch 193, Loss: 0.4055690193046163\n",
      "Epoch 194, Loss: 0.40493745780105006\n",
      "Epoch 195, Loss: 0.4039232121342495\n",
      "Epoch 196, Loss: 0.40342049820678805\n",
      "Epoch 197, Loss: 0.40342376712204797\n",
      "Epoch 198, Loss: 0.4036129681733452\n",
      "Epoch 199, Loss: 0.4039003574671985\n",
      "Epoch 200, Loss: 0.40345519906836785\n",
      "Epoch 201, Loss: 0.4027296826360275\n",
      "Epoch 202, Loss: 0.4016890337594088\n",
      "Epoch 203, Loss: 0.40116288677424317\n",
      "Epoch 204, Loss: 0.4011113820437582\n",
      "Epoch 205, Loss: 0.4012393794332776\n",
      "Epoch 206, Loss: 0.40157585567128384\n",
      "Epoch 207, Loss: 0.40129123906611286\n",
      "Epoch 208, Loss: 0.40091702353205816\n",
      "Epoch 209, Loss: 0.39985675109381585\n",
      "Epoch 210, Loss: 0.39905694418484744\n",
      "Epoch 211, Loss: 0.3987323754400725\n",
      "Epoch 212, Loss: 0.3987992084717237\n",
      "Epoch 213, Loss: 0.3991626423863185\n",
      "Epoch 214, Loss: 0.3991463470496827\n",
      "Epoch 215, Loss: 0.39925842237337317\n",
      "Epoch 216, Loss: 0.3981518001608637\n",
      "Epoch 217, Loss: 0.39718817271874196\n",
      "Epoch 218, Loss: 0.3964650755446115\n",
      "Epoch 219, Loss: 0.39633901402519967\n",
      "Epoch 220, Loss: 0.3966436395085403\n",
      "Epoch 221, Loss: 0.3968002864768355\n",
      "Epoch 222, Loss: 0.3971297925540439\n",
      "Epoch 223, Loss: 0.3963324344941372\n",
      "Epoch 224, Loss: 0.3952332473741813\n",
      "Epoch 225, Loss: 0.394189233117129\n",
      "Epoch 226, Loss: 0.3937313544687622\n",
      "Epoch 227, Loss: 0.39373485520922186\n",
      "Epoch 228, Loss: 0.39413260157786173\n",
      "Epoch 229, Loss: 0.39491811990131775\n",
      "Epoch 230, Loss: 0.39489431011470016\n",
      "Epoch 231, Loss: 0.39440294577826457\n",
      "Epoch 232, Loss: 0.39230794766811183\n",
      "Epoch 233, Loss: 0.39112560619503556\n",
      "Epoch 234, Loss: 0.39137524084122155\n",
      "Epoch 235, Loss: 0.39204577510679905\n",
      "Epoch 236, Loss: 0.39277896203813223\n",
      "Epoch 237, Loss: 0.39165252962706587\n",
      "Epoch 238, Loss: 0.38993943135339176\n",
      "Epoch 239, Loss: 0.3891355346395766\n",
      "Epoch 240, Loss: 0.3893817763557868\n",
      "Epoch 241, Loss: 0.38999902159617034\n",
      "Epoch 242, Loss: 0.3904916344905404\n",
      "Epoch 243, Loss: 0.39097179277681415\n",
      "Epoch 244, Loss: 0.3884984880476881\n",
      "Epoch 245, Loss: 0.387276815160795\n",
      "Epoch 246, Loss: 0.3867660455007567\n",
      "Epoch 247, Loss: 0.3871610212470052\n",
      "Epoch 248, Loss: 0.3885183174781005\n",
      "Epoch 249, Loss: 0.3880618882275043\n",
      "Epoch 250, Loss: 0.38743711468892356\n",
      "Epoch 251, Loss: 0.3849091044483726\n",
      "Epoch 252, Loss: 0.3846951725161331\n",
      "Epoch 253, Loss: 0.38536847517792283\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.24554484831413287\n",
      "Test R^2 score: 0.3545465731729379\n",
      "Num of epochs: 254\n",
      "Epoch 1, Loss: 0.5574192691306332\n",
      "Epoch 2, Loss: 0.5569767522703081\n",
      "Epoch 3, Loss: 0.5566303988404141\n",
      "Epoch 4, Loss: 0.5563961362147194\n",
      "Epoch 5, Loss: 0.5562607121239791\n",
      "Epoch 6, Loss: 0.5562000873760387\n",
      "Epoch 7, Loss: 0.5561951845998994\n",
      "Epoch 8, Loss: 0.556223127166038\n",
      "Epoch 9, Loss: 0.5562674358935599\n",
      "Epoch 10, Loss: 0.5563067053705322\n",
      "Epoch 11, Loss: 0.5563275176051525\n",
      "Epoch 12, Loss: 0.5563257230158528\n",
      "Epoch 13, Loss: 0.5563019642506698\n",
      "Epoch 14, Loss: 0.5562613282496738\n",
      "Epoch 15, Loss: 0.5562109376285943\n",
      "Epoch 16, Loss: 0.5561559608348547\n",
      "Epoch 17, Loss: 0.5561032830386153\n",
      "Epoch 18, Loss: 0.5560564422311755\n",
      "Epoch 19, Loss: 0.55601643148334\n",
      "Epoch 20, Loss: 0.5559803309031818\n",
      "Epoch 21, Loss: 0.5559441743721312\n",
      "Epoch 22, Loss: 0.555903404995831\n",
      "Epoch 23, Loss: 0.5558519632323852\n",
      "Epoch 24, Loss: 0.5557841353922006\n",
      "Epoch 25, Loss: 0.5556975021088554\n",
      "Epoch 26, Loss: 0.5555855103867724\n",
      "Epoch 27, Loss: 0.5554417867863176\n",
      "Epoch 28, Loss: 0.5552689634311267\n",
      "Epoch 29, Loss: 0.5550600600608321\n",
      "Epoch 30, Loss: 0.5548027080115695\n",
      "Epoch 31, Loss: 0.5544917607482149\n",
      "Epoch 32, Loss: 0.5541096753617999\n",
      "Epoch 33, Loss: 0.5536388101308739\n",
      "Epoch 34, Loss: 0.5530602939926849\n",
      "Epoch 35, Loss: 0.5523502916005341\n",
      "Epoch 36, Loss: 0.5514810593863793\n",
      "Epoch 37, Loss: 0.5504254213032035\n",
      "Epoch 38, Loss: 0.5491595913320773\n",
      "Epoch 39, Loss: 0.5476619235845476\n",
      "Epoch 40, Loss: 0.5459069539669983\n",
      "Epoch 41, Loss: 0.543934628503271\n",
      "Epoch 42, Loss: 0.5417221633896018\n",
      "Epoch 43, Loss: 0.5391983192837893\n",
      "Epoch 44, Loss: 0.5363104965302349\n",
      "Epoch 45, Loss: 0.5330208826751517\n",
      "Epoch 46, Loss: 0.529339158737564\n",
      "Epoch 47, Loss: 0.525300879772589\n",
      "Epoch 48, Loss: 0.520812669979916\n",
      "Epoch 49, Loss: 0.5158575285052804\n",
      "Epoch 50, Loss: 0.510471367013398\n",
      "Epoch 51, Loss: 0.5046264469786491\n",
      "Epoch 52, Loss: 0.49837577282147444\n",
      "Epoch 53, Loss: 0.49199298769229693\n",
      "Epoch 54, Loss: 0.48638250820547996\n",
      "Epoch 55, Loss: 0.48291961382947707\n",
      "Epoch 56, Loss: 0.48179347698163305\n",
      "Epoch 57, Loss: 0.4810117119237615\n",
      "Epoch 58, Loss: 0.4805350374225236\n",
      "Epoch 59, Loss: 0.4804611360520394\n",
      "Epoch 60, Loss: 0.47942988967972056\n",
      "Epoch 61, Loss: 0.47714282488088605\n",
      "Epoch 62, Loss: 0.47474115998855015\n",
      "Epoch 63, Loss: 0.4737356172658154\n",
      "Epoch 64, Loss: 0.4736021995482885\n",
      "Epoch 65, Loss: 0.47355778680001315\n",
      "Epoch 66, Loss: 0.4723699033350688\n",
      "Epoch 67, Loss: 0.4703358844000295\n",
      "Epoch 68, Loss: 0.46848275195730804\n",
      "Epoch 69, Loss: 0.467289509050431\n",
      "Epoch 70, Loss: 0.4661663217854693\n",
      "Epoch 71, Loss: 0.4651408167884178\n",
      "Epoch 72, Loss: 0.46416712650753417\n",
      "Epoch 73, Loss: 0.4633616694469305\n",
      "Epoch 74, Loss: 0.46275900728021463\n",
      "Epoch 75, Loss: 0.46217390498245525\n",
      "Epoch 76, Loss: 0.46144357475406295\n",
      "Epoch 77, Loss: 0.4606239901393136\n",
      "Epoch 78, Loss: 0.4598398393418679\n",
      "Epoch 79, Loss: 0.45916770358006054\n",
      "Epoch 80, Loss: 0.458571325270493\n",
      "Epoch 81, Loss: 0.45799458694070233\n",
      "Epoch 82, Loss: 0.45739979026899713\n",
      "Epoch 83, Loss: 0.45675052269987654\n",
      "Epoch 84, Loss: 0.4560822962505125\n",
      "Epoch 85, Loss: 0.45544036070091576\n",
      "Epoch 86, Loss: 0.4548526909544684\n",
      "Epoch 87, Loss: 0.4543157421074571\n",
      "Epoch 88, Loss: 0.4538228974490281\n",
      "Epoch 89, Loss: 0.45333904932721725\n",
      "Epoch 90, Loss: 0.4528491726301144\n",
      "Epoch 91, Loss: 0.4523523418816218\n",
      "Epoch 92, Loss: 0.451848567120947\n",
      "Epoch 93, Loss: 0.45130456071523295\n",
      "Epoch 94, Loss: 0.4507359797655811\n",
      "Epoch 95, Loss: 0.45017161275911555\n",
      "Epoch 96, Loss: 0.44961707657913424\n",
      "Epoch 97, Loss: 0.4490621210785543\n",
      "Epoch 98, Loss: 0.44850347213081554\n",
      "Epoch 99, Loss: 0.4479358266088888\n",
      "Epoch 100, Loss: 0.4473878951547132\n",
      "Epoch 101, Loss: 0.44683950856793797\n",
      "Epoch 102, Loss: 0.4462982276960377\n",
      "Epoch 103, Loss: 0.4457424163216032\n",
      "Epoch 104, Loss: 0.4451448727375968\n",
      "Epoch 105, Loss: 0.44456013483420936\n",
      "Epoch 106, Loss: 0.44391899249040023\n",
      "Epoch 107, Loss: 0.44326144241758053\n",
      "Epoch 108, Loss: 0.442570947385195\n",
      "Epoch 109, Loss: 0.44187477025480654\n",
      "Epoch 110, Loss: 0.44120507170960377\n",
      "Epoch 111, Loss: 0.44052792825831316\n",
      "Epoch 112, Loss: 0.43983610631016345\n",
      "Epoch 113, Loss: 0.4391339647771734\n",
      "Epoch 114, Loss: 0.43840665196215367\n",
      "Epoch 115, Loss: 0.4376730236147207\n",
      "Epoch 116, Loss: 0.4369372938491494\n",
      "Epoch 117, Loss: 0.436214055763892\n",
      "Epoch 118, Loss: 0.43546282380625817\n",
      "Epoch 119, Loss: 0.4347081512273578\n",
      "Epoch 120, Loss: 0.4339550849651349\n",
      "Epoch 121, Loss: 0.4332178565668754\n",
      "Epoch 122, Loss: 0.43249992348554517\n",
      "Epoch 123, Loss: 0.43180283135298175\n",
      "Epoch 124, Loss: 0.4312017462174421\n",
      "Epoch 125, Loss: 0.43059257208055846\n",
      "Epoch 126, Loss: 0.4299943695143297\n",
      "Epoch 127, Loss: 0.4293751708562031\n",
      "Epoch 128, Loss: 0.4287695355872133\n",
      "Epoch 129, Loss: 0.428163496082684\n",
      "Epoch 130, Loss: 0.427571723007655\n",
      "Epoch 131, Loss: 0.4270262059717461\n",
      "Epoch 132, Loss: 0.42672034476676074\n",
      "Epoch 133, Loss: 0.42670607962527063\n",
      "Epoch 134, Loss: 0.4253786265745217\n",
      "Epoch 135, Loss: 0.42481961278894437\n",
      "Epoch 136, Loss: 0.4247921470457276\n",
      "Epoch 137, Loss: 0.4237053337299848\n",
      "Epoch 138, Loss: 0.4231836895549305\n",
      "Epoch 139, Loss: 0.42298724880568966\n",
      "Epoch 140, Loss: 0.4219896725819162\n",
      "Epoch 141, Loss: 0.4215224346975814\n",
      "Epoch 142, Loss: 0.42125635351715535\n",
      "Epoch 143, Loss: 0.42031191077776026\n",
      "Epoch 144, Loss: 0.4199042205647947\n",
      "Epoch 145, Loss: 0.41961791992009945\n",
      "Epoch 146, Loss: 0.4187385742564539\n",
      "Epoch 147, Loss: 0.4182132647457554\n",
      "Epoch 148, Loss: 0.41793557507776335\n",
      "Epoch 149, Loss: 0.4170944481561805\n",
      "Epoch 150, Loss: 0.41649447896647995\n",
      "Epoch 151, Loss: 0.41619070604507025\n",
      "Epoch 152, Loss: 0.41556548000741106\n",
      "Epoch 153, Loss: 0.41481408697425065\n",
      "Epoch 154, Loss: 0.414123764544025\n",
      "Epoch 155, Loss: 0.4136706963685331\n",
      "Epoch 156, Loss: 0.41343546119354474\n",
      "Epoch 157, Loss: 0.41314938466048073\n",
      "Epoch 158, Loss: 0.41273304901689883\n",
      "Epoch 159, Loss: 0.4115626428266435\n",
      "Epoch 160, Loss: 0.4106894161265004\n",
      "Epoch 161, Loss: 0.4103558191063235\n",
      "Epoch 162, Loss: 0.4101431344978001\n",
      "Epoch 163, Loss: 0.40976494788158463\n",
      "Epoch 164, Loss: 0.4088002997547514\n",
      "Epoch 165, Loss: 0.40793041994459583\n",
      "Epoch 166, Loss: 0.40739241774253854\n",
      "Epoch 167, Loss: 0.4071358412721328\n",
      "Epoch 168, Loss: 0.40714134953095427\n",
      "Epoch 169, Loss: 0.40687886495556397\n",
      "Epoch 170, Loss: 0.4062573175504859\n",
      "Epoch 171, Loss: 0.40502903934261325\n",
      "Epoch 172, Loss: 0.40419052863059163\n",
      "Epoch 173, Loss: 0.4040245392057875\n",
      "Epoch 174, Loss: 0.404089501312933\n",
      "Epoch 175, Loss: 0.4040356036009268\n",
      "Epoch 176, Loss: 0.4027598553356858\n",
      "Epoch 177, Loss: 0.40169899398197223\n",
      "Epoch 178, Loss: 0.4013510559255858\n",
      "Epoch 179, Loss: 0.40149115065873353\n",
      "Epoch 180, Loss: 0.40164343986719486\n",
      "Epoch 181, Loss: 0.4007081982103101\n",
      "Epoch 182, Loss: 0.399571898223508\n",
      "Epoch 183, Loss: 0.3988091287749909\n",
      "Epoch 184, Loss: 0.3988218136996996\n",
      "Epoch 185, Loss: 0.3990683330088679\n",
      "Epoch 186, Loss: 0.3985826003707079\n",
      "Epoch 187, Loss: 0.3977050406571307\n",
      "Epoch 188, Loss: 0.3967691535677129\n",
      "Epoch 189, Loss: 0.3963273399821996\n",
      "Epoch 190, Loss: 0.39630549487492445\n",
      "Epoch 191, Loss: 0.3963439955974908\n",
      "Epoch 192, Loss: 0.39612465310916656\n",
      "Epoch 193, Loss: 0.39549244038413806\n",
      "Epoch 194, Loss: 0.3946814675976321\n",
      "Epoch 195, Loss: 0.3939729271412586\n",
      "Epoch 196, Loss: 0.3936275480992886\n",
      "Epoch 197, Loss: 0.3935573568324584\n",
      "Epoch 198, Loss: 0.39362010932663055\n",
      "Epoch 199, Loss: 0.39381420959212976\n",
      "Epoch 200, Loss: 0.393831974155267\n",
      "Epoch 201, Loss: 0.39344284323653744\n",
      "Epoch 202, Loss: 0.3922228937781933\n",
      "Epoch 203, Loss: 0.3911606930154832\n",
      "Epoch 204, Loss: 0.39085657884663944\n",
      "Epoch 205, Loss: 0.39114606436541866\n",
      "Epoch 206, Loss: 0.39152862935114385\n",
      "Epoch 207, Loss: 0.39110289903974244\n",
      "Epoch 208, Loss: 0.39022961633661873\n",
      "Epoch 209, Loss: 0.38930733648487015\n",
      "Epoch 210, Loss: 0.38889078464310894\n",
      "Epoch 211, Loss: 0.38893155188458733\n",
      "Epoch 212, Loss: 0.3891931230277588\n",
      "Epoch 213, Loss: 0.38944340333120725\n",
      "Epoch 214, Loss: 0.3890966078733173\n",
      "Epoch 215, Loss: 0.38840297042195016\n",
      "Epoch 216, Loss: 0.3874741122612129\n",
      "Epoch 217, Loss: 0.3869140594189724\n",
      "Epoch 218, Loss: 0.386793206493569\n",
      "Epoch 219, Loss: 0.38694760265295325\n",
      "Epoch 220, Loss: 0.3872210583064263\n",
      "Epoch 221, Loss: 0.38715176470537976\n",
      "Epoch 222, Loss: 0.3868532621165022\n",
      "Epoch 223, Loss: 0.38614808951041957\n",
      "Epoch 224, Loss: 0.3854760132883481\n",
      "Epoch 225, Loss: 0.3849373061670013\n",
      "Epoch 226, Loss: 0.38477441613083196\n",
      "Epoch 227, Loss: 0.38483807806248593\n",
      "Epoch 228, Loss: 0.38500746276979536\n",
      "Epoch 229, Loss: 0.3853230770852872\n",
      "Epoch 230, Loss: 0.38547645783807105\n",
      "Epoch 231, Loss: 0.3852389372611753\n",
      "Epoch 232, Loss: 0.3844461809324604\n",
      "Epoch 233, Loss: 0.38366064199301547\n",
      "Epoch 234, Loss: 0.3830413134531178\n",
      "Epoch 235, Loss: 0.3829171952308657\n",
      "Epoch 236, Loss: 0.38311840991377855\n",
      "Epoch 237, Loss: 0.3833016365187512\n",
      "Epoch 238, Loss: 0.38371076100564877\n",
      "Epoch 239, Loss: 0.3837461180599331\n",
      "Epoch 240, Loss: 0.3833351848737257\n",
      "Epoch 241, Loss: 0.38242951522847896\n",
      "Epoch 242, Loss: 0.3817736289462801\n",
      "Epoch 243, Loss: 0.3813022874716018\n",
      "Epoch 244, Loss: 0.38132678962697225\n",
      "Epoch 245, Loss: 0.38176931595164654\n",
      "Epoch 246, Loss: 0.38212161097397906\n",
      "Epoch 247, Loss: 0.38259992730942116\n",
      "Epoch 248, Loss: 0.3823180411315943\n",
      "Epoch 249, Loss: 0.38142089531209994\n",
      "Epoch 250, Loss: 0.3802512963289815\n",
      "Epoch 251, Loss: 0.3799006401527054\n",
      "Epoch 252, Loss: 0.38014084944317994\n",
      "Epoch 253, Loss: 0.3804331424038045\n",
      "Epoch 254, Loss: 0.3807904107671073\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.24825016473201278\n",
      "Test R^2 score: 0.3356668163721278\n",
      "Num of epochs: 255\n",
      "Epoch 1, Loss: 0.5898294510276603\n",
      "Epoch 2, Loss: 0.5869459248302611\n",
      "Epoch 3, Loss: 0.5842143087736048\n",
      "Epoch 4, Loss: 0.5817823709990502\n",
      "Epoch 5, Loss: 0.5794945809700924\n",
      "Epoch 6, Loss: 0.5772912224811821\n",
      "Epoch 7, Loss: 0.5751849239946186\n",
      "Epoch 8, Loss: 0.5734208200715735\n",
      "Epoch 9, Loss: 0.5717391889890268\n",
      "Epoch 10, Loss: 0.570199720126926\n",
      "Epoch 11, Loss: 0.5687848625397435\n",
      "Epoch 12, Loss: 0.5674760909232487\n",
      "Epoch 13, Loss: 0.5662250360455447\n",
      "Epoch 14, Loss: 0.5650342965477202\n",
      "Epoch 15, Loss: 0.5639198450408849\n",
      "Epoch 16, Loss: 0.5628730808253295\n",
      "Epoch 17, Loss: 0.5618952838516486\n",
      "Epoch 18, Loss: 0.5609892584848448\n",
      "Epoch 19, Loss: 0.560157028899988\n",
      "Epoch 20, Loss: 0.5593999366955931\n",
      "Epoch 21, Loss: 0.5587185006788926\n",
      "Epoch 22, Loss: 0.5581568363076198\n",
      "Epoch 23, Loss: 0.5576707109461216\n",
      "Epoch 24, Loss: 0.5572339559840733\n",
      "Epoch 25, Loss: 0.5568558394007466\n",
      "Epoch 26, Loss: 0.5565314738018111\n",
      "Epoch 27, Loss: 0.5562348878072056\n",
      "Epoch 28, Loss: 0.5560397468706217\n",
      "Epoch 29, Loss: 0.5558010261026515\n",
      "Epoch 30, Loss: 0.5555634365582434\n",
      "Epoch 31, Loss: 0.5553104770690102\n",
      "Epoch 32, Loss: 0.5550268505234147\n",
      "Epoch 33, Loss: 0.5546961770252083\n",
      "Epoch 34, Loss: 0.5543101733214035\n",
      "Epoch 35, Loss: 0.5538399359387651\n",
      "Epoch 36, Loss: 0.5532515838952022\n",
      "Epoch 37, Loss: 0.5525175282558905\n",
      "Epoch 38, Loss: 0.5516036636942494\n",
      "Epoch 39, Loss: 0.5504673002182263\n",
      "Epoch 40, Loss: 0.5490680862342328\n",
      "Epoch 41, Loss: 0.5473541340671908\n",
      "Epoch 42, Loss: 0.5452771413100553\n",
      "Epoch 43, Loss: 0.5427821545417378\n",
      "Epoch 44, Loss: 0.5398470380271668\n",
      "Epoch 45, Loss: 0.5365237285667382\n",
      "Epoch 46, Loss: 0.5329754241910178\n",
      "Epoch 47, Loss: 0.5295318138409965\n",
      "Epoch 48, Loss: 0.526834680184237\n",
      "Epoch 49, Loss: 0.5256288690231845\n",
      "Epoch 50, Loss: 0.5252770793984568\n",
      "Epoch 51, Loss: 0.5234127892881655\n",
      "Epoch 52, Loss: 0.5199022904167491\n",
      "Epoch 53, Loss: 0.5163090243553298\n",
      "Epoch 54, Loss: 0.5136509299994031\n",
      "Epoch 55, Loss: 0.5118517520827974\n",
      "Epoch 56, Loss: 0.5102972422910074\n",
      "Epoch 57, Loss: 0.5084615227874519\n",
      "Epoch 58, Loss: 0.5062127076059239\n",
      "Epoch 59, Loss: 0.5037399727365289\n",
      "Epoch 60, Loss: 0.5014634768459035\n",
      "Epoch 61, Loss: 0.4998009702805882\n",
      "Epoch 62, Loss: 0.4986528935705259\n",
      "Epoch 63, Loss: 0.497330153624279\n",
      "Epoch 64, Loss: 0.4954633086070243\n",
      "Epoch 65, Loss: 0.4934069951045949\n",
      "Epoch 66, Loss: 0.49164271101000623\n",
      "Epoch 67, Loss: 0.4902057107395109\n",
      "Epoch 68, Loss: 0.48876719898197146\n",
      "Epoch 69, Loss: 0.4870386104376347\n",
      "Epoch 70, Loss: 0.4851144714304009\n",
      "Epoch 71, Loss: 0.48337278972364056\n",
      "Epoch 72, Loss: 0.48208132009269933\n",
      "Epoch 73, Loss: 0.4808413913565081\n",
      "Epoch 74, Loss: 0.47932137362197147\n",
      "Epoch 75, Loss: 0.4776832347331571\n",
      "Epoch 76, Loss: 0.47622326205131377\n",
      "Epoch 77, Loss: 0.47486686785834836\n",
      "Epoch 78, Loss: 0.4733388873594903\n",
      "Epoch 79, Loss: 0.4716152992292251\n",
      "Epoch 80, Loss: 0.4700344131684881\n",
      "Epoch 81, Loss: 0.46869633685341466\n",
      "Epoch 82, Loss: 0.46733877418493946\n",
      "Epoch 83, Loss: 0.4658795684936407\n",
      "Epoch 84, Loss: 0.46468826706905714\n",
      "Epoch 85, Loss: 0.4636125849647756\n",
      "Epoch 86, Loss: 0.4623408050030776\n",
      "Epoch 87, Loss: 0.4613648066525067\n",
      "Epoch 88, Loss: 0.4603793110372445\n",
      "Epoch 89, Loss: 0.4591104374909519\n",
      "Epoch 90, Loss: 0.4579699893129019\n",
      "Epoch 91, Loss: 0.45693285608364564\n",
      "Epoch 92, Loss: 0.4559562299095918\n",
      "Epoch 93, Loss: 0.4550878008030771\n",
      "Epoch 94, Loss: 0.4541284860812637\n",
      "Epoch 95, Loss: 0.453243453886983\n",
      "Epoch 96, Loss: 0.4524475657132111\n",
      "Epoch 97, Loss: 0.4518044730900974\n",
      "Epoch 98, Loss: 0.4510958058356969\n",
      "Epoch 99, Loss: 0.4503981160370519\n",
      "Epoch 100, Loss: 0.44959339607274157\n",
      "Epoch 101, Loss: 0.4488481734589761\n",
      "Epoch 102, Loss: 0.4480534573830589\n",
      "Epoch 103, Loss: 0.447349940186208\n",
      "Epoch 104, Loss: 0.44664064411018495\n",
      "Epoch 105, Loss: 0.4458889659889896\n",
      "Epoch 106, Loss: 0.4451730242026119\n",
      "Epoch 107, Loss: 0.44442174732678646\n",
      "Epoch 108, Loss: 0.4437167202196322\n",
      "Epoch 109, Loss: 0.4429995383137521\n",
      "Epoch 110, Loss: 0.44223067002132194\n",
      "Epoch 111, Loss: 0.44148187917781195\n",
      "Epoch 112, Loss: 0.4407243609844485\n",
      "Epoch 113, Loss: 0.43997099138674267\n",
      "Epoch 114, Loss: 0.43923108743434197\n",
      "Epoch 115, Loss: 0.4384812182750631\n",
      "Epoch 116, Loss: 0.4377077154524066\n",
      "Epoch 117, Loss: 0.43693512826133163\n",
      "Epoch 118, Loss: 0.4361708068014652\n",
      "Epoch 119, Loss: 0.43540976380469254\n",
      "Epoch 120, Loss: 0.4346704089152591\n",
      "Epoch 121, Loss: 0.4338797751383455\n",
      "Epoch 122, Loss: 0.43317117805426264\n",
      "Epoch 123, Loss: 0.43254410791671255\n",
      "Epoch 124, Loss: 0.432218415208954\n",
      "Epoch 125, Loss: 0.4317834540141979\n",
      "Epoch 126, Loss: 0.4303512302053567\n",
      "Epoch 127, Loss: 0.4299551910240957\n",
      "Epoch 128, Loss: 0.42972009708564296\n",
      "Epoch 129, Loss: 0.42842806997014543\n",
      "Epoch 130, Loss: 0.4281664716863182\n",
      "Epoch 131, Loss: 0.42759500262174466\n",
      "Epoch 132, Loss: 0.4266090220978131\n",
      "Epoch 133, Loss: 0.42650343517471884\n",
      "Epoch 134, Loss: 0.4256444063677894\n",
      "Epoch 135, Loss: 0.4249888930552351\n",
      "Epoch 136, Loss: 0.42472126459518683\n",
      "Epoch 137, Loss: 0.4237590856618975\n",
      "Epoch 138, Loss: 0.4233814821808567\n",
      "Epoch 139, Loss: 0.42283070008436935\n",
      "Epoch 140, Loss: 0.42198972554942193\n",
      "Epoch 141, Loss: 0.4216489362789883\n",
      "Epoch 142, Loss: 0.4210811846668396\n",
      "Epoch 143, Loss: 0.42031311616533346\n",
      "Epoch 144, Loss: 0.41991979908984517\n",
      "Epoch 145, Loss: 0.41938085080086274\n",
      "Epoch 146, Loss: 0.41874220399574164\n",
      "Epoch 147, Loss: 0.418239719579186\n",
      "Epoch 148, Loss: 0.4178489442051276\n",
      "Epoch 149, Loss: 0.4172392030888096\n",
      "Epoch 150, Loss: 0.4166386018679254\n",
      "Epoch 151, Loss: 0.4161816476140316\n",
      "Epoch 152, Loss: 0.4157709288579396\n",
      "Epoch 153, Loss: 0.4152131915856981\n",
      "Epoch 154, Loss: 0.4146133393622317\n",
      "Epoch 155, Loss: 0.41403622813819924\n",
      "Epoch 156, Loss: 0.41358263171577986\n",
      "Epoch 157, Loss: 0.4131900484811148\n",
      "Epoch 158, Loss: 0.4128899616680032\n",
      "Epoch 159, Loss: 0.41266330896397124\n",
      "Epoch 160, Loss: 0.4124159915227651\n",
      "Epoch 161, Loss: 0.41180886254243443\n",
      "Epoch 162, Loss: 0.41091215323831376\n",
      "Epoch 163, Loss: 0.41013979197588335\n",
      "Epoch 164, Loss: 0.40973567289519186\n",
      "Epoch 165, Loss: 0.4095902488560606\n",
      "Epoch 166, Loss: 0.40948782450818766\n",
      "Epoch 167, Loss: 0.408966883127728\n",
      "Epoch 168, Loss: 0.40820836333057686\n",
      "Epoch 169, Loss: 0.40733921313347443\n",
      "Epoch 170, Loss: 0.4068737743142413\n",
      "Epoch 171, Loss: 0.40666835591416156\n",
      "Epoch 172, Loss: 0.4065916202270373\n",
      "Epoch 173, Loss: 0.4065231175447526\n",
      "Epoch 174, Loss: 0.40581468954807237\n",
      "Epoch 175, Loss: 0.4048688960685532\n",
      "Epoch 176, Loss: 0.4040038295318848\n",
      "Epoch 177, Loss: 0.4037100730558238\n",
      "Epoch 178, Loss: 0.4037795511893011\n",
      "Epoch 179, Loss: 0.4036918942002213\n",
      "Epoch 180, Loss: 0.40328979376721824\n",
      "Epoch 181, Loss: 0.40226042912502763\n",
      "Epoch 182, Loss: 0.4014327837948954\n",
      "Epoch 183, Loss: 0.4010224172588066\n",
      "Epoch 184, Loss: 0.4010265046098063\n",
      "Epoch 185, Loss: 0.40132521435389634\n",
      "Epoch 186, Loss: 0.40121152509145463\n",
      "Epoch 187, Loss: 0.40040192006624453\n",
      "Epoch 188, Loss: 0.3991383204652147\n",
      "Epoch 189, Loss: 0.398529883501487\n",
      "Epoch 190, Loss: 0.3986418331009664\n",
      "Epoch 191, Loss: 0.3986254043301924\n",
      "Epoch 192, Loss: 0.39818791444799084\n",
      "Epoch 193, Loss: 0.39734012351591896\n",
      "Epoch 194, Loss: 0.3964908204705755\n",
      "Epoch 195, Loss: 0.39606525085370387\n",
      "Epoch 196, Loss: 0.3959988783281027\n",
      "Epoch 197, Loss: 0.39609156726484035\n",
      "Epoch 198, Loss: 0.39621842207369673\n",
      "Epoch 199, Loss: 0.3965187245790582\n",
      "Epoch 200, Loss: 0.39584867129809365\n",
      "Epoch 201, Loss: 0.39444250109504253\n",
      "Epoch 202, Loss: 0.39316454307955057\n",
      "Epoch 203, Loss: 0.3930376125238354\n",
      "Epoch 204, Loss: 0.3932900876312829\n",
      "Epoch 205, Loss: 0.3934268412460464\n",
      "Epoch 206, Loss: 0.39307298358603115\n",
      "Epoch 207, Loss: 0.3918822654707679\n",
      "Epoch 208, Loss: 0.39084241538621706\n",
      "Epoch 209, Loss: 0.39024198828249923\n",
      "Epoch 210, Loss: 0.39022035621305773\n",
      "Epoch 211, Loss: 0.39054934722734486\n",
      "Epoch 212, Loss: 0.39157420226905226\n",
      "Epoch 213, Loss: 0.39254166542911373\n",
      "Epoch 214, Loss: 0.39107184601367684\n",
      "Epoch 215, Loss: 0.38838392162849483\n",
      "Epoch 216, Loss: 0.38776571946097416\n",
      "Epoch 217, Loss: 0.3890949994037211\n",
      "Epoch 218, Loss: 0.3888340328994837\n",
      "Epoch 219, Loss: 0.38691719820310744\n",
      "Epoch 220, Loss: 0.38582770449910864\n",
      "Epoch 221, Loss: 0.3871605786315499\n",
      "Epoch 222, Loss: 0.38855448344604865\n",
      "Epoch 223, Loss: 0.3868091169410603\n",
      "Epoch 224, Loss: 0.38420474616022887\n",
      "Epoch 225, Loss: 0.38453316807026316\n",
      "Epoch 226, Loss: 0.38608929432760675\n",
      "Epoch 227, Loss: 0.384596172526919\n",
      "Epoch 228, Loss: 0.38234456326078997\n",
      "Epoch 229, Loss: 0.38201030057480717\n",
      "Epoch 230, Loss: 0.3824659842281981\n",
      "Epoch 231, Loss: 0.3836147698821735\n",
      "Epoch 232, Loss: 0.3821252180740887\n",
      "Epoch 233, Loss: 0.3809118968254944\n",
      "Epoch 234, Loss: 0.37930271210976857\n",
      "Epoch 235, Loss: 0.37888526858413046\n",
      "Epoch 236, Loss: 0.37943250939812223\n",
      "Epoch 237, Loss: 0.3811819226816549\n",
      "Epoch 238, Loss: 0.3874137297856987\n",
      "Epoch 239, Loss: 0.38488068772363165\n",
      "Epoch 240, Loss: 0.37844131889904925\n",
      "Epoch 241, Loss: 0.38056529502324654\n",
      "Epoch 242, Loss: 0.38434957869908476\n",
      "Epoch 243, Loss: 0.3818392155889498\n",
      "Epoch 244, Loss: 0.37746754070965916\n",
      "Epoch 245, Loss: 0.3842790693270997\n",
      "Epoch 246, Loss: 0.3808873092970878\n",
      "Epoch 247, Loss: 0.3773571872885484\n",
      "Epoch 248, Loss: 0.3787820553512578\n",
      "Epoch 249, Loss: 0.37791387638266233\n",
      "Epoch 250, Loss: 0.37365786462958017\n",
      "Epoch 251, Loss: 0.37738253787012654\n",
      "Epoch 252, Loss: 0.3741101993497061\n",
      "Epoch 253, Loss: 0.3738794273642337\n",
      "Epoch 254, Loss: 0.3745874877836504\n",
      "Epoch 255, Loss: 0.37554181217140137\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.25458572152252323\n",
      "Test R^2 score: 0.2993634065259982\n",
      "Num of epochs: 256\n",
      "Epoch 1, Loss: 0.5722458871816125\n",
      "Epoch 2, Loss: 0.5704375090830504\n",
      "Epoch 3, Loss: 0.5687375465538763\n",
      "Epoch 4, Loss: 0.5671480517159795\n",
      "Epoch 5, Loss: 0.5656705880103174\n",
      "Epoch 6, Loss: 0.5643011238268799\n",
      "Epoch 7, Loss: 0.563031634128048\n",
      "Epoch 8, Loss: 0.5618654751845507\n",
      "Epoch 9, Loss: 0.560823166440018\n",
      "Epoch 10, Loss: 0.5599224586957484\n",
      "Epoch 11, Loss: 0.5591164657449742\n",
      "Epoch 12, Loss: 0.5584101875512616\n",
      "Epoch 13, Loss: 0.5577983394930454\n",
      "Epoch 14, Loss: 0.5572825160716207\n",
      "Epoch 15, Loss: 0.5568669177067161\n",
      "Epoch 16, Loss: 0.5565447808453895\n",
      "Epoch 17, Loss: 0.5563213034802077\n",
      "Epoch 18, Loss: 0.5561907372355276\n",
      "Epoch 19, Loss: 0.5561427516629192\n",
      "Epoch 20, Loss: 0.5561622839785381\n",
      "Epoch 21, Loss: 0.5562312980251064\n",
      "Epoch 22, Loss: 0.5563263390695485\n",
      "Epoch 23, Loss: 0.556425032776676\n",
      "Epoch 24, Loss: 0.5564992892542685\n",
      "Epoch 25, Loss: 0.5565378194538282\n",
      "Epoch 26, Loss: 0.556535784569079\n",
      "Epoch 27, Loss: 0.5564913900999742\n",
      "Epoch 28, Loss: 0.5564066880526234\n",
      "Epoch 29, Loss: 0.5562868834707944\n",
      "Epoch 30, Loss: 0.556156309145488\n",
      "Epoch 31, Loss: 0.5560000297285662\n",
      "Epoch 32, Loss: 0.5558183988693317\n",
      "Epoch 33, Loss: 0.5556209393278879\n",
      "Epoch 34, Loss: 0.5554108268915378\n",
      "Epoch 35, Loss: 0.5551849069239542\n",
      "Epoch 36, Loss: 0.5549336813919801\n",
      "Epoch 37, Loss: 0.5546444889639734\n",
      "Epoch 38, Loss: 0.5542983987261721\n",
      "Epoch 39, Loss: 0.553878274488229\n",
      "Epoch 40, Loss: 0.5533496949877251\n",
      "Epoch 41, Loss: 0.5526871947516625\n",
      "Epoch 42, Loss: 0.5518596453922946\n",
      "Epoch 43, Loss: 0.5508451762876431\n",
      "Epoch 44, Loss: 0.5495809096262917\n",
      "Epoch 45, Loss: 0.5480008661339869\n",
      "Epoch 46, Loss: 0.5460376323195304\n",
      "Epoch 47, Loss: 0.5435958369720213\n",
      "Epoch 48, Loss: 0.5405521542197197\n",
      "Epoch 49, Loss: 0.5368452775341578\n",
      "Epoch 50, Loss: 0.5325621500594976\n",
      "Epoch 51, Loss: 0.528017955292307\n",
      "Epoch 52, Loss: 0.5239993538797924\n",
      "Epoch 53, Loss: 0.5217354844966254\n",
      "Epoch 54, Loss: 0.5211939771080261\n",
      "Epoch 55, Loss: 0.5192389849273638\n",
      "Epoch 56, Loss: 0.515163388398048\n",
      "Epoch 57, Loss: 0.5111227277228042\n",
      "Epoch 58, Loss: 0.5086878348196043\n",
      "Epoch 59, Loss: 0.5074224000712226\n",
      "Epoch 60, Loss: 0.506053990224095\n",
      "Epoch 61, Loss: 0.503808507385069\n",
      "Epoch 62, Loss: 0.5007743501708601\n",
      "Epoch 63, Loss: 0.4977708986887115\n",
      "Epoch 64, Loss: 0.4957552829053124\n",
      "Epoch 65, Loss: 0.4945350249087634\n",
      "Epoch 66, Loss: 0.4928025535300594\n",
      "Epoch 67, Loss: 0.4900560396612967\n",
      "Epoch 68, Loss: 0.48739288388157653\n",
      "Epoch 69, Loss: 0.4855408481705686\n",
      "Epoch 70, Loss: 0.4839649618348716\n",
      "Epoch 71, Loss: 0.4819502745488565\n",
      "Epoch 72, Loss: 0.4794180165900703\n",
      "Epoch 73, Loss: 0.47711117224560146\n",
      "Epoch 74, Loss: 0.4754777977289728\n",
      "Epoch 75, Loss: 0.4736809145697037\n",
      "Epoch 76, Loss: 0.4712846100490555\n",
      "Epoch 77, Loss: 0.46895534468107614\n",
      "Epoch 78, Loss: 0.46708432528685095\n",
      "Epoch 79, Loss: 0.46537714896575577\n",
      "Epoch 80, Loss: 0.4636961450949633\n",
      "Epoch 81, Loss: 0.46249611053893347\n",
      "Epoch 82, Loss: 0.4620169107729576\n",
      "Epoch 83, Loss: 0.4616716970876598\n",
      "Epoch 84, Loss: 0.460894130024203\n",
      "Epoch 85, Loss: 0.4599083872457275\n",
      "Epoch 86, Loss: 0.4590246304654047\n",
      "Epoch 87, Loss: 0.4582156622716999\n",
      "Epoch 88, Loss: 0.4573895606689038\n",
      "Epoch 89, Loss: 0.45655058992114006\n",
      "Epoch 90, Loss: 0.4559100981721268\n",
      "Epoch 91, Loss: 0.4553680151488256\n",
      "Epoch 92, Loss: 0.4546708507045845\n",
      "Epoch 93, Loss: 0.4539885513620353\n",
      "Epoch 94, Loss: 0.4532642315020574\n",
      "Epoch 95, Loss: 0.4525761568937701\n",
      "Epoch 96, Loss: 0.4518056769109788\n",
      "Epoch 97, Loss: 0.4509318980968095\n",
      "Epoch 98, Loss: 0.450107888692863\n",
      "Epoch 99, Loss: 0.4492994816425389\n",
      "Epoch 100, Loss: 0.4485435387052151\n",
      "Epoch 101, Loss: 0.4477531740937648\n",
      "Epoch 102, Loss: 0.4469823148224355\n",
      "Epoch 103, Loss: 0.446242649327706\n",
      "Epoch 104, Loss: 0.44552513533732996\n",
      "Epoch 105, Loss: 0.444720728337113\n",
      "Epoch 106, Loss: 0.4439085697219537\n",
      "Epoch 107, Loss: 0.44308416084229973\n",
      "Epoch 108, Loss: 0.44224820815500215\n",
      "Epoch 109, Loss: 0.44138297298126056\n",
      "Epoch 110, Loss: 0.4405351330713932\n",
      "Epoch 111, Loss: 0.43969428333073846\n",
      "Epoch 112, Loss: 0.43887762745695746\n",
      "Epoch 113, Loss: 0.4380696709070849\n",
      "Epoch 114, Loss: 0.4372759483744988\n",
      "Epoch 115, Loss: 0.43646408804086667\n",
      "Epoch 116, Loss: 0.4356492439704341\n",
      "Epoch 117, Loss: 0.4348387671242375\n",
      "Epoch 118, Loss: 0.4340216097923278\n",
      "Epoch 119, Loss: 0.43319386437082924\n",
      "Epoch 120, Loss: 0.43234704325544937\n",
      "Epoch 121, Loss: 0.4315463865118481\n",
      "Epoch 122, Loss: 0.4308451403759155\n",
      "Epoch 123, Loss: 0.43020202002461183\n",
      "Epoch 124, Loss: 0.42949261147069195\n",
      "Epoch 125, Loss: 0.4287087129782833\n",
      "Epoch 126, Loss: 0.42798361636493537\n",
      "Epoch 127, Loss: 0.4273436342340344\n",
      "Epoch 128, Loss: 0.4267513702395162\n",
      "Epoch 129, Loss: 0.42607891981603385\n",
      "Epoch 130, Loss: 0.42537186566368673\n",
      "Epoch 131, Loss: 0.42469249427671407\n",
      "Epoch 132, Loss: 0.42407272242212374\n",
      "Epoch 133, Loss: 0.4234695323919692\n",
      "Epoch 134, Loss: 0.4228630504853667\n",
      "Epoch 135, Loss: 0.42218033020007883\n",
      "Epoch 136, Loss: 0.4214263225523126\n",
      "Epoch 137, Loss: 0.42068523840040584\n",
      "Epoch 138, Loss: 0.4199712679889891\n",
      "Epoch 139, Loss: 0.4192729104821857\n",
      "Epoch 140, Loss: 0.41858643497285186\n",
      "Epoch 141, Loss: 0.4179856840607064\n",
      "Epoch 142, Loss: 0.4177870667505125\n",
      "Epoch 143, Loss: 0.4184768654252388\n",
      "Epoch 144, Loss: 0.4172912168698768\n",
      "Epoch 145, Loss: 0.41548606586847464\n",
      "Epoch 146, Loss: 0.41572349213114446\n",
      "Epoch 147, Loss: 0.41519786713700985\n",
      "Epoch 148, Loss: 0.41389519532339586\n",
      "Epoch 149, Loss: 0.4139079399261595\n",
      "Epoch 150, Loss: 0.4131659211626107\n",
      "Epoch 151, Loss: 0.4123847005558253\n",
      "Epoch 152, Loss: 0.4122969214188216\n",
      "Epoch 153, Loss: 0.411462683191927\n",
      "Epoch 154, Loss: 0.41096010907423264\n",
      "Epoch 155, Loss: 0.41071174788135223\n",
      "Epoch 156, Loss: 0.40996158158177654\n",
      "Epoch 157, Loss: 0.409514078874037\n",
      "Epoch 158, Loss: 0.40931804930600224\n",
      "Epoch 159, Loss: 0.40862243507889556\n",
      "Epoch 160, Loss: 0.4080497051844206\n",
      "Epoch 161, Loss: 0.40781849896925915\n",
      "Epoch 162, Loss: 0.4074127540042881\n",
      "Epoch 163, Loss: 0.4067937623064792\n",
      "Epoch 164, Loss: 0.4061637566795769\n",
      "Epoch 165, Loss: 0.4059125342264779\n",
      "Epoch 166, Loss: 0.40573617645920296\n",
      "Epoch 167, Loss: 0.4052573878775613\n",
      "Epoch 168, Loss: 0.40453501151860427\n",
      "Epoch 169, Loss: 0.40397164721072315\n",
      "Epoch 170, Loss: 0.40372009414601456\n",
      "Epoch 171, Loss: 0.4036802297723882\n",
      "Epoch 172, Loss: 0.40328103675526267\n",
      "Epoch 173, Loss: 0.40281314689992687\n",
      "Epoch 174, Loss: 0.4020548959502506\n",
      "Epoch 175, Loss: 0.40146012170047196\n",
      "Epoch 176, Loss: 0.40103519938154775\n",
      "Epoch 177, Loss: 0.4009074155680681\n",
      "Epoch 178, Loss: 0.4011457440298505\n",
      "Epoch 179, Loss: 0.4016789249011165\n",
      "Epoch 180, Loss: 0.4016746587010963\n",
      "Epoch 181, Loss: 0.3995563281695593\n",
      "Epoch 182, Loss: 0.3988999693421309\n",
      "Epoch 183, Loss: 0.3996060383378652\n",
      "Epoch 184, Loss: 0.3990038231628263\n",
      "Epoch 185, Loss: 0.39787759897004615\n",
      "Epoch 186, Loss: 0.39754886263897077\n",
      "Epoch 187, Loss: 0.39790413255906326\n",
      "Epoch 188, Loss: 0.39756818444479447\n",
      "Epoch 189, Loss: 0.3965389608757363\n",
      "Epoch 190, Loss: 0.39614295352902484\n",
      "Epoch 191, Loss: 0.39630733727986384\n",
      "Epoch 192, Loss: 0.3960745812467136\n",
      "Epoch 193, Loss: 0.3954291748236491\n",
      "Epoch 194, Loss: 0.39476484049876326\n",
      "Epoch 195, Loss: 0.39446248503331177\n",
      "Epoch 196, Loss: 0.39451614199878743\n",
      "Epoch 197, Loss: 0.39459233708097347\n",
      "Epoch 198, Loss: 0.3943512761012794\n",
      "Epoch 199, Loss: 0.39393218987414563\n",
      "Epoch 200, Loss: 0.39320225234060846\n",
      "Epoch 201, Loss: 0.39242968433590714\n",
      "Epoch 202, Loss: 0.3920274164613715\n",
      "Epoch 203, Loss: 0.3919190715422926\n",
      "Epoch 204, Loss: 0.39213609244526987\n",
      "Epoch 205, Loss: 0.39293379353236985\n",
      "Epoch 206, Loss: 0.39272838772364\n",
      "Epoch 207, Loss: 0.3918977791950799\n",
      "Epoch 208, Loss: 0.39011836575725234\n",
      "Epoch 209, Loss: 0.3901083772412545\n",
      "Epoch 210, Loss: 0.39106542554056434\n",
      "Epoch 211, Loss: 0.39072947058805263\n",
      "Epoch 212, Loss: 0.3891056266689603\n",
      "Epoch 213, Loss: 0.38827891588948643\n",
      "Epoch 214, Loss: 0.3885951325837171\n",
      "Epoch 215, Loss: 0.38985552339989277\n",
      "Epoch 216, Loss: 0.3884128301555549\n",
      "Epoch 217, Loss: 0.38732388862879336\n",
      "Epoch 218, Loss: 0.3864396562030279\n",
      "Epoch 219, Loss: 0.38631770984893316\n",
      "Epoch 220, Loss: 0.38654523867999346\n",
      "Epoch 221, Loss: 0.38664890390667705\n",
      "Epoch 222, Loss: 0.3868919331568654\n",
      "Epoch 223, Loss: 0.3854969838799962\n",
      "Epoch 224, Loss: 0.3843572938143871\n",
      "Epoch 225, Loss: 0.38375869902651294\n",
      "Epoch 226, Loss: 0.383973793046963\n",
      "Epoch 227, Loss: 0.38482549366180513\n",
      "Epoch 228, Loss: 0.3851919958461005\n",
      "Epoch 229, Loss: 0.38597169639655604\n",
      "Epoch 230, Loss: 0.38313466742859503\n",
      "Epoch 231, Loss: 0.38155372122148573\n",
      "Epoch 232, Loss: 0.3830071168666594\n",
      "Epoch 233, Loss: 0.383418440527745\n",
      "Epoch 234, Loss: 0.3825999857300807\n",
      "Epoch 235, Loss: 0.37964919097163086\n",
      "Epoch 236, Loss: 0.3809124836206237\n",
      "Epoch 237, Loss: 0.3828971146471606\n",
      "Epoch 238, Loss: 0.38053618191892796\n",
      "Epoch 239, Loss: 0.3781802704510475\n",
      "Epoch 240, Loss: 0.38204649756335984\n",
      "Epoch 241, Loss: 0.38074689328960676\n",
      "Epoch 242, Loss: 0.37976168390523307\n",
      "Epoch 243, Loss: 0.37665397751724844\n",
      "Epoch 244, Loss: 0.3812178660749239\n",
      "Epoch 245, Loss: 0.38030662528949233\n",
      "Epoch 246, Loss: 0.3769442700546737\n",
      "Epoch 247, Loss: 0.37724735458285774\n",
      "Epoch 248, Loss: 0.3787645684641345\n",
      "Epoch 249, Loss: 0.3744760667922848\n",
      "Epoch 250, Loss: 0.37587362093937315\n",
      "Epoch 251, Loss: 0.37641243378091355\n",
      "Epoch 252, Loss: 0.372706592606214\n",
      "Epoch 253, Loss: 0.37463217816048455\n",
      "Epoch 254, Loss: 0.3763044042636703\n",
      "Epoch 255, Loss: 0.3736209546454372\n",
      "Epoch 256, Loss: 0.3715296544218747\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.23351333574151564\n",
      "Test R^2 score: 0.40936966543075703\n",
      "Num of epochs: 257\n",
      "Epoch 1, Loss: 0.5970345548504846\n",
      "Epoch 2, Loss: 0.5944559768967307\n",
      "Epoch 3, Loss: 0.5920689275395302\n",
      "Epoch 4, Loss: 0.5897942073807272\n",
      "Epoch 5, Loss: 0.5876035781620268\n",
      "Epoch 6, Loss: 0.5855070949323287\n",
      "Epoch 7, Loss: 0.5834952254667964\n",
      "Epoch 8, Loss: 0.5815706414621892\n",
      "Epoch 9, Loss: 0.5797272722527672\n",
      "Epoch 10, Loss: 0.5779655339712825\n",
      "Epoch 11, Loss: 0.5762852702652443\n",
      "Epoch 12, Loss: 0.5746854066629126\n",
      "Epoch 13, Loss: 0.5731635746511503\n",
      "Epoch 14, Loss: 0.5717182861893392\n",
      "Epoch 15, Loss: 0.570347797921405\n",
      "Epoch 16, Loss: 0.569050319736097\n",
      "Epoch 17, Loss: 0.5678238853190712\n",
      "Epoch 18, Loss: 0.566666904851452\n",
      "Epoch 19, Loss: 0.5655780920315383\n",
      "Epoch 20, Loss: 0.5645559408667716\n",
      "Epoch 21, Loss: 0.5635997564822226\n",
      "Epoch 22, Loss: 0.5627118612369737\n",
      "Epoch 23, Loss: 0.5619007203152655\n",
      "Epoch 24, Loss: 0.5611604529058396\n",
      "Epoch 25, Loss: 0.5604769832622106\n",
      "Epoch 26, Loss: 0.5598476182152943\n",
      "Epoch 27, Loss: 0.5592711016528269\n",
      "Epoch 28, Loss: 0.5587452769666577\n",
      "Epoch 29, Loss: 0.5582686058169207\n",
      "Epoch 30, Loss: 0.5578486401473565\n",
      "Epoch 31, Loss: 0.5574820332989177\n",
      "Epoch 32, Loss: 0.5571567752430632\n",
      "Epoch 33, Loss: 0.5568676401972762\n",
      "Epoch 34, Loss: 0.5566018074287294\n",
      "Epoch 35, Loss: 0.5563537661602115\n",
      "Epoch 36, Loss: 0.556131230222307\n",
      "Epoch 37, Loss: 0.5559182549373258\n",
      "Epoch 38, Loss: 0.5557113385997927\n",
      "Epoch 39, Loss: 0.5554942590621144\n",
      "Epoch 40, Loss: 0.5552362763015487\n",
      "Epoch 41, Loss: 0.5549040358290248\n",
      "Epoch 42, Loss: 0.5544670902819244\n",
      "Epoch 43, Loss: 0.5539032132989584\n",
      "Epoch 44, Loss: 0.5531855113664249\n",
      "Epoch 45, Loss: 0.5522715109887735\n",
      "Epoch 46, Loss: 0.5511373626696354\n",
      "Epoch 47, Loss: 0.5497314783821311\n",
      "Epoch 48, Loss: 0.5480578573027892\n",
      "Epoch 49, Loss: 0.546024178369586\n",
      "Epoch 50, Loss: 0.5436257976877864\n",
      "Epoch 51, Loss: 0.5409036513591258\n",
      "Epoch 52, Loss: 0.5379126074017523\n",
      "Epoch 53, Loss: 0.5348176093571274\n",
      "Epoch 54, Loss: 0.5319811333845973\n",
      "Epoch 55, Loss: 0.529902741352354\n",
      "Epoch 56, Loss: 0.5286085713851669\n",
      "Epoch 57, Loss: 0.5268389793834831\n",
      "Epoch 58, Loss: 0.5238958316430363\n",
      "Epoch 59, Loss: 0.520510560792463\n",
      "Epoch 60, Loss: 0.5175383066659447\n",
      "Epoch 61, Loss: 0.5153070972591999\n",
      "Epoch 62, Loss: 0.5134972685320599\n",
      "Epoch 63, Loss: 0.5116656326797094\n",
      "Epoch 64, Loss: 0.5096429845384162\n",
      "Epoch 65, Loss: 0.5075470157042137\n",
      "Epoch 66, Loss: 0.5056143797052621\n",
      "Epoch 67, Loss: 0.5039599781816418\n",
      "Epoch 68, Loss: 0.5024051931248742\n",
      "Epoch 69, Loss: 0.5005901549329449\n",
      "Epoch 70, Loss: 0.498530194503498\n",
      "Epoch 71, Loss: 0.4965507775057947\n",
      "Epoch 72, Loss: 0.49485416686859257\n",
      "Epoch 73, Loss: 0.4933591249152703\n",
      "Epoch 74, Loss: 0.49185790273381264\n",
      "Epoch 75, Loss: 0.49031373251765537\n",
      "Epoch 76, Loss: 0.48884395981586426\n",
      "Epoch 77, Loss: 0.4875090940556461\n",
      "Epoch 78, Loss: 0.48611059264503564\n",
      "Epoch 79, Loss: 0.4845312850838962\n",
      "Epoch 80, Loss: 0.4829505000990488\n",
      "Epoch 81, Loss: 0.4815273253747393\n",
      "Epoch 82, Loss: 0.4801642685930394\n",
      "Epoch 83, Loss: 0.4787912159053022\n",
      "Epoch 84, Loss: 0.47749553084154417\n",
      "Epoch 85, Loss: 0.47627055496753445\n",
      "Epoch 86, Loss: 0.47496777412619995\n",
      "Epoch 87, Loss: 0.4735685639211544\n",
      "Epoch 88, Loss: 0.47220872547303133\n",
      "Epoch 89, Loss: 0.47092195228270484\n",
      "Epoch 90, Loss: 0.46961800952690996\n",
      "Epoch 91, Loss: 0.46836018248067673\n",
      "Epoch 92, Loss: 0.4672198115373689\n",
      "Epoch 93, Loss: 0.4660748919701263\n",
      "Epoch 94, Loss: 0.4648821358098435\n",
      "Epoch 95, Loss: 0.4637124536332198\n",
      "Epoch 96, Loss: 0.46241940685399163\n",
      "Epoch 97, Loss: 0.4611265150558719\n",
      "Epoch 98, Loss: 0.4599702028284895\n",
      "Epoch 99, Loss: 0.45879845607555164\n",
      "Epoch 100, Loss: 0.4576799077007632\n",
      "Epoch 101, Loss: 0.45657160868034563\n",
      "Epoch 102, Loss: 0.4553826913291413\n",
      "Epoch 103, Loss: 0.4542270117954135\n",
      "Epoch 104, Loss: 0.4531138846250829\n",
      "Epoch 105, Loss: 0.4520950450640035\n",
      "Epoch 106, Loss: 0.4511096465557317\n",
      "Epoch 107, Loss: 0.45015160271875043\n",
      "Epoch 108, Loss: 0.4492143547838227\n",
      "Epoch 109, Loss: 0.44825980623478906\n",
      "Epoch 110, Loss: 0.44730310407969087\n",
      "Epoch 111, Loss: 0.44639803100753295\n",
      "Epoch 112, Loss: 0.44549379506483466\n",
      "Epoch 113, Loss: 0.44458223999101126\n",
      "Epoch 114, Loss: 0.4436772589097415\n",
      "Epoch 115, Loss: 0.44279583645885967\n",
      "Epoch 116, Loss: 0.4419512464683331\n",
      "Epoch 117, Loss: 0.441116997798374\n",
      "Epoch 118, Loss: 0.44028274216278235\n",
      "Epoch 119, Loss: 0.4394517856153634\n",
      "Epoch 120, Loss: 0.4385944539313516\n",
      "Epoch 121, Loss: 0.43776835998493385\n",
      "Epoch 122, Loss: 0.43695966527781976\n",
      "Epoch 123, Loss: 0.4361372739475698\n",
      "Epoch 124, Loss: 0.4353167006925946\n",
      "Epoch 125, Loss: 0.4344425142086924\n",
      "Epoch 126, Loss: 0.43359940327576013\n",
      "Epoch 127, Loss: 0.43274690220460665\n",
      "Epoch 128, Loss: 0.4319141608672208\n",
      "Epoch 129, Loss: 0.43111688245573077\n",
      "Epoch 130, Loss: 0.4306962396966387\n",
      "Epoch 131, Loss: 0.430012579972308\n",
      "Epoch 132, Loss: 0.4283955310991819\n",
      "Epoch 133, Loss: 0.42827944232234916\n",
      "Epoch 134, Loss: 0.427075771714547\n",
      "Epoch 135, Loss: 0.4263838432298575\n",
      "Epoch 136, Loss: 0.4257708556980073\n",
      "Epoch 137, Loss: 0.4246762837998299\n",
      "Epoch 138, Loss: 0.4243637778437458\n",
      "Epoch 139, Loss: 0.4232859153673513\n",
      "Epoch 140, Loss: 0.42290274506316405\n",
      "Epoch 141, Loss: 0.42207610670470075\n",
      "Epoch 142, Loss: 0.42138335932766113\n",
      "Epoch 143, Loss: 0.42085212753680873\n",
      "Epoch 144, Loss: 0.41996830528310103\n",
      "Epoch 145, Loss: 0.4195551313142166\n",
      "Epoch 146, Loss: 0.4188170514584546\n",
      "Epoch 147, Loss: 0.4181085691374051\n",
      "Epoch 148, Loss: 0.41763029923398093\n",
      "Epoch 149, Loss: 0.41680981044842497\n",
      "Epoch 150, Loss: 0.41624132937774244\n",
      "Epoch 151, Loss: 0.4156913388880408\n",
      "Epoch 152, Loss: 0.4149212838400162\n",
      "Epoch 153, Loss: 0.4143935805250187\n",
      "Epoch 154, Loss: 0.4138528905094012\n",
      "Epoch 155, Loss: 0.41316274735965547\n",
      "Epoch 156, Loss: 0.41261730260178386\n",
      "Epoch 157, Loss: 0.4121597042356934\n",
      "Epoch 158, Loss: 0.41155158165284933\n",
      "Epoch 159, Loss: 0.41094919485414066\n",
      "Epoch 160, Loss: 0.4104435414101559\n",
      "Epoch 161, Loss: 0.4099417170816441\n",
      "Epoch 162, Loss: 0.40935681863261275\n",
      "Epoch 163, Loss: 0.4087665447771424\n",
      "Epoch 164, Loss: 0.4082179819716145\n",
      "Epoch 165, Loss: 0.40770797266852415\n",
      "Epoch 166, Loss: 0.40722703819338596\n",
      "Epoch 167, Loss: 0.40674269583368283\n",
      "Epoch 168, Loss: 0.4063664782876453\n",
      "Epoch 169, Loss: 0.406079623368166\n",
      "Epoch 170, Loss: 0.40583236942268175\n",
      "Epoch 171, Loss: 0.40525176208626024\n",
      "Epoch 172, Loss: 0.4043636727552233\n",
      "Epoch 173, Loss: 0.4037139301899652\n",
      "Epoch 174, Loss: 0.40361599555534655\n",
      "Epoch 175, Loss: 0.4034463902446109\n",
      "Epoch 176, Loss: 0.40268080213519153\n",
      "Epoch 177, Loss: 0.4019791515884469\n",
      "Epoch 178, Loss: 0.4016906659915718\n",
      "Epoch 179, Loss: 0.40162986086490016\n",
      "Epoch 180, Loss: 0.4010463648269053\n",
      "Epoch 181, Loss: 0.40038781513995947\n",
      "Epoch 182, Loss: 0.3998727566273643\n",
      "Epoch 183, Loss: 0.39961897762988174\n",
      "Epoch 184, Loss: 0.39952058001351065\n",
      "Epoch 185, Loss: 0.39935102641545805\n",
      "Epoch 186, Loss: 0.3988224862323097\n",
      "Epoch 187, Loss: 0.3979746991758649\n",
      "Epoch 188, Loss: 0.39735459913292487\n",
      "Epoch 189, Loss: 0.39715412491888635\n",
      "Epoch 190, Loss: 0.39710142480012944\n",
      "Epoch 191, Loss: 0.39683862654642954\n",
      "Epoch 192, Loss: 0.3961472228784271\n",
      "Epoch 193, Loss: 0.3954160419006289\n",
      "Epoch 194, Loss: 0.3949573029305715\n",
      "Epoch 195, Loss: 0.3947855630199828\n",
      "Epoch 196, Loss: 0.39469504025249563\n",
      "Epoch 197, Loss: 0.3943685063766075\n",
      "Epoch 198, Loss: 0.393784335319663\n",
      "Epoch 199, Loss: 0.39312413899338017\n",
      "Epoch 200, Loss: 0.39263226719336464\n",
      "Epoch 201, Loss: 0.3924336713278187\n",
      "Epoch 202, Loss: 0.39235705703658913\n",
      "Epoch 203, Loss: 0.3922837325495971\n",
      "Epoch 204, Loss: 0.3919639337732366\n",
      "Epoch 205, Loss: 0.3913388405503874\n",
      "Epoch 206, Loss: 0.3904851472364703\n",
      "Epoch 207, Loss: 0.3898421262657583\n",
      "Epoch 208, Loss: 0.3894925486852096\n",
      "Epoch 209, Loss: 0.3893792888778662\n",
      "Epoch 210, Loss: 0.389583649184699\n",
      "Epoch 211, Loss: 0.38992773768168365\n",
      "Epoch 212, Loss: 0.3897970580613871\n",
      "Epoch 213, Loss: 0.388457809617013\n",
      "Epoch 214, Loss: 0.3870547020236147\n",
      "Epoch 215, Loss: 0.3867623275710588\n",
      "Epoch 216, Loss: 0.3874184222643493\n",
      "Epoch 217, Loss: 0.387351183617998\n",
      "Epoch 218, Loss: 0.3863141997540179\n",
      "Epoch 219, Loss: 0.38495118367357134\n",
      "Epoch 220, Loss: 0.3846170942332712\n",
      "Epoch 221, Loss: 0.38509788303065784\n",
      "Epoch 222, Loss: 0.385756151936464\n",
      "Epoch 223, Loss: 0.38568601561442883\n",
      "Epoch 224, Loss: 0.3840511097161801\n",
      "Epoch 225, Loss: 0.3824789968969823\n",
      "Epoch 226, Loss: 0.3820458345028116\n",
      "Epoch 227, Loss: 0.3825536163936441\n",
      "Epoch 228, Loss: 0.3833603733656893\n",
      "Epoch 229, Loss: 0.38209909020065735\n",
      "Epoch 230, Loss: 0.3806529341470988\n",
      "Epoch 231, Loss: 0.3796259936211991\n",
      "Epoch 232, Loss: 0.37953232628020717\n",
      "Epoch 233, Loss: 0.38033648077556503\n",
      "Epoch 234, Loss: 0.3818060041241266\n",
      "Epoch 235, Loss: 0.38175961641466843\n",
      "Epoch 236, Loss: 0.3791956435473903\n",
      "Epoch 237, Loss: 0.37709566494850727\n",
      "Epoch 238, Loss: 0.3773210735891928\n",
      "Epoch 239, Loss: 0.3789088258950679\n",
      "Epoch 240, Loss: 0.3796186337595074\n",
      "Epoch 241, Loss: 0.37741602014048403\n",
      "Epoch 242, Loss: 0.37526105694933487\n",
      "Epoch 243, Loss: 0.3749453186857979\n",
      "Epoch 244, Loss: 0.37587564278164837\n",
      "Epoch 245, Loss: 0.3763429120187569\n",
      "Epoch 246, Loss: 0.3756710049389434\n",
      "Epoch 247, Loss: 0.3740063456721184\n",
      "Epoch 248, Loss: 0.3727881448085565\n",
      "Epoch 249, Loss: 0.3725717924687341\n",
      "Epoch 250, Loss: 0.3732546282760438\n",
      "Epoch 251, Loss: 0.3740352897658545\n",
      "Epoch 252, Loss: 0.3744832491840065\n",
      "Epoch 253, Loss: 0.3734461859167762\n",
      "Epoch 254, Loss: 0.3716941193240899\n",
      "Epoch 255, Loss: 0.37020261075661914\n",
      "Epoch 256, Loss: 0.36996919999931804\n",
      "Epoch 257, Loss: 0.37072983013471356\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.25020400618767086\n",
      "Test R^2 score: 0.3242632213176178\n",
      "Num of epochs: 258\n",
      "Epoch 1, Loss: 0.5580184214501107\n",
      "Epoch 2, Loss: 0.5575850656212917\n",
      "Epoch 3, Loss: 0.5572104766267445\n",
      "Epoch 4, Loss: 0.5568943716890559\n",
      "Epoch 5, Loss: 0.556635699334018\n",
      "Epoch 6, Loss: 0.5564344057598888\n",
      "Epoch 7, Loss: 0.5562913568531224\n",
      "Epoch 8, Loss: 0.5562016412523533\n",
      "Epoch 9, Loss: 0.5561626858708338\n",
      "Epoch 10, Loss: 0.5561513256033536\n",
      "Epoch 11, Loss: 0.5561754658943873\n",
      "Epoch 12, Loss: 0.5562103750281092\n",
      "Epoch 13, Loss: 0.5562430584935176\n",
      "Epoch 14, Loss: 0.5562663108063038\n",
      "Epoch 15, Loss: 0.556272498758052\n",
      "Epoch 16, Loss: 0.5562581940379593\n",
      "Epoch 17, Loss: 0.5562236093840043\n",
      "Epoch 18, Loss: 0.5561717685592728\n",
      "Epoch 19, Loss: 0.5561062305547286\n",
      "Epoch 20, Loss: 0.5560292416677104\n",
      "Epoch 21, Loss: 0.5559417620662219\n",
      "Epoch 22, Loss: 0.5558435455234387\n",
      "Epoch 23, Loss: 0.555734398652474\n",
      "Epoch 24, Loss: 0.5556118744543149\n",
      "Epoch 25, Loss: 0.5554753470800339\n",
      "Epoch 26, Loss: 0.5553209958690448\n",
      "Epoch 27, Loss: 0.555141478110343\n",
      "Epoch 28, Loss: 0.5549294118840665\n",
      "Epoch 29, Loss: 0.5546736648338556\n",
      "Epoch 30, Loss: 0.5543661664325646\n",
      "Epoch 31, Loss: 0.5539969053991075\n",
      "Epoch 32, Loss: 0.553538838978605\n",
      "Epoch 33, Loss: 0.5529586822119271\n",
      "Epoch 34, Loss: 0.5522300117505302\n",
      "Epoch 35, Loss: 0.5513226979299249\n",
      "Epoch 36, Loss: 0.550184616618654\n",
      "Epoch 37, Loss: 0.5487613026404281\n",
      "Epoch 38, Loss: 0.5470212740779827\n",
      "Epoch 39, Loss: 0.5449214374718225\n",
      "Epoch 40, Loss: 0.5424311054888805\n",
      "Epoch 41, Loss: 0.5394668997208206\n",
      "Epoch 42, Loss: 0.5359289341011257\n",
      "Epoch 43, Loss: 0.5318301623279873\n",
      "Epoch 44, Loss: 0.5273567480675305\n",
      "Epoch 45, Loss: 0.5228805995625825\n",
      "Epoch 46, Loss: 0.518475283992849\n",
      "Epoch 47, Loss: 0.514233416403505\n",
      "Epoch 48, Loss: 0.5103040752661553\n",
      "Epoch 49, Loss: 0.5065292282991404\n",
      "Epoch 50, Loss: 0.5028600255626949\n",
      "Epoch 51, Loss: 0.49902879745680506\n",
      "Epoch 52, Loss: 0.49444163807716657\n",
      "Epoch 53, Loss: 0.4892024239198158\n",
      "Epoch 54, Loss: 0.4842992846470082\n",
      "Epoch 55, Loss: 0.4805201991377716\n",
      "Epoch 56, Loss: 0.4780638917505486\n",
      "Epoch 57, Loss: 0.4768400790926165\n",
      "Epoch 58, Loss: 0.47644846755726195\n",
      "Epoch 59, Loss: 0.4765841682385858\n",
      "Epoch 60, Loss: 0.47624982676164973\n",
      "Epoch 61, Loss: 0.4747931513136109\n",
      "Epoch 62, Loss: 0.47299172972249687\n",
      "Epoch 63, Loss: 0.4714685129248619\n",
      "Epoch 64, Loss: 0.4703726181945187\n",
      "Epoch 65, Loss: 0.4694046535344165\n",
      "Epoch 66, Loss: 0.4681633775409244\n",
      "Epoch 67, Loss: 0.46715423440035886\n",
      "Epoch 68, Loss: 0.46654168339950414\n",
      "Epoch 69, Loss: 0.46617827666630574\n",
      "Epoch 70, Loss: 0.4658197366962833\n",
      "Epoch 71, Loss: 0.465255154546792\n",
      "Epoch 72, Loss: 0.464608445436822\n",
      "Epoch 73, Loss: 0.46404763978227\n",
      "Epoch 74, Loss: 0.46355540187359867\n",
      "Epoch 75, Loss: 0.46290454763085154\n",
      "Epoch 76, Loss: 0.4620203778945727\n",
      "Epoch 77, Loss: 0.4610849888071667\n",
      "Epoch 78, Loss: 0.46020554762596244\n",
      "Epoch 79, Loss: 0.45963196217334734\n",
      "Epoch 80, Loss: 0.4591172370970986\n",
      "Epoch 81, Loss: 0.458502089976141\n",
      "Epoch 82, Loss: 0.4579135822242013\n",
      "Epoch 83, Loss: 0.45744717248665495\n",
      "Epoch 84, Loss: 0.45694177517921325\n",
      "Epoch 85, Loss: 0.4564216819852361\n",
      "Epoch 86, Loss: 0.455893265380493\n",
      "Epoch 87, Loss: 0.45544000080124053\n",
      "Epoch 88, Loss: 0.45503272292608266\n",
      "Epoch 89, Loss: 0.4545821733165641\n",
      "Epoch 90, Loss: 0.4540796746342087\n",
      "Epoch 91, Loss: 0.4535972994811036\n",
      "Epoch 92, Loss: 0.45312450671991267\n",
      "Epoch 93, Loss: 0.45257482342114186\n",
      "Epoch 94, Loss: 0.4519833290076653\n",
      "Epoch 95, Loss: 0.4514372734482255\n",
      "Epoch 96, Loss: 0.45092340538536896\n",
      "Epoch 97, Loss: 0.4503801839235287\n",
      "Epoch 98, Loss: 0.4498633859475532\n",
      "Epoch 99, Loss: 0.4493479833055292\n",
      "Epoch 100, Loss: 0.44877551229419105\n",
      "Epoch 101, Loss: 0.44822400290974945\n",
      "Epoch 102, Loss: 0.4476850284027292\n",
      "Epoch 103, Loss: 0.44713938901451616\n",
      "Epoch 104, Loss: 0.4466277325384048\n",
      "Epoch 105, Loss: 0.44611624078122575\n",
      "Epoch 106, Loss: 0.4456059843984576\n",
      "Epoch 107, Loss: 0.44513471300239726\n",
      "Epoch 108, Loss: 0.44465203412533433\n",
      "Epoch 109, Loss: 0.44416188614415597\n",
      "Epoch 110, Loss: 0.4436584505823423\n",
      "Epoch 111, Loss: 0.44314776844989445\n",
      "Epoch 112, Loss: 0.44262809774310774\n",
      "Epoch 113, Loss: 0.44209972696651817\n",
      "Epoch 114, Loss: 0.44156022888593033\n",
      "Epoch 115, Loss: 0.4410296496179336\n",
      "Epoch 116, Loss: 0.44052447802440897\n",
      "Epoch 117, Loss: 0.44001532303073115\n",
      "Epoch 118, Loss: 0.43952154686527484\n",
      "Epoch 119, Loss: 0.4390490899804123\n",
      "Epoch 120, Loss: 0.4385959997822702\n",
      "Epoch 121, Loss: 0.4381473214235741\n",
      "Epoch 122, Loss: 0.4377127368595951\n",
      "Epoch 123, Loss: 0.43726403821391807\n",
      "Epoch 124, Loss: 0.4368045422354088\n",
      "Epoch 125, Loss: 0.4363325584958198\n",
      "Epoch 126, Loss: 0.4358346270796694\n",
      "Epoch 127, Loss: 0.4353022037830211\n",
      "Epoch 128, Loss: 0.43475523025411306\n",
      "Epoch 129, Loss: 0.43420924928202065\n",
      "Epoch 130, Loss: 0.4336855335864456\n",
      "Epoch 131, Loss: 0.433176836844897\n",
      "Epoch 132, Loss: 0.43268818843136037\n",
      "Epoch 133, Loss: 0.4322125542495658\n",
      "Epoch 134, Loss: 0.43173014890496486\n",
      "Epoch 135, Loss: 0.43124050046989926\n",
      "Epoch 136, Loss: 0.43075067596360367\n",
      "Epoch 137, Loss: 0.4302709952556547\n",
      "Epoch 138, Loss: 0.42978296086488044\n",
      "Epoch 139, Loss: 0.4292769811878559\n",
      "Epoch 140, Loss: 0.42874701484997807\n",
      "Epoch 141, Loss: 0.42822564884127506\n",
      "Epoch 142, Loss: 0.42771786174513315\n",
      "Epoch 143, Loss: 0.42721991758540684\n",
      "Epoch 144, Loss: 0.4267235050334575\n",
      "Epoch 145, Loss: 0.42613922609466004\n",
      "Epoch 146, Loss: 0.4255119837195159\n",
      "Epoch 147, Loss: 0.42483976372787935\n",
      "Epoch 148, Loss: 0.4243007433143738\n",
      "Epoch 149, Loss: 0.4239483675929685\n",
      "Epoch 150, Loss: 0.42358361499781266\n",
      "Epoch 151, Loss: 0.4232353776736875\n",
      "Epoch 152, Loss: 0.42252663336557145\n",
      "Epoch 153, Loss: 0.42181738707310973\n",
      "Epoch 154, Loss: 0.421400279935274\n",
      "Epoch 155, Loss: 0.42100461607438855\n",
      "Epoch 156, Loss: 0.42037768797932445\n",
      "Epoch 157, Loss: 0.4196854036439304\n",
      "Epoch 158, Loss: 0.4192496663628503\n",
      "Epoch 159, Loss: 0.4188568092888333\n",
      "Epoch 160, Loss: 0.4184088484489458\n",
      "Epoch 161, Loss: 0.417876545370601\n",
      "Epoch 162, Loss: 0.4172132384114975\n",
      "Epoch 163, Loss: 0.416587311420014\n",
      "Epoch 164, Loss: 0.4160555072705075\n",
      "Epoch 165, Loss: 0.4155983780100455\n",
      "Epoch 166, Loss: 0.4152318529140355\n",
      "Epoch 167, Loss: 0.41506421181271635\n",
      "Epoch 168, Loss: 0.41507850010813835\n",
      "Epoch 169, Loss: 0.4141124299372852\n",
      "Epoch 170, Loss: 0.41315237823119455\n",
      "Epoch 171, Loss: 0.4128142741913828\n",
      "Epoch 172, Loss: 0.4127088949818122\n",
      "Epoch 173, Loss: 0.4122616816381435\n",
      "Epoch 174, Loss: 0.41123912098301696\n",
      "Epoch 175, Loss: 0.4107537413535258\n",
      "Epoch 176, Loss: 0.41072740296925125\n",
      "Epoch 177, Loss: 0.4101962297118906\n",
      "Epoch 178, Loss: 0.40942966955177146\n",
      "Epoch 179, Loss: 0.4088420886383789\n",
      "Epoch 180, Loss: 0.4086493831710146\n",
      "Epoch 181, Loss: 0.40867618363810443\n",
      "Epoch 182, Loss: 0.4082106630642305\n",
      "Epoch 183, Loss: 0.40732287907660186\n",
      "Epoch 184, Loss: 0.4065907773000175\n",
      "Epoch 185, Loss: 0.4064763428970228\n",
      "Epoch 186, Loss: 0.40631836536013316\n",
      "Epoch 187, Loss: 0.40552472516490273\n",
      "Epoch 188, Loss: 0.40478118047843953\n",
      "Epoch 189, Loss: 0.4045598745698453\n",
      "Epoch 190, Loss: 0.40442955677907927\n",
      "Epoch 191, Loss: 0.4039199657066729\n",
      "Epoch 192, Loss: 0.4029760299859254\n",
      "Epoch 193, Loss: 0.40247216999204183\n",
      "Epoch 194, Loss: 0.40234758319695374\n",
      "Epoch 195, Loss: 0.40212669814026647\n",
      "Epoch 196, Loss: 0.4016012173107494\n",
      "Epoch 197, Loss: 0.40093300532187615\n",
      "Epoch 198, Loss: 0.40023171597665463\n",
      "Epoch 199, Loss: 0.39978060889776\n",
      "Epoch 200, Loss: 0.3994575234343892\n",
      "Epoch 201, Loss: 0.3991913862611098\n",
      "Epoch 202, Loss: 0.3991135490344674\n",
      "Epoch 203, Loss: 0.39911293299587375\n",
      "Epoch 204, Loss: 0.39889223665097656\n",
      "Epoch 205, Loss: 0.3985561680319944\n",
      "Epoch 206, Loss: 0.3974469531549189\n",
      "Epoch 207, Loss: 0.396596545057402\n",
      "Epoch 208, Loss: 0.3965805012350057\n",
      "Epoch 209, Loss: 0.39660712160174333\n",
      "Epoch 210, Loss: 0.396237244656437\n",
      "Epoch 211, Loss: 0.3953366509700944\n",
      "Epoch 212, Loss: 0.39485712095928055\n",
      "Epoch 213, Loss: 0.39452413042650814\n",
      "Epoch 214, Loss: 0.3945930168221779\n",
      "Epoch 215, Loss: 0.3945671480673372\n",
      "Epoch 216, Loss: 0.39415246890885797\n",
      "Epoch 217, Loss: 0.39369681846901844\n",
      "Epoch 218, Loss: 0.3928459544415459\n",
      "Epoch 219, Loss: 0.39220410649981624\n",
      "Epoch 220, Loss: 0.3918456650968634\n",
      "Epoch 221, Loss: 0.3915611303294857\n",
      "Epoch 222, Loss: 0.3913556132807262\n",
      "Epoch 223, Loss: 0.391119815233684\n",
      "Epoch 224, Loss: 0.390885152018248\n",
      "Epoch 225, Loss: 0.3906745879169824\n",
      "Epoch 226, Loss: 0.3902720382584402\n",
      "Epoch 227, Loss: 0.3895071629231643\n",
      "Epoch 228, Loss: 0.38868926119616226\n",
      "Epoch 229, Loss: 0.38797816953005343\n",
      "Epoch 230, Loss: 0.38744811433620496\n",
      "Epoch 231, Loss: 0.386902486135965\n",
      "Epoch 232, Loss: 0.3867998519779818\n",
      "Epoch 233, Loss: 0.38693851430270454\n",
      "Epoch 234, Loss: 0.38891019176234287\n",
      "Epoch 235, Loss: 0.39297833137131544\n",
      "Epoch 236, Loss: 0.38749418638852046\n",
      "Epoch 237, Loss: 0.38451648527256327\n",
      "Epoch 238, Loss: 0.38729235946418206\n",
      "Epoch 239, Loss: 0.3858564183549974\n",
      "Epoch 240, Loss: 0.3830190023745562\n",
      "Epoch 241, Loss: 0.38559722107879163\n",
      "Epoch 242, Loss: 0.38372258588556024\n",
      "Epoch 243, Loss: 0.381638829706317\n",
      "Epoch 244, Loss: 0.3825508118520251\n",
      "Epoch 245, Loss: 0.3825722933374035\n",
      "Epoch 246, Loss: 0.38060352828624994\n",
      "Epoch 247, Loss: 0.3795297742479639\n",
      "Epoch 248, Loss: 0.38049120591962854\n",
      "Epoch 249, Loss: 0.3790420603450092\n",
      "Epoch 250, Loss: 0.3785414168287568\n",
      "Epoch 251, Loss: 0.37699411594291715\n",
      "Epoch 252, Loss: 0.37756237149500826\n",
      "Epoch 253, Loss: 0.37654002189818725\n",
      "Epoch 254, Loss: 0.3763038696809847\n",
      "Epoch 255, Loss: 0.37497564077733947\n",
      "Epoch 256, Loss: 0.3743918374976759\n",
      "Epoch 257, Loss: 0.3739389269299629\n",
      "Epoch 258, Loss: 0.37317996621820765\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.24643673556851328\n",
      "Test R^2 score: 0.33821888670876804\n",
      "Num of epochs: 259\n",
      "Epoch 1, Loss: 0.5598907618329921\n",
      "Epoch 2, Loss: 0.5588684473645437\n",
      "Epoch 3, Loss: 0.5580137482815772\n",
      "Epoch 4, Loss: 0.5573275159434484\n",
      "Epoch 5, Loss: 0.5568097844667251\n",
      "Epoch 6, Loss: 0.556455320333219\n",
      "Epoch 7, Loss: 0.5562512826368996\n",
      "Epoch 8, Loss: 0.5561712595039624\n",
      "Epoch 9, Loss: 0.5561871471684686\n",
      "Epoch 10, Loss: 0.5562588905309775\n",
      "Epoch 11, Loss: 0.5563404545477747\n",
      "Epoch 12, Loss: 0.5564011711268025\n",
      "Epoch 13, Loss: 0.5564249524361373\n",
      "Epoch 14, Loss: 0.5564197838371107\n",
      "Epoch 15, Loss: 0.5563812454634152\n",
      "Epoch 16, Loss: 0.5563110982364882\n",
      "Epoch 17, Loss: 0.5562160010073527\n",
      "Epoch 18, Loss: 0.5561029078990802\n",
      "Epoch 19, Loss: 0.5559772487108955\n",
      "Epoch 20, Loss: 0.5558447250826909\n",
      "Epoch 21, Loss: 0.5557066192152413\n",
      "Epoch 22, Loss: 0.5555589841365981\n",
      "Epoch 23, Loss: 0.5553999341784731\n",
      "Epoch 24, Loss: 0.5552255948683377\n",
      "Epoch 25, Loss: 0.5550238972751338\n",
      "Epoch 26, Loss: 0.5547671193751547\n",
      "Epoch 27, Loss: 0.5543865677014823\n",
      "Epoch 28, Loss: 0.5538941203135707\n",
      "Epoch 29, Loss: 0.5533002780420655\n",
      "Epoch 30, Loss: 0.5525965434515445\n",
      "Epoch 31, Loss: 0.5517763387894982\n",
      "Epoch 32, Loss: 0.5508994388253399\n",
      "Epoch 33, Loss: 0.5498818162173469\n",
      "Epoch 34, Loss: 0.5486704100847684\n",
      "Epoch 35, Loss: 0.547258542305683\n",
      "Epoch 36, Loss: 0.5456619979007737\n",
      "Epoch 37, Loss: 0.543827338583232\n",
      "Epoch 38, Loss: 0.5417293701803291\n",
      "Epoch 39, Loss: 0.5393367290953798\n",
      "Epoch 40, Loss: 0.5366226487835749\n",
      "Epoch 41, Loss: 0.5334490533794414\n",
      "Epoch 42, Loss: 0.529749124593763\n",
      "Epoch 43, Loss: 0.5254512028709334\n",
      "Epoch 44, Loss: 0.5205020009587767\n",
      "Epoch 45, Loss: 0.5149363340449569\n",
      "Epoch 46, Loss: 0.5088449985559349\n",
      "Epoch 47, Loss: 0.5022678205139811\n",
      "Epoch 48, Loss: 0.49530550894632047\n",
      "Epoch 49, Loss: 0.4882800598130026\n",
      "Epoch 50, Loss: 0.48175699540618516\n",
      "Epoch 51, Loss: 0.4767063111489436\n",
      "Epoch 52, Loss: 0.47424099601338404\n",
      "Epoch 53, Loss: 0.47419232227271246\n",
      "Epoch 54, Loss: 0.47503492327350816\n",
      "Epoch 55, Loss: 0.4761503031650272\n",
      "Epoch 56, Loss: 0.4755605577280562\n",
      "Epoch 57, Loss: 0.4728241456760225\n",
      "Epoch 58, Loss: 0.47024306294821955\n",
      "Epoch 59, Loss: 0.4687429904413649\n",
      "Epoch 60, Loss: 0.4678060882577457\n",
      "Epoch 61, Loss: 0.46697384978969153\n",
      "Epoch 62, Loss: 0.4663667173261035\n",
      "Epoch 63, Loss: 0.46534783415564457\n",
      "Epoch 64, Loss: 0.46392560089137375\n",
      "Epoch 65, Loss: 0.4626980312488142\n",
      "Epoch 66, Loss: 0.46144774046623793\n",
      "Epoch 67, Loss: 0.46009547701745146\n",
      "Epoch 68, Loss: 0.45905285588177913\n",
      "Epoch 69, Loss: 0.45820556470866997\n",
      "Epoch 70, Loss: 0.457307487538525\n",
      "Epoch 71, Loss: 0.4566681878848855\n",
      "Epoch 72, Loss: 0.4558814983997805\n",
      "Epoch 73, Loss: 0.45500955351556716\n",
      "Epoch 74, Loss: 0.4542260768366373\n",
      "Epoch 75, Loss: 0.4533229921484445\n",
      "Epoch 76, Loss: 0.45258532646951716\n",
      "Epoch 77, Loss: 0.4518224476162311\n",
      "Epoch 78, Loss: 0.4509827684030813\n",
      "Epoch 79, Loss: 0.4502175712461458\n",
      "Epoch 80, Loss: 0.44939601551941327\n",
      "Epoch 81, Loss: 0.4486600469843193\n",
      "Epoch 82, Loss: 0.4477871515376464\n",
      "Epoch 83, Loss: 0.4469626120734168\n",
      "Epoch 84, Loss: 0.44605960414631163\n",
      "Epoch 85, Loss: 0.44531405599221885\n",
      "Epoch 86, Loss: 0.44452735215340267\n",
      "Epoch 87, Loss: 0.44375449903652076\n",
      "Epoch 88, Loss: 0.4429407033501679\n",
      "Epoch 89, Loss: 0.4421139335768059\n",
      "Epoch 90, Loss: 0.44136094392505804\n",
      "Epoch 91, Loss: 0.4405249346745655\n",
      "Epoch 92, Loss: 0.43956414409836037\n",
      "Epoch 93, Loss: 0.4386487592957231\n",
      "Epoch 94, Loss: 0.4377531783643766\n",
      "Epoch 95, Loss: 0.4368142305111444\n",
      "Epoch 96, Loss: 0.43596823799300655\n",
      "Epoch 97, Loss: 0.4351268333751494\n",
      "Epoch 98, Loss: 0.4345903542001171\n",
      "Epoch 99, Loss: 0.434137707670088\n",
      "Epoch 100, Loss: 0.43345761954457096\n",
      "Epoch 101, Loss: 0.4314382087119243\n",
      "Epoch 102, Loss: 0.43153300605111095\n",
      "Epoch 103, Loss: 0.43126111154477337\n",
      "Epoch 104, Loss: 0.42933635235116413\n",
      "Epoch 105, Loss: 0.43027980901889795\n",
      "Epoch 106, Loss: 0.4286992586322102\n",
      "Epoch 107, Loss: 0.427879448243761\n",
      "Epoch 108, Loss: 0.4277579418640125\n",
      "Epoch 109, Loss: 0.4259641936761429\n",
      "Epoch 110, Loss: 0.4262346076423516\n",
      "Epoch 111, Loss: 0.4246865119108561\n",
      "Epoch 112, Loss: 0.424695634546472\n",
      "Epoch 113, Loss: 0.42383522695752646\n",
      "Epoch 114, Loss: 0.42299004945369134\n",
      "Epoch 115, Loss: 0.42288355893486734\n",
      "Epoch 116, Loss: 0.421583339750103\n",
      "Epoch 117, Loss: 0.4214329699686235\n",
      "Epoch 118, Loss: 0.42073424072807486\n",
      "Epoch 119, Loss: 0.41987724954218836\n",
      "Epoch 120, Loss: 0.4197263750490362\n",
      "Epoch 121, Loss: 0.41882413165254573\n",
      "Epoch 122, Loss: 0.41831538719777883\n",
      "Epoch 123, Loss: 0.41808098328984084\n",
      "Epoch 124, Loss: 0.41727304045989744\n",
      "Epoch 125, Loss: 0.41673714121229816\n",
      "Epoch 126, Loss: 0.416541005100128\n",
      "Epoch 127, Loss: 0.4159288091919506\n",
      "Epoch 128, Loss: 0.4152510875593501\n",
      "Epoch 129, Loss: 0.4147397566513983\n",
      "Epoch 130, Loss: 0.41445993746840193\n",
      "Epoch 131, Loss: 0.41425596072202586\n",
      "Epoch 132, Loss: 0.4137645585186936\n",
      "Epoch 133, Loss: 0.4130851799707704\n",
      "Epoch 134, Loss: 0.4124315999859576\n",
      "Epoch 135, Loss: 0.4119414760390191\n",
      "Epoch 136, Loss: 0.41165705803160774\n",
      "Epoch 137, Loss: 0.41149493147253513\n",
      "Epoch 138, Loss: 0.4116653110923276\n",
      "Epoch 139, Loss: 0.411736685924987\n",
      "Epoch 140, Loss: 0.4119831090642843\n",
      "Epoch 141, Loss: 0.409951967501999\n",
      "Epoch 142, Loss: 0.4090928597837237\n",
      "Epoch 143, Loss: 0.4097106147547932\n",
      "Epoch 144, Loss: 0.40983054535013025\n",
      "Epoch 145, Loss: 0.40873646914983464\n",
      "Epoch 146, Loss: 0.40750862434247687\n",
      "Epoch 147, Loss: 0.40818297414003885\n",
      "Epoch 148, Loss: 0.4089789250838701\n",
      "Epoch 149, Loss: 0.40705910219460945\n",
      "Epoch 150, Loss: 0.4065619701349792\n",
      "Epoch 151, Loss: 0.408394599798005\n",
      "Epoch 152, Loss: 0.4063972793052495\n",
      "Epoch 153, Loss: 0.4054811427991665\n",
      "Epoch 154, Loss: 0.40558865709117714\n",
      "Epoch 155, Loss: 0.4056078530729799\n",
      "Epoch 156, Loss: 0.40437224049636306\n",
      "Epoch 157, Loss: 0.40400642982526475\n",
      "Epoch 158, Loss: 0.40393009226099413\n",
      "Epoch 159, Loss: 0.40394787306454044\n",
      "Epoch 160, Loss: 0.4029961269112089\n",
      "Epoch 161, Loss: 0.40253345868736906\n",
      "Epoch 162, Loss: 0.40234145376790903\n",
      "Epoch 163, Loss: 0.4023623415901408\n",
      "Epoch 164, Loss: 0.40214874578818927\n",
      "Epoch 165, Loss: 0.40162184681205193\n",
      "Epoch 166, Loss: 0.4008993684887402\n",
      "Epoch 167, Loss: 0.40050557045033247\n",
      "Epoch 168, Loss: 0.4002577398339307\n",
      "Epoch 169, Loss: 0.40029310574032484\n",
      "Epoch 170, Loss: 0.40015095306191467\n",
      "Epoch 171, Loss: 0.4002015760759129\n",
      "Epoch 172, Loss: 0.39987598001587177\n",
      "Epoch 173, Loss: 0.3998359559862138\n",
      "Epoch 174, Loss: 0.398861323066856\n",
      "Epoch 175, Loss: 0.3982035380079355\n",
      "Epoch 176, Loss: 0.39762709984799016\n",
      "Epoch 177, Loss: 0.39738639863673264\n",
      "Epoch 178, Loss: 0.397185096343276\n",
      "Epoch 179, Loss: 0.397216140380767\n",
      "Epoch 180, Loss: 0.39754567660601753\n",
      "Epoch 181, Loss: 0.39792439201937885\n",
      "Epoch 182, Loss: 0.39867003517989696\n",
      "Epoch 183, Loss: 0.39767174906026265\n",
      "Epoch 184, Loss: 0.3967691911239603\n",
      "Epoch 185, Loss: 0.3952358676680885\n",
      "Epoch 186, Loss: 0.39501598531029763\n",
      "Epoch 187, Loss: 0.3956803498864102\n",
      "Epoch 188, Loss: 0.39594418036072326\n",
      "Epoch 189, Loss: 0.3952453307431551\n",
      "Epoch 190, Loss: 0.394022301719241\n",
      "Epoch 191, Loss: 0.3935095900829596\n",
      "Epoch 192, Loss: 0.39380037954253067\n",
      "Epoch 193, Loss: 0.3941534329498719\n",
      "Epoch 194, Loss: 0.3942549842998357\n",
      "Epoch 195, Loss: 0.3934896334890674\n",
      "Epoch 196, Loss: 0.39253832487222456\n",
      "Epoch 197, Loss: 0.3919857737382849\n",
      "Epoch 198, Loss: 0.39189787425277206\n",
      "Epoch 199, Loss: 0.39215053216941137\n",
      "Epoch 200, Loss: 0.3923171775080798\n",
      "Epoch 201, Loss: 0.3926701983377758\n",
      "Epoch 202, Loss: 0.3924963377216803\n",
      "Epoch 203, Loss: 0.39205601832515513\n",
      "Epoch 204, Loss: 0.3909285510324965\n",
      "Epoch 205, Loss: 0.39015325671152673\n",
      "Epoch 206, Loss: 0.3898405208721474\n",
      "Epoch 207, Loss: 0.3899212410458681\n",
      "Epoch 208, Loss: 0.39027362278634264\n",
      "Epoch 209, Loss: 0.3906598266335303\n",
      "Epoch 210, Loss: 0.3908498688997593\n",
      "Epoch 211, Loss: 0.39034967256163133\n",
      "Epoch 212, Loss: 0.3897469379336573\n",
      "Epoch 213, Loss: 0.3888254868485145\n",
      "Epoch 214, Loss: 0.38817917923246537\n",
      "Epoch 215, Loss: 0.3880014628070608\n",
      "Epoch 216, Loss: 0.388223782744186\n",
      "Epoch 217, Loss: 0.3884997154305986\n",
      "Epoch 218, Loss: 0.38878152728647697\n",
      "Epoch 219, Loss: 0.3892449031819551\n",
      "Epoch 220, Loss: 0.388912126673755\n",
      "Epoch 221, Loss: 0.38835008038003915\n",
      "Epoch 222, Loss: 0.3871625800191448\n",
      "Epoch 223, Loss: 0.3863640516834781\n",
      "Epoch 224, Loss: 0.38620932577836115\n",
      "Epoch 225, Loss: 0.3865085762794694\n",
      "Epoch 226, Loss: 0.3871328852930975\n",
      "Epoch 227, Loss: 0.3874662669173253\n",
      "Epoch 228, Loss: 0.38772440688267246\n",
      "Epoch 229, Loss: 0.3870055358685455\n",
      "Epoch 230, Loss: 0.38592418771247955\n",
      "Epoch 231, Loss: 0.38496159631371796\n",
      "Epoch 232, Loss: 0.3847578406151598\n",
      "Epoch 233, Loss: 0.3850586448319179\n",
      "Epoch 234, Loss: 0.3855162526253391\n",
      "Epoch 235, Loss: 0.38600404760234847\n",
      "Epoch 236, Loss: 0.3857151649764045\n",
      "Epoch 237, Loss: 0.3852095391045049\n",
      "Epoch 238, Loss: 0.38422565039806084\n",
      "Epoch 239, Loss: 0.38348854471328775\n",
      "Epoch 240, Loss: 0.3832416853329385\n",
      "Epoch 241, Loss: 0.383398405629884\n",
      "Epoch 242, Loss: 0.38398665760250505\n",
      "Epoch 243, Loss: 0.3844746103932293\n",
      "Epoch 244, Loss: 0.3853817958350133\n",
      "Epoch 245, Loss: 0.38529500028993463\n",
      "Epoch 246, Loss: 0.3842175060250528\n",
      "Epoch 247, Loss: 0.38243062571409925\n",
      "Epoch 248, Loss: 0.38183521553615213\n",
      "Epoch 249, Loss: 0.382234818686631\n",
      "Epoch 250, Loss: 0.3828705918746093\n",
      "Epoch 251, Loss: 0.38322834861248467\n",
      "Epoch 252, Loss: 0.38224511040628373\n",
      "Epoch 253, Loss: 0.38136211372742784\n",
      "Epoch 254, Loss: 0.3806171331547911\n",
      "Epoch 255, Loss: 0.38061742677968635\n",
      "Epoch 256, Loss: 0.381048634772864\n",
      "Epoch 257, Loss: 0.38151847344789\n",
      "Epoch 258, Loss: 0.3821866505349077\n",
      "Epoch 259, Loss: 0.3815999777631433\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.24188122284655295\n",
      "Test R^2 score: 0.37111559525882415\n",
      "Num of epochs: 260\n",
      "Epoch 1, Loss: 0.5645553337933765\n",
      "Epoch 2, Loss: 0.5637051335262595\n",
      "Epoch 3, Loss: 0.5628985211826484\n",
      "Epoch 4, Loss: 0.5621368242444864\n",
      "Epoch 5, Loss: 0.5614209156153988\n",
      "Epoch 6, Loss: 0.5607532559919791\n",
      "Epoch 7, Loss: 0.5601338582903754\n",
      "Epoch 8, Loss: 0.5595610719353868\n",
      "Epoch 9, Loss: 0.55903514682133\n",
      "Epoch 10, Loss: 0.5585558951829211\n",
      "Epoch 11, Loss: 0.5581229566769506\n",
      "Epoch 12, Loss: 0.5577360651129825\n",
      "Epoch 13, Loss: 0.5573945411016515\n",
      "Epoch 14, Loss: 0.5570976656446986\n",
      "Epoch 15, Loss: 0.5568445200343989\n",
      "Epoch 16, Loss: 0.5566351103927768\n",
      "Epoch 17, Loss: 0.5564660852745162\n",
      "Epoch 18, Loss: 0.5563348566115964\n",
      "Epoch 19, Loss: 0.5562349681751965\n",
      "Epoch 20, Loss: 0.5561676961037438\n",
      "Epoch 21, Loss: 0.5561278541270486\n",
      "Epoch 22, Loss: 0.5561089101012747\n",
      "Epoch 23, Loss: 0.5560545127769225\n",
      "Epoch 24, Loss: 0.5560452405839246\n",
      "Epoch 25, Loss: 0.5560318143888157\n",
      "Epoch 26, Loss: 0.556007078254364\n",
      "Epoch 27, Loss: 0.555963579652228\n",
      "Epoch 28, Loss: 0.5558968376569288\n",
      "Epoch 29, Loss: 0.5558003558461443\n",
      "Epoch 30, Loss: 0.5556794283440156\n",
      "Epoch 31, Loss: 0.5555384918082497\n",
      "Epoch 32, Loss: 0.5553756796853944\n",
      "Epoch 33, Loss: 0.5551855510835066\n",
      "Epoch 34, Loss: 0.5549578209477565\n",
      "Epoch 35, Loss: 0.5546844912165316\n",
      "Epoch 36, Loss: 0.5543634515826028\n",
      "Epoch 37, Loss: 0.5539877063595645\n",
      "Epoch 38, Loss: 0.5535467533466021\n",
      "Epoch 39, Loss: 0.5530365027198536\n",
      "Epoch 40, Loss: 0.5524592439368889\n",
      "Epoch 41, Loss: 0.5518198704211656\n",
      "Epoch 42, Loss: 0.5510987523249092\n",
      "Epoch 43, Loss: 0.5502546782825497\n",
      "Epoch 44, Loss: 0.5492576194672232\n",
      "Epoch 45, Loss: 0.5480576941685885\n",
      "Epoch 46, Loss: 0.5465992641134854\n",
      "Epoch 47, Loss: 0.5448576092851274\n",
      "Epoch 48, Loss: 0.542882898802434\n",
      "Epoch 49, Loss: 0.540529383764923\n",
      "Epoch 50, Loss: 0.5378165843039391\n",
      "Epoch 51, Loss: 0.5348387284395575\n",
      "Epoch 52, Loss: 0.5316928532358824\n",
      "Epoch 53, Loss: 0.528400154215323\n",
      "Epoch 54, Loss: 0.524674931433016\n",
      "Epoch 55, Loss: 0.5202529884648497\n",
      "Epoch 56, Loss: 0.5150592185203949\n",
      "Epoch 57, Loss: 0.509232252983112\n",
      "Epoch 58, Loss: 0.5032861723921153\n",
      "Epoch 59, Loss: 0.49832848459880935\n",
      "Epoch 60, Loss: 0.4954651431912088\n",
      "Epoch 61, Loss: 0.492988071576868\n",
      "Epoch 62, Loss: 0.48912742537226905\n",
      "Epoch 63, Loss: 0.4851384299379504\n",
      "Epoch 64, Loss: 0.4823088880420748\n",
      "Epoch 65, Loss: 0.4804608724304988\n",
      "Epoch 66, Loss: 0.47878569163651274\n",
      "Epoch 67, Loss: 0.4766382563678616\n",
      "Epoch 68, Loss: 0.47412725379784304\n",
      "Epoch 69, Loss: 0.47168937025537205\n",
      "Epoch 70, Loss: 0.4695631603498828\n",
      "Epoch 71, Loss: 0.4676926768117217\n",
      "Epoch 72, Loss: 0.46590766647484827\n",
      "Epoch 73, Loss: 0.46439901282142315\n",
      "Epoch 74, Loss: 0.463299840004134\n",
      "Epoch 75, Loss: 0.462281208223738\n",
      "Epoch 76, Loss: 0.46124443244675284\n",
      "Epoch 77, Loss: 0.4602821993776914\n",
      "Epoch 78, Loss: 0.45942900204002884\n",
      "Epoch 79, Loss: 0.4585151221538574\n",
      "Epoch 80, Loss: 0.4576157150212302\n",
      "Epoch 81, Loss: 0.4569382532171199\n",
      "Epoch 82, Loss: 0.4563890983234471\n",
      "Epoch 83, Loss: 0.4557999056456126\n",
      "Epoch 84, Loss: 0.4551118502583458\n",
      "Epoch 85, Loss: 0.4543091330346423\n",
      "Epoch 86, Loss: 0.4534502834986723\n",
      "Epoch 87, Loss: 0.4526020518239973\n",
      "Epoch 88, Loss: 0.45181412005770577\n",
      "Epoch 89, Loss: 0.45110196649502876\n",
      "Epoch 90, Loss: 0.4504437867656539\n",
      "Epoch 91, Loss: 0.44980602852227636\n",
      "Epoch 92, Loss: 0.44914107273070863\n",
      "Epoch 93, Loss: 0.4484316689248401\n",
      "Epoch 94, Loss: 0.447726133394178\n",
      "Epoch 95, Loss: 0.4470206676831955\n",
      "Epoch 96, Loss: 0.446294955625795\n",
      "Epoch 97, Loss: 0.44556936585531093\n",
      "Epoch 98, Loss: 0.4448496772523978\n",
      "Epoch 99, Loss: 0.44413699213184493\n",
      "Epoch 100, Loss: 0.44339644491356067\n",
      "Epoch 101, Loss: 0.4426305384630112\n",
      "Epoch 102, Loss: 0.4418261733319761\n",
      "Epoch 103, Loss: 0.4410292948520906\n",
      "Epoch 104, Loss: 0.44020687311847717\n",
      "Epoch 105, Loss: 0.43941336557877486\n",
      "Epoch 106, Loss: 0.43865898432690964\n",
      "Epoch 107, Loss: 0.43795299919513403\n",
      "Epoch 108, Loss: 0.4372581596889084\n",
      "Epoch 109, Loss: 0.4365680338973708\n",
      "Epoch 110, Loss: 0.43587867859539886\n",
      "Epoch 111, Loss: 0.4351592627100866\n",
      "Epoch 112, Loss: 0.43444592699557844\n",
      "Epoch 113, Loss: 0.43374045356007174\n",
      "Epoch 114, Loss: 0.43302899602642153\n",
      "Epoch 115, Loss: 0.4323273973367504\n",
      "Epoch 116, Loss: 0.4316336514699338\n",
      "Epoch 117, Loss: 0.4309599329342674\n",
      "Epoch 118, Loss: 0.43036719230197445\n",
      "Epoch 119, Loss: 0.4298151173514002\n",
      "Epoch 120, Loss: 0.42944228371143356\n",
      "Epoch 121, Loss: 0.42866872175561055\n",
      "Epoch 122, Loss: 0.4277988367845558\n",
      "Epoch 123, Loss: 0.42703494712772894\n",
      "Epoch 124, Loss: 0.42664174961122786\n",
      "Epoch 125, Loss: 0.4261948562705498\n",
      "Epoch 126, Loss: 0.4252023874166469\n",
      "Epoch 127, Loss: 0.42461396243820476\n",
      "Epoch 128, Loss: 0.42426402445773526\n",
      "Epoch 129, Loss: 0.42344438962504516\n",
      "Epoch 130, Loss: 0.4226927425968093\n",
      "Epoch 131, Loss: 0.42228449268517415\n",
      "Epoch 132, Loss: 0.4217583000404287\n",
      "Epoch 133, Loss: 0.42106936495635916\n",
      "Epoch 134, Loss: 0.42038013382067313\n",
      "Epoch 135, Loss: 0.4198674543735607\n",
      "Epoch 136, Loss: 0.4194829909487632\n",
      "Epoch 137, Loss: 0.4190004041323841\n",
      "Epoch 138, Loss: 0.41843992040274575\n",
      "Epoch 139, Loss: 0.41764335800807173\n",
      "Epoch 140, Loss: 0.41700099605217217\n",
      "Epoch 141, Loss: 0.4165230106028523\n",
      "Epoch 142, Loss: 0.4161184121249543\n",
      "Epoch 143, Loss: 0.4157352308504726\n",
      "Epoch 144, Loss: 0.41501060837090253\n",
      "Epoch 145, Loss: 0.4142877577804096\n",
      "Epoch 146, Loss: 0.41354687092514747\n",
      "Epoch 147, Loss: 0.41290833102312247\n",
      "Epoch 148, Loss: 0.4123392051801909\n",
      "Epoch 149, Loss: 0.41184728885215377\n",
      "Epoch 150, Loss: 0.4116481532278884\n",
      "Epoch 151, Loss: 0.4120563454882221\n",
      "Epoch 152, Loss: 0.41347478146320366\n",
      "Epoch 153, Loss: 0.41009270311992435\n",
      "Epoch 154, Loss: 0.40971877973083753\n",
      "Epoch 155, Loss: 0.41076054334778417\n",
      "Epoch 156, Loss: 0.4080081090565394\n",
      "Epoch 157, Loss: 0.40940386473835333\n",
      "Epoch 158, Loss: 0.40860110143171346\n",
      "Epoch 159, Loss: 0.4069431700196489\n",
      "Epoch 160, Loss: 0.40859548520946937\n",
      "Epoch 161, Loss: 0.4058801544715085\n",
      "Epoch 162, Loss: 0.4063454845895748\n",
      "Epoch 163, Loss: 0.4054800770671339\n",
      "Epoch 164, Loss: 0.4041598543923562\n",
      "Epoch 165, Loss: 0.4048402976474472\n",
      "Epoch 166, Loss: 0.40293167269093333\n",
      "Epoch 167, Loss: 0.4038265459528313\n",
      "Epoch 168, Loss: 0.40302668636814687\n",
      "Epoch 169, Loss: 0.4016587249708099\n",
      "Epoch 170, Loss: 0.40282311631944057\n",
      "Epoch 171, Loss: 0.4010619884973385\n",
      "Epoch 172, Loss: 0.40049785015634076\n",
      "Epoch 173, Loss: 0.40113723739069096\n",
      "Epoch 174, Loss: 0.39919752672968717\n",
      "Epoch 175, Loss: 0.39931147220853663\n",
      "Epoch 176, Loss: 0.39916844732263007\n",
      "Epoch 177, Loss: 0.39761032933546264\n",
      "Epoch 178, Loss: 0.3978542471988456\n",
      "Epoch 179, Loss: 0.39750030097710115\n",
      "Epoch 180, Loss: 0.39617082571990136\n",
      "Epoch 181, Loss: 0.39616264481456237\n",
      "Epoch 182, Loss: 0.3961337187876752\n",
      "Epoch 183, Loss: 0.39514086619848743\n",
      "Epoch 184, Loss: 0.39421302878952813\n",
      "Epoch 185, Loss: 0.39431853272495143\n",
      "Epoch 186, Loss: 0.39454180637249314\n",
      "Epoch 187, Loss: 0.3934522168813407\n",
      "Epoch 188, Loss: 0.3923728368164205\n",
      "Epoch 189, Loss: 0.3919756047153486\n",
      "Epoch 190, Loss: 0.3920584888201371\n",
      "Epoch 191, Loss: 0.3923383141630638\n",
      "Epoch 192, Loss: 0.3915156320103835\n",
      "Epoch 193, Loss: 0.3904855288426343\n",
      "Epoch 194, Loss: 0.38959864248023585\n",
      "Epoch 195, Loss: 0.38926838861884794\n",
      "Epoch 196, Loss: 0.3895224652024675\n",
      "Epoch 197, Loss: 0.38961441924090484\n",
      "Epoch 198, Loss: 0.38994382594327753\n",
      "Epoch 199, Loss: 0.38837663181282567\n",
      "Epoch 200, Loss: 0.38707953298583125\n",
      "Epoch 201, Loss: 0.3865316497099965\n",
      "Epoch 202, Loss: 0.3868941477657599\n",
      "Epoch 203, Loss: 0.38759186947732455\n",
      "Epoch 204, Loss: 0.3862666753298886\n",
      "Epoch 205, Loss: 0.3849652735728676\n",
      "Epoch 206, Loss: 0.38433331441851654\n",
      "Epoch 207, Loss: 0.3844947636115049\n",
      "Epoch 208, Loss: 0.38489706437564014\n",
      "Epoch 209, Loss: 0.3845008093710071\n",
      "Epoch 210, Loss: 0.3840006664774495\n",
      "Epoch 211, Loss: 0.3826914615404251\n",
      "Epoch 212, Loss: 0.3817822938198968\n",
      "Epoch 213, Loss: 0.38168234309161897\n",
      "Epoch 214, Loss: 0.382136448610987\n",
      "Epoch 215, Loss: 0.38281160471286013\n",
      "Epoch 216, Loss: 0.3825857892475198\n",
      "Epoch 217, Loss: 0.3830259467641148\n",
      "Epoch 218, Loss: 0.380300552036297\n",
      "Epoch 219, Loss: 0.3790213813085136\n",
      "Epoch 220, Loss: 0.37989114786530304\n",
      "Epoch 221, Loss: 0.38003946717372367\n",
      "Epoch 222, Loss: 0.380148649974635\n",
      "Epoch 223, Loss: 0.37829471672885373\n",
      "Epoch 224, Loss: 0.37699314754870966\n",
      "Epoch 225, Loss: 0.3765739747827722\n",
      "Epoch 226, Loss: 0.37676075983155344\n",
      "Epoch 227, Loss: 0.3784488985280728\n",
      "Epoch 228, Loss: 0.37987592833098954\n",
      "Epoch 229, Loss: 0.38195311170434804\n",
      "Epoch 230, Loss: 0.37631351185199946\n",
      "Epoch 231, Loss: 0.3743219205518322\n",
      "Epoch 232, Loss: 0.376668753611148\n",
      "Epoch 233, Loss: 0.37708367177340385\n",
      "Epoch 234, Loss: 0.37579856721626237\n",
      "Epoch 235, Loss: 0.3728053724274295\n",
      "Epoch 236, Loss: 0.3727822888356896\n",
      "Epoch 237, Loss: 0.3750125565016117\n",
      "Epoch 238, Loss: 0.37474222065216484\n",
      "Epoch 239, Loss: 0.3725516142385118\n",
      "Epoch 240, Loss: 0.37066000636395363\n",
      "Epoch 241, Loss: 0.37119490599995886\n",
      "Epoch 242, Loss: 0.37299648164235216\n",
      "Epoch 243, Loss: 0.37248989286727857\n",
      "Epoch 244, Loss: 0.3711573696814948\n",
      "Epoch 245, Loss: 0.3691635528387206\n",
      "Epoch 246, Loss: 0.36852178219505166\n",
      "Epoch 247, Loss: 0.3689823517752995\n",
      "Epoch 248, Loss: 0.3700931913704535\n",
      "Epoch 249, Loss: 0.3711253905610663\n",
      "Epoch 250, Loss: 0.3708602773150341\n",
      "Epoch 251, Loss: 0.36969434997842165\n",
      "Epoch 252, Loss: 0.3670006337394232\n",
      "Epoch 253, Loss: 0.365839798098268\n",
      "Epoch 254, Loss: 0.3659588772843789\n",
      "Epoch 255, Loss: 0.3670835753745682\n",
      "Epoch 256, Loss: 0.36930913964119605\n",
      "Epoch 257, Loss: 0.3699265243093088\n",
      "Epoch 258, Loss: 0.369142885554421\n",
      "Epoch 259, Loss: 0.36554478393008777\n",
      "Epoch 260, Loss: 0.36338043909690176\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2395315223539053\n",
      "Test R^2 score: 0.38000008264349805\n",
      "Num of epochs: 261\n",
      "Epoch 1, Loss: 0.5722054199212729\n",
      "Epoch 2, Loss: 0.5700995165133805\n",
      "Epoch 3, Loss: 0.5681315748801581\n",
      "Epoch 4, Loss: 0.5663072960015281\n",
      "Epoch 5, Loss: 0.5646310281725214\n",
      "Epoch 6, Loss: 0.563105654495334\n",
      "Epoch 7, Loss: 0.5617342611195342\n",
      "Epoch 8, Loss: 0.5605214342464886\n",
      "Epoch 9, Loss: 0.559463464145719\n",
      "Epoch 10, Loss: 0.5585624045800585\n",
      "Epoch 11, Loss: 0.5578155164877489\n",
      "Epoch 12, Loss: 0.557217857488059\n",
      "Epoch 13, Loss: 0.5567696137469941\n",
      "Epoch 14, Loss: 0.5564513838474611\n",
      "Epoch 15, Loss: 0.556254256157183\n",
      "Epoch 16, Loss: 0.5561631145556293\n",
      "Epoch 17, Loss: 0.5561595778961852\n",
      "Epoch 18, Loss: 0.556228377961386\n",
      "Epoch 19, Loss: 0.5563408563113628\n",
      "Epoch 20, Loss: 0.5564712802214401\n",
      "Epoch 21, Loss: 0.5565965333842982\n",
      "Epoch 22, Loss: 0.556693385785943\n",
      "Epoch 23, Loss: 0.5567493800950764\n",
      "Epoch 24, Loss: 0.556771594250132\n",
      "Epoch 25, Loss: 0.5567578644010777\n",
      "Epoch 26, Loss: 0.5567111589683489\n",
      "Epoch 27, Loss: 0.5566351103927768\n",
      "Epoch 28, Loss: 0.5565355435953924\n",
      "Epoch 29, Loss: 0.5564172932515261\n",
      "Epoch 30, Loss: 0.5562854905539826\n",
      "Epoch 31, Loss: 0.55614355547545\n",
      "Epoch 32, Loss: 0.5559938655453109\n",
      "Epoch 33, Loss: 0.555837915774343\n",
      "Epoch 34, Loss: 0.5556807155158496\n",
      "Epoch 35, Loss: 0.5555199300416614\n",
      "Epoch 36, Loss: 0.5553486872674606\n",
      "Epoch 37, Loss: 0.5551627634848989\n",
      "Epoch 38, Loss: 0.5549536590302943\n",
      "Epoch 39, Loss: 0.5547146589050842\n",
      "Epoch 40, Loss: 0.5544415855631302\n",
      "Epoch 41, Loss: 0.5541359483001731\n",
      "Epoch 42, Loss: 0.5537955137109666\n",
      "Epoch 43, Loss: 0.5533934798307718\n",
      "Epoch 44, Loss: 0.5529132998243487\n",
      "Epoch 45, Loss: 0.552355336414415\n",
      "Epoch 46, Loss: 0.5517193806184694\n",
      "Epoch 47, Loss: 0.5510057032579024\n",
      "Epoch 48, Loss: 0.5502320926981277\n",
      "Epoch 49, Loss: 0.5493755122281097\n",
      "Epoch 50, Loss: 0.5483801156912539\n",
      "Epoch 51, Loss: 0.5472465615284308\n",
      "Epoch 52, Loss: 0.5460344940038533\n",
      "Epoch 53, Loss: 0.544596229518246\n",
      "Epoch 54, Loss: 0.542850481504248\n",
      "Epoch 55, Loss: 0.5407367634874962\n",
      "Epoch 56, Loss: 0.5382052529866487\n",
      "Epoch 57, Loss: 0.5350767758798433\n",
      "Epoch 58, Loss: 0.5313207915767145\n",
      "Epoch 59, Loss: 0.5270844563810223\n",
      "Epoch 60, Loss: 0.5226752011180558\n",
      "Epoch 61, Loss: 0.5181884334281122\n",
      "Epoch 62, Loss: 0.5135327575044912\n",
      "Epoch 63, Loss: 0.5086538534204644\n",
      "Epoch 64, Loss: 0.5036819905264819\n",
      "Epoch 65, Loss: 0.4989537229570517\n",
      "Epoch 66, Loss: 0.49536060617092537\n",
      "Epoch 67, Loss: 0.49314321341680895\n",
      "Epoch 68, Loss: 0.49056589839699577\n",
      "Epoch 69, Loss: 0.4871713306760786\n",
      "Epoch 70, Loss: 0.4833755796018154\n",
      "Epoch 71, Loss: 0.4802745333515958\n",
      "Epoch 72, Loss: 0.47832996114124776\n",
      "Epoch 73, Loss: 0.4759201035103563\n",
      "Epoch 74, Loss: 0.4730291865701296\n",
      "Epoch 75, Loss: 0.4704108696144782\n",
      "Epoch 76, Loss: 0.4684370585739163\n",
      "Epoch 77, Loss: 0.467185445289814\n",
      "Epoch 78, Loss: 0.46613322050907424\n",
      "Epoch 79, Loss: 0.4650848468670906\n",
      "Epoch 80, Loss: 0.4642583542926148\n",
      "Epoch 81, Loss: 0.46340935851226334\n",
      "Epoch 82, Loss: 0.46230214371684436\n",
      "Epoch 83, Loss: 0.46107259484019364\n",
      "Epoch 84, Loss: 0.460187851965398\n",
      "Epoch 85, Loss: 0.45970725091634873\n",
      "Epoch 86, Loss: 0.45927181577184467\n",
      "Epoch 87, Loss: 0.4586287886379124\n",
      "Epoch 88, Loss: 0.45796462060738435\n",
      "Epoch 89, Loss: 0.4573187779476211\n",
      "Epoch 90, Loss: 0.45676045668794213\n",
      "Epoch 91, Loss: 0.4561596898618692\n",
      "Epoch 92, Loss: 0.4552831719927621\n",
      "Epoch 93, Loss: 0.45432940273982264\n",
      "Epoch 94, Loss: 0.4536215593549686\n",
      "Epoch 95, Loss: 0.4531424453271032\n",
      "Epoch 96, Loss: 0.45265240523759986\n",
      "Epoch 97, Loss: 0.4520443988183845\n",
      "Epoch 98, Loss: 0.4514536287473067\n",
      "Epoch 99, Loss: 0.45093706965012875\n",
      "Epoch 100, Loss: 0.4504059569767384\n",
      "Epoch 101, Loss: 0.4497456321758669\n",
      "Epoch 102, Loss: 0.4490625690468116\n",
      "Epoch 103, Loss: 0.4484565072899514\n",
      "Epoch 104, Loss: 0.44793569354372614\n",
      "Epoch 105, Loss: 0.4473537374934472\n",
      "Epoch 106, Loss: 0.4467683217956481\n",
      "Epoch 107, Loss: 0.4462364215815252\n",
      "Epoch 108, Loss: 0.4457261523383835\n",
      "Epoch 109, Loss: 0.44515114922913424\n",
      "Epoch 110, Loss: 0.4445254749533052\n",
      "Epoch 111, Loss: 0.44395980844859756\n",
      "Epoch 112, Loss: 0.44341675979361406\n",
      "Epoch 113, Loss: 0.4428324656269233\n",
      "Epoch 114, Loss: 0.44225444152201776\n",
      "Epoch 115, Loss: 0.44171336132604333\n",
      "Epoch 116, Loss: 0.4411591369832765\n",
      "Epoch 117, Loss: 0.4405650165662948\n",
      "Epoch 118, Loss: 0.43998123649123433\n",
      "Epoch 119, Loss: 0.43940619324046976\n",
      "Epoch 120, Loss: 0.4387877110090542\n",
      "Epoch 121, Loss: 0.43814570597044467\n",
      "Epoch 122, Loss: 0.43750803803825533\n",
      "Epoch 123, Loss: 0.43686846724115896\n",
      "Epoch 124, Loss: 0.43622882980199346\n",
      "Epoch 125, Loss: 0.4355936581243244\n",
      "Epoch 126, Loss: 0.43494135414714896\n",
      "Epoch 127, Loss: 0.4342826319673423\n",
      "Epoch 128, Loss: 0.4336384930593815\n",
      "Epoch 129, Loss: 0.43296787695519634\n",
      "Epoch 130, Loss: 0.4323026835711484\n",
      "Epoch 131, Loss: 0.43166182107795525\n",
      "Epoch 132, Loss: 0.4310108095072579\n",
      "Epoch 133, Loss: 0.4303480965789065\n",
      "Epoch 134, Loss: 0.42969958548455933\n",
      "Epoch 135, Loss: 0.42903804248137234\n",
      "Epoch 136, Loss: 0.4283866785682095\n",
      "Epoch 137, Loss: 0.4277305254479937\n",
      "Epoch 138, Loss: 0.4270653914737947\n",
      "Epoch 139, Loss: 0.42640121191395597\n",
      "Epoch 140, Loss: 0.4257474063406771\n",
      "Epoch 141, Loss: 0.4250945757371549\n",
      "Epoch 142, Loss: 0.4244270838825923\n",
      "Epoch 143, Loss: 0.4237449845717704\n",
      "Epoch 144, Loss: 0.4230535258354182\n",
      "Epoch 145, Loss: 0.4223586594874477\n",
      "Epoch 146, Loss: 0.42167998150898733\n",
      "Epoch 147, Loss: 0.4211827178844362\n",
      "Epoch 148, Loss: 0.420877124220198\n",
      "Epoch 149, Loss: 0.42010377005020716\n",
      "Epoch 150, Loss: 0.418839447944313\n",
      "Epoch 151, Loss: 0.4187533243246643\n",
      "Epoch 152, Loss: 0.4182164892964879\n",
      "Epoch 153, Loss: 0.4169972796877402\n",
      "Epoch 154, Loss: 0.4168393929414874\n",
      "Epoch 155, Loss: 0.4160516033822957\n",
      "Epoch 156, Loss: 0.4150667607657845\n",
      "Epoch 157, Loss: 0.4149592782918987\n",
      "Epoch 158, Loss: 0.4139161841070533\n",
      "Epoch 159, Loss: 0.41348809760882627\n",
      "Epoch 160, Loss: 0.41302837935774384\n",
      "Epoch 161, Loss: 0.41214186192324115\n",
      "Epoch 162, Loss: 0.41178250117827275\n",
      "Epoch 163, Loss: 0.41122623931514346\n",
      "Epoch 164, Loss: 0.4104126083670384\n",
      "Epoch 165, Loss: 0.4101253861213594\n",
      "Epoch 166, Loss: 0.4094834577144256\n",
      "Epoch 167, Loss: 0.40880910256552655\n",
      "Epoch 168, Loss: 0.40839879580043725\n",
      "Epoch 169, Loss: 0.40792945193333496\n",
      "Epoch 170, Loss: 0.40719752585539093\n",
      "Epoch 171, Loss: 0.40664382332341975\n",
      "Epoch 172, Loss: 0.40618492485576596\n",
      "Epoch 173, Loss: 0.40571753746802924\n",
      "Epoch 174, Loss: 0.4050052720774604\n",
      "Epoch 175, Loss: 0.40441682667037676\n",
      "Epoch 176, Loss: 0.4038841057025133\n",
      "Epoch 177, Loss: 0.4033037602535686\n",
      "Epoch 178, Loss: 0.40281242554089053\n",
      "Epoch 179, Loss: 0.4023113052471318\n",
      "Epoch 180, Loss: 0.4017821345851014\n",
      "Epoch 181, Loss: 0.4014577090613687\n",
      "Epoch 182, Loss: 0.4015304715931826\n",
      "Epoch 183, Loss: 0.40227017146519745\n",
      "Epoch 184, Loss: 0.40185754527485973\n",
      "Epoch 185, Loss: 0.39976609066564633\n",
      "Epoch 186, Loss: 0.39938751729413763\n",
      "Epoch 187, Loss: 0.4001430769676937\n",
      "Epoch 188, Loss: 0.3986408986042941\n",
      "Epoch 189, Loss: 0.39807293612862643\n",
      "Epoch 190, Loss: 0.39859551680953514\n",
      "Epoch 191, Loss: 0.3972947244104752\n",
      "Epoch 192, Loss: 0.39685494154455736\n",
      "Epoch 193, Loss: 0.39715999673121666\n",
      "Epoch 194, Loss: 0.39604132190564256\n",
      "Epoch 195, Loss: 0.3956386585198024\n",
      "Epoch 196, Loss: 0.3958333688869795\n",
      "Epoch 197, Loss: 0.39500527185229717\n",
      "Epoch 198, Loss: 0.3943978641248093\n",
      "Epoch 199, Loss: 0.39461376724713954\n",
      "Epoch 200, Loss: 0.39413362237855065\n",
      "Epoch 201, Loss: 0.3933528259398885\n",
      "Epoch 202, Loss: 0.393186392152384\n",
      "Epoch 203, Loss: 0.39311346874094044\n",
      "Epoch 204, Loss: 0.3926081100323857\n",
      "Epoch 205, Loss: 0.3920100642805075\n",
      "Epoch 206, Loss: 0.39173405562978125\n",
      "Epoch 207, Loss: 0.3916472600971811\n",
      "Epoch 208, Loss: 0.3913170977573535\n",
      "Epoch 209, Loss: 0.3907547925849219\n",
      "Epoch 210, Loss: 0.39035555129474014\n",
      "Epoch 211, Loss: 0.3901417604199425\n",
      "Epoch 212, Loss: 0.3899321515107361\n",
      "Epoch 213, Loss: 0.38972929304439025\n",
      "Epoch 214, Loss: 0.3893774519608938\n",
      "Epoch 215, Loss: 0.3890579070161012\n",
      "Epoch 216, Loss: 0.38861386426920363\n",
      "Epoch 217, Loss: 0.3882342035662664\n",
      "Epoch 218, Loss: 0.3878838107306691\n",
      "Epoch 219, Loss: 0.3875500961961603\n",
      "Epoch 220, Loss: 0.38725486354101013\n",
      "Epoch 221, Loss: 0.38701475740482033\n",
      "Epoch 222, Loss: 0.38685202950981495\n",
      "Epoch 223, Loss: 0.3871081924805349\n",
      "Epoch 224, Loss: 0.3886671784850415\n",
      "Epoch 225, Loss: 0.3897570695242036\n",
      "Epoch 226, Loss: 0.3889093679852556\n",
      "Epoch 227, Loss: 0.3855292203159773\n",
      "Epoch 228, Loss: 0.38685580435539124\n",
      "Epoch 229, Loss: 0.38786381439642276\n",
      "Epoch 230, Loss: 0.3848232671480698\n",
      "Epoch 231, Loss: 0.3861960722488463\n",
      "Epoch 232, Loss: 0.3868266061209943\n",
      "Epoch 233, Loss: 0.384043000442464\n",
      "Epoch 234, Loss: 0.3865285463462941\n",
      "Epoch 235, Loss: 0.385736875859642\n",
      "Epoch 236, Loss: 0.3837716872769022\n",
      "Epoch 237, Loss: 0.3860986342327659\n",
      "Epoch 238, Loss: 0.38383353560485567\n",
      "Epoch 239, Loss: 0.3835985327148618\n",
      "Epoch 240, Loss: 0.3844234474787844\n",
      "Epoch 241, Loss: 0.38240773347263085\n",
      "Epoch 242, Loss: 0.38344063121011485\n",
      "Epoch 243, Loss: 0.3826093329207104\n",
      "Epoch 244, Loss: 0.38201379170536265\n",
      "Epoch 245, Loss: 0.38253458795430384\n",
      "Epoch 246, Loss: 0.38141105017479787\n",
      "Epoch 247, Loss: 0.3815542875026277\n",
      "Epoch 248, Loss: 0.381602867390548\n",
      "Epoch 249, Loss: 0.38051202046258964\n",
      "Epoch 250, Loss: 0.3811373747520995\n",
      "Epoch 251, Loss: 0.38059828196241546\n",
      "Epoch 252, Loss: 0.3798901476311233\n",
      "Epoch 253, Loss: 0.38018488702812075\n",
      "Epoch 254, Loss: 0.37983230608103363\n",
      "Epoch 255, Loss: 0.3790302663559644\n",
      "Epoch 256, Loss: 0.37922083193565465\n",
      "Epoch 257, Loss: 0.37904093993182525\n",
      "Epoch 258, Loss: 0.37841710244356486\n",
      "Epoch 259, Loss: 0.378077357419764\n",
      "Epoch 260, Loss: 0.3782038716744418\n",
      "Epoch 261, Loss: 0.3777932208989794\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2442796318767163\n",
      "Test R^2 score: 0.3506453114579265\n",
      "Num of epochs: 262\n",
      "Epoch 1, Loss: 0.5983638439218282\n",
      "Epoch 2, Loss: 0.5949600337734626\n",
      "Epoch 3, Loss: 0.5916635847906879\n",
      "Epoch 4, Loss: 0.5884673119446837\n",
      "Epoch 5, Loss: 0.5853779982515098\n",
      "Epoch 6, Loss: 0.5824031026003668\n",
      "Epoch 7, Loss: 0.5795493750516095\n",
      "Epoch 8, Loss: 0.5768235739768067\n",
      "Epoch 9, Loss: 0.5742327370529562\n",
      "Epoch 10, Loss: 0.5718691757822761\n",
      "Epoch 11, Loss: 0.5696860491576686\n",
      "Epoch 12, Loss: 0.567659425524464\n",
      "Epoch 13, Loss: 0.5657738674117253\n",
      "Epoch 14, Loss: 0.5640465615258257\n",
      "Epoch 15, Loss: 0.5624738263292621\n",
      "Epoch 16, Loss: 0.5610642388278515\n",
      "Epoch 17, Loss: 0.5598249937679707\n",
      "Epoch 18, Loss: 0.5587615981381042\n",
      "Epoch 19, Loss: 0.5578776484466534\n",
      "Epoch 20, Loss: 0.5571731162019827\n",
      "Epoch 21, Loss: 0.5566660825027705\n",
      "Epoch 22, Loss: 0.5563321781533105\n",
      "Epoch 23, Loss: 0.5561586937278101\n",
      "Epoch 24, Loss: 0.5561152069848376\n",
      "Epoch 25, Loss: 0.5561727598761715\n",
      "Epoch 26, Loss: 0.5563003302960441\n",
      "Epoch 27, Loss: 0.5564719228919153\n",
      "Epoch 28, Loss: 0.5566243754909601\n",
      "Epoch 29, Loss: 0.5567241137618505\n",
      "Epoch 30, Loss: 0.5567616381360209\n",
      "Epoch 31, Loss: 0.5567264423807851\n",
      "Epoch 32, Loss: 0.5566031192391266\n",
      "Epoch 33, Loss: 0.5563840308141036\n",
      "Epoch 34, Loss: 0.5560774514108126\n",
      "Epoch 35, Loss: 0.5556884921155909\n",
      "Epoch 36, Loss: 0.5552120683364294\n",
      "Epoch 37, Loss: 0.5546347633329549\n",
      "Epoch 38, Loss: 0.5539511238720288\n",
      "Epoch 39, Loss: 0.5531614560974407\n",
      "Epoch 40, Loss: 0.5522496554717703\n",
      "Epoch 41, Loss: 0.5511870005672712\n",
      "Epoch 42, Loss: 0.5499434897262103\n",
      "Epoch 43, Loss: 0.5484859445156759\n",
      "Epoch 44, Loss: 0.5468349442117705\n",
      "Epoch 45, Loss: 0.5449403328999675\n",
      "Epoch 46, Loss: 0.5427889354644222\n",
      "Epoch 47, Loss: 0.5403349964054281\n",
      "Epoch 48, Loss: 0.5375270814505015\n",
      "Epoch 49, Loss: 0.5342756112010812\n",
      "Epoch 50, Loss: 0.5305144884394326\n",
      "Epoch 51, Loss: 0.5259888940407443\n",
      "Epoch 52, Loss: 0.5206371669103207\n",
      "Epoch 53, Loss: 0.514592321474392\n",
      "Epoch 54, Loss: 0.5083719253221949\n",
      "Epoch 55, Loss: 0.5027373603548393\n",
      "Epoch 56, Loss: 0.4978197814207734\n",
      "Epoch 57, Loss: 0.49258373599142724\n",
      "Epoch 58, Loss: 0.4868365315186761\n",
      "Epoch 59, Loss: 0.482062588234093\n",
      "Epoch 60, Loss: 0.48016350827253623\n",
      "Epoch 61, Loss: 0.47962494544793705\n",
      "Epoch 62, Loss: 0.4786140340703007\n",
      "Epoch 63, Loss: 0.47689326330087384\n",
      "Epoch 64, Loss: 0.475476857547791\n",
      "Epoch 65, Loss: 0.47467823863333786\n",
      "Epoch 66, Loss: 0.47384825850039236\n",
      "Epoch 67, Loss: 0.47242042080765956\n",
      "Epoch 68, Loss: 0.47031242332584605\n",
      "Epoch 69, Loss: 0.46807657187406304\n",
      "Epoch 70, Loss: 0.4659456128514909\n",
      "Epoch 71, Loss: 0.46411042913182265\n",
      "Epoch 72, Loss: 0.46262752926930534\n",
      "Epoch 73, Loss: 0.46158016790874973\n",
      "Epoch 74, Loss: 0.461076618472252\n",
      "Epoch 75, Loss: 0.46075447134062025\n",
      "Epoch 76, Loss: 0.45993744937996495\n",
      "Epoch 77, Loss: 0.458681761632324\n",
      "Epoch 78, Loss: 0.4576049529526999\n",
      "Epoch 79, Loss: 0.45678127005762925\n",
      "Epoch 80, Loss: 0.45589620707821593\n",
      "Epoch 81, Loss: 0.45481917581904846\n",
      "Epoch 82, Loss: 0.4536930666953941\n",
      "Epoch 83, Loss: 0.4528587150815049\n",
      "Epoch 84, Loss: 0.45221495499533293\n",
      "Epoch 85, Loss: 0.4514630356640414\n",
      "Epoch 86, Loss: 0.4505906427647863\n",
      "Epoch 87, Loss: 0.4496968089048797\n",
      "Epoch 88, Loss: 0.44894216564419503\n",
      "Epoch 89, Loss: 0.4482593907065649\n",
      "Epoch 90, Loss: 0.4474857904533096\n",
      "Epoch 91, Loss: 0.446623795602468\n",
      "Epoch 92, Loss: 0.44578732724063536\n",
      "Epoch 93, Loss: 0.4450193410592157\n",
      "Epoch 94, Loss: 0.44416514037957294\n",
      "Epoch 95, Loss: 0.4432319256270442\n",
      "Epoch 96, Loss: 0.44230959456889524\n",
      "Epoch 97, Loss: 0.441429053198626\n",
      "Epoch 98, Loss: 0.4404993277088885\n",
      "Epoch 99, Loss: 0.43956533059171954\n",
      "Epoch 100, Loss: 0.43873355869994507\n",
      "Epoch 101, Loss: 0.4379238902106283\n",
      "Epoch 102, Loss: 0.43709958008401495\n",
      "Epoch 103, Loss: 0.4363154997745042\n",
      "Epoch 104, Loss: 0.43559618957239227\n",
      "Epoch 105, Loss: 0.4348452780419497\n",
      "Epoch 106, Loss: 0.4340923981774929\n",
      "Epoch 107, Loss: 0.43335210235308447\n",
      "Epoch 108, Loss: 0.43259484984722335\n",
      "Epoch 109, Loss: 0.4318701190093008\n",
      "Epoch 110, Loss: 0.4311733910336447\n",
      "Epoch 111, Loss: 0.4304633332342666\n",
      "Epoch 112, Loss: 0.4297805685341516\n",
      "Epoch 113, Loss: 0.42911013914556334\n",
      "Epoch 114, Loss: 0.42844201692833683\n",
      "Epoch 115, Loss: 0.42779054664811234\n",
      "Epoch 116, Loss: 0.4271153189924266\n",
      "Epoch 117, Loss: 0.4264450673138182\n",
      "Epoch 118, Loss: 0.42577841521553095\n",
      "Epoch 119, Loss: 0.4251682523458339\n",
      "Epoch 120, Loss: 0.4247868325876843\n",
      "Epoch 121, Loss: 0.42517256318871793\n",
      "Epoch 122, Loss: 0.42433266559172717\n",
      "Epoch 123, Loss: 0.4226595330243046\n",
      "Epoch 124, Loss: 0.422747733603549\n",
      "Epoch 125, Loss: 0.42209840087068057\n",
      "Epoch 126, Loss: 0.42092870616718797\n",
      "Epoch 127, Loss: 0.42096254785406445\n",
      "Epoch 128, Loss: 0.41990757407743123\n",
      "Epoch 129, Loss: 0.4195436593037229\n",
      "Epoch 130, Loss: 0.4192499507023709\n",
      "Epoch 131, Loss: 0.4181544702348207\n",
      "Epoch 132, Loss: 0.4181151802038897\n",
      "Epoch 133, Loss: 0.41738642475455445\n",
      "Epoch 134, Loss: 0.4165529175305101\n",
      "Epoch 135, Loss: 0.4165234041289998\n",
      "Epoch 136, Loss: 0.41566561808768693\n",
      "Epoch 137, Loss: 0.41493493064088327\n",
      "Epoch 138, Loss: 0.41483400552515604\n",
      "Epoch 139, Loss: 0.41405319707244476\n",
      "Epoch 140, Loss: 0.41324686293152646\n",
      "Epoch 141, Loss: 0.4130977150971831\n",
      "Epoch 142, Loss: 0.41248622495597004\n",
      "Epoch 143, Loss: 0.4115809628075375\n",
      "Epoch 144, Loss: 0.41134652497815366\n",
      "Epoch 145, Loss: 0.41106843784168057\n",
      "Epoch 146, Loss: 0.41016689468376416\n",
      "Epoch 147, Loss: 0.4095894121001601\n",
      "Epoch 148, Loss: 0.4094257934741514\n",
      "Epoch 149, Loss: 0.4089826050057863\n",
      "Epoch 150, Loss: 0.4082746853685723\n",
      "Epoch 151, Loss: 0.4075934680568355\n",
      "Epoch 152, Loss: 0.4072914712162313\n",
      "Epoch 153, Loss: 0.4071237081999718\n",
      "Epoch 154, Loss: 0.4066293119383096\n",
      "Epoch 155, Loss: 0.4059244281816693\n",
      "Epoch 156, Loss: 0.4051857543218085\n",
      "Epoch 157, Loss: 0.4047382912005453\n",
      "Epoch 158, Loss: 0.4044697525529536\n",
      "Epoch 159, Loss: 0.4041697168562846\n",
      "Epoch 160, Loss: 0.40385180314797225\n",
      "Epoch 161, Loss: 0.40322775159643526\n",
      "Epoch 162, Loss: 0.4026103571538818\n",
      "Epoch 163, Loss: 0.4019063219824204\n",
      "Epoch 164, Loss: 0.4013274792708151\n",
      "Epoch 165, Loss: 0.40085392640655493\n",
      "Epoch 166, Loss: 0.4004760837069474\n",
      "Epoch 167, Loss: 0.40025330956858113\n",
      "Epoch 168, Loss: 0.40033531737385164\n",
      "Epoch 169, Loss: 0.40123061480888794\n",
      "Epoch 170, Loss: 0.40100274165445815\n",
      "Epoch 171, Loss: 0.39967211009945935\n",
      "Epoch 172, Loss: 0.3978034753067947\n",
      "Epoch 173, Loss: 0.39842676634448737\n",
      "Epoch 174, Loss: 0.3990244935890446\n",
      "Epoch 175, Loss: 0.3970241349028235\n",
      "Epoch 176, Loss: 0.3966885872335096\n",
      "Epoch 177, Loss: 0.39752807799924683\n",
      "Epoch 178, Loss: 0.396141768635351\n",
      "Epoch 179, Loss: 0.3953065524954319\n",
      "Epoch 180, Loss: 0.39585111812324264\n",
      "Epoch 181, Loss: 0.3951884357743569\n",
      "Epoch 182, Loss: 0.3942109875967493\n",
      "Epoch 183, Loss: 0.3940857364177673\n",
      "Epoch 184, Loss: 0.39417057736387673\n",
      "Epoch 185, Loss: 0.39346448749702323\n",
      "Epoch 186, Loss: 0.3927421796397703\n",
      "Epoch 187, Loss: 0.3927462772821857\n",
      "Epoch 188, Loss: 0.3926841061384879\n",
      "Epoch 189, Loss: 0.39200856279611207\n",
      "Epoch 190, Loss: 0.39132914973494354\n",
      "Epoch 191, Loss: 0.3913661030111718\n",
      "Epoch 192, Loss: 0.39127218040384865\n",
      "Epoch 193, Loss: 0.39073004263923156\n",
      "Epoch 194, Loss: 0.3900816762813346\n",
      "Epoch 195, Loss: 0.3896708852473238\n",
      "Epoch 196, Loss: 0.3897578341618583\n",
      "Epoch 197, Loss: 0.3893349325649902\n",
      "Epoch 198, Loss: 0.3888322892137536\n",
      "Epoch 199, Loss: 0.3883657543860919\n",
      "Epoch 200, Loss: 0.38789604621164414\n",
      "Epoch 201, Loss: 0.38775736122473237\n",
      "Epoch 202, Loss: 0.38757047396895267\n",
      "Epoch 203, Loss: 0.38733571861715016\n",
      "Epoch 204, Loss: 0.3871050744919698\n",
      "Epoch 205, Loss: 0.3867743481059311\n",
      "Epoch 206, Loss: 0.3863753711287692\n",
      "Epoch 207, Loss: 0.3860021946231932\n",
      "Epoch 208, Loss: 0.38552920099038435\n",
      "Epoch 209, Loss: 0.38514986555212777\n",
      "Epoch 210, Loss: 0.38477360286284257\n",
      "Epoch 211, Loss: 0.38437322755730585\n",
      "Epoch 212, Loss: 0.38410959617696205\n",
      "Epoch 213, Loss: 0.38400373206336685\n",
      "Epoch 214, Loss: 0.3841908804771299\n",
      "Epoch 215, Loss: 0.3849595254207359\n",
      "Epoch 216, Loss: 0.3855343415639672\n",
      "Epoch 217, Loss: 0.3856543718648836\n",
      "Epoch 218, Loss: 0.38333800311284894\n",
      "Epoch 219, Loss: 0.38166053821538165\n",
      "Epoch 220, Loss: 0.38256343212740174\n",
      "Epoch 221, Loss: 0.3834422633987437\n",
      "Epoch 222, Loss: 0.3818292446476755\n",
      "Epoch 223, Loss: 0.3807904107671073\n",
      "Epoch 224, Loss: 0.38137471473030515\n",
      "Epoch 225, Loss: 0.3820809166262265\n",
      "Epoch 226, Loss: 0.3797140261328231\n",
      "Epoch 227, Loss: 0.37983112915237\n",
      "Epoch 228, Loss: 0.38071804847956375\n",
      "Epoch 229, Loss: 0.3793620091936859\n",
      "Epoch 230, Loss: 0.3786180717789005\n",
      "Epoch 231, Loss: 0.37871759181597453\n",
      "Epoch 232, Loss: 0.37896370206402474\n",
      "Epoch 233, Loss: 0.37740076001656303\n",
      "Epoch 234, Loss: 0.3774252983100674\n",
      "Epoch 235, Loss: 0.3776539035356485\n",
      "Epoch 236, Loss: 0.3771613934196457\n",
      "Epoch 237, Loss: 0.37641556116656394\n",
      "Epoch 238, Loss: 0.3758758608228127\n",
      "Epoch 239, Loss: 0.3763635600558096\n",
      "Epoch 240, Loss: 0.37546514432384676\n",
      "Epoch 241, Loss: 0.3749694414403444\n",
      "Epoch 242, Loss: 0.3745908690844845\n",
      "Epoch 243, Loss: 0.37414893293446505\n",
      "Epoch 244, Loss: 0.374193695599435\n",
      "Epoch 245, Loss: 0.37375800771650947\n",
      "Epoch 246, Loss: 0.37338666769442386\n",
      "Epoch 247, Loss: 0.3730475540554397\n",
      "Epoch 248, Loss: 0.3724055144467668\n",
      "Epoch 249, Loss: 0.3721163263178211\n",
      "Epoch 250, Loss: 0.3716966850655835\n",
      "Epoch 251, Loss: 0.37119906085641624\n",
      "Epoch 252, Loss: 0.3709396443871441\n",
      "Epoch 253, Loss: 0.37053634541731906\n",
      "Epoch 254, Loss: 0.37008970858142026\n",
      "Epoch 255, Loss: 0.36983106519689224\n",
      "Epoch 256, Loss: 0.36956881358422605\n",
      "Epoch 257, Loss: 0.36946069878639465\n",
      "Epoch 258, Loss: 0.37015348070299525\n",
      "Epoch 259, Loss: 0.3721617338548642\n",
      "Epoch 260, Loss: 0.3743761356826904\n",
      "Epoch 261, Loss: 0.372835388951837\n",
      "Epoch 262, Loss: 0.36769229603592574\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.24153151363873998\n",
      "Test R^2 score: 0.3684816068813128\n",
      "Num of epochs: 263\n",
      "Epoch 1, Loss: 0.5687914120615323\n",
      "Epoch 2, Loss: 0.5677500076629893\n",
      "Epoch 3, Loss: 0.5667526238359276\n",
      "Epoch 4, Loss: 0.5658003624798614\n",
      "Epoch 5, Loss: 0.5648947443439563\n",
      "Epoch 6, Loss: 0.5640345674821208\n",
      "Epoch 7, Loss: 0.5632211777482832\n",
      "Epoch 8, Loss: 0.5624568445817247\n",
      "Epoch 9, Loss: 0.5617377096273842\n",
      "Epoch 10, Loss: 0.5610627515362455\n",
      "Epoch 11, Loss: 0.5605015487156075\n",
      "Epoch 12, Loss: 0.5600017861354817\n",
      "Epoch 13, Loss: 0.5595323373314743\n",
      "Epoch 14, Loss: 0.5590935185347574\n",
      "Epoch 15, Loss: 0.5586853219047547\n",
      "Epoch 16, Loss: 0.5583075743991429\n",
      "Epoch 17, Loss: 0.55795999067701\n",
      "Epoch 18, Loss: 0.5576415849950128\n",
      "Epoch 19, Loss: 0.5573509368989221\n",
      "Epoch 20, Loss: 0.5570868594111046\n",
      "Epoch 21, Loss: 0.5568558394007466\n",
      "Epoch 22, Loss: 0.5566747554554948\n",
      "Epoch 23, Loss: 0.5565104549861949\n",
      "Epoch 24, Loss: 0.5563832005667994\n",
      "Epoch 25, Loss: 0.5563086607358817\n",
      "Epoch 26, Loss: 0.5562117681330323\n",
      "Epoch 27, Loss: 0.5561284703999344\n",
      "Epoch 28, Loss: 0.5560579161153305\n",
      "Epoch 29, Loss: 0.5560156006871334\n",
      "Epoch 30, Loss: 0.5559633920353593\n",
      "Epoch 31, Loss: 0.5559077742436312\n",
      "Epoch 32, Loss: 0.555845127204591\n",
      "Epoch 33, Loss: 0.5557736521693003\n",
      "Epoch 34, Loss: 0.5556913345697161\n",
      "Epoch 35, Loss: 0.5555943343085815\n",
      "Epoch 36, Loss: 0.5554806317696365\n",
      "Epoch 37, Loss: 0.5553382494896988\n",
      "Epoch 38, Loss: 0.5551593278176313\n",
      "Epoch 39, Loss: 0.5549286331652447\n",
      "Epoch 40, Loss: 0.5546345483999566\n",
      "Epoch 41, Loss: 0.554259255808148\n",
      "Epoch 42, Loss: 0.5537664261183521\n",
      "Epoch 43, Loss: 0.5531510578634006\n",
      "Epoch 44, Loss: 0.552374921725756\n",
      "Epoch 45, Loss: 0.5514281511808117\n",
      "Epoch 46, Loss: 0.5502551657309863\n",
      "Epoch 47, Loss: 0.5487312692995167\n",
      "Epoch 48, Loss: 0.5467677964993246\n",
      "Epoch 49, Loss: 0.5443730205145145\n",
      "Epoch 50, Loss: 0.5415081440215433\n",
      "Epoch 51, Loss: 0.5380358940988039\n",
      "Epoch 52, Loss: 0.5338910594070848\n",
      "Epoch 53, Loss: 0.5292286564970006\n",
      "Epoch 54, Loss: 0.5250513335517358\n",
      "Epoch 55, Loss: 0.5228804285732939\n",
      "Epoch 56, Loss: 0.5220506715059049\n",
      "Epoch 57, Loss: 0.5194682032828905\n",
      "Epoch 58, Loss: 0.515580782294828\n",
      "Epoch 59, Loss: 0.5122393224263331\n",
      "Epoch 60, Loss: 0.5101872596838293\n",
      "Epoch 61, Loss: 0.5088676640865654\n",
      "Epoch 62, Loss: 0.5074726434672565\n",
      "Epoch 63, Loss: 0.5054949769846822\n",
      "Epoch 64, Loss: 0.5029808833165865\n",
      "Epoch 65, Loss: 0.5002918881537379\n",
      "Epoch 66, Loss: 0.49769883804503734\n",
      "Epoch 67, Loss: 0.49551476461294747\n",
      "Epoch 68, Loss: 0.4936826943746651\n",
      "Epoch 69, Loss: 0.4916171750790007\n",
      "Epoch 70, Loss: 0.48880463587467554\n",
      "Epoch 71, Loss: 0.4854305824719095\n",
      "Epoch 72, Loss: 0.4820968676007765\n",
      "Epoch 73, Loss: 0.4789045349389088\n",
      "Epoch 74, Loss: 0.47571233052909934\n",
      "Epoch 75, Loss: 0.47244177436837925\n",
      "Epoch 76, Loss: 0.4697157606758511\n",
      "Epoch 77, Loss: 0.46850910354612196\n",
      "Epoch 78, Loss: 0.46872765169910924\n",
      "Epoch 79, Loss: 0.4681486882377694\n",
      "Epoch 80, Loss: 0.46654054954183605\n",
      "Epoch 81, Loss: 0.4651987659525719\n",
      "Epoch 82, Loss: 0.46474144715456933\n",
      "Epoch 83, Loss: 0.46443703433462513\n",
      "Epoch 84, Loss: 0.4636520047256668\n",
      "Epoch 85, Loss: 0.462249166541537\n",
      "Epoch 86, Loss: 0.4605858156211989\n",
      "Epoch 87, Loss: 0.4593749150126891\n",
      "Epoch 88, Loss: 0.458910639907159\n",
      "Epoch 89, Loss: 0.4585148946626599\n",
      "Epoch 90, Loss: 0.45770297449152636\n",
      "Epoch 91, Loss: 0.45671993640454533\n",
      "Epoch 92, Loss: 0.4559079900215879\n",
      "Epoch 93, Loss: 0.45551104275626386\n",
      "Epoch 94, Loss: 0.45522671021554983\n",
      "Epoch 95, Loss: 0.4546034633673632\n",
      "Epoch 96, Loss: 0.45368423153416854\n",
      "Epoch 97, Loss: 0.4528587315338336\n",
      "Epoch 98, Loss: 0.4523164671739328\n",
      "Epoch 99, Loss: 0.45187163479661246\n",
      "Epoch 100, Loss: 0.45132587331269924\n",
      "Epoch 101, Loss: 0.45069738100398443\n",
      "Epoch 102, Loss: 0.4500868991552109\n",
      "Epoch 103, Loss: 0.44957758627898936\n",
      "Epoch 104, Loss: 0.44912766901566764\n",
      "Epoch 105, Loss: 0.4485782037032209\n",
      "Epoch 106, Loss: 0.4479465548575617\n",
      "Epoch 107, Loss: 0.44736013288541315\n",
      "Epoch 108, Loss: 0.4469088001406528\n",
      "Epoch 109, Loss: 0.44645193788140114\n",
      "Epoch 110, Loss: 0.44588009315749494\n",
      "Epoch 111, Loss: 0.44528248334407705\n",
      "Epoch 112, Loss: 0.44474259097600516\n",
      "Epoch 113, Loss: 0.4442434361348051\n",
      "Epoch 114, Loss: 0.44372452810547053\n",
      "Epoch 115, Loss: 0.4431708855269746\n",
      "Epoch 116, Loss: 0.4426063999931579\n",
      "Epoch 117, Loss: 0.4420583010527632\n",
      "Epoch 118, Loss: 0.4415293159083415\n",
      "Epoch 119, Loss: 0.44097899968236376\n",
      "Epoch 120, Loss: 0.4404169660198502\n",
      "Epoch 121, Loss: 0.43987963853576306\n",
      "Epoch 122, Loss: 0.4393465718260739\n",
      "Epoch 123, Loss: 0.4387924823408678\n",
      "Epoch 124, Loss: 0.43824328565812715\n",
      "Epoch 125, Loss: 0.4376956808624011\n",
      "Epoch 126, Loss: 0.43714933306496884\n",
      "Epoch 127, Loss: 0.43660595346512243\n",
      "Epoch 128, Loss: 0.4360717553032289\n",
      "Epoch 129, Loss: 0.4355718323267099\n",
      "Epoch 130, Loss: 0.43505866225185347\n",
      "Epoch 131, Loss: 0.4345349758225765\n",
      "Epoch 132, Loss: 0.43403465604630115\n",
      "Epoch 133, Loss: 0.43354444824907784\n",
      "Epoch 134, Loss: 0.43304647669669766\n",
      "Epoch 135, Loss: 0.43254278158819476\n",
      "Epoch 136, Loss: 0.43204998437916536\n",
      "Epoch 137, Loss: 0.4315563827401521\n",
      "Epoch 138, Loss: 0.43104885496645207\n",
      "Epoch 139, Loss: 0.430592174109381\n",
      "Epoch 140, Loss: 0.4301314401452091\n",
      "Epoch 141, Loss: 0.4296806508298674\n",
      "Epoch 142, Loss: 0.4292198584132261\n",
      "Epoch 143, Loss: 0.42874937819277326\n",
      "Epoch 144, Loss: 0.42829501194294906\n",
      "Epoch 145, Loss: 0.42784246185133334\n",
      "Epoch 146, Loss: 0.42737088370091164\n",
      "Epoch 147, Loss: 0.42691580076140384\n",
      "Epoch 148, Loss: 0.42648469054571536\n",
      "Epoch 149, Loss: 0.42606125819979507\n",
      "Epoch 150, Loss: 0.42562810961109737\n",
      "Epoch 151, Loss: 0.425191313094402\n",
      "Epoch 152, Loss: 0.42475736507925516\n",
      "Epoch 153, Loss: 0.42432523834553554\n",
      "Epoch 154, Loss: 0.4239067672686966\n",
      "Epoch 155, Loss: 0.4234794377747581\n",
      "Epoch 156, Loss: 0.4230563084333426\n",
      "Epoch 157, Loss: 0.42265239368308294\n",
      "Epoch 158, Loss: 0.4222639022072117\n",
      "Epoch 159, Loss: 0.42188589647137603\n",
      "Epoch 160, Loss: 0.4215050594143838\n",
      "Epoch 161, Loss: 0.42112754020932536\n",
      "Epoch 162, Loss: 0.42073882720968225\n",
      "Epoch 163, Loss: 0.42039417054801387\n",
      "Epoch 164, Loss: 0.42006212598128173\n",
      "Epoch 165, Loss: 0.419738339080967\n",
      "Epoch 166, Loss: 0.4194225092212566\n",
      "Epoch 167, Loss: 0.4191368749900504\n",
      "Epoch 168, Loss: 0.4187838903633812\n",
      "Epoch 169, Loss: 0.41839524372681486\n",
      "Epoch 170, Loss: 0.41805289660347844\n",
      "Epoch 171, Loss: 0.4177494543324256\n",
      "Epoch 172, Loss: 0.41743774195420047\n",
      "Epoch 173, Loss: 0.4170641513164659\n",
      "Epoch 174, Loss: 0.41667956888567836\n",
      "Epoch 175, Loss: 0.41627163240851695\n",
      "Epoch 176, Loss: 0.41592633717473254\n",
      "Epoch 177, Loss: 0.4156429609562392\n",
      "Epoch 178, Loss: 0.41541085139993084\n",
      "Epoch 179, Loss: 0.4151171622003038\n",
      "Epoch 180, Loss: 0.41456817842065613\n",
      "Epoch 181, Loss: 0.4141343432304269\n",
      "Epoch 182, Loss: 0.41396841743728297\n",
      "Epoch 183, Loss: 0.41375530291383067\n",
      "Epoch 184, Loss: 0.4132118303806755\n",
      "Epoch 185, Loss: 0.4127380673909274\n",
      "Epoch 186, Loss: 0.4125803204568137\n",
      "Epoch 187, Loss: 0.41236719319960563\n",
      "Epoch 188, Loss: 0.4119455816546607\n",
      "Epoch 189, Loss: 0.4114230257490283\n",
      "Epoch 190, Loss: 0.4112815134966293\n",
      "Epoch 191, Loss: 0.41112068865154605\n",
      "Epoch 192, Loss: 0.41055077243337834\n",
      "Epoch 193, Loss: 0.4101315990487961\n",
      "Epoch 194, Loss: 0.41004339209494195\n",
      "Epoch 195, Loss: 0.40974072798013084\n",
      "Epoch 196, Loss: 0.4092064714428571\n",
      "Epoch 197, Loss: 0.4088598198307504\n",
      "Epoch 198, Loss: 0.4087358858430656\n",
      "Epoch 199, Loss: 0.4084422857387974\n",
      "Epoch 200, Loss: 0.4079782149269966\n",
      "Epoch 201, Loss: 0.40756306821341554\n",
      "Epoch 202, Loss: 0.4073653133407676\n",
      "Epoch 203, Loss: 0.4071931162027473\n",
      "Epoch 204, Loss: 0.4068244943460798\n",
      "Epoch 205, Loss: 0.4063483082592571\n",
      "Epoch 206, Loss: 0.4059920225463699\n",
      "Epoch 207, Loss: 0.4057356255653398\n",
      "Epoch 208, Loss: 0.40548044456125465\n",
      "Epoch 209, Loss: 0.4052921888310755\n",
      "Epoch 210, Loss: 0.40511287587970063\n",
      "Epoch 211, Loss: 0.40506069620393287\n",
      "Epoch 212, Loss: 0.4045120440683424\n",
      "Epoch 213, Loss: 0.4038964098796067\n",
      "Epoch 214, Loss: 0.4033809366915297\n",
      "Epoch 215, Loss: 0.40317876516402945\n",
      "Epoch 216, Loss: 0.4032930083188316\n",
      "Epoch 217, Loss: 0.40336787795407286\n",
      "Epoch 218, Loss: 0.4028627141191172\n",
      "Epoch 219, Loss: 0.4022006548884261\n",
      "Epoch 220, Loss: 0.40152234422163946\n",
      "Epoch 221, Loss: 0.40136854259698446\n",
      "Epoch 222, Loss: 0.40142948010656454\n",
      "Epoch 223, Loss: 0.4007889046040268\n",
      "Epoch 224, Loss: 0.40023936694291856\n",
      "Epoch 225, Loss: 0.3997547962719275\n",
      "Epoch 226, Loss: 0.3994276235651984\n",
      "Epoch 227, Loss: 0.39926736091532283\n",
      "Epoch 228, Loss: 0.3996433635140129\n",
      "Epoch 229, Loss: 0.40117859876545536\n",
      "Epoch 230, Loss: 0.39985814857570595\n",
      "Epoch 231, Loss: 0.3980740029746398\n",
      "Epoch 232, Loss: 0.3978469998187471\n",
      "Epoch 233, Loss: 0.3982878011087641\n",
      "Epoch 234, Loss: 0.3973657179987667\n",
      "Epoch 235, Loss: 0.39658878624072924\n",
      "Epoch 236, Loss: 0.3973030882868744\n",
      "Epoch 237, Loss: 0.39734276741797386\n",
      "Epoch 238, Loss: 0.39547784008851333\n",
      "Epoch 239, Loss: 0.39603242342960265\n",
      "Epoch 240, Loss: 0.39633109977593833\n",
      "Epoch 241, Loss: 0.3946064603520799\n",
      "Epoch 242, Loss: 0.39517175030880747\n",
      "Epoch 243, Loss: 0.3956697109081733\n",
      "Epoch 244, Loss: 0.39359164005333375\n",
      "Epoch 245, Loss: 0.39468860321011556\n",
      "Epoch 246, Loss: 0.39507281082016055\n",
      "Epoch 247, Loss: 0.392522267025862\n",
      "Epoch 248, Loss: 0.39463829250260346\n",
      "Epoch 249, Loss: 0.3936968941676732\n",
      "Epoch 250, Loss: 0.39192310174924083\n",
      "Epoch 251, Loss: 0.39377268014408184\n",
      "Epoch 252, Loss: 0.39157463989557867\n",
      "Epoch 253, Loss: 0.39134855016408376\n",
      "Epoch 254, Loss: 0.39180489681167036\n",
      "Epoch 255, Loss: 0.38999487598427635\n",
      "Epoch 256, Loss: 0.3905094548044245\n",
      "Epoch 257, Loss: 0.3895691525671427\n",
      "Epoch 258, Loss: 0.3887736125042858\n",
      "Epoch 259, Loss: 0.3895132073953202\n",
      "Epoch 260, Loss: 0.38797609553486917\n",
      "Epoch 261, Loss: 0.3876406729604087\n",
      "Epoch 262, Loss: 0.3879111815630567\n",
      "Epoch 263, Loss: 0.3869651433355663\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.24344523462009607\n",
      "Test R^2 score: 0.3577661602584802\n",
      "Num of epochs: 264\n",
      "Epoch 1, Loss: 0.5865334341319594\n",
      "Epoch 2, Loss: 0.5836483553218552\n",
      "Epoch 3, Loss: 0.5809523035454383\n",
      "Epoch 4, Loss: 0.5785800328741816\n",
      "Epoch 5, Loss: 0.5764944175903198\n",
      "Epoch 6, Loss: 0.5745550196059136\n",
      "Epoch 7, Loss: 0.5727567940953812\n",
      "Epoch 8, Loss: 0.571078791598571\n",
      "Epoch 9, Loss: 0.5695136236281063\n",
      "Epoch 10, Loss: 0.5680552714481073\n",
      "Epoch 11, Loss: 0.5666982490022452\n",
      "Epoch 12, Loss: 0.5654384895654214\n",
      "Epoch 13, Loss: 0.5642770670837017\n",
      "Epoch 14, Loss: 0.563220357579668\n",
      "Epoch 15, Loss: 0.5622538186821819\n",
      "Epoch 16, Loss: 0.5614611516491346\n",
      "Epoch 17, Loss: 0.5607776233367694\n",
      "Epoch 18, Loss: 0.5601422913327105\n",
      "Epoch 19, Loss: 0.5595509257794588\n",
      "Epoch 20, Loss: 0.559001613647029\n",
      "Epoch 21, Loss: 0.5585241741252346\n",
      "Epoch 22, Loss: 0.5580969248307082\n",
      "Epoch 23, Loss: 0.5576984727073524\n",
      "Epoch 24, Loss: 0.5573270346806188\n",
      "Epoch 25, Loss: 0.5569808455637459\n",
      "Epoch 26, Loss: 0.5566577038738204\n",
      "Epoch 27, Loss: 0.5563804152119546\n",
      "Epoch 28, Loss: 0.5561326771140009\n",
      "Epoch 29, Loss: 0.55586820851409\n",
      "Epoch 30, Loss: 0.5555779469136775\n",
      "Epoch 31, Loss: 0.5552477358016593\n",
      "Epoch 32, Loss: 0.5549382193863919\n",
      "Epoch 33, Loss: 0.5545883896088718\n",
      "Epoch 34, Loss: 0.5541493397587705\n",
      "Epoch 35, Loss: 0.5536144515647772\n",
      "Epoch 36, Loss: 0.5529978632963266\n",
      "Epoch 37, Loss: 0.5523199408119436\n",
      "Epoch 38, Loss: 0.5515235876346192\n",
      "Epoch 39, Loss: 0.5505368387090521\n",
      "Epoch 40, Loss: 0.5493229437545009\n",
      "Epoch 41, Loss: 0.5478414714788262\n",
      "Epoch 42, Loss: 0.5461218143177259\n",
      "Epoch 43, Loss: 0.5440878005173277\n",
      "Epoch 44, Loss: 0.5416168838023171\n",
      "Epoch 45, Loss: 0.5386069210911006\n",
      "Epoch 46, Loss: 0.5348964812495521\n",
      "Epoch 47, Loss: 0.5303940609472139\n",
      "Epoch 48, Loss: 0.52517778133982\n",
      "Epoch 49, Loss: 0.5194870779433165\n",
      "Epoch 50, Loss: 0.5138906440905361\n",
      "Epoch 51, Loss: 0.5093445482103252\n",
      "Epoch 52, Loss: 0.5062208614676226\n",
      "Epoch 53, Loss: 0.5025016370433503\n",
      "Epoch 54, Loss: 0.49683133059361073\n",
      "Epoch 55, Loss: 0.4913906731736963\n",
      "Epoch 56, Loss: 0.489055477494104\n",
      "Epoch 57, Loss: 0.48630315264582613\n",
      "Epoch 58, Loss: 0.48220214781945375\n",
      "Epoch 59, Loss: 0.4801275390820054\n",
      "Epoch 60, Loss: 0.48064469008175914\n",
      "Epoch 61, Loss: 0.4803038368362138\n",
      "Epoch 62, Loss: 0.4784104523590986\n",
      "Epoch 63, Loss: 0.47667411372674107\n",
      "Epoch 64, Loss: 0.4754607331511761\n",
      "Epoch 65, Loss: 0.47391790874363826\n",
      "Epoch 66, Loss: 0.47211532535997847\n",
      "Epoch 67, Loss: 0.47080386338236907\n",
      "Epoch 68, Loss: 0.4701812510310316\n",
      "Epoch 69, Loss: 0.46983607357897705\n",
      "Epoch 70, Loss: 0.46923334315596416\n",
      "Epoch 71, Loss: 0.4683251999197433\n",
      "Epoch 72, Loss: 0.46753017335814545\n",
      "Epoch 73, Loss: 0.4670900198497277\n",
      "Epoch 74, Loss: 0.4664836455112491\n",
      "Epoch 75, Loss: 0.46534578477162175\n",
      "Epoch 76, Loss: 0.46428563568617603\n",
      "Epoch 77, Loss: 0.4635476869199333\n",
      "Epoch 78, Loss: 0.46259122734925595\n",
      "Epoch 79, Loss: 0.46144341329159366\n",
      "Epoch 80, Loss: 0.4606492385801653\n",
      "Epoch 81, Loss: 0.4600112304405033\n",
      "Epoch 82, Loss: 0.45915014641680624\n",
      "Epoch 83, Loss: 0.45845114393154984\n",
      "Epoch 84, Loss: 0.4579835409471982\n",
      "Epoch 85, Loss: 0.4574139614707461\n",
      "Epoch 86, Loss: 0.45675199079053597\n",
      "Epoch 87, Loss: 0.4562079357979685\n",
      "Epoch 88, Loss: 0.45556226853171017\n",
      "Epoch 89, Loss: 0.4547029839989306\n",
      "Epoch 90, Loss: 0.4539825283440336\n",
      "Epoch 91, Loss: 0.4533277419770422\n",
      "Epoch 92, Loss: 0.4525332203941948\n",
      "Epoch 93, Loss: 0.451824822179054\n",
      "Epoch 94, Loss: 0.4512524223262621\n",
      "Epoch 95, Loss: 0.45063361555162085\n",
      "Epoch 96, Loss: 0.4501169430256095\n",
      "Epoch 97, Loss: 0.4495650905140456\n",
      "Epoch 98, Loss: 0.44894002477336087\n",
      "Epoch 99, Loss: 0.4484175461639549\n",
      "Epoch 100, Loss: 0.44787208387004174\n",
      "Epoch 101, Loss: 0.44734869106493913\n",
      "Epoch 102, Loss: 0.4468687203773027\n",
      "Epoch 103, Loss: 0.4463272579217411\n",
      "Epoch 104, Loss: 0.44582351008255944\n",
      "Epoch 105, Loss: 0.44531102765827046\n",
      "Epoch 106, Loss: 0.44476699879814563\n",
      "Epoch 107, Loss: 0.4442711248393144\n",
      "Epoch 108, Loss: 0.44372451131446555\n",
      "Epoch 109, Loss: 0.44319865804970016\n",
      "Epoch 110, Loss: 0.44262330042683234\n",
      "Epoch 111, Loss: 0.4420593797262669\n",
      "Epoch 112, Loss: 0.44147003185631306\n",
      "Epoch 113, Loss: 0.4409067822090239\n",
      "Epoch 114, Loss: 0.44037061070927375\n",
      "Epoch 115, Loss: 0.439853180941742\n",
      "Epoch 116, Loss: 0.43933766861685863\n",
      "Epoch 117, Loss: 0.4388366953464689\n",
      "Epoch 118, Loss: 0.4383071368183217\n",
      "Epoch 119, Loss: 0.43779516481201447\n",
      "Epoch 120, Loss: 0.43727252359760427\n",
      "Epoch 121, Loss: 0.43674268912827396\n",
      "Epoch 122, Loss: 0.4362225786515636\n",
      "Epoch 123, Loss: 0.4356951439810353\n",
      "Epoch 124, Loss: 0.43515386940323775\n",
      "Epoch 125, Loss: 0.43460100044165184\n",
      "Epoch 126, Loss: 0.43404371952873744\n",
      "Epoch 127, Loss: 0.43349302685660973\n",
      "Epoch 128, Loss: 0.43295803377566183\n",
      "Epoch 129, Loss: 0.4324400390559281\n",
      "Epoch 130, Loss: 0.43199426309873573\n",
      "Epoch 131, Loss: 0.43172048459997187\n",
      "Epoch 132, Loss: 0.431394204617809\n",
      "Epoch 133, Loss: 0.43075506931206825\n",
      "Epoch 134, Loss: 0.42908864338265434\n",
      "Epoch 135, Loss: 0.42854382292644383\n",
      "Epoch 136, Loss: 0.4286870232866003\n",
      "Epoch 137, Loss: 0.42758076666098355\n",
      "Epoch 138, Loss: 0.4266478442657203\n",
      "Epoch 139, Loss: 0.4266153791858973\n",
      "Epoch 140, Loss: 0.426057113734285\n",
      "Epoch 141, Loss: 0.4251219167869543\n",
      "Epoch 142, Loss: 0.42459034390163214\n",
      "Epoch 143, Loss: 0.4244093184155514\n",
      "Epoch 144, Loss: 0.4239339740262922\n",
      "Epoch 145, Loss: 0.4228951869953208\n",
      "Epoch 146, Loss: 0.42220558353664156\n",
      "Epoch 147, Loss: 0.4220071868081125\n",
      "Epoch 148, Loss: 0.42176291071651123\n",
      "Epoch 149, Loss: 0.42117841927424354\n",
      "Epoch 150, Loss: 0.4202795767386685\n",
      "Epoch 151, Loss: 0.41965083756728566\n",
      "Epoch 152, Loss: 0.41939548945509564\n",
      "Epoch 153, Loss: 0.41920632010170067\n",
      "Epoch 154, Loss: 0.41884695467953525\n",
      "Epoch 155, Loss: 0.41815381097677373\n",
      "Epoch 156, Loss: 0.4174309059749702\n",
      "Epoch 157, Loss: 0.41690096426866247\n",
      "Epoch 158, Loss: 0.41665542905276426\n",
      "Epoch 159, Loss: 0.41658743661359265\n",
      "Epoch 160, Loss: 0.41637424897120734\n",
      "Epoch 161, Loss: 0.4159981629911082\n",
      "Epoch 162, Loss: 0.4151779122061704\n",
      "Epoch 163, Loss: 0.41440267804143016\n",
      "Epoch 164, Loss: 0.41390113565317255\n",
      "Epoch 165, Loss: 0.4137158292161165\n",
      "Epoch 166, Loss: 0.41369745969677063\n",
      "Epoch 167, Loss: 0.41349669251162785\n",
      "Epoch 168, Loss: 0.4130339533424501\n",
      "Epoch 169, Loss: 0.412102739904423\n",
      "Epoch 170, Loss: 0.4111054653758797\n",
      "Epoch 171, Loss: 0.4104099215842367\n",
      "Epoch 172, Loss: 0.4101000792777918\n",
      "Epoch 173, Loss: 0.4101009331594202\n",
      "Epoch 174, Loss: 0.41029960306995855\n",
      "Epoch 175, Loss: 0.41029213970305944\n",
      "Epoch 176, Loss: 0.4092822253683165\n",
      "Epoch 177, Loss: 0.40784641358708035\n",
      "Epoch 178, Loss: 0.407126599673817\n",
      "Epoch 179, Loss: 0.4072210188014915\n",
      "Epoch 180, Loss: 0.40729767249411936\n",
      "Epoch 181, Loss: 0.40665981822748465\n",
      "Epoch 182, Loss: 0.40561483320476055\n",
      "Epoch 183, Loss: 0.404907355367452\n",
      "Epoch 184, Loss: 0.4047788244472359\n",
      "Epoch 185, Loss: 0.40489467708356147\n",
      "Epoch 186, Loss: 0.40471319978625625\n",
      "Epoch 187, Loss: 0.40416966155341955\n",
      "Epoch 188, Loss: 0.40321871607068627\n",
      "Epoch 189, Loss: 0.4024676160046288\n",
      "Epoch 190, Loss: 0.4020463900156036\n",
      "Epoch 191, Loss: 0.40183095752963577\n",
      "Epoch 192, Loss: 0.40179327927385505\n",
      "Epoch 193, Loss: 0.40179359451013946\n",
      "Epoch 194, Loss: 0.4019331827953582\n",
      "Epoch 195, Loss: 0.40153264257554866\n",
      "Epoch 196, Loss: 0.4007726939814321\n",
      "Epoch 197, Loss: 0.39951539561263477\n",
      "Epoch 198, Loss: 0.39875391943269906\n",
      "Epoch 199, Loss: 0.3987423534616814\n",
      "Epoch 200, Loss: 0.3989453725311464\n",
      "Epoch 201, Loss: 0.39903341869954223\n",
      "Epoch 202, Loss: 0.39831548580317755\n",
      "Epoch 203, Loss: 0.39727195727197523\n",
      "Epoch 204, Loss: 0.396477290498927\n",
      "Epoch 205, Loss: 0.3962552954443274\n",
      "Epoch 206, Loss: 0.39643250675776526\n",
      "Epoch 207, Loss: 0.3964930942121623\n",
      "Epoch 208, Loss: 0.39639324399958137\n",
      "Epoch 209, Loss: 0.3955064184847154\n",
      "Epoch 210, Loss: 0.39452575453150723\n",
      "Epoch 211, Loss: 0.39368913497985003\n",
      "Epoch 212, Loss: 0.3933823163067642\n",
      "Epoch 213, Loss: 0.39349156481658204\n",
      "Epoch 214, Loss: 0.3935661219599367\n",
      "Epoch 215, Loss: 0.39367346473913384\n",
      "Epoch 216, Loss: 0.39331846507441093\n",
      "Epoch 217, Loss: 0.3926116397652825\n",
      "Epoch 218, Loss: 0.3914591466067266\n",
      "Epoch 219, Loss: 0.390498636787956\n",
      "Epoch 220, Loss: 0.3901647717603556\n",
      "Epoch 221, Loss: 0.3901772412392475\n",
      "Epoch 222, Loss: 0.39068488615654007\n",
      "Epoch 223, Loss: 0.391130882752928\n",
      "Epoch 224, Loss: 0.39077088492892215\n",
      "Epoch 225, Loss: 0.3895920256122673\n",
      "Epoch 226, Loss: 0.38806131224313023\n",
      "Epoch 227, Loss: 0.3875160859983766\n",
      "Epoch 228, Loss: 0.38731236606513714\n",
      "Epoch 229, Loss: 0.3874846493849134\n",
      "Epoch 230, Loss: 0.3879230896731811\n",
      "Epoch 231, Loss: 0.3874980511154881\n",
      "Epoch 232, Loss: 0.3870823432114458\n",
      "Epoch 233, Loss: 0.386142706273955\n",
      "Epoch 234, Loss: 0.38546520863960126\n",
      "Epoch 235, Loss: 0.38444660729300284\n",
      "Epoch 236, Loss: 0.38396599260881425\n",
      "Epoch 237, Loss: 0.3837427009360543\n",
      "Epoch 238, Loss: 0.38365351489115107\n",
      "Epoch 239, Loss: 0.38414943558506115\n",
      "Epoch 240, Loss: 0.3864067051719394\n",
      "Epoch 241, Loss: 0.3889593278674321\n",
      "Epoch 242, Loss: 0.3876353681137843\n",
      "Epoch 243, Loss: 0.38243578845577963\n",
      "Epoch 244, Loss: 0.3820153519768593\n",
      "Epoch 245, Loss: 0.3847549746825686\n",
      "Epoch 246, Loss: 0.38382711052056867\n",
      "Epoch 247, Loss: 0.3802333087643624\n",
      "Epoch 248, Loss: 0.38200359127343797\n",
      "Epoch 249, Loss: 0.38394784918574004\n",
      "Epoch 250, Loss: 0.38186830739526484\n",
      "Epoch 251, Loss: 0.3788289650034309\n",
      "Epoch 252, Loss: 0.38199368313614473\n",
      "Epoch 253, Loss: 0.38172965753611837\n",
      "Epoch 254, Loss: 0.3789432350277125\n",
      "Epoch 255, Loss: 0.3785564735188607\n",
      "Epoch 256, Loss: 0.3821530793380002\n",
      "Epoch 257, Loss: 0.37899739850341607\n",
      "Epoch 258, Loss: 0.3775976333929915\n",
      "Epoch 259, Loss: 0.37829836031865716\n",
      "Epoch 260, Loss: 0.3787076960754965\n",
      "Epoch 261, Loss: 0.3755894439105105\n",
      "Epoch 262, Loss: 0.37634629734504094\n",
      "Epoch 263, Loss: 0.37619586840332564\n",
      "Epoch 264, Loss: 0.37648455497704153\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2442240815290223\n",
      "Test R^2 score: 0.3557638451482005\n",
      "Num of epochs: 265\n",
      "Epoch 1, Loss: 0.5996443896678555\n",
      "Epoch 2, Loss: 0.5979091881961093\n",
      "Epoch 3, Loss: 0.5962459155008779\n",
      "Epoch 4, Loss: 0.5946231244715009\n",
      "Epoch 5, Loss: 0.5931334305818297\n",
      "Epoch 6, Loss: 0.5917688495307506\n",
      "Epoch 7, Loss: 0.5904411675702799\n",
      "Epoch 8, Loss: 0.5891407699594899\n",
      "Epoch 9, Loss: 0.5878672294143694\n",
      "Epoch 10, Loss: 0.5866219401333607\n",
      "Epoch 11, Loss: 0.585405591495685\n",
      "Epoch 12, Loss: 0.5842180581916413\n",
      "Epoch 13, Loss: 0.5830680522116634\n",
      "Epoch 14, Loss: 0.5819612755411454\n",
      "Epoch 15, Loss: 0.5808659864202038\n",
      "Epoch 16, Loss: 0.5797899602941893\n",
      "Epoch 17, Loss: 0.5787636348279955\n",
      "Epoch 18, Loss: 0.5777652497517695\n",
      "Epoch 19, Loss: 0.5768217398213135\n",
      "Epoch 20, Loss: 0.5758695682197428\n",
      "Epoch 21, Loss: 0.574919888886542\n",
      "Epoch 22, Loss: 0.5739834361693686\n",
      "Epoch 23, Loss: 0.5730779045248712\n",
      "Epoch 24, Loss: 0.5721806537962373\n",
      "Epoch 25, Loss: 0.571293131495926\n",
      "Epoch 26, Loss: 0.5703810036682064\n",
      "Epoch 27, Loss: 0.5694678335374509\n",
      "Epoch 28, Loss: 0.568585983143651\n",
      "Epoch 29, Loss: 0.567714836946618\n",
      "Epoch 30, Loss: 0.5668441658087895\n",
      "Epoch 31, Loss: 0.5659890841941169\n",
      "Epoch 32, Loss: 0.5651519567670901\n",
      "Epoch 33, Loss: 0.5643203473586416\n",
      "Epoch 34, Loss: 0.5635019491681538\n",
      "Epoch 35, Loss: 0.5627228242556434\n",
      "Epoch 36, Loss: 0.5619364935859881\n",
      "Epoch 37, Loss: 0.5611202218661075\n",
      "Epoch 38, Loss: 0.5602499677291242\n",
      "Epoch 39, Loss: 0.5593230281959615\n",
      "Epoch 40, Loss: 0.5583095227568564\n",
      "Epoch 41, Loss: 0.5571975866272331\n",
      "Epoch 42, Loss: 0.5559732552363479\n",
      "Epoch 43, Loss: 0.5546518233740146\n",
      "Epoch 44, Loss: 0.5532575900974541\n",
      "Epoch 45, Loss: 0.5517678859094971\n",
      "Epoch 46, Loss: 0.5501652241835954\n",
      "Epoch 47, Loss: 0.5482924484192083\n",
      "Epoch 48, Loss: 0.5462942309334549\n",
      "Epoch 49, Loss: 0.5443113181162359\n",
      "Epoch 50, Loss: 0.5426173273566535\n",
      "Epoch 51, Loss: 0.5412714109084277\n",
      "Epoch 52, Loss: 0.5399283490505564\n",
      "Epoch 53, Loss: 0.5379401146111737\n",
      "Epoch 54, Loss: 0.5352722098024586\n",
      "Epoch 55, Loss: 0.5323904922427416\n",
      "Epoch 56, Loss: 0.5295840395820924\n",
      "Epoch 57, Loss: 0.5269047640700395\n",
      "Epoch 58, Loss: 0.5242784207489352\n",
      "Epoch 59, Loss: 0.5217071514548367\n",
      "Epoch 60, Loss: 0.5194512786121\n",
      "Epoch 61, Loss: 0.5179651792469333\n",
      "Epoch 62, Loss: 0.5174135342293894\n",
      "Epoch 63, Loss: 0.5168223783467236\n",
      "Epoch 64, Loss: 0.5152846571396529\n",
      "Epoch 65, Loss: 0.5131702366913602\n",
      "Epoch 66, Loss: 0.5112568466828641\n",
      "Epoch 67, Loss: 0.509663772638827\n",
      "Epoch 68, Loss: 0.508012292146273\n",
      "Epoch 69, Loss: 0.5061482668724787\n",
      "Epoch 70, Loss: 0.5042567845135411\n",
      "Epoch 71, Loss: 0.5027322622401519\n",
      "Epoch 72, Loss: 0.5017245770558261\n",
      "Epoch 73, Loss: 0.5007303982772372\n",
      "Epoch 74, Loss: 0.49928896235626297\n",
      "Epoch 75, Loss: 0.49768082873912683\n",
      "Epoch 76, Loss: 0.4962838176763919\n",
      "Epoch 77, Loss: 0.4949163597660726\n",
      "Epoch 78, Loss: 0.49333417621209763\n",
      "Epoch 79, Loss: 0.49162775332884756\n",
      "Epoch 80, Loss: 0.49013025766367735\n",
      "Epoch 81, Loss: 0.4889295622795579\n",
      "Epoch 82, Loss: 0.48766967620505475\n",
      "Epoch 83, Loss: 0.48621241407092813\n",
      "Epoch 84, Loss: 0.4847898552531111\n",
      "Epoch 85, Loss: 0.483505761148712\n",
      "Epoch 86, Loss: 0.482200788115811\n",
      "Epoch 87, Loss: 0.48077995022414255\n",
      "Epoch 88, Loss: 0.47939885429504825\n",
      "Epoch 89, Loss: 0.4781892247167039\n",
      "Epoch 90, Loss: 0.4769416770217259\n",
      "Epoch 91, Loss: 0.47559157726539236\n",
      "Epoch 92, Loss: 0.4743041638747514\n",
      "Epoch 93, Loss: 0.47299815650766186\n",
      "Epoch 94, Loss: 0.4715586599821825\n",
      "Epoch 95, Loss: 0.47013141212766385\n",
      "Epoch 96, Loss: 0.46878857453890393\n",
      "Epoch 97, Loss: 0.4674004359734591\n",
      "Epoch 98, Loss: 0.46600055206556734\n",
      "Epoch 99, Loss: 0.46464377196873136\n",
      "Epoch 100, Loss: 0.4631769928209491\n",
      "Epoch 101, Loss: 0.46169822763446106\n",
      "Epoch 102, Loss: 0.46023756969912116\n",
      "Epoch 103, Loss: 0.45871601781831195\n",
      "Epoch 104, Loss: 0.45722786024480605\n",
      "Epoch 105, Loss: 0.45570042837448027\n",
      "Epoch 106, Loss: 0.4541460897293089\n",
      "Epoch 107, Loss: 0.4527200500749785\n",
      "Epoch 108, Loss: 0.4513081596597935\n",
      "Epoch 109, Loss: 0.44997291284735497\n",
      "Epoch 110, Loss: 0.44854561502632706\n",
      "Epoch 111, Loss: 0.44716729828250473\n",
      "Epoch 112, Loss: 0.44579097072674045\n",
      "Epoch 113, Loss: 0.44458783733168394\n",
      "Epoch 114, Loss: 0.44356844505700227\n",
      "Epoch 115, Loss: 0.4428807334313442\n",
      "Epoch 116, Loss: 0.4425009260329562\n",
      "Epoch 117, Loss: 0.44235205806582406\n",
      "Epoch 118, Loss: 0.4420979068695768\n",
      "Epoch 119, Loss: 0.44156598264558633\n",
      "Epoch 120, Loss: 0.44079371800143524\n",
      "Epoch 121, Loss: 0.43992591009252363\n",
      "Epoch 122, Loss: 0.4391202386380227\n",
      "Epoch 123, Loss: 0.4383903027755021\n",
      "Epoch 124, Loss: 0.43764885005122156\n",
      "Epoch 125, Loss: 0.43700703027010995\n",
      "Epoch 126, Loss: 0.436435989393657\n",
      "Epoch 127, Loss: 0.43577099494999777\n",
      "Epoch 128, Loss: 0.4350202995255487\n",
      "Epoch 129, Loss: 0.43437408131564026\n",
      "Epoch 130, Loss: 0.43376252609766885\n",
      "Epoch 131, Loss: 0.4331494882054604\n",
      "Epoch 132, Loss: 0.43256229715462413\n",
      "Epoch 133, Loss: 0.432021408934718\n",
      "Epoch 134, Loss: 0.4312911711956445\n",
      "Epoch 135, Loss: 0.4305651804231051\n",
      "Epoch 136, Loss: 0.4300382223163512\n",
      "Epoch 137, Loss: 0.42967156467366197\n",
      "Epoch 138, Loss: 0.42893136859431863\n",
      "Epoch 139, Loss: 0.42815477796702034\n",
      "Epoch 140, Loss: 0.42751440723859624\n",
      "Epoch 141, Loss: 0.42696471621736737\n",
      "Epoch 142, Loss: 0.4265351401976189\n",
      "Epoch 143, Loss: 0.42602647491579426\n",
      "Epoch 144, Loss: 0.4253908870195295\n",
      "Epoch 145, Loss: 0.42472024714155726\n",
      "Epoch 146, Loss: 0.4239687883960917\n",
      "Epoch 147, Loss: 0.42345411964824153\n",
      "Epoch 148, Loss: 0.42303325458555235\n",
      "Epoch 149, Loss: 0.422402528912793\n",
      "Epoch 150, Loss: 0.421745898661545\n",
      "Epoch 151, Loss: 0.42124805843347296\n",
      "Epoch 152, Loss: 0.4208324230140182\n",
      "Epoch 153, Loss: 0.4204194602867191\n",
      "Epoch 154, Loss: 0.41991240024966886\n",
      "Epoch 155, Loss: 0.41941357388307615\n",
      "Epoch 156, Loss: 0.41899773685417696\n",
      "Epoch 157, Loss: 0.4185840320491459\n",
      "Epoch 158, Loss: 0.4181695437974095\n",
      "Epoch 159, Loss: 0.4177584966027198\n",
      "Epoch 160, Loss: 0.417342581481326\n",
      "Epoch 161, Loss: 0.41691383143786453\n",
      "Epoch 162, Loss: 0.41650785956345726\n",
      "Epoch 163, Loss: 0.41611001461728053\n",
      "Epoch 164, Loss: 0.41573098344373227\n",
      "Epoch 165, Loss: 0.4153657951058278\n",
      "Epoch 166, Loss: 0.4150276631304482\n",
      "Epoch 167, Loss: 0.4147846474365758\n",
      "Epoch 168, Loss: 0.41461479492555237\n",
      "Epoch 169, Loss: 0.4144129979072019\n",
      "Epoch 170, Loss: 0.4138733773806006\n",
      "Epoch 171, Loss: 0.4131123058659949\n",
      "Epoch 172, Loss: 0.4126381577696747\n",
      "Epoch 173, Loss: 0.41259344877546833\n",
      "Epoch 174, Loss: 0.41236536834467596\n",
      "Epoch 175, Loss: 0.4117184633547167\n",
      "Epoch 176, Loss: 0.4111115547537916\n",
      "Epoch 177, Loss: 0.4109472186603729\n",
      "Epoch 178, Loss: 0.4108180383726491\n",
      "Epoch 179, Loss: 0.41031296778679105\n",
      "Epoch 180, Loss: 0.40973727307271024\n",
      "Epoch 181, Loss: 0.4094279225917526\n",
      "Epoch 182, Loss: 0.40931116873198026\n",
      "Epoch 183, Loss: 0.4090012955831606\n",
      "Epoch 184, Loss: 0.4085450816299493\n",
      "Epoch 185, Loss: 0.40803836618630746\n",
      "Epoch 186, Loss: 0.40763130474274156\n",
      "Epoch 187, Loss: 0.4074060424186176\n",
      "Epoch 188, Loss: 0.4072934834406432\n",
      "Epoch 189, Loss: 0.4070908025129888\n",
      "Epoch 190, Loss: 0.4067175265692044\n",
      "Epoch 191, Loss: 0.40608764118386226\n",
      "Epoch 192, Loss: 0.4056046568672805\n",
      "Epoch 193, Loss: 0.4053642446977336\n",
      "Epoch 194, Loss: 0.40521412610748786\n",
      "Epoch 195, Loss: 0.40479627347802744\n",
      "Epoch 196, Loss: 0.40424954786965417\n",
      "Epoch 197, Loss: 0.40376907026055786\n",
      "Epoch 198, Loss: 0.4034349772686908\n",
      "Epoch 199, Loss: 0.40318918752132343\n",
      "Epoch 200, Loss: 0.40294652063264186\n",
      "Epoch 201, Loss: 0.4025869837947924\n",
      "Epoch 202, Loss: 0.4021883358831841\n",
      "Epoch 203, Loss: 0.4017796126159691\n",
      "Epoch 204, Loss: 0.40144119137345635\n",
      "Epoch 205, Loss: 0.40106165410886363\n",
      "Epoch 206, Loss: 0.4007712067355128\n",
      "Epoch 207, Loss: 0.4004718791111608\n",
      "Epoch 208, Loss: 0.4003073256766443\n",
      "Epoch 209, Loss: 0.4002939991543368\n",
      "Epoch 210, Loss: 0.40053068363030303\n",
      "Epoch 211, Loss: 0.4010354780570114\n",
      "Epoch 212, Loss: 0.4003168363730871\n",
      "Epoch 213, Loss: 0.39897523384386174\n",
      "Epoch 214, Loss: 0.39865164518376883\n",
      "Epoch 215, Loss: 0.3991686713056194\n",
      "Epoch 216, Loss: 0.3983974623665843\n",
      "Epoch 217, Loss: 0.39756835310821814\n",
      "Epoch 218, Loss: 0.3977168053946422\n",
      "Epoch 219, Loss: 0.39759902992091817\n",
      "Epoch 220, Loss: 0.3967277832024489\n",
      "Epoch 221, Loss: 0.39635196598292527\n",
      "Epoch 222, Loss: 0.3963534134178005\n",
      "Epoch 223, Loss: 0.39592154256191814\n",
      "Epoch 224, Loss: 0.395297618631099\n",
      "Epoch 225, Loss: 0.3950901604920587\n",
      "Epoch 226, Loss: 0.39485189419654704\n",
      "Epoch 227, Loss: 0.39463519624956744\n",
      "Epoch 228, Loss: 0.39412265808469515\n",
      "Epoch 229, Loss: 0.39379126014697907\n",
      "Epoch 230, Loss: 0.39359924972829025\n",
      "Epoch 231, Loss: 0.3932406021712202\n",
      "Epoch 232, Loss: 0.39309752915653173\n",
      "Epoch 233, Loss: 0.3927480605021083\n",
      "Epoch 234, Loss: 0.39242860214539876\n",
      "Epoch 235, Loss: 0.39204225928370273\n",
      "Epoch 236, Loss: 0.3916546412238367\n",
      "Epoch 237, Loss: 0.39119998575651305\n",
      "Epoch 238, Loss: 0.39093758474054796\n",
      "Epoch 239, Loss: 0.3904526521036511\n",
      "Epoch 240, Loss: 0.3901210204058675\n",
      "Epoch 241, Loss: 0.3899159290102651\n",
      "Epoch 242, Loss: 0.3895134560583052\n",
      "Epoch 243, Loss: 0.389368783892003\n",
      "Epoch 244, Loss: 0.3895327173932986\n",
      "Epoch 245, Loss: 0.39038028681213877\n",
      "Epoch 246, Loss: 0.39148017733364976\n",
      "Epoch 247, Loss: 0.3909950982649989\n",
      "Epoch 248, Loss: 0.3881272952922578\n",
      "Epoch 249, Loss: 0.3879140817977442\n",
      "Epoch 250, Loss: 0.3889678901325123\n",
      "Epoch 251, Loss: 0.3874515756990748\n",
      "Epoch 252, Loss: 0.3866361664726745\n",
      "Epoch 253, Loss: 0.38701704831608386\n",
      "Epoch 254, Loss: 0.38668258574960634\n",
      "Epoch 255, Loss: 0.38576138605556654\n",
      "Epoch 256, Loss: 0.38501059774576174\n",
      "Epoch 257, Loss: 0.3853988471508352\n",
      "Epoch 258, Loss: 0.3845717430572483\n",
      "Epoch 259, Loss: 0.3840652520350412\n",
      "Epoch 260, Loss: 0.38350669043821173\n",
      "Epoch 261, Loss: 0.38332925678587243\n",
      "Epoch 262, Loss: 0.38282236748259013\n",
      "Epoch 263, Loss: 0.382163841157814\n",
      "Epoch 264, Loss: 0.38188305732355693\n",
      "Epoch 265, Loss: 0.38155926683510427\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.23562943595759808\n",
      "Test R^2 score: 0.397364946681645\n",
      "Num of epochs: 266\n",
      "Epoch 1, Loss: 0.5575244512456157\n",
      "Epoch 2, Loss: 0.5571422792613347\n",
      "Epoch 3, Loss: 0.5568271257605794\n",
      "Epoch 4, Loss: 0.556580550315004\n",
      "Epoch 5, Loss: 0.5564145884093925\n",
      "Epoch 6, Loss: 0.5562997945721714\n",
      "Epoch 7, Loss: 0.5562192694072569\n",
      "Epoch 8, Loss: 0.5561717953516446\n",
      "Epoch 9, Loss: 0.556139134492153\n",
      "Epoch 10, Loss: 0.556112098744841\n",
      "Epoch 11, Loss: 0.5560894830962879\n",
      "Epoch 12, Loss: 0.5560659822121495\n",
      "Epoch 13, Loss: 0.5560351374692919\n",
      "Epoch 14, Loss: 0.5559872456724053\n",
      "Epoch 15, Loss: 0.5559247952189434\n",
      "Epoch 16, Loss: 0.5558447250826909\n",
      "Epoch 17, Loss: 0.5557448021769643\n",
      "Epoch 18, Loss: 0.5556198665695\n",
      "Epoch 19, Loss: 0.5554668163582455\n",
      "Epoch 20, Loss: 0.5552774166859571\n",
      "Epoch 21, Loss: 0.5550427977926019\n",
      "Epoch 22, Loss: 0.5547538502728463\n",
      "Epoch 23, Loss: 0.5543989586195585\n",
      "Epoch 24, Loss: 0.5539651384780886\n",
      "Epoch 25, Loss: 0.5534340571550047\n",
      "Epoch 26, Loss: 0.5527881016584558\n",
      "Epoch 27, Loss: 0.5520149374526773\n",
      "Epoch 28, Loss: 0.5510971840604643\n",
      "Epoch 29, Loss: 0.5500179168643885\n",
      "Epoch 30, Loss: 0.5487778664380297\n",
      "Epoch 31, Loss: 0.547357972635734\n",
      "Epoch 32, Loss: 0.5457250493751017\n",
      "Epoch 33, Loss: 0.54381081580833\n",
      "Epoch 34, Loss: 0.5415232511320703\n",
      "Epoch 35, Loss: 0.5388124687726686\n",
      "Epoch 36, Loss: 0.5356182971744157\n",
      "Epoch 37, Loss: 0.531894909478227\n",
      "Epoch 38, Loss: 0.5277631434146145\n",
      "Epoch 39, Loss: 0.5234367028984719\n",
      "Epoch 40, Loss: 0.5192661039034374\n",
      "Epoch 41, Loss: 0.5160512895986941\n",
      "Epoch 42, Loss: 0.5144579134800074\n",
      "Epoch 43, Loss: 0.5134578592602161\n",
      "Epoch 44, Loss: 0.5112941523748945\n",
      "Epoch 45, Loss: 0.5081988112364058\n",
      "Epoch 46, Loss: 0.5051589004347957\n",
      "Epoch 47, Loss: 0.5029484717555482\n",
      "Epoch 48, Loss: 0.5015584975228492\n",
      "Epoch 49, Loss: 0.5003821581467403\n",
      "Epoch 50, Loss: 0.49892209511435126\n",
      "Epoch 51, Loss: 0.49694104565418334\n",
      "Epoch 52, Loss: 0.49442982409443686\n",
      "Epoch 53, Loss: 0.49160150430199295\n",
      "Epoch 54, Loss: 0.488823475180775\n",
      "Epoch 55, Loss: 0.48642908909669896\n",
      "Epoch 56, Loss: 0.48442506531421964\n",
      "Epoch 57, Loss: 0.48244187471887395\n",
      "Epoch 58, Loss: 0.47986647221370166\n",
      "Epoch 59, Loss: 0.47729105057573235\n",
      "Epoch 60, Loss: 0.47478142904593224\n",
      "Epoch 61, Loss: 0.4726688919268328\n",
      "Epoch 62, Loss: 0.4709674045811069\n",
      "Epoch 63, Loss: 0.469639585694435\n",
      "Epoch 64, Loss: 0.46851894724159215\n",
      "Epoch 65, Loss: 0.4672433800593209\n",
      "Epoch 66, Loss: 0.4660758830887508\n",
      "Epoch 67, Loss: 0.4643498690134149\n",
      "Epoch 68, Loss: 0.4627930904596752\n",
      "Epoch 69, Loss: 0.4613063274146822\n",
      "Epoch 70, Loss: 0.459729810825281\n",
      "Epoch 71, Loss: 0.4581491866238901\n",
      "Epoch 72, Loss: 0.4567455637809824\n",
      "Epoch 73, Loss: 0.4555371306765268\n",
      "Epoch 74, Loss: 0.4544714784842594\n",
      "Epoch 75, Loss: 0.4535356173844201\n",
      "Epoch 76, Loss: 0.45276466380216507\n",
      "Epoch 77, Loss: 0.45214601520194325\n",
      "Epoch 78, Loss: 0.45161185341374604\n",
      "Epoch 79, Loss: 0.4510343928407656\n",
      "Epoch 80, Loss: 0.4504385599267059\n",
      "Epoch 81, Loss: 0.4497390884753054\n",
      "Epoch 82, Loss: 0.44905102127790725\n",
      "Epoch 83, Loss: 0.4484128440166325\n",
      "Epoch 84, Loss: 0.4476898546903857\n",
      "Epoch 85, Loss: 0.44694847623277484\n",
      "Epoch 86, Loss: 0.4461783808182271\n",
      "Epoch 87, Loss: 0.4453202799067264\n",
      "Epoch 88, Loss: 0.4445126360329783\n",
      "Epoch 89, Loss: 0.44375070450955195\n",
      "Epoch 90, Loss: 0.44299059078996517\n",
      "Epoch 91, Loss: 0.4422711027123212\n",
      "Epoch 92, Loss: 0.4415449582804844\n",
      "Epoch 93, Loss: 0.440833319124367\n",
      "Epoch 94, Loss: 0.44015067793379975\n",
      "Epoch 95, Loss: 0.4394743172515977\n",
      "Epoch 96, Loss: 0.4387987478187937\n",
      "Epoch 97, Loss: 0.4381181403206721\n",
      "Epoch 98, Loss: 0.43745512391587577\n",
      "Epoch 99, Loss: 0.43680428638014435\n",
      "Epoch 100, Loss: 0.43616764665781915\n",
      "Epoch 101, Loss: 0.4355218478141355\n",
      "Epoch 102, Loss: 0.4348741133818726\n",
      "Epoch 103, Loss: 0.4342449727741952\n",
      "Epoch 104, Loss: 0.4336461903245849\n",
      "Epoch 105, Loss: 0.433041968953577\n",
      "Epoch 106, Loss: 0.43243269936953665\n",
      "Epoch 107, Loss: 0.43181668656605926\n",
      "Epoch 108, Loss: 0.4312082774946495\n",
      "Epoch 109, Loss: 0.43058905953963644\n",
      "Epoch 110, Loss: 0.42994214228682864\n",
      "Epoch 111, Loss: 0.42930353522232423\n",
      "Epoch 112, Loss: 0.4286608134449029\n",
      "Epoch 113, Loss: 0.4280263870719438\n",
      "Epoch 114, Loss: 0.4274079806301219\n",
      "Epoch 115, Loss: 0.4267801588828999\n",
      "Epoch 116, Loss: 0.42612198660902095\n",
      "Epoch 117, Loss: 0.425452201456993\n",
      "Epoch 118, Loss: 0.4247893056605894\n",
      "Epoch 119, Loss: 0.4241316099925038\n",
      "Epoch 120, Loss: 0.423461650145628\n",
      "Epoch 121, Loss: 0.4227931310442172\n",
      "Epoch 122, Loss: 0.4221209233137693\n",
      "Epoch 123, Loss: 0.4214323865559638\n",
      "Epoch 124, Loss: 0.42077670361555486\n",
      "Epoch 125, Loss: 0.4201365432288455\n",
      "Epoch 126, Loss: 0.41950382448483176\n",
      "Epoch 127, Loss: 0.41891324647484013\n",
      "Epoch 128, Loss: 0.41834594961471333\n",
      "Epoch 129, Loss: 0.4177679845339034\n",
      "Epoch 130, Loss: 0.4170720294210707\n",
      "Epoch 131, Loss: 0.41634563555967297\n",
      "Epoch 132, Loss: 0.4157425248190298\n",
      "Epoch 133, Loss: 0.4152477861537173\n",
      "Epoch 134, Loss: 0.4147623373775417\n",
      "Epoch 135, Loss: 0.4140467730720366\n",
      "Epoch 136, Loss: 0.41335511511981665\n",
      "Epoch 137, Loss: 0.41278523351471436\n",
      "Epoch 138, Loss: 0.41226592864313993\n",
      "Epoch 139, Loss: 0.4116767311732061\n",
      "Epoch 140, Loss: 0.4109432299834537\n",
      "Epoch 141, Loss: 0.4102901240259414\n",
      "Epoch 142, Loss: 0.4097375094620411\n",
      "Epoch 143, Loss: 0.40915730854463594\n",
      "Epoch 144, Loss: 0.4085694453521664\n",
      "Epoch 145, Loss: 0.4079486656139556\n",
      "Epoch 146, Loss: 0.40732620813125847\n",
      "Epoch 147, Loss: 0.4067533932153351\n",
      "Epoch 148, Loss: 0.40621904108486195\n",
      "Epoch 149, Loss: 0.40570907159417985\n",
      "Epoch 150, Loss: 0.40522635312779076\n",
      "Epoch 151, Loss: 0.4048410706043099\n",
      "Epoch 152, Loss: 0.40440374611233504\n",
      "Epoch 153, Loss: 0.40381370458170834\n",
      "Epoch 154, Loss: 0.4029368686082336\n",
      "Epoch 155, Loss: 0.402197913247722\n",
      "Epoch 156, Loss: 0.4017780549212437\n",
      "Epoch 157, Loss: 0.4015909578206855\n",
      "Epoch 158, Loss: 0.40129278008406183\n",
      "Epoch 159, Loss: 0.40035543519736694\n",
      "Epoch 160, Loss: 0.3995650549332102\n",
      "Epoch 161, Loss: 0.3991933273312953\n",
      "Epoch 162, Loss: 0.39895549462738605\n",
      "Epoch 163, Loss: 0.3984990539874595\n",
      "Epoch 164, Loss: 0.3977455226315312\n",
      "Epoch 165, Loss: 0.3970806355032817\n",
      "Epoch 166, Loss: 0.3967402154224344\n",
      "Epoch 167, Loss: 0.39647381397331866\n",
      "Epoch 168, Loss: 0.39590025846328836\n",
      "Epoch 169, Loss: 0.39525633929439163\n",
      "Epoch 170, Loss: 0.39473922837523245\n",
      "Epoch 171, Loss: 0.39428578662945696\n",
      "Epoch 172, Loss: 0.3938878166367667\n",
      "Epoch 173, Loss: 0.3935424007646544\n",
      "Epoch 174, Loss: 0.3931803851996051\n",
      "Epoch 175, Loss: 0.3928890989360804\n",
      "Epoch 176, Loss: 0.3925622965340405\n",
      "Epoch 177, Loss: 0.3922268638765446\n",
      "Epoch 178, Loss: 0.3915490093784225\n",
      "Epoch 179, Loss: 0.3907477948778818\n",
      "Epoch 180, Loss: 0.3901238278203611\n",
      "Epoch 181, Loss: 0.38991577614486\n",
      "Epoch 182, Loss: 0.3897396927290953\n",
      "Epoch 183, Loss: 0.38950085055781136\n",
      "Epoch 184, Loss: 0.3895800537678517\n",
      "Epoch 185, Loss: 0.3894586698544867\n",
      "Epoch 186, Loss: 0.38872031288620934\n",
      "Epoch 187, Loss: 0.3873927860220506\n",
      "Epoch 188, Loss: 0.387356011495528\n",
      "Epoch 189, Loss: 0.3872364509248889\n",
      "Epoch 190, Loss: 0.38660747198633916\n",
      "Epoch 191, Loss: 0.3866202296367565\n",
      "Epoch 192, Loss: 0.38602300152411706\n",
      "Epoch 193, Loss: 0.38525758071906985\n",
      "Epoch 194, Loss: 0.385140831505236\n",
      "Epoch 195, Loss: 0.38466693367665067\n",
      "Epoch 196, Loss: 0.3843680520709047\n",
      "Epoch 197, Loss: 0.38398985912174877\n",
      "Epoch 198, Loss: 0.3836510096931072\n",
      "Epoch 199, Loss: 0.38324246296995695\n",
      "Epoch 200, Loss: 0.3828996053194018\n",
      "Epoch 201, Loss: 0.38270699740477615\n",
      "Epoch 202, Loss: 0.38255215569744977\n",
      "Epoch 203, Loss: 0.38257877844454186\n",
      "Epoch 204, Loss: 0.38360461202186885\n",
      "Epoch 205, Loss: 0.383527904693901\n",
      "Epoch 206, Loss: 0.38244414610495214\n",
      "Epoch 207, Loss: 0.38094790481239554\n",
      "Epoch 208, Loss: 0.38054103752080604\n",
      "Epoch 209, Loss: 0.38155350642497066\n",
      "Epoch 210, Loss: 0.3812825908176148\n",
      "Epoch 211, Loss: 0.3794975190075278\n",
      "Epoch 212, Loss: 0.37936395352540864\n",
      "Epoch 213, Loss: 0.3796320384142129\n",
      "Epoch 214, Loss: 0.37927915961934233\n",
      "Epoch 215, Loss: 0.3782541621900089\n",
      "Epoch 216, Loss: 0.378156510135721\n",
      "Epoch 217, Loss: 0.3779495194625979\n",
      "Epoch 218, Loss: 0.37753878937310265\n",
      "Epoch 219, Loss: 0.37726021151945194\n",
      "Epoch 220, Loss: 0.3764764212523944\n",
      "Epoch 221, Loss: 0.3762993157976891\n",
      "Epoch 222, Loss: 0.3758641062414746\n",
      "Epoch 223, Loss: 0.3757667451466129\n",
      "Epoch 224, Loss: 0.3756703306256099\n",
      "Epoch 225, Loss: 0.37530435688291136\n",
      "Epoch 226, Loss: 0.37548131651055566\n",
      "Epoch 227, Loss: 0.3753172803791919\n",
      "Epoch 228, Loss: 0.3750148809977201\n",
      "Epoch 229, Loss: 0.3741887775435652\n",
      "Epoch 230, Loss: 0.3736103256485981\n",
      "Epoch 231, Loss: 0.3733481344130178\n",
      "Epoch 232, Loss: 0.37275926377741464\n",
      "Epoch 233, Loss: 0.37237044116684154\n",
      "Epoch 234, Loss: 0.37281294673179854\n",
      "Epoch 235, Loss: 0.37406847411239524\n",
      "Epoch 236, Loss: 0.37504791907274937\n",
      "Epoch 237, Loss: 0.3733700855009598\n",
      "Epoch 238, Loss: 0.3709107801202674\n",
      "Epoch 239, Loss: 0.3713224007750984\n",
      "Epoch 240, Loss: 0.3732982008587421\n",
      "Epoch 241, Loss: 0.37177152476304776\n",
      "Epoch 242, Loss: 0.37005284537716315\n",
      "Epoch 243, Loss: 0.37125066150259556\n",
      "Epoch 244, Loss: 0.37015561430245686\n",
      "Epoch 245, Loss: 0.36939890469495584\n",
      "Epoch 246, Loss: 0.3689245772504934\n",
      "Epoch 247, Loss: 0.36885342198300036\n",
      "Epoch 248, Loss: 0.36803134377734165\n",
      "Epoch 249, Loss: 0.3671539981249271\n",
      "Epoch 250, Loss: 0.36668576801281777\n",
      "Epoch 251, Loss: 0.3664663619325278\n",
      "Epoch 252, Loss: 0.36625451400891446\n",
      "Epoch 253, Loss: 0.36508689799625993\n",
      "Epoch 254, Loss: 0.36504695796030834\n",
      "Epoch 255, Loss: 0.36436544674083515\n",
      "Epoch 256, Loss: 0.3641739613255615\n",
      "Epoch 257, Loss: 0.36398401273867825\n",
      "Epoch 258, Loss: 0.36348499204278817\n",
      "Epoch 259, Loss: 0.3645169152205883\n",
      "Epoch 260, Loss: 0.3672903809585326\n",
      "Epoch 261, Loss: 0.36701906683373037\n",
      "Epoch 262, Loss: 0.3641291332252555\n",
      "Epoch 263, Loss: 0.36227719184618357\n",
      "Epoch 264, Loss: 0.3626808619663332\n",
      "Epoch 265, Loss: 0.36378247538841013\n",
      "Epoch 266, Loss: 0.36307103217250636\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2515087711331086\n",
      "Test R^2 score: 0.318403256115838\n",
      "Num of epochs: 267\n",
      "Epoch 1, Loss: 0.5620655660410968\n",
      "Epoch 2, Loss: 0.5614619478476205\n",
      "Epoch 3, Loss: 0.5609165527767931\n",
      "Epoch 4, Loss: 0.5603967392461722\n",
      "Epoch 5, Loss: 0.5599052398837747\n",
      "Epoch 6, Loss: 0.5594483087761457\n",
      "Epoch 7, Loss: 0.5590176074627837\n",
      "Epoch 8, Loss: 0.5586133033157845\n",
      "Epoch 9, Loss: 0.5582344927293161\n",
      "Epoch 10, Loss: 0.5578797852782971\n",
      "Epoch 11, Loss: 0.5575501623808048\n",
      "Epoch 12, Loss: 0.5572413097934473\n",
      "Epoch 13, Loss: 0.5569486067191731\n",
      "Epoch 14, Loss: 0.5566767898322477\n",
      "Epoch 15, Loss: 0.5564202926650521\n",
      "Epoch 16, Loss: 0.5561722508217686\n",
      "Epoch 17, Loss: 0.555919407533524\n",
      "Epoch 18, Loss: 0.5556578945896969\n",
      "Epoch 19, Loss: 0.5553827897958727\n",
      "Epoch 20, Loss: 0.555088220836039\n",
      "Epoch 21, Loss: 0.5547762786310725\n",
      "Epoch 22, Loss: 0.5544331195646646\n",
      "Epoch 23, Loss: 0.5540517467954922\n",
      "Epoch 24, Loss: 0.5536207499044881\n",
      "Epoch 25, Loss: 0.5531212089969012\n",
      "Epoch 26, Loss: 0.552538725932758\n",
      "Epoch 27, Loss: 0.551893585514228\n",
      "Epoch 28, Loss: 0.5511202749515683\n",
      "Epoch 29, Loss: 0.550208639539378\n",
      "Epoch 30, Loss: 0.5491551412589548\n",
      "Epoch 31, Loss: 0.54794718677917\n",
      "Epoch 32, Loss: 0.5465531900964155\n",
      "Epoch 33, Loss: 0.5449643682503528\n",
      "Epoch 34, Loss: 0.5431592319003498\n",
      "Epoch 35, Loss: 0.5411201954392819\n",
      "Epoch 36, Loss: 0.5388408702854585\n",
      "Epoch 37, Loss: 0.5362279977708531\n",
      "Epoch 38, Loss: 0.5331759044140686\n",
      "Epoch 39, Loss: 0.5295902860661791\n",
      "Epoch 40, Loss: 0.5253790815141757\n",
      "Epoch 41, Loss: 0.5204313984331483\n",
      "Epoch 42, Loss: 0.51466847331878\n",
      "Epoch 43, Loss: 0.5081362352618839\n",
      "Epoch 44, Loss: 0.5010958821340841\n",
      "Epoch 45, Loss: 0.4942606603006313\n",
      "Epoch 46, Loss: 0.48879742614229205\n",
      "Epoch 47, Loss: 0.4853281978762973\n",
      "Epoch 48, Loss: 0.4827604765780015\n",
      "Epoch 49, Loss: 0.4806741260031555\n",
      "Epoch 50, Loss: 0.47941117855159743\n",
      "Epoch 51, Loss: 0.4777194035602291\n",
      "Epoch 52, Loss: 0.4752583246751145\n",
      "Epoch 53, Loss: 0.47349584112989473\n",
      "Epoch 54, Loss: 0.47262049768336845\n",
      "Epoch 55, Loss: 0.47135474975999486\n",
      "Epoch 56, Loss: 0.47044389163059475\n",
      "Epoch 57, Loss: 0.4702059545894832\n",
      "Epoch 58, Loss: 0.4698715144923963\n",
      "Epoch 59, Loss: 0.4691429080955225\n",
      "Epoch 60, Loss: 0.46824159071764854\n",
      "Epoch 61, Loss: 0.46737373493081524\n",
      "Epoch 62, Loss: 0.4665544431007351\n",
      "Epoch 63, Loss: 0.46565968365110827\n",
      "Epoch 64, Loss: 0.46471452920441264\n",
      "Epoch 65, Loss: 0.4638962585976751\n",
      "Epoch 66, Loss: 0.4631996732683874\n",
      "Epoch 67, Loss: 0.46236923083098835\n",
      "Epoch 68, Loss: 0.46132901907889917\n",
      "Epoch 69, Loss: 0.46043038354984317\n",
      "Epoch 70, Loss: 0.4596769423993707\n",
      "Epoch 71, Loss: 0.45874822507093943\n",
      "Epoch 72, Loss: 0.4579927324037014\n",
      "Epoch 73, Loss: 0.4574872700686815\n",
      "Epoch 74, Loss: 0.4568605185586753\n",
      "Epoch 75, Loss: 0.4561870636055319\n",
      "Epoch 76, Loss: 0.45555932467763527\n",
      "Epoch 77, Loss: 0.4547488449767776\n",
      "Epoch 78, Loss: 0.4540188457667404\n",
      "Epoch 79, Loss: 0.4534065259926979\n",
      "Epoch 80, Loss: 0.45271689024923933\n",
      "Epoch 81, Loss: 0.45207210415490306\n",
      "Epoch 82, Loss: 0.451463695791189\n",
      "Epoch 83, Loss: 0.4507475174260549\n",
      "Epoch 84, Loss: 0.4501354318377674\n",
      "Epoch 85, Loss: 0.44947121201685436\n",
      "Epoch 86, Loss: 0.4488479742669279\n",
      "Epoch 87, Loss: 0.4482335939601671\n",
      "Epoch 88, Loss: 0.4476179043256175\n",
      "Epoch 89, Loss: 0.4470479677148364\n",
      "Epoch 90, Loss: 0.44645013552764157\n",
      "Epoch 91, Loss: 0.44589508162316305\n",
      "Epoch 92, Loss: 0.4453361906475831\n",
      "Epoch 93, Loss: 0.44474604199166984\n",
      "Epoch 94, Loss: 0.44422210241254323\n",
      "Epoch 95, Loss: 0.4436585681368647\n",
      "Epoch 96, Loss: 0.44315271140264084\n",
      "Epoch 97, Loss: 0.44258057676950974\n",
      "Epoch 98, Loss: 0.4419866139275012\n",
      "Epoch 99, Loss: 0.44140896754145664\n",
      "Epoch 100, Loss: 0.4408133077339572\n",
      "Epoch 101, Loss: 0.4402326663372523\n",
      "Epoch 102, Loss: 0.43966078196497294\n",
      "Epoch 103, Loss: 0.43909064708371087\n",
      "Epoch 104, Loss: 0.4385424863878625\n",
      "Epoch 105, Loss: 0.43800968045593575\n",
      "Epoch 106, Loss: 0.4374613404223166\n",
      "Epoch 107, Loss: 0.4369214524116078\n",
      "Epoch 108, Loss: 0.4363817842798091\n",
      "Epoch 109, Loss: 0.4358235152064405\n",
      "Epoch 110, Loss: 0.4352272297689171\n",
      "Epoch 111, Loss: 0.4346903431605388\n",
      "Epoch 112, Loss: 0.43433612128060967\n",
      "Epoch 113, Loss: 0.434357271587384\n",
      "Epoch 114, Loss: 0.43298625488027337\n",
      "Epoch 115, Loss: 0.43215928482776444\n",
      "Epoch 116, Loss: 0.4320313424356924\n",
      "Epoch 117, Loss: 0.4310099797642329\n",
      "Epoch 118, Loss: 0.4303648378433841\n",
      "Epoch 119, Loss: 0.4300846518593834\n",
      "Epoch 120, Loss: 0.42916904729658156\n",
      "Epoch 121, Loss: 0.42858846735575734\n",
      "Epoch 122, Loss: 0.4282307118405199\n",
      "Epoch 123, Loss: 0.42724979072061214\n",
      "Epoch 124, Loss: 0.4264296747568996\n",
      "Epoch 125, Loss: 0.4259117696355298\n",
      "Epoch 126, Loss: 0.42509094765800953\n",
      "Epoch 127, Loss: 0.4242958441384467\n",
      "Epoch 128, Loss: 0.4237806407855732\n",
      "Epoch 129, Loss: 0.4234141776218142\n",
      "Epoch 130, Loss: 0.4229229344841536\n",
      "Epoch 131, Loss: 0.42221029520791503\n",
      "Epoch 132, Loss: 0.42160956544896183\n",
      "Epoch 133, Loss: 0.4210969850490207\n",
      "Epoch 134, Loss: 0.42065806948962114\n",
      "Epoch 135, Loss: 0.4202801617516032\n",
      "Epoch 136, Loss: 0.419803070295255\n",
      "Epoch 137, Loss: 0.41930873375732314\n",
      "Epoch 138, Loss: 0.4187134854922211\n",
      "Epoch 139, Loss: 0.4181303977332797\n",
      "Epoch 140, Loss: 0.417600558671267\n",
      "Epoch 141, Loss: 0.41710105743374765\n",
      "Epoch 142, Loss: 0.4166220959030831\n",
      "Epoch 143, Loss: 0.4161590006738047\n",
      "Epoch 144, Loss: 0.41576494356253163\n",
      "Epoch 145, Loss: 0.41556972910570966\n",
      "Epoch 146, Loss: 0.4162547181122675\n",
      "Epoch 147, Loss: 0.41643377789227054\n",
      "Epoch 148, Loss: 0.4157246212132124\n",
      "Epoch 149, Loss: 0.41322360438969086\n",
      "Epoch 150, Loss: 0.41475164896112393\n",
      "Epoch 151, Loss: 0.41466665277348175\n",
      "Epoch 152, Loss: 0.4121185952551759\n",
      "Epoch 153, Loss: 0.41446568994054706\n",
      "Epoch 154, Loss: 0.4118074332461221\n",
      "Epoch 155, Loss: 0.4122330719495224\n",
      "Epoch 156, Loss: 0.4112977265720619\n",
      "Epoch 157, Loss: 0.4103953981294433\n",
      "Epoch 158, Loss: 0.41083708069209735\n",
      "Epoch 159, Loss: 0.4092917823656715\n",
      "Epoch 160, Loss: 0.4102381488231995\n",
      "Epoch 161, Loss: 0.4083661205726414\n",
      "Epoch 162, Loss: 0.4089602699208022\n",
      "Epoch 163, Loss: 0.40778395015709246\n",
      "Epoch 164, Loss: 0.40761540279536934\n",
      "Epoch 165, Loss: 0.4074429273423806\n",
      "Epoch 166, Loss: 0.40642582316418796\n",
      "Epoch 167, Loss: 0.40683467679828783\n",
      "Epoch 168, Loss: 0.40562251121098386\n",
      "Epoch 169, Loss: 0.4055612668015579\n",
      "Epoch 170, Loss: 0.40517738766741385\n",
      "Epoch 171, Loss: 0.404277008600537\n",
      "Epoch 172, Loss: 0.4043767546095361\n",
      "Epoch 173, Loss: 0.4035724286019996\n",
      "Epoch 174, Loss: 0.4031217885443938\n",
      "Epoch 175, Loss: 0.40303323056039836\n",
      "Epoch 176, Loss: 0.402231515581795\n",
      "Epoch 177, Loss: 0.4019289749052882\n",
      "Epoch 178, Loss: 0.4017477343031893\n",
      "Epoch 179, Loss: 0.40100300177261616\n",
      "Epoch 180, Loss: 0.4006272523908931\n",
      "Epoch 181, Loss: 0.40049606423581263\n",
      "Epoch 182, Loss: 0.3999248679947604\n",
      "Epoch 183, Loss: 0.3992973660813284\n",
      "Epoch 184, Loss: 0.3989872225601349\n",
      "Epoch 185, Loss: 0.3987748457005238\n",
      "Epoch 186, Loss: 0.3983705501780673\n",
      "Epoch 187, Loss: 0.39778645000884383\n",
      "Epoch 188, Loss: 0.397243693448728\n",
      "Epoch 189, Loss: 0.39684305738326625\n",
      "Epoch 190, Loss: 0.3965593088681461\n",
      "Epoch 191, Loss: 0.39634692811642935\n",
      "Epoch 192, Loss: 0.39614643295821816\n",
      "Epoch 193, Loss: 0.3960462507851849\n",
      "Epoch 194, Loss: 0.39585572940645164\n",
      "Epoch 195, Loss: 0.3956828919008164\n",
      "Epoch 196, Loss: 0.3951839863857609\n",
      "Epoch 197, Loss: 0.3946041757395544\n",
      "Epoch 198, Loss: 0.39393763688363637\n",
      "Epoch 199, Loss: 0.3934025813658986\n",
      "Epoch 200, Loss: 0.3930597340272211\n",
      "Epoch 201, Loss: 0.39289139352155533\n",
      "Epoch 202, Loss: 0.3928725244248085\n",
      "Epoch 203, Loss: 0.39312554145618017\n",
      "Epoch 204, Loss: 0.39385936671411487\n",
      "Epoch 205, Loss: 0.3942628835315882\n",
      "Epoch 206, Loss: 0.39397264347011907\n",
      "Epoch 207, Loss: 0.3918081105105475\n",
      "Epoch 208, Loss: 0.39080804350895815\n",
      "Epoch 209, Loss: 0.3914670261245523\n",
      "Epoch 210, Loss: 0.3919699023440512\n",
      "Epoch 211, Loss: 0.3912427595035305\n",
      "Epoch 212, Loss: 0.38986267089795973\n",
      "Epoch 213, Loss: 0.3899514303774719\n",
      "Epoch 214, Loss: 0.3906450457197873\n",
      "Epoch 215, Loss: 0.3902379025289353\n",
      "Epoch 216, Loss: 0.3890864207869081\n",
      "Epoch 217, Loss: 0.388614669500539\n",
      "Epoch 218, Loss: 0.3888388998490506\n",
      "Epoch 219, Loss: 0.3891447822855727\n",
      "Epoch 220, Loss: 0.3885722392056478\n",
      "Epoch 221, Loss: 0.38786022224636474\n",
      "Epoch 222, Loss: 0.3874008059441076\n",
      "Epoch 223, Loss: 0.38739647866865734\n",
      "Epoch 224, Loss: 0.3875015504867544\n",
      "Epoch 225, Loss: 0.3875214886090792\n",
      "Epoch 226, Loss: 0.38740824874481716\n",
      "Epoch 227, Loss: 0.386904007435856\n",
      "Epoch 228, Loss: 0.3863840485028223\n",
      "Epoch 229, Loss: 0.3859317748228129\n",
      "Epoch 230, Loss: 0.38571491386473433\n",
      "Epoch 231, Loss: 0.3856484021484972\n",
      "Epoch 232, Loss: 0.3857507439159308\n",
      "Epoch 233, Loss: 0.3859894937557964\n",
      "Epoch 234, Loss: 0.38635905713794794\n",
      "Epoch 235, Loss: 0.3868344836981511\n",
      "Epoch 236, Loss: 0.38674668490537006\n",
      "Epoch 237, Loss: 0.3859788772085842\n",
      "Epoch 238, Loss: 0.3846922673813945\n",
      "Epoch 239, Loss: 0.3840092422955118\n",
      "Epoch 240, Loss: 0.3841294388134424\n",
      "Epoch 241, Loss: 0.38466278870681175\n",
      "Epoch 242, Loss: 0.3849090850916448\n",
      "Epoch 243, Loss: 0.384442828171716\n",
      "Epoch 244, Loss: 0.3836179550831644\n",
      "Epoch 245, Loss: 0.3829933440001087\n",
      "Epoch 246, Loss: 0.38290123981425545\n",
      "Epoch 247, Loss: 0.38322226333656345\n",
      "Epoch 248, Loss: 0.38361424548679196\n",
      "Epoch 249, Loss: 0.3837292845474698\n",
      "Epoch 250, Loss: 0.3833334550477263\n",
      "Epoch 251, Loss: 0.38269076065949603\n",
      "Epoch 252, Loss: 0.3820241868940035\n",
      "Epoch 253, Loss: 0.3817490578860266\n",
      "Epoch 254, Loss: 0.38180500890639407\n",
      "Epoch 255, Loss: 0.3821091125961585\n",
      "Epoch 256, Loss: 0.38260600301023356\n",
      "Epoch 257, Loss: 0.38295696413168034\n",
      "Epoch 258, Loss: 0.3829993161937396\n",
      "Epoch 259, Loss: 0.3822738205003719\n",
      "Epoch 260, Loss: 0.38136561079167236\n",
      "Epoch 261, Loss: 0.38073072950648607\n",
      "Epoch 262, Loss: 0.3806835453377289\n",
      "Epoch 263, Loss: 0.3810501207853295\n",
      "Epoch 264, Loss: 0.38140337313544176\n",
      "Epoch 265, Loss: 0.38142954866540263\n",
      "Epoch 266, Loss: 0.3810105635037158\n",
      "Epoch 267, Loss: 0.38044910341017546\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.24325791092990434\n",
      "Test R^2 score: 0.3554075270601834\n",
      "Num of epochs: 268\n",
      "Epoch 1, Loss: 0.5658737573477295\n",
      "Epoch 2, Loss: 0.5648553332648781\n",
      "Epoch 3, Loss: 0.563886417368884\n",
      "Epoch 4, Loss: 0.5629654124529199\n",
      "Epoch 5, Loss: 0.5620638958186054\n",
      "Epoch 6, Loss: 0.5612138508410218\n",
      "Epoch 7, Loss: 0.5604127464251859\n",
      "Epoch 8, Loss: 0.5596674224046774\n",
      "Epoch 9, Loss: 0.5589830602474466\n",
      "Epoch 10, Loss: 0.5583639672638804\n",
      "Epoch 11, Loss: 0.5578142876689913\n",
      "Epoch 12, Loss: 0.5573378362574501\n",
      "Epoch 13, Loss: 0.5569328210441717\n",
      "Epoch 14, Loss: 0.5566206275961816\n",
      "Epoch 15, Loss: 0.5563649080295814\n",
      "Epoch 16, Loss: 0.5561819495676361\n",
      "Epoch 17, Loss: 0.5560721455959755\n",
      "Epoch 18, Loss: 0.5560169942800651\n",
      "Epoch 19, Loss: 0.5560133762911784\n",
      "Epoch 20, Loss: 0.5560304208330279\n",
      "Epoch 21, Loss: 0.5560460177389851\n",
      "Epoch 22, Loss: 0.5560368793987046\n",
      "Epoch 23, Loss: 0.5559855571901821\n",
      "Epoch 24, Loss: 0.5558793065028885\n",
      "Epoch 25, Loss: 0.5557177204310672\n",
      "Epoch 26, Loss: 0.5555044524875339\n",
      "Epoch 27, Loss: 0.5552335925436888\n",
      "Epoch 28, Loss: 0.55490806385175\n",
      "Epoch 29, Loss: 0.5545281194672153\n",
      "Epoch 30, Loss: 0.5541041355658226\n",
      "Epoch 31, Loss: 0.5536346113826677\n",
      "Epoch 32, Loss: 0.5530896881383706\n",
      "Epoch 33, Loss: 0.5524430332763406\n",
      "Epoch 34, Loss: 0.5516651176976396\n",
      "Epoch 35, Loss: 0.5507512185857714\n",
      "Epoch 36, Loss: 0.5497076785757564\n",
      "Epoch 37, Loss: 0.5484867323815612\n",
      "Epoch 38, Loss: 0.5470451362806465\n",
      "Epoch 39, Loss: 0.5453658944033641\n",
      "Epoch 40, Loss: 0.5434044935086281\n",
      "Epoch 41, Loss: 0.5411508164040241\n",
      "Epoch 42, Loss: 0.5386472844409398\n",
      "Epoch 43, Loss: 0.5358961795637249\n",
      "Epoch 44, Loss: 0.532781916660722\n",
      "Epoch 45, Loss: 0.5292335556837979\n",
      "Epoch 46, Loss: 0.5251251457557394\n",
      "Epoch 47, Loss: 0.5204226941334097\n",
      "Epoch 48, Loss: 0.5152336137952525\n",
      "Epoch 49, Loss: 0.5097867004013367\n",
      "Epoch 50, Loss: 0.5043988444613804\n",
      "Epoch 51, Loss: 0.4987525578005414\n",
      "Epoch 52, Loss: 0.4926657548078883\n",
      "Epoch 53, Loss: 0.4863621037267846\n",
      "Epoch 54, Loss: 0.4808953879883058\n",
      "Epoch 55, Loss: 0.4775298728136657\n",
      "Epoch 56, Loss: 0.4765955960397634\n",
      "Epoch 57, Loss: 0.47624665096437063\n",
      "Epoch 58, Loss: 0.4754911481011304\n",
      "Epoch 59, Loss: 0.47459680046095376\n",
      "Epoch 60, Loss: 0.4732567779017361\n",
      "Epoch 61, Loss: 0.4713191358359404\n",
      "Epoch 62, Loss: 0.46928064192817426\n",
      "Epoch 63, Loss: 0.4681047767274015\n",
      "Epoch 64, Loss: 0.4675867110175537\n",
      "Epoch 65, Loss: 0.46655544916996977\n",
      "Epoch 66, Loss: 0.4652542737777845\n",
      "Epoch 67, Loss: 0.46427855872571816\n",
      "Epoch 68, Loss: 0.4635879800641228\n",
      "Epoch 69, Loss: 0.46260042389035133\n",
      "Epoch 70, Loss: 0.46142287480483446\n",
      "Epoch 71, Loss: 0.460497484478826\n",
      "Epoch 72, Loss: 0.45977533244318597\n",
      "Epoch 73, Loss: 0.4588598691201324\n",
      "Epoch 74, Loss: 0.45777998017824995\n",
      "Epoch 75, Loss: 0.45691684366902613\n",
      "Epoch 76, Loss: 0.4562772905992951\n",
      "Epoch 77, Loss: 0.45548204170318524\n",
      "Epoch 78, Loss: 0.45467194861595606\n",
      "Epoch 79, Loss: 0.45407983871508845\n",
      "Epoch 80, Loss: 0.45336664267957516\n",
      "Epoch 81, Loss: 0.45251400630834365\n",
      "Epoch 82, Loss: 0.4518338256163937\n",
      "Epoch 83, Loss: 0.45117823278398\n",
      "Epoch 84, Loss: 0.45047678392161744\n",
      "Epoch 85, Loss: 0.44990417599330823\n",
      "Epoch 86, Loss: 0.44920461881221274\n",
      "Epoch 87, Loss: 0.44847069527714045\n",
      "Epoch 88, Loss: 0.4478049878317557\n",
      "Epoch 89, Loss: 0.4470896478807256\n",
      "Epoch 90, Loss: 0.4464862813433302\n",
      "Epoch 91, Loss: 0.44586896427177036\n",
      "Epoch 92, Loss: 0.4452869006378061\n",
      "Epoch 93, Loss: 0.4446814063881807\n",
      "Epoch 94, Loss: 0.44402691501904434\n",
      "Epoch 95, Loss: 0.44339481497797023\n",
      "Epoch 96, Loss: 0.44272734844285627\n",
      "Epoch 97, Loss: 0.44212448291138967\n",
      "Epoch 98, Loss: 0.44148407309134874\n",
      "Epoch 99, Loss: 0.4408687255668144\n",
      "Epoch 100, Loss: 0.4402116121433888\n",
      "Epoch 101, Loss: 0.4395789072377381\n",
      "Epoch 102, Loss: 0.4389198288628298\n",
      "Epoch 103, Loss: 0.4382602353421322\n",
      "Epoch 104, Loss: 0.4375916793677271\n",
      "Epoch 105, Loss: 0.4369175303308329\n",
      "Epoch 106, Loss: 0.4362141753245901\n",
      "Epoch 107, Loss: 0.43551917907515025\n",
      "Epoch 108, Loss: 0.43481483009660454\n",
      "Epoch 109, Loss: 0.43411817711263856\n",
      "Epoch 110, Loss: 0.4334203871832752\n",
      "Epoch 111, Loss: 0.4327497946420818\n",
      "Epoch 112, Loss: 0.43209592186857937\n",
      "Epoch 113, Loss: 0.4314551321684839\n",
      "Epoch 114, Loss: 0.4308167617212951\n",
      "Epoch 115, Loss: 0.43017280222524823\n",
      "Epoch 116, Loss: 0.4295182154715174\n",
      "Epoch 117, Loss: 0.4288557672582702\n",
      "Epoch 118, Loss: 0.4281790873199861\n",
      "Epoch 119, Loss: 0.42754290053177146\n",
      "Epoch 120, Loss: 0.42693714415577705\n",
      "Epoch 121, Loss: 0.42633299120334284\n",
      "Epoch 122, Loss: 0.42574975133452936\n",
      "Epoch 123, Loss: 0.4251646248953969\n",
      "Epoch 124, Loss: 0.424556844035975\n",
      "Epoch 125, Loss: 0.42394339404704123\n",
      "Epoch 126, Loss: 0.42331756216368227\n",
      "Epoch 127, Loss: 0.42272270653235794\n",
      "Epoch 128, Loss: 0.4221710296738733\n",
      "Epoch 129, Loss: 0.42169551210098183\n",
      "Epoch 130, Loss: 0.4213546793792711\n",
      "Epoch 131, Loss: 0.42106449896117254\n",
      "Epoch 132, Loss: 0.42047372087129503\n",
      "Epoch 133, Loss: 0.4194348371884763\n",
      "Epoch 134, Loss: 0.4189250203088859\n",
      "Epoch 135, Loss: 0.4187999731108011\n",
      "Epoch 136, Loss: 0.41803872779374107\n",
      "Epoch 137, Loss: 0.41719170114637855\n",
      "Epoch 138, Loss: 0.41694998248386494\n",
      "Epoch 139, Loss: 0.41656357761481194\n",
      "Epoch 140, Loss: 0.41564812344926283\n",
      "Epoch 141, Loss: 0.4151706083181571\n",
      "Epoch 142, Loss: 0.4149624383542486\n",
      "Epoch 143, Loss: 0.4142483348202892\n",
      "Epoch 144, Loss: 0.41351224216480703\n",
      "Epoch 145, Loss: 0.41316042109086937\n",
      "Epoch 146, Loss: 0.4127630319923634\n",
      "Epoch 147, Loss: 0.41209630357884486\n",
      "Epoch 148, Loss: 0.41147740436572056\n",
      "Epoch 149, Loss: 0.41111400135344567\n",
      "Epoch 150, Loss: 0.410718695693893\n",
      "Epoch 151, Loss: 0.4100887242998824\n",
      "Epoch 152, Loss: 0.4094206981050228\n",
      "Epoch 153, Loss: 0.4088407036413343\n",
      "Epoch 154, Loss: 0.40836976952730947\n",
      "Epoch 155, Loss: 0.4079826708799651\n",
      "Epoch 156, Loss: 0.40765961598490363\n",
      "Epoch 157, Loss: 0.4074518326217589\n",
      "Epoch 158, Loss: 0.4072253366721752\n",
      "Epoch 159, Loss: 0.4065780965348309\n",
      "Epoch 160, Loss: 0.40553001646548154\n",
      "Epoch 161, Loss: 0.40480485046848724\n",
      "Epoch 162, Loss: 0.4047123161277562\n",
      "Epoch 163, Loss: 0.4046745379224187\n",
      "Epoch 164, Loss: 0.4042221590008219\n",
      "Epoch 165, Loss: 0.40326880617981004\n",
      "Epoch 166, Loss: 0.40254906165795773\n",
      "Epoch 167, Loss: 0.40233737977549616\n",
      "Epoch 168, Loss: 0.40237247031211537\n",
      "Epoch 169, Loss: 0.4022808766543712\n",
      "Epoch 170, Loss: 0.4017156308979269\n",
      "Epoch 171, Loss: 0.40077118814490387\n",
      "Epoch 172, Loss: 0.4000716078260386\n",
      "Epoch 173, Loss: 0.39993462996981405\n",
      "Epoch 174, Loss: 0.40007955981822096\n",
      "Epoch 175, Loss: 0.4000056206785123\n",
      "Epoch 176, Loss: 0.3992185417219541\n",
      "Epoch 177, Loss: 0.398325492972594\n",
      "Epoch 178, Loss: 0.3978222790794933\n",
      "Epoch 179, Loss: 0.3977538770286499\n",
      "Epoch 180, Loss: 0.39791175338281537\n",
      "Epoch 181, Loss: 0.3980234275852462\n",
      "Epoch 182, Loss: 0.39766991297664384\n",
      "Epoch 183, Loss: 0.3968054312459267\n",
      "Epoch 184, Loss: 0.3959233867535559\n",
      "Epoch 185, Loss: 0.39552092353847235\n",
      "Epoch 186, Loss: 0.3955898058636142\n",
      "Epoch 187, Loss: 0.3958598701047841\n",
      "Epoch 188, Loss: 0.39592891927692875\n",
      "Epoch 189, Loss: 0.3952958469124936\n",
      "Epoch 190, Loss: 0.3943420560833512\n",
      "Epoch 191, Loss: 0.39368171629629256\n",
      "Epoch 192, Loss: 0.39354079153361776\n",
      "Epoch 193, Loss: 0.39374238642643244\n",
      "Epoch 194, Loss: 0.39396248790877597\n",
      "Epoch 195, Loss: 0.3937664550794298\n",
      "Epoch 196, Loss: 0.39288248059381387\n",
      "Epoch 197, Loss: 0.3920379262259174\n",
      "Epoch 198, Loss: 0.3915656208848604\n",
      "Epoch 199, Loss: 0.39166936501459526\n",
      "Epoch 200, Loss: 0.39206857968029457\n",
      "Epoch 201, Loss: 0.39248956089351617\n",
      "Epoch 202, Loss: 0.3926634814336133\n",
      "Epoch 203, Loss: 0.3914992086918947\n",
      "Epoch 204, Loss: 0.3901720663584035\n",
      "Epoch 205, Loss: 0.389756018144979\n",
      "Epoch 206, Loss: 0.39021770224022345\n",
      "Epoch 207, Loss: 0.39063638670537687\n",
      "Epoch 208, Loss: 0.38979247067462175\n",
      "Epoch 209, Loss: 0.38887122327931906\n",
      "Epoch 210, Loss: 0.3884042940194105\n",
      "Epoch 211, Loss: 0.38841944792976035\n",
      "Epoch 212, Loss: 0.3886621943662809\n",
      "Epoch 213, Loss: 0.38877907429615194\n",
      "Epoch 214, Loss: 0.38860299348286825\n",
      "Epoch 215, Loss: 0.38792961977192825\n",
      "Epoch 216, Loss: 0.38727231335246415\n",
      "Epoch 217, Loss: 0.3867052056609055\n",
      "Epoch 218, Loss: 0.3864184282715305\n",
      "Epoch 219, Loss: 0.38643092223616576\n",
      "Epoch 220, Loss: 0.3868141249368141\n",
      "Epoch 221, Loss: 0.387863468629415\n",
      "Epoch 222, Loss: 0.3880800120991328\n",
      "Epoch 223, Loss: 0.3872460902406401\n",
      "Epoch 224, Loss: 0.38554352098917294\n",
      "Epoch 225, Loss: 0.3849262154150372\n",
      "Epoch 226, Loss: 0.38545712911579716\n",
      "Epoch 227, Loss: 0.38595138864584916\n",
      "Epoch 228, Loss: 0.38600088209090966\n",
      "Epoch 229, Loss: 0.3846775089580994\n",
      "Epoch 230, Loss: 0.383820238861249\n",
      "Epoch 231, Loss: 0.38369388710592806\n",
      "Epoch 232, Loss: 0.384207034434648\n",
      "Epoch 233, Loss: 0.3848823331634191\n",
      "Epoch 234, Loss: 0.38452070932461574\n",
      "Epoch 235, Loss: 0.3837070911412356\n",
      "Epoch 236, Loss: 0.3826756914090306\n",
      "Epoch 237, Loss: 0.3823220751082345\n",
      "Epoch 238, Loss: 0.3825772983697113\n",
      "Epoch 239, Loss: 0.38310884177157106\n",
      "Epoch 240, Loss: 0.3835853055191529\n",
      "Epoch 241, Loss: 0.3828231848957759\n",
      "Epoch 242, Loss: 0.3819328633874217\n",
      "Epoch 243, Loss: 0.3810597210683129\n",
      "Epoch 244, Loss: 0.38097641931486337\n",
      "Epoch 245, Loss: 0.3815156417679821\n",
      "Epoch 246, Loss: 0.38179509561560004\n",
      "Epoch 247, Loss: 0.3817772198186681\n",
      "Epoch 248, Loss: 0.380884727221108\n",
      "Epoch 249, Loss: 0.380045583808022\n",
      "Epoch 250, Loss: 0.3794024453141655\n",
      "Epoch 251, Loss: 0.3793396388421205\n",
      "Epoch 252, Loss: 0.3797159882835034\n",
      "Epoch 253, Loss: 0.38041671068052696\n",
      "Epoch 254, Loss: 0.38131842702683827\n",
      "Epoch 255, Loss: 0.38080007629438845\n",
      "Epoch 256, Loss: 0.3797064521360909\n",
      "Epoch 257, Loss: 0.37790786325294434\n",
      "Epoch 258, Loss: 0.37780118822781295\n",
      "Epoch 259, Loss: 0.3787754462289791\n",
      "Epoch 260, Loss: 0.3793735375603984\n",
      "Epoch 261, Loss: 0.37885522007194844\n",
      "Epoch 262, Loss: 0.37744671619228415\n",
      "Epoch 263, Loss: 0.37623876371112824\n",
      "Epoch 264, Loss: 0.375789942809379\n",
      "Epoch 265, Loss: 0.3762158709790671\n",
      "Epoch 266, Loss: 0.37711384168610834\n",
      "Epoch 267, Loss: 0.3783227025371596\n",
      "Epoch 268, Loss: 0.37948623000733833\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.24558011264105756\n",
      "Test R^2 score: 0.347431018140394\n",
      "Num of epochs: 269\n",
      "Epoch 1, Loss: 0.5824682400194301\n",
      "Epoch 2, Loss: 0.5805425358285295\n",
      "Epoch 3, Loss: 0.5787217694394353\n",
      "Epoch 4, Loss: 0.5769489027319505\n",
      "Epoch 5, Loss: 0.5752290932753369\n",
      "Epoch 6, Loss: 0.5735688196893867\n",
      "Epoch 7, Loss: 0.5719658649152768\n",
      "Epoch 8, Loss: 0.5704181782256841\n",
      "Epoch 9, Loss: 0.5689289084105015\n",
      "Epoch 10, Loss: 0.5675014562210019\n",
      "Epoch 11, Loss: 0.5661645834121505\n",
      "Epoch 12, Loss: 0.5648986747492505\n",
      "Epoch 13, Loss: 0.5636934230014045\n",
      "Epoch 14, Loss: 0.5625559725993541\n",
      "Epoch 15, Loss: 0.5614943521679265\n",
      "Epoch 16, Loss: 0.5605568702152204\n",
      "Epoch 17, Loss: 0.5597250360013768\n",
      "Epoch 18, Loss: 0.5589569884814979\n",
      "Epoch 19, Loss: 0.5582541653981247\n",
      "Epoch 20, Loss: 0.5576147289856594\n",
      "Epoch 21, Loss: 0.5570382822670914\n",
      "Epoch 22, Loss: 0.5565110976114304\n",
      "Epoch 23, Loss: 0.5560371205885009\n",
      "Epoch 24, Loss: 0.5556081197296375\n",
      "Epoch 25, Loss: 0.5552181606842468\n",
      "Epoch 26, Loss: 0.5548520180019846\n",
      "Epoch 27, Loss: 0.5544902827010806\n",
      "Epoch 28, Loss: 0.554118146301952\n",
      "Epoch 29, Loss: 0.5537359914880663\n",
      "Epoch 30, Loss: 0.5532748272664957\n",
      "Epoch 31, Loss: 0.5527289831754466\n",
      "Epoch 32, Loss: 0.5520982620332127\n",
      "Epoch 33, Loss: 0.551360238572322\n",
      "Epoch 34, Loss: 0.5504443714331908\n",
      "Epoch 35, Loss: 0.5493100856841231\n",
      "Epoch 36, Loss: 0.5479294284692942\n",
      "Epoch 37, Loss: 0.5463034776920831\n",
      "Epoch 38, Loss: 0.5444075368624381\n",
      "Epoch 39, Loss: 0.5422028278305934\n",
      "Epoch 40, Loss: 0.5396738041574026\n",
      "Epoch 41, Loss: 0.5367706340382514\n",
      "Epoch 42, Loss: 0.5334689976086773\n",
      "Epoch 43, Loss: 0.5297263961059228\n",
      "Epoch 44, Loss: 0.5254281183074305\n",
      "Epoch 45, Loss: 0.5205341783326569\n",
      "Epoch 46, Loss: 0.5152771961617879\n",
      "Epoch 47, Loss: 0.5100749162738666\n",
      "Epoch 48, Loss: 0.5056998100625892\n",
      "Epoch 49, Loss: 0.5027900576043214\n",
      "Epoch 50, Loss: 0.5000549524627097\n",
      "Epoch 51, Loss: 0.49603395777542264\n",
      "Epoch 52, Loss: 0.4919425718239664\n",
      "Epoch 53, Loss: 0.4899579062676398\n",
      "Epoch 54, Loss: 0.48929525753644987\n",
      "Epoch 55, Loss: 0.48731759155556886\n",
      "Epoch 56, Loss: 0.48428340784219714\n",
      "Epoch 57, Loss: 0.48189944191678913\n",
      "Epoch 58, Loss: 0.48082581874797736\n",
      "Epoch 59, Loss: 0.47993253233731004\n",
      "Epoch 60, Loss: 0.47824472037999\n",
      "Epoch 61, Loss: 0.4762818495045399\n",
      "Epoch 62, Loss: 0.47491845321865883\n",
      "Epoch 63, Loss: 0.47416694647250557\n",
      "Epoch 64, Loss: 0.4734168435302164\n",
      "Epoch 65, Loss: 0.4723320629505033\n",
      "Epoch 66, Loss: 0.47117861399308725\n",
      "Epoch 67, Loss: 0.4703861609783893\n",
      "Epoch 68, Loss: 0.4699422773211475\n",
      "Epoch 69, Loss: 0.4693981299307816\n",
      "Epoch 70, Loss: 0.4684426571674733\n",
      "Epoch 71, Loss: 0.46729368642517055\n",
      "Epoch 72, Loss: 0.4662886849991698\n",
      "Epoch 73, Loss: 0.46547726329177624\n",
      "Epoch 74, Loss: 0.46467409323648334\n",
      "Epoch 75, Loss: 0.4637672718255725\n",
      "Epoch 76, Loss: 0.462876331736405\n",
      "Epoch 77, Loss: 0.4621361486912873\n",
      "Epoch 78, Loss: 0.46147108713383417\n",
      "Epoch 79, Loss: 0.46071244257392446\n",
      "Epoch 80, Loss: 0.4599142678592168\n",
      "Epoch 81, Loss: 0.4592448043570874\n",
      "Epoch 82, Loss: 0.45865406569035944\n",
      "Epoch 83, Loss: 0.45788128371929615\n",
      "Epoch 84, Loss: 0.4570215175277087\n",
      "Epoch 85, Loss: 0.4562863041530094\n",
      "Epoch 86, Loss: 0.45558627658698253\n",
      "Epoch 87, Loss: 0.4548103297701953\n",
      "Epoch 88, Loss: 0.4540786573314306\n",
      "Epoch 89, Loss: 0.45337632214143336\n",
      "Epoch 90, Loss: 0.4526507921716114\n",
      "Epoch 91, Loss: 0.45192028905598625\n",
      "Epoch 92, Loss: 0.45125666560589\n",
      "Epoch 93, Loss: 0.45057938219187327\n",
      "Epoch 94, Loss: 0.4498749956712354\n",
      "Epoch 95, Loss: 0.4492446560231377\n",
      "Epoch 96, Loss: 0.4486491033031771\n",
      "Epoch 97, Loss: 0.44805508700014735\n",
      "Epoch 98, Loss: 0.4474897031558423\n",
      "Epoch 99, Loss: 0.44689224516665366\n",
      "Epoch 100, Loss: 0.4462598795291395\n",
      "Epoch 101, Loss: 0.44565480444218764\n",
      "Epoch 102, Loss: 0.4450490071603509\n",
      "Epoch 103, Loss: 0.44445747138674374\n",
      "Epoch 104, Loss: 0.44389108040444636\n",
      "Epoch 105, Loss: 0.44332324313510096\n",
      "Epoch 106, Loss: 0.44277414692879524\n",
      "Epoch 107, Loss: 0.4422449566611243\n",
      "Epoch 108, Loss: 0.44172282386739026\n",
      "Epoch 109, Loss: 0.4411980804826131\n",
      "Epoch 110, Loss: 0.44066500245447093\n",
      "Epoch 111, Loss: 0.4401090516340329\n",
      "Epoch 112, Loss: 0.43953671825925134\n",
      "Epoch 113, Loss: 0.43896265421863384\n",
      "Epoch 114, Loss: 0.43836781739919845\n",
      "Epoch 115, Loss: 0.4377595097768612\n",
      "Epoch 116, Loss: 0.43714848088617136\n",
      "Epoch 117, Loss: 0.4365472296390399\n",
      "Epoch 118, Loss: 0.4359463284053168\n",
      "Epoch 119, Loss: 0.4352983869248869\n",
      "Epoch 120, Loss: 0.4346470282915669\n",
      "Epoch 121, Loss: 0.43398437431328585\n",
      "Epoch 122, Loss: 0.43333248480689285\n",
      "Epoch 123, Loss: 0.4326827126645491\n",
      "Epoch 124, Loss: 0.432026686135549\n",
      "Epoch 125, Loss: 0.43134570511041337\n",
      "Epoch 126, Loss: 0.43064890724556365\n",
      "Epoch 127, Loss: 0.4299382431849009\n",
      "Epoch 128, Loss: 0.4292115783647738\n",
      "Epoch 129, Loss: 0.4284875239822807\n",
      "Epoch 130, Loss: 0.42782246975814525\n",
      "Epoch 131, Loss: 0.42724508230907066\n",
      "Epoch 132, Loss: 0.4268450964176049\n",
      "Epoch 133, Loss: 0.4259873687478872\n",
      "Epoch 134, Loss: 0.4252232210797945\n",
      "Epoch 135, Loss: 0.42468588033652205\n",
      "Epoch 136, Loss: 0.42428564173031286\n",
      "Epoch 137, Loss: 0.42369262005809666\n",
      "Epoch 138, Loss: 0.4229050177424637\n",
      "Epoch 139, Loss: 0.4223035472458931\n",
      "Epoch 140, Loss: 0.42186281398551384\n",
      "Epoch 141, Loss: 0.4212513835612592\n",
      "Epoch 142, Loss: 0.42046179548428453\n",
      "Epoch 143, Loss: 0.41982860860151106\n",
      "Epoch 144, Loss: 0.4192929370653271\n",
      "Epoch 145, Loss: 0.41888391716235834\n",
      "Epoch 146, Loss: 0.4186129730128076\n",
      "Epoch 147, Loss: 0.418907377219471\n",
      "Epoch 148, Loss: 0.4171215455286862\n",
      "Epoch 149, Loss: 0.41662687071853216\n",
      "Epoch 150, Loss: 0.4177217734244488\n",
      "Epoch 151, Loss: 0.4156622482760665\n",
      "Epoch 152, Loss: 0.4150708534182486\n",
      "Epoch 153, Loss: 0.4153821536885104\n",
      "Epoch 154, Loss: 0.4138818562722306\n",
      "Epoch 155, Loss: 0.41361983046611256\n",
      "Epoch 156, Loss: 0.4139883226853252\n",
      "Epoch 157, Loss: 0.4124157205372845\n",
      "Epoch 158, Loss: 0.41265036342225364\n",
      "Epoch 159, Loss: 0.4129773982596996\n",
      "Epoch 160, Loss: 0.41096763282794013\n",
      "Epoch 161, Loss: 0.41209006603257936\n",
      "Epoch 162, Loss: 0.4114493014957953\n",
      "Epoch 163, Loss: 0.4099992178990883\n",
      "Epoch 164, Loss: 0.41151678499077937\n",
      "Epoch 165, Loss: 0.40916548456201246\n",
      "Epoch 166, Loss: 0.40951999178726184\n",
      "Epoch 167, Loss: 0.40875553553154786\n",
      "Epoch 168, Loss: 0.4078587991733576\n",
      "Epoch 169, Loss: 0.4082996309086731\n",
      "Epoch 170, Loss: 0.40672956184850373\n",
      "Epoch 171, Loss: 0.4074231594866422\n",
      "Epoch 172, Loss: 0.40615566698986244\n",
      "Epoch 173, Loss: 0.40575520020171063\n",
      "Epoch 174, Loss: 0.40582811016713843\n",
      "Epoch 175, Loss: 0.40461554384657294\n",
      "Epoch 176, Loss: 0.4044055884700523\n",
      "Epoch 177, Loss: 0.4042905171212327\n",
      "Epoch 178, Loss: 0.4031686751784912\n",
      "Epoch 179, Loss: 0.40290031085633166\n",
      "Epoch 180, Loss: 0.4027070747542642\n",
      "Epoch 181, Loss: 0.4019339428060484\n",
      "Epoch 182, Loss: 0.4013327145216587\n",
      "Epoch 183, Loss: 0.40122014157442903\n",
      "Epoch 184, Loss: 0.4008865076940412\n",
      "Epoch 185, Loss: 0.40006499656466804\n",
      "Epoch 186, Loss: 0.39948266519790926\n",
      "Epoch 187, Loss: 0.39914280043923994\n",
      "Epoch 188, Loss: 0.3989322619804735\n",
      "Epoch 189, Loss: 0.39897842713526294\n",
      "Epoch 190, Loss: 0.39868573328593426\n",
      "Epoch 191, Loss: 0.3987371776277073\n",
      "Epoch 192, Loss: 0.3974057470895762\n",
      "Epoch 193, Loss: 0.3964964014493759\n",
      "Epoch 194, Loss: 0.3960960064584839\n",
      "Epoch 195, Loss: 0.39634649575923153\n",
      "Epoch 196, Loss: 0.39787480881446996\n",
      "Epoch 197, Loss: 0.3967300743659283\n",
      "Epoch 198, Loss: 0.3956343083544614\n",
      "Epoch 199, Loss: 0.394089801184439\n",
      "Epoch 200, Loss: 0.393519814131771\n",
      "Epoch 201, Loss: 0.3937218739288534\n",
      "Epoch 202, Loss: 0.3943570762889821\n",
      "Epoch 203, Loss: 0.395692927990771\n",
      "Epoch 204, Loss: 0.39238415381286346\n",
      "Epoch 205, Loss: 0.3917084355436176\n",
      "Epoch 206, Loss: 0.3931509175877037\n",
      "Epoch 207, Loss: 0.39253181450068814\n",
      "Epoch 208, Loss: 0.39193426064375464\n",
      "Epoch 209, Loss: 0.3900511914059365\n",
      "Epoch 210, Loss: 0.390353089108856\n",
      "Epoch 211, Loss: 0.3927273253276156\n",
      "Epoch 212, Loss: 0.3896255677665463\n",
      "Epoch 213, Loss: 0.3885103973337664\n",
      "Epoch 214, Loss: 0.38905490040538215\n",
      "Epoch 215, Loss: 0.3901773558114785\n",
      "Epoch 216, Loss: 0.3915658301891514\n",
      "Epoch 217, Loss: 0.38713725400553944\n",
      "Epoch 218, Loss: 0.3888155034434742\n",
      "Epoch 219, Loss: 0.3936609924471655\n",
      "Epoch 220, Loss: 0.3865077088304044\n",
      "Epoch 221, Loss: 0.3955434900840062\n",
      "Epoch 222, Loss: 0.3949436449640466\n",
      "Epoch 223, Loss: 0.3917769232069284\n",
      "Epoch 224, Loss: 0.3924865805706963\n",
      "Epoch 225, Loss: 0.3868522413643688\n",
      "Epoch 226, Loss: 0.3914797015378396\n",
      "Epoch 227, Loss: 0.3866392882426708\n",
      "Epoch 228, Loss: 0.38997661184215876\n",
      "Epoch 229, Loss: 0.3847293739862941\n",
      "Epoch 230, Loss: 0.38726175121211465\n",
      "Epoch 231, Loss: 0.3837570487689057\n",
      "Epoch 232, Loss: 0.3874099988399819\n",
      "Epoch 233, Loss: 0.38429952361141617\n",
      "Epoch 234, Loss: 0.3850514468585061\n",
      "Epoch 235, Loss: 0.3831788470464576\n",
      "Epoch 236, Loss: 0.3828032161598966\n",
      "Epoch 237, Loss: 0.3834005626866366\n",
      "Epoch 238, Loss: 0.3815514560885134\n",
      "Epoch 239, Loss: 0.38323719444828847\n",
      "Epoch 240, Loss: 0.38063136391416813\n",
      "Epoch 241, Loss: 0.38148425753574255\n",
      "Epoch 242, Loss: 0.38053273597033055\n",
      "Epoch 243, Loss: 0.3795874459887971\n",
      "Epoch 244, Loss: 0.3801175056905437\n",
      "Epoch 245, Loss: 0.37866553299497985\n",
      "Epoch 246, Loss: 0.3790760839470306\n",
      "Epoch 247, Loss: 0.3787228051736619\n",
      "Epoch 248, Loss: 0.37753545420935797\n",
      "Epoch 249, Loss: 0.37842438723135324\n",
      "Epoch 250, Loss: 0.37769387155246725\n",
      "Epoch 251, Loss: 0.3765253792665295\n",
      "Epoch 252, Loss: 0.37704719595104846\n",
      "Epoch 253, Loss: 0.3769861315571958\n",
      "Epoch 254, Loss: 0.37535527407212216\n",
      "Epoch 255, Loss: 0.3754551430156276\n",
      "Epoch 256, Loss: 0.3756578159437678\n",
      "Epoch 257, Loss: 0.37464337478063214\n",
      "Epoch 258, Loss: 0.3737640078735962\n",
      "Epoch 259, Loss: 0.3738223100327557\n",
      "Epoch 260, Loss: 0.37374873818149434\n",
      "Epoch 261, Loss: 0.37341366456390074\n",
      "Epoch 262, Loss: 0.3725337948926207\n",
      "Epoch 263, Loss: 0.3718487537963285\n",
      "Epoch 264, Loss: 0.37124488162355984\n",
      "Epoch 265, Loss: 0.3708401265040052\n",
      "Epoch 266, Loss: 0.37060846420504906\n",
      "Epoch 267, Loss: 0.37108939318860007\n",
      "Epoch 268, Loss: 0.3733086591184825\n",
      "Epoch 269, Loss: 0.3751017114667867\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2508638743084243\n",
      "Test R^2 score: 0.3163644267641653\n",
      "Num of epochs: 270\n",
      "Epoch 1, Loss: 0.566594664706901\n",
      "Epoch 2, Loss: 0.5653778210505686\n",
      "Epoch 3, Loss: 0.564246327886434\n",
      "Epoch 4, Loss: 0.5632011229603447\n",
      "Epoch 5, Loss: 0.5622519900031046\n",
      "Epoch 6, Loss: 0.5613930194165254\n",
      "Epoch 7, Loss: 0.560615163225612\n",
      "Epoch 8, Loss: 0.5599038293548462\n",
      "Epoch 9, Loss: 0.5592565805408689\n",
      "Epoch 10, Loss: 0.5586704121515697\n",
      "Epoch 11, Loss: 0.5581597729793807\n",
      "Epoch 12, Loss: 0.5577019728890569\n",
      "Epoch 13, Loss: 0.5572922222336706\n",
      "Epoch 14, Loss: 0.5569426938323013\n",
      "Epoch 15, Loss: 0.5567016568103912\n",
      "Epoch 16, Loss: 0.5564882304068612\n",
      "Epoch 17, Loss: 0.5563326870613771\n",
      "Epoch 18, Loss: 0.5562301996543129\n",
      "Epoch 19, Loss: 0.5561726527068622\n",
      "Epoch 20, Loss: 0.5561484051197371\n",
      "Epoch 21, Loss: 0.5561463152229644\n",
      "Epoch 22, Loss: 0.5561579971093125\n",
      "Epoch 23, Loss: 0.5561750104268962\n",
      "Epoch 24, Loss: 0.5561857807935744\n",
      "Epoch 25, Loss: 0.5561826997398278\n",
      "Epoch 26, Loss: 0.5561603013056283\n",
      "Epoch 27, Loss: 0.5561135456863111\n",
      "Epoch 28, Loss: 0.5560353250619524\n",
      "Epoch 29, Loss: 0.5559252508914349\n",
      "Epoch 30, Loss: 0.5557874867644597\n",
      "Epoch 31, Loss: 0.5556203224920679\n",
      "Epoch 32, Loss: 0.5554054342203916\n",
      "Epoch 33, Loss: 0.5551303922137485\n",
      "Epoch 34, Loss: 0.5547795555128835\n",
      "Epoch 35, Loss: 0.554334232504309\n",
      "Epoch 36, Loss: 0.553775144484064\n",
      "Epoch 37, Loss: 0.5530794502080987\n",
      "Epoch 38, Loss: 0.5522088292076797\n",
      "Epoch 39, Loss: 0.5511024836947853\n",
      "Epoch 40, Loss: 0.5497138319274212\n",
      "Epoch 41, Loss: 0.5479908322468897\n",
      "Epoch 42, Loss: 0.5458719045779702\n",
      "Epoch 43, Loss: 0.5432947950015883\n",
      "Epoch 44, Loss: 0.5403340863427138\n",
      "Epoch 45, Loss: 0.5367455654858364\n",
      "Epoch 46, Loss: 0.5324154299977755\n",
      "Epoch 47, Loss: 0.5274195863800956\n",
      "Epoch 48, Loss: 0.5221514203923943\n",
      "Epoch 49, Loss: 0.5172905752954277\n",
      "Epoch 50, Loss: 0.5137122250798173\n",
      "Epoch 51, Loss: 0.5116585266550971\n",
      "Epoch 52, Loss: 0.5097813220183364\n",
      "Epoch 53, Loss: 0.5072520170702812\n",
      "Epoch 54, Loss: 0.5041182316089969\n",
      "Epoch 55, Loss: 0.5010021716259244\n",
      "Epoch 56, Loss: 0.4983512546698804\n",
      "Epoch 57, Loss: 0.4959857252358745\n",
      "Epoch 58, Loss: 0.49361471604381074\n",
      "Epoch 59, Loss: 0.49107689668657806\n",
      "Epoch 60, Loss: 0.48832728359665134\n",
      "Epoch 61, Loss: 0.48558870658609715\n",
      "Epoch 62, Loss: 0.48320307010782926\n",
      "Epoch 63, Loss: 0.4812054607291193\n",
      "Epoch 64, Loss: 0.4793621127648102\n",
      "Epoch 65, Loss: 0.47746816159500527\n",
      "Epoch 66, Loss: 0.4756880382313764\n",
      "Epoch 67, Loss: 0.47423425614522446\n",
      "Epoch 68, Loss: 0.47304909514229865\n",
      "Epoch 69, Loss: 0.47189600941958704\n",
      "Epoch 70, Loss: 0.4705051464798622\n",
      "Epoch 71, Loss: 0.46883451971375667\n",
      "Epoch 72, Loss: 0.46728622452345725\n",
      "Epoch 73, Loss: 0.46642424262787285\n",
      "Epoch 74, Loss: 0.4659364823369273\n",
      "Epoch 75, Loss: 0.46505769246101236\n",
      "Epoch 76, Loss: 0.4636358065504069\n",
      "Epoch 77, Loss: 0.4621450802188821\n",
      "Epoch 78, Loss: 0.4610139815678254\n",
      "Epoch 79, Loss: 0.4600766597237997\n",
      "Epoch 80, Loss: 0.4590111257995694\n",
      "Epoch 81, Loss: 0.4580082029166113\n",
      "Epoch 82, Loss: 0.4572856879513297\n",
      "Epoch 83, Loss: 0.4565028208659029\n",
      "Epoch 84, Loss: 0.4555063320509113\n",
      "Epoch 85, Loss: 0.45463227464290334\n",
      "Epoch 86, Loss: 0.4540160231882107\n",
      "Epoch 87, Loss: 0.453330305877679\n",
      "Epoch 88, Loss: 0.45268589974773216\n",
      "Epoch 89, Loss: 0.45204326156127167\n",
      "Epoch 90, Loss: 0.45124543816434776\n",
      "Epoch 91, Loss: 0.4506291514667063\n",
      "Epoch 92, Loss: 0.45000104374234695\n",
      "Epoch 93, Loss: 0.4493465407675042\n",
      "Epoch 94, Loss: 0.4487613837516968\n",
      "Epoch 95, Loss: 0.4480435298937815\n",
      "Epoch 96, Loss: 0.447407562522511\n",
      "Epoch 97, Loss: 0.44665105316762194\n",
      "Epoch 98, Loss: 0.445908732886476\n",
      "Epoch 99, Loss: 0.4452051568739871\n",
      "Epoch 100, Loss: 0.4445030820265553\n",
      "Epoch 101, Loss: 0.44382076370803747\n",
      "Epoch 102, Loss: 0.4430636793678656\n",
      "Epoch 103, Loss: 0.44234436070148403\n",
      "Epoch 104, Loss: 0.44154077353619187\n",
      "Epoch 105, Loss: 0.4407544852118897\n",
      "Epoch 106, Loss: 0.43994862066825047\n",
      "Epoch 107, Loss: 0.4392046246993446\n",
      "Epoch 108, Loss: 0.4384581258249425\n",
      "Epoch 109, Loss: 0.43771532413843883\n",
      "Epoch 110, Loss: 0.43694552980557494\n",
      "Epoch 111, Loss: 0.436178869334502\n",
      "Epoch 112, Loss: 0.43541948311486506\n",
      "Epoch 113, Loss: 0.4346517079452191\n",
      "Epoch 114, Loss: 0.43391458137269506\n",
      "Epoch 115, Loss: 0.43316737681904655\n",
      "Epoch 116, Loss: 0.4324362313937961\n",
      "Epoch 117, Loss: 0.4317139438136578\n",
      "Epoch 118, Loss: 0.4309892183822823\n",
      "Epoch 119, Loss: 0.4302541291228811\n",
      "Epoch 120, Loss: 0.42953224845317806\n",
      "Epoch 121, Loss: 0.4288015943184881\n",
      "Epoch 122, Loss: 0.4280486324167701\n",
      "Epoch 123, Loss: 0.4273014054598237\n",
      "Epoch 124, Loss: 0.4265712269040528\n",
      "Epoch 125, Loss: 0.4259022532018106\n",
      "Epoch 126, Loss: 0.4253121337776934\n",
      "Epoch 127, Loss: 0.424818841106484\n",
      "Epoch 128, Loss: 0.4240497765427927\n",
      "Epoch 129, Loss: 0.42312863194809996\n",
      "Epoch 130, Loss: 0.42250975786599476\n",
      "Epoch 131, Loss: 0.42209359969293664\n",
      "Epoch 132, Loss: 0.4215163896650384\n",
      "Epoch 133, Loss: 0.4206620191860458\n",
      "Epoch 134, Loss: 0.419921005602979\n",
      "Epoch 135, Loss: 0.4194597051839366\n",
      "Epoch 136, Loss: 0.41917324312535476\n",
      "Epoch 137, Loss: 0.4186795509917433\n",
      "Epoch 138, Loss: 0.4178152604678827\n",
      "Epoch 139, Loss: 0.4171210989811112\n",
      "Epoch 140, Loss: 0.41686105564707615\n",
      "Epoch 141, Loss: 0.41648764539417443\n",
      "Epoch 142, Loss: 0.41583206712011433\n",
      "Epoch 143, Loss: 0.4150536209245826\n",
      "Epoch 144, Loss: 0.4146590164567218\n",
      "Epoch 145, Loss: 0.41437892699071\n",
      "Epoch 146, Loss: 0.41390968597817696\n",
      "Epoch 147, Loss: 0.41313883485583325\n",
      "Epoch 148, Loss: 0.41248953040159164\n",
      "Epoch 149, Loss: 0.41202936706575644\n",
      "Epoch 150, Loss: 0.41181785433077933\n",
      "Epoch 151, Loss: 0.4115642721069928\n",
      "Epoch 152, Loss: 0.4110473761505994\n",
      "Epoch 153, Loss: 0.4102735079318795\n",
      "Epoch 154, Loss: 0.4093846465568527\n",
      "Epoch 155, Loss: 0.40883011554836285\n",
      "Epoch 156, Loss: 0.40859479229358314\n",
      "Epoch 157, Loss: 0.40847154398083635\n",
      "Epoch 158, Loss: 0.408149332398973\n",
      "Epoch 159, Loss: 0.4073295554499916\n",
      "Epoch 160, Loss: 0.40627360275368185\n",
      "Epoch 161, Loss: 0.4057644179491957\n",
      "Epoch 162, Loss: 0.4057616269401878\n",
      "Epoch 163, Loss: 0.4056629744741499\n",
      "Epoch 164, Loss: 0.4045498742818254\n",
      "Epoch 165, Loss: 0.40366393223045577\n",
      "Epoch 166, Loss: 0.40352405638993594\n",
      "Epoch 167, Loss: 0.4036609236654935\n",
      "Epoch 168, Loss: 0.40315703257369534\n",
      "Epoch 169, Loss: 0.401885039677252\n",
      "Epoch 170, Loss: 0.4013488097055705\n",
      "Epoch 171, Loss: 0.4014633880195402\n",
      "Epoch 172, Loss: 0.40166198967483446\n",
      "Epoch 173, Loss: 0.4006110538251242\n",
      "Epoch 174, Loss: 0.3995338950369848\n",
      "Epoch 175, Loss: 0.39908972818303007\n",
      "Epoch 176, Loss: 0.3993288989315749\n",
      "Epoch 177, Loss: 0.3991033936102257\n",
      "Epoch 178, Loss: 0.3983651450787217\n",
      "Epoch 179, Loss: 0.3974323309274135\n",
      "Epoch 180, Loss: 0.39674498538530123\n",
      "Epoch 181, Loss: 0.39641645629638794\n",
      "Epoch 182, Loss: 0.3963511764707654\n",
      "Epoch 183, Loss: 0.3965989496961644\n",
      "Epoch 184, Loss: 0.3963492966735786\n",
      "Epoch 185, Loss: 0.39553928956412165\n",
      "Epoch 186, Loss: 0.3942770375007615\n",
      "Epoch 187, Loss: 0.3935615785056987\n",
      "Epoch 188, Loss: 0.39331994261550446\n",
      "Epoch 189, Loss: 0.39369954361141846\n",
      "Epoch 190, Loss: 0.39406718920610834\n",
      "Epoch 191, Loss: 0.39345282284665306\n",
      "Epoch 192, Loss: 0.39216785913657093\n",
      "Epoch 193, Loss: 0.3908803677301652\n",
      "Epoch 194, Loss: 0.3904432827756531\n",
      "Epoch 195, Loss: 0.3905411821085124\n",
      "Epoch 196, Loss: 0.3911602549258368\n",
      "Epoch 197, Loss: 0.3907930394178486\n",
      "Epoch 198, Loss: 0.3894863891169959\n",
      "Epoch 199, Loss: 0.3881903881701963\n",
      "Epoch 200, Loss: 0.38742786474380475\n",
      "Epoch 201, Loss: 0.38708732842449484\n",
      "Epoch 202, Loss: 0.3872183452939962\n",
      "Epoch 203, Loss: 0.38778656623068086\n",
      "Epoch 204, Loss: 0.3888333047679319\n",
      "Epoch 205, Loss: 0.38774312298675645\n",
      "Epoch 206, Loss: 0.3853550573887526\n",
      "Epoch 207, Loss: 0.3837964006261135\n",
      "Epoch 208, Loss: 0.3838039715615587\n",
      "Epoch 209, Loss: 0.3850772970186427\n",
      "Epoch 210, Loss: 0.3853400536591056\n",
      "Epoch 211, Loss: 0.3837698817616742\n",
      "Epoch 212, Loss: 0.3812441520555094\n",
      "Epoch 213, Loss: 0.3800794391668169\n",
      "Epoch 214, Loss: 0.3804211565207471\n",
      "Epoch 215, Loss: 0.3818594883829193\n",
      "Epoch 216, Loss: 0.38311562895399\n",
      "Epoch 217, Loss: 0.3809787660924397\n",
      "Epoch 218, Loss: 0.3777513502186465\n",
      "Epoch 219, Loss: 0.37635611659872636\n",
      "Epoch 220, Loss: 0.3787345693926043\n",
      "Epoch 221, Loss: 0.3815519833189404\n",
      "Epoch 222, Loss: 0.3778782102238372\n",
      "Epoch 223, Loss: 0.37345568241561894\n",
      "Epoch 224, Loss: 0.3754464908753375\n",
      "Epoch 225, Loss: 0.37850984503995094\n",
      "Epoch 226, Loss: 0.37605655364194357\n",
      "Epoch 227, Loss: 0.3711936213972459\n",
      "Epoch 228, Loss: 0.37519729907628396\n",
      "Epoch 229, Loss: 0.37792162430710335\n",
      "Epoch 230, Loss: 0.3721355270944391\n",
      "Epoch 231, Loss: 0.36972256359551425\n",
      "Epoch 232, Loss: 0.3780839787450311\n",
      "Epoch 233, Loss: 0.3713070306739536\n",
      "Epoch 234, Loss: 0.367729112219933\n",
      "Epoch 235, Loss: 0.3692192115086639\n",
      "Epoch 236, Loss: 0.37017469538103354\n",
      "Epoch 237, Loss: 0.36464079903528446\n",
      "Epoch 238, Loss: 0.364283911048743\n",
      "Epoch 239, Loss: 0.3651928393567568\n",
      "Epoch 240, Loss: 0.36654661942576383\n",
      "Epoch 241, Loss: 0.36318174660713765\n",
      "Epoch 242, Loss: 0.3606649137387951\n",
      "Epoch 243, Loss: 0.36004571935627727\n",
      "Epoch 244, Loss: 0.3601151184294035\n",
      "Epoch 245, Loss: 0.3627343111122366\n",
      "Epoch 246, Loss: 0.361468932063282\n",
      "Epoch 247, Loss: 0.35955470194749317\n",
      "Epoch 248, Loss: 0.35669818426225636\n",
      "Epoch 249, Loss: 0.35568119868768283\n",
      "Epoch 250, Loss: 0.35430133820974685\n",
      "Epoch 251, Loss: 0.35437547848516116\n",
      "Epoch 252, Loss: 0.3554776997539962\n",
      "Epoch 253, Loss: 0.36061673629257485\n",
      "Epoch 254, Loss: 0.366875191027252\n",
      "Epoch 255, Loss: 0.36456786758680454\n",
      "Epoch 256, Loss: 0.3530285467230217\n",
      "Epoch 257, Loss: 0.3505161077720274\n",
      "Epoch 258, Loss: 0.36140210193409106\n",
      "Epoch 259, Loss: 0.36369982570012604\n",
      "Epoch 260, Loss: 0.35140686828911694\n",
      "Epoch 261, Loss: 0.3493153491816045\n",
      "Epoch 262, Loss: 0.3605395811258601\n",
      "Epoch 263, Loss: 0.35932414068162954\n",
      "Epoch 264, Loss: 0.3477611169279067\n",
      "Epoch 265, Loss: 0.3577131533237832\n",
      "Epoch 266, Loss: 0.3617178593536024\n",
      "Epoch 267, Loss: 0.34708348787509613\n",
      "Epoch 268, Loss: 0.35202065390510245\n",
      "Epoch 269, Loss: 0.3551506883191615\n",
      "Epoch 270, Loss: 0.34437066096222174\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2635976234677769\n",
      "Test R^2 score: 0.2376687252874778\n",
      "Num of epochs: 271\n",
      "Epoch 1, Loss: 0.5892328294332826\n",
      "Epoch 2, Loss: 0.58715386339515\n",
      "Epoch 3, Loss: 0.5851743433030582\n",
      "Epoch 4, Loss: 0.5832938254692233\n",
      "Epoch 5, Loss: 0.5815862452165425\n",
      "Epoch 6, Loss: 0.5802084009066621\n",
      "Epoch 7, Loss: 0.5788731502486107\n",
      "Epoch 8, Loss: 0.577575499772316\n",
      "Epoch 9, Loss: 0.5764162999903338\n",
      "Epoch 10, Loss: 0.575297581335746\n",
      "Epoch 11, Loss: 0.5742020637008084\n",
      "Epoch 12, Loss: 0.573124914179705\n",
      "Epoch 13, Loss: 0.5720705604748043\n",
      "Epoch 14, Loss: 0.5710418166149137\n",
      "Epoch 15, Loss: 0.570037644925051\n",
      "Epoch 16, Loss: 0.5690640672288206\n",
      "Epoch 17, Loss: 0.5681133458754065\n",
      "Epoch 18, Loss: 0.5671847813648823\n",
      "Epoch 19, Loss: 0.5662789826628507\n",
      "Epoch 20, Loss: 0.5653901028653768\n",
      "Epoch 21, Loss: 0.5645238970571459\n",
      "Epoch 22, Loss: 0.5636789893787213\n",
      "Epoch 23, Loss: 0.5628533048521384\n",
      "Epoch 24, Loss: 0.5620884714487938\n",
      "Epoch 25, Loss: 0.561400982316846\n",
      "Epoch 26, Loss: 0.5607262566939952\n",
      "Epoch 27, Loss: 0.5600133875966635\n",
      "Epoch 28, Loss: 0.559133255789937\n",
      "Epoch 29, Loss: 0.558116308659357\n",
      "Epoch 30, Loss: 0.557201651555535\n",
      "Epoch 31, Loss: 0.5562465946221856\n",
      "Epoch 32, Loss: 0.555224252965214\n",
      "Epoch 33, Loss: 0.5541495548799622\n",
      "Epoch 34, Loss: 0.5530145965998596\n",
      "Epoch 35, Loss: 0.5517806867060929\n",
      "Epoch 36, Loss: 0.5504227682329421\n",
      "Epoch 37, Loss: 0.5489146751497792\n",
      "Epoch 38, Loss: 0.5472458807945756\n",
      "Epoch 39, Loss: 0.5453915776407129\n",
      "Epoch 40, Loss: 0.5433389513138756\n",
      "Epoch 41, Loss: 0.5411228115066612\n",
      "Epoch 42, Loss: 0.5388572136127727\n",
      "Epoch 43, Loss: 0.5365413922449913\n",
      "Epoch 44, Loss: 0.5340262128043369\n",
      "Epoch 45, Loss: 0.5312343202408757\n",
      "Epoch 46, Loss: 0.5283354300488445\n",
      "Epoch 47, Loss: 0.5256226321608182\n",
      "Epoch 48, Loss: 0.523144426429486\n",
      "Epoch 49, Loss: 0.5209911743046212\n",
      "Epoch 50, Loss: 0.5188103456901672\n",
      "Epoch 51, Loss: 0.5166317330620129\n",
      "Epoch 52, Loss: 0.5145191124238321\n",
      "Epoch 53, Loss: 0.5126126758644625\n",
      "Epoch 54, Loss: 0.511079578302309\n",
      "Epoch 55, Loss: 0.5095243504164422\n",
      "Epoch 56, Loss: 0.5079685558270611\n",
      "Epoch 57, Loss: 0.5064173386538836\n",
      "Epoch 58, Loss: 0.5048488406293926\n",
      "Epoch 59, Loss: 0.5032626929143988\n",
      "Epoch 60, Loss: 0.5016900646048644\n",
      "Epoch 61, Loss: 0.5001025988694529\n",
      "Epoch 62, Loss: 0.498488197020492\n",
      "Epoch 63, Loss: 0.49689047207525144\n",
      "Epoch 64, Loss: 0.49527933448923167\n",
      "Epoch 65, Loss: 0.49366585159309595\n",
      "Epoch 66, Loss: 0.4920913360143081\n",
      "Epoch 67, Loss: 0.4905535961844379\n",
      "Epoch 68, Loss: 0.48902628706659385\n",
      "Epoch 69, Loss: 0.48753965901180235\n",
      "Epoch 70, Loss: 0.48610314370241176\n",
      "Epoch 71, Loss: 0.48473367946963297\n",
      "Epoch 72, Loss: 0.48338148299260303\n",
      "Epoch 73, Loss: 0.4820132204266804\n",
      "Epoch 74, Loss: 0.48064977445606055\n",
      "Epoch 75, Loss: 0.479286087399732\n",
      "Epoch 76, Loss: 0.4778903534997428\n",
      "Epoch 77, Loss: 0.4764372864369556\n",
      "Epoch 78, Loss: 0.474963052467113\n",
      "Epoch 79, Loss: 0.473500105366398\n",
      "Epoch 80, Loss: 0.4719936202808175\n",
      "Epoch 81, Loss: 0.47049914487057687\n",
      "Epoch 82, Loss: 0.4689975402804131\n",
      "Epoch 83, Loss: 0.4675347310440145\n",
      "Epoch 84, Loss: 0.46608935889574366\n",
      "Epoch 85, Loss: 0.46467062988134955\n",
      "Epoch 86, Loss: 0.46325538846117736\n",
      "Epoch 87, Loss: 0.4618721553833618\n",
      "Epoch 88, Loss: 0.4605306187317534\n",
      "Epoch 89, Loss: 0.45921853768005344\n",
      "Epoch 90, Loss: 0.4579097748614688\n",
      "Epoch 91, Loss: 0.45662408607886434\n",
      "Epoch 92, Loss: 0.4553978578546441\n",
      "Epoch 93, Loss: 0.45420278425996846\n",
      "Epoch 94, Loss: 0.452976054342906\n",
      "Epoch 95, Loss: 0.45167303943302484\n",
      "Epoch 96, Loss: 0.45038283077486707\n",
      "Epoch 97, Loss: 0.4491530328862452\n",
      "Epoch 98, Loss: 0.44796310413263546\n",
      "Epoch 99, Loss: 0.44675483021529155\n",
      "Epoch 100, Loss: 0.44572060272424413\n",
      "Epoch 101, Loss: 0.44484096792869887\n",
      "Epoch 102, Loss: 0.44406183193084053\n",
      "Epoch 103, Loss: 0.44335646775422605\n",
      "Epoch 104, Loss: 0.4426360763223983\n",
      "Epoch 105, Loss: 0.4418881073374145\n",
      "Epoch 106, Loss: 0.4410418635250632\n",
      "Epoch 107, Loss: 0.4401255570429554\n",
      "Epoch 108, Loss: 0.4392133100804476\n",
      "Epoch 109, Loss: 0.43828281123517326\n",
      "Epoch 110, Loss: 0.43738695795960403\n",
      "Epoch 111, Loss: 0.4365274313929604\n",
      "Epoch 112, Loss: 0.435722897118424\n",
      "Epoch 113, Loss: 0.4349620467926803\n",
      "Epoch 114, Loss: 0.4342445438351894\n",
      "Epoch 115, Loss: 0.43354341713134764\n",
      "Epoch 116, Loss: 0.4327829357750397\n",
      "Epoch 117, Loss: 0.4320243234751726\n",
      "Epoch 118, Loss: 0.4312835873778953\n",
      "Epoch 119, Loss: 0.4305425805611588\n",
      "Epoch 120, Loss: 0.4298400608072215\n",
      "Epoch 121, Loss: 0.42910644083978794\n",
      "Epoch 122, Loss: 0.42831717375628525\n",
      "Epoch 123, Loss: 0.42752596162857737\n",
      "Epoch 124, Loss: 0.4267700856973277\n",
      "Epoch 125, Loss: 0.4260381745876965\n",
      "Epoch 126, Loss: 0.4253145162070734\n",
      "Epoch 127, Loss: 0.42445065884336236\n",
      "Epoch 128, Loss: 0.4235146941312163\n",
      "Epoch 129, Loss: 0.4227197454850689\n",
      "Epoch 130, Loss: 0.42198308690357195\n",
      "Epoch 131, Loss: 0.4212351644716527\n",
      "Epoch 132, Loss: 0.4204237312136696\n",
      "Epoch 133, Loss: 0.4196250576227198\n",
      "Epoch 134, Loss: 0.41895025646075756\n",
      "Epoch 135, Loss: 0.4182578183530454\n",
      "Epoch 136, Loss: 0.4175074161510457\n",
      "Epoch 137, Loss: 0.4167535532323329\n",
      "Epoch 138, Loss: 0.4160418255932536\n",
      "Epoch 139, Loss: 0.4153830684586532\n",
      "Epoch 140, Loss: 0.41477783958282055\n",
      "Epoch 141, Loss: 0.41421644479979997\n",
      "Epoch 142, Loss: 0.4136802240237\n",
      "Epoch 143, Loss: 0.41309591150529934\n",
      "Epoch 144, Loss: 0.4124059468752623\n",
      "Epoch 145, Loss: 0.41170197729586094\n",
      "Epoch 146, Loss: 0.411089770313401\n",
      "Epoch 147, Loss: 0.4105393391796838\n",
      "Epoch 148, Loss: 0.40996494373037856\n",
      "Epoch 149, Loss: 0.40939813213658394\n",
      "Epoch 150, Loss: 0.40878119900827564\n",
      "Epoch 151, Loss: 0.4081332498274498\n",
      "Epoch 152, Loss: 0.40753928419334007\n",
      "Epoch 153, Loss: 0.4070106684191\n",
      "Epoch 154, Loss: 0.4065476940722524\n",
      "Epoch 155, Loss: 0.40618189827771406\n",
      "Epoch 156, Loss: 0.40582276767564884\n",
      "Epoch 157, Loss: 0.40527029380957874\n",
      "Epoch 158, Loss: 0.40442681182570556\n",
      "Epoch 159, Loss: 0.4037984087949995\n",
      "Epoch 160, Loss: 0.40351181471614517\n",
      "Epoch 161, Loss: 0.4031952301476486\n",
      "Epoch 162, Loss: 0.4025665518135237\n",
      "Epoch 163, Loss: 0.4019354628231175\n",
      "Epoch 164, Loss: 0.4015383019188424\n",
      "Epoch 165, Loss: 0.40124604561898214\n",
      "Epoch 166, Loss: 0.4008281457245435\n",
      "Epoch 167, Loss: 0.40024156354367935\n",
      "Epoch 168, Loss: 0.39967814997517837\n",
      "Epoch 169, Loss: 0.39926627859730085\n",
      "Epoch 170, Loss: 0.398961564026875\n",
      "Epoch 171, Loss: 0.39869978630413244\n",
      "Epoch 172, Loss: 0.3983059647300975\n",
      "Epoch 173, Loss: 0.39780819506237486\n",
      "Epoch 174, Loss: 0.3972213923042508\n",
      "Epoch 175, Loss: 0.3966684524845881\n",
      "Epoch 176, Loss: 0.3962433180862369\n",
      "Epoch 177, Loss: 0.39591587820531954\n",
      "Epoch 178, Loss: 0.3957664491797801\n",
      "Epoch 179, Loss: 0.39575208490970776\n",
      "Epoch 180, Loss: 0.3955724592710575\n",
      "Epoch 181, Loss: 0.39481149294883144\n",
      "Epoch 182, Loss: 0.39399959131645657\n",
      "Epoch 183, Loss: 0.39378666252931377\n",
      "Epoch 184, Loss: 0.39386258256636486\n",
      "Epoch 185, Loss: 0.3934931363800155\n",
      "Epoch 186, Loss: 0.3927447786123721\n",
      "Epoch 187, Loss: 0.39238667920544357\n",
      "Epoch 188, Loss: 0.39233641513909406\n",
      "Epoch 189, Loss: 0.3920580327299275\n",
      "Epoch 190, Loss: 0.3915295427644288\n",
      "Epoch 191, Loss: 0.3910389233030416\n",
      "Epoch 192, Loss: 0.3908132290329288\n",
      "Epoch 193, Loss: 0.39067542704295666\n",
      "Epoch 194, Loss: 0.39042979131165767\n",
      "Epoch 195, Loss: 0.3900728137561781\n",
      "Epoch 196, Loss: 0.3896911138812073\n",
      "Epoch 197, Loss: 0.3893008486341883\n",
      "Epoch 198, Loss: 0.38894605311068164\n",
      "Epoch 199, Loss: 0.38866160010170253\n",
      "Epoch 200, Loss: 0.388415688280566\n",
      "Epoch 201, Loss: 0.3881733635088177\n",
      "Epoch 202, Loss: 0.38792679647801764\n",
      "Epoch 203, Loss: 0.38791216111494575\n",
      "Epoch 204, Loss: 0.3883671164791414\n",
      "Epoch 205, Loss: 0.3891050905255943\n",
      "Epoch 206, Loss: 0.3891883562273709\n",
      "Epoch 207, Loss: 0.38693477877481197\n",
      "Epoch 208, Loss: 0.3869391882343091\n",
      "Epoch 209, Loss: 0.3878488500866964\n",
      "Epoch 210, Loss: 0.38605505894163783\n",
      "Epoch 211, Loss: 0.3860697261077833\n",
      "Epoch 212, Loss: 0.38699556327095236\n",
      "Epoch 213, Loss: 0.3853638157392435\n",
      "Epoch 214, Loss: 0.3852900498989756\n",
      "Epoch 215, Loss: 0.3857016047122657\n",
      "Epoch 216, Loss: 0.384575055947021\n",
      "Epoch 217, Loss: 0.3845412476319947\n",
      "Epoch 218, Loss: 0.3847450793052641\n",
      "Epoch 219, Loss: 0.3839477909701685\n",
      "Epoch 220, Loss: 0.38352718591506635\n",
      "Epoch 221, Loss: 0.38372730408568956\n",
      "Epoch 222, Loss: 0.3831876356939406\n",
      "Epoch 223, Loss: 0.38248932100485433\n",
      "Epoch 224, Loss: 0.38255630406006924\n",
      "Epoch 225, Loss: 0.3823800076720746\n",
      "Epoch 226, Loss: 0.38189419743409136\n",
      "Epoch 227, Loss: 0.3814417177217465\n",
      "Epoch 228, Loss: 0.3810185026647181\n",
      "Epoch 229, Loss: 0.3808661827065854\n",
      "Epoch 230, Loss: 0.3807926412951784\n",
      "Epoch 231, Loss: 0.3806646974342026\n",
      "Epoch 232, Loss: 0.3803513684624377\n",
      "Epoch 233, Loss: 0.37999117759451645\n",
      "Epoch 234, Loss: 0.37925920073451297\n",
      "Epoch 235, Loss: 0.3788013509680958\n",
      "Epoch 236, Loss: 0.3785730843880525\n",
      "Epoch 237, Loss: 0.37840930559640135\n",
      "Epoch 238, Loss: 0.3787019709862931\n",
      "Epoch 239, Loss: 0.37906159824600577\n",
      "Epoch 240, Loss: 0.3794697180126742\n",
      "Epoch 241, Loss: 0.37766670717621864\n",
      "Epoch 242, Loss: 0.3763201246149662\n",
      "Epoch 243, Loss: 0.37606295299074805\n",
      "Epoch 244, Loss: 0.3767411619376178\n",
      "Epoch 245, Loss: 0.3776231256745944\n",
      "Epoch 246, Loss: 0.37608496354176135\n",
      "Epoch 247, Loss: 0.37472707035185765\n",
      "Epoch 248, Loss: 0.37380616572985886\n",
      "Epoch 249, Loss: 0.3743791606716454\n",
      "Epoch 250, Loss: 0.3747535332722496\n",
      "Epoch 251, Loss: 0.37348157710353697\n",
      "Epoch 252, Loss: 0.37267952452459463\n",
      "Epoch 253, Loss: 0.3714465020706588\n",
      "Epoch 254, Loss: 0.3718472911224652\n",
      "Epoch 255, Loss: 0.3736389016085481\n",
      "Epoch 256, Loss: 0.3732341875289898\n",
      "Epoch 257, Loss: 0.37336691265076527\n",
      "Epoch 258, Loss: 0.36929172874627203\n",
      "Epoch 259, Loss: 0.3710551392395566\n",
      "Epoch 260, Loss: 0.373819260606731\n",
      "Epoch 261, Loss: 0.36914112958924056\n",
      "Epoch 262, Loss: 0.36791560848266797\n",
      "Epoch 263, Loss: 0.37039462036089255\n",
      "Epoch 264, Loss: 0.3670948601593328\n",
      "Epoch 265, Loss: 0.3666272861111597\n",
      "Epoch 266, Loss: 0.3677691864075911\n",
      "Epoch 267, Loss: 0.36704233018853616\n",
      "Epoch 268, Loss: 0.3640895178596942\n",
      "Epoch 269, Loss: 0.3642192953163755\n",
      "Epoch 270, Loss: 0.36322301992705963\n",
      "Epoch 271, Loss: 0.36458679152165585\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.25377491024024534\n",
      "Test R^2 score: 0.3015292767734808\n",
      "Num of epochs: 272\n",
      "Epoch 1, Loss: 0.5726795197009645\n",
      "Epoch 2, Loss: 0.5710741992114018\n",
      "Epoch 3, Loss: 0.5696387033913267\n",
      "Epoch 4, Loss: 0.5682804013472212\n",
      "Epoch 5, Loss: 0.5669947230919342\n",
      "Epoch 6, Loss: 0.5657808468492489\n",
      "Epoch 7, Loss: 0.5646385231585929\n",
      "Epoch 8, Loss: 0.5635657545666078\n",
      "Epoch 9, Loss: 0.5625708058615754\n",
      "Epoch 10, Loss: 0.5616536130529656\n",
      "Epoch 11, Loss: 0.5608056830023007\n",
      "Epoch 12, Loss: 0.5600261329615919\n",
      "Epoch 13, Loss: 0.5593845132199953\n",
      "Epoch 14, Loss: 0.5587977590354188\n",
      "Epoch 15, Loss: 0.558255873711141\n",
      "Epoch 16, Loss: 0.557759121603523\n",
      "Epoch 17, Loss: 0.5573095217782734\n",
      "Epoch 18, Loss: 0.5569073489776432\n",
      "Epoch 19, Loss: 0.556557418226017\n",
      "Epoch 20, Loss: 0.5562438353721973\n",
      "Epoch 21, Loss: 0.555963633257036\n",
      "Epoch 22, Loss: 0.555735498003182\n",
      "Epoch 23, Loss: 0.5555282453606051\n",
      "Epoch 24, Loss: 0.5553263356938358\n",
      "Epoch 25, Loss: 0.5551217488187447\n",
      "Epoch 26, Loss: 0.5549280155598849\n",
      "Epoch 27, Loss: 0.5546958009340505\n",
      "Epoch 28, Loss: 0.5543818639181952\n",
      "Epoch 29, Loss: 0.5539549167274721\n",
      "Epoch 30, Loss: 0.5533645865316001\n",
      "Epoch 31, Loss: 0.5525419082109856\n",
      "Epoch 32, Loss: 0.5514794111481022\n",
      "Epoch 33, Loss: 0.5502176309378007\n",
      "Epoch 34, Loss: 0.5486916749149904\n",
      "Epoch 35, Loss: 0.5468260334436075\n",
      "Epoch 36, Loss: 0.5445792649060462\n",
      "Epoch 37, Loss: 0.5419342009996412\n",
      "Epoch 38, Loss: 0.5390300464535969\n",
      "Epoch 39, Loss: 0.5360031110011388\n",
      "Epoch 40, Loss: 0.5331713209343583\n",
      "Epoch 41, Loss: 0.5309647186828537\n",
      "Epoch 42, Loss: 0.5295376669820498\n",
      "Epoch 43, Loss: 0.5280723060187756\n",
      "Epoch 44, Loss: 0.5256425898599044\n",
      "Epoch 45, Loss: 0.5228627593787026\n",
      "Epoch 46, Loss: 0.5206893117779503\n",
      "Epoch 47, Loss: 0.5191012158731071\n",
      "Epoch 48, Loss: 0.5176268932470959\n",
      "Epoch 49, Loss: 0.5158276015391019\n",
      "Epoch 50, Loss: 0.51362528426496\n",
      "Epoch 51, Loss: 0.5113032452247362\n",
      "Epoch 52, Loss: 0.5093082115057391\n",
      "Epoch 53, Loss: 0.5077844758737409\n",
      "Epoch 54, Loss: 0.5062053484122068\n",
      "Epoch 55, Loss: 0.5040920122166432\n",
      "Epoch 56, Loss: 0.5018231412857046\n",
      "Epoch 57, Loss: 0.4999186479428856\n",
      "Epoch 58, Loss: 0.4982954863329498\n",
      "Epoch 59, Loss: 0.4965170008446456\n",
      "Epoch 60, Loss: 0.49444816277060705\n",
      "Epoch 61, Loss: 0.4924364066094273\n",
      "Epoch 62, Loss: 0.49073298049618336\n",
      "Epoch 63, Loss: 0.48911306101585433\n",
      "Epoch 64, Loss: 0.4873243492303334\n",
      "Epoch 65, Loss: 0.48564360215976315\n",
      "Epoch 66, Loss: 0.4842217264394749\n",
      "Epoch 67, Loss: 0.4827532228789964\n",
      "Epoch 68, Loss: 0.48116380922915697\n",
      "Epoch 69, Loss: 0.47973679404199704\n",
      "Epoch 70, Loss: 0.4784879248250438\n",
      "Epoch 71, Loss: 0.4770550761815282\n",
      "Epoch 72, Loss: 0.4756114412397766\n",
      "Epoch 73, Loss: 0.47438681450808584\n",
      "Epoch 74, Loss: 0.4730486541386986\n",
      "Epoch 75, Loss: 0.47157752468778347\n",
      "Epoch 76, Loss: 0.4703214213643558\n",
      "Epoch 77, Loss: 0.4691748124624363\n",
      "Epoch 78, Loss: 0.46796125173531905\n",
      "Epoch 79, Loss: 0.46683751013191427\n",
      "Epoch 80, Loss: 0.4657000980365217\n",
      "Epoch 81, Loss: 0.46446931007103553\n",
      "Epoch 82, Loss: 0.46328115286351645\n",
      "Epoch 83, Loss: 0.4620639324013814\n",
      "Epoch 84, Loss: 0.460803723723421\n",
      "Epoch 85, Loss: 0.45962753685382635\n",
      "Epoch 86, Loss: 0.45839214670084927\n",
      "Epoch 87, Loss: 0.45720147769235286\n",
      "Epoch 88, Loss: 0.4561124352564211\n",
      "Epoch 89, Loss: 0.45502564942197415\n",
      "Epoch 90, Loss: 0.4541007749489138\n",
      "Epoch 91, Loss: 0.45325824817258004\n",
      "Epoch 92, Loss: 0.4525583440091705\n",
      "Epoch 93, Loss: 0.4519338407498906\n",
      "Epoch 94, Loss: 0.4513436357930786\n",
      "Epoch 95, Loss: 0.45066959115507654\n",
      "Epoch 96, Loss: 0.44983589239701116\n",
      "Epoch 97, Loss: 0.4489535502586864\n",
      "Epoch 98, Loss: 0.4480448934815548\n",
      "Epoch 99, Loss: 0.4471835431737605\n",
      "Epoch 100, Loss: 0.4463040539249907\n",
      "Epoch 101, Loss: 0.4454575018129993\n",
      "Epoch 102, Loss: 0.444565095601897\n",
      "Epoch 103, Loss: 0.4436251478111642\n",
      "Epoch 104, Loss: 0.442631901893788\n",
      "Epoch 105, Loss: 0.44164441865391263\n",
      "Epoch 106, Loss: 0.44072103062639895\n",
      "Epoch 107, Loss: 0.43983761391840015\n",
      "Epoch 108, Loss: 0.43904276019483895\n",
      "Epoch 109, Loss: 0.4383142761462104\n",
      "Epoch 110, Loss: 0.4375701235022751\n",
      "Epoch 111, Loss: 0.4368428164949082\n",
      "Epoch 112, Loss: 0.4360864829069897\n",
      "Epoch 113, Loss: 0.4354136310209959\n",
      "Epoch 114, Loss: 0.4349417481388319\n",
      "Epoch 115, Loss: 0.43478232366226016\n",
      "Epoch 116, Loss: 0.4337745323993853\n",
      "Epoch 117, Loss: 0.4324874855722654\n",
      "Epoch 118, Loss: 0.4324102660346418\n",
      "Epoch 119, Loss: 0.4312292183830655\n",
      "Epoch 120, Loss: 0.4304422166127514\n",
      "Epoch 121, Loss: 0.4300699092901421\n",
      "Epoch 122, Loss: 0.42891689905728914\n",
      "Epoch 123, Loss: 0.4285416496949416\n",
      "Epoch 124, Loss: 0.4277861402707067\n",
      "Epoch 125, Loss: 0.4269118391145409\n",
      "Epoch 126, Loss: 0.426555227560014\n",
      "Epoch 127, Loss: 0.4256767354659083\n",
      "Epoch 128, Loss: 0.4250026548527094\n",
      "Epoch 129, Loss: 0.42461178663984955\n",
      "Epoch 130, Loss: 0.423713879635277\n",
      "Epoch 131, Loss: 0.42309265663912393\n",
      "Epoch 132, Loss: 0.4226425923169788\n",
      "Epoch 133, Loss: 0.4218739050391787\n",
      "Epoch 134, Loss: 0.42109923208769545\n",
      "Epoch 135, Loss: 0.42052368686902575\n",
      "Epoch 136, Loss: 0.42001203411890803\n",
      "Epoch 137, Loss: 0.41930276342400674\n",
      "Epoch 138, Loss: 0.4186008344266497\n",
      "Epoch 139, Loss: 0.4179412618849706\n",
      "Epoch 140, Loss: 0.4174240520348414\n",
      "Epoch 141, Loss: 0.41693795630982294\n",
      "Epoch 142, Loss: 0.4165657239075183\n",
      "Epoch 143, Loss: 0.416125753090917\n",
      "Epoch 144, Loss: 0.41549655607497016\n",
      "Epoch 145, Loss: 0.41451963345858106\n",
      "Epoch 146, Loss: 0.4138529625212694\n",
      "Epoch 147, Loss: 0.4135651750712982\n",
      "Epoch 148, Loss: 0.41326577530790054\n",
      "Epoch 149, Loss: 0.4126520786847334\n",
      "Epoch 150, Loss: 0.41181213724059873\n",
      "Epoch 151, Loss: 0.41119994931466536\n",
      "Epoch 152, Loss: 0.41083399770978296\n",
      "Epoch 153, Loss: 0.41057973525115554\n",
      "Epoch 154, Loss: 0.4102656082413083\n",
      "Epoch 155, Loss: 0.40965823865572665\n",
      "Epoch 156, Loss: 0.4088743796080008\n",
      "Epoch 157, Loss: 0.40816223815866576\n",
      "Epoch 158, Loss: 0.40767478517655464\n",
      "Epoch 159, Loss: 0.4074424336148313\n",
      "Epoch 160, Loss: 0.40735102885144325\n",
      "Epoch 161, Loss: 0.40729017241155896\n",
      "Epoch 162, Loss: 0.4066627129997038\n",
      "Epoch 163, Loss: 0.4055363181674154\n",
      "Epoch 164, Loss: 0.4047398927273679\n",
      "Epoch 165, Loss: 0.40470949945341067\n",
      "Epoch 166, Loss: 0.404880931093562\n",
      "Epoch 167, Loss: 0.4042447190113769\n",
      "Epoch 168, Loss: 0.40310916499893124\n",
      "Epoch 169, Loss: 0.4024975491976315\n",
      "Epoch 170, Loss: 0.4024527689073239\n",
      "Epoch 171, Loss: 0.40229239645321657\n",
      "Epoch 172, Loss: 0.4016978069293037\n",
      "Epoch 173, Loss: 0.4008661191436549\n",
      "Epoch 174, Loss: 0.40032590017291964\n",
      "Epoch 175, Loss: 0.39995005489505886\n",
      "Epoch 176, Loss: 0.39982028440643863\n",
      "Epoch 177, Loss: 0.3997133434849469\n",
      "Epoch 178, Loss: 0.3995684113300177\n",
      "Epoch 179, Loss: 0.399310371351457\n",
      "Epoch 180, Loss: 0.39828858678202744\n",
      "Epoch 181, Loss: 0.3975558905625559\n",
      "Epoch 182, Loss: 0.3970370645108564\n",
      "Epoch 183, Loss: 0.39703062790811045\n",
      "Epoch 184, Loss: 0.39719432539819194\n",
      "Epoch 185, Loss: 0.39711793537958395\n",
      "Epoch 186, Loss: 0.3966175475816503\n",
      "Epoch 187, Loss: 0.3953290181987236\n",
      "Epoch 188, Loss: 0.3947433052872357\n",
      "Epoch 189, Loss: 0.3944482810527103\n",
      "Epoch 190, Loss: 0.3946451079496126\n",
      "Epoch 191, Loss: 0.39468139208781555\n",
      "Epoch 192, Loss: 0.3942532078957779\n",
      "Epoch 193, Loss: 0.3933957633316895\n",
      "Epoch 194, Loss: 0.39240978674218685\n",
      "Epoch 195, Loss: 0.39209911672759734\n",
      "Epoch 196, Loss: 0.39200917099301585\n",
      "Epoch 197, Loss: 0.3921663392578025\n",
      "Epoch 198, Loss: 0.3920307423667008\n",
      "Epoch 199, Loss: 0.3914711180821103\n",
      "Epoch 200, Loss: 0.39080413525608326\n",
      "Epoch 201, Loss: 0.3898161715918238\n",
      "Epoch 202, Loss: 0.38920533649083217\n",
      "Epoch 203, Loss: 0.38881703642059956\n",
      "Epoch 204, Loss: 0.3884394732031571\n",
      "Epoch 205, Loss: 0.38846176065560617\n",
      "Epoch 206, Loss: 0.38922761837332603\n",
      "Epoch 207, Loss: 0.3920037351997173\n",
      "Epoch 208, Loss: 0.39461716575688205\n",
      "Epoch 209, Loss: 0.3892934611563343\n",
      "Epoch 210, Loss: 0.38617023909876524\n",
      "Epoch 211, Loss: 0.38907734409800965\n",
      "Epoch 212, Loss: 0.3879137360755423\n",
      "Epoch 213, Loss: 0.3848209438156549\n",
      "Epoch 214, Loss: 0.3863350284218046\n",
      "Epoch 215, Loss: 0.38655325691194187\n",
      "Epoch 216, Loss: 0.38432957295505105\n",
      "Epoch 217, Loss: 0.38319337153878896\n",
      "Epoch 218, Loss: 0.38455711562964073\n",
      "Epoch 219, Loss: 0.384598419727713\n",
      "Epoch 220, Loss: 0.38217885261041606\n",
      "Epoch 221, Loss: 0.3815153878922051\n",
      "Epoch 222, Loss: 0.3826437987127769\n",
      "Epoch 223, Loss: 0.3826197508745069\n",
      "Epoch 224, Loss: 0.38047599080615524\n",
      "Epoch 225, Loss: 0.3790890164389911\n",
      "Epoch 226, Loss: 0.37875479197854206\n",
      "Epoch 227, Loss: 0.37877583963234257\n",
      "Epoch 228, Loss: 0.3793092924024218\n",
      "Epoch 229, Loss: 0.3799169176967857\n",
      "Epoch 230, Loss: 0.3794739982419859\n",
      "Epoch 231, Loss: 0.3780660654279195\n",
      "Epoch 232, Loss: 0.37614995747983937\n",
      "Epoch 233, Loss: 0.3743706428771021\n",
      "Epoch 234, Loss: 0.373693355395119\n",
      "Epoch 235, Loss: 0.37460041612208933\n",
      "Epoch 236, Loss: 0.3764987836250728\n",
      "Epoch 237, Loss: 0.37902661014484357\n",
      "Epoch 238, Loss: 0.37861002324640636\n",
      "Epoch 239, Loss: 0.37271806696034965\n",
      "Epoch 240, Loss: 0.36989911179560947\n",
      "Epoch 241, Loss: 0.37146419305863243\n",
      "Epoch 242, Loss: 0.37355570019843304\n",
      "Epoch 243, Loss: 0.37376189487245376\n",
      "Epoch 244, Loss: 0.3690638992257205\n",
      "Epoch 245, Loss: 0.3662907221031283\n",
      "Epoch 246, Loss: 0.3663941802291956\n",
      "Epoch 247, Loss: 0.3680851899918434\n",
      "Epoch 248, Loss: 0.37287261647668857\n",
      "Epoch 249, Loss: 0.36992273783759383\n",
      "Epoch 250, Loss: 0.36566261440365677\n",
      "Epoch 251, Loss: 0.36248867165195164\n",
      "Epoch 252, Loss: 0.3621209184932111\n",
      "Epoch 253, Loss: 0.3640258909818818\n",
      "Epoch 254, Loss: 0.3671277383098887\n",
      "Epoch 255, Loss: 0.3687169706778711\n",
      "Epoch 256, Loss: 0.36375242871525665\n",
      "Epoch 257, Loss: 0.35943681765740143\n",
      "Epoch 258, Loss: 0.35779987212973624\n",
      "Epoch 259, Loss: 0.35848798334792825\n",
      "Epoch 260, Loss: 0.3604789240029252\n",
      "Epoch 261, Loss: 0.3635381590046396\n",
      "Epoch 262, Loss: 0.3667416808310115\n",
      "Epoch 263, Loss: 0.35782758689291216\n",
      "Epoch 264, Loss: 0.3547942920855727\n",
      "Epoch 265, Loss: 0.3549867862942071\n",
      "Epoch 266, Loss: 0.3572990748505849\n",
      "Epoch 267, Loss: 0.3622788988173829\n",
      "Epoch 268, Loss: 0.35930299037466107\n",
      "Epoch 269, Loss: 0.35481243537927776\n",
      "Epoch 270, Loss: 0.3507379398923571\n",
      "Epoch 271, Loss: 0.35072277235851435\n",
      "Epoch 272, Loss: 0.3525723048041874\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2622177253395105\n",
      "Test R^2 score: 0.25178316338892154\n",
      "Num of epochs: 273\n",
      "Epoch 1, Loss: 0.5662947183176451\n",
      "Epoch 2, Loss: 0.5649695756198183\n",
      "Epoch 3, Loss: 0.5637635503438785\n",
      "Epoch 4, Loss: 0.5626716087086231\n",
      "Epoch 5, Loss: 0.5616862450799266\n",
      "Epoch 6, Loss: 0.5608148499183138\n",
      "Epoch 7, Loss: 0.5600845610261703\n",
      "Epoch 8, Loss: 0.5594346978922111\n",
      "Epoch 9, Loss: 0.5588621281758587\n",
      "Epoch 10, Loss: 0.5583625795286568\n",
      "Epoch 11, Loss: 0.5579313338614055\n",
      "Epoch 12, Loss: 0.5575629907782689\n",
      "Epoch 13, Loss: 0.5572499737934228\n",
      "Epoch 14, Loss: 0.5570015523519064\n",
      "Epoch 15, Loss: 0.5567949583026754\n",
      "Epoch 16, Loss: 0.5566240810144266\n",
      "Epoch 17, Loss: 0.5564832498372217\n",
      "Epoch 18, Loss: 0.5563675327644115\n",
      "Epoch 19, Loss: 0.5562721773077082\n",
      "Epoch 20, Loss: 0.5561927465913042\n",
      "Epoch 21, Loss: 0.5561250674933\n",
      "Epoch 22, Loss: 0.5560635168394911\n",
      "Epoch 23, Loss: 0.5560071854555875\n",
      "Epoch 24, Loss: 0.5559502855002549\n",
      "Epoch 25, Loss: 0.555890243434499\n",
      "Epoch 26, Loss: 0.5558205972362874\n",
      "Epoch 27, Loss: 0.5557334065536267\n",
      "Epoch 28, Loss: 0.5556193838275497\n",
      "Epoch 29, Loss: 0.5554699550352693\n",
      "Epoch 30, Loss: 0.5552759138945037\n",
      "Epoch 31, Loss: 0.5550273337807282\n",
      "Epoch 32, Loss: 0.5547031883922467\n",
      "Epoch 33, Loss: 0.5542760047989175\n",
      "Epoch 34, Loss: 0.5537230475176226\n",
      "Epoch 35, Loss: 0.5530216562314455\n",
      "Epoch 36, Loss: 0.5521535618817164\n",
      "Epoch 37, Loss: 0.5510474569476772\n",
      "Epoch 38, Loss: 0.5496254555980329\n",
      "Epoch 39, Loss: 0.5477876404922626\n",
      "Epoch 40, Loss: 0.5454268491371032\n",
      "Epoch 41, Loss: 0.5425152428414916\n",
      "Epoch 42, Loss: 0.5390693553543943\n",
      "Epoch 43, Loss: 0.5351298527576638\n",
      "Epoch 44, Loss: 0.5310393364537045\n",
      "Epoch 45, Loss: 0.5274058270121295\n",
      "Epoch 46, Loss: 0.5251999689919288\n",
      "Epoch 47, Loss: 0.5245355504427547\n",
      "Epoch 48, Loss: 0.5229442036991089\n",
      "Epoch 49, Loss: 0.5195831330285481\n",
      "Epoch 50, Loss: 0.5157534699353322\n",
      "Epoch 51, Loss: 0.5125464813739801\n",
      "Epoch 52, Loss: 0.5101928674428853\n",
      "Epoch 53, Loss: 0.5082924555409044\n",
      "Epoch 54, Loss: 0.5062980075726154\n",
      "Epoch 55, Loss: 0.5038759089362109\n",
      "Epoch 56, Loss: 0.5009897687632519\n",
      "Epoch 57, Loss: 0.4978641099871357\n",
      "Epoch 58, Loss: 0.4948538205778565\n",
      "Epoch 59, Loss: 0.49233444987150865\n",
      "Epoch 60, Loss: 0.49029417547115367\n",
      "Epoch 61, Loss: 0.4882213861008129\n",
      "Epoch 62, Loss: 0.48574963216134526\n",
      "Epoch 63, Loss: 0.48317173737925306\n",
      "Epoch 64, Loss: 0.4809340728082428\n",
      "Epoch 65, Loss: 0.4791467824901328\n",
      "Epoch 66, Loss: 0.477587348353444\n",
      "Epoch 67, Loss: 0.4758579643302504\n",
      "Epoch 68, Loss: 0.47398754875210825\n",
      "Epoch 69, Loss: 0.4722051595974306\n",
      "Epoch 70, Loss: 0.4706986771369452\n",
      "Epoch 71, Loss: 0.4693975267706356\n",
      "Epoch 72, Loss: 0.46805610159902794\n",
      "Epoch 73, Loss: 0.46661039641853275\n",
      "Epoch 74, Loss: 0.46522403836878384\n",
      "Epoch 75, Loss: 0.4640150296370913\n",
      "Epoch 76, Loss: 0.46287060143021125\n",
      "Epoch 77, Loss: 0.4617729213325192\n",
      "Epoch 78, Loss: 0.46061035443526027\n",
      "Epoch 79, Loss: 0.45947559124681125\n",
      "Epoch 80, Loss: 0.4584935587365024\n",
      "Epoch 81, Loss: 0.45758906175029734\n",
      "Epoch 82, Loss: 0.4566250487608718\n",
      "Epoch 83, Loss: 0.4556626916268759\n",
      "Epoch 84, Loss: 0.4548464664337489\n",
      "Epoch 85, Loss: 0.45408390790193925\n",
      "Epoch 86, Loss: 0.45322617683777594\n",
      "Epoch 87, Loss: 0.4523023339320759\n",
      "Epoch 88, Loss: 0.4513765341543295\n",
      "Epoch 89, Loss: 0.45046611593258995\n",
      "Epoch 90, Loss: 0.4495728796921174\n",
      "Epoch 91, Loss: 0.4486408663048795\n",
      "Epoch 92, Loss: 0.44766202793087395\n",
      "Epoch 93, Loss: 0.44672681178757145\n",
      "Epoch 94, Loss: 0.44572869310252095\n",
      "Epoch 95, Loss: 0.44475270941210837\n",
      "Epoch 96, Loss: 0.4438591547484809\n",
      "Epoch 97, Loss: 0.44296546275485044\n",
      "Epoch 98, Loss: 0.44207630107234935\n",
      "Epoch 99, Loss: 0.44112647313223047\n",
      "Epoch 100, Loss: 0.4402175527775561\n",
      "Epoch 101, Loss: 0.439219993635688\n",
      "Epoch 102, Loss: 0.43822859653514096\n",
      "Epoch 103, Loss: 0.4372363828989134\n",
      "Epoch 104, Loss: 0.43632743582675365\n",
      "Epoch 105, Loss: 0.43538214472149783\n",
      "Epoch 106, Loss: 0.4344462356885475\n",
      "Epoch 107, Loss: 0.4335313872432883\n",
      "Epoch 108, Loss: 0.43259588322591946\n",
      "Epoch 109, Loss: 0.43170220811750576\n",
      "Epoch 110, Loss: 0.430813423950453\n",
      "Epoch 111, Loss: 0.42988321875380126\n",
      "Epoch 112, Loss: 0.4289772579427369\n",
      "Epoch 113, Loss: 0.42807524524239027\n",
      "Epoch 114, Loss: 0.42715939759337984\n",
      "Epoch 115, Loss: 0.42624514795153895\n",
      "Epoch 116, Loss: 0.4253389528556282\n",
      "Epoch 117, Loss: 0.4244478151721964\n",
      "Epoch 118, Loss: 0.42355286761495115\n",
      "Epoch 119, Loss: 0.42266062594984793\n",
      "Epoch 120, Loss: 0.42182008951073957\n",
      "Epoch 121, Loss: 0.42095560982198293\n",
      "Epoch 122, Loss: 0.4199834734072052\n",
      "Epoch 123, Loss: 0.4190136335813304\n",
      "Epoch 124, Loss: 0.4181585683020715\n",
      "Epoch 125, Loss: 0.4173326732632309\n",
      "Epoch 126, Loss: 0.4164565172325993\n",
      "Epoch 127, Loss: 0.4154812241453759\n",
      "Epoch 128, Loss: 0.4145452815792987\n",
      "Epoch 129, Loss: 0.4136961269744168\n",
      "Epoch 130, Loss: 0.4128921631465906\n",
      "Epoch 131, Loss: 0.41213609509376287\n",
      "Epoch 132, Loss: 0.41136733590042673\n",
      "Epoch 133, Loss: 0.4105010626845364\n",
      "Epoch 134, Loss: 0.4095949055533226\n",
      "Epoch 135, Loss: 0.4087618239614536\n",
      "Epoch 136, Loss: 0.40798851467894526\n",
      "Epoch 137, Loss: 0.4072790500836393\n",
      "Epoch 138, Loss: 0.4066105489757498\n",
      "Epoch 139, Loss: 0.40585863996334537\n",
      "Epoch 140, Loss: 0.40501597855683735\n",
      "Epoch 141, Loss: 0.4040484194798873\n",
      "Epoch 142, Loss: 0.40314149009629807\n",
      "Epoch 143, Loss: 0.40233408351507993\n",
      "Epoch 144, Loss: 0.4016178953799109\n",
      "Epoch 145, Loss: 0.4010568240220173\n",
      "Epoch 146, Loss: 0.4007145013679913\n",
      "Epoch 147, Loss: 0.4005012917515643\n",
      "Epoch 148, Loss: 0.3993612315113385\n",
      "Epoch 149, Loss: 0.3980722436130172\n",
      "Epoch 150, Loss: 0.3977537459071806\n",
      "Epoch 151, Loss: 0.39753103926768274\n",
      "Epoch 152, Loss: 0.3964363971113308\n",
      "Epoch 153, Loss: 0.3955948533719972\n",
      "Epoch 154, Loss: 0.39535807848142884\n",
      "Epoch 155, Loss: 0.39489195169794955\n",
      "Epoch 156, Loss: 0.3939583272680117\n",
      "Epoch 157, Loss: 0.39330217386872385\n",
      "Epoch 158, Loss: 0.3930818921942162\n",
      "Epoch 159, Loss: 0.39263427864170014\n",
      "Epoch 160, Loss: 0.3918434024160943\n",
      "Epoch 161, Loss: 0.3912144219428534\n",
      "Epoch 162, Loss: 0.39081298119695174\n",
      "Epoch 163, Loss: 0.39051264100611166\n",
      "Epoch 164, Loss: 0.3901408437575262\n",
      "Epoch 165, Loss: 0.38951420204630766\n",
      "Epoch 166, Loss: 0.38888588002531965\n",
      "Epoch 167, Loss: 0.388450597908973\n",
      "Epoch 168, Loss: 0.3881057565252337\n",
      "Epoch 169, Loss: 0.3878206295541522\n",
      "Epoch 170, Loss: 0.3876084583533203\n",
      "Epoch 171, Loss: 0.38723075572737053\n",
      "Epoch 172, Loss: 0.3867723447093959\n",
      "Epoch 173, Loss: 0.386254754731625\n",
      "Epoch 174, Loss: 0.38578268876701644\n",
      "Epoch 175, Loss: 0.38536835917598394\n",
      "Epoch 176, Loss: 0.38508476537952624\n",
      "Epoch 177, Loss: 0.38492166675943695\n",
      "Epoch 178, Loss: 0.38477809517883094\n",
      "Epoch 179, Loss: 0.3845615136034544\n",
      "Epoch 180, Loss: 0.38418112571769036\n",
      "Epoch 181, Loss: 0.38373163390554277\n",
      "Epoch 182, Loss: 0.3831917577334946\n",
      "Epoch 183, Loss: 0.38277234625911405\n",
      "Epoch 184, Loss: 0.38255959545192686\n",
      "Epoch 185, Loss: 0.38248626276043834\n",
      "Epoch 186, Loss: 0.3824824447904153\n",
      "Epoch 187, Loss: 0.38244697091011076\n",
      "Epoch 188, Loss: 0.3823146891959215\n",
      "Epoch 189, Loss: 0.38182421029660546\n",
      "Epoch 190, Loss: 0.38107291861855813\n",
      "Epoch 191, Loss: 0.3806840346270547\n",
      "Epoch 192, Loss: 0.38073542607594\n",
      "Epoch 193, Loss: 0.3807328821080107\n",
      "Epoch 194, Loss: 0.3804838236303918\n",
      "Epoch 195, Loss: 0.3802279397620957\n",
      "Epoch 196, Loss: 0.37980770751355075\n",
      "Epoch 197, Loss: 0.3793590042977859\n",
      "Epoch 198, Loss: 0.37917778274813824\n",
      "Epoch 199, Loss: 0.3792052907798963\n",
      "Epoch 200, Loss: 0.3790906280560093\n",
      "Epoch 201, Loss: 0.37876393899982586\n",
      "Epoch 202, Loss: 0.3785155730350801\n",
      "Epoch 203, Loss: 0.37836852704356666\n",
      "Epoch 204, Loss: 0.37807786978835856\n",
      "Epoch 205, Loss: 0.37777261155856373\n",
      "Epoch 206, Loss: 0.3776243292150061\n",
      "Epoch 207, Loss: 0.37754861708074433\n",
      "Epoch 208, Loss: 0.3774198696215066\n",
      "Epoch 209, Loss: 0.37724253558742965\n",
      "Epoch 210, Loss: 0.37726777538035083\n",
      "Epoch 211, Loss: 0.3776953313111243\n",
      "Epoch 212, Loss: 0.37825201517968865\n",
      "Epoch 213, Loss: 0.3786455220881901\n",
      "Epoch 214, Loss: 0.3779597110306149\n",
      "Epoch 215, Loss: 0.37683726294185466\n",
      "Epoch 216, Loss: 0.3762513976847393\n",
      "Epoch 217, Loss: 0.3767839951659999\n",
      "Epoch 218, Loss: 0.37696057643344577\n",
      "Epoch 219, Loss: 0.3759774542463552\n",
      "Epoch 220, Loss: 0.37563740679646546\n",
      "Epoch 221, Loss: 0.3760730570039955\n",
      "Epoch 222, Loss: 0.3759449734979488\n",
      "Epoch 223, Loss: 0.37553570154025623\n",
      "Epoch 224, Loss: 0.37536273737595055\n",
      "Epoch 225, Loss: 0.37508363585822574\n",
      "Epoch 226, Loss: 0.37508615855040256\n",
      "Epoch 227, Loss: 0.37519034879341\n",
      "Epoch 228, Loss: 0.3747556605633634\n",
      "Epoch 229, Loss: 0.37446235818858636\n",
      "Epoch 230, Loss: 0.3745322290247796\n",
      "Epoch 231, Loss: 0.37438481255919653\n",
      "Epoch 232, Loss: 0.37425216971553943\n",
      "Epoch 233, Loss: 0.3742421957169325\n",
      "Epoch 234, Loss: 0.3740404887085064\n",
      "Epoch 235, Loss: 0.37373362734984694\n",
      "Epoch 236, Loss: 0.37370222755985005\n",
      "Epoch 237, Loss: 0.37365431536762045\n",
      "Epoch 238, Loss: 0.3733795041175634\n",
      "Epoch 239, Loss: 0.37323496605451056\n",
      "Epoch 240, Loss: 0.373255326914606\n",
      "Epoch 241, Loss: 0.3731302697402224\n",
      "Epoch 242, Loss: 0.3729942644179412\n",
      "Epoch 243, Loss: 0.37313042948237374\n",
      "Epoch 244, Loss: 0.37361957867601836\n",
      "Epoch 245, Loss: 0.3744781160759901\n",
      "Epoch 246, Loss: 0.37515680690407877\n",
      "Epoch 247, Loss: 0.373696525473669\n",
      "Epoch 248, Loss: 0.3723152735966882\n",
      "Epoch 249, Loss: 0.37266425038193\n",
      "Epoch 250, Loss: 0.3734814175115754\n",
      "Epoch 251, Loss: 0.3729106994059129\n",
      "Epoch 252, Loss: 0.37193786586588995\n",
      "Epoch 253, Loss: 0.3720095326999354\n",
      "Epoch 254, Loss: 0.3724871125648117\n",
      "Epoch 255, Loss: 0.37222072734856804\n",
      "Epoch 256, Loss: 0.37140317364334574\n",
      "Epoch 257, Loss: 0.3713327942949306\n",
      "Epoch 258, Loss: 0.37177553289166326\n",
      "Epoch 259, Loss: 0.37181531122568096\n",
      "Epoch 260, Loss: 0.37128363318890895\n",
      "Epoch 261, Loss: 0.3707400794949508\n",
      "Epoch 262, Loss: 0.37077701503490845\n",
      "Epoch 263, Loss: 0.37111661740167645\n",
      "Epoch 264, Loss: 0.37103985846862625\n",
      "Epoch 265, Loss: 0.3705359432659656\n",
      "Epoch 266, Loss: 0.3701082092645578\n",
      "Epoch 267, Loss: 0.3702497823535555\n",
      "Epoch 268, Loss: 0.3704675913019937\n",
      "Epoch 269, Loss: 0.3703543072049484\n",
      "Epoch 270, Loss: 0.36996597784437474\n",
      "Epoch 271, Loss: 0.3694792914607688\n",
      "Epoch 272, Loss: 0.36935555795794855\n",
      "Epoch 273, Loss: 0.36951903470195524\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.26344251665136637\n",
      "Test R^2 score: 0.2505605507179862\n",
      "Num of epochs: 274\n",
      "Epoch 1, Loss: 0.5701381991815002\n",
      "Epoch 2, Loss: 0.5682822368488444\n",
      "Epoch 3, Loss: 0.5665614211529298\n",
      "Epoch 4, Loss: 0.5650509371203658\n",
      "Epoch 5, Loss: 0.5636789893787213\n",
      "Epoch 6, Loss: 0.5624245487048373\n",
      "Epoch 7, Loss: 0.5613024467482896\n",
      "Epoch 8, Loss: 0.560293213341628\n",
      "Epoch 9, Loss: 0.5594152798348726\n",
      "Epoch 10, Loss: 0.5586735595029055\n",
      "Epoch 11, Loss: 0.5580354047501932\n",
      "Epoch 12, Loss: 0.5574973757643583\n",
      "Epoch 13, Loss: 0.5570578366819169\n",
      "Epoch 14, Loss: 0.556713300277327\n",
      "Epoch 15, Loss: 0.5564582392060393\n",
      "Epoch 16, Loss: 0.5562864548813776\n",
      "Epoch 17, Loss: 0.5561887010809355\n",
      "Epoch 18, Loss: 0.556153281514999\n",
      "Epoch 19, Loss: 0.5561662493031534\n",
      "Epoch 20, Loss: 0.5562101339134414\n",
      "Epoch 21, Loss: 0.5562727666331967\n",
      "Epoch 22, Loss: 0.5563169106948357\n",
      "Epoch 23, Loss: 0.5563483558450847\n",
      "Epoch 24, Loss: 0.5563515431163043\n",
      "Epoch 25, Loss: 0.5563198035086147\n",
      "Epoch 26, Loss: 0.5562504789800403\n",
      "Epoch 27, Loss: 0.5561412780035951\n",
      "Epoch 28, Loss: 0.5559894969740599\n",
      "Epoch 29, Loss: 0.5557911866559634\n",
      "Epoch 30, Loss: 0.5555409863336519\n",
      "Epoch 31, Loss: 0.5552223474572061\n",
      "Epoch 32, Loss: 0.5548185274347435\n",
      "Epoch 33, Loss: 0.5543126464922697\n",
      "Epoch 34, Loss: 0.5536946558366663\n",
      "Epoch 35, Loss: 0.5529732070230148\n",
      "Epoch 36, Loss: 0.5521668394980643\n",
      "Epoch 37, Loss: 0.5512756671682296\n",
      "Epoch 38, Loss: 0.550228328343924\n",
      "Epoch 39, Loss: 0.5489163039427148\n",
      "Epoch 40, Loss: 0.5472301147615767\n",
      "Epoch 41, Loss: 0.5450971041362248\n",
      "Epoch 42, Loss: 0.5424826112940082\n",
      "Epoch 43, Loss: 0.5393516207476066\n",
      "Epoch 44, Loss: 0.5358507425358433\n",
      "Epoch 45, Loss: 0.5320656629459626\n",
      "Epoch 46, Loss: 0.5284651242282299\n",
      "Epoch 47, Loss: 0.5257815640180764\n",
      "Epoch 48, Loss: 0.5242844178048984\n",
      "Epoch 49, Loss: 0.5227793356163596\n",
      "Epoch 50, Loss: 0.5200756060674087\n",
      "Epoch 51, Loss: 0.5165478799254508\n",
      "Epoch 52, Loss: 0.5132415477430202\n",
      "Epoch 53, Loss: 0.5107644770993666\n",
      "Epoch 54, Loss: 0.50892400141985\n",
      "Epoch 55, Loss: 0.5072163530511317\n",
      "Epoch 56, Loss: 0.5051936183503728\n",
      "Epoch 57, Loss: 0.5028072171025584\n",
      "Epoch 58, Loss: 0.5001896260216472\n",
      "Epoch 59, Loss: 0.4975810247125044\n",
      "Epoch 60, Loss: 0.49508215424780855\n",
      "Epoch 61, Loss: 0.49264337227030613\n",
      "Epoch 62, Loss: 0.4901004167495058\n",
      "Epoch 63, Loss: 0.48735753997832\n",
      "Epoch 64, Loss: 0.48467268563903176\n",
      "Epoch 65, Loss: 0.48227916568129464\n",
      "Epoch 66, Loss: 0.48010697739812197\n",
      "Epoch 67, Loss: 0.4779856647093596\n",
      "Epoch 68, Loss: 0.4757401453311538\n",
      "Epoch 69, Loss: 0.4734554942019424\n",
      "Epoch 70, Loss: 0.47128982701972705\n",
      "Epoch 71, Loss: 0.4693594943709663\n",
      "Epoch 72, Loss: 0.467536069656598\n",
      "Epoch 73, Loss: 0.46601944991378275\n",
      "Epoch 74, Loss: 0.4651211624058957\n",
      "Epoch 75, Loss: 0.4647521561854241\n",
      "Epoch 76, Loss: 0.464588127054478\n",
      "Epoch 77, Loss: 0.46432684359884085\n",
      "Epoch 78, Loss: 0.4638138911096982\n",
      "Epoch 79, Loss: 0.4631722313944826\n",
      "Epoch 80, Loss: 0.4623539384684279\n",
      "Epoch 81, Loss: 0.4613395650738823\n",
      "Epoch 82, Loss: 0.4603260801996356\n",
      "Epoch 83, Loss: 0.45930395160796544\n",
      "Epoch 84, Loss: 0.4583667739315202\n",
      "Epoch 85, Loss: 0.4575851539930365\n",
      "Epoch 86, Loss: 0.4568927750736962\n",
      "Epoch 87, Loss: 0.4562664806315749\n",
      "Epoch 88, Loss: 0.45568741380070454\n",
      "Epoch 89, Loss: 0.4550933835332572\n",
      "Epoch 90, Loss: 0.4544300327004924\n",
      "Epoch 91, Loss: 0.4537070416641638\n",
      "Epoch 92, Loss: 0.4529585039151749\n",
      "Epoch 93, Loss: 0.45221109965337164\n",
      "Epoch 94, Loss: 0.45150635446151294\n",
      "Epoch 95, Loss: 0.450839775028264\n",
      "Epoch 96, Loss: 0.45020534148392344\n",
      "Epoch 97, Loss: 0.44960516191061317\n",
      "Epoch 98, Loss: 0.44902064059972296\n",
      "Epoch 99, Loss: 0.4484632524545873\n",
      "Epoch 100, Loss: 0.44789974786905057\n",
      "Epoch 101, Loss: 0.44730836755672704\n",
      "Epoch 102, Loss: 0.4466715369504664\n",
      "Epoch 103, Loss: 0.4459840161897757\n",
      "Epoch 104, Loss: 0.44530006859811166\n",
      "Epoch 105, Loss: 0.4446499396228996\n",
      "Epoch 106, Loss: 0.4440182902364226\n",
      "Epoch 107, Loss: 0.4434065100531784\n",
      "Epoch 108, Loss: 0.4428047879179451\n",
      "Epoch 109, Loss: 0.44220024198364166\n",
      "Epoch 110, Loss: 0.4415890475511301\n",
      "Epoch 111, Loss: 0.44097036597427736\n",
      "Epoch 112, Loss: 0.44035017221949235\n",
      "Epoch 113, Loss: 0.4397350847838804\n",
      "Epoch 114, Loss: 0.4391268387757897\n",
      "Epoch 115, Loss: 0.43852673691671507\n",
      "Epoch 116, Loss: 0.4379188882382437\n",
      "Epoch 117, Loss: 0.4373129547005558\n",
      "Epoch 118, Loss: 0.4367078523862816\n",
      "Epoch 119, Loss: 0.4361004070401233\n",
      "Epoch 120, Loss: 0.435485767131925\n",
      "Epoch 121, Loss: 0.43485939611810653\n",
      "Epoch 122, Loss: 0.4342311264091718\n",
      "Epoch 123, Loss: 0.4335938874665463\n",
      "Epoch 124, Loss: 0.43294896477406897\n",
      "Epoch 125, Loss: 0.4322840180543846\n",
      "Epoch 126, Loss: 0.4316000423081813\n",
      "Epoch 127, Loss: 0.43090687176117803\n",
      "Epoch 128, Loss: 0.43021888820025017\n",
      "Epoch 129, Loss: 0.4295600702157937\n",
      "Epoch 130, Loss: 0.4289088216124327\n",
      "Epoch 131, Loss: 0.42826317624823423\n",
      "Epoch 132, Loss: 0.42759883596959486\n",
      "Epoch 133, Loss: 0.42693752808278285\n",
      "Epoch 134, Loss: 0.42627150632350463\n",
      "Epoch 135, Loss: 0.4256195146148378\n",
      "Epoch 136, Loss: 0.4249789176648587\n",
      "Epoch 137, Loss: 0.42435387554599135\n",
      "Epoch 138, Loss: 0.4237523692410832\n",
      "Epoch 139, Loss: 0.4231710658501451\n",
      "Epoch 140, Loss: 0.4225951864585844\n",
      "Epoch 141, Loss: 0.4220145136124972\n",
      "Epoch 142, Loss: 0.421399714157911\n",
      "Epoch 143, Loss: 0.420779094017673\n",
      "Epoch 144, Loss: 0.4201608554450073\n",
      "Epoch 145, Loss: 0.4195452043141265\n",
      "Epoch 146, Loss: 0.4189375941136872\n",
      "Epoch 147, Loss: 0.41833617202142687\n",
      "Epoch 148, Loss: 0.4177696074479191\n",
      "Epoch 149, Loss: 0.4172123990861644\n",
      "Epoch 150, Loss: 0.4166545170761049\n",
      "Epoch 151, Loss: 0.4160023181201922\n",
      "Epoch 152, Loss: 0.4152976274087776\n",
      "Epoch 153, Loss: 0.41466084918556956\n",
      "Epoch 154, Loss: 0.4141397584058024\n",
      "Epoch 155, Loss: 0.41362817045318423\n",
      "Epoch 156, Loss: 0.41304356783832086\n",
      "Epoch 157, Loss: 0.41239982241077283\n",
      "Epoch 158, Loss: 0.41170400415756864\n",
      "Epoch 159, Loss: 0.4111053928827422\n",
      "Epoch 160, Loss: 0.4105671958358632\n",
      "Epoch 161, Loss: 0.41005892734282356\n",
      "Epoch 162, Loss: 0.40958244513140146\n",
      "Epoch 163, Loss: 0.4089785789508971\n",
      "Epoch 164, Loss: 0.4082529868012569\n",
      "Epoch 165, Loss: 0.4075674007409525\n",
      "Epoch 166, Loss: 0.4069986963708137\n",
      "Epoch 167, Loss: 0.4065277177386118\n",
      "Epoch 168, Loss: 0.40607435757699467\n",
      "Epoch 169, Loss: 0.40554756177720247\n",
      "Epoch 170, Loss: 0.40480921251623864\n",
      "Epoch 171, Loss: 0.4040659369302603\n",
      "Epoch 172, Loss: 0.40340064405641407\n",
      "Epoch 173, Loss: 0.40285548286376194\n",
      "Epoch 174, Loss: 0.4024349590730201\n",
      "Epoch 175, Loss: 0.40209568116724964\n",
      "Epoch 176, Loss: 0.4017753103967953\n",
      "Epoch 177, Loss: 0.4012150162749587\n",
      "Epoch 178, Loss: 0.4002945947625703\n",
      "Epoch 179, Loss: 0.3995124863510199\n",
      "Epoch 180, Loss: 0.39913018171708325\n",
      "Epoch 181, Loss: 0.3988859607334627\n",
      "Epoch 182, Loss: 0.39844546590583585\n",
      "Epoch 183, Loss: 0.39768501357578684\n",
      "Epoch 184, Loss: 0.39695942423821984\n",
      "Epoch 185, Loss: 0.39647325020953667\n",
      "Epoch 186, Loss: 0.39620587945669583\n",
      "Epoch 187, Loss: 0.3960582152910363\n",
      "Epoch 188, Loss: 0.3958153929743959\n",
      "Epoch 189, Loss: 0.39534021287963594\n",
      "Epoch 190, Loss: 0.3943230485628299\n",
      "Epoch 191, Loss: 0.39356229788944797\n",
      "Epoch 192, Loss: 0.39338879366347407\n",
      "Epoch 193, Loss: 0.3932959224129713\n",
      "Epoch 194, Loss: 0.39287883950984087\n",
      "Epoch 195, Loss: 0.3920182558219479\n",
      "Epoch 196, Loss: 0.39137385114332435\n",
      "Epoch 197, Loss: 0.3911228250203505\n",
      "Epoch 198, Loss: 0.3909790723180617\n",
      "Epoch 199, Loss: 0.3906776392755222\n",
      "Epoch 200, Loss: 0.39008933532729995\n",
      "Epoch 201, Loss: 0.3893953232643058\n",
      "Epoch 202, Loss: 0.3888416207155679\n",
      "Epoch 203, Loss: 0.38853680357902387\n",
      "Epoch 204, Loss: 0.3883950095594675\n",
      "Epoch 205, Loss: 0.3884608400288453\n",
      "Epoch 206, Loss: 0.3886592230343025\n",
      "Epoch 207, Loss: 0.38820823735160226\n",
      "Epoch 208, Loss: 0.3871160643275801\n",
      "Epoch 209, Loss: 0.38644532449973484\n",
      "Epoch 210, Loss: 0.38635273190654745\n",
      "Epoch 211, Loss: 0.38608302257027743\n",
      "Epoch 212, Loss: 0.3858201153422438\n",
      "Epoch 213, Loss: 0.3858640067978561\n",
      "Epoch 214, Loss: 0.3849449514382274\n",
      "Epoch 215, Loss: 0.3843733632432778\n",
      "Epoch 216, Loss: 0.38446356443120194\n",
      "Epoch 217, Loss: 0.38398714268289413\n",
      "Epoch 218, Loss: 0.38363772604409496\n",
      "Epoch 219, Loss: 0.3835765065592535\n",
      "Epoch 220, Loss: 0.38298192459535846\n",
      "Epoch 221, Loss: 0.3825809011734485\n",
      "Epoch 222, Loss: 0.38251238366569\n",
      "Epoch 223, Loss: 0.3820469656054069\n",
      "Epoch 224, Loss: 0.38205778891780434\n",
      "Epoch 225, Loss: 0.3824740490182027\n",
      "Epoch 226, Loss: 0.38254736457478333\n",
      "Epoch 227, Loss: 0.3822226943735014\n",
      "Epoch 228, Loss: 0.3816118290012459\n",
      "Epoch 229, Loss: 0.3802569197176214\n",
      "Epoch 230, Loss: 0.3802069920903765\n",
      "Epoch 231, Loss: 0.3804891890219355\n",
      "Epoch 232, Loss: 0.3800210970744245\n",
      "Epoch 233, Loss: 0.3798328749285804\n",
      "Epoch 234, Loss: 0.37898998711652937\n",
      "Epoch 235, Loss: 0.37819841476120303\n",
      "Epoch 236, Loss: 0.37840015000260707\n",
      "Epoch 237, Loss: 0.37827596645770023\n",
      "Epoch 238, Loss: 0.3780683908569569\n",
      "Epoch 239, Loss: 0.37781714210151074\n",
      "Epoch 240, Loss: 0.3771651269745314\n",
      "Epoch 241, Loss: 0.3761095084425906\n",
      "Epoch 242, Loss: 0.37603985142291707\n",
      "Epoch 243, Loss: 0.3760139545821261\n",
      "Epoch 244, Loss: 0.3754455184893094\n",
      "Epoch 245, Loss: 0.3757313907403411\n",
      "Epoch 246, Loss: 0.3761291788654433\n",
      "Epoch 247, Loss: 0.3759000824265264\n",
      "Epoch 248, Loss: 0.3751494983858367\n",
      "Epoch 249, Loss: 0.3746382637539769\n",
      "Epoch 250, Loss: 0.37315357140395206\n",
      "Epoch 251, Loss: 0.37338096078917127\n",
      "Epoch 252, Loss: 0.374239050169223\n",
      "Epoch 253, Loss: 0.37323891854364283\n",
      "Epoch 254, Loss: 0.37304264086172845\n",
      "Epoch 255, Loss: 0.37203494727401526\n",
      "Epoch 256, Loss: 0.3713382919078618\n",
      "Epoch 257, Loss: 0.3715829736444501\n",
      "Epoch 258, Loss: 0.3713577134799868\n",
      "Epoch 259, Loss: 0.37104419578162934\n",
      "Epoch 260, Loss: 0.37132914255084254\n",
      "Epoch 261, Loss: 0.37131086322607953\n",
      "Epoch 262, Loss: 0.37068223723562277\n",
      "Epoch 263, Loss: 0.37082592183468316\n",
      "Epoch 264, Loss: 0.37009949251818863\n",
      "Epoch 265, Loss: 0.36926112151007595\n",
      "Epoch 266, Loss: 0.3694259711338054\n",
      "Epoch 267, Loss: 0.36934000514315674\n",
      "Epoch 268, Loss: 0.3683801517715299\n",
      "Epoch 269, Loss: 0.36870959513149415\n",
      "Epoch 270, Loss: 0.36839200357726953\n",
      "Epoch 271, Loss: 0.3679818023504892\n",
      "Epoch 272, Loss: 0.3686670363574103\n",
      "Epoch 273, Loss: 0.36979046897515133\n",
      "Epoch 274, Loss: 0.3694199811911649\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2660640536977056\n",
      "Test R^2 score: 0.2301560073329464\n",
      "Num of epochs: 275\n",
      "Epoch 1, Loss: 0.5565366413635645\n",
      "Epoch 2, Loss: 0.5563346423354081\n",
      "Epoch 3, Loss: 0.5562183317535112\n",
      "Epoch 4, Loss: 0.556176296451793\n",
      "Epoch 5, Loss: 0.5561849502503318\n",
      "Epoch 6, Loss: 0.5562045614564409\n",
      "Epoch 7, Loss: 0.5562206892799199\n",
      "Epoch 8, Loss: 0.5562247077678115\n",
      "Epoch 9, Loss: 0.5562139113645622\n",
      "Epoch 10, Loss: 0.5561910319414958\n",
      "Epoch 11, Loss: 0.5561605424419003\n",
      "Epoch 12, Loss: 0.5561268091410292\n",
      "Epoch 13, Loss: 0.5560926450550648\n",
      "Epoch 14, Loss: 0.5560596847711597\n",
      "Epoch 15, Loss: 0.5560255433602664\n",
      "Epoch 16, Loss: 0.5559877816974356\n",
      "Epoch 17, Loss: 0.5559417352627641\n",
      "Epoch 18, Loss: 0.5558826036887519\n",
      "Epoch 19, Loss: 0.5558063345056379\n",
      "Epoch 20, Loss: 0.5557095420206256\n",
      "Epoch 21, Loss: 0.5555881924447001\n",
      "Epoch 22, Loss: 0.5554364212436015\n",
      "Epoch 23, Loss: 0.5552472795731543\n",
      "Epoch 24, Loss: 0.5550121378215728\n",
      "Epoch 25, Loss: 0.5547262903538805\n",
      "Epoch 26, Loss: 0.5543850087377289\n",
      "Epoch 27, Loss: 0.5539721590975408\n",
      "Epoch 28, Loss: 0.5534698122781223\n",
      "Epoch 29, Loss: 0.552865784461546\n",
      "Epoch 30, Loss: 0.5521614691185233\n",
      "Epoch 31, Loss: 0.5513256710041661\n",
      "Epoch 32, Loss: 0.550318340809904\n",
      "Epoch 33, Loss: 0.5491242068272174\n",
      "Epoch 34, Loss: 0.547735110059187\n",
      "Epoch 35, Loss: 0.546155128795217\n",
      "Epoch 36, Loss: 0.5443647264108987\n",
      "Epoch 37, Loss: 0.5423433832789933\n",
      "Epoch 38, Loss: 0.5400942727644653\n",
      "Epoch 39, Loss: 0.5376033384211659\n",
      "Epoch 40, Loss: 0.5347949290971721\n",
      "Epoch 41, Loss: 0.5316632010258256\n",
      "Epoch 42, Loss: 0.5281198512622023\n",
      "Epoch 43, Loss: 0.5240465862153152\n",
      "Epoch 44, Loss: 0.5194694654396342\n",
      "Epoch 45, Loss: 0.5144816930162657\n",
      "Epoch 46, Loss: 0.5092634160742348\n",
      "Epoch 47, Loss: 0.5042747214937757\n",
      "Epoch 48, Loss: 0.5002807186785604\n",
      "Epoch 49, Loss: 0.49827259409082814\n",
      "Epoch 50, Loss: 0.49727896037953345\n",
      "Epoch 51, Loss: 0.49429650543184606\n",
      "Epoch 52, Loss: 0.48949770652089536\n",
      "Epoch 53, Loss: 0.4846717325495244\n",
      "Epoch 54, Loss: 0.4806011761786681\n",
      "Epoch 55, Loss: 0.4775301068486192\n",
      "Epoch 56, Loss: 0.4752843946565697\n",
      "Epoch 57, Loss: 0.4739119660749369\n",
      "Epoch 58, Loss: 0.4734898144866152\n",
      "Epoch 59, Loss: 0.47303340776143754\n",
      "Epoch 60, Loss: 0.47163450921140543\n",
      "Epoch 61, Loss: 0.4700494715088818\n",
      "Epoch 62, Loss: 0.4692188302572603\n",
      "Epoch 63, Loss: 0.4685927922161779\n",
      "Epoch 64, Loss: 0.4678401381814586\n",
      "Epoch 65, Loss: 0.46649425066178196\n",
      "Epoch 66, Loss: 0.46478739164407734\n",
      "Epoch 67, Loss: 0.46364445207547633\n",
      "Epoch 68, Loss: 0.46334330640094834\n",
      "Epoch 69, Loss: 0.4630721979504285\n",
      "Epoch 70, Loss: 0.4623604003187401\n",
      "Epoch 71, Loss: 0.4613472523547606\n",
      "Epoch 72, Loss: 0.4604659011747517\n",
      "Epoch 73, Loss: 0.45989202481252084\n",
      "Epoch 74, Loss: 0.4592787589899605\n",
      "Epoch 75, Loss: 0.45835719985666873\n",
      "Epoch 76, Loss: 0.45728110958011964\n",
      "Epoch 77, Loss: 0.4564424455101328\n",
      "Epoch 78, Loss: 0.45588872205449077\n",
      "Epoch 79, Loss: 0.45527453133980667\n",
      "Epoch 80, Loss: 0.4545241491786597\n",
      "Epoch 81, Loss: 0.4538320582517031\n",
      "Epoch 82, Loss: 0.45330619477752404\n",
      "Epoch 83, Loss: 0.452704415305127\n",
      "Epoch 84, Loss: 0.45190637424183183\n",
      "Epoch 85, Loss: 0.4512105322456142\n",
      "Epoch 86, Loss: 0.45069830675173117\n",
      "Epoch 87, Loss: 0.45004983400867943\n",
      "Epoch 88, Loss: 0.44935030462136477\n",
      "Epoch 89, Loss: 0.44880941234122024\n",
      "Epoch 90, Loss: 0.44818560340787533\n",
      "Epoch 91, Loss: 0.44743885200574374\n",
      "Epoch 92, Loss: 0.4468081604382264\n",
      "Epoch 93, Loss: 0.4462107082507615\n",
      "Epoch 94, Loss: 0.44550112025658456\n",
      "Epoch 95, Loss: 0.44490104204524406\n",
      "Epoch 96, Loss: 0.444216114697873\n",
      "Epoch 97, Loss: 0.44350908079387485\n",
      "Epoch 98, Loss: 0.44286285022604494\n",
      "Epoch 99, Loss: 0.4421128550364035\n",
      "Epoch 100, Loss: 0.4414308422968675\n",
      "Epoch 101, Loss: 0.44067097079124723\n",
      "Epoch 102, Loss: 0.4399655893264976\n",
      "Epoch 103, Loss: 0.4392083906473978\n",
      "Epoch 104, Loss: 0.4385096785989828\n",
      "Epoch 105, Loss: 0.4378076221158933\n",
      "Epoch 106, Loss: 0.43715016819857855\n",
      "Epoch 107, Loss: 0.43646436116586257\n",
      "Epoch 108, Loss: 0.43583996067819086\n",
      "Epoch 109, Loss: 0.43520322850862675\n",
      "Epoch 110, Loss: 0.43453248963081464\n",
      "Epoch 111, Loss: 0.43386074815255926\n",
      "Epoch 112, Loss: 0.43316474517512527\n",
      "Epoch 113, Loss: 0.4324752023511744\n",
      "Epoch 114, Loss: 0.43177960605091653\n",
      "Epoch 115, Loss: 0.4310890920345221\n",
      "Epoch 116, Loss: 0.4304270016179391\n",
      "Epoch 117, Loss: 0.4298031044549243\n",
      "Epoch 118, Loss: 0.42926637647068205\n",
      "Epoch 119, Loss: 0.428916794833163\n",
      "Epoch 120, Loss: 0.42888665562743067\n",
      "Epoch 121, Loss: 0.42761822869817095\n",
      "Epoch 122, Loss: 0.4270234143473085\n",
      "Epoch 123, Loss: 0.4269913617015221\n",
      "Epoch 124, Loss: 0.42585571757768326\n",
      "Epoch 125, Loss: 0.4255650872790418\n",
      "Epoch 126, Loss: 0.42534506617754364\n",
      "Epoch 127, Loss: 0.42419106900720405\n",
      "Epoch 128, Loss: 0.42426569276738274\n",
      "Epoch 129, Loss: 0.42368083802987216\n",
      "Epoch 130, Loss: 0.4226788879649823\n",
      "Epoch 131, Loss: 0.4228531482834187\n",
      "Epoch 132, Loss: 0.4219350772042797\n",
      "Epoch 133, Loss: 0.4211614189909175\n",
      "Epoch 134, Loss: 0.4211952242909274\n",
      "Epoch 135, Loss: 0.42018862391396306\n",
      "Epoch 136, Loss: 0.41962496884606965\n",
      "Epoch 137, Loss: 0.41950071639294206\n",
      "Epoch 138, Loss: 0.41858762752986567\n",
      "Epoch 139, Loss: 0.4180710569291005\n",
      "Epoch 140, Loss: 0.41786192482528123\n",
      "Epoch 141, Loss: 0.41706608066196527\n",
      "Epoch 142, Loss: 0.4164370341131612\n",
      "Epoch 143, Loss: 0.416251388868243\n",
      "Epoch 144, Loss: 0.41571607237269464\n",
      "Epoch 145, Loss: 0.4148635313558518\n",
      "Epoch 146, Loss: 0.4144474974743671\n",
      "Epoch 147, Loss: 0.4142444678589272\n",
      "Epoch 148, Loss: 0.4137208896953046\n",
      "Epoch 149, Loss: 0.4130303636327669\n",
      "Epoch 150, Loss: 0.4122258243284879\n",
      "Epoch 151, Loss: 0.4116640622845532\n",
      "Epoch 152, Loss: 0.41133511384277743\n",
      "Epoch 153, Loss: 0.411180380201067\n",
      "Epoch 154, Loss: 0.4114815146117037\n",
      "Epoch 155, Loss: 0.4109882816514364\n",
      "Epoch 156, Loss: 0.4101683115321017\n",
      "Epoch 157, Loss: 0.408615615726467\n",
      "Epoch 158, Loss: 0.4083833251083532\n",
      "Epoch 159, Loss: 0.40894092157731965\n",
      "Epoch 160, Loss: 0.4079826343559583\n",
      "Epoch 161, Loss: 0.4067668927629053\n",
      "Epoch 162, Loss: 0.40622157217477944\n",
      "Epoch 163, Loss: 0.4063481432401402\n",
      "Epoch 164, Loss: 0.4064291962302259\n",
      "Epoch 165, Loss: 0.40529992809812676\n",
      "Epoch 166, Loss: 0.4042471703092377\n",
      "Epoch 167, Loss: 0.4038225607434239\n",
      "Epoch 168, Loss: 0.40392856130459026\n",
      "Epoch 169, Loss: 0.40406695107518353\n",
      "Epoch 170, Loss: 0.403270561345609\n",
      "Epoch 171, Loss: 0.4022589844233168\n",
      "Epoch 172, Loss: 0.40142558246177584\n",
      "Epoch 173, Loss: 0.4011558848967246\n",
      "Epoch 174, Loss: 0.4012236141133123\n",
      "Epoch 175, Loss: 0.40115352614653976\n",
      "Epoch 176, Loss: 0.4009146447925943\n",
      "Epoch 177, Loss: 0.3998602913717848\n",
      "Epoch 178, Loss: 0.39894270189836095\n",
      "Epoch 179, Loss: 0.3984354617496789\n",
      "Epoch 180, Loss: 0.39836467750612775\n",
      "Epoch 181, Loss: 0.39859450743575975\n",
      "Epoch 182, Loss: 0.3986940866689607\n",
      "Epoch 183, Loss: 0.39877486438420084\n",
      "Epoch 184, Loss: 0.39749554007805266\n",
      "Epoch 185, Loss: 0.39626426412377974\n",
      "Epoch 186, Loss: 0.3955796541498671\n",
      "Epoch 187, Loss: 0.39563557009565387\n",
      "Epoch 188, Loss: 0.3960428081009717\n",
      "Epoch 189, Loss: 0.3959439169191367\n",
      "Epoch 190, Loss: 0.3955117873003876\n",
      "Epoch 191, Loss: 0.39422005948375766\n",
      "Epoch 192, Loss: 0.3933543412342004\n",
      "Epoch 193, Loss: 0.39317468135192846\n",
      "Epoch 194, Loss: 0.39336549740887916\n",
      "Epoch 195, Loss: 0.3936997139321921\n",
      "Epoch 196, Loss: 0.3933213254373971\n",
      "Epoch 197, Loss: 0.3927754717470184\n",
      "Epoch 198, Loss: 0.39162456416359376\n",
      "Epoch 199, Loss: 0.3908456369990255\n",
      "Epoch 200, Loss: 0.3904578423474415\n",
      "Epoch 201, Loss: 0.3903759734782584\n",
      "Epoch 202, Loss: 0.39067939379589095\n",
      "Epoch 203, Loss: 0.39109655527837806\n",
      "Epoch 204, Loss: 0.39204923388578145\n",
      "Epoch 205, Loss: 0.3907619808346961\n",
      "Epoch 206, Loss: 0.38942050242410753\n",
      "Epoch 207, Loss: 0.38804476192690857\n",
      "Epoch 208, Loss: 0.38788419489606607\n",
      "Epoch 209, Loss: 0.38859200735280447\n",
      "Epoch 210, Loss: 0.38861965422881484\n",
      "Epoch 211, Loss: 0.3883107678804396\n",
      "Epoch 212, Loss: 0.3868059194944729\n",
      "Epoch 213, Loss: 0.38594438106564777\n",
      "Epoch 214, Loss: 0.38573386267841536\n",
      "Epoch 215, Loss: 0.38598625091416844\n",
      "Epoch 216, Loss: 0.3866428531960987\n",
      "Epoch 217, Loss: 0.38631142251346295\n",
      "Epoch 218, Loss: 0.38602711258799266\n",
      "Epoch 219, Loss: 0.38461012045760734\n",
      "Epoch 220, Loss: 0.38368870245606385\n",
      "Epoch 221, Loss: 0.3834672699915966\n",
      "Epoch 222, Loss: 0.3837848692220826\n",
      "Epoch 223, Loss: 0.384619612510075\n",
      "Epoch 224, Loss: 0.38477910207004684\n",
      "Epoch 225, Loss: 0.3848470417769386\n",
      "Epoch 226, Loss: 0.3828871907140692\n",
      "Epoch 227, Loss: 0.3815549123636021\n",
      "Epoch 228, Loss: 0.3814044670741546\n",
      "Epoch 229, Loss: 0.3820967698031325\n",
      "Epoch 230, Loss: 0.38323456988094656\n",
      "Epoch 231, Loss: 0.38219148516819124\n",
      "Epoch 232, Loss: 0.38081619800454364\n",
      "Epoch 233, Loss: 0.3795707224786454\n",
      "Epoch 234, Loss: 0.37957464825143367\n",
      "Epoch 235, Loss: 0.38036466894245013\n",
      "Epoch 236, Loss: 0.38055397896351134\n",
      "Epoch 237, Loss: 0.380338811912384\n",
      "Epoch 238, Loss: 0.3789293931008621\n",
      "Epoch 239, Loss: 0.37776649756669445\n",
      "Epoch 240, Loss: 0.3777542298393822\n",
      "Epoch 241, Loss: 0.37843996045598766\n",
      "Epoch 242, Loss: 0.3792668425969848\n",
      "Epoch 243, Loss: 0.37901284989437434\n",
      "Epoch 244, Loss: 0.3782476423319918\n",
      "Epoch 245, Loss: 0.37656863274863145\n",
      "Epoch 246, Loss: 0.37575419401923355\n",
      "Epoch 247, Loss: 0.3762174552960476\n",
      "Epoch 248, Loss: 0.37703575454088845\n",
      "Epoch 249, Loss: 0.3777225133538443\n",
      "Epoch 250, Loss: 0.3765926119529439\n",
      "Epoch 251, Loss: 0.3752874226573512\n",
      "Epoch 252, Loss: 0.37415257707050115\n",
      "Epoch 253, Loss: 0.37402248133445015\n",
      "Epoch 254, Loss: 0.37464969883383176\n",
      "Epoch 255, Loss: 0.37527163919173034\n",
      "Epoch 256, Loss: 0.3759596189173721\n",
      "Epoch 257, Loss: 0.3747113030503075\n",
      "Epoch 258, Loss: 0.37312617632426487\n",
      "Epoch 259, Loss: 0.37215586802525225\n",
      "Epoch 260, Loss: 0.37238118558588496\n",
      "Epoch 261, Loss: 0.3734325592161079\n",
      "Epoch 262, Loss: 0.3743026726898136\n",
      "Epoch 263, Loss: 0.3751979345242944\n",
      "Epoch 264, Loss: 0.3728065915211093\n",
      "Epoch 265, Loss: 0.3709280949326627\n",
      "Epoch 266, Loss: 0.3707922664505597\n",
      "Epoch 267, Loss: 0.3719368242114387\n",
      "Epoch 268, Loss: 0.37335659571249974\n",
      "Epoch 269, Loss: 0.37229215961687656\n",
      "Epoch 270, Loss: 0.37064551336891344\n",
      "Epoch 271, Loss: 0.3693440194862029\n",
      "Epoch 272, Loss: 0.36964301582527836\n",
      "Epoch 273, Loss: 0.3713924009303208\n",
      "Epoch 274, Loss: 0.3718694510166111\n",
      "Epoch 275, Loss: 0.3712056443018573\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.24354145091593463\n",
      "Test R^2 score: 0.3569455061837701\n",
      "Num of epochs: 276\n",
      "Epoch 1, Loss: 0.5641614695027423\n",
      "Epoch 2, Loss: 0.5627794366388245\n",
      "Epoch 3, Loss: 0.5615479041035216\n",
      "Epoch 4, Loss: 0.5605094445255528\n",
      "Epoch 5, Loss: 0.5596299064818206\n",
      "Epoch 6, Loss: 0.5588683940383559\n",
      "Epoch 7, Loss: 0.5582343058756782\n",
      "Epoch 8, Loss: 0.557735984961295\n",
      "Epoch 9, Loss: 0.5573322216025509\n",
      "Epoch 10, Loss: 0.5570262175729926\n",
      "Epoch 11, Loss: 0.5567893381734035\n",
      "Epoch 12, Loss: 0.5566165851956681\n",
      "Epoch 13, Loss: 0.5564942820067601\n",
      "Epoch 14, Loss: 0.5564091251237947\n",
      "Epoch 15, Loss: 0.5563489450898792\n",
      "Epoch 16, Loss: 0.5563018838923578\n",
      "Epoch 17, Loss: 0.5562490056061161\n",
      "Epoch 18, Loss: 0.5561760553223514\n",
      "Epoch 19, Loss: 0.5560995048360227\n",
      "Epoch 20, Loss: 0.555995393197096\n",
      "Epoch 21, Loss: 0.5558585847164067\n",
      "Epoch 22, Loss: 0.5556870976988173\n",
      "Epoch 23, Loss: 0.5554788880958836\n",
      "Epoch 24, Loss: 0.5552326532253731\n",
      "Epoch 25, Loss: 0.554943831410998\n",
      "Epoch 26, Loss: 0.5546045375623218\n",
      "Epoch 27, Loss: 0.5541901575095552\n",
      "Epoch 28, Loss: 0.5536847789579988\n",
      "Epoch 29, Loss: 0.5530866167791875\n",
      "Epoch 30, Loss: 0.5523623774947247\n",
      "Epoch 31, Loss: 0.5514801136764949\n",
      "Epoch 32, Loss: 0.5504108834041046\n",
      "Epoch 33, Loss: 0.5491270832601445\n",
      "Epoch 34, Loss: 0.5475831215611855\n",
      "Epoch 35, Loss: 0.5457440261968212\n",
      "Epoch 36, Loss: 0.5435757160402586\n",
      "Epoch 37, Loss: 0.5410168644309048\n",
      "Epoch 38, Loss: 0.5380168115761572\n",
      "Epoch 39, Loss: 0.5345441004132027\n",
      "Epoch 40, Loss: 0.5306104288246031\n",
      "Epoch 41, Loss: 0.5263478234857127\n",
      "Epoch 42, Loss: 0.5220875198833704\n",
      "Epoch 43, Loss: 0.5184733583858148\n",
      "Epoch 44, Loss: 0.5163075524455465\n",
      "Epoch 45, Loss: 0.5154094534512875\n",
      "Epoch 46, Loss: 0.5135508347544712\n",
      "Epoch 47, Loss: 0.5101603883163591\n",
      "Epoch 48, Loss: 0.5064439672767789\n",
      "Epoch 49, Loss: 0.5034919928545712\n",
      "Epoch 50, Loss: 0.5015021053091264\n",
      "Epoch 51, Loss: 0.49988697681926647\n",
      "Epoch 52, Loss: 0.4979440470739462\n",
      "Epoch 53, Loss: 0.4953391125145284\n",
      "Epoch 54, Loss: 0.49216928902495916\n",
      "Epoch 55, Loss: 0.48890310743034515\n",
      "Epoch 56, Loss: 0.4860638279474264\n",
      "Epoch 57, Loss: 0.48365095844739747\n",
      "Epoch 58, Loss: 0.4812393986165938\n",
      "Epoch 59, Loss: 0.47832908887120873\n",
      "Epoch 60, Loss: 0.47508638060814246\n",
      "Epoch 61, Loss: 0.47208046324189384\n",
      "Epoch 62, Loss: 0.46995664104875456\n",
      "Epoch 63, Loss: 0.4686082466684026\n",
      "Epoch 64, Loss: 0.4674648150804952\n",
      "Epoch 65, Loss: 0.4665167538648741\n",
      "Epoch 66, Loss: 0.4662697661047749\n",
      "Epoch 67, Loss: 0.46620459869895425\n",
      "Epoch 68, Loss: 0.4650912066964705\n",
      "Epoch 69, Loss: 0.4636483569716804\n",
      "Epoch 70, Loss: 0.46243935329160235\n",
      "Epoch 71, Loss: 0.4611397638891621\n",
      "Epoch 72, Loss: 0.46001396764405705\n",
      "Epoch 73, Loss: 0.4593694816309801\n",
      "Epoch 74, Loss: 0.45883958846051404\n",
      "Epoch 75, Loss: 0.45822001992742795\n",
      "Epoch 76, Loss: 0.4576344218572326\n",
      "Epoch 77, Loss: 0.4570403790988615\n",
      "Epoch 78, Loss: 0.45632121366450307\n",
      "Epoch 79, Loss: 0.4555288873823057\n",
      "Epoch 80, Loss: 0.45478347932007945\n",
      "Epoch 81, Loss: 0.4539914561677683\n",
      "Epoch 82, Loss: 0.4531501894559341\n",
      "Epoch 83, Loss: 0.4524088659509282\n",
      "Epoch 84, Loss: 0.45164745416049357\n",
      "Epoch 85, Loss: 0.4508567799672133\n",
      "Epoch 86, Loss: 0.45019941679765507\n",
      "Epoch 87, Loss: 0.44950509274687894\n",
      "Epoch 88, Loss: 0.448782651106554\n",
      "Epoch 89, Loss: 0.4480829059776627\n",
      "Epoch 90, Loss: 0.4473124483744629\n",
      "Epoch 91, Loss: 0.4465814713491888\n",
      "Epoch 92, Loss: 0.44583189940296253\n",
      "Epoch 93, Loss: 0.445157258262577\n",
      "Epoch 94, Loss: 0.44444540163605983\n",
      "Epoch 95, Loss: 0.44375434792766005\n",
      "Epoch 96, Loss: 0.44303546113884335\n",
      "Epoch 97, Loss: 0.4422852532809289\n",
      "Epoch 98, Loss: 0.441551336564443\n",
      "Epoch 99, Loss: 0.4407799759352485\n",
      "Epoch 100, Loss: 0.4400497455544609\n",
      "Epoch 101, Loss: 0.4392882991674846\n",
      "Epoch 102, Loss: 0.43850295023540087\n",
      "Epoch 103, Loss: 0.43770694946997496\n",
      "Epoch 104, Loss: 0.43691081155412476\n",
      "Epoch 105, Loss: 0.4361036189242938\n",
      "Epoch 106, Loss: 0.4352243366771716\n",
      "Epoch 107, Loss: 0.4343243706651363\n",
      "Epoch 108, Loss: 0.433442046286703\n",
      "Epoch 109, Loss: 0.4326067335531955\n",
      "Epoch 110, Loss: 0.43180438426324375\n",
      "Epoch 111, Loss: 0.43102672989219737\n",
      "Epoch 112, Loss: 0.4302480162852438\n",
      "Epoch 113, Loss: 0.42966690014097164\n",
      "Epoch 114, Loss: 0.4299774058915388\n",
      "Epoch 115, Loss: 0.4292596767925547\n",
      "Epoch 116, Loss: 0.4272671067656301\n",
      "Epoch 117, Loss: 0.42677272185724885\n",
      "Epoch 118, Loss: 0.42644274361495255\n",
      "Epoch 119, Loss: 0.42490773321410347\n",
      "Epoch 120, Loss: 0.42460146899263446\n",
      "Epoch 121, Loss: 0.42385762195517834\n",
      "Epoch 122, Loss: 0.4227511174318602\n",
      "Epoch 123, Loss: 0.4224047337294791\n",
      "Epoch 124, Loss: 0.42162630026803716\n",
      "Epoch 125, Loss: 0.42064262458074064\n",
      "Epoch 126, Loss: 0.42012593833503026\n",
      "Epoch 127, Loss: 0.4196684849082083\n",
      "Epoch 128, Loss: 0.41888388158887074\n",
      "Epoch 129, Loss: 0.41807973582477853\n",
      "Epoch 130, Loss: 0.41755536394740556\n",
      "Epoch 131, Loss: 0.4172570952754442\n",
      "Epoch 132, Loss: 0.41663427425675237\n",
      "Epoch 133, Loss: 0.41589104663125104\n",
      "Epoch 134, Loss: 0.41508731337173865\n",
      "Epoch 135, Loss: 0.41461801152266836\n",
      "Epoch 136, Loss: 0.4143859751356942\n",
      "Epoch 137, Loss: 0.4142096635821232\n",
      "Epoch 138, Loss: 0.413777649263898\n",
      "Epoch 139, Loss: 0.41263620772072584\n",
      "Epoch 140, Loss: 0.4117230416930187\n",
      "Epoch 141, Loss: 0.4113719905927497\n",
      "Epoch 142, Loss: 0.4111700698027213\n",
      "Epoch 143, Loss: 0.4108331453517667\n",
      "Epoch 144, Loss: 0.4099814996383374\n",
      "Epoch 145, Loss: 0.4091858783699696\n",
      "Epoch 146, Loss: 0.40865040417339316\n",
      "Epoch 147, Loss: 0.40840041945937505\n",
      "Epoch 148, Loss: 0.4082828060665033\n",
      "Epoch 149, Loss: 0.4080638921827563\n",
      "Epoch 150, Loss: 0.4077332269784349\n",
      "Epoch 151, Loss: 0.406742439386149\n",
      "Epoch 152, Loss: 0.40578891190209004\n",
      "Epoch 153, Loss: 0.4052552552338411\n",
      "Epoch 154, Loss: 0.4051539968949476\n",
      "Epoch 155, Loss: 0.4051648281673699\n",
      "Epoch 156, Loss: 0.40458563844565615\n",
      "Epoch 157, Loss: 0.40389159524625373\n",
      "Epoch 158, Loss: 0.4030544152675658\n",
      "Epoch 159, Loss: 0.4024805558584462\n",
      "Epoch 160, Loss: 0.40215272905784233\n",
      "Epoch 161, Loss: 0.40203591950036544\n",
      "Epoch 162, Loss: 0.40242001819867257\n",
      "Epoch 163, Loss: 0.40265075303848924\n",
      "Epoch 164, Loss: 0.4032003487541473\n",
      "Epoch 165, Loss: 0.40079626609229835\n",
      "Epoch 166, Loss: 0.39955077128483285\n",
      "Epoch 167, Loss: 0.40014555339227803\n",
      "Epoch 168, Loss: 0.4004110935840862\n",
      "Epoch 169, Loss: 0.3997133807645643\n",
      "Epoch 170, Loss: 0.39807375965913405\n",
      "Epoch 171, Loss: 0.3986198905409227\n",
      "Epoch 172, Loss: 0.39988747593555674\n",
      "Epoch 173, Loss: 0.3980725617960143\n",
      "Epoch 174, Loss: 0.3968936142348392\n",
      "Epoch 175, Loss: 0.39800950044286576\n",
      "Epoch 176, Loss: 0.39804529071825756\n",
      "Epoch 177, Loss: 0.3966810180401334\n",
      "Epoch 178, Loss: 0.39576226985222634\n",
      "Epoch 179, Loss: 0.3968736212999321\n",
      "Epoch 180, Loss: 0.39780429939513745\n",
      "Epoch 181, Loss: 0.39519346955614254\n",
      "Epoch 182, Loss: 0.39596753187927736\n",
      "Epoch 183, Loss: 0.39803426570967354\n",
      "Epoch 184, Loss: 0.3949360234624901\n",
      "Epoch 185, Loss: 0.3952177326161849\n",
      "Epoch 186, Loss: 0.39663698989317453\n",
      "Epoch 187, Loss: 0.3934872477184619\n",
      "Epoch 188, Loss: 0.3949991982488101\n",
      "Epoch 189, Loss: 0.395589994204636\n",
      "Epoch 190, Loss: 0.3927961285076941\n",
      "Epoch 191, Loss: 0.3965153047871743\n",
      "Epoch 192, Loss: 0.394658889518826\n",
      "Epoch 193, Loss: 0.393242326309939\n",
      "Epoch 194, Loss: 0.39475476193953185\n",
      "Epoch 195, Loss: 0.3920136944278805\n",
      "Epoch 196, Loss: 0.39309603182585806\n",
      "Epoch 197, Loss: 0.3923529743187333\n",
      "Epoch 198, Loss: 0.39154664984039383\n",
      "Epoch 199, Loss: 0.39212305823767396\n",
      "Epoch 200, Loss: 0.39084967827458567\n",
      "Epoch 201, Loss: 0.39125311895961523\n",
      "Epoch 202, Loss: 0.3911605406365314\n",
      "Epoch 203, Loss: 0.3901949613445282\n",
      "Epoch 204, Loss: 0.391182234992418\n",
      "Epoch 205, Loss: 0.39003468732142155\n",
      "Epoch 206, Loss: 0.3896870223518877\n",
      "Epoch 207, Loss: 0.3901585273233176\n",
      "Epoch 208, Loss: 0.3891433846223248\n",
      "Epoch 209, Loss: 0.38912031288032245\n",
      "Epoch 210, Loss: 0.3892745324968712\n",
      "Epoch 211, Loss: 0.3886459380270433\n",
      "Epoch 212, Loss: 0.38833070282734156\n",
      "Epoch 213, Loss: 0.38872493209234754\n",
      "Epoch 214, Loss: 0.38806947194203206\n",
      "Epoch 215, Loss: 0.3877058051776946\n",
      "Epoch 216, Loss: 0.3878343270466271\n",
      "Epoch 217, Loss: 0.38771695093454056\n",
      "Epoch 218, Loss: 0.3870391096750071\n",
      "Epoch 219, Loss: 0.3870243829911868\n",
      "Epoch 220, Loss: 0.3870042652429832\n",
      "Epoch 221, Loss: 0.3866796184739736\n",
      "Epoch 222, Loss: 0.3862496623250726\n",
      "Epoch 223, Loss: 0.3861581225824051\n",
      "Epoch 224, Loss: 0.3860595749442705\n",
      "Epoch 225, Loss: 0.385931118437482\n",
      "Epoch 226, Loss: 0.3856164461729743\n",
      "Epoch 227, Loss: 0.38533487182294107\n",
      "Epoch 228, Loss: 0.38516433506153586\n",
      "Epoch 229, Loss: 0.38506665532155254\n",
      "Epoch 230, Loss: 0.38512688344923907\n",
      "Epoch 231, Loss: 0.38509171121211294\n",
      "Epoch 232, Loss: 0.3852437916093904\n",
      "Epoch 233, Loss: 0.3851230529654222\n",
      "Epoch 234, Loss: 0.3851889590598293\n",
      "Epoch 235, Loss: 0.3845306104757795\n",
      "Epoch 236, Loss: 0.38411518247740833\n",
      "Epoch 237, Loss: 0.38370575134071955\n",
      "Epoch 238, Loss: 0.38343787201829943\n",
      "Epoch 239, Loss: 0.38332041307457937\n",
      "Epoch 240, Loss: 0.38328336445302535\n",
      "Epoch 241, Loss: 0.38349223609734545\n",
      "Epoch 242, Loss: 0.3837724638399792\n",
      "Epoch 243, Loss: 0.3847870022019957\n",
      "Epoch 244, Loss: 0.38467510727134474\n",
      "Epoch 245, Loss: 0.38484860992150854\n",
      "Epoch 246, Loss: 0.3829690846535486\n",
      "Epoch 247, Loss: 0.38208820955929\n",
      "Epoch 248, Loss: 0.3822658879201029\n",
      "Epoch 249, Loss: 0.3826994047679115\n",
      "Epoch 250, Loss: 0.3831338506799549\n",
      "Epoch 251, Loss: 0.3821720682866798\n",
      "Epoch 252, Loss: 0.3814105032152743\n",
      "Epoch 253, Loss: 0.3812720190787501\n",
      "Epoch 254, Loss: 0.3816334414318506\n",
      "Epoch 255, Loss: 0.3820683779159037\n",
      "Epoch 256, Loss: 0.38170069179846994\n",
      "Epoch 257, Loss: 0.38124256908491694\n",
      "Epoch 258, Loss: 0.38057737425205307\n",
      "Epoch 259, Loss: 0.3802836835565317\n",
      "Epoch 260, Loss: 0.38032940892015016\n",
      "Epoch 261, Loss: 0.3805949931852254\n",
      "Epoch 262, Loss: 0.38119982639415867\n",
      "Epoch 263, Loss: 0.38155536148179536\n",
      "Epoch 264, Loss: 0.3823907631053277\n",
      "Epoch 265, Loss: 0.38152372664667855\n",
      "Epoch 266, Loss: 0.3805853028729181\n",
      "Epoch 267, Loss: 0.3793842603945278\n",
      "Epoch 268, Loss: 0.3791387965191451\n",
      "Epoch 269, Loss: 0.37957178244129963\n",
      "Epoch 270, Loss: 0.3798422902125087\n",
      "Epoch 271, Loss: 0.37983107030584107\n",
      "Epoch 272, Loss: 0.37913093590672364\n",
      "Epoch 273, Loss: 0.3786033520836809\n",
      "Epoch 274, Loss: 0.37816931646129576\n",
      "Epoch 275, Loss: 0.37811925111293937\n",
      "Epoch 276, Loss: 0.37841680711137227\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.23840222844643175\n",
      "Test R^2 score: 0.38408056716898237\n",
      "Num of epochs: 277\n",
      "Epoch 1, Loss: 0.5797025447240137\n",
      "Epoch 2, Loss: 0.5779151019969277\n",
      "Epoch 3, Loss: 0.576186616353397\n",
      "Epoch 4, Loss: 0.5745275017701924\n",
      "Epoch 5, Loss: 0.572930012171817\n",
      "Epoch 6, Loss: 0.5713962030609737\n",
      "Epoch 7, Loss: 0.5699281050280764\n",
      "Epoch 8, Loss: 0.5685252573513863\n",
      "Epoch 9, Loss: 0.5671906925668532\n",
      "Epoch 10, Loss: 0.5659394807322747\n",
      "Epoch 11, Loss: 0.5647763973194989\n",
      "Epoch 12, Loss: 0.5636756320545295\n",
      "Epoch 13, Loss: 0.5626377625779649\n",
      "Epoch 14, Loss: 0.5616394719191465\n",
      "Epoch 15, Loss: 0.5607095409258508\n",
      "Epoch 16, Loss: 0.5598441580649275\n",
      "Epoch 17, Loss: 0.5590502334281039\n",
      "Epoch 18, Loss: 0.5583178765971014\n",
      "Epoch 19, Loss: 0.557646555219087\n",
      "Epoch 20, Loss: 0.5570350454235917\n",
      "Epoch 21, Loss: 0.5564803043180712\n",
      "Epoch 22, Loss: 0.555986414832587\n",
      "Epoch 23, Loss: 0.5555560605391221\n",
      "Epoch 24, Loss: 0.5551686416475562\n",
      "Epoch 25, Loss: 0.5548074888016166\n",
      "Epoch 26, Loss: 0.5545054929614275\n",
      "Epoch 27, Loss: 0.5542673211959356\n",
      "Epoch 28, Loss: 0.5539623409650872\n",
      "Epoch 29, Loss: 0.5534929387969741\n",
      "Epoch 30, Loss: 0.5528367557670791\n",
      "Epoch 31, Loss: 0.5519714212051148\n",
      "Epoch 32, Loss: 0.5508828306202039\n",
      "Epoch 33, Loss: 0.5495394241293422\n",
      "Epoch 34, Loss: 0.5479028307203679\n",
      "Epoch 35, Loss: 0.5459197830094167\n",
      "Epoch 36, Loss: 0.5435333061330704\n",
      "Epoch 37, Loss: 0.5407049616074343\n",
      "Epoch 38, Loss: 0.5374500927932039\n",
      "Epoch 39, Loss: 0.5338190733997629\n",
      "Epoch 40, Loss: 0.5299753717782245\n",
      "Epoch 41, Loss: 0.5262158800965819\n",
      "Epoch 42, Loss: 0.5230362336242178\n",
      "Epoch 43, Loss: 0.5209760438587988\n",
      "Epoch 44, Loss: 0.5198181622109541\n",
      "Epoch 45, Loss: 0.5180084167297443\n",
      "Epoch 46, Loss: 0.5147780485010225\n",
      "Epoch 47, Loss: 0.5110158096170843\n",
      "Epoch 48, Loss: 0.507842840608784\n",
      "Epoch 49, Loss: 0.505769817422246\n",
      "Epoch 50, Loss: 0.5043868796404292\n",
      "Epoch 51, Loss: 0.5029657443556107\n",
      "Epoch 52, Loss: 0.5011791392251091\n",
      "Epoch 53, Loss: 0.49906335958408005\n",
      "Epoch 54, Loss: 0.4968994686411755\n",
      "Epoch 55, Loss: 0.4950330613876578\n",
      "Epoch 56, Loss: 0.49357633071501306\n",
      "Epoch 57, Loss: 0.49218370042575604\n",
      "Epoch 58, Loss: 0.4904675632011587\n",
      "Epoch 59, Loss: 0.4885107645402749\n",
      "Epoch 60, Loss: 0.4867803776455196\n",
      "Epoch 61, Loss: 0.4855458966196995\n",
      "Epoch 62, Loss: 0.48449702417859286\n",
      "Epoch 63, Loss: 0.4832968865278322\n",
      "Epoch 64, Loss: 0.4818632312183581\n",
      "Epoch 65, Loss: 0.480403585589477\n",
      "Epoch 66, Loss: 0.4791233174438551\n",
      "Epoch 67, Loss: 0.47795863529612914\n",
      "Epoch 68, Loss: 0.4767053890200141\n",
      "Epoch 69, Loss: 0.4753591791941308\n",
      "Epoch 70, Loss: 0.47411444646573603\n",
      "Epoch 71, Loss: 0.4730688926304161\n",
      "Epoch 72, Loss: 0.4720371858134564\n",
      "Epoch 73, Loss: 0.4709136144026896\n",
      "Epoch 74, Loss: 0.46978340677357383\n",
      "Epoch 75, Loss: 0.46875009536742196\n",
      "Epoch 76, Loss: 0.4677045289573769\n",
      "Epoch 77, Loss: 0.46656086274336916\n",
      "Epoch 78, Loss: 0.46542890567049544\n",
      "Epoch 79, Loss: 0.4644351092695281\n",
      "Epoch 80, Loss: 0.46348639669486347\n",
      "Epoch 81, Loss: 0.46248048406098535\n",
      "Epoch 82, Loss: 0.46153212840598296\n",
      "Epoch 83, Loss: 0.4606455993963445\n",
      "Epoch 84, Loss: 0.4596822262739593\n",
      "Epoch 85, Loss: 0.4587233105309408\n",
      "Epoch 86, Loss: 0.4578687053979861\n",
      "Epoch 87, Loss: 0.4569840855185536\n",
      "Epoch 88, Loss: 0.4559923247801938\n",
      "Epoch 89, Loss: 0.45498395936064584\n",
      "Epoch 90, Loss: 0.4539768663060149\n",
      "Epoch 91, Loss: 0.45292415771793487\n",
      "Epoch 92, Loss: 0.45190179083246246\n",
      "Epoch 93, Loss: 0.45095835005049273\n",
      "Epoch 94, Loss: 0.4501451311257658\n",
      "Epoch 95, Loss: 0.44941256115466577\n",
      "Epoch 96, Loss: 0.4487309336530168\n",
      "Epoch 97, Loss: 0.4480774021807301\n",
      "Epoch 98, Loss: 0.4474143734585009\n",
      "Epoch 99, Loss: 0.4466992085823664\n",
      "Epoch 100, Loss: 0.4459701333405747\n",
      "Epoch 101, Loss: 0.4452015587995338\n",
      "Epoch 102, Loss: 0.4444309007382428\n",
      "Epoch 103, Loss: 0.443670776844093\n",
      "Epoch 104, Loss: 0.44290892787439523\n",
      "Epoch 105, Loss: 0.44219163212008117\n",
      "Epoch 106, Loss: 0.4414945699729385\n",
      "Epoch 107, Loss: 0.4408251727051333\n",
      "Epoch 108, Loss: 0.4401572287660008\n",
      "Epoch 109, Loss: 0.4394838110488559\n",
      "Epoch 110, Loss: 0.4388238427929661\n",
      "Epoch 111, Loss: 0.4381804283985048\n",
      "Epoch 112, Loss: 0.43754454794647263\n",
      "Epoch 113, Loss: 0.43690543986898106\n",
      "Epoch 114, Loss: 0.4362791602545953\n",
      "Epoch 115, Loss: 0.4356739389139253\n",
      "Epoch 116, Loss: 0.43507027316016633\n",
      "Epoch 117, Loss: 0.43447310828581753\n",
      "Epoch 118, Loss: 0.43388449741080815\n",
      "Epoch 119, Loss: 0.4332983712006167\n",
      "Epoch 120, Loss: 0.4327196641368113\n",
      "Epoch 121, Loss: 0.4320898350870523\n",
      "Epoch 122, Loss: 0.4314348930181757\n",
      "Epoch 123, Loss: 0.43075403151726055\n",
      "Epoch 124, Loss: 0.4300570719292806\n",
      "Epoch 125, Loss: 0.42939463952249457\n",
      "Epoch 126, Loss: 0.4287811604122938\n",
      "Epoch 127, Loss: 0.42819399938966846\n",
      "Epoch 128, Loss: 0.427562870845737\n",
      "Epoch 129, Loss: 0.42688251829438273\n",
      "Epoch 130, Loss: 0.4262379113493954\n",
      "Epoch 131, Loss: 0.4256580769574098\n",
      "Epoch 132, Loss: 0.4250891598974771\n",
      "Epoch 133, Loss: 0.4244846585470397\n",
      "Epoch 134, Loss: 0.42387105135483244\n",
      "Epoch 135, Loss: 0.4232883620060708\n",
      "Epoch 136, Loss: 0.42272360541760956\n",
      "Epoch 137, Loss: 0.42219310705949703\n",
      "Epoch 138, Loss: 0.42166033334210173\n",
      "Epoch 139, Loss: 0.421184416088719\n",
      "Epoch 140, Loss: 0.4206637726268324\n",
      "Epoch 141, Loss: 0.42001361288421235\n",
      "Epoch 142, Loss: 0.41936539438563225\n",
      "Epoch 143, Loss: 0.4188828321696279\n",
      "Epoch 144, Loss: 0.4184713105265891\n",
      "Epoch 145, Loss: 0.41795406137485824\n",
      "Epoch 146, Loss: 0.4173736971126213\n",
      "Epoch 147, Loss: 0.4167368372799058\n",
      "Epoch 148, Loss: 0.4161830797901634\n",
      "Epoch 149, Loss: 0.41571273881491466\n",
      "Epoch 150, Loss: 0.4153296855588501\n",
      "Epoch 151, Loss: 0.41512534647108423\n",
      "Epoch 152, Loss: 0.41488161578740756\n",
      "Epoch 153, Loss: 0.4139911122231901\n",
      "Epoch 154, Loss: 0.41314732882224686\n",
      "Epoch 155, Loss: 0.4129141051113204\n",
      "Epoch 156, Loss: 0.4127693315700495\n",
      "Epoch 157, Loss: 0.41197564002584053\n",
      "Epoch 158, Loss: 0.41129600566141306\n",
      "Epoch 159, Loss: 0.41112239217351526\n",
      "Epoch 160, Loss: 0.41071040547060295\n",
      "Epoch 161, Loss: 0.4099864971740269\n",
      "Epoch 162, Loss: 0.40949055373064147\n",
      "Epoch 163, Loss: 0.40927235867216144\n",
      "Epoch 164, Loss: 0.4088589451342558\n",
      "Epoch 165, Loss: 0.40817864814637805\n",
      "Epoch 166, Loss: 0.407584200275076\n",
      "Epoch 167, Loss: 0.40717383027277887\n",
      "Epoch 168, Loss: 0.40684192889302856\n",
      "Epoch 169, Loss: 0.406376910560409\n",
      "Epoch 170, Loss: 0.40587765796591124\n",
      "Epoch 171, Loss: 0.4053561758128275\n",
      "Epoch 172, Loss: 0.4048772690978244\n",
      "Epoch 173, Loss: 0.40437290379778346\n",
      "Epoch 174, Loss: 0.4038964652198863\n",
      "Epoch 175, Loss: 0.40346145931047867\n",
      "Epoch 176, Loss: 0.40300921618191365\n",
      "Epoch 177, Loss: 0.4026155202069952\n",
      "Epoch 178, Loss: 0.4024954019307566\n",
      "Epoch 179, Loss: 0.40311003368895654\n",
      "Epoch 180, Loss: 0.4043461866298733\n",
      "Epoch 181, Loss: 0.4033452134839175\n",
      "Epoch 182, Loss: 0.4006536596702589\n",
      "Epoch 183, Loss: 0.4021184345927211\n",
      "Epoch 184, Loss: 0.4014538302496478\n",
      "Epoch 185, Loss: 0.3995561789924554\n",
      "Epoch 186, Loss: 0.4009914077708696\n",
      "Epoch 187, Loss: 0.39929731010364045\n",
      "Epoch 188, Loss: 0.39892081324123124\n",
      "Epoch 189, Loss: 0.3993632836929107\n",
      "Epoch 190, Loss: 0.3978245639395183\n",
      "Epoch 191, Loss: 0.398116075604361\n",
      "Epoch 192, Loss: 0.39770558394089034\n",
      "Epoch 193, Loss: 0.39667703617323696\n",
      "Epoch 194, Loss: 0.3971103931318639\n",
      "Epoch 195, Loss: 0.39607388523707965\n",
      "Epoch 196, Loss: 0.3957726239613385\n",
      "Epoch 197, Loss: 0.3957907524127777\n",
      "Epoch 198, Loss: 0.3949347783517245\n",
      "Epoch 199, Loss: 0.39469436068699554\n",
      "Epoch 200, Loss: 0.3946118980543053\n",
      "Epoch 201, Loss: 0.39381260147178176\n",
      "Epoch 202, Loss: 0.39351973839905263\n",
      "Epoch 203, Loss: 0.39340242985531104\n",
      "Epoch 204, Loss: 0.39272364486202155\n",
      "Epoch 205, Loss: 0.39238859697391343\n",
      "Epoch 206, Loss: 0.39225471042262783\n",
      "Epoch 207, Loss: 0.3918339712698084\n",
      "Epoch 208, Loss: 0.3911384260117094\n",
      "Epoch 209, Loss: 0.39086792068243414\n",
      "Epoch 210, Loss: 0.39063611968426065\n",
      "Epoch 211, Loss: 0.3903398808388407\n",
      "Epoch 212, Loss: 0.3898179299895479\n",
      "Epoch 213, Loss: 0.3892632782165249\n",
      "Epoch 214, Loss: 0.3888779865261795\n",
      "Epoch 215, Loss: 0.3885405812320769\n",
      "Epoch 216, Loss: 0.38826268188166746\n",
      "Epoch 217, Loss: 0.3881664536248836\n",
      "Epoch 218, Loss: 0.38826272026073694\n",
      "Epoch 219, Loss: 0.3886059268996148\n",
      "Epoch 220, Loss: 0.3889517806587009\n",
      "Epoch 221, Loss: 0.387722024069477\n",
      "Epoch 222, Loss: 0.3862639363253008\n",
      "Epoch 223, Loss: 0.38576092252020966\n",
      "Epoch 224, Loss: 0.38643063302858854\n",
      "Epoch 225, Loss: 0.38691792994053414\n",
      "Epoch 226, Loss: 0.38557820758060457\n",
      "Epoch 227, Loss: 0.38440177870719977\n",
      "Epoch 228, Loss: 0.38381391061418946\n",
      "Epoch 229, Loss: 0.3839576486811516\n",
      "Epoch 230, Loss: 0.38429279611388395\n",
      "Epoch 231, Loss: 0.3842408721561906\n",
      "Epoch 232, Loss: 0.38383180802478806\n",
      "Epoch 233, Loss: 0.3826348807434018\n",
      "Epoch 234, Loss: 0.38144646413446626\n",
      "Epoch 235, Loss: 0.38113772662099965\n",
      "Epoch 236, Loss: 0.38140014990492077\n",
      "Epoch 237, Loss: 0.382376558854965\n",
      "Epoch 238, Loss: 0.38267942957301593\n",
      "Epoch 239, Loss: 0.38179847162739106\n",
      "Epoch 240, Loss: 0.37980396070197964\n",
      "Epoch 241, Loss: 0.3787993644107312\n",
      "Epoch 242, Loss: 0.379441856074003\n",
      "Epoch 243, Loss: 0.3803492332905102\n",
      "Epoch 244, Loss: 0.3800410551555509\n",
      "Epoch 245, Loss: 0.378328906007453\n",
      "Epoch 246, Loss: 0.37690671328696507\n",
      "Epoch 247, Loss: 0.3769251561042011\n",
      "Epoch 248, Loss: 0.3782349174515478\n",
      "Epoch 249, Loss: 0.37869301921287113\n",
      "Epoch 250, Loss: 0.37732148825489137\n",
      "Epoch 251, Loss: 0.37546996628798046\n",
      "Epoch 252, Loss: 0.3746377267938216\n",
      "Epoch 253, Loss: 0.37550026585535223\n",
      "Epoch 254, Loss: 0.3768618181558212\n",
      "Epoch 255, Loss: 0.37665546108699055\n",
      "Epoch 256, Loss: 0.3746606165235095\n",
      "Epoch 257, Loss: 0.3728189620987192\n",
      "Epoch 258, Loss: 0.3724284613482841\n",
      "Epoch 259, Loss: 0.3735564979988828\n",
      "Epoch 260, Loss: 0.37449283875543754\n",
      "Epoch 261, Loss: 0.3739859460112767\n",
      "Epoch 262, Loss: 0.3719854182915601\n",
      "Epoch 263, Loss: 0.37055060140081975\n",
      "Epoch 264, Loss: 0.3701800491778542\n",
      "Epoch 265, Loss: 0.3711436187966432\n",
      "Epoch 266, Loss: 0.37262496257092054\n",
      "Epoch 267, Loss: 0.37272696234025104\n",
      "Epoch 268, Loss: 0.3713087964620464\n",
      "Epoch 269, Loss: 0.3687705753534484\n",
      "Epoch 270, Loss: 0.3677997759981702\n",
      "Epoch 271, Loss: 0.3682558871029784\n",
      "Epoch 272, Loss: 0.36950100861696916\n",
      "Epoch 273, Loss: 0.3704740871912186\n",
      "Epoch 274, Loss: 0.369124982391419\n",
      "Epoch 275, Loss: 0.36710320174666244\n",
      "Epoch 276, Loss: 0.36545876122793464\n",
      "Epoch 277, Loss: 0.36609855453327766\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2611745701531023\n",
      "Test R^2 score: 0.2569977851246969\n",
      "Num of epochs: 278\n",
      "Epoch 1, Loss: 0.5687800682419857\n",
      "Epoch 2, Loss: 0.5676922372991806\n",
      "Epoch 3, Loss: 0.5666706388932672\n",
      "Epoch 4, Loss: 0.5657040946413731\n",
      "Epoch 5, Loss: 0.5648030710939225\n",
      "Epoch 6, Loss: 0.5639678294445453\n",
      "Epoch 7, Loss: 0.5632003821365593\n",
      "Epoch 8, Loss: 0.5624891650957763\n",
      "Epoch 9, Loss: 0.5618285569207009\n",
      "Epoch 10, Loss: 0.5612202763067515\n",
      "Epoch 11, Loss: 0.5606338486669514\n",
      "Epoch 12, Loss: 0.5600791069338228\n",
      "Epoch 13, Loss: 0.5595745732276706\n",
      "Epoch 14, Loss: 0.5591139072176632\n",
      "Epoch 15, Loss: 0.558687829051362\n",
      "Epoch 16, Loss: 0.5582932684411076\n",
      "Epoch 17, Loss: 0.5579234282739347\n",
      "Epoch 18, Loss: 0.557577422372622\n",
      "Epoch 19, Loss: 0.5572825695495607\n",
      "Epoch 20, Loss: 0.5570143131286776\n",
      "Epoch 21, Loss: 0.556758319391753\n",
      "Epoch 22, Loss: 0.5565086877629711\n",
      "Epoch 23, Loss: 0.5562639802611775\n",
      "Epoch 24, Loss: 0.5560183074702081\n",
      "Epoch 25, Loss: 0.555759388233876\n",
      "Epoch 26, Loss: 0.5554743008664856\n",
      "Epoch 27, Loss: 0.5551580125956278\n",
      "Epoch 28, Loss: 0.5548106043504871\n",
      "Epoch 29, Loss: 0.5544277711370982\n",
      "Epoch 30, Loss: 0.553996636423511\n",
      "Epoch 31, Loss: 0.5535007730563036\n",
      "Epoch 32, Loss: 0.5529275293823512\n",
      "Epoch 33, Loss: 0.5522682731889788\n",
      "Epoch 34, Loss: 0.5515331519858863\n",
      "Epoch 35, Loss: 0.5506828166038197\n",
      "Epoch 36, Loss: 0.549674335428361\n",
      "Epoch 37, Loss: 0.5484519565339757\n",
      "Epoch 38, Loss: 0.5469327078753081\n",
      "Epoch 39, Loss: 0.5450564802721185\n",
      "Epoch 40, Loss: 0.5428275604003542\n",
      "Epoch 41, Loss: 0.540292166641148\n",
      "Epoch 42, Loss: 0.5374595748869677\n",
      "Epoch 43, Loss: 0.5343131503624282\n",
      "Epoch 44, Loss: 0.5308933463325096\n",
      "Epoch 45, Loss: 0.5273534985806828\n",
      "Epoch 46, Loss: 0.5240312596326281\n",
      "Epoch 47, Loss: 0.521407361005103\n",
      "Epoch 48, Loss: 0.5196425526645688\n",
      "Epoch 49, Loss: 0.5182915431171565\n",
      "Epoch 50, Loss: 0.5162493653559075\n",
      "Epoch 51, Loss: 0.5136490733376425\n",
      "Epoch 52, Loss: 0.5112485691134475\n",
      "Epoch 53, Loss: 0.5094482778720201\n",
      "Epoch 54, Loss: 0.5079815803158322\n",
      "Epoch 55, Loss: 0.5062244232215894\n",
      "Epoch 56, Loss: 0.5040340113763155\n",
      "Epoch 57, Loss: 0.5016324692642247\n",
      "Epoch 58, Loss: 0.4994847951365729\n",
      "Epoch 59, Loss: 0.49768347852826644\n",
      "Epoch 60, Loss: 0.4959889699263223\n",
      "Epoch 61, Loss: 0.4940644005649018\n",
      "Epoch 62, Loss: 0.49193714980378433\n",
      "Epoch 63, Loss: 0.4898887571012636\n",
      "Epoch 64, Loss: 0.48818637689146993\n",
      "Epoch 65, Loss: 0.4865883739846458\n",
      "Epoch 66, Loss: 0.4847788357836555\n",
      "Epoch 67, Loss: 0.4828767832457232\n",
      "Epoch 68, Loss: 0.48112099268397296\n",
      "Epoch 69, Loss: 0.47950514641864983\n",
      "Epoch 70, Loss: 0.47761856384653095\n",
      "Epoch 71, Loss: 0.475591890583731\n",
      "Epoch 72, Loss: 0.4737223432414557\n",
      "Epoch 73, Loss: 0.4718300715903825\n",
      "Epoch 74, Loss: 0.46964526513843186\n",
      "Epoch 75, Loss: 0.4673590048669618\n",
      "Epoch 76, Loss: 0.4652275616637758\n",
      "Epoch 77, Loss: 0.463039744376779\n",
      "Epoch 78, Loss: 0.4607982748514241\n",
      "Epoch 79, Loss: 0.45876760030656216\n",
      "Epoch 80, Loss: 0.4569707488093435\n",
      "Epoch 81, Loss: 0.4557620136594339\n",
      "Epoch 82, Loss: 0.4557687487896838\n",
      "Epoch 83, Loss: 0.45607215145417385\n",
      "Epoch 84, Loss: 0.45537586868207464\n",
      "Epoch 85, Loss: 0.45417894914041623\n",
      "Epoch 86, Loss: 0.45323189757019794\n",
      "Epoch 87, Loss: 0.4524582528514927\n",
      "Epoch 88, Loss: 0.4516907057869416\n",
      "Epoch 89, Loss: 0.45080458978958277\n",
      "Epoch 90, Loss: 0.4499153541056623\n",
      "Epoch 91, Loss: 0.44920456905372386\n",
      "Epoch 92, Loss: 0.4485130904285052\n",
      "Epoch 93, Loss: 0.44767542559977935\n",
      "Epoch 94, Loss: 0.44674797586944176\n",
      "Epoch 95, Loss: 0.4458319662495031\n",
      "Epoch 96, Loss: 0.4450718246048847\n",
      "Epoch 97, Loss: 0.4443558405516248\n",
      "Epoch 98, Loss: 0.4435576949023913\n",
      "Epoch 99, Loss: 0.4426965506238528\n",
      "Epoch 100, Loss: 0.4418854264643863\n",
      "Epoch 101, Loss: 0.4411360158206933\n",
      "Epoch 102, Loss: 0.440361897396271\n",
      "Epoch 103, Loss: 0.43959838161955933\n",
      "Epoch 104, Loss: 0.43885060012905\n",
      "Epoch 105, Loss: 0.4381030388469178\n",
      "Epoch 106, Loss: 0.4373121880266735\n",
      "Epoch 107, Loss: 0.4365494483520462\n",
      "Epoch 108, Loss: 0.4358452429277804\n",
      "Epoch 109, Loss: 0.4351654948925302\n",
      "Epoch 110, Loss: 0.4344224828386481\n",
      "Epoch 111, Loss: 0.4336678381505024\n",
      "Epoch 112, Loss: 0.43293645371434136\n",
      "Epoch 113, Loss: 0.4322255689193262\n",
      "Epoch 114, Loss: 0.43151905539994817\n",
      "Epoch 115, Loss: 0.4308681047926473\n",
      "Epoch 116, Loss: 0.43019486730281137\n",
      "Epoch 117, Loss: 0.4294642995789596\n",
      "Epoch 118, Loss: 0.428773202045891\n",
      "Epoch 119, Loss: 0.4280835472699483\n",
      "Epoch 120, Loss: 0.42736479935769334\n",
      "Epoch 121, Loss: 0.42666892166895315\n",
      "Epoch 122, Loss: 0.4259570922319781\n",
      "Epoch 123, Loss: 0.4252550741102641\n",
      "Epoch 124, Loss: 0.42460069691371277\n",
      "Epoch 125, Loss: 0.42393279650898086\n",
      "Epoch 126, Loss: 0.4232776776596396\n",
      "Epoch 127, Loss: 0.42260401926593627\n",
      "Epoch 128, Loss: 0.42194182255253804\n",
      "Epoch 129, Loss: 0.4214007749898435\n",
      "Epoch 130, Loss: 0.42125564605370314\n",
      "Epoch 131, Loss: 0.42109880745138445\n",
      "Epoch 132, Loss: 0.41969562911783637\n",
      "Epoch 133, Loss: 0.4188446777693228\n",
      "Epoch 134, Loss: 0.4188830633978225\n",
      "Epoch 135, Loss: 0.41767548584944325\n",
      "Epoch 136, Loss: 0.41724150661694587\n",
      "Epoch 137, Loss: 0.4169397790212078\n",
      "Epoch 138, Loss: 0.41582145995362063\n",
      "Epoch 139, Loss: 0.415704530262987\n",
      "Epoch 140, Loss: 0.4149624383542486\n",
      "Epoch 141, Loss: 0.4141713305267659\n",
      "Epoch 142, Loss: 0.4139994987206027\n",
      "Epoch 143, Loss: 0.4130547874736136\n",
      "Epoch 144, Loss: 0.41265117591589595\n",
      "Epoch 145, Loss: 0.4122258424025143\n",
      "Epoch 146, Loss: 0.41133035005291874\n",
      "Epoch 147, Loss: 0.4109870670434782\n",
      "Epoch 148, Loss: 0.4104485333201212\n",
      "Epoch 149, Loss: 0.4096291015519768\n",
      "Epoch 150, Loss: 0.40921038601234266\n",
      "Epoch 151, Loss: 0.40874997611439484\n",
      "Epoch 152, Loss: 0.40801464639348467\n",
      "Epoch 153, Loss: 0.40754358041036615\n",
      "Epoch 154, Loss: 0.40714169722585447\n",
      "Epoch 155, Loss: 0.40654051003593444\n",
      "Epoch 156, Loss: 0.4059751754791371\n",
      "Epoch 157, Loss: 0.4055667413333103\n",
      "Epoch 158, Loss: 0.4051361402941386\n",
      "Epoch 159, Loss: 0.4046279730889399\n",
      "Epoch 160, Loss: 0.4041057079428899\n",
      "Epoch 161, Loss: 0.40366572259282774\n",
      "Epoch 162, Loss: 0.40325384077169335\n",
      "Epoch 163, Loss: 0.4028795803790884\n",
      "Epoch 164, Loss: 0.4024833696199451\n",
      "Epoch 165, Loss: 0.4021458185230142\n",
      "Epoch 166, Loss: 0.4018125267770497\n",
      "Epoch 167, Loss: 0.4015548527208361\n",
      "Epoch 168, Loss: 0.4013446328167472\n",
      "Epoch 169, Loss: 0.40102397788865024\n",
      "Epoch 170, Loss: 0.4004260722030534\n",
      "Epoch 171, Loss: 0.3996765095241352\n",
      "Epoch 172, Loss: 0.3991544108045676\n",
      "Epoch 173, Loss: 0.398979304819065\n",
      "Epoch 174, Loss: 0.39887916171139226\n",
      "Epoch 175, Loss: 0.3985997598898567\n",
      "Epoch 176, Loss: 0.39806325951753985\n",
      "Epoch 177, Loss: 0.3974356303488242\n",
      "Epoch 178, Loss: 0.3969803887959612\n",
      "Epoch 179, Loss: 0.3967342434983146\n",
      "Epoch 180, Loss: 0.39656932277837376\n",
      "Epoch 181, Loss: 0.3964832475016681\n",
      "Epoch 182, Loss: 0.3962576081421\n",
      "Epoch 183, Loss: 0.39585070404620365\n",
      "Epoch 184, Loss: 0.39534072172123647\n",
      "Epoch 185, Loss: 0.3948864801168426\n",
      "Epoch 186, Loss: 0.3946188461203301\n",
      "Epoch 187, Loss: 0.3945200512495842\n",
      "Epoch 188, Loss: 0.39447304324600313\n",
      "Epoch 189, Loss: 0.39437028226131404\n",
      "Epoch 190, Loss: 0.3941087443347418\n",
      "Epoch 191, Loss: 0.3935926433273573\n",
      "Epoch 192, Loss: 0.39305804699840907\n",
      "Epoch 193, Loss: 0.3927396944747007\n",
      "Epoch 194, Loss: 0.3926123608896049\n",
      "Epoch 195, Loss: 0.39255506533181445\n",
      "Epoch 196, Loss: 0.392451156656838\n",
      "Epoch 197, Loss: 0.39218678113407957\n",
      "Epoch 198, Loss: 0.3917893603926838\n",
      "Epoch 199, Loss: 0.3913582404991341\n",
      "Epoch 200, Loss: 0.3909858181593736\n",
      "Epoch 201, Loss: 0.3907151881054609\n",
      "Epoch 202, Loss: 0.39055739771476483\n",
      "Epoch 203, Loss: 0.3904919779303991\n",
      "Epoch 204, Loss: 0.3905723917821476\n",
      "Epoch 205, Loss: 0.3906899016823223\n",
      "Epoch 206, Loss: 0.39069974184240086\n",
      "Epoch 207, Loss: 0.3901639888241884\n",
      "Epoch 208, Loss: 0.38931665660031206\n",
      "Epoch 209, Loss: 0.388804906573801\n",
      "Epoch 210, Loss: 0.38877531812472205\n",
      "Epoch 211, Loss: 0.3888756107814778\n",
      "Epoch 212, Loss: 0.38874952221194037\n",
      "Epoch 213, Loss: 0.3882976820172411\n",
      "Epoch 214, Loss: 0.38770144287182307\n",
      "Epoch 215, Loss: 0.38746465167974703\n",
      "Epoch 216, Loss: 0.387481572882064\n",
      "Epoch 217, Loss: 0.3874745352899482\n",
      "Epoch 218, Loss: 0.3874022098942019\n",
      "Epoch 219, Loss: 0.3870839023004189\n",
      "Epoch 220, Loss: 0.3865213757460447\n",
      "Epoch 221, Loss: 0.38612983636862047\n",
      "Epoch 222, Loss: 0.3859919644739885\n",
      "Epoch 223, Loss: 0.3859140906396562\n",
      "Epoch 224, Loss: 0.3858877559218022\n",
      "Epoch 225, Loss: 0.38597055749205117\n",
      "Epoch 226, Loss: 0.38572117229147046\n",
      "Epoch 227, Loss: 0.38545359185470546\n",
      "Epoch 228, Loss: 0.3851033002193418\n",
      "Epoch 229, Loss: 0.3846852756005191\n",
      "Epoch 230, Loss: 0.38432414486039984\n",
      "Epoch 231, Loss: 0.38416099483470806\n",
      "Epoch 232, Loss: 0.38406870508729585\n",
      "Epoch 233, Loss: 0.38402092217405526\n",
      "Epoch 234, Loss: 0.3842270853411316\n",
      "Epoch 235, Loss: 0.38451578771821887\n",
      "Epoch 236, Loss: 0.3848765450558402\n",
      "Epoch 237, Loss: 0.3845835608374576\n",
      "Epoch 238, Loss: 0.3836487763632296\n",
      "Epoch 239, Loss: 0.3828400387881854\n",
      "Epoch 240, Loss: 0.38277915887248215\n",
      "Epoch 241, Loss: 0.3830328326731393\n",
      "Epoch 242, Loss: 0.38313410348329147\n",
      "Epoch 243, Loss: 0.38288541994602426\n",
      "Epoch 244, Loss: 0.3821865920510662\n",
      "Epoch 245, Loss: 0.3818135169585961\n",
      "Epoch 246, Loss: 0.3819240458657393\n",
      "Epoch 247, Loss: 0.3820064388401564\n",
      "Epoch 248, Loss: 0.38193153687062\n",
      "Epoch 249, Loss: 0.3816483566141348\n",
      "Epoch 250, Loss: 0.3811239448462694\n",
      "Epoch 251, Loss: 0.38085109995141886\n",
      "Epoch 252, Loss: 0.38079768928414787\n",
      "Epoch 253, Loss: 0.38072487828265716\n",
      "Epoch 254, Loss: 0.3807166981601478\n",
      "Epoch 255, Loss: 0.3807161306331667\n",
      "Epoch 256, Loss: 0.38062425838830416\n",
      "Epoch 257, Loss: 0.3804192371775983\n",
      "Epoch 258, Loss: 0.38029208850234647\n",
      "Epoch 259, Loss: 0.3800320172938514\n",
      "Epoch 260, Loss: 0.3796647924532415\n",
      "Epoch 261, Loss: 0.37932101879023084\n",
      "Epoch 262, Loss: 0.37906596170403023\n",
      "Epoch 263, Loss: 0.3788110672470965\n",
      "Epoch 264, Loss: 0.3785261627084677\n",
      "Epoch 265, Loss: 0.3783489927371473\n",
      "Epoch 266, Loss: 0.3782654879601786\n",
      "Epoch 267, Loss: 0.378158598581487\n",
      "Epoch 268, Loss: 0.37828321457186875\n",
      "Epoch 269, Loss: 0.3792632476011715\n",
      "Epoch 270, Loss: 0.3818969482694999\n",
      "Epoch 271, Loss: 0.3824068762046286\n",
      "Epoch 272, Loss: 0.3795151488091365\n",
      "Epoch 273, Loss: 0.37709526979230723\n",
      "Epoch 274, Loss: 0.3789790565307842\n",
      "Epoch 275, Loss: 0.37994480362737415\n",
      "Epoch 276, Loss: 0.37685883286500127\n",
      "Epoch 277, Loss: 0.3773816494439598\n",
      "Epoch 278, Loss: 0.3792185332207675\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2524458222009196\n",
      "Test R^2 score: 0.3060728047899948\n",
      "Num of epochs: 279\n",
      "Epoch 1, Loss: 0.563142171506906\n",
      "Epoch 2, Loss: 0.5616982892677805\n",
      "Epoch 3, Loss: 0.5604481095022048\n",
      "Epoch 4, Loss: 0.5594100855900466\n",
      "Epoch 5, Loss: 0.5585668864159583\n",
      "Epoch 6, Loss: 0.5578943422260707\n",
      "Epoch 7, Loss: 0.5573801315064556\n",
      "Epoch 8, Loss: 0.5570063410214833\n",
      "Epoch 9, Loss: 0.5567472389248651\n",
      "Epoch 10, Loss: 0.5565759721653679\n",
      "Epoch 11, Loss: 0.5564678258549189\n",
      "Epoch 12, Loss: 0.5564024298477045\n",
      "Epoch 13, Loss: 0.5563642920185925\n",
      "Epoch 14, Loss: 0.5563425704994119\n",
      "Epoch 15, Loss: 0.5563296871755314\n",
      "Epoch 16, Loss: 0.5563204731392899\n",
      "Epoch 17, Loss: 0.5563116339494757\n",
      "Epoch 18, Loss: 0.5562999820755855\n",
      "Epoch 19, Loss: 0.5562828654320489\n",
      "Epoch 20, Loss: 0.5562575243323116\n",
      "Epoch 21, Loss: 0.5562487645081933\n",
      "Epoch 22, Loss: 0.5561838249962181\n",
      "Epoch 23, Loss: 0.5560997459986573\n",
      "Epoch 24, Loss: 0.5560067834508929\n",
      "Epoch 25, Loss: 0.5558874019974669\n",
      "Epoch 26, Loss: 0.5557394127465798\n",
      "Epoch 27, Loss: 0.5555615053917913\n",
      "Epoch 28, Loss: 0.5553526852332017\n",
      "Epoch 29, Loss: 0.5551139105926316\n",
      "Epoch 30, Loss: 0.5548435851225505\n",
      "Epoch 31, Loss: 0.5545273670566849\n",
      "Epoch 32, Loss: 0.5541507918251946\n",
      "Epoch 33, Loss: 0.5537000113457101\n",
      "Epoch 34, Loss: 0.5531772147064967\n",
      "Epoch 35, Loss: 0.5525796087227027\n",
      "Epoch 36, Loss: 0.5519086783426813\n",
      "Epoch 37, Loss: 0.5511600463376537\n",
      "Epoch 38, Loss: 0.5502908566154286\n",
      "Epoch 39, Loss: 0.5492615803803044\n",
      "Epoch 40, Loss: 0.5480166643751877\n",
      "Epoch 41, Loss: 0.5464811541753477\n",
      "Epoch 42, Loss: 0.5445833419336709\n",
      "Epoch 43, Loss: 0.542279526433809\n",
      "Epoch 44, Loss: 0.5394770369039912\n",
      "Epoch 45, Loss: 0.536103044527713\n",
      "Epoch 46, Loss: 0.5322342898306586\n",
      "Epoch 47, Loss: 0.527877226949263\n",
      "Epoch 48, Loss: 0.5230121022660422\n",
      "Epoch 49, Loss: 0.517779041376514\n",
      "Epoch 50, Loss: 0.5123078253443059\n",
      "Epoch 51, Loss: 0.50707831494939\n",
      "Epoch 52, Loss: 0.5026628693870189\n",
      "Epoch 53, Loss: 0.49945197768954497\n",
      "Epoch 54, Loss: 0.4962026821898111\n",
      "Epoch 55, Loss: 0.49152108141023604\n",
      "Epoch 56, Loss: 0.4858971796756267\n",
      "Epoch 57, Loss: 0.4813018801827386\n",
      "Epoch 58, Loss: 0.4790727913852824\n",
      "Epoch 59, Loss: 0.4795471128871025\n",
      "Epoch 60, Loss: 0.48103895699866944\n",
      "Epoch 61, Loss: 0.4807127821318202\n",
      "Epoch 62, Loss: 0.4790006864946977\n",
      "Epoch 63, Loss: 0.4766934011816057\n",
      "Epoch 64, Loss: 0.4744951087068462\n",
      "Epoch 65, Loss: 0.47344414797606776\n",
      "Epoch 66, Loss: 0.4727679506834651\n",
      "Epoch 67, Loss: 0.4720752550086555\n",
      "Epoch 68, Loss: 0.4711243893099921\n",
      "Epoch 69, Loss: 0.47026014258353865\n",
      "Epoch 70, Loss: 0.4695602566713577\n",
      "Epoch 71, Loss: 0.46896440053252164\n",
      "Epoch 72, Loss: 0.4684422754473109\n",
      "Epoch 73, Loss: 0.46782777984271073\n",
      "Epoch 74, Loss: 0.46701531506509314\n",
      "Epoch 75, Loss: 0.46612618758361557\n",
      "Epoch 76, Loss: 0.465332127317917\n",
      "Epoch 77, Loss: 0.46467779707382595\n",
      "Epoch 78, Loss: 0.4639640305467214\n",
      "Epoch 79, Loss: 0.46297661670666407\n",
      "Epoch 80, Loss: 0.4619625138725871\n",
      "Epoch 81, Loss: 0.46135409974078845\n",
      "Epoch 82, Loss: 0.46098211040250253\n",
      "Epoch 83, Loss: 0.46055611495179727\n",
      "Epoch 84, Loss: 0.4600330790256678\n",
      "Epoch 85, Loss: 0.4594290831252445\n",
      "Epoch 86, Loss: 0.4588259484414663\n",
      "Epoch 87, Loss: 0.45825027847593747\n",
      "Epoch 88, Loss: 0.45770733702835786\n",
      "Epoch 89, Loss: 0.4571887177029375\n",
      "Epoch 90, Loss: 0.4566893154320682\n",
      "Epoch 91, Loss: 0.45617863606471265\n",
      "Epoch 92, Loss: 0.45568157674172904\n",
      "Epoch 93, Loss: 0.4551997042812114\n",
      "Epoch 94, Loss: 0.45474895966438633\n",
      "Epoch 95, Loss: 0.45432853358817415\n",
      "Epoch 96, Loss: 0.45390258039084336\n",
      "Epoch 97, Loss: 0.45345401328979024\n",
      "Epoch 98, Loss: 0.4529976994822362\n",
      "Epoch 99, Loss: 0.45254863058815936\n",
      "Epoch 100, Loss: 0.452112299420391\n",
      "Epoch 101, Loss: 0.4516978315156507\n",
      "Epoch 102, Loss: 0.45129784150798186\n",
      "Epoch 103, Loss: 0.4508881275274266\n",
      "Epoch 104, Loss: 0.450465834757369\n",
      "Epoch 105, Loss: 0.4500487413765326\n",
      "Epoch 106, Loss: 0.44963087996582435\n",
      "Epoch 107, Loss: 0.4492008371513494\n",
      "Epoch 108, Loss: 0.44877069768219874\n",
      "Epoch 109, Loss: 0.4483315206364617\n",
      "Epoch 110, Loss: 0.44789818422494954\n",
      "Epoch 111, Loss: 0.4474660432708245\n",
      "Epoch 112, Loss: 0.4470318345643068\n",
      "Epoch 113, Loss: 0.4465995059420206\n",
      "Epoch 114, Loss: 0.4461728368290236\n",
      "Epoch 115, Loss: 0.4457364824602061\n",
      "Epoch 116, Loss: 0.4452909665171679\n",
      "Epoch 117, Loss: 0.4448518210597719\n",
      "Epoch 118, Loss: 0.4444020819425958\n",
      "Epoch 119, Loss: 0.4439466007346558\n",
      "Epoch 120, Loss: 0.4434920629169573\n",
      "Epoch 121, Loss: 0.44302214177943977\n",
      "Epoch 122, Loss: 0.44254192328810027\n",
      "Epoch 123, Loss: 0.4420471096598447\n",
      "Epoch 124, Loss: 0.4415391030021922\n",
      "Epoch 125, Loss: 0.4409953542667925\n",
      "Epoch 126, Loss: 0.4404371814978346\n",
      "Epoch 127, Loss: 0.43989833743753975\n",
      "Epoch 128, Loss: 0.43934730103331104\n",
      "Epoch 129, Loss: 0.4387962008873393\n",
      "Epoch 130, Loss: 0.43823968142816294\n",
      "Epoch 131, Loss: 0.43766330327891345\n",
      "Epoch 132, Loss: 0.4370812898805681\n",
      "Epoch 133, Loss: 0.43648407692503904\n",
      "Epoch 134, Loss: 0.4358567132234365\n",
      "Epoch 135, Loss: 0.4352412156276346\n",
      "Epoch 136, Loss: 0.43460689776433065\n",
      "Epoch 137, Loss: 0.43394306648944375\n",
      "Epoch 138, Loss: 0.43323562197482224\n",
      "Epoch 139, Loss: 0.43252567675340065\n",
      "Epoch 140, Loss: 0.43184156616904285\n",
      "Epoch 141, Loss: 0.4311809249511541\n",
      "Epoch 142, Loss: 0.4305059787277488\n",
      "Epoch 143, Loss: 0.42986469083283907\n",
      "Epoch 144, Loss: 0.4292758356827461\n",
      "Epoch 145, Loss: 0.4287135443466978\n",
      "Epoch 146, Loss: 0.42812629059088875\n",
      "Epoch 147, Loss: 0.42754211633810596\n",
      "Epoch 148, Loss: 0.4269587656889245\n",
      "Epoch 149, Loss: 0.4263761546528351\n",
      "Epoch 150, Loss: 0.42578697200744986\n",
      "Epoch 151, Loss: 0.42521127119767366\n",
      "Epoch 152, Loss: 0.4246207705094233\n",
      "Epoch 153, Loss: 0.42401182351181405\n",
      "Epoch 154, Loss: 0.4233981117706918\n",
      "Epoch 155, Loss: 0.4228941122940523\n",
      "Epoch 156, Loss: 0.42260366666239413\n",
      "Epoch 157, Loss: 0.42251510096542494\n",
      "Epoch 158, Loss: 0.4217292392552695\n",
      "Epoch 159, Loss: 0.42067544433430637\n",
      "Epoch 160, Loss: 0.4207933830271302\n",
      "Epoch 161, Loss: 0.42015824873205193\n",
      "Epoch 162, Loss: 0.419208061858317\n",
      "Epoch 163, Loss: 0.4191611385391718\n",
      "Epoch 164, Loss: 0.41835375015366977\n",
      "Epoch 165, Loss: 0.4177018498831589\n",
      "Epoch 166, Loss: 0.4175403752762689\n",
      "Epoch 167, Loss: 0.4168902055806803\n",
      "Epoch 168, Loss: 0.4162082315801825\n",
      "Epoch 169, Loss: 0.41597607921637103\n",
      "Epoch 170, Loss: 0.4155303739802572\n",
      "Epoch 171, Loss: 0.41479238921363903\n",
      "Epoch 172, Loss: 0.41431852738384994\n",
      "Epoch 173, Loss: 0.4140007404836768\n",
      "Epoch 174, Loss: 0.4135009989051793\n",
      "Epoch 175, Loss: 0.41286188276394264\n",
      "Epoch 176, Loss: 0.4124271559697824\n",
      "Epoch 177, Loss: 0.41212761644245005\n",
      "Epoch 178, Loss: 0.41167997072642465\n",
      "Epoch 179, Loss: 0.41107750019941075\n",
      "Epoch 180, Loss: 0.41056178798140514\n",
      "Epoch 181, Loss: 0.410149674135809\n",
      "Epoch 182, Loss: 0.4098132743077645\n",
      "Epoch 183, Loss: 0.4094551452051179\n",
      "Epoch 184, Loss: 0.40900457454375594\n",
      "Epoch 185, Loss: 0.4084612199277339\n",
      "Epoch 186, Loss: 0.40794455630016485\n",
      "Epoch 187, Loss: 0.407444938818805\n",
      "Epoch 188, Loss: 0.4069864493698815\n",
      "Epoch 189, Loss: 0.40661786003774714\n",
      "Epoch 190, Loss: 0.40643266092652186\n",
      "Epoch 191, Loss: 0.40686626641763596\n",
      "Epoch 192, Loss: 0.4078050525029097\n",
      "Epoch 193, Loss: 0.4069464106380251\n",
      "Epoch 194, Loss: 0.4046616866373808\n",
      "Epoch 195, Loss: 0.40574153845373295\n",
      "Epoch 196, Loss: 0.4055483517576729\n",
      "Epoch 197, Loss: 0.40355313580031626\n",
      "Epoch 198, Loss: 0.4047555394951081\n",
      "Epoch 199, Loss: 0.4037863784085282\n",
      "Epoch 200, Loss: 0.402576601368682\n",
      "Epoch 201, Loss: 0.4035764162813951\n",
      "Epoch 202, Loss: 0.402080987106488\n",
      "Epoch 203, Loss: 0.4019176115282882\n",
      "Epoch 204, Loss: 0.4022614478218327\n",
      "Epoch 205, Loss: 0.40087134183374895\n",
      "Epoch 206, Loss: 0.4011430323260371\n",
      "Epoch 207, Loss: 0.40086559872952615\n",
      "Epoch 208, Loss: 0.39980757525453575\n",
      "Epoch 209, Loss: 0.400137323410807\n",
      "Epoch 210, Loss: 0.3993664552255074\n",
      "Epoch 211, Loss: 0.39886554464013646\n",
      "Epoch 212, Loss: 0.3990368542537191\n",
      "Epoch 213, Loss: 0.3982686077519412\n",
      "Epoch 214, Loss: 0.39791242745356603\n",
      "Epoch 215, Loss: 0.39795273855326063\n",
      "Epoch 216, Loss: 0.3973555366547031\n",
      "Epoch 217, Loss: 0.3968689467501642\n",
      "Epoch 218, Loss: 0.39691837404182745\n",
      "Epoch 219, Loss: 0.39652875830370804\n",
      "Epoch 220, Loss: 0.39590878353140807\n",
      "Epoch 221, Loss: 0.39572798640486934\n",
      "Epoch 222, Loss: 0.39559835645562785\n",
      "Epoch 223, Loss: 0.3950730748426157\n",
      "Epoch 224, Loss: 0.39459031673214795\n",
      "Epoch 225, Loss: 0.3944374010620573\n",
      "Epoch 226, Loss: 0.39420580896764734\n",
      "Epoch 227, Loss: 0.39375394788912466\n",
      "Epoch 228, Loss: 0.3932754624084505\n",
      "Epoch 229, Loss: 0.3929061657799221\n",
      "Epoch 230, Loss: 0.39262868071746365\n",
      "Epoch 231, Loss: 0.3924806578237776\n",
      "Epoch 232, Loss: 0.3924795188237389\n",
      "Epoch 233, Loss: 0.3924398036220282\n",
      "Epoch 234, Loss: 0.3922845112551001\n",
      "Epoch 235, Loss: 0.3916301954651073\n",
      "Epoch 236, Loss: 0.39070918129794396\n",
      "Epoch 237, Loss: 0.3899624737389565\n",
      "Epoch 238, Loss: 0.38970809135700046\n",
      "Epoch 239, Loss: 0.3898328951622103\n",
      "Epoch 240, Loss: 0.3901081480562417\n",
      "Epoch 241, Loss: 0.3905087297968171\n",
      "Epoch 242, Loss: 0.3898076470730324\n",
      "Epoch 243, Loss: 0.38838771995191246\n",
      "Epoch 244, Loss: 0.38713363586834604\n",
      "Epoch 245, Loss: 0.386998374106321\n",
      "Epoch 246, Loss: 0.3872665032489754\n",
      "Epoch 247, Loss: 0.38731680969874077\n",
      "Epoch 248, Loss: 0.38690982298283083\n",
      "Epoch 249, Loss: 0.38569963437780846\n",
      "Epoch 250, Loss: 0.38467716032708144\n",
      "Epoch 251, Loss: 0.38444635535273947\n",
      "Epoch 252, Loss: 0.384684733296415\n",
      "Epoch 253, Loss: 0.3847491265647051\n",
      "Epoch 254, Loss: 0.38451987614371025\n",
      "Epoch 255, Loss: 0.383825771138998\n",
      "Epoch 256, Loss: 0.3826328556733637\n",
      "Epoch 257, Loss: 0.3815884580850515\n",
      "Epoch 258, Loss: 0.38111244987851056\n",
      "Epoch 259, Loss: 0.38145437469108956\n",
      "Epoch 260, Loss: 0.38270617974342824\n",
      "Epoch 261, Loss: 0.38273604271753736\n",
      "Epoch 262, Loss: 0.3821235802598808\n",
      "Epoch 263, Loss: 0.3801476896163372\n",
      "Epoch 264, Loss: 0.3778778158859642\n",
      "Epoch 265, Loss: 0.3784026308950639\n",
      "Epoch 266, Loss: 0.3804590321891855\n",
      "Epoch 267, Loss: 0.38005564075234133\n",
      "Epoch 268, Loss: 0.3772236935144109\n",
      "Epoch 269, Loss: 0.3748101508859054\n",
      "Epoch 270, Loss: 0.37541455957680164\n",
      "Epoch 271, Loss: 0.3757367050194469\n",
      "Epoch 272, Loss: 0.37581940375958556\n",
      "Epoch 273, Loss: 0.3759565471919735\n",
      "Epoch 274, Loss: 0.372726222732486\n",
      "Epoch 275, Loss: 0.37149149008434335\n",
      "Epoch 276, Loss: 0.3707937533797882\n",
      "Epoch 277, Loss: 0.37033551703921436\n",
      "Epoch 278, Loss: 0.37152871189217873\n",
      "Epoch 279, Loss: 0.37421589573546143\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2410489904395327\n",
      "Test R^2 score: 0.3699952110768611\n",
      "Num of epochs: 280\n",
      "Epoch 1, Loss: 0.5584073322517709\n",
      "Epoch 2, Loss: 0.5577548202911645\n",
      "Epoch 3, Loss: 0.5572268160108437\n",
      "Epoch 4, Loss: 0.5568200073318423\n",
      "Epoch 5, Loss: 0.5565300814971746\n",
      "Epoch 6, Loss: 0.5563441239777694\n",
      "Epoch 7, Loss: 0.5562396830770006\n",
      "Epoch 8, Loss: 0.55619759580668\n",
      "Epoch 9, Loss: 0.556197569015551\n",
      "Epoch 10, Loss: 0.556221198289992\n",
      "Epoch 11, Loss: 0.5562538007542064\n",
      "Epoch 12, Loss: 0.5562842315684786\n",
      "Epoch 13, Loss: 0.556304857142171\n",
      "Epoch 14, Loss: 0.5563098393089371\n",
      "Epoch 15, Loss: 0.5562952676848478\n",
      "Epoch 16, Loss: 0.5562649178379769\n",
      "Epoch 17, Loss: 0.5562102946565649\n",
      "Epoch 18, Loss: 0.5561319000800407\n",
      "Epoch 19, Loss: 0.5560350838713773\n",
      "Epoch 20, Loss: 0.5559244735675481\n",
      "Epoch 21, Loss: 0.5557985327443553\n",
      "Epoch 22, Loss: 0.555655454223674\n",
      "Epoch 23, Loss: 0.5554924081305906\n",
      "Epoch 24, Loss: 0.5553034733697139\n",
      "Epoch 25, Loss: 0.5550810264173324\n",
      "Epoch 26, Loss: 0.5548117323897297\n",
      "Epoch 27, Loss: 0.554486117274323\n",
      "Epoch 28, Loss: 0.5540915229111051\n",
      "Epoch 29, Loss: 0.553610091133771\n",
      "Epoch 30, Loss: 0.5530259943572956\n",
      "Epoch 31, Loss: 0.5523287359676367\n",
      "Epoch 32, Loss: 0.5514948935855941\n",
      "Epoch 33, Loss: 0.5505221954829297\n",
      "Epoch 34, Loss: 0.5493953122581597\n",
      "Epoch 35, Loss: 0.5480778952511443\n",
      "Epoch 36, Loss: 0.546563577536409\n",
      "Epoch 37, Loss: 0.5448072306036938\n",
      "Epoch 38, Loss: 0.5427573087367964\n",
      "Epoch 39, Loss: 0.5403699085631961\n",
      "Epoch 40, Loss: 0.5376162547429303\n",
      "Epoch 41, Loss: 0.5344712823159757\n",
      "Epoch 42, Loss: 0.5308769262470664\n",
      "Epoch 43, Loss: 0.526801784491938\n",
      "Epoch 44, Loss: 0.5223158590371492\n",
      "Epoch 45, Loss: 0.5174201004341172\n",
      "Epoch 46, Loss: 0.5120828803546456\n",
      "Epoch 47, Loss: 0.5062193896611454\n",
      "Epoch 48, Loss: 0.49977699909681483\n",
      "Epoch 49, Loss: 0.49304709983195555\n",
      "Epoch 50, Loss: 0.4868451170265187\n",
      "Epoch 51, Loss: 0.48253248853952535\n",
      "Epoch 52, Loss: 0.48133126043441765\n",
      "Epoch 53, Loss: 0.4820296820764993\n",
      "Epoch 54, Loss: 0.4816737687215394\n",
      "Epoch 55, Loss: 0.479873101924512\n",
      "Epoch 56, Loss: 0.47743222342305786\n",
      "Epoch 57, Loss: 0.47490419249789556\n",
      "Epoch 58, Loss: 0.4726713982038365\n",
      "Epoch 59, Loss: 0.47102294440378983\n",
      "Epoch 60, Loss: 0.4703186649412717\n",
      "Epoch 61, Loss: 0.4697637245879503\n",
      "Epoch 62, Loss: 0.46841224581976965\n",
      "Epoch 63, Loss: 0.46668433584527885\n",
      "Epoch 64, Loss: 0.4651112147612764\n",
      "Epoch 65, Loss: 0.4639013016855373\n",
      "Epoch 66, Loss: 0.46296110300732446\n",
      "Epoch 67, Loss: 0.46223030797401077\n",
      "Epoch 68, Loss: 0.4615085588107914\n",
      "Epoch 69, Loss: 0.46056124314535146\n",
      "Epoch 70, Loss: 0.45950361060404055\n",
      "Epoch 71, Loss: 0.4585678320714174\n",
      "Epoch 72, Loss: 0.4578041811502972\n",
      "Epoch 73, Loss: 0.4571747676773887\n",
      "Epoch 74, Loss: 0.4565278729069663\n",
      "Epoch 75, Loss: 0.45575616120815593\n",
      "Epoch 76, Loss: 0.45495142011889317\n",
      "Epoch 77, Loss: 0.45425091000068474\n",
      "Epoch 78, Loss: 0.453704709795653\n",
      "Epoch 79, Loss: 0.4531990352525653\n",
      "Epoch 80, Loss: 0.45257383566110637\n",
      "Epoch 81, Loss: 0.451814350922783\n",
      "Epoch 82, Loss: 0.451085152486298\n",
      "Epoch 83, Loss: 0.4504896844080836\n",
      "Epoch 84, Loss: 0.4499137974666606\n",
      "Epoch 85, Loss: 0.4492470773804562\n",
      "Epoch 86, Loss: 0.4485290041883046\n",
      "Epoch 87, Loss: 0.447829178834268\n",
      "Epoch 88, Loss: 0.4472041691699626\n",
      "Epoch 89, Loss: 0.4465865097638831\n",
      "Epoch 90, Loss: 0.445934730954251\n",
      "Epoch 91, Loss: 0.4452351787430697\n",
      "Epoch 92, Loss: 0.4445313914588743\n",
      "Epoch 93, Loss: 0.4438630490629209\n",
      "Epoch 94, Loss: 0.443172936583935\n",
      "Epoch 95, Loss: 0.44246293914899865\n",
      "Epoch 96, Loss: 0.44177738554824597\n",
      "Epoch 97, Loss: 0.4411334148251877\n",
      "Epoch 98, Loss: 0.4404868957852268\n",
      "Epoch 99, Loss: 0.43984003624440826\n",
      "Epoch 100, Loss: 0.43917749874116185\n",
      "Epoch 101, Loss: 0.43851674666771834\n",
      "Epoch 102, Loss: 0.43784616603651666\n",
      "Epoch 103, Loss: 0.43717990814117796\n",
      "Epoch 104, Loss: 0.43652990622282556\n",
      "Epoch 105, Loss: 0.43586761912624183\n",
      "Epoch 106, Loss: 0.4351931106050122\n",
      "Epoch 107, Loss: 0.4345344957314824\n",
      "Epoch 108, Loss: 0.43390759287575886\n",
      "Epoch 109, Loss: 0.43329108044449893\n",
      "Epoch 110, Loss: 0.4326875168787815\n",
      "Epoch 111, Loss: 0.43209169734092895\n",
      "Epoch 112, Loss: 0.4315033603782691\n",
      "Epoch 113, Loss: 0.43092853617041915\n",
      "Epoch 114, Loss: 0.4303354925912325\n",
      "Epoch 115, Loss: 0.4297323550307313\n",
      "Epoch 116, Loss: 0.42913777993337443\n",
      "Epoch 117, Loss: 0.4285460483040814\n",
      "Epoch 118, Loss: 0.42795121779920947\n",
      "Epoch 119, Loss: 0.42736326518297807\n",
      "Epoch 120, Loss: 0.42679040640311267\n",
      "Epoch 121, Loss: 0.426225203299039\n",
      "Epoch 122, Loss: 0.42566504336301253\n",
      "Epoch 123, Loss: 0.4250989749606689\n",
      "Epoch 124, Loss: 0.4245267638530001\n",
      "Epoch 125, Loss: 0.42393694416736877\n",
      "Epoch 126, Loss: 0.42334957617601865\n",
      "Epoch 127, Loss: 0.42276227329898086\n",
      "Epoch 128, Loss: 0.4221770829808126\n",
      "Epoch 129, Loss: 0.42161329417260357\n",
      "Epoch 130, Loss: 0.4210929863521184\n",
      "Epoch 131, Loss: 0.42088114267029714\n",
      "Epoch 132, Loss: 0.42105609392794235\n",
      "Epoch 133, Loss: 0.4198572508299072\n",
      "Epoch 134, Loss: 0.41893005343305023\n",
      "Epoch 135, Loss: 0.41913735494200155\n",
      "Epoch 136, Loss: 0.41784462912945397\n",
      "Epoch 137, Loss: 0.4177086279179144\n",
      "Epoch 138, Loss: 0.41716450117059456\n",
      "Epoch 139, Loss: 0.4162209232587777\n",
      "Epoch 140, Loss: 0.4162015365190479\n",
      "Epoch 141, Loss: 0.41518916389032007\n",
      "Epoch 142, Loss: 0.4149703204503518\n",
      "Epoch 143, Loss: 0.41447800355786246\n",
      "Epoch 144, Loss: 0.41373317145499533\n",
      "Epoch 145, Loss: 0.4136484523118063\n",
      "Epoch 146, Loss: 0.41285217380397216\n",
      "Epoch 147, Loss: 0.4125135166670191\n",
      "Epoch 148, Loss: 0.41211270154722274\n",
      "Epoch 149, Loss: 0.41142883879138664\n",
      "Epoch 150, Loss: 0.4112153502769542\n",
      "Epoch 151, Loss: 0.4106561611492728\n",
      "Epoch 152, Loss: 0.4101258039527647\n",
      "Epoch 153, Loss: 0.40991410873498035\n",
      "Epoch 154, Loss: 0.4093344857646726\n",
      "Epoch 155, Loss: 0.40885420716238935\n",
      "Epoch 156, Loss: 0.4085786907856333\n",
      "Epoch 157, Loss: 0.40801813414772187\n",
      "Epoch 158, Loss: 0.4075687717843771\n",
      "Epoch 159, Loss: 0.40726157936649443\n",
      "Epoch 160, Loss: 0.4067852089360953\n",
      "Epoch 161, Loss: 0.4062599951174748\n",
      "Epoch 162, Loss: 0.4058558679599892\n",
      "Epoch 163, Loss: 0.4054822085283981\n",
      "Epoch 164, Loss: 0.4050153163085929\n",
      "Epoch 165, Loss: 0.40451305709484114\n",
      "Epoch 166, Loss: 0.4040081449032279\n",
      "Epoch 167, Loss: 0.4035230962720797\n",
      "Epoch 168, Loss: 0.40304116109164756\n",
      "Epoch 169, Loss: 0.4025699757232913\n",
      "Epoch 170, Loss: 0.4021135801425609\n",
      "Epoch 171, Loss: 0.4016952844307358\n",
      "Epoch 172, Loss: 0.4014291645843466\n",
      "Epoch 173, Loss: 0.40187061601089674\n",
      "Epoch 174, Loss: 0.40287018566350113\n",
      "Epoch 175, Loss: 0.40191516456004295\n",
      "Epoch 176, Loss: 0.39945640432801166\n",
      "Epoch 177, Loss: 0.400163502357478\n",
      "Epoch 178, Loss: 0.4002017436295043\n",
      "Epoch 179, Loss: 0.3983289159279784\n",
      "Epoch 180, Loss: 0.39882347634769966\n",
      "Epoch 181, Loss: 0.3984151160740528\n",
      "Epoch 182, Loss: 0.3971777242002228\n",
      "Epoch 183, Loss: 0.3974913039545808\n",
      "Epoch 184, Loss: 0.39686620582389015\n",
      "Epoch 185, Loss: 0.39593981473467404\n",
      "Epoch 186, Loss: 0.39629705354277206\n",
      "Epoch 187, Loss: 0.3953979151124743\n",
      "Epoch 188, Loss: 0.39483783631449476\n",
      "Epoch 189, Loss: 0.39488751783632664\n",
      "Epoch 190, Loss: 0.3943129587114864\n",
      "Epoch 191, Loss: 0.3938721921330992\n",
      "Epoch 192, Loss: 0.39354626289229505\n",
      "Epoch 193, Loss: 0.39353329432345824\n",
      "Epoch 194, Loss: 0.39293364184102325\n",
      "Epoch 195, Loss: 0.3923096189309549\n",
      "Epoch 196, Loss: 0.392308080609735\n",
      "Epoch 197, Loss: 0.39190604912804666\n",
      "Epoch 198, Loss: 0.39153487096612094\n",
      "Epoch 199, Loss: 0.39121249841844313\n",
      "Epoch 200, Loss: 0.3906986929999293\n",
      "Epoch 201, Loss: 0.39061809533692604\n",
      "Epoch 202, Loss: 0.3905025671778073\n",
      "Epoch 203, Loss: 0.3900131201676826\n",
      "Epoch 204, Loss: 0.3898589251666516\n",
      "Epoch 205, Loss: 0.38939208965241123\n",
      "Epoch 206, Loss: 0.38886398091855046\n",
      "Epoch 207, Loss: 0.38873817606788397\n",
      "Epoch 208, Loss: 0.38844388476254943\n",
      "Epoch 209, Loss: 0.38793372983653834\n",
      "Epoch 210, Loss: 0.3879279104331713\n",
      "Epoch 211, Loss: 0.3881366245476246\n",
      "Epoch 212, Loss: 0.38887603228562917\n",
      "Epoch 213, Loss: 0.39049602286600615\n",
      "Epoch 214, Loss: 0.3901663185320679\n",
      "Epoch 215, Loss: 0.3869701108048313\n",
      "Epoch 216, Loss: 0.38750347320476763\n",
      "Epoch 217, Loss: 0.38873687277337604\n",
      "Epoch 218, Loss: 0.3871811693365187\n",
      "Epoch 219, Loss: 0.38604731985702573\n",
      "Epoch 220, Loss: 0.38835735150924505\n",
      "Epoch 221, Loss: 0.3855822460951247\n",
      "Epoch 222, Loss: 0.38566777924058737\n",
      "Epoch 223, Loss: 0.3856881598771551\n",
      "Epoch 224, Loss: 0.38522915101865757\n",
      "Epoch 225, Loss: 0.38412691732313553\n",
      "Epoch 226, Loss: 0.38448654742698196\n",
      "Epoch 227, Loss: 0.3841684810088061\n",
      "Epoch 228, Loss: 0.3834475485332985\n",
      "Epoch 229, Loss: 0.3833570111086977\n",
      "Epoch 230, Loss: 0.3830263358018224\n",
      "Epoch 231, Loss: 0.3832897014595877\n",
      "Epoch 232, Loss: 0.3823345080631726\n",
      "Epoch 233, Loss: 0.38227734820431963\n",
      "Epoch 234, Loss: 0.38177165785523076\n",
      "Epoch 235, Loss: 0.38204511293561333\n",
      "Epoch 236, Loss: 0.38173248762846385\n",
      "Epoch 237, Loss: 0.38145203083956297\n",
      "Epoch 238, Loss: 0.3808793478399289\n",
      "Epoch 239, Loss: 0.38045155135806136\n",
      "Epoch 240, Loss: 0.38053907962427735\n",
      "Epoch 241, Loss: 0.38030454863963403\n",
      "Epoch 242, Loss: 0.3804814933820317\n",
      "Epoch 243, Loss: 0.380708420010354\n",
      "Epoch 244, Loss: 0.38056376796216107\n",
      "Epoch 245, Loss: 0.3800870253333361\n",
      "Epoch 246, Loss: 0.37899932504709577\n",
      "Epoch 247, Loss: 0.3785764694520895\n",
      "Epoch 248, Loss: 0.3779998635286761\n",
      "Epoch 249, Loss: 0.3778922286678827\n",
      "Epoch 250, Loss: 0.3781556826351516\n",
      "Epoch 251, Loss: 0.3782687575977035\n",
      "Epoch 252, Loss: 0.3792388085843304\n",
      "Epoch 253, Loss: 0.3796861821218468\n",
      "Epoch 254, Loss: 0.37913024809538265\n",
      "Epoch 255, Loss: 0.3768978374830591\n",
      "Epoch 256, Loss: 0.3756702116290136\n",
      "Epoch 257, Loss: 0.37618931287235835\n",
      "Epoch 258, Loss: 0.3770878012622547\n",
      "Epoch 259, Loss: 0.3780572168425989\n",
      "Epoch 260, Loss: 0.3765884968184932\n",
      "Epoch 261, Loss: 0.3744545187905292\n",
      "Epoch 262, Loss: 0.37417089677952725\n",
      "Epoch 263, Loss: 0.37523617856991887\n",
      "Epoch 264, Loss: 0.376037057740911\n",
      "Epoch 265, Loss: 0.37502731780050574\n",
      "Epoch 266, Loss: 0.3735502950555093\n",
      "Epoch 267, Loss: 0.3722080166124031\n",
      "Epoch 268, Loss: 0.3722715859671412\n",
      "Epoch 269, Loss: 0.37291831152924365\n",
      "Epoch 270, Loss: 0.3736910625542514\n",
      "Epoch 271, Loss: 0.3741725494917749\n",
      "Epoch 272, Loss: 0.372917492384325\n",
      "Epoch 273, Loss: 0.37057625676801337\n",
      "Epoch 274, Loss: 0.36967848894966576\n",
      "Epoch 275, Loss: 0.3701583919889889\n",
      "Epoch 276, Loss: 0.371274723295818\n",
      "Epoch 277, Loss: 0.37263290044220987\n",
      "Epoch 278, Loss: 0.3729960421935162\n",
      "Epoch 279, Loss: 0.36922496256079396\n",
      "Epoch 280, Loss: 0.3675854332549043\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2443575218154964\n",
      "Test R^2 score: 0.354778050697439\n",
      "Num of epochs: 281\n",
      "Epoch 1, Loss: 0.5624477044273598\n",
      "Epoch 2, Loss: 0.5610192465124095\n",
      "Epoch 3, Loss: 0.5597947288129405\n",
      "Epoch 4, Loss: 0.5587693318600625\n",
      "Epoch 5, Loss: 0.5579350729515947\n",
      "Epoch 6, Loss: 0.5572822754208272\n",
      "Epoch 7, Loss: 0.5567984374018918\n",
      "Epoch 8, Loss: 0.556467477739274\n",
      "Epoch 9, Loss: 0.5562747489052577\n",
      "Epoch 10, Loss: 0.5561912998558768\n",
      "Epoch 11, Loss: 0.5561915945615469\n",
      "Epoch 12, Loss: 0.5562488984514966\n",
      "Epoch 13, Loss: 0.5563411509378096\n",
      "Epoch 14, Loss: 0.5564290230088297\n",
      "Epoch 15, Loss: 0.5565048319837306\n",
      "Epoch 16, Loss: 0.5565566150112117\n",
      "Epoch 17, Loss: 0.556577096626662\n",
      "Epoch 18, Loss: 0.5565641919581009\n",
      "Epoch 19, Loss: 0.5565194516719644\n",
      "Epoch 20, Loss: 0.5564468849724952\n",
      "Epoch 21, Loss: 0.5563519448718849\n",
      "Epoch 22, Loss: 0.5562402188587677\n",
      "Epoch 23, Loss: 0.5561150462142294\n",
      "Epoch 24, Loss: 0.5559786960033144\n",
      "Epoch 25, Loss: 0.5558308651033853\n",
      "Epoch 26, Loss: 0.5556694794777973\n",
      "Epoch 27, Loss: 0.5554894573574372\n",
      "Epoch 28, Loss: 0.5552830521176848\n",
      "Epoch 29, Loss: 0.5550338040186735\n",
      "Epoch 30, Loss: 0.5547349130488042\n",
      "Epoch 31, Loss: 0.5543762462047173\n",
      "Epoch 32, Loss: 0.553954351835754\n",
      "Epoch 33, Loss: 0.5534704315106588\n",
      "Epoch 34, Loss: 0.5529155905923192\n",
      "Epoch 35, Loss: 0.552277392943169\n",
      "Epoch 36, Loss: 0.5515365021714\n",
      "Epoch 37, Loss: 0.5506762140641753\n",
      "Epoch 38, Loss: 0.5496573106674292\n",
      "Epoch 39, Loss: 0.5484587760341385\n",
      "Epoch 40, Loss: 0.5470746901914781\n",
      "Epoch 41, Loss: 0.5454930419233354\n",
      "Epoch 42, Loss: 0.5436934704828239\n",
      "Epoch 43, Loss: 0.541671052939433\n",
      "Epoch 44, Loss: 0.5394119291161833\n",
      "Epoch 45, Loss: 0.5368732835167123\n",
      "Epoch 46, Loss: 0.5341234473936377\n",
      "Epoch 47, Loss: 0.5311986393503922\n",
      "Epoch 48, Loss: 0.5280543590454952\n",
      "Epoch 49, Loss: 0.5246150592373868\n",
      "Epoch 50, Loss: 0.5207796514184991\n",
      "Epoch 51, Loss: 0.516490037269927\n",
      "Epoch 52, Loss: 0.5118766133489091\n",
      "Epoch 53, Loss: 0.5070674125107104\n",
      "Epoch 54, Loss: 0.5021766432114972\n",
      "Epoch 55, Loss: 0.4972560513062503\n",
      "Epoch 56, Loss: 0.49254336434881113\n",
      "Epoch 57, Loss: 0.4883125295156882\n",
      "Epoch 58, Loss: 0.4848037022368621\n",
      "Epoch 59, Loss: 0.48215172806152923\n",
      "Epoch 60, Loss: 0.47980596216559346\n",
      "Epoch 61, Loss: 0.47790611530098265\n",
      "Epoch 62, Loss: 0.4753762317443907\n",
      "Epoch 63, Loss: 0.47359436508335107\n",
      "Epoch 64, Loss: 0.47224487183362807\n",
      "Epoch 65, Loss: 0.4712944432001642\n",
      "Epoch 66, Loss: 0.4705563233206149\n",
      "Epoch 67, Loss: 0.4695659846757027\n",
      "Epoch 68, Loss: 0.4684478739785191\n",
      "Epoch 69, Loss: 0.4671965926698484\n",
      "Epoch 70, Loss: 0.4656677956083881\n",
      "Epoch 71, Loss: 0.4640581239949959\n",
      "Epoch 72, Loss: 0.46242436937605824\n",
      "Epoch 73, Loss: 0.460747016729424\n",
      "Epoch 74, Loss: 0.4591817877691825\n",
      "Epoch 75, Loss: 0.457968329901553\n",
      "Epoch 76, Loss: 0.4570548711688044\n",
      "Epoch 77, Loss: 0.45643968688867187\n",
      "Epoch 78, Loss: 0.45585971234071304\n",
      "Epoch 79, Loss: 0.4552412927539591\n",
      "Epoch 80, Loss: 0.4544739211755571\n",
      "Epoch 81, Loss: 0.453583206148823\n",
      "Epoch 82, Loss: 0.4525938538436175\n",
      "Epoch 83, Loss: 0.4516217024646087\n",
      "Epoch 84, Loss: 0.45071386233569627\n",
      "Epoch 85, Loss: 0.44988993384781456\n",
      "Epoch 86, Loss: 0.4490836230508494\n",
      "Epoch 87, Loss: 0.44830242076409943\n",
      "Epoch 88, Loss: 0.44751043158365617\n",
      "Epoch 89, Loss: 0.44668871724918413\n",
      "Epoch 90, Loss: 0.44585933906551023\n",
      "Epoch 91, Loss: 0.44495420932915614\n",
      "Epoch 92, Loss: 0.4440285426343282\n",
      "Epoch 93, Loss: 0.44310788655559885\n",
      "Epoch 94, Loss: 0.44222698035421343\n",
      "Epoch 95, Loss: 0.44139296587644317\n",
      "Epoch 96, Loss: 0.44056680917330365\n",
      "Epoch 97, Loss: 0.43975211250986196\n",
      "Epoch 98, Loss: 0.43894456046388736\n",
      "Epoch 99, Loss: 0.4381447877102213\n",
      "Epoch 100, Loss: 0.43736501723107524\n",
      "Epoch 101, Loss: 0.43661885424137514\n",
      "Epoch 102, Loss: 0.4359258704873195\n",
      "Epoch 103, Loss: 0.4348984240456659\n",
      "Epoch 104, Loss: 0.43392201618567144\n",
      "Epoch 105, Loss: 0.43322447783505663\n",
      "Epoch 106, Loss: 0.4325845503713093\n",
      "Epoch 107, Loss: 0.43181468509326054\n",
      "Epoch 108, Loss: 0.4309733484750474\n",
      "Epoch 109, Loss: 0.43024888213154844\n",
      "Epoch 110, Loss: 0.42961477184357033\n",
      "Epoch 111, Loss: 0.4289124695095916\n",
      "Epoch 112, Loss: 0.4280396508674064\n",
      "Epoch 113, Loss: 0.42716311275632574\n",
      "Epoch 114, Loss: 0.42652046709155655\n",
      "Epoch 115, Loss: 0.4259954840975927\n",
      "Epoch 116, Loss: 0.42539424982269247\n",
      "Epoch 117, Loss: 0.4246334739380784\n",
      "Epoch 118, Loss: 0.4237873391773826\n",
      "Epoch 119, Loss: 0.42309834456898693\n",
      "Epoch 120, Loss: 0.42255179547632693\n",
      "Epoch 121, Loss: 0.4220096761703758\n",
      "Epoch 122, Loss: 0.421356253113864\n",
      "Epoch 123, Loss: 0.4205762156385667\n",
      "Epoch 124, Loss: 0.419787948897995\n",
      "Epoch 125, Loss: 0.41912636923744084\n",
      "Epoch 126, Loss: 0.41856169309818847\n",
      "Epoch 127, Loss: 0.4180520767860671\n",
      "Epoch 128, Loss: 0.4175742952975877\n",
      "Epoch 129, Loss: 0.41694621205652344\n",
      "Epoch 130, Loss: 0.4161064514444781\n",
      "Epoch 131, Loss: 0.41515221343628284\n",
      "Epoch 132, Loss: 0.4144242164244501\n",
      "Epoch 133, Loss: 0.41390864194795907\n",
      "Epoch 134, Loss: 0.4134166286675845\n",
      "Epoch 135, Loss: 0.41294634830076404\n",
      "Epoch 136, Loss: 0.4122453257421235\n",
      "Epoch 137, Loss: 0.4113477385247217\n",
      "Epoch 138, Loss: 0.41043815007919987\n",
      "Epoch 139, Loss: 0.40980123868790425\n",
      "Epoch 140, Loss: 0.4093902337537691\n",
      "Epoch 141, Loss: 0.4091097605821857\n",
      "Epoch 142, Loss: 0.4087888357687666\n",
      "Epoch 143, Loss: 0.4081223147772742\n",
      "Epoch 144, Loss: 0.40708478110663443\n",
      "Epoch 145, Loss: 0.4062201048781978\n",
      "Epoch 146, Loss: 0.40589974049364635\n",
      "Epoch 147, Loss: 0.40574750634377293\n",
      "Epoch 148, Loss: 0.40525678117833486\n",
      "Epoch 149, Loss: 0.4044816705136834\n",
      "Epoch 150, Loss: 0.40378781764541666\n",
      "Epoch 151, Loss: 0.40340614790948026\n",
      "Epoch 152, Loss: 0.40325757293779785\n",
      "Epoch 153, Loss: 0.40305020059780045\n",
      "Epoch 154, Loss: 0.40264886564352903\n",
      "Epoch 155, Loss: 0.40197651964620773\n",
      "Epoch 156, Loss: 0.4012853720038632\n",
      "Epoch 157, Loss: 0.4008678476571624\n",
      "Epoch 158, Loss: 0.40068341226594567\n",
      "Epoch 159, Loss: 0.4005491361634203\n",
      "Epoch 160, Loss: 0.40022011824768855\n",
      "Epoch 161, Loss: 0.3996487513259343\n",
      "Epoch 162, Loss: 0.39899353423173933\n",
      "Epoch 163, Loss: 0.39860088140133737\n",
      "Epoch 164, Loss: 0.39842755174372024\n",
      "Epoch 165, Loss: 0.39835641073203965\n",
      "Epoch 166, Loss: 0.3982440815609749\n",
      "Epoch 167, Loss: 0.39785008980315073\n",
      "Epoch 168, Loss: 0.39717699260604417\n",
      "Epoch 169, Loss: 0.3964641359171531\n",
      "Epoch 170, Loss: 0.39595833067981123\n",
      "Epoch 171, Loss: 0.3957291913649647\n",
      "Epoch 172, Loss: 0.39569177940800926\n",
      "Epoch 173, Loss: 0.39575116241583175\n",
      "Epoch 174, Loss: 0.39558773410645665\n",
      "Epoch 175, Loss: 0.3951455234807878\n",
      "Epoch 176, Loss: 0.3943338750262878\n",
      "Epoch 177, Loss: 0.3936921629737803\n",
      "Epoch 178, Loss: 0.3934080357081898\n",
      "Epoch 179, Loss: 0.39334392346791774\n",
      "Epoch 180, Loss: 0.39337669114730284\n",
      "Epoch 181, Loss: 0.39325136370461833\n",
      "Epoch 182, Loss: 0.3928769810268888\n",
      "Epoch 183, Loss: 0.3923526135183681\n",
      "Epoch 184, Loss: 0.39184374467116695\n",
      "Epoch 185, Loss: 0.391394391517923\n",
      "Epoch 186, Loss: 0.39123196176378594\n",
      "Epoch 187, Loss: 0.39119234845566353\n",
      "Epoch 188, Loss: 0.39111417658366426\n",
      "Epoch 189, Loss: 0.39110912839896916\n",
      "Epoch 190, Loss: 0.39097114485296164\n",
      "Epoch 191, Loss: 0.3907284980991264\n",
      "Epoch 192, Loss: 0.3902252249652117\n",
      "Epoch 193, Loss: 0.38969738492687844\n",
      "Epoch 194, Loss: 0.389210524225162\n",
      "Epoch 195, Loss: 0.38901401202307995\n",
      "Epoch 196, Loss: 0.3890312105641976\n",
      "Epoch 197, Loss: 0.3890558962280663\n",
      "Epoch 198, Loss: 0.38924595594173517\n",
      "Epoch 199, Loss: 0.3894225687266382\n",
      "Epoch 200, Loss: 0.38922225858683523\n",
      "Epoch 201, Loss: 0.38831805893255894\n",
      "Epoch 202, Loss: 0.38748595689122783\n",
      "Epoch 203, Loss: 0.38718984789440486\n",
      "Epoch 204, Loss: 0.3873873046848412\n",
      "Epoch 205, Loss: 0.38765207044692346\n",
      "Epoch 206, Loss: 0.3875240264642623\n",
      "Epoch 207, Loss: 0.38702655834054045\n",
      "Epoch 208, Loss: 0.3861928697266146\n",
      "Epoch 209, Loss: 0.3856271499808796\n",
      "Epoch 210, Loss: 0.3854781973755372\n",
      "Epoch 211, Loss: 0.3856024766771231\n",
      "Epoch 212, Loss: 0.3858031792045464\n",
      "Epoch 213, Loss: 0.3857036909377791\n",
      "Epoch 214, Loss: 0.3854294680282294\n",
      "Epoch 215, Loss: 0.3848438280285947\n",
      "Epoch 216, Loss: 0.3842188052580345\n",
      "Epoch 217, Loss: 0.38382821696268876\n",
      "Epoch 218, Loss: 0.38367835236497455\n",
      "Epoch 219, Loss: 0.38363543437391595\n",
      "Epoch 220, Loss: 0.3837183336308023\n",
      "Epoch 221, Loss: 0.3841901241527504\n",
      "Epoch 222, Loss: 0.3848229186491018\n",
      "Epoch 223, Loss: 0.3852510633472519\n",
      "Epoch 224, Loss: 0.3841367510417355\n",
      "Epoch 225, Loss: 0.3826171025991224\n",
      "Epoch 226, Loss: 0.382024323414299\n",
      "Epoch 227, Loss: 0.3825983499482423\n",
      "Epoch 228, Loss: 0.38293824758031764\n",
      "Epoch 229, Loss: 0.3824554452004029\n",
      "Epoch 230, Loss: 0.3816426756383023\n",
      "Epoch 231, Loss: 0.3810237627566356\n",
      "Epoch 232, Loss: 0.3809851414318767\n",
      "Epoch 233, Loss: 0.38130447592590594\n",
      "Epoch 234, Loss: 0.38146419917870494\n",
      "Epoch 235, Loss: 0.3812785849251803\n",
      "Epoch 236, Loss: 0.38076863308283887\n",
      "Epoch 237, Loss: 0.3801631138531178\n",
      "Epoch 238, Loss: 0.3795898994934496\n",
      "Epoch 239, Loss: 0.3793447650883587\n",
      "Epoch 240, Loss: 0.3795434568663548\n",
      "Epoch 241, Loss: 0.3797680600576175\n",
      "Epoch 242, Loss: 0.37993854810090416\n",
      "Epoch 243, Loss: 0.38051464422821124\n",
      "Epoch 244, Loss: 0.38069941756276815\n",
      "Epoch 245, Loss: 0.3795639700544694\n",
      "Epoch 246, Loss: 0.3781978828557013\n",
      "Epoch 247, Loss: 0.3776206396609434\n",
      "Epoch 248, Loss: 0.37823785248517505\n",
      "Epoch 249, Loss: 0.3790627775639385\n",
      "Epoch 250, Loss: 0.37895190563626224\n",
      "Epoch 251, Loss: 0.3776703568247693\n",
      "Epoch 252, Loss: 0.37644659609178455\n",
      "Epoch 253, Loss: 0.3761364683480079\n",
      "Epoch 254, Loss: 0.3764352947666431\n",
      "Epoch 255, Loss: 0.37670526607752586\n",
      "Epoch 256, Loss: 0.37666976239963385\n",
      "Epoch 257, Loss: 0.37622933746074333\n",
      "Epoch 258, Loss: 0.3756895282495783\n",
      "Epoch 259, Loss: 0.3747562967602293\n",
      "Epoch 260, Loss: 0.37405871431606924\n",
      "Epoch 261, Loss: 0.37376488496490173\n",
      "Epoch 262, Loss: 0.3737033839163665\n",
      "Epoch 263, Loss: 0.37408801285781246\n",
      "Epoch 264, Loss: 0.3758425783484969\n",
      "Epoch 265, Loss: 0.3784566354993141\n",
      "Epoch 266, Loss: 0.37784681964170336\n",
      "Epoch 267, Loss: 0.37458040684301874\n",
      "Epoch 268, Loss: 0.37195867831165486\n",
      "Epoch 269, Loss: 0.3735634387909031\n",
      "Epoch 270, Loss: 0.3757343651595499\n",
      "Epoch 271, Loss: 0.3727997765364407\n",
      "Epoch 272, Loss: 0.3707787632527254\n",
      "Epoch 273, Loss: 0.3713814272868463\n",
      "Epoch 274, Loss: 0.3728185823940426\n",
      "Epoch 275, Loss: 0.3726837427966101\n",
      "Epoch 276, Loss: 0.3699343186796105\n",
      "Epoch 277, Loss: 0.36923497119581167\n",
      "Epoch 278, Loss: 0.37040190201002193\n",
      "Epoch 279, Loss: 0.3698208913761702\n",
      "Epoch 280, Loss: 0.36895636344583405\n",
      "Epoch 281, Loss: 0.3680922946747331\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2680627179314869\n",
      "Test R^2 score: 0.21369346462191624\n",
      "Num of epochs: 282\n",
      "Epoch 1, Loss: 0.5595478099938647\n",
      "Epoch 2, Loss: 0.5586002322801188\n",
      "Epoch 3, Loss: 0.557813325982858\n",
      "Epoch 4, Loss: 0.5571919705590808\n",
      "Epoch 5, Loss: 0.5567309925276044\n",
      "Epoch 6, Loss: 0.556422435093386\n",
      "Epoch 7, Loss: 0.5562509075971764\n",
      "Epoch 8, Loss: 0.5561918624756569\n",
      "Epoch 9, Loss: 0.5562075352264987\n",
      "Epoch 10, Loss: 0.5562631230467209\n",
      "Epoch 11, Loss: 0.5563239284207641\n",
      "Epoch 12, Loss: 0.5563675595473562\n",
      "Epoch 13, Loss: 0.5563813258102649\n",
      "Epoch 14, Loss: 0.5563613994361325\n",
      "Epoch 15, Loss: 0.5563104553802223\n",
      "Epoch 16, Loss: 0.556235530750807\n",
      "Epoch 17, Loss: 0.5561444396678922\n",
      "Epoch 18, Loss: 0.5560439274573885\n",
      "Epoch 19, Loss: 0.5559389208925046\n",
      "Epoch 20, Loss: 0.5558318838370362\n",
      "Epoch 21, Loss: 0.5557223592792311\n",
      "Epoch 22, Loss: 0.5556070201268927\n",
      "Epoch 23, Loss: 0.5554805512925068\n",
      "Epoch 24, Loss: 0.5553370956873134\n",
      "Epoch 25, Loss: 0.5551695273926979\n",
      "Epoch 26, Loss: 0.5549716490300309\n",
      "Epoch 27, Loss: 0.5547377335273985\n",
      "Epoch 28, Loss: 0.5544641878019588\n",
      "Epoch 29, Loss: 0.5541464087242115\n",
      "Epoch 30, Loss: 0.5537781313000099\n",
      "Epoch 31, Loss: 0.553352307095832\n",
      "Epoch 32, Loss: 0.5528433594573187\n",
      "Epoch 33, Loss: 0.5522182737539134\n",
      "Epoch 34, Loss: 0.551442878438365\n",
      "Epoch 35, Loss: 0.5505105834795919\n",
      "Epoch 36, Loss: 0.5493968311351045\n",
      "Epoch 37, Loss: 0.5480585098391063\n",
      "Epoch 38, Loss: 0.5464416421757042\n",
      "Epoch 39, Loss: 0.5444795734507873\n",
      "Epoch 40, Loss: 0.5420649849056087\n",
      "Epoch 41, Loss: 0.5392117501011486\n",
      "Epoch 42, Loss: 0.5359689708845159\n",
      "Epoch 43, Loss: 0.5323347069297193\n",
      "Epoch 44, Loss: 0.5282372428754583\n",
      "Epoch 45, Loss: 0.5235700012576778\n",
      "Epoch 46, Loss: 0.5184412255593068\n",
      "Epoch 47, Loss: 0.5131032428937847\n",
      "Epoch 48, Loss: 0.5082887616967164\n",
      "Epoch 49, Loss: 0.5047966239749807\n",
      "Epoch 50, Loss: 0.5026901711783415\n",
      "Epoch 51, Loss: 0.49992602516355733\n",
      "Epoch 52, Loss: 0.495928398870886\n",
      "Epoch 53, Loss: 0.49170441610549914\n",
      "Epoch 54, Loss: 0.48862533652664114\n",
      "Epoch 55, Loss: 0.4865661559460637\n",
      "Epoch 56, Loss: 0.4846949904728168\n",
      "Epoch 57, Loss: 0.4823640487546785\n",
      "Epoch 58, Loss: 0.47951303968907594\n",
      "Epoch 59, Loss: 0.47641073217939006\n",
      "Epoch 60, Loss: 0.47340803023168593\n",
      "Epoch 61, Loss: 0.4712273934808223\n",
      "Epoch 62, Loss: 0.47047179619883944\n",
      "Epoch 63, Loss: 0.4706128773894734\n",
      "Epoch 64, Loss: 0.47006332475599766\n",
      "Epoch 65, Loss: 0.468269928829388\n",
      "Epoch 66, Loss: 0.46628724693449164\n",
      "Epoch 67, Loss: 0.46481948276294854\n",
      "Epoch 68, Loss: 0.46408347458111465\n",
      "Epoch 69, Loss: 0.46376590626935155\n",
      "Epoch 70, Loss: 0.463499336953085\n",
      "Epoch 71, Loss: 0.46292851288977754\n",
      "Epoch 72, Loss: 0.4620039128668337\n",
      "Epoch 73, Loss: 0.46093145463502866\n",
      "Epoch 74, Loss: 0.45989555655529063\n",
      "Epoch 75, Loss: 0.45911869761988666\n",
      "Epoch 76, Loss: 0.4586014306694087\n",
      "Epoch 77, Loss: 0.45802014299724864\n",
      "Epoch 78, Loss: 0.4572048672593057\n",
      "Epoch 79, Loss: 0.4563132294514605\n",
      "Epoch 80, Loss: 0.45551505008878834\n",
      "Epoch 81, Loss: 0.45494496767267056\n",
      "Epoch 82, Loss: 0.4545580630558593\n",
      "Epoch 83, Loss: 0.4541986341191763\n",
      "Epoch 84, Loss: 0.45373899690827824\n",
      "Epoch 85, Loss: 0.45318511038021175\n",
      "Epoch 86, Loss: 0.45259775531062985\n",
      "Epoch 87, Loss: 0.45202463650867886\n",
      "Epoch 88, Loss: 0.45146072521142344\n",
      "Epoch 89, Loss: 0.45089619128115455\n",
      "Epoch 90, Loss: 0.4503430271059497\n",
      "Epoch 91, Loss: 0.4498289028048238\n",
      "Epoch 92, Loss: 0.44931566602732576\n",
      "Epoch 93, Loss: 0.4487460261357568\n",
      "Epoch 94, Loss: 0.448140251187443\n",
      "Epoch 95, Loss: 0.4475421467172276\n",
      "Epoch 96, Loss: 0.4469629287911408\n",
      "Epoch 97, Loss: 0.4463752813549325\n",
      "Epoch 98, Loss: 0.44575831199487104\n",
      "Epoch 99, Loss: 0.4451302941984194\n",
      "Epoch 100, Loss: 0.44450812723799094\n",
      "Epoch 101, Loss: 0.44386714477055433\n",
      "Epoch 102, Loss: 0.4432313540980343\n",
      "Epoch 103, Loss: 0.4425744153344553\n",
      "Epoch 104, Loss: 0.4419461046335279\n",
      "Epoch 105, Loss: 0.4412984463191306\n",
      "Epoch 106, Loss: 0.4406309830820761\n",
      "Epoch 107, Loss: 0.4399544971139974\n",
      "Epoch 108, Loss: 0.43929437101011076\n",
      "Epoch 109, Loss: 0.43861470244792705\n",
      "Epoch 110, Loss: 0.43792599986892583\n",
      "Epoch 111, Loss: 0.43720661271522365\n",
      "Epoch 112, Loss: 0.4364970495795026\n",
      "Epoch 113, Loss: 0.4357755599500157\n",
      "Epoch 114, Loss: 0.43509604552932735\n",
      "Epoch 115, Loss: 0.4344071328332754\n",
      "Epoch 116, Loss: 0.43372006337747354\n",
      "Epoch 117, Loss: 0.4330556468842542\n",
      "Epoch 118, Loss: 0.43240955958967964\n",
      "Epoch 119, Loss: 0.43176611202528514\n",
      "Epoch 120, Loss: 0.4311434441379149\n",
      "Epoch 121, Loss: 0.43054666454439483\n",
      "Epoch 122, Loss: 0.42994425645175594\n",
      "Epoch 123, Loss: 0.4293444217526974\n",
      "Epoch 124, Loss: 0.4287405851014406\n",
      "Epoch 125, Loss: 0.42813474825042447\n",
      "Epoch 126, Loss: 0.4275306146657553\n",
      "Epoch 127, Loss: 0.42692712702915175\n",
      "Epoch 128, Loss: 0.42633028242010274\n",
      "Epoch 129, Loss: 0.4257556312623178\n",
      "Epoch 130, Loss: 0.42527555480413143\n",
      "Epoch 131, Loss: 0.42522246765139826\n",
      "Epoch 132, Loss: 0.4258559975064137\n",
      "Epoch 133, Loss: 0.42366879188615836\n",
      "Epoch 134, Loss: 0.42401739368322167\n",
      "Epoch 135, Loss: 0.4237708830962416\n",
      "Epoch 136, Loss: 0.4223300810537888\n",
      "Epoch 137, Loss: 0.4229340858192011\n",
      "Epoch 138, Loss: 0.421019269057144\n",
      "Epoch 139, Loss: 0.42152840894281407\n",
      "Epoch 140, Loss: 0.4199727759450376\n",
      "Epoch 141, Loss: 0.42049269801863426\n",
      "Epoch 142, Loss: 0.4191031525455761\n",
      "Epoch 143, Loss: 0.4190776944801654\n",
      "Epoch 144, Loss: 0.4180976455020004\n",
      "Epoch 145, Loss: 0.41768279944912495\n",
      "Epoch 146, Loss: 0.4172336138552732\n",
      "Epoch 147, Loss: 0.4163305675444247\n",
      "Epoch 148, Loss: 0.4162741023752213\n",
      "Epoch 149, Loss: 0.41510434703113014\n",
      "Epoch 150, Loss: 0.41501445024105144\n",
      "Epoch 151, Loss: 0.4141217315342195\n",
      "Epoch 152, Loss: 0.4136447958867975\n",
      "Epoch 153, Loss: 0.4132741584962642\n",
      "Epoch 154, Loss: 0.4123476975495228\n",
      "Epoch 155, Loss: 0.41222768594904485\n",
      "Epoch 156, Loss: 0.4114699985765942\n",
      "Epoch 157, Loss: 0.4107280015876506\n",
      "Epoch 158, Loss: 0.4105546378899865\n",
      "Epoch 159, Loss: 0.40974371008732197\n",
      "Epoch 160, Loss: 0.4089968689446581\n",
      "Epoch 161, Loss: 0.4087636102224504\n",
      "Epoch 162, Loss: 0.40806312533059147\n",
      "Epoch 163, Loss: 0.4071700974066271\n",
      "Epoch 164, Loss: 0.40684676355103927\n",
      "Epoch 165, Loss: 0.4064940673094904\n",
      "Epoch 166, Loss: 0.4055101921056554\n",
      "Epoch 167, Loss: 0.4047953900008752\n",
      "Epoch 168, Loss: 0.40449093570266864\n",
      "Epoch 169, Loss: 0.4040979458041845\n",
      "Epoch 170, Loss: 0.4035656531489739\n",
      "Epoch 171, Loss: 0.40260476839810994\n",
      "Epoch 172, Loss: 0.40189594051093425\n",
      "Epoch 173, Loss: 0.40148508238484215\n",
      "Epoch 174, Loss: 0.401289753742007\n",
      "Epoch 175, Loss: 0.40140691036230924\n",
      "Epoch 176, Loss: 0.4008384433263323\n",
      "Epoch 177, Loss: 0.4000963944277187\n",
      "Epoch 178, Loss: 0.3987090550450454\n",
      "Epoch 179, Loss: 0.3981364739889057\n",
      "Epoch 180, Loss: 0.39824540986782153\n",
      "Epoch 181, Loss: 0.3979977817976781\n",
      "Epoch 182, Loss: 0.39726543070170434\n",
      "Epoch 183, Loss: 0.396031689719696\n",
      "Epoch 184, Loss: 0.3954130459503456\n",
      "Epoch 185, Loss: 0.395405546553883\n",
      "Epoch 186, Loss: 0.39542095973207025\n",
      "Epoch 187, Loss: 0.39526951522230724\n",
      "Epoch 188, Loss: 0.39393046875479343\n",
      "Epoch 189, Loss: 0.39287231581666404\n",
      "Epoch 190, Loss: 0.3924066539184212\n",
      "Epoch 191, Loss: 0.3924330827744183\n",
      "Epoch 192, Loss: 0.39269402913857454\n",
      "Epoch 193, Loss: 0.3921220702042722\n",
      "Epoch 194, Loss: 0.39143434602629223\n",
      "Epoch 195, Loss: 0.38999990038381427\n",
      "Epoch 196, Loss: 0.3894360568210074\n",
      "Epoch 197, Loss: 0.38970608392375766\n",
      "Epoch 198, Loss: 0.3898702769150862\n",
      "Epoch 199, Loss: 0.3899441507588252\n",
      "Epoch 200, Loss: 0.3881252796829371\n",
      "Epoch 201, Loss: 0.38702070604545286\n",
      "Epoch 202, Loss: 0.38689041180949685\n",
      "Epoch 203, Loss: 0.38713904381622455\n",
      "Epoch 204, Loss: 0.3873754570383759\n",
      "Epoch 205, Loss: 0.3858272024220953\n",
      "Epoch 206, Loss: 0.38479101029515456\n",
      "Epoch 207, Loss: 0.3844365101731603\n",
      "Epoch 208, Loss: 0.3845705418854858\n",
      "Epoch 209, Loss: 0.384919924706887\n",
      "Epoch 210, Loss: 0.3840803831575767\n",
      "Epoch 211, Loss: 0.3831180015223469\n",
      "Epoch 212, Loss: 0.3820944103928813\n",
      "Epoch 213, Loss: 0.38165169488007517\n",
      "Epoch 214, Loss: 0.3815412628237234\n",
      "Epoch 215, Loss: 0.38137936429752695\n",
      "Epoch 216, Loss: 0.3816303958517606\n",
      "Epoch 217, Loss: 0.38080256111702254\n",
      "Epoch 218, Loss: 0.3801137619326778\n",
      "Epoch 219, Loss: 0.3792780399065658\n",
      "Epoch 220, Loss: 0.378571864183129\n",
      "Epoch 221, Loss: 0.37791255547384267\n",
      "Epoch 222, Loss: 0.3774606519680449\n",
      "Epoch 223, Loss: 0.3772790320204919\n",
      "Epoch 224, Loss: 0.37736301175509607\n",
      "Epoch 225, Loss: 0.3782912897529045\n",
      "Epoch 226, Loss: 0.3783433803759142\n",
      "Epoch 227, Loss: 0.3789589835369844\n",
      "Epoch 228, Loss: 0.3755326461873968\n",
      "Epoch 229, Loss: 0.3745292052721236\n",
      "Epoch 230, Loss: 0.37574771009725855\n",
      "Epoch 231, Loss: 0.37517408462832674\n",
      "Epoch 232, Loss: 0.37416571956138\n",
      "Epoch 233, Loss: 0.3725340148897417\n",
      "Epoch 234, Loss: 0.37230398694945965\n",
      "Epoch 235, Loss: 0.37298303826861895\n",
      "Epoch 236, Loss: 0.37244444532043197\n",
      "Epoch 237, Loss: 0.3719316559596704\n",
      "Epoch 238, Loss: 0.37037605351926817\n",
      "Epoch 239, Loss: 0.3698113015384154\n",
      "Epoch 240, Loss: 0.369525446453048\n",
      "Epoch 241, Loss: 0.36919931419511376\n",
      "Epoch 242, Loss: 0.36969954950683365\n",
      "Epoch 243, Loss: 0.3688001121802687\n",
      "Epoch 244, Loss: 0.36920272466273063\n",
      "Epoch 245, Loss: 0.36845129733018356\n",
      "Epoch 246, Loss: 0.3675895883716518\n",
      "Epoch 247, Loss: 0.36678978503832754\n",
      "Epoch 248, Loss: 0.36637250260901355\n",
      "Epoch 249, Loss: 0.3649638392878037\n",
      "Epoch 250, Loss: 0.364702275719693\n",
      "Epoch 251, Loss: 0.36408871977859736\n",
      "Epoch 252, Loss: 0.36395600934843364\n",
      "Epoch 253, Loss: 0.3636730911119822\n",
      "Epoch 254, Loss: 0.36625056751715007\n",
      "Epoch 255, Loss: 0.3672675390463466\n",
      "Epoch 256, Loss: 0.36847087107169135\n",
      "Epoch 257, Loss: 0.3626118717545711\n",
      "Epoch 258, Loss: 0.36058144615466475\n",
      "Epoch 259, Loss: 0.3630254521707777\n",
      "Epoch 260, Loss: 0.3639819862498584\n",
      "Epoch 261, Loss: 0.35981131065798927\n",
      "Epoch 262, Loss: 0.35744105219856037\n",
      "Epoch 263, Loss: 0.35858810353872095\n",
      "Epoch 264, Loss: 0.35933730715575524\n",
      "Epoch 265, Loss: 0.35737305187856516\n",
      "Epoch 266, Loss: 0.35656602461574816\n",
      "Epoch 267, Loss: 0.35440856956245576\n",
      "Epoch 268, Loss: 0.3544234111893695\n",
      "Epoch 269, Loss: 0.35597601527282186\n",
      "Epoch 270, Loss: 0.35691902350081695\n",
      "Epoch 271, Loss: 0.359822471509637\n",
      "Epoch 272, Loss: 0.3568349929070459\n",
      "Epoch 273, Loss: 0.35275446896861673\n",
      "Epoch 274, Loss: 0.3511903276358499\n",
      "Epoch 275, Loss: 0.35247041239914206\n",
      "Epoch 276, Loss: 0.35570847109927156\n",
      "Epoch 277, Loss: 0.3543399452350374\n",
      "Epoch 278, Loss: 0.3513707167663937\n",
      "Epoch 279, Loss: 0.3485729903499102\n",
      "Epoch 280, Loss: 0.34941286286200907\n",
      "Epoch 281, Loss: 0.3523270770101378\n",
      "Epoch 282, Loss: 0.3517040603464596\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.25442494223967066\n",
      "Test R^2 score: 0.2930113556625229\n",
      "Num of epochs: 283\n",
      "Epoch 1, Loss: 0.5606521348117038\n",
      "Epoch 2, Loss: 0.5597655004167119\n",
      "Epoch 3, Loss: 0.5589874587383821\n",
      "Epoch 4, Loss: 0.5582890246255922\n",
      "Epoch 5, Loss: 0.5576761351524713\n",
      "Epoch 6, Loss: 0.5571545286580454\n",
      "Epoch 7, Loss: 0.5567451780407595\n",
      "Epoch 8, Loss: 0.5564366284727478\n",
      "Epoch 9, Loss: 0.5562075620171477\n",
      "Epoch 10, Loss: 0.5560651514899748\n",
      "Epoch 11, Loss: 0.5559948035776062\n",
      "Epoch 12, Loss: 0.5559662062817426\n",
      "Epoch 13, Loss: 0.5559493741959368\n",
      "Epoch 14, Loss: 0.5559196487742862\n",
      "Epoch 15, Loss: 0.5558488267124232\n",
      "Epoch 16, Loss: 0.5557173450312562\n",
      "Epoch 17, Loss: 0.5555082079129066\n",
      "Epoch 18, Loss: 0.5552039629947313\n",
      "Epoch 19, Loss: 0.5547900038018723\n",
      "Epoch 20, Loss: 0.5542509483360261\n",
      "Epoch 21, Loss: 0.5535720839474574\n",
      "Epoch 22, Loss: 0.5527342671640244\n",
      "Epoch 23, Loss: 0.5517264568230285\n",
      "Epoch 24, Loss: 0.5505202736997572\n",
      "Epoch 25, Loss: 0.549056416338336\n",
      "Epoch 26, Loss: 0.5472854436407569\n",
      "Epoch 27, Loss: 0.5451404037643518\n",
      "Epoch 28, Loss: 0.5425464717016574\n",
      "Epoch 29, Loss: 0.5394364041575966\n",
      "Epoch 30, Loss: 0.5357738745563607\n",
      "Epoch 31, Loss: 0.5315890072016795\n",
      "Epoch 32, Loss: 0.5271190305792022\n",
      "Epoch 33, Loss: 0.5229562853309897\n",
      "Epoch 34, Loss: 0.520121647654142\n",
      "Epoch 35, Loss: 0.5188888651190722\n",
      "Epoch 36, Loss: 0.5172565252796839\n",
      "Epoch 37, Loss: 0.5139454740295133\n",
      "Epoch 38, Loss: 0.5101386857331683\n",
      "Epoch 39, Loss: 0.5072605361107458\n",
      "Epoch 40, Loss: 0.5055683432901702\n",
      "Epoch 41, Loss: 0.5043531993612084\n",
      "Epoch 42, Loss: 0.5028445273584127\n",
      "Epoch 43, Loss: 0.5007044478869331\n",
      "Epoch 44, Loss: 0.498103463941039\n",
      "Epoch 45, Loss: 0.4955362356151259\n",
      "Epoch 46, Loss: 0.4935785194986397\n",
      "Epoch 47, Loss: 0.49232250965611873\n",
      "Epoch 48, Loss: 0.49104734089221425\n",
      "Epoch 49, Loss: 0.48915405086850855\n",
      "Epoch 50, Loss: 0.48702918695056324\n",
      "Epoch 51, Loss: 0.48528118889802313\n",
      "Epoch 52, Loss: 0.4839468263310985\n",
      "Epoch 53, Loss: 0.4826726223190038\n",
      "Epoch 54, Loss: 0.4811015884885807\n",
      "Epoch 55, Loss: 0.47928150155455757\n",
      "Epoch 56, Loss: 0.47760313575436464\n",
      "Epoch 57, Loss: 0.47627399654457925\n",
      "Epoch 58, Loss: 0.47508909368689084\n",
      "Epoch 59, Loss: 0.47370703990581975\n",
      "Epoch 60, Loss: 0.4721469184104333\n",
      "Epoch 61, Loss: 0.4707946213558809\n",
      "Epoch 62, Loss: 0.46970782966296876\n",
      "Epoch 63, Loss: 0.4686634460647635\n",
      "Epoch 64, Loss: 0.46746738113497693\n",
      "Epoch 65, Loss: 0.4662414342640568\n",
      "Epoch 66, Loss: 0.4651492581468292\n",
      "Epoch 67, Loss: 0.4641373179070223\n",
      "Epoch 68, Loss: 0.4630144975598493\n",
      "Epoch 69, Loss: 0.46177356672119796\n",
      "Epoch 70, Loss: 0.46061206902996216\n",
      "Epoch 71, Loss: 0.4595705063961737\n",
      "Epoch 72, Loss: 0.4584926974787268\n",
      "Epoch 73, Loss: 0.4573526963745935\n",
      "Epoch 74, Loss: 0.4563146662935636\n",
      "Epoch 75, Loss: 0.45540703605678773\n",
      "Epoch 76, Loss: 0.45446100263242145\n",
      "Epoch 77, Loss: 0.4535171357621716\n",
      "Epoch 78, Loss: 0.4526889281218103\n",
      "Epoch 79, Loss: 0.4518760536308193\n",
      "Epoch 80, Loss: 0.45101711376690495\n",
      "Epoch 81, Loss: 0.4502272025706501\n",
      "Epoch 82, Loss: 0.44947920173417977\n",
      "Epoch 83, Loss: 0.44867378017918425\n",
      "Epoch 84, Loss: 0.44788698903911395\n",
      "Epoch 85, Loss: 0.44710919505663443\n",
      "Epoch 86, Loss: 0.44625552195383583\n",
      "Epoch 87, Loss: 0.4453983056905507\n",
      "Epoch 88, Loss: 0.44454863770709213\n",
      "Epoch 89, Loss: 0.44363223514584815\n",
      "Epoch 90, Loss: 0.4426914174457117\n",
      "Epoch 91, Loss: 0.4417016214207967\n",
      "Epoch 92, Loss: 0.4407216730324487\n",
      "Epoch 93, Loss: 0.4398277042639916\n",
      "Epoch 94, Loss: 0.43890877812256\n",
      "Epoch 95, Loss: 0.4380564386756949\n",
      "Epoch 96, Loss: 0.4371860944767596\n",
      "Epoch 97, Loss: 0.43634444285644214\n",
      "Epoch 98, Loss: 0.43547211420233156\n",
      "Epoch 99, Loss: 0.43464488557619185\n",
      "Epoch 100, Loss: 0.43381235265406426\n",
      "Epoch 101, Loss: 0.4329991258464826\n",
      "Epoch 102, Loss: 0.43219919441272514\n",
      "Epoch 103, Loss: 0.4314071058121827\n",
      "Epoch 104, Loss: 0.4305432900695014\n",
      "Epoch 105, Loss: 0.42968297435804736\n",
      "Epoch 106, Loss: 0.42885111122565567\n",
      "Epoch 107, Loss: 0.42802052093157766\n",
      "Epoch 108, Loss: 0.4271970012252814\n",
      "Epoch 109, Loss: 0.4263740577441305\n",
      "Epoch 110, Loss: 0.4255529193928632\n",
      "Epoch 111, Loss: 0.42472373804987995\n",
      "Epoch 112, Loss: 0.4239214956914515\n",
      "Epoch 113, Loss: 0.423154356908652\n",
      "Epoch 114, Loss: 0.4223888940707604\n",
      "Epoch 115, Loss: 0.42163328027610036\n",
      "Epoch 116, Loss: 0.4208764692268978\n",
      "Epoch 117, Loss: 0.4201667249231375\n",
      "Epoch 118, Loss: 0.4196134277216221\n",
      "Epoch 119, Loss: 0.4192339918484525\n",
      "Epoch 120, Loss: 0.4184241799420306\n",
      "Epoch 121, Loss: 0.4173174623517419\n",
      "Epoch 122, Loss: 0.4167685880777712\n",
      "Epoch 123, Loss: 0.4162115253675257\n",
      "Epoch 124, Loss: 0.4151870463717795\n",
      "Epoch 125, Loss: 0.414451776011552\n",
      "Epoch 126, Loss: 0.41399543147054235\n",
      "Epoch 127, Loss: 0.4132394888534003\n",
      "Epoch 128, Loss: 0.41233889800610773\n",
      "Epoch 129, Loss: 0.4118312602341542\n",
      "Epoch 130, Loss: 0.411475829062324\n",
      "Epoch 131, Loss: 0.4108479797558732\n",
      "Epoch 132, Loss: 0.41009244876728673\n",
      "Epoch 133, Loss: 0.40952968878013635\n",
      "Epoch 134, Loss: 0.40917775738609147\n",
      "Epoch 135, Loss: 0.4088399017987956\n",
      "Epoch 136, Loss: 0.4082055160233409\n",
      "Epoch 137, Loss: 0.4075176013175923\n",
      "Epoch 138, Loss: 0.4069079426498135\n",
      "Epoch 139, Loss: 0.4064702207383701\n",
      "Epoch 140, Loss: 0.4061596109630261\n",
      "Epoch 141, Loss: 0.4058768686263876\n",
      "Epoch 142, Loss: 0.40553584049081554\n",
      "Epoch 143, Loss: 0.40496529504052997\n",
      "Epoch 144, Loss: 0.40434935593103855\n",
      "Epoch 145, Loss: 0.4037789791738005\n",
      "Epoch 146, Loss: 0.4031897973317583\n",
      "Epoch 147, Loss: 0.4026505680001588\n",
      "Epoch 148, Loss: 0.4022492047676016\n",
      "Epoch 149, Loss: 0.4018157160623295\n",
      "Epoch 150, Loss: 0.40152130509378187\n",
      "Epoch 151, Loss: 0.4017253679036789\n",
      "Epoch 152, Loss: 0.40260134478423554\n",
      "Epoch 153, Loss: 0.4040018562484342\n",
      "Epoch 154, Loss: 0.4009605817030438\n",
      "Epoch 155, Loss: 0.40017150837899074\n",
      "Epoch 156, Loss: 0.4016661632634935\n",
      "Epoch 157, Loss: 0.39915463479543345\n",
      "Epoch 158, Loss: 0.399950073523836\n",
      "Epoch 159, Loss: 0.39969544886722075\n",
      "Epoch 160, Loss: 0.39811046118666504\n",
      "Epoch 161, Loss: 0.3993883940789356\n",
      "Epoch 162, Loss: 0.3978076144605423\n",
      "Epoch 163, Loss: 0.397412083878067\n",
      "Epoch 164, Loss: 0.39774883818681506\n",
      "Epoch 165, Loss: 0.39623438653961324\n",
      "Epoch 166, Loss: 0.3966372528744305\n",
      "Epoch 167, Loss: 0.3960709318852974\n",
      "Epoch 168, Loss: 0.3953589642022851\n",
      "Epoch 169, Loss: 0.3956643818965003\n",
      "Epoch 170, Loss: 0.3947769004590021\n",
      "Epoch 171, Loss: 0.3944711167237993\n",
      "Epoch 172, Loss: 0.39452396046164506\n",
      "Epoch 173, Loss: 0.3936821137293129\n",
      "Epoch 174, Loss: 0.39361346541846043\n",
      "Epoch 175, Loss: 0.3933992102415306\n",
      "Epoch 176, Loss: 0.3928183015441981\n",
      "Epoch 177, Loss: 0.39256540913651033\n",
      "Epoch 178, Loss: 0.3925602087990435\n",
      "Epoch 179, Loss: 0.3919166191791038\n",
      "Epoch 180, Loss: 0.39161659268956484\n",
      "Epoch 181, Loss: 0.39155283408324854\n",
      "Epoch 182, Loss: 0.39115966445640665\n",
      "Epoch 183, Loss: 0.3907426656887702\n",
      "Epoch 184, Loss: 0.39042009701573777\n",
      "Epoch 185, Loss: 0.3903352425686287\n",
      "Epoch 186, Loss: 0.39005017902270894\n",
      "Epoch 187, Loss: 0.3896743077459517\n",
      "Epoch 188, Loss: 0.3893238714029945\n",
      "Epoch 189, Loss: 0.38900721283553236\n",
      "Epoch 190, Loss: 0.388854899037439\n",
      "Epoch 191, Loss: 0.3886245238631587\n",
      "Epoch 192, Loss: 0.388292501275057\n",
      "Epoch 193, Loss: 0.38807095026912225\n",
      "Epoch 194, Loss: 0.38772711635407764\n",
      "Epoch 195, Loss: 0.3875849107803027\n",
      "Epoch 196, Loss: 0.3872482835843667\n",
      "Epoch 197, Loss: 0.3869404013082393\n",
      "Epoch 198, Loss: 0.3864563138177275\n",
      "Epoch 199, Loss: 0.38601420022608507\n",
      "Epoch 200, Loss: 0.3853736952290331\n",
      "Epoch 201, Loss: 0.3850368763553045\n",
      "Epoch 202, Loss: 0.3848422598645397\n",
      "Epoch 203, Loss: 0.38460837699393363\n",
      "Epoch 204, Loss: 0.38469286777770567\n",
      "Epoch 205, Loss: 0.3851308880052221\n",
      "Epoch 206, Loss: 0.3864274710116245\n",
      "Epoch 207, Loss: 0.3866849171644869\n",
      "Epoch 208, Loss: 0.3855107252803518\n",
      "Epoch 209, Loss: 0.3831355619608222\n",
      "Epoch 210, Loss: 0.3839698734436216\n",
      "Epoch 211, Loss: 0.38522120193118264\n",
      "Epoch 212, Loss: 0.3828801465113591\n",
      "Epoch 213, Loss: 0.3826594922764446\n",
      "Epoch 214, Loss: 0.38416122756770615\n",
      "Epoch 215, Loss: 0.38245885434468285\n",
      "Epoch 216, Loss: 0.3817484138258462\n",
      "Epoch 217, Loss: 0.3826156421452968\n",
      "Epoch 218, Loss: 0.3819669415851594\n",
      "Epoch 219, Loss: 0.38100172463725074\n",
      "Epoch 220, Loss: 0.38126881427931003\n",
      "Epoch 221, Loss: 0.38147550776869266\n",
      "Epoch 222, Loss: 0.3806994567043054\n",
      "Epoch 223, Loss: 0.3800184699011999\n",
      "Epoch 224, Loss: 0.3805550557656885\n",
      "Epoch 225, Loss: 0.3807005526657141\n",
      "Epoch 226, Loss: 0.3797349028960974\n",
      "Epoch 227, Loss: 0.3794682258112894\n",
      "Epoch 228, Loss: 0.3792898261911105\n",
      "Epoch 229, Loss: 0.37939891051682456\n",
      "Epoch 230, Loss: 0.3791080999031819\n",
      "Epoch 231, Loss: 0.378108748567517\n",
      "Epoch 232, Loss: 0.37825357127095277\n",
      "Epoch 233, Loss: 0.37842137489016464\n",
      "Epoch 234, Loss: 0.3778422843545642\n",
      "Epoch 235, Loss: 0.3778764357001678\n",
      "Epoch 236, Loss: 0.37718533493975576\n",
      "Epoch 237, Loss: 0.37666107881812333\n",
      "Epoch 238, Loss: 0.3772040801682674\n",
      "Epoch 239, Loss: 0.37653853787361236\n",
      "Epoch 240, Loss: 0.37583756292561277\n",
      "Epoch 241, Loss: 0.37606384453224867\n",
      "Epoch 242, Loss: 0.37556510308097274\n",
      "Epoch 243, Loss: 0.3748541985630156\n",
      "Epoch 244, Loss: 0.37470881760176145\n",
      "Epoch 245, Loss: 0.3746162676450583\n",
      "Epoch 246, Loss: 0.3745720527521775\n",
      "Epoch 247, Loss: 0.3753932440722952\n",
      "Epoch 248, Loss: 0.37822682136824787\n",
      "Epoch 249, Loss: 0.3787433824810887\n",
      "Epoch 250, Loss: 0.3771651467286918\n",
      "Epoch 251, Loss: 0.3727284215620779\n",
      "Epoch 252, Loss: 0.3757963070460107\n",
      "Epoch 253, Loss: 0.37783759126099564\n",
      "Epoch 254, Loss: 0.3730649494366176\n",
      "Epoch 255, Loss: 0.37527205612199976\n",
      "Epoch 256, Loss: 0.3748869526856972\n",
      "Epoch 257, Loss: 0.3740006681438843\n",
      "Epoch 258, Loss: 0.3721382099186484\n",
      "Epoch 259, Loss: 0.37517289308668245\n",
      "Epoch 260, Loss: 0.37023623924647325\n",
      "Epoch 261, Loss: 0.37241947881505116\n",
      "Epoch 262, Loss: 0.37102831213363185\n",
      "Epoch 263, Loss: 0.3703736194439385\n",
      "Epoch 264, Loss: 0.3697478331076143\n",
      "Epoch 265, Loss: 0.37004487229510674\n",
      "Epoch 266, Loss: 0.3688053647197789\n",
      "Epoch 267, Loss: 0.36811862736028955\n",
      "Epoch 268, Loss: 0.3687927382966522\n",
      "Epoch 269, Loss: 0.3670997717738449\n",
      "Epoch 270, Loss: 0.3678236584198354\n",
      "Epoch 271, Loss: 0.36705798035938525\n",
      "Epoch 272, Loss: 0.3662595386044178\n",
      "Epoch 273, Loss: 0.36673721136979387\n",
      "Epoch 274, Loss: 0.3648514601813769\n",
      "Epoch 275, Loss: 0.36511791636887136\n",
      "Epoch 276, Loss: 0.3649219870153707\n",
      "Epoch 277, Loss: 0.36367397205309515\n",
      "Epoch 278, Loss: 0.36413512835705053\n",
      "Epoch 279, Loss: 0.36379650451198264\n",
      "Epoch 280, Loss: 0.3638185813656361\n",
      "Epoch 281, Loss: 0.3653123945655377\n",
      "Epoch 282, Loss: 0.37053831595264175\n",
      "Epoch 283, Loss: 0.36878328334796345\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2507183089580517\n",
      "Test R^2 score: 0.31518044005101153\n",
      "Num of epochs: 284\n",
      "Epoch 1, Loss: 0.5623522935426587\n",
      "Epoch 2, Loss: 0.5610064971483001\n",
      "Epoch 3, Loss: 0.5598358269997733\n",
      "Epoch 4, Loss: 0.5588324510302103\n",
      "Epoch 5, Loss: 0.5580005563832315\n",
      "Epoch 6, Loss: 0.5573347883089519\n",
      "Epoch 7, Loss: 0.5568272060430913\n",
      "Epoch 8, Loss: 0.5564692986494688\n",
      "Epoch 9, Loss: 0.5562454427039518\n",
      "Epoch 10, Loss: 0.5561371249426728\n",
      "Epoch 11, Loss: 0.5561185027720643\n",
      "Epoch 12, Loss: 0.5561627126636433\n",
      "Epoch 13, Loss: 0.556241317209777\n",
      "Epoch 14, Loss: 0.5563279997326346\n",
      "Epoch 15, Loss: 0.5564005015932478\n",
      "Epoch 16, Loss: 0.5564415559009213\n",
      "Epoch 17, Loss: 0.5564408060777096\n",
      "Epoch 18, Loss: 0.5563950381693304\n",
      "Epoch 19, Loss: 0.5563060892950941\n",
      "Epoch 20, Loss: 0.5561771538000722\n",
      "Epoch 21, Loss: 0.5560117682885609\n",
      "Epoch 22, Loss: 0.555809927032428\n",
      "Epoch 23, Loss: 0.5555719121538452\n",
      "Epoch 24, Loss: 0.5553085718568751\n",
      "Epoch 25, Loss: 0.5550037610725602\n",
      "Epoch 26, Loss: 0.5546589427635256\n",
      "Epoch 27, Loss: 0.5542631003242986\n",
      "Epoch 28, Loss: 0.553802348131786\n",
      "Epoch 29, Loss: 0.5532866236445414\n",
      "Epoch 30, Loss: 0.55267818960656\n",
      "Epoch 31, Loss: 0.5519560871193269\n",
      "Epoch 32, Loss: 0.5511235194957468\n",
      "Epoch 33, Loss: 0.5501462915240243\n",
      "Epoch 34, Loss: 0.5489979274255511\n",
      "Epoch 35, Loss: 0.5476282926163106\n",
      "Epoch 36, Loss: 0.5459820132349531\n",
      "Epoch 37, Loss: 0.5439843757889077\n",
      "Epoch 38, Loss: 0.5415723944815058\n",
      "Epoch 39, Loss: 0.5386545047075555\n",
      "Epoch 40, Loss: 0.5351331107156034\n",
      "Epoch 41, Loss: 0.5309146495839253\n",
      "Epoch 42, Loss: 0.5260041352533741\n",
      "Epoch 43, Loss: 0.520500082849648\n",
      "Epoch 44, Loss: 0.5147438033343738\n",
      "Epoch 45, Loss: 0.5096012303486468\n",
      "Epoch 46, Loss: 0.5064974851028051\n",
      "Epoch 47, Loss: 0.5060134711903657\n",
      "Epoch 48, Loss: 0.5051248881324091\n",
      "Epoch 49, Loss: 0.5016891141423307\n",
      "Epoch 50, Loss: 0.49735592054503824\n",
      "Epoch 51, Loss: 0.4939456449472101\n",
      "Epoch 52, Loss: 0.491999211702258\n",
      "Epoch 53, Loss: 0.49080106953288305\n",
      "Epoch 54, Loss: 0.4894778124404989\n",
      "Epoch 55, Loss: 0.48762141085244765\n",
      "Epoch 56, Loss: 0.48525129545157775\n",
      "Epoch 57, Loss: 0.48256577727775213\n",
      "Epoch 58, Loss: 0.4800096660127537\n",
      "Epoch 59, Loss: 0.47814223065213735\n",
      "Epoch 60, Loss: 0.4770539985477968\n",
      "Epoch 61, Loss: 0.47613791015259627\n",
      "Epoch 62, Loss: 0.47464693964738414\n",
      "Epoch 63, Loss: 0.47267883814282746\n",
      "Epoch 64, Loss: 0.47083606662913363\n",
      "Epoch 65, Loss: 0.46953580476452655\n",
      "Epoch 66, Loss: 0.4687051433717268\n",
      "Epoch 67, Loss: 0.467831872782292\n",
      "Epoch 68, Loss: 0.4667071491660429\n",
      "Epoch 69, Loss: 0.4653431429742137\n",
      "Epoch 70, Loss: 0.4640461947726627\n",
      "Epoch 71, Loss: 0.46307704085190854\n",
      "Epoch 72, Loss: 0.46238653685673203\n",
      "Epoch 73, Loss: 0.46153367814541046\n",
      "Epoch 74, Loss: 0.46045056178037663\n",
      "Epoch 75, Loss: 0.45945927826462024\n",
      "Epoch 76, Loss: 0.4587295636554566\n",
      "Epoch 77, Loss: 0.4579786279160343\n",
      "Epoch 78, Loss: 0.45699070481649123\n",
      "Epoch 79, Loss: 0.4559837629236157\n",
      "Epoch 80, Loss: 0.455189916280346\n",
      "Epoch 81, Loss: 0.4545591776304332\n",
      "Epoch 82, Loss: 0.4538647434081151\n",
      "Epoch 83, Loss: 0.45307599822175787\n",
      "Epoch 84, Loss: 0.45235053009591614\n",
      "Epoch 85, Loss: 0.4517411772769432\n",
      "Epoch 86, Loss: 0.45110670667697317\n",
      "Epoch 87, Loss: 0.45038465047613896\n",
      "Epoch 88, Loss: 0.44964161748140613\n",
      "Epoch 89, Loss: 0.4489480737308992\n",
      "Epoch 90, Loss: 0.4482211770845239\n",
      "Epoch 91, Loss: 0.44742145072713074\n",
      "Epoch 92, Loss: 0.4466823122441979\n",
      "Epoch 93, Loss: 0.4459802239260964\n",
      "Epoch 94, Loss: 0.4452537363999736\n",
      "Epoch 95, Loss: 0.44455748683420215\n",
      "Epoch 96, Loss: 0.44390071472025355\n",
      "Epoch 97, Loss: 0.4432212849807892\n",
      "Epoch 98, Loss: 0.44251481669884085\n",
      "Epoch 99, Loss: 0.4418230536383955\n",
      "Epoch 100, Loss: 0.44111311302156514\n",
      "Epoch 101, Loss: 0.4404307024958856\n",
      "Epoch 102, Loss: 0.4397622610598156\n",
      "Epoch 103, Loss: 0.439056149365528\n",
      "Epoch 104, Loss: 0.43836591382232637\n",
      "Epoch 105, Loss: 0.4376670995128106\n",
      "Epoch 106, Loss: 0.4369468086668721\n",
      "Epoch 107, Loss: 0.4362346880392549\n",
      "Epoch 108, Loss: 0.4354972468955944\n",
      "Epoch 109, Loss: 0.43477911915363543\n",
      "Epoch 110, Loss: 0.4340120995127005\n",
      "Epoch 111, Loss: 0.43325386816500294\n",
      "Epoch 112, Loss: 0.4324635045414106\n",
      "Epoch 113, Loss: 0.43169428634224744\n",
      "Epoch 114, Loss: 0.43089046279655735\n",
      "Epoch 115, Loss: 0.4301169070463866\n",
      "Epoch 116, Loss: 0.42932916785313885\n",
      "Epoch 117, Loss: 0.42853865931037854\n",
      "Epoch 118, Loss: 0.4277463414856763\n",
      "Epoch 119, Loss: 0.4268926760922104\n",
      "Epoch 120, Loss: 0.4260643009462775\n",
      "Epoch 121, Loss: 0.4252202774449911\n",
      "Epoch 122, Loss: 0.42436351448775395\n",
      "Epoch 123, Loss: 0.4235017460299532\n",
      "Epoch 124, Loss: 0.4226576115838364\n",
      "Epoch 125, Loss: 0.4218455586933325\n",
      "Epoch 126, Loss: 0.4210627648838428\n",
      "Epoch 127, Loss: 0.42032438991704063\n",
      "Epoch 128, Loss: 0.41965083756728566\n",
      "Epoch 129, Loss: 0.41887683797881015\n",
      "Epoch 130, Loss: 0.418043718121136\n",
      "Epoch 131, Loss: 0.4172168099897795\n",
      "Epoch 132, Loss: 0.4165506817399663\n",
      "Epoch 133, Loss: 0.415919458440803\n",
      "Epoch 134, Loss: 0.4152276183015545\n",
      "Epoch 135, Loss: 0.414428549135876\n",
      "Epoch 136, Loss: 0.4136489926674408\n",
      "Epoch 137, Loss: 0.4130254931225109\n",
      "Epoch 138, Loss: 0.41244984524155504\n",
      "Epoch 139, Loss: 0.4118730852953757\n",
      "Epoch 140, Loss: 0.4110688365896226\n",
      "Epoch 141, Loss: 0.410301636859298\n",
      "Epoch 142, Loss: 0.40958821153436037\n",
      "Epoch 143, Loss: 0.40891838379328305\n",
      "Epoch 144, Loss: 0.40831807904393075\n",
      "Epoch 145, Loss: 0.40774477546146737\n",
      "Epoch 146, Loss: 0.4072893309302645\n",
      "Epoch 147, Loss: 0.4068608093716953\n",
      "Epoch 148, Loss: 0.40621641827214966\n",
      "Epoch 149, Loss: 0.4051816905398233\n",
      "Epoch 150, Loss: 0.4044610210883635\n",
      "Epoch 151, Loss: 0.40422284098038047\n",
      "Epoch 152, Loss: 0.40385737464672977\n",
      "Epoch 153, Loss: 0.4030318995468538\n",
      "Epoch 154, Loss: 0.4021557489057504\n",
      "Epoch 155, Loss: 0.401652770527521\n",
      "Epoch 156, Loss: 0.4014055182723893\n",
      "Epoch 157, Loss: 0.4007970840270934\n",
      "Epoch 158, Loss: 0.39997272547479223\n",
      "Epoch 159, Loss: 0.3992672489515256\n",
      "Epoch 160, Loss: 0.39877267838804864\n",
      "Epoch 161, Loss: 0.3984837037766538\n",
      "Epoch 162, Loss: 0.3980142551941108\n",
      "Epoch 163, Loss: 0.39743913595406083\n",
      "Epoch 164, Loss: 0.3967340557005008\n",
      "Epoch 165, Loss: 0.39607333971516023\n",
      "Epoch 166, Loss: 0.39554460142485415\n",
      "Epoch 167, Loss: 0.3951571193095729\n",
      "Epoch 168, Loss: 0.3948515922875607\n",
      "Epoch 169, Loss: 0.3946597012948804\n",
      "Epoch 170, Loss: 0.3947703326390186\n",
      "Epoch 171, Loss: 0.3944855087505129\n",
      "Epoch 172, Loss: 0.393706999807407\n",
      "Epoch 173, Loss: 0.3924696473516045\n",
      "Epoch 174, Loss: 0.39220498034667295\n",
      "Epoch 175, Loss: 0.3924744882006947\n",
      "Epoch 176, Loss: 0.39186580047882147\n",
      "Epoch 177, Loss: 0.3909536505030482\n",
      "Epoch 178, Loss: 0.39034608420050576\n",
      "Epoch 179, Loss: 0.39038797816978027\n",
      "Epoch 180, Loss: 0.39040752078892044\n",
      "Epoch 181, Loss: 0.3897777715592152\n",
      "Epoch 182, Loss: 0.388976145739829\n",
      "Epoch 183, Loss: 0.388385955078985\n",
      "Epoch 184, Loss: 0.3882172575934757\n",
      "Epoch 185, Loss: 0.3882257210766509\n",
      "Epoch 186, Loss: 0.3879610203292913\n",
      "Epoch 187, Loss: 0.38763190839209066\n",
      "Epoch 188, Loss: 0.38691831506493973\n",
      "Epoch 189, Loss: 0.38627246189543946\n",
      "Epoch 190, Loss: 0.38596024928824896\n",
      "Epoch 191, Loss: 0.3858830255218178\n",
      "Epoch 192, Loss: 0.3859960565662062\n",
      "Epoch 193, Loss: 0.3858870608462551\n",
      "Epoch 194, Loss: 0.3857039227399174\n",
      "Epoch 195, Loss: 0.3848504103759128\n",
      "Epoch 196, Loss: 0.38416446642062857\n",
      "Epoch 197, Loss: 0.38380480629658237\n",
      "Epoch 198, Loss: 0.38396882562208917\n",
      "Epoch 199, Loss: 0.3843013848003101\n",
      "Epoch 200, Loss: 0.38377279387881114\n",
      "Epoch 201, Loss: 0.3831874995881048\n",
      "Epoch 202, Loss: 0.3824403471961519\n",
      "Epoch 203, Loss: 0.3819865249321751\n",
      "Epoch 204, Loss: 0.3820311298643208\n",
      "Epoch 205, Loss: 0.38200421539946655\n",
      "Epoch 206, Loss: 0.381985491175013\n",
      "Epoch 207, Loss: 0.3818211272116274\n",
      "Epoch 208, Loss: 0.38118346681226545\n",
      "Epoch 209, Loss: 0.3805021322280853\n",
      "Epoch 210, Loss: 0.3801615655780635\n",
      "Epoch 211, Loss: 0.37988026282232007\n",
      "Epoch 212, Loss: 0.37991040676284443\n",
      "Epoch 213, Loss: 0.3801376351072682\n",
      "Epoch 214, Loss: 0.379983177753832\n",
      "Epoch 215, Loss: 0.37982102703135\n",
      "Epoch 216, Loss: 0.37902989287365\n",
      "Epoch 217, Loss: 0.37826105617745454\n",
      "Epoch 218, Loss: 0.37783743350893867\n",
      "Epoch 219, Loss: 0.3776505102022074\n",
      "Epoch 220, Loss: 0.3776337403741524\n",
      "Epoch 221, Loss: 0.3778054281981719\n",
      "Epoch 222, Loss: 0.37824969087954924\n",
      "Epoch 223, Loss: 0.3780457271677539\n",
      "Epoch 224, Loss: 0.37761712764551286\n",
      "Epoch 225, Loss: 0.3761845991571332\n",
      "Epoch 226, Loss: 0.37554006628693437\n",
      "Epoch 227, Loss: 0.3758143682022644\n",
      "Epoch 228, Loss: 0.37602554596700954\n",
      "Epoch 229, Loss: 0.37609665178955304\n",
      "Epoch 230, Loss: 0.3748520519550504\n",
      "Epoch 231, Loss: 0.37401098723643167\n",
      "Epoch 232, Loss: 0.3737202104925432\n",
      "Epoch 233, Loss: 0.3738598577888711\n",
      "Epoch 234, Loss: 0.3742473718771332\n",
      "Epoch 235, Loss: 0.37381208538854555\n",
      "Epoch 236, Loss: 0.3730676655193645\n",
      "Epoch 237, Loss: 0.37199803649091895\n",
      "Epoch 238, Loss: 0.37133353667807245\n",
      "Epoch 239, Loss: 0.37129326526524736\n",
      "Epoch 240, Loss: 0.3713868238723289\n",
      "Epoch 241, Loss: 0.37165422778348023\n",
      "Epoch 242, Loss: 0.3711534953961439\n",
      "Epoch 243, Loss: 0.37051076772232167\n",
      "Epoch 244, Loss: 0.36916486468783083\n",
      "Epoch 245, Loss: 0.3683869878425389\n",
      "Epoch 246, Loss: 0.36789132698787613\n",
      "Epoch 247, Loss: 0.3676832383249435\n",
      "Epoch 248, Loss: 0.36883671678435437\n",
      "Epoch 249, Loss: 0.3701560772516597\n",
      "Epoch 250, Loss: 0.3736591407604718\n",
      "Epoch 251, Loss: 0.36748277682213903\n",
      "Epoch 252, Loss: 0.3665018782443933\n",
      "Epoch 253, Loss: 0.3701463753255477\n",
      "Epoch 254, Loss: 0.36692543011363526\n",
      "Epoch 255, Loss: 0.3643834815175097\n",
      "Epoch 256, Loss: 0.36881114242683966\n",
      "Epoch 257, Loss: 0.36396843509524524\n",
      "Epoch 258, Loss: 0.36281976819048384\n",
      "Epoch 259, Loss: 0.3651405254695087\n",
      "Epoch 260, Loss: 0.36309594381168525\n",
      "Epoch 261, Loss: 0.3621102399928884\n",
      "Epoch 262, Loss: 0.3600752890523386\n",
      "Epoch 263, Loss: 0.3624907887044847\n",
      "Epoch 264, Loss: 0.36223959530853905\n",
      "Epoch 265, Loss: 0.3600252115839057\n",
      "Epoch 266, Loss: 0.35963291781489837\n",
      "Epoch 267, Loss: 0.3643234848261619\n",
      "Epoch 268, Loss: 0.3578585890692331\n",
      "Epoch 269, Loss: 0.358160724855245\n",
      "Epoch 270, Loss: 0.36179645189867216\n",
      "Epoch 271, Loss: 0.3556452512086985\n",
      "Epoch 272, Loss: 0.35716945302232117\n",
      "Epoch 273, Loss: 0.35985543437875733\n",
      "Epoch 274, Loss: 0.3537264664104277\n",
      "Epoch 275, Loss: 0.3572971355623955\n",
      "Epoch 276, Loss: 0.36299056041413535\n",
      "Epoch 277, Loss: 0.3541037793518798\n",
      "Epoch 278, Loss: 0.36743638552013125\n",
      "Epoch 279, Loss: 0.35939834353055145\n",
      "Epoch 280, Loss: 0.35884924452921274\n",
      "Epoch 281, Loss: 0.3573481791246394\n",
      "Epoch 282, Loss: 0.35429164373705885\n",
      "Epoch 283, Loss: 0.3574789449853856\n",
      "Epoch 284, Loss: 0.3516665728491316\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2623569252737725\n",
      "Test R^2 score: 0.26425168685428113\n",
      "Num of epochs: 285\n",
      "Epoch 1, Loss: 0.5872249446377924\n",
      "Epoch 2, Loss: 0.5854041660462959\n",
      "Epoch 3, Loss: 0.583652670055051\n",
      "Epoch 4, Loss: 0.5823013907651623\n",
      "Epoch 5, Loss: 0.5810023949437507\n",
      "Epoch 6, Loss: 0.5797430027304644\n",
      "Epoch 7, Loss: 0.5785251212258276\n",
      "Epoch 8, Loss: 0.5774250432700316\n",
      "Epoch 9, Loss: 0.576366947578631\n",
      "Epoch 10, Loss: 0.5753455492065801\n",
      "Epoch 11, Loss: 0.5743603175033158\n",
      "Epoch 12, Loss: 0.5734361778472709\n",
      "Epoch 13, Loss: 0.5725538029438565\n",
      "Epoch 14, Loss: 0.5717007449709229\n",
      "Epoch 15, Loss: 0.570874185794177\n",
      "Epoch 16, Loss: 0.5700725155011104\n",
      "Epoch 17, Loss: 0.5692932479321967\n",
      "Epoch 18, Loss: 0.5685357675447846\n",
      "Epoch 19, Loss: 0.5678021035636132\n",
      "Epoch 20, Loss: 0.5670742173995587\n",
      "Epoch 21, Loss: 0.5663462903086246\n",
      "Epoch 22, Loss: 0.565638159498702\n",
      "Epoch 23, Loss: 0.5649408259673175\n",
      "Epoch 24, Loss: 0.5642942581211143\n",
      "Epoch 25, Loss: 0.5636674369272481\n",
      "Epoch 26, Loss: 0.5630364773741547\n",
      "Epoch 27, Loss: 0.5623980535736696\n",
      "Epoch 28, Loss: 0.5617475775482682\n",
      "Epoch 29, Loss: 0.5610768540891796\n",
      "Epoch 30, Loss: 0.5603742965176464\n",
      "Epoch 31, Loss: 0.5596241018063561\n",
      "Epoch 32, Loss: 0.5588003990092727\n",
      "Epoch 33, Loss: 0.5578851807417734\n",
      "Epoch 34, Loss: 0.556884631834637\n",
      "Epoch 35, Loss: 0.5558329829949338\n",
      "Epoch 36, Loss: 0.5546310825938588\n",
      "Epoch 37, Loss: 0.5531840837032881\n",
      "Epoch 38, Loss: 0.5514423379954986\n",
      "Epoch 39, Loss: 0.5493748883799503\n",
      "Epoch 40, Loss: 0.5469558111156713\n",
      "Epoch 41, Loss: 0.5441245805794387\n",
      "Epoch 42, Loss: 0.5408163151123176\n",
      "Epoch 43, Loss: 0.5370164825566685\n",
      "Epoch 44, Loss: 0.532808961604834\n",
      "Epoch 45, Loss: 0.5283993363994962\n",
      "Epoch 46, Loss: 0.5244584162476574\n",
      "Epoch 47, Loss: 0.5223466980006825\n",
      "Epoch 48, Loss: 0.5227944708780594\n",
      "Epoch 49, Loss: 0.5227742049197268\n",
      "Epoch 50, Loss: 0.5199378007589177\n",
      "Epoch 51, Loss: 0.5158116262990804\n",
      "Epoch 52, Loss: 0.5122864755235875\n",
      "Epoch 53, Loss: 0.5100793859460675\n",
      "Epoch 54, Loss: 0.5088130483995712\n",
      "Epoch 55, Loss: 0.5076954633385725\n",
      "Epoch 56, Loss: 0.506136637816974\n",
      "Epoch 57, Loss: 0.5039821242348872\n",
      "Epoch 58, Loss: 0.501429421901952\n",
      "Epoch 59, Loss: 0.4988833116848802\n",
      "Epoch 60, Loss: 0.4968056414437065\n",
      "Epoch 61, Loss: 0.495478947467459\n",
      "Epoch 62, Loss: 0.4943658217580029\n",
      "Epoch 63, Loss: 0.49275104110449086\n",
      "Epoch 64, Loss: 0.4905830906019112\n",
      "Epoch 65, Loss: 0.48847455585224675\n",
      "Epoch 66, Loss: 0.48690761373681596\n",
      "Epoch 67, Loss: 0.4857628689463538\n",
      "Epoch 68, Loss: 0.4845812573747894\n",
      "Epoch 69, Loss: 0.4830035976499042\n",
      "Epoch 70, Loss: 0.4811706533291076\n",
      "Epoch 71, Loss: 0.47953132733804\n",
      "Epoch 72, Loss: 0.4783088860289889\n",
      "Epoch 73, Loss: 0.4772145391421716\n",
      "Epoch 74, Loss: 0.4758418058747863\n",
      "Epoch 75, Loss: 0.47431336893385856\n",
      "Epoch 76, Loss: 0.4730469216205754\n",
      "Epoch 77, Loss: 0.47205278003412615\n",
      "Epoch 78, Loss: 0.47096102918384125\n",
      "Epoch 79, Loss: 0.4696109970590225\n",
      "Epoch 80, Loss: 0.4682957991846407\n",
      "Epoch 81, Loss: 0.46725160803194143\n",
      "Epoch 82, Loss: 0.46623988419264284\n",
      "Epoch 83, Loss: 0.46503106518517384\n",
      "Epoch 84, Loss: 0.4638416162770861\n",
      "Epoch 85, Loss: 0.4628607663853959\n",
      "Epoch 86, Loss: 0.4618699776579022\n",
      "Epoch 87, Loss: 0.4606885075882236\n",
      "Epoch 88, Loss: 0.4595322767892811\n",
      "Epoch 89, Loss: 0.4585081998711672\n",
      "Epoch 90, Loss: 0.45743845869668276\n",
      "Epoch 91, Loss: 0.4563415082847593\n",
      "Epoch 92, Loss: 0.4554099318147988\n",
      "Epoch 93, Loss: 0.45458915538305494\n",
      "Epoch 94, Loss: 0.45373684582940155\n",
      "Epoch 95, Loss: 0.45299317645729514\n",
      "Epoch 96, Loss: 0.4523789413546078\n",
      "Epoch 97, Loss: 0.45175829671725765\n",
      "Epoch 98, Loss: 0.4511226280384698\n",
      "Epoch 99, Loss: 0.45042946243578247\n",
      "Epoch 100, Loss: 0.4497216105298244\n",
      "Epoch 101, Loss: 0.4490369014040556\n",
      "Epoch 102, Loss: 0.4483048139716588\n",
      "Epoch 103, Loss: 0.44753783492294286\n",
      "Epoch 104, Loss: 0.446798905649655\n",
      "Epoch 105, Loss: 0.44602166978084484\n",
      "Epoch 106, Loss: 0.44532647027304234\n",
      "Epoch 107, Loss: 0.44471535046583344\n",
      "Epoch 108, Loss: 0.4441455810592443\n",
      "Epoch 109, Loss: 0.4435806394482446\n",
      "Epoch 110, Loss: 0.4430356629442396\n",
      "Epoch 111, Loss: 0.4424790368260081\n",
      "Epoch 112, Loss: 0.4419040910729998\n",
      "Epoch 113, Loss: 0.4413126956067842\n",
      "Epoch 114, Loss: 0.4407115296696971\n",
      "Epoch 115, Loss: 0.44009801382545394\n",
      "Epoch 116, Loss: 0.4394239458357396\n",
      "Epoch 117, Loss: 0.43877850779544597\n",
      "Epoch 118, Loss: 0.43813438062651994\n",
      "Epoch 119, Loss: 0.4374701966624821\n",
      "Epoch 120, Loss: 0.4367674245988673\n",
      "Epoch 121, Loss: 0.436061093711253\n",
      "Epoch 122, Loss: 0.4353747348428642\n",
      "Epoch 123, Loss: 0.4347051347052819\n",
      "Epoch 124, Loss: 0.43402045964323344\n",
      "Epoch 125, Loss: 0.43335851525839836\n",
      "Epoch 126, Loss: 0.43270626830133385\n",
      "Epoch 127, Loss: 0.43203299799698297\n",
      "Epoch 128, Loss: 0.4313172211984945\n",
      "Epoch 129, Loss: 0.4305535172427888\n",
      "Epoch 130, Loss: 0.4298602537192136\n",
      "Epoch 131, Loss: 0.42917026252845036\n",
      "Epoch 132, Loss: 0.4285036424406358\n",
      "Epoch 133, Loss: 0.4278710900166221\n",
      "Epoch 134, Loss: 0.42724572753890555\n",
      "Epoch 135, Loss: 0.42666335118888105\n",
      "Epoch 136, Loss: 0.42608472525674346\n",
      "Epoch 137, Loss: 0.4254905163047631\n",
      "Epoch 138, Loss: 0.42490282350204905\n",
      "Epoch 139, Loss: 0.4243418485083517\n",
      "Epoch 140, Loss: 0.4237679469547562\n",
      "Epoch 141, Loss: 0.423176805545031\n",
      "Epoch 142, Loss: 0.422580993636965\n",
      "Epoch 143, Loss: 0.42200690432636057\n",
      "Epoch 144, Loss: 0.4214388747664523\n",
      "Epoch 145, Loss: 0.4208840281416362\n",
      "Epoch 146, Loss: 0.42030925182236095\n",
      "Epoch 147, Loss: 0.4197440547147193\n",
      "Epoch 148, Loss: 0.41920040162973604\n",
      "Epoch 149, Loss: 0.41869944580434126\n",
      "Epoch 150, Loss: 0.41820818736409626\n",
      "Epoch 151, Loss: 0.41770003049721127\n",
      "Epoch 152, Loss: 0.4170946803758162\n",
      "Epoch 153, Loss: 0.416464800413119\n",
      "Epoch 154, Loss: 0.4159402734275657\n",
      "Epoch 155, Loss: 0.41549372284872393\n",
      "Epoch 156, Loss: 0.41506229111238685\n",
      "Epoch 157, Loss: 0.4144811313381578\n",
      "Epoch 158, Loss: 0.41386507833968633\n",
      "Epoch 159, Loss: 0.41328468681882286\n",
      "Epoch 160, Loss: 0.41280144167692695\n",
      "Epoch 161, Loss: 0.41234527633864404\n",
      "Epoch 162, Loss: 0.41179601678992234\n",
      "Epoch 163, Loss: 0.4112493209485416\n",
      "Epoch 164, Loss: 0.4106637993282584\n",
      "Epoch 165, Loss: 0.4101554870598373\n",
      "Epoch 166, Loss: 0.40969928535369304\n",
      "Epoch 167, Loss: 0.40931306181149874\n",
      "Epoch 168, Loss: 0.40896240146198654\n",
      "Epoch 169, Loss: 0.4085764660653334\n",
      "Epoch 170, Loss: 0.4081102658017469\n",
      "Epoch 171, Loss: 0.4073677641503089\n",
      "Epoch 172, Loss: 0.4068072421996675\n",
      "Epoch 173, Loss: 0.40653290434893735\n",
      "Epoch 174, Loss: 0.4062343007502174\n",
      "Epoch 175, Loss: 0.4056285726921844\n",
      "Epoch 176, Loss: 0.40493467949168904\n",
      "Epoch 177, Loss: 0.4045012321547708\n",
      "Epoch 178, Loss: 0.4042074500805905\n",
      "Epoch 179, Loss: 0.4037857694990696\n",
      "Epoch 180, Loss: 0.4031914604464382\n",
      "Epoch 181, Loss: 0.4025838746471447\n",
      "Epoch 182, Loss: 0.4021676798622109\n",
      "Epoch 183, Loss: 0.4018236891647828\n",
      "Epoch 184, Loss: 0.4014186408482913\n",
      "Epoch 185, Loss: 0.4009640564898386\n",
      "Epoch 186, Loss: 0.4004105725785602\n",
      "Epoch 187, Loss: 0.39983025391293764\n",
      "Epoch 188, Loss: 0.399291096531497\n",
      "Epoch 189, Loss: 0.39877079132190396\n",
      "Epoch 190, Loss: 0.39826394957557015\n",
      "Epoch 191, Loss: 0.3977711097598978\n",
      "Epoch 192, Loss: 0.3972938805118218\n",
      "Epoch 193, Loss: 0.396993132153496\n",
      "Epoch 194, Loss: 0.3969784556735914\n",
      "Epoch 195, Loss: 0.3978153682344634\n",
      "Epoch 196, Loss: 0.39861082533177417\n",
      "Epoch 197, Loss: 0.39598798449546957\n",
      "Epoch 198, Loss: 0.395272719601898\n",
      "Epoch 199, Loss: 0.39653189613926376\n",
      "Epoch 200, Loss: 0.39459566024906395\n",
      "Epoch 201, Loss: 0.3944709656236207\n",
      "Epoch 202, Loss: 0.39511495788518386\n",
      "Epoch 203, Loss: 0.3933234091324367\n",
      "Epoch 204, Loss: 0.3939189503009524\n",
      "Epoch 205, Loss: 0.39370563726436986\n",
      "Epoch 206, Loss: 0.39253785035899696\n",
      "Epoch 207, Loss: 0.39308037584963446\n",
      "Epoch 208, Loss: 0.3925227035953839\n",
      "Epoch 209, Loss: 0.39172291005211446\n",
      "Epoch 210, Loss: 0.3922526400448689\n",
      "Epoch 211, Loss: 0.3913736798103652\n",
      "Epoch 212, Loss: 0.3910144199958701\n",
      "Epoch 213, Loss: 0.3910079033057752\n",
      "Epoch 214, Loss: 0.39055516572421534\n",
      "Epoch 215, Loss: 0.39006475326750323\n",
      "Epoch 216, Loss: 0.39016297673364414\n",
      "Epoch 217, Loss: 0.38969683047873643\n",
      "Epoch 218, Loss: 0.3893614551092598\n",
      "Epoch 219, Loss: 0.3892247470683133\n",
      "Epoch 220, Loss: 0.3890455165664512\n",
      "Epoch 221, Loss: 0.388547887147228\n",
      "Epoch 222, Loss: 0.3883746366815307\n",
      "Epoch 223, Loss: 0.3882111737512209\n",
      "Epoch 224, Loss: 0.38799917770819686\n",
      "Epoch 225, Loss: 0.38765045598353964\n",
      "Epoch 226, Loss: 0.3872304286357804\n",
      "Epoch 227, Loss: 0.38697351868291285\n",
      "Epoch 228, Loss: 0.38669668963154513\n",
      "Epoch 229, Loss: 0.3866326978097827\n",
      "Epoch 230, Loss: 0.38641200760478756\n",
      "Epoch 231, Loss: 0.38621810333866985\n",
      "Epoch 232, Loss: 0.38593746988396777\n",
      "Epoch 233, Loss: 0.385556468438449\n",
      "Epoch 234, Loss: 0.3852629763232949\n",
      "Epoch 235, Loss: 0.3848055320221646\n",
      "Epoch 236, Loss: 0.3844858691963582\n",
      "Epoch 237, Loss: 0.38419784247007543\n",
      "Epoch 238, Loss: 0.38390424324973693\n",
      "Epoch 239, Loss: 0.3837190326348208\n",
      "Epoch 240, Loss: 0.38358004170647136\n",
      "Epoch 241, Loss: 0.38396290731715504\n",
      "Epoch 242, Loss: 0.38583481074984777\n",
      "Epoch 243, Loss: 0.3886477017193723\n",
      "Epoch 244, Loss: 0.38791508054904117\n",
      "Epoch 245, Loss: 0.38282446939868436\n",
      "Epoch 246, Loss: 0.38763313851889725\n",
      "Epoch 247, Loss: 0.3856011048182908\n",
      "Epoch 248, Loss: 0.38399370090960716\n",
      "Epoch 249, Loss: 0.38614164505361015\n",
      "Epoch 250, Loss: 0.3826639899409169\n",
      "Epoch 251, Loss: 0.3839698152313893\n",
      "Epoch 252, Loss: 0.3831153761384628\n",
      "Epoch 253, Loss: 0.3824995669194182\n",
      "Epoch 254, Loss: 0.38354428083049347\n",
      "Epoch 255, Loss: 0.38159579947941774\n",
      "Epoch 256, Loss: 0.38278007369990025\n",
      "Epoch 257, Loss: 0.38187105841717417\n",
      "Epoch 258, Loss: 0.38130068520245036\n",
      "Epoch 259, Loss: 0.3817881678678654\n",
      "Epoch 260, Loss: 0.38069348757338783\n",
      "Epoch 261, Loss: 0.3811515860876225\n",
      "Epoch 262, Loss: 0.3805374349834085\n",
      "Epoch 263, Loss: 0.38042883379650755\n",
      "Epoch 264, Loss: 0.380033389651117\n",
      "Epoch 265, Loss: 0.38028288027692675\n",
      "Epoch 266, Loss: 0.3793441365867987\n",
      "Epoch 267, Loss: 0.37971455591450604\n",
      "Epoch 268, Loss: 0.379217924157223\n",
      "Epoch 269, Loss: 0.3789896725717048\n",
      "Epoch 270, Loss: 0.3786861921137682\n",
      "Epoch 271, Loss: 0.3787311857416498\n",
      "Epoch 272, Loss: 0.3782956227058127\n",
      "Epoch 273, Loss: 0.37809000877965343\n",
      "Epoch 274, Loss: 0.3778552393565288\n",
      "Epoch 275, Loss: 0.37774233646937816\n",
      "Epoch 276, Loss: 0.3774543750109169\n",
      "Epoch 277, Loss: 0.3773624391844029\n",
      "Epoch 278, Loss: 0.37697065638752913\n",
      "Epoch 279, Loss: 0.37681980443731233\n",
      "Epoch 280, Loss: 0.3765257156577014\n",
      "Epoch 281, Loss: 0.37632970697546786\n",
      "Epoch 282, Loss: 0.3760153812333947\n",
      "Epoch 283, Loss: 0.3759413863731916\n",
      "Epoch 284, Loss: 0.3761447480780384\n",
      "Epoch 285, Loss: 0.37685954459211185\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.24360289473794647\n",
      "Test R^2 score: 0.3519521240924003\n",
      "Num of epochs: 286\n",
      "Epoch 1, Loss: 0.5640964899362695\n",
      "Epoch 2, Loss: 0.5628040075005581\n",
      "Epoch 3, Loss: 0.5617132512912419\n",
      "Epoch 4, Loss: 0.560731332448648\n",
      "Epoch 5, Loss: 0.5598495878297979\n",
      "Epoch 6, Loss: 0.5590663591212246\n",
      "Epoch 7, Loss: 0.55838328844985\n",
      "Epoch 8, Loss: 0.5578032281783565\n",
      "Epoch 9, Loss: 0.557325323520526\n",
      "Epoch 10, Loss: 0.5569505865858163\n",
      "Epoch 11, Loss: 0.5566536617425537\n",
      "Epoch 12, Loss: 0.5564383423657572\n",
      "Epoch 13, Loss: 0.556291437212955\n",
      "Epoch 14, Loss: 0.556208365736017\n",
      "Epoch 15, Loss: 0.5561768590867503\n",
      "Epoch 16, Loss: 0.5561836910372433\n",
      "Epoch 17, Loss: 0.5562183317535112\n",
      "Epoch 18, Loss: 0.5562682663136463\n",
      "Epoch 19, Loss: 0.5563221606050165\n",
      "Epoch 20, Loss: 0.5563720322810266\n",
      "Epoch 21, Loss: 0.5564098214278831\n",
      "Epoch 22, Loss: 0.5564304155663355\n",
      "Epoch 23, Loss: 0.5564313528626945\n",
      "Epoch 24, Loss: 0.5564125798547465\n",
      "Epoch 25, Loss: 0.5563754068946078\n",
      "Epoch 26, Loss: 0.5563219731090774\n",
      "Epoch 27, Loss: 0.5562552205387262\n",
      "Epoch 28, Loss: 0.5561775824737162\n",
      "Epoch 29, Loss: 0.5560913052442189\n",
      "Epoch 30, Loss: 0.5559986628938282\n",
      "Epoch 31, Loss: 0.5558997862676658\n",
      "Epoch 32, Loss: 0.555793224266854\n",
      "Epoch 33, Loss: 0.5556762372176517\n",
      "Epoch 34, Loss: 0.5555426493443638\n",
      "Epoch 35, Loss: 0.5553850167174162\n",
      "Epoch 36, Loss: 0.5551937372127186\n",
      "Epoch 37, Loss: 0.5549568006095893\n",
      "Epoch 38, Loss: 0.5546582711269095\n",
      "Epoch 39, Loss: 0.5542812740396681\n",
      "Epoch 40, Loss: 0.55379745103567\n",
      "Epoch 41, Loss: 0.5531481215391216\n",
      "Epoch 42, Loss: 0.5523604890911891\n",
      "Epoch 43, Loss: 0.5514079106933629\n",
      "Epoch 44, Loss: 0.5502394046794592\n",
      "Epoch 45, Loss: 0.5487843832049606\n",
      "Epoch 46, Loss: 0.5469401729441268\n",
      "Epoch 47, Loss: 0.5446091441590538\n",
      "Epoch 48, Loss: 0.5417377596441881\n",
      "Epoch 49, Loss: 0.5383530246402708\n",
      "Epoch 50, Loss: 0.5344611895917037\n",
      "Epoch 51, Loss: 0.530009335669582\n",
      "Epoch 52, Loss: 0.5249102356783176\n",
      "Epoch 53, Loss: 0.5191133869451168\n",
      "Epoch 54, Loss: 0.5125270022280269\n",
      "Epoch 55, Loss: 0.5052663501055163\n",
      "Epoch 56, Loss: 0.49784766308292616\n",
      "Epoch 57, Loss: 0.4913524931840809\n",
      "Epoch 58, Loss: 0.4875018498801322\n",
      "Epoch 59, Loss: 0.48728013215664284\n",
      "Epoch 60, Loss: 0.48870865998230245\n",
      "Epoch 61, Loss: 0.4886486807242613\n",
      "Epoch 62, Loss: 0.486039516497632\n",
      "Epoch 63, Loss: 0.4823836492923043\n",
      "Epoch 64, Loss: 0.4793733189191524\n",
      "Epoch 65, Loss: 0.4780124743821041\n",
      "Epoch 66, Loss: 0.4782137950397971\n",
      "Epoch 67, Loss: 0.4785252317125997\n",
      "Epoch 68, Loss: 0.47817121294869086\n",
      "Epoch 69, Loss: 0.4771623119908799\n",
      "Epoch 70, Loss: 0.4757835087464183\n",
      "Epoch 71, Loss: 0.4742743954384051\n",
      "Epoch 72, Loss: 0.47281944988359437\n",
      "Epoch 73, Loss: 0.47155294038298545\n",
      "Epoch 74, Loss: 0.47051441002729655\n",
      "Epoch 75, Loss: 0.4695670477602344\n",
      "Epoch 76, Loss: 0.46866101373982116\n",
      "Epoch 77, Loss: 0.467752093821681\n",
      "Epoch 78, Loss: 0.4667512719770936\n",
      "Epoch 79, Loss: 0.46566217965301465\n",
      "Epoch 80, Loss: 0.4646285384327961\n",
      "Epoch 81, Loss: 0.4637735854626518\n",
      "Epoch 82, Loss: 0.4631649926456089\n",
      "Epoch 83, Loss: 0.4626634740603656\n",
      "Epoch 84, Loss: 0.462163007240697\n",
      "Epoch 85, Loss: 0.46151456432877375\n",
      "Epoch 86, Loss: 0.46072968146220433\n",
      "Epoch 87, Loss: 0.459865616885427\n",
      "Epoch 88, Loss: 0.4590034480900371\n",
      "Epoch 89, Loss: 0.4582342470596639\n",
      "Epoch 90, Loss: 0.45760268979261554\n",
      "Epoch 91, Loss: 0.4570607721949944\n",
      "Epoch 92, Loss: 0.45654806042448143\n",
      "Epoch 93, Loss: 0.45602804102030337\n",
      "Epoch 94, Loss: 0.4554796698489726\n",
      "Epoch 95, Loss: 0.4549568898874226\n",
      "Epoch 96, Loss: 0.4544802655540376\n",
      "Epoch 97, Loss: 0.4540403755557974\n",
      "Epoch 98, Loss: 0.4536054629010362\n",
      "Epoch 99, Loss: 0.4531536422095708\n",
      "Epoch 100, Loss: 0.4526609148885306\n",
      "Epoch 101, Loss: 0.4521522604201912\n",
      "Epoch 102, Loss: 0.45164946672316664\n",
      "Epoch 103, Loss: 0.4511753924344167\n",
      "Epoch 104, Loss: 0.45072045800571037\n",
      "Epoch 105, Loss: 0.45026445168194273\n",
      "Epoch 106, Loss: 0.44980506781008334\n",
      "Epoch 107, Loss: 0.4493359454325009\n",
      "Epoch 108, Loss: 0.44886898854075025\n",
      "Epoch 109, Loss: 0.448416416323869\n",
      "Epoch 110, Loss: 0.4479713868568181\n",
      "Epoch 111, Loss: 0.4475213032185728\n",
      "Epoch 112, Loss: 0.44705190091532676\n",
      "Epoch 113, Loss: 0.44656118364720704\n",
      "Epoch 114, Loss: 0.4460598546928228\n",
      "Epoch 115, Loss: 0.4455413230457775\n",
      "Epoch 116, Loss: 0.4449933732268009\n",
      "Epoch 117, Loss: 0.4444422835638577\n",
      "Epoch 118, Loss: 0.4438686722583977\n",
      "Epoch 119, Loss: 0.44330430213923977\n",
      "Epoch 120, Loss: 0.44273791681814645\n",
      "Epoch 121, Loss: 0.442142884662512\n",
      "Epoch 122, Loss: 0.4415369431104805\n",
      "Epoch 123, Loss: 0.4409490428633012\n",
      "Epoch 124, Loss: 0.4403461791587328\n",
      "Epoch 125, Loss: 0.4397375076746777\n",
      "Epoch 126, Loss: 0.4391356444606586\n",
      "Epoch 127, Loss: 0.4385472943661452\n",
      "Epoch 128, Loss: 0.4379600592358948\n",
      "Epoch 129, Loss: 0.43736881605400835\n",
      "Epoch 130, Loss: 0.43678613733102484\n",
      "Epoch 131, Loss: 0.43621219402879347\n",
      "Epoch 132, Loss: 0.4356668418262736\n",
      "Epoch 133, Loss: 0.43514934924696247\n",
      "Epoch 134, Loss: 0.4346802133186665\n",
      "Epoch 135, Loss: 0.4341237892344885\n",
      "Epoch 136, Loss: 0.4334942471541579\n",
      "Epoch 137, Loss: 0.43288750738767545\n",
      "Epoch 138, Loss: 0.43237657938655244\n",
      "Epoch 139, Loss: 0.4319214231159391\n",
      "Epoch 140, Loss: 0.43138512001116136\n",
      "Epoch 141, Loss: 0.43080538206475283\n",
      "Epoch 142, Loss: 0.4302188016096616\n",
      "Epoch 143, Loss: 0.4296833038125185\n",
      "Epoch 144, Loss: 0.4292280341533998\n",
      "Epoch 145, Loss: 0.42881000390860174\n",
      "Epoch 146, Loss: 0.428287114127928\n",
      "Epoch 147, Loss: 0.42776314973935387\n",
      "Epoch 148, Loss: 0.42724584960930523\n",
      "Epoch 149, Loss: 0.4267487863245166\n",
      "Epoch 150, Loss: 0.4262631340464453\n",
      "Epoch 151, Loss: 0.4257870769976938\n",
      "Epoch 152, Loss: 0.4252977688471403\n",
      "Epoch 153, Loss: 0.4248075287822546\n",
      "Epoch 154, Loss: 0.424352699193846\n",
      "Epoch 155, Loss: 0.42423469625889876\n",
      "Epoch 156, Loss: 0.4244637184218371\n",
      "Epoch 157, Loss: 0.42452737811375924\n",
      "Epoch 158, Loss: 0.4224209608262479\n",
      "Epoch 159, Loss: 0.4234382664578529\n",
      "Epoch 160, Loss: 0.4228513334419035\n",
      "Epoch 161, Loss: 0.42161317047140023\n",
      "Epoch 162, Loss: 0.4225248700220197\n",
      "Epoch 163, Loss: 0.4204729412129385\n",
      "Epoch 164, Loss: 0.4212125769781997\n",
      "Epoch 165, Loss: 0.41978196763160674\n",
      "Epoch 166, Loss: 0.42016317842047596\n",
      "Epoch 167, Loss: 0.41940756951310626\n",
      "Epoch 168, Loss: 0.4188915476056227\n",
      "Epoch 169, Loss: 0.4187969309570494\n",
      "Epoch 170, Loss: 0.41776461384618746\n",
      "Epoch 171, Loss: 0.41804218538406046\n",
      "Epoch 172, Loss: 0.4168795002318377\n",
      "Epoch 173, Loss: 0.41709764563056745\n",
      "Epoch 174, Loss: 0.4162909442937471\n",
      "Epoch 175, Loss: 0.41581405986136094\n",
      "Epoch 176, Loss: 0.41574046388265395\n",
      "Epoch 177, Loss: 0.4146999993700736\n",
      "Epoch 178, Loss: 0.41461617860446515\n",
      "Epoch 179, Loss: 0.4140543127150191\n",
      "Epoch 180, Loss: 0.4132636299054855\n",
      "Epoch 181, Loss: 0.4130581965950292\n",
      "Epoch 182, Loss: 0.41259189579119504\n",
      "Epoch 183, Loss: 0.41181280665083003\n",
      "Epoch 184, Loss: 0.4113250246863977\n",
      "Epoch 185, Loss: 0.4110757964914066\n",
      "Epoch 186, Loss: 0.4105860501807197\n",
      "Epoch 187, Loss: 0.4098688299291121\n",
      "Epoch 188, Loss: 0.4092235678221317\n",
      "Epoch 189, Loss: 0.40873577647295367\n",
      "Epoch 190, Loss: 0.4085214824479088\n",
      "Epoch 191, Loss: 0.40848270679765497\n",
      "Epoch 192, Loss: 0.408027665973193\n",
      "Epoch 193, Loss: 0.40730862968353865\n",
      "Epoch 194, Loss: 0.40633939713104367\n",
      "Epoch 195, Loss: 0.4055927351652264\n",
      "Epoch 196, Loss: 0.40516449716503156\n",
      "Epoch 197, Loss: 0.4052754781280986\n",
      "Epoch 198, Loss: 0.4061882265515572\n",
      "Epoch 199, Loss: 0.40547381124112286\n",
      "Epoch 200, Loss: 0.40406979066742743\n",
      "Epoch 201, Loss: 0.40236206383366113\n",
      "Epoch 202, Loss: 0.40252818352492487\n",
      "Epoch 203, Loss: 0.40336106212262396\n",
      "Epoch 204, Loss: 0.40188741267302613\n",
      "Epoch 205, Loss: 0.4004042646364368\n",
      "Epoch 206, Loss: 0.3997621768029625\n",
      "Epoch 207, Loss: 0.40004095300004794\n",
      "Epoch 208, Loss: 0.40044944145100814\n",
      "Epoch 209, Loss: 0.39913010704890095\n",
      "Epoch 210, Loss: 0.3976779879341149\n",
      "Epoch 211, Loss: 0.3969686210023709\n",
      "Epoch 212, Loss: 0.39714213714749974\n",
      "Epoch 213, Loss: 0.3977746498698557\n",
      "Epoch 214, Loss: 0.39738444874039547\n",
      "Epoch 215, Loss: 0.39636730476423526\n",
      "Epoch 216, Loss: 0.3943993942950068\n",
      "Epoch 217, Loss: 0.39401976790070903\n",
      "Epoch 218, Loss: 0.39498382520152614\n",
      "Epoch 219, Loss: 0.3951080939716827\n",
      "Epoch 220, Loss: 0.3946593803603608\n",
      "Epoch 221, Loss: 0.3920620995155696\n",
      "Epoch 222, Loss: 0.3913583928011096\n",
      "Epoch 223, Loss: 0.3926781484233219\n",
      "Epoch 224, Loss: 0.3925647828221431\n",
      "Epoch 225, Loss: 0.3919427199006225\n",
      "Epoch 226, Loss: 0.3895642564900123\n",
      "Epoch 227, Loss: 0.3891031757218277\n",
      "Epoch 228, Loss: 0.39048539528051934\n",
      "Epoch 229, Loss: 0.3907899508295048\n",
      "Epoch 230, Loss: 0.39032298810808436\n",
      "Epoch 231, Loss: 0.38754138725513215\n",
      "Epoch 232, Loss: 0.3870327378060763\n",
      "Epoch 233, Loss: 0.3887398626778198\n",
      "Epoch 234, Loss: 0.3884941154645556\n",
      "Epoch 235, Loss: 0.3872622321901577\n",
      "Epoch 236, Loss: 0.3851936399560665\n",
      "Epoch 237, Loss: 0.3847883382376875\n",
      "Epoch 238, Loss: 0.3860340607654363\n",
      "Epoch 239, Loss: 0.3865992236136501\n",
      "Epoch 240, Loss: 0.3867846924017664\n",
      "Epoch 241, Loss: 0.38417976817686306\n",
      "Epoch 242, Loss: 0.382611552844928\n",
      "Epoch 243, Loss: 0.38230714723320575\n",
      "Epoch 244, Loss: 0.3828578260407778\n",
      "Epoch 245, Loss: 0.3844314130618417\n",
      "Epoch 246, Loss: 0.3844250367323798\n",
      "Epoch 247, Loss: 0.3838441144368045\n",
      "Epoch 248, Loss: 0.3812072339070039\n",
      "Epoch 249, Loss: 0.379858099518499\n",
      "Epoch 250, Loss: 0.3800534647109275\n",
      "Epoch 251, Loss: 0.38081940661299235\n",
      "Epoch 252, Loss: 0.38203922333617135\n",
      "Epoch 253, Loss: 0.38147789053763986\n",
      "Epoch 254, Loss: 0.38073558262725743\n",
      "Epoch 255, Loss: 0.37848610541441\n",
      "Epoch 256, Loss: 0.3772792097542218\n",
      "Epoch 257, Loss: 0.37759536425974666\n",
      "Epoch 258, Loss: 0.378991048703385\n",
      "Epoch 259, Loss: 0.3811812776632186\n",
      "Epoch 260, Loss: 0.3806627793190136\n",
      "Epoch 261, Loss: 0.3789692265981057\n",
      "Epoch 262, Loss: 0.37596332477203004\n",
      "Epoch 263, Loss: 0.3753059053437194\n",
      "Epoch 264, Loss: 0.3765223121566886\n",
      "Epoch 265, Loss: 0.37768570469049706\n",
      "Epoch 266, Loss: 0.3775209686000897\n",
      "Epoch 267, Loss: 0.37532680893936415\n",
      "Epoch 268, Loss: 0.3735491980612358\n",
      "Epoch 269, Loss: 0.37350838758505783\n",
      "Epoch 270, Loss: 0.3743307181074776\n",
      "Epoch 271, Loss: 0.3756150328127811\n",
      "Epoch 272, Loss: 0.37608557767907685\n",
      "Epoch 273, Loss: 0.3760861720045564\n",
      "Epoch 274, Loss: 0.37383502567184285\n",
      "Epoch 275, Loss: 0.37181491045764437\n",
      "Epoch 276, Loss: 0.3712322378244363\n",
      "Epoch 277, Loss: 0.37189818077606634\n",
      "Epoch 278, Loss: 0.3732497178081102\n",
      "Epoch 279, Loss: 0.37430092102552015\n",
      "Epoch 280, Loss: 0.37502795353653273\n",
      "Epoch 281, Loss: 0.37288054907592816\n",
      "Epoch 282, Loss: 0.37064842809443893\n",
      "Epoch 283, Loss: 0.3692713309294985\n",
      "Epoch 284, Loss: 0.3691862572616293\n",
      "Epoch 285, Loss: 0.3698110799215779\n",
      "Epoch 286, Loss: 0.37128413486572\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.25225813286827964\n",
      "Test R^2 score: 0.30785661392995944\n",
      "Num of epochs: 287\n",
      "Epoch 1, Loss: 0.5922960498937003\n",
      "Epoch 2, Loss: 0.5902914912058248\n",
      "Epoch 3, Loss: 0.5883854909188083\n",
      "Epoch 4, Loss: 0.5865350600801816\n",
      "Epoch 5, Loss: 0.584702270582216\n",
      "Epoch 6, Loss: 0.5829093504913073\n",
      "Epoch 7, Loss: 0.581213716174327\n",
      "Epoch 8, Loss: 0.5795463667826689\n",
      "Epoch 9, Loss: 0.5778930559631928\n",
      "Epoch 10, Loss: 0.5762571368737466\n",
      "Epoch 11, Loss: 0.5746419994602205\n",
      "Epoch 12, Loss: 0.5730484955289533\n",
      "Epoch 13, Loss: 0.5715162037598984\n",
      "Epoch 14, Loss: 0.5700997517537538\n",
      "Epoch 15, Loss: 0.5686999477118811\n",
      "Epoch 16, Loss: 0.5673220629842695\n",
      "Epoch 17, Loss: 0.5659720499497394\n",
      "Epoch 18, Loss: 0.5646503196428956\n",
      "Epoch 19, Loss: 0.5633739728442152\n",
      "Epoch 20, Loss: 0.562199856896384\n",
      "Epoch 21, Loss: 0.5610578646932092\n",
      "Epoch 22, Loss: 0.5599523175749977\n",
      "Epoch 23, Loss: 0.5588871645421569\n",
      "Epoch 24, Loss: 0.557862369861924\n",
      "Epoch 25, Loss: 0.5568755340145475\n",
      "Epoch 26, Loss: 0.5559096505971768\n",
      "Epoch 27, Loss: 0.5549225644914677\n",
      "Epoch 28, Loss: 0.5540107574657891\n",
      "Epoch 29, Loss: 0.5530475497575101\n",
      "Epoch 30, Loss: 0.551994880452119\n",
      "Epoch 31, Loss: 0.550817880697491\n",
      "Epoch 32, Loss: 0.5494760510204144\n",
      "Epoch 33, Loss: 0.5478144614428818\n",
      "Epoch 34, Loss: 0.5458808036235373\n",
      "Epoch 35, Loss: 0.5435744824439172\n",
      "Epoch 36, Loss: 0.5408386051036642\n",
      "Epoch 37, Loss: 0.537738778061515\n",
      "Epoch 38, Loss: 0.5344182794456271\n",
      "Epoch 39, Loss: 0.531123735345101\n",
      "Epoch 40, Loss: 0.5281469938675668\n",
      "Epoch 41, Loss: 0.5256751895851406\n",
      "Epoch 42, Loss: 0.5234270521800852\n",
      "Epoch 43, Loss: 0.5206696507424983\n",
      "Epoch 44, Loss: 0.5171820798745471\n",
      "Epoch 45, Loss: 0.5135752075673239\n",
      "Epoch 46, Loss: 0.5105494469225429\n",
      "Epoch 47, Loss: 0.5081666738352281\n",
      "Epoch 48, Loss: 0.5059411708140199\n",
      "Epoch 49, Loss: 0.5035384854379441\n",
      "Epoch 50, Loss: 0.5009721305903958\n",
      "Epoch 51, Loss: 0.49856834786839754\n",
      "Epoch 52, Loss: 0.4967594486205729\n",
      "Epoch 53, Loss: 0.49546535371682826\n",
      "Epoch 54, Loss: 0.4940809583262105\n",
      "Epoch 55, Loss: 0.49227698587403823\n",
      "Epoch 56, Loss: 0.49041035141952966\n",
      "Epoch 57, Loss: 0.4887184931948736\n",
      "Epoch 58, Loss: 0.48717443525745835\n",
      "Epoch 59, Loss: 0.4857002402777232\n",
      "Epoch 60, Loss: 0.4841019106706463\n",
      "Epoch 61, Loss: 0.48256681172401517\n",
      "Epoch 62, Loss: 0.4811512666213667\n",
      "Epoch 63, Loss: 0.4796755686714379\n",
      "Epoch 64, Loss: 0.4780502703490469\n",
      "Epoch 65, Loss: 0.4764403358594258\n",
      "Epoch 66, Loss: 0.47491857872365134\n",
      "Epoch 67, Loss: 0.4734138218463464\n",
      "Epoch 68, Loss: 0.4719459777149388\n",
      "Epoch 69, Loss: 0.47065334135944575\n",
      "Epoch 70, Loss: 0.4694891347420092\n",
      "Epoch 71, Loss: 0.46830012668141147\n",
      "Epoch 72, Loss: 0.4672324570423605\n",
      "Epoch 73, Loss: 0.4662603862669235\n",
      "Epoch 74, Loss: 0.46521867330015865\n",
      "Epoch 75, Loss: 0.4639854521320595\n",
      "Epoch 76, Loss: 0.4626703341735616\n",
      "Epoch 77, Loss: 0.46150655695409754\n",
      "Epoch 78, Loss: 0.4602838666340238\n",
      "Epoch 79, Loss: 0.4591570914747648\n",
      "Epoch 80, Loss: 0.45807152733981565\n",
      "Epoch 81, Loss: 0.45707565483151097\n",
      "Epoch 82, Loss: 0.45629967719540454\n",
      "Epoch 83, Loss: 0.45516416857739417\n",
      "Epoch 84, Loss: 0.45411521316848075\n",
      "Epoch 85, Loss: 0.45319375799001543\n",
      "Epoch 86, Loss: 0.4522513978861666\n",
      "Epoch 87, Loss: 0.45134933086416235\n",
      "Epoch 88, Loss: 0.45053367559691965\n",
      "Epoch 89, Loss: 0.4498197598567815\n",
      "Epoch 90, Loss: 0.44896886758622895\n",
      "Epoch 91, Loss: 0.44819853659454323\n",
      "Epoch 92, Loss: 0.44743618773901916\n",
      "Epoch 93, Loss: 0.44676948915675\n",
      "Epoch 94, Loss: 0.4459767323420377\n",
      "Epoch 95, Loss: 0.4453260352771392\n",
      "Epoch 96, Loss: 0.44465327406612654\n",
      "Epoch 97, Loss: 0.443897827804357\n",
      "Epoch 98, Loss: 0.4432822172942985\n",
      "Epoch 99, Loss: 0.44258527354353416\n",
      "Epoch 100, Loss: 0.441884988081086\n",
      "Epoch 101, Loss: 0.44119549674025427\n",
      "Epoch 102, Loss: 0.44051023706714554\n",
      "Epoch 103, Loss: 0.4398424754962784\n",
      "Epoch 104, Loss: 0.43918146849823086\n",
      "Epoch 105, Loss: 0.43850673920031913\n",
      "Epoch 106, Loss: 0.43781864959732636\n",
      "Epoch 107, Loss: 0.4371344196961644\n",
      "Epoch 108, Loss: 0.43644616383935814\n",
      "Epoch 109, Loss: 0.4357387650311372\n",
      "Epoch 110, Loss: 0.4350920898695157\n",
      "Epoch 111, Loss: 0.43443742070302294\n",
      "Epoch 112, Loss: 0.4337528555443511\n",
      "Epoch 113, Loss: 0.4330730232549075\n",
      "Epoch 114, Loss: 0.4323720818912157\n",
      "Epoch 115, Loss: 0.431693665020393\n",
      "Epoch 116, Loss: 0.4310213021614435\n",
      "Epoch 117, Loss: 0.43039887236709784\n",
      "Epoch 118, Loss: 0.4299198042861119\n",
      "Epoch 119, Loss: 0.42969882256588693\n",
      "Epoch 120, Loss: 0.4286333678678327\n",
      "Epoch 121, Loss: 0.42752639730836467\n",
      "Epoch 122, Loss: 0.4270684619578407\n",
      "Epoch 123, Loss: 0.4265403280679061\n",
      "Epoch 124, Loss: 0.42563057779586827\n",
      "Epoch 125, Loss: 0.4248052312036302\n",
      "Epoch 126, Loss: 0.42441356674706077\n",
      "Epoch 127, Loss: 0.4239740428154145\n",
      "Epoch 128, Loss: 0.42302937986596406\n",
      "Epoch 129, Loss: 0.4223232889811313\n",
      "Epoch 130, Loss: 0.4220156258632467\n",
      "Epoch 131, Loss: 0.42145223981167307\n",
      "Epoch 132, Loss: 0.42062783448623203\n",
      "Epoch 133, Loss: 0.42009312885797245\n",
      "Epoch 134, Loss: 0.4197183870040327\n",
      "Epoch 135, Loss: 0.419148322583109\n",
      "Epoch 136, Loss: 0.4184183750525443\n",
      "Epoch 137, Loss: 0.41793901569450437\n",
      "Epoch 138, Loss: 0.417520799975304\n",
      "Epoch 139, Loss: 0.4168948164809559\n",
      "Epoch 140, Loss: 0.41619790252366\n",
      "Epoch 141, Loss: 0.4157031322838421\n",
      "Epoch 142, Loss: 0.4152802249144568\n",
      "Epoch 143, Loss: 0.4147987298190057\n",
      "Epoch 144, Loss: 0.41419399620638614\n",
      "Epoch 145, Loss: 0.4135810824458581\n",
      "Epoch 146, Loss: 0.41298409146618886\n",
      "Epoch 147, Loss: 0.41243006445732766\n",
      "Epoch 148, Loss: 0.4118989524765012\n",
      "Epoch 149, Loss: 0.4114025255173018\n",
      "Epoch 150, Loss: 0.41099078336995\n",
      "Epoch 151, Loss: 0.41081508220010227\n",
      "Epoch 152, Loss: 0.41095537719712777\n",
      "Epoch 153, Loss: 0.4103804202783551\n",
      "Epoch 154, Loss: 0.4090202221103308\n",
      "Epoch 155, Loss: 0.40802739207326955\n",
      "Epoch 156, Loss: 0.40804683851095463\n",
      "Epoch 157, Loss: 0.407920118725788\n",
      "Epoch 158, Loss: 0.4068781141815312\n",
      "Epoch 159, Loss: 0.4060505964505198\n",
      "Epoch 160, Loss: 0.4059774695108897\n",
      "Epoch 161, Loss: 0.4058383176185497\n",
      "Epoch 162, Loss: 0.4052028180836368\n",
      "Epoch 163, Loss: 0.40429709614181\n",
      "Epoch 164, Loss: 0.40384093665938\n",
      "Epoch 165, Loss: 0.40376927323887396\n",
      "Epoch 166, Loss: 0.403702543233222\n",
      "Epoch 167, Loss: 0.40334951742991476\n",
      "Epoch 168, Loss: 0.40245593460618273\n",
      "Epoch 169, Loss: 0.4016582797818415\n",
      "Epoch 170, Loss: 0.40137398150186204\n",
      "Epoch 171, Loss: 0.4013689138556338\n",
      "Epoch 172, Loss: 0.4012695527883242\n",
      "Epoch 173, Loss: 0.4007140551300007\n",
      "Epoch 174, Loss: 0.3998966426233382\n",
      "Epoch 175, Loss: 0.39923653236395396\n",
      "Epoch 176, Loss: 0.39903649949677683\n",
      "Epoch 177, Loss: 0.39917098578914983\n",
      "Epoch 178, Loss: 0.39929648909664894\n",
      "Epoch 179, Loss: 0.3989811908990009\n",
      "Epoch 180, Loss: 0.3979898256518184\n",
      "Epoch 181, Loss: 0.397024960608811\n",
      "Epoch 182, Loss: 0.39668781717328905\n",
      "Epoch 183, Loss: 0.3968538901955066\n",
      "Epoch 184, Loss: 0.3970587380181638\n",
      "Epoch 185, Loss: 0.39674143608768325\n",
      "Epoch 186, Loss: 0.3959145985387862\n",
      "Epoch 187, Loss: 0.3949624151142419\n",
      "Epoch 188, Loss: 0.39443828885031734\n",
      "Epoch 189, Loss: 0.3944725899475075\n",
      "Epoch 190, Loss: 0.39463563048164074\n",
      "Epoch 191, Loss: 0.3945684887525064\n",
      "Epoch 192, Loss: 0.39425420948628404\n",
      "Epoch 193, Loss: 0.3935345817333399\n",
      "Epoch 194, Loss: 0.39264657481880805\n",
      "Epoch 195, Loss: 0.392193164252606\n",
      "Epoch 196, Loss: 0.3921843684402003\n",
      "Epoch 197, Loss: 0.3923193425008284\n",
      "Epoch 198, Loss: 0.39241498907306754\n",
      "Epoch 199, Loss: 0.39239457807280204\n",
      "Epoch 200, Loss: 0.39203104644806597\n",
      "Epoch 201, Loss: 0.3912999806456996\n",
      "Epoch 202, Loss: 0.39050029671470904\n",
      "Epoch 203, Loss: 0.3900149922973836\n",
      "Epoch 204, Loss: 0.39007755064812183\n",
      "Epoch 205, Loss: 0.390188240020016\n",
      "Epoch 206, Loss: 0.3902829961872829\n",
      "Epoch 207, Loss: 0.3902862415078523\n",
      "Epoch 208, Loss: 0.3899267058702846\n",
      "Epoch 209, Loss: 0.3892649242710398\n",
      "Epoch 210, Loss: 0.3885742141482038\n",
      "Epoch 211, Loss: 0.38800966216867433\n",
      "Epoch 212, Loss: 0.3877653351782016\n",
      "Epoch 213, Loss: 0.3879377630351794\n",
      "Epoch 214, Loss: 0.3883843436662645\n",
      "Epoch 215, Loss: 0.3893164843620092\n",
      "Epoch 216, Loss: 0.39036748027002277\n",
      "Epoch 217, Loss: 0.389534630085602\n",
      "Epoch 218, Loss: 0.3871458565683007\n",
      "Epoch 219, Loss: 0.38628069795757786\n",
      "Epoch 220, Loss: 0.38750128130547123\n",
      "Epoch 221, Loss: 0.3881363750025604\n",
      "Epoch 222, Loss: 0.3862570308613277\n",
      "Epoch 223, Loss: 0.38515971184155506\n",
      "Epoch 224, Loss: 0.3858834889105007\n",
      "Epoch 225, Loss: 0.38602605104987037\n",
      "Epoch 226, Loss: 0.38513845205291786\n",
      "Epoch 227, Loss: 0.3842280742852637\n",
      "Epoch 228, Loss: 0.384211882428648\n",
      "Epoch 229, Loss: 0.38483923967872563\n",
      "Epoch 230, Loss: 0.3850985408362057\n",
      "Epoch 231, Loss: 0.38448015263356167\n",
      "Epoch 232, Loss: 0.3834370947775841\n",
      "Epoch 233, Loss: 0.3826009009859152\n",
      "Epoch 234, Loss: 0.3823477395570148\n",
      "Epoch 235, Loss: 0.3826401380867403\n",
      "Epoch 236, Loss: 0.38317373320526366\n",
      "Epoch 237, Loss: 0.38376062108230946\n",
      "Epoch 238, Loss: 0.38435448304910663\n",
      "Epoch 239, Loss: 0.3835195706619701\n",
      "Epoch 240, Loss: 0.3815245273137475\n",
      "Epoch 241, Loss: 0.38029588927931907\n",
      "Epoch 242, Loss: 0.38039028917487006\n",
      "Epoch 243, Loss: 0.3814254466488072\n",
      "Epoch 244, Loss: 0.38226438714315614\n",
      "Epoch 245, Loss: 0.38220538439823026\n",
      "Epoch 246, Loss: 0.3804858405565259\n",
      "Epoch 247, Loss: 0.37890210100242333\n",
      "Epoch 248, Loss: 0.3783137220951888\n",
      "Epoch 249, Loss: 0.37883468817345395\n",
      "Epoch 250, Loss: 0.3797710813355198\n",
      "Epoch 251, Loss: 0.380290521160574\n",
      "Epoch 252, Loss: 0.3799605890591878\n",
      "Epoch 253, Loss: 0.3781087091577915\n",
      "Epoch 254, Loss: 0.3767289003755435\n",
      "Epoch 255, Loss: 0.3766083400572665\n",
      "Epoch 256, Loss: 0.37763413496689713\n",
      "Epoch 257, Loss: 0.37924867082085034\n",
      "Epoch 258, Loss: 0.37964689485040454\n",
      "Epoch 259, Loss: 0.3777663397849494\n",
      "Epoch 260, Loss: 0.37560553140061015\n",
      "Epoch 261, Loss: 0.3747196142705081\n",
      "Epoch 262, Loss: 0.3755710148537257\n",
      "Epoch 263, Loss: 0.377510607298819\n",
      "Epoch 264, Loss: 0.37840767138837395\n",
      "Epoch 265, Loss: 0.3760957405154935\n",
      "Epoch 266, Loss: 0.3737877284817606\n",
      "Epoch 267, Loss: 0.3735418181978434\n",
      "Epoch 268, Loss: 0.37510288337177966\n",
      "Epoch 269, Loss: 0.3760653898658429\n",
      "Epoch 270, Loss: 0.37534596458355324\n",
      "Epoch 271, Loss: 0.37261482504357585\n",
      "Epoch 272, Loss: 0.37200746981750427\n",
      "Epoch 273, Loss: 0.3723016855520885\n",
      "Epoch 274, Loss: 0.37288824173768914\n",
      "Epoch 275, Loss: 0.3745275740270008\n",
      "Epoch 276, Loss: 0.37383048157462384\n",
      "Epoch 277, Loss: 0.37214878085863234\n",
      "Epoch 278, Loss: 0.3708954733137028\n",
      "Epoch 279, Loss: 0.3696828220809899\n",
      "Epoch 280, Loss: 0.3696121756270759\n",
      "Epoch 281, Loss: 0.3703872178747134\n",
      "Epoch 282, Loss: 0.3720778817435658\n",
      "Epoch 283, Loss: 0.37487339823203514\n",
      "Epoch 284, Loss: 0.37461674497035313\n",
      "Epoch 285, Loss: 0.37087078423284897\n",
      "Epoch 286, Loss: 0.36874859292359946\n",
      "Epoch 287, Loss: 0.3682249509614146\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2581134685794029\n",
      "Test R^2 score: 0.28413191754075323\n",
      "Num of epochs: 288\n",
      "Epoch 1, Loss: 0.5840487492525986\n",
      "Epoch 2, Loss: 0.5823603985870505\n",
      "Epoch 3, Loss: 0.5807128156974511\n",
      "Epoch 4, Loss: 0.5791048303933275\n",
      "Epoch 5, Loss: 0.5775405661879758\n",
      "Epoch 6, Loss: 0.5760294075386292\n",
      "Epoch 7, Loss: 0.5746422587722417\n",
      "Epoch 8, Loss: 0.5734084244094927\n",
      "Epoch 9, Loss: 0.5722011751200193\n",
      "Epoch 10, Loss: 0.5710258203437364\n",
      "Epoch 11, Loss: 0.5698853813760384\n",
      "Epoch 12, Loss: 0.5687816139489557\n",
      "Epoch 13, Loss: 0.5677163068112265\n",
      "Epoch 14, Loss: 0.5666921748936887\n",
      "Epoch 15, Loss: 0.5657104954465276\n",
      "Epoch 16, Loss: 0.5647684028568781\n",
      "Epoch 17, Loss: 0.5638831405576329\n",
      "Epoch 18, Loss: 0.5630389386799808\n",
      "Epoch 19, Loss: 0.5622280311074971\n",
      "Epoch 20, Loss: 0.5614486777254447\n",
      "Epoch 21, Loss: 0.5606952696769932\n",
      "Epoch 22, Loss: 0.5600080658553173\n",
      "Epoch 23, Loss: 0.5593324325390967\n",
      "Epoch 24, Loss: 0.5586284813387259\n",
      "Epoch 25, Loss: 0.5579018742958061\n",
      "Epoch 26, Loss: 0.5571581124917492\n",
      "Epoch 27, Loss: 0.5563963236856668\n",
      "Epoch 28, Loss: 0.5555782151237042\n",
      "Epoch 29, Loss: 0.5546849747721183\n",
      "Epoch 30, Loss: 0.5536788043028178\n",
      "Epoch 31, Loss: 0.5525591137707536\n",
      "Epoch 32, Loss: 0.5513009669731512\n",
      "Epoch 33, Loss: 0.5498960158279192\n",
      "Epoch 34, Loss: 0.5483476701077721\n",
      "Epoch 35, Loss: 0.5465239896997123\n",
      "Epoch 36, Loss: 0.5443095386620365\n",
      "Epoch 37, Loss: 0.541698396804871\n",
      "Epoch 38, Loss: 0.5387360786975969\n",
      "Epoch 39, Loss: 0.5353445571056952\n",
      "Epoch 40, Loss: 0.5314309148720302\n",
      "Epoch 41, Loss: 0.5269719826708242\n",
      "Epoch 42, Loss: 0.521969144861099\n",
      "Epoch 43, Loss: 0.5163612888633274\n",
      "Epoch 44, Loss: 0.510198884032497\n",
      "Epoch 45, Loss: 0.5036853335597026\n",
      "Epoch 46, Loss: 0.497507438987438\n",
      "Epoch 47, Loss: 0.4933018406946735\n",
      "Epoch 48, Loss: 0.4930066452332934\n",
      "Epoch 49, Loss: 0.4945905845686856\n",
      "Epoch 50, Loss: 0.4936680701643891\n",
      "Epoch 51, Loss: 0.49060441295899404\n",
      "Epoch 52, Loss: 0.4879085797074857\n",
      "Epoch 53, Loss: 0.48654908212573794\n",
      "Epoch 54, Loss: 0.48436906257189793\n",
      "Epoch 55, Loss: 0.4811370357852411\n",
      "Epoch 56, Loss: 0.4784293739281566\n",
      "Epoch 57, Loss: 0.47711164072615936\n",
      "Epoch 58, Loss: 0.4766271734910935\n",
      "Epoch 59, Loss: 0.47612600191631343\n",
      "Epoch 60, Loss: 0.4750325392570138\n",
      "Epoch 61, Loss: 0.4733184872597024\n",
      "Epoch 62, Loss: 0.47140093478303136\n",
      "Epoch 63, Loss: 0.46974031424269036\n",
      "Epoch 64, Loss: 0.4685882925216295\n",
      "Epoch 65, Loss: 0.46777230662804486\n",
      "Epoch 66, Loss: 0.46698409280498177\n",
      "Epoch 67, Loss: 0.4660708795167375\n",
      "Epoch 68, Loss: 0.46512574369724263\n",
      "Epoch 69, Loss: 0.464394568753621\n",
      "Epoch 70, Loss: 0.46391292948811014\n",
      "Epoch 71, Loss: 0.4634049531873611\n",
      "Epoch 72, Loss: 0.46267413456807477\n",
      "Epoch 73, Loss: 0.46183276116234645\n",
      "Epoch 74, Loss: 0.46115175213952947\n",
      "Epoch 75, Loss: 0.46074635373213224\n",
      "Epoch 76, Loss: 0.46039515447921114\n",
      "Epoch 77, Loss: 0.45982157869905305\n",
      "Epoch 78, Loss: 0.4590375828845979\n",
      "Epoch 79, Loss: 0.4582952479953686\n",
      "Epoch 80, Loss: 0.4577229799622235\n",
      "Epoch 81, Loss: 0.457245442335921\n",
      "Epoch 82, Loss: 0.45670070269304863\n",
      "Epoch 83, Loss: 0.4561256990550218\n",
      "Epoch 84, Loss: 0.4555860803409782\n",
      "Epoch 85, Loss: 0.45502648449415584\n",
      "Epoch 86, Loss: 0.4544002576049474\n",
      "Epoch 87, Loss: 0.45383337161327475\n",
      "Epoch 88, Loss: 0.4533725752774869\n",
      "Epoch 89, Loss: 0.45289120726575105\n",
      "Epoch 90, Loss: 0.45229841344408783\n",
      "Epoch 91, Loss: 0.4517107136241441\n",
      "Epoch 92, Loss: 0.4511833354600812\n",
      "Epoch 93, Loss: 0.45062862238704443\n",
      "Epoch 94, Loss: 0.4500796154906681\n",
      "Epoch 95, Loss: 0.44955383739931676\n",
      "Epoch 96, Loss: 0.44895346728149105\n",
      "Epoch 97, Loss: 0.448326202696898\n",
      "Epoch 98, Loss: 0.44774894753209415\n",
      "Epoch 99, Loss: 0.4471785781311564\n",
      "Epoch 100, Loss: 0.4465554608803985\n",
      "Epoch 101, Loss: 0.44593087143973836\n",
      "Epoch 102, Loss: 0.4452917027218069\n",
      "Epoch 103, Loss: 0.4446386961651979\n",
      "Epoch 104, Loss: 0.4440147161042545\n",
      "Epoch 105, Loss: 0.44336340814176034\n",
      "Epoch 106, Loss: 0.4426807638073487\n",
      "Epoch 107, Loss: 0.4420047011481428\n",
      "Epoch 108, Loss: 0.441309386571521\n",
      "Epoch 109, Loss: 0.44060785111407585\n",
      "Epoch 110, Loss: 0.43987311744558105\n",
      "Epoch 111, Loss: 0.43911967872459845\n",
      "Epoch 112, Loss: 0.438403422961133\n",
      "Epoch 113, Loss: 0.43769207212311695\n",
      "Epoch 114, Loss: 0.4369625809817912\n",
      "Epoch 115, Loss: 0.4362247477767524\n",
      "Epoch 116, Loss: 0.4354898389754293\n",
      "Epoch 117, Loss: 0.43474241127906293\n",
      "Epoch 118, Loss: 0.43401091500479555\n",
      "Epoch 119, Loss: 0.43331322745605044\n",
      "Epoch 120, Loss: 0.432620718018052\n",
      "Epoch 121, Loss: 0.4319382068957778\n",
      "Epoch 122, Loss: 0.43126277006287944\n",
      "Epoch 123, Loss: 0.43059238174656295\n",
      "Epoch 124, Loss: 0.4299263203782918\n",
      "Epoch 125, Loss: 0.42928322934373825\n",
      "Epoch 126, Loss: 0.4286481598442909\n",
      "Epoch 127, Loss: 0.42802804071716477\n",
      "Epoch 128, Loss: 0.4274214902250984\n",
      "Epoch 129, Loss: 0.42681615504862863\n",
      "Epoch 130, Loss: 0.4262204311272528\n",
      "Epoch 131, Loss: 0.42564325108657486\n",
      "Epoch 132, Loss: 0.4251589120363048\n",
      "Epoch 133, Loss: 0.4250462163311396\n",
      "Epoch 134, Loss: 0.42519706056346784\n",
      "Epoch 135, Loss: 0.42456337224229707\n",
      "Epoch 136, Loss: 0.42309140634088377\n",
      "Epoch 137, Loss: 0.4237761927136174\n",
      "Epoch 138, Loss: 0.4226235530425707\n",
      "Epoch 139, Loss: 0.4220742885220503\n",
      "Epoch 140, Loss: 0.42211910532415625\n",
      "Epoch 141, Loss: 0.42085322515605406\n",
      "Epoch 142, Loss: 0.42111805720053974\n",
      "Epoch 143, Loss: 0.4200951684406979\n",
      "Epoch 144, Loss: 0.41998638278593803\n",
      "Epoch 145, Loss: 0.4195824959426802\n",
      "Epoch 146, Loss: 0.4189124105556125\n",
      "Epoch 147, Loss: 0.4189010632317282\n",
      "Epoch 148, Loss: 0.4180719658157386\n",
      "Epoch 149, Loss: 0.4179677695860015\n",
      "Epoch 150, Loss: 0.4174500392955835\n",
      "Epoch 151, Loss: 0.4169717645222403\n",
      "Epoch 152, Loss: 0.416768945618028\n",
      "Epoch 153, Loss: 0.4161308021679475\n",
      "Epoch 154, Loss: 0.4159503760232841\n",
      "Epoch 155, Loss: 0.41548204903552094\n",
      "Epoch 156, Loss: 0.4150011292120496\n",
      "Epoch 157, Loss: 0.41478775494217646\n",
      "Epoch 158, Loss: 0.414293548610914\n",
      "Epoch 159, Loss: 0.41385845338931443\n",
      "Epoch 160, Loss: 0.4136210913820755\n",
      "Epoch 161, Loss: 0.4132119025042635\n",
      "Epoch 162, Loss: 0.41271526759620836\n",
      "Epoch 163, Loss: 0.4123954503185359\n",
      "Epoch 164, Loss: 0.4120947487210736\n",
      "Epoch 165, Loss: 0.41164636138434757\n",
      "Epoch 166, Loss: 0.4111821015956402\n",
      "Epoch 167, Loss: 0.4107918854820648\n",
      "Epoch 168, Loss: 0.41046381726330505\n",
      "Epoch 169, Loss: 0.41021887891448744\n",
      "Epoch 170, Loss: 0.4099167078883758\n",
      "Epoch 171, Loss: 0.4096185338380407\n",
      "Epoch 172, Loss: 0.40916685025055\n",
      "Epoch 173, Loss: 0.40866748735263514\n",
      "Epoch 174, Loss: 0.4081466854812792\n",
      "Epoch 175, Loss: 0.4076813461339856\n",
      "Epoch 176, Loss: 0.4072597682231001\n",
      "Epoch 177, Loss: 0.40688576834942036\n",
      "Epoch 178, Loss: 0.40661844638288996\n",
      "Epoch 179, Loss: 0.40678927501467854\n",
      "Epoch 180, Loss: 0.40714865106150483\n",
      "Epoch 181, Loss: 0.407438063185622\n",
      "Epoch 182, Loss: 0.40550383487680175\n",
      "Epoch 183, Loss: 0.4042755342462652\n",
      "Epoch 184, Loss: 0.4046435137081916\n",
      "Epoch 185, Loss: 0.4046943848072148\n",
      "Epoch 186, Loss: 0.40361494335807924\n",
      "Epoch 187, Loss: 0.4026118191003719\n",
      "Epoch 188, Loss: 0.40278360711552735\n",
      "Epoch 189, Loss: 0.4027233000156603\n",
      "Epoch 190, Loss: 0.40153316212514345\n",
      "Epoch 191, Loss: 0.40079087511666506\n",
      "Epoch 192, Loss: 0.4008076426718671\n",
      "Epoch 193, Loss: 0.4007751665155582\n",
      "Epoch 194, Loss: 0.400341719455109\n",
      "Epoch 195, Loss: 0.3992168247303384\n",
      "Epoch 196, Loss: 0.39833961481198604\n",
      "Epoch 197, Loss: 0.39812794047995953\n",
      "Epoch 198, Loss: 0.39833692141370663\n",
      "Epoch 199, Loss: 0.39871210097536247\n",
      "Epoch 200, Loss: 0.39784750545420083\n",
      "Epoch 201, Loss: 0.3966587979607465\n",
      "Epoch 202, Loss: 0.39555654343284935\n",
      "Epoch 203, Loss: 0.3952726442050296\n",
      "Epoch 204, Loss: 0.39538297213520046\n",
      "Epoch 205, Loss: 0.39548968991803907\n",
      "Epoch 206, Loss: 0.39497843034617514\n",
      "Epoch 207, Loss: 0.3940338927858115\n",
      "Epoch 208, Loss: 0.392919174009692\n",
      "Epoch 209, Loss: 0.3923571329937281\n",
      "Epoch 210, Loss: 0.3923490054964675\n",
      "Epoch 211, Loss: 0.3926571059606644\n",
      "Epoch 212, Loss: 0.3931217889093639\n",
      "Epoch 213, Loss: 0.39318851446076347\n",
      "Epoch 214, Loss: 0.3914982381150122\n",
      "Epoch 215, Loss: 0.38979359841220623\n",
      "Epoch 216, Loss: 0.38936277544845305\n",
      "Epoch 217, Loss: 0.38989603689590807\n",
      "Epoch 218, Loss: 0.39054494037366483\n",
      "Epoch 219, Loss: 0.3895661116514781\n",
      "Epoch 220, Loss: 0.3880894576797602\n",
      "Epoch 221, Loss: 0.38701152315406756\n",
      "Epoch 222, Loss: 0.3869496436514115\n",
      "Epoch 223, Loss: 0.38758504534192695\n",
      "Epoch 224, Loss: 0.388096618505361\n",
      "Epoch 225, Loss: 0.3882973558244019\n",
      "Epoch 226, Loss: 0.3862842855081935\n",
      "Epoch 227, Loss: 0.38458879154226633\n",
      "Epoch 228, Loss: 0.3843507611765544\n",
      "Epoch 229, Loss: 0.3852574646837404\n",
      "Epoch 230, Loss: 0.38614019793025783\n",
      "Epoch 231, Loss: 0.38505057612679305\n",
      "Epoch 232, Loss: 0.38306566547486914\n",
      "Epoch 233, Loss: 0.38192691353340213\n",
      "Epoch 234, Loss: 0.381915832902477\n",
      "Epoch 235, Loss: 0.3824724516578425\n",
      "Epoch 236, Loss: 0.382951127467455\n",
      "Epoch 237, Loss: 0.38287479516577155\n",
      "Epoch 238, Loss: 0.38155661119920325\n",
      "Epoch 239, Loss: 0.3801123898655882\n",
      "Epoch 240, Loss: 0.3790751798353477\n",
      "Epoch 241, Loss: 0.37876336854689263\n",
      "Epoch 242, Loss: 0.3793379104369683\n",
      "Epoch 243, Loss: 0.38024069591729004\n",
      "Epoch 244, Loss: 0.3818489716395494\n",
      "Epoch 245, Loss: 0.3813269850126333\n",
      "Epoch 246, Loss: 0.3794887430660036\n",
      "Epoch 247, Loss: 0.37659633136270065\n",
      "Epoch 248, Loss: 0.37631877831336363\n",
      "Epoch 249, Loss: 0.37760353307561223\n",
      "Epoch 250, Loss: 0.3785497620486226\n",
      "Epoch 251, Loss: 0.3775220935242572\n",
      "Epoch 252, Loss: 0.37497482612672467\n",
      "Epoch 253, Loss: 0.37391224694932573\n",
      "Epoch 254, Loss: 0.3742860713602659\n",
      "Epoch 255, Loss: 0.3754970514788722\n",
      "Epoch 256, Loss: 0.3774427288076663\n",
      "Epoch 257, Loss: 0.3756527782203913\n",
      "Epoch 258, Loss: 0.37365599030443153\n",
      "Epoch 259, Loss: 0.3717330445294704\n",
      "Epoch 260, Loss: 0.3714979079034871\n",
      "Epoch 261, Loss: 0.37271117039612295\n",
      "Epoch 262, Loss: 0.3746558636886001\n",
      "Epoch 263, Loss: 0.37746388910010625\n",
      "Epoch 264, Loss: 0.37280531247189974\n",
      "Epoch 265, Loss: 0.3698401105965171\n",
      "Epoch 266, Loss: 0.3698235104062751\n",
      "Epoch 267, Loss: 0.37171179852714353\n",
      "Epoch 268, Loss: 0.37519346650765134\n",
      "Epoch 269, Loss: 0.3717318820437655\n",
      "Epoch 270, Loss: 0.3688192229841988\n",
      "Epoch 271, Loss: 0.36798854458772495\n",
      "Epoch 272, Loss: 0.369257529987117\n",
      "Epoch 273, Loss: 0.37176499142077946\n",
      "Epoch 274, Loss: 0.3707147972271144\n",
      "Epoch 275, Loss: 0.36954101162491576\n",
      "Epoch 276, Loss: 0.3670818907456444\n",
      "Epoch 277, Loss: 0.3660647087610194\n",
      "Epoch 278, Loss: 0.3665441192675568\n",
      "Epoch 279, Loss: 0.36795582434757407\n",
      "Epoch 280, Loss: 0.37116074208348915\n",
      "Epoch 281, Loss: 0.3709797533518036\n",
      "Epoch 282, Loss: 0.36906149687214834\n",
      "Epoch 283, Loss: 0.36528418706163013\n",
      "Epoch 284, Loss: 0.3648263416588972\n",
      "Epoch 285, Loss: 0.36745268802622516\n",
      "Epoch 286, Loss: 0.368560577491066\n",
      "Epoch 287, Loss: 0.3675781160814728\n",
      "Epoch 288, Loss: 0.3644340027661131\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2527276262687921\n",
      "Test R^2 score: 0.3068929387911665\n",
      "Num of epochs: 289\n",
      "Epoch 1, Loss: 0.5870830019816142\n",
      "Epoch 2, Loss: 0.5851122576037732\n",
      "Epoch 3, Loss: 0.5832054787120093\n",
      "Epoch 4, Loss: 0.5813638585871983\n",
      "Epoch 5, Loss: 0.5795819507758816\n",
      "Epoch 6, Loss: 0.5778626542634355\n",
      "Epoch 7, Loss: 0.5762058571314883\n",
      "Epoch 8, Loss: 0.574611866606517\n",
      "Epoch 9, Loss: 0.5730811287615335\n",
      "Epoch 10, Loss: 0.571614829536217\n",
      "Epoch 11, Loss: 0.5702153475851142\n",
      "Epoch 12, Loss: 0.5688934962585674\n",
      "Epoch 13, Loss: 0.567640630085563\n",
      "Epoch 14, Loss: 0.5664580485895172\n",
      "Epoch 15, Loss: 0.5653474316366668\n",
      "Epoch 16, Loss: 0.5643072500784245\n",
      "Epoch 17, Loss: 0.5633352753739298\n",
      "Epoch 18, Loss: 0.5624409220718879\n",
      "Epoch 19, Loss: 0.5616055635849829\n",
      "Epoch 20, Loss: 0.5608386300598753\n",
      "Epoch 21, Loss: 0.5601416262708919\n",
      "Epoch 22, Loss: 0.5595133221483095\n",
      "Epoch 23, Loss: 0.558952483114461\n",
      "Epoch 24, Loss: 0.5584570977647189\n",
      "Epoch 25, Loss: 0.5580256047014291\n",
      "Epoch 26, Loss: 0.5576530485096037\n",
      "Epoch 27, Loss: 0.557338665082668\n",
      "Epoch 28, Loss: 0.5570817237018545\n",
      "Epoch 29, Loss: 0.556875641048589\n",
      "Epoch 30, Loss: 0.5567128720161902\n",
      "Epoch 31, Loss: 0.5565903758072618\n",
      "Epoch 32, Loss: 0.556512918378901\n",
      "Epoch 33, Loss: 0.5564495093206456\n",
      "Epoch 34, Loss: 0.556381647197548\n",
      "Epoch 35, Loss: 0.5563035178424202\n",
      "Epoch 36, Loss: 0.556204668619602\n",
      "Epoch 37, Loss: 0.5560857047999346\n",
      "Epoch 38, Loss: 0.5559380095695575\n",
      "Epoch 39, Loss: 0.5557471080864377\n",
      "Epoch 40, Loss: 0.555502843011745\n",
      "Epoch 41, Loss: 0.5551987293503015\n",
      "Epoch 42, Loss: 0.554837434948128\n",
      "Epoch 43, Loss: 0.5544198962227014\n",
      "Epoch 44, Loss: 0.5539432152814058\n",
      "Epoch 45, Loss: 0.5533706184353336\n",
      "Epoch 46, Loss: 0.5526480455682036\n",
      "Epoch 47, Loss: 0.5517359636420065\n",
      "Epoch 48, Loss: 0.5506263948091643\n",
      "Epoch 49, Loss: 0.5493001299671997\n",
      "Epoch 50, Loss: 0.5476879616778625\n",
      "Epoch 51, Loss: 0.5456994091390746\n",
      "Epoch 52, Loss: 0.5432319552044298\n",
      "Epoch 53, Loss: 0.540197173387165\n",
      "Epoch 54, Loss: 0.5365840770668688\n",
      "Epoch 55, Loss: 0.5321330697072997\n",
      "Epoch 56, Loss: 0.5265998679918268\n",
      "Epoch 57, Loss: 0.520084803250267\n",
      "Epoch 58, Loss: 0.5130706575730084\n",
      "Epoch 59, Loss: 0.5065642347076666\n",
      "Epoch 60, Loss: 0.5008642654525304\n",
      "Epoch 61, Loss: 0.49566227629612764\n",
      "Epoch 62, Loss: 0.4923203909564705\n",
      "Epoch 63, Loss: 0.4924301729951094\n",
      "Epoch 64, Loss: 0.49269878231681646\n",
      "Epoch 65, Loss: 0.4902521867289934\n",
      "Epoch 66, Loss: 0.48613421086270764\n",
      "Epoch 67, Loss: 0.4823620716664745\n",
      "Epoch 68, Loss: 0.4801736561245429\n",
      "Epoch 69, Loss: 0.4795127600084859\n",
      "Epoch 70, Loss: 0.47956078498998017\n",
      "Epoch 71, Loss: 0.4794724843003416\n",
      "Epoch 72, Loss: 0.4788506561171637\n",
      "Epoch 73, Loss: 0.47770552279043044\n",
      "Epoch 74, Loss: 0.47622961393663765\n",
      "Epoch 75, Loss: 0.47464177527330514\n",
      "Epoch 76, Loss: 0.47306367952973627\n",
      "Epoch 77, Loss: 0.47147290611698206\n",
      "Epoch 78, Loss: 0.47006443426613986\n",
      "Epoch 79, Loss: 0.46905483824122735\n",
      "Epoch 80, Loss: 0.46823971311794244\n",
      "Epoch 81, Loss: 0.46717865147711235\n",
      "Epoch 82, Loss: 0.4659101131738837\n",
      "Epoch 83, Loss: 0.4646419600058905\n",
      "Epoch 84, Loss: 0.46352143904310505\n",
      "Epoch 85, Loss: 0.4628074184914062\n",
      "Epoch 86, Loss: 0.4624392243997755\n",
      "Epoch 87, Loss: 0.4619621267978703\n",
      "Epoch 88, Loss: 0.4612398126040571\n",
      "Epoch 89, Loss: 0.4603978732173046\n",
      "Epoch 90, Loss: 0.45947273732751176\n",
      "Epoch 91, Loss: 0.4586586466008825\n",
      "Epoch 92, Loss: 0.4581411204292624\n",
      "Epoch 93, Loss: 0.4575843887199986\n",
      "Epoch 94, Loss: 0.45683695257693047\n",
      "Epoch 95, Loss: 0.4560226167760752\n",
      "Epoch 96, Loss: 0.45518197769697494\n",
      "Epoch 97, Loss: 0.4544540349916132\n",
      "Epoch 98, Loss: 0.45391691001678736\n",
      "Epoch 99, Loss: 0.45339453014465836\n",
      "Epoch 100, Loss: 0.4528108033647995\n",
      "Epoch 101, Loss: 0.45215931296400313\n",
      "Epoch 102, Loss: 0.4513923964812454\n",
      "Epoch 103, Loss: 0.45065879546906024\n",
      "Epoch 104, Loss: 0.4499679951412753\n",
      "Epoch 105, Loss: 0.4492475583334385\n",
      "Epoch 106, Loss: 0.44847627731299555\n",
      "Epoch 107, Loss: 0.44757627335317035\n",
      "Epoch 108, Loss: 0.44667180383394584\n",
      "Epoch 109, Loss: 0.4459134280224336\n",
      "Epoch 110, Loss: 0.445138462256222\n",
      "Epoch 111, Loss: 0.4442799627238875\n",
      "Epoch 112, Loss: 0.4434760524128904\n",
      "Epoch 113, Loss: 0.44278589205058877\n",
      "Epoch 114, Loss: 0.4420899522838961\n",
      "Epoch 115, Loss: 0.4413170513398663\n",
      "Epoch 116, Loss: 0.44062403347369306\n",
      "Epoch 117, Loss: 0.4399921925621498\n",
      "Epoch 118, Loss: 0.4392964910471265\n",
      "Epoch 119, Loss: 0.4385682925510028\n",
      "Epoch 120, Loss: 0.4378958341916508\n",
      "Epoch 121, Loss: 0.43725415543096946\n",
      "Epoch 122, Loss: 0.4365992128285587\n",
      "Epoch 123, Loss: 0.43599624716495383\n",
      "Epoch 124, Loss: 0.4353811521815592\n",
      "Epoch 125, Loss: 0.43469291414883454\n",
      "Epoch 126, Loss: 0.4340220046189261\n",
      "Epoch 127, Loss: 0.43333659407721536\n",
      "Epoch 128, Loss: 0.43266599220557367\n",
      "Epoch 129, Loss: 0.4321227164821964\n",
      "Epoch 130, Loss: 0.4318519006174303\n",
      "Epoch 131, Loss: 0.431758847164211\n",
      "Epoch 132, Loss: 0.43075828646008285\n",
      "Epoch 133, Loss: 0.42951068708226425\n",
      "Epoch 134, Loss: 0.429857133846272\n",
      "Epoch 135, Loss: 0.4290381293102675\n",
      "Epoch 136, Loss: 0.42759211016380044\n",
      "Epoch 137, Loss: 0.4280200509405919\n",
      "Epoch 138, Loss: 0.4268394933262516\n",
      "Epoch 139, Loss: 0.42623882030133897\n",
      "Epoch 140, Loss: 0.42606961695695117\n",
      "Epoch 141, Loss: 0.42484051783497734\n",
      "Epoch 142, Loss: 0.4246703538387748\n",
      "Epoch 143, Loss: 0.423957998180335\n",
      "Epoch 144, Loss: 0.42324564060550574\n",
      "Epoch 145, Loss: 0.4229486014926011\n",
      "Epoch 146, Loss: 0.42227080109958876\n",
      "Epoch 147, Loss: 0.42167142972153343\n",
      "Epoch 148, Loss: 0.4213068633370933\n",
      "Epoch 149, Loss: 0.42083520259379087\n",
      "Epoch 150, Loss: 0.4201660510899353\n",
      "Epoch 151, Loss: 0.41966253744663834\n",
      "Epoch 152, Loss: 0.4193082362327936\n",
      "Epoch 153, Loss: 0.4189423069701613\n",
      "Epoch 154, Loss: 0.41838199472407106\n",
      "Epoch 155, Loss: 0.4177102332258262\n",
      "Epoch 156, Loss: 0.4170771563615935\n",
      "Epoch 157, Loss: 0.41654111242084135\n",
      "Epoch 158, Loss: 0.4160036434543596\n",
      "Epoch 159, Loss: 0.41555185391390403\n",
      "Epoch 160, Loss: 0.4151224748155016\n",
      "Epoch 161, Loss: 0.41489720332425273\n",
      "Epoch 162, Loss: 0.41501689178490614\n",
      "Epoch 163, Loss: 0.4150087412809789\n",
      "Epoch 164, Loss: 0.41477848624391667\n",
      "Epoch 165, Loss: 0.41261289669984963\n",
      "Epoch 166, Loss: 0.4124807880724965\n",
      "Epoch 167, Loss: 0.413629359292939\n",
      "Epoch 168, Loss: 0.411900128218864\n",
      "Epoch 169, Loss: 0.4107323370100173\n",
      "Epoch 170, Loss: 0.4110345247263372\n",
      "Epoch 171, Loss: 0.41052964788674395\n",
      "Epoch 172, Loss: 0.409413364301708\n",
      "Epoch 173, Loss: 0.4089733322678526\n",
      "Epoch 174, Loss: 0.4089799088286151\n",
      "Epoch 175, Loss: 0.408588665407247\n",
      "Epoch 176, Loss: 0.40772542425806385\n",
      "Epoch 177, Loss: 0.40718471760359093\n",
      "Epoch 178, Loss: 0.4071616068385233\n",
      "Epoch 179, Loss: 0.4070544897023747\n",
      "Epoch 180, Loss: 0.4066907985489586\n",
      "Epoch 181, Loss: 0.4059138557942652\n",
      "Epoch 182, Loss: 0.40525560454694315\n",
      "Epoch 183, Loss: 0.40475680961794624\n",
      "Epoch 184, Loss: 0.40450233730400054\n",
      "Epoch 185, Loss: 0.4045646075849886\n",
      "Epoch 186, Loss: 0.40475771158681695\n",
      "Epoch 187, Loss: 0.4052971706565044\n",
      "Epoch 188, Loss: 0.40413920695957406\n",
      "Epoch 189, Loss: 0.40300352203164763\n",
      "Epoch 190, Loss: 0.40217081075333594\n",
      "Epoch 191, Loss: 0.40216832827361676\n",
      "Epoch 192, Loss: 0.4025016030581757\n",
      "Epoch 193, Loss: 0.4022015440651815\n",
      "Epoch 194, Loss: 0.4016657180827694\n",
      "Epoch 195, Loss: 0.40058655945698457\n",
      "Epoch 196, Loss: 0.40001267994214174\n",
      "Epoch 197, Loss: 0.39998840970890487\n",
      "Epoch 198, Loss: 0.40018212076528\n",
      "Epoch 199, Loss: 0.40059033507226127\n",
      "Epoch 200, Loss: 0.3997623259031954\n",
      "Epoch 201, Loss: 0.3988446604918486\n",
      "Epoch 202, Loss: 0.397874471747371\n",
      "Epoch 203, Loss: 0.3974707599897689\n",
      "Epoch 204, Loss: 0.3975876364879186\n",
      "Epoch 205, Loss: 0.3979043385291918\n",
      "Epoch 206, Loss: 0.39827638996521775\n",
      "Epoch 207, Loss: 0.3971596027784736\n",
      "Epoch 208, Loss: 0.39598290436742584\n",
      "Epoch 209, Loss: 0.3951550452838844\n",
      "Epoch 210, Loss: 0.39501238275385403\n",
      "Epoch 211, Loss: 0.39532713354113114\n",
      "Epoch 212, Loss: 0.39538116311097843\n",
      "Epoch 213, Loss: 0.3953164662098097\n",
      "Epoch 214, Loss: 0.3942929671947793\n",
      "Epoch 215, Loss: 0.3932976084214296\n",
      "Epoch 216, Loss: 0.39272254450994026\n",
      "Epoch 217, Loss: 0.3926602178115835\n",
      "Epoch 218, Loss: 0.3932274719437549\n",
      "Epoch 219, Loss: 0.3934228075054972\n",
      "Epoch 220, Loss: 0.3940185198945474\n",
      "Epoch 221, Loss: 0.3926865726820036\n",
      "Epoch 222, Loss: 0.3911072043567093\n",
      "Epoch 223, Loss: 0.39056270102576474\n",
      "Epoch 224, Loss: 0.39119438635351733\n",
      "Epoch 225, Loss: 0.39233451610593245\n",
      "Epoch 226, Loss: 0.39099155393853985\n",
      "Epoch 227, Loss: 0.38922664213199826\n",
      "Epoch 228, Loss: 0.3888236281533679\n",
      "Epoch 229, Loss: 0.38959026619493425\n",
      "Epoch 230, Loss: 0.38990578243896845\n",
      "Epoch 231, Loss: 0.3889945334697633\n",
      "Epoch 232, Loss: 0.3879598680601811\n",
      "Epoch 233, Loss: 0.38716215664955483\n",
      "Epoch 234, Loss: 0.3864661075430449\n",
      "Epoch 235, Loss: 0.3862362751482104\n",
      "Epoch 236, Loss: 0.38641638446726534\n",
      "Epoch 237, Loss: 0.38696354526019155\n",
      "Epoch 238, Loss: 0.3877456209610602\n",
      "Epoch 239, Loss: 0.3898250017263872\n",
      "Epoch 240, Loss: 0.3895531827135864\n",
      "Epoch 241, Loss: 0.38522379362249287\n",
      "Epoch 242, Loss: 0.38512647718761006\n",
      "Epoch 243, Loss: 0.3894697271881296\n",
      "Epoch 244, Loss: 0.39132231461469874\n",
      "Epoch 245, Loss: 0.3840167508296417\n",
      "Epoch 246, Loss: 0.3899670782315528\n",
      "Epoch 247, Loss: 0.39271044043355957\n",
      "Epoch 248, Loss: 0.3828937288636014\n",
      "Epoch 249, Loss: 0.38956953507057707\n",
      "Epoch 250, Loss: 0.3831966380154514\n",
      "Epoch 251, Loss: 0.3852862016995645\n",
      "Epoch 252, Loss: 0.3867987925605804\n",
      "Epoch 253, Loss: 0.38109622339851296\n",
      "Epoch 254, Loss: 0.3845641678628723\n",
      "Epoch 255, Loss: 0.38082351515751006\n",
      "Epoch 256, Loss: 0.38161464044358684\n",
      "Epoch 257, Loss: 0.3825385806940442\n",
      "Epoch 258, Loss: 0.38014327977667894\n",
      "Epoch 259, Loss: 0.380575103307992\n",
      "Epoch 260, Loss: 0.37982145858376115\n",
      "Epoch 261, Loss: 0.3786939439113545\n",
      "Epoch 262, Loss: 0.3781539488185631\n",
      "Epoch 263, Loss: 0.37906598135913294\n",
      "Epoch 264, Loss: 0.37696124843877027\n",
      "Epoch 265, Loss: 0.3774603953649257\n",
      "Epoch 266, Loss: 0.37805426069890125\n",
      "Epoch 267, Loss: 0.377755038496052\n",
      "Epoch 268, Loss: 0.3758865645062818\n",
      "Epoch 269, Loss: 0.3763337457485378\n",
      "Epoch 270, Loss: 0.3781819056417249\n",
      "Epoch 271, Loss: 0.37729380338257923\n",
      "Epoch 272, Loss: 0.37496268563588825\n",
      "Epoch 273, Loss: 0.3746186542654506\n",
      "Epoch 274, Loss: 0.37838605192393227\n",
      "Epoch 275, Loss: 0.37624579363908106\n",
      "Epoch 276, Loss: 0.3741786027369519\n",
      "Epoch 277, Loss: 0.37320294535702253\n",
      "Epoch 278, Loss: 0.3770843633177514\n",
      "Epoch 279, Loss: 0.3751450297923142\n",
      "Epoch 280, Loss: 0.37390176571915995\n",
      "Epoch 281, Loss: 0.37118884424190035\n",
      "Epoch 282, Loss: 0.3755764702661573\n",
      "Epoch 283, Loss: 0.3746081331329923\n",
      "Epoch 284, Loss: 0.372699176067417\n",
      "Epoch 285, Loss: 0.3702640091256768\n",
      "Epoch 286, Loss: 0.373286265311195\n",
      "Epoch 287, Loss: 0.3739024830750774\n",
      "Epoch 288, Loss: 0.36996090289343214\n",
      "Epoch 289, Loss: 0.36900664224177193\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.25227667185442615\n",
      "Test R^2 score: 0.30972181417146044\n",
      "Num of epochs: 290\n",
      "Epoch 1, Loss: 0.6105287096441566\n",
      "Epoch 2, Loss: 0.6069854935101971\n",
      "Epoch 3, Loss: 0.6034942178725745\n",
      "Epoch 4, Loss: 0.600054373860254\n",
      "Epoch 5, Loss: 0.5967257367983893\n",
      "Epoch 6, Loss: 0.5935295348190087\n",
      "Epoch 7, Loss: 0.5904652687327474\n",
      "Epoch 8, Loss: 0.5875278506880908\n",
      "Epoch 9, Loss: 0.5847268631293616\n",
      "Epoch 10, Loss: 0.582078150965295\n",
      "Epoch 11, Loss: 0.5795552886971702\n",
      "Epoch 12, Loss: 0.5771434544898439\n",
      "Epoch 13, Loss: 0.5748472342524239\n",
      "Epoch 14, Loss: 0.5726759028998125\n",
      "Epoch 15, Loss: 0.5706245927088476\n",
      "Epoch 16, Loss: 0.568691982202572\n",
      "Epoch 17, Loss: 0.5668768144807723\n",
      "Epoch 18, Loss: 0.5651796410666063\n",
      "Epoch 19, Loss: 0.563597958609591\n",
      "Epoch 20, Loss: 0.5621272282419455\n",
      "Epoch 21, Loss: 0.5608461491573901\n",
      "Epoch 22, Loss: 0.5597467593669577\n",
      "Epoch 23, Loss: 0.5587482372145187\n",
      "Epoch 24, Loss: 0.557801919190315\n",
      "Epoch 25, Loss: 0.5569210216287822\n",
      "Epoch 26, Loss: 0.556110276665042\n",
      "Epoch 27, Loss: 0.5552871847312696\n",
      "Epoch 28, Loss: 0.5544730833174828\n",
      "Epoch 29, Loss: 0.5536413132156162\n",
      "Epoch 30, Loss: 0.5527411686240516\n",
      "Epoch 31, Loss: 0.5517239990676097\n",
      "Epoch 32, Loss: 0.5505716452582238\n",
      "Epoch 33, Loss: 0.5492498874655509\n",
      "Epoch 34, Loss: 0.5476936207862096\n",
      "Epoch 35, Loss: 0.5458552798986619\n",
      "Epoch 36, Loss: 0.5436782866356303\n",
      "Epoch 37, Loss: 0.5411730926178365\n",
      "Epoch 38, Loss: 0.5384152161276027\n",
      "Epoch 39, Loss: 0.5355987111943602\n",
      "Epoch 40, Loss: 0.5330410945198167\n",
      "Epoch 41, Loss: 0.5311102963928578\n",
      "Epoch 42, Loss: 0.5298254041721421\n",
      "Epoch 43, Loss: 0.5283397170362081\n",
      "Epoch 44, Loss: 0.5258165639550008\n",
      "Epoch 45, Loss: 0.52252792927141\n",
      "Epoch 46, Loss: 0.5193768035086157\n",
      "Epoch 47, Loss: 0.5168208502342736\n",
      "Epoch 48, Loss: 0.5148230587588652\n",
      "Epoch 49, Loss: 0.5129893304540687\n",
      "Epoch 50, Loss: 0.5109727678171899\n",
      "Epoch 51, Loss: 0.5086395278228382\n",
      "Epoch 52, Loss: 0.5060930632833619\n",
      "Epoch 53, Loss: 0.5036132611298201\n",
      "Epoch 54, Loss: 0.5015618844191913\n",
      "Epoch 55, Loss: 0.4999938904865844\n",
      "Epoch 56, Loss: 0.4984269431021646\n",
      "Epoch 57, Loss: 0.49645385288207616\n",
      "Epoch 58, Loss: 0.4943383315144072\n",
      "Epoch 59, Loss: 0.4925214300721489\n",
      "Epoch 60, Loss: 0.49107474226886333\n",
      "Epoch 61, Loss: 0.4897075725402263\n",
      "Epoch 62, Loss: 0.4881555166486254\n",
      "Epoch 63, Loss: 0.48644472738947764\n",
      "Epoch 64, Loss: 0.48482291215871837\n",
      "Epoch 65, Loss: 0.4834194910878462\n",
      "Epoch 66, Loss: 0.48208682205148967\n",
      "Epoch 67, Loss: 0.4806082143196277\n",
      "Epoch 68, Loss: 0.47911411149221894\n",
      "Epoch 69, Loss: 0.47781644850721733\n",
      "Epoch 70, Loss: 0.4766654544372528\n",
      "Epoch 71, Loss: 0.47544974819075986\n",
      "Epoch 72, Loss: 0.47412612236648416\n",
      "Epoch 73, Loss: 0.47285745609964147\n",
      "Epoch 74, Loss: 0.47169794714672836\n",
      "Epoch 75, Loss: 0.4705025969929224\n",
      "Epoch 76, Loss: 0.4692226411275123\n",
      "Epoch 77, Loss: 0.4680222584187439\n",
      "Epoch 78, Loss: 0.4669417152587258\n",
      "Epoch 79, Loss: 0.4658215600722779\n",
      "Epoch 80, Loss: 0.46466431239855266\n",
      "Epoch 81, Loss: 0.4635765048304768\n",
      "Epoch 82, Loss: 0.4625337730139417\n",
      "Epoch 83, Loss: 0.46145142176197557\n",
      "Epoch 84, Loss: 0.46038555785270757\n",
      "Epoch 85, Loss: 0.45941074128495574\n",
      "Epoch 86, Loss: 0.45843836996857956\n",
      "Epoch 87, Loss: 0.4574709676171152\n",
      "Epoch 88, Loss: 0.45656472220588273\n",
      "Epoch 89, Loss: 0.45567214245751236\n",
      "Epoch 90, Loss: 0.45476447499281675\n",
      "Epoch 91, Loss: 0.4539012836440669\n",
      "Epoch 92, Loss: 0.45306422385046863\n",
      "Epoch 93, Loss: 0.45219623815586385\n",
      "Epoch 94, Loss: 0.451333797182134\n",
      "Epoch 95, Loss: 0.4504628245175355\n",
      "Epoch 96, Loss: 0.44959888131152664\n",
      "Epoch 97, Loss: 0.44878544019309224\n",
      "Epoch 98, Loss: 0.44793176810364455\n",
      "Epoch 99, Loss: 0.4471094450149868\n",
      "Epoch 100, Loss: 0.4462904147538748\n",
      "Epoch 101, Loss: 0.4454706480052043\n",
      "Epoch 102, Loss: 0.4446819592986539\n",
      "Epoch 103, Loss: 0.4438908789879471\n",
      "Epoch 104, Loss: 0.44314808789408533\n",
      "Epoch 105, Loss: 0.442374324085574\n",
      "Epoch 106, Loss: 0.44162363421533685\n",
      "Epoch 107, Loss: 0.4408634190067171\n",
      "Epoch 108, Loss: 0.44007277141601187\n",
      "Epoch 109, Loss: 0.43930873618071836\n",
      "Epoch 110, Loss: 0.4386089099727871\n",
      "Epoch 111, Loss: 0.4379342682704091\n",
      "Epoch 112, Loss: 0.43731781027059785\n",
      "Epoch 113, Loss: 0.4366505414348964\n",
      "Epoch 114, Loss: 0.43589467757813755\n",
      "Epoch 115, Loss: 0.43527074365741664\n",
      "Epoch 116, Loss: 0.43449699554897125\n",
      "Epoch 117, Loss: 0.4337192731741867\n",
      "Epoch 118, Loss: 0.43284113751359\n",
      "Epoch 119, Loss: 0.43194063902354457\n",
      "Epoch 120, Loss: 0.43129944586971425\n",
      "Epoch 121, Loss: 0.43055972956955113\n",
      "Epoch 122, Loss: 0.42987852185407566\n",
      "Epoch 123, Loss: 0.42918073074048757\n",
      "Epoch 124, Loss: 0.42846295390348355\n",
      "Epoch 125, Loss: 0.4277683923859408\n",
      "Epoch 126, Loss: 0.4269442642004432\n",
      "Epoch 127, Loss: 0.4262397642109211\n",
      "Epoch 128, Loss: 0.4255880389921028\n",
      "Epoch 129, Loss: 0.4249412580173292\n",
      "Epoch 130, Loss: 0.4243259933670419\n",
      "Epoch 131, Loss: 0.42373353807999753\n",
      "Epoch 132, Loss: 0.42312729371433827\n",
      "Epoch 133, Loss: 0.4225280616684538\n",
      "Epoch 134, Loss: 0.42189306644326513\n",
      "Epoch 135, Loss: 0.4212670714431096\n",
      "Epoch 136, Loss: 0.42065622746605186\n",
      "Epoch 137, Loss: 0.4200399898042379\n",
      "Epoch 138, Loss: 0.4194148351451333\n",
      "Epoch 139, Loss: 0.41890954707497635\n",
      "Epoch 140, Loss: 0.41848752991181054\n",
      "Epoch 141, Loss: 0.4178943567827886\n",
      "Epoch 142, Loss: 0.41715378500044165\n",
      "Epoch 143, Loss: 0.4165323835791515\n",
      "Epoch 144, Loss: 0.4161491716972705\n",
      "Epoch 145, Loss: 0.4157877015620728\n",
      "Epoch 146, Loss: 0.41517064420981287\n",
      "Epoch 147, Loss: 0.41443227055724596\n",
      "Epoch 148, Loss: 0.4138767797592548\n",
      "Epoch 149, Loss: 0.4134920256997788\n",
      "Epoch 150, Loss: 0.41312882581777427\n",
      "Epoch 151, Loss: 0.4124927816337402\n",
      "Epoch 152, Loss: 0.41175997417299787\n",
      "Epoch 153, Loss: 0.411142344602144\n",
      "Epoch 154, Loss: 0.41073984679653947\n",
      "Epoch 155, Loss: 0.4103890258014281\n",
      "Epoch 156, Loss: 0.4099321570614567\n",
      "Epoch 157, Loss: 0.40929560510213014\n",
      "Epoch 158, Loss: 0.4086007914474336\n",
      "Epoch 159, Loss: 0.4079739598117268\n",
      "Epoch 160, Loss: 0.4074990255250571\n",
      "Epoch 161, Loss: 0.40713393806903786\n",
      "Epoch 162, Loss: 0.40683231434557077\n",
      "Epoch 163, Loss: 0.4065426359374576\n",
      "Epoch 164, Loss: 0.4060963376745463\n",
      "Epoch 165, Loss: 0.405407674228381\n",
      "Epoch 166, Loss: 0.404731958664604\n",
      "Epoch 167, Loss: 0.40430146366777214\n",
      "Epoch 168, Loss: 0.4040158350020026\n",
      "Epoch 169, Loss: 0.4037312407018163\n",
      "Epoch 170, Loss: 0.4032922878181116\n",
      "Epoch 171, Loss: 0.4027427250674518\n",
      "Epoch 172, Loss: 0.40213164507065563\n",
      "Epoch 173, Loss: 0.4015872843771565\n",
      "Epoch 174, Loss: 0.4012049140437165\n",
      "Epoch 175, Loss: 0.4010190730315473\n",
      "Epoch 176, Loss: 0.40134402020273113\n",
      "Epoch 177, Loss: 0.4021711812713828\n",
      "Epoch 178, Loss: 0.4021279580384261\n",
      "Epoch 179, Loss: 0.39944041941636405\n",
      "Epoch 180, Loss: 0.3998349497438975\n",
      "Epoch 181, Loss: 0.4002168603981907\n",
      "Epoch 182, Loss: 0.3982277299278153\n",
      "Epoch 183, Loss: 0.39923544996235644\n",
      "Epoch 184, Loss: 0.3982579817920935\n",
      "Epoch 185, Loss: 0.39748322520458446\n",
      "Epoch 186, Loss: 0.3981267427798562\n",
      "Epoch 187, Loss: 0.39669555527144573\n",
      "Epoch 188, Loss: 0.3968307598116814\n",
      "Epoch 189, Loss: 0.39670426984205076\n",
      "Epoch 190, Loss: 0.3956416339300219\n",
      "Epoch 191, Loss: 0.3959979375944473\n",
      "Epoch 192, Loss: 0.39543616505387436\n",
      "Epoch 193, Loss: 0.3947799012369382\n",
      "Epoch 194, Loss: 0.3949856360455458\n",
      "Epoch 195, Loss: 0.39432873579971733\n",
      "Epoch 196, Loss: 0.3938664226378899\n",
      "Epoch 197, Loss: 0.39397290822985565\n",
      "Epoch 198, Loss: 0.393371084847739\n",
      "Epoch 199, Loss: 0.3929214115335018\n",
      "Epoch 200, Loss: 0.3929122527748694\n",
      "Epoch 201, Loss: 0.39249218052163776\n",
      "Epoch 202, Loss: 0.39194809951282544\n",
      "Epoch 203, Loss: 0.3917565550362226\n",
      "Epoch 204, Loss: 0.39151028451650477\n",
      "Epoch 205, Loss: 0.39099892838811734\n",
      "Epoch 206, Loss: 0.39054163997016106\n",
      "Epoch 207, Loss: 0.39031206947956515\n",
      "Epoch 208, Loss: 0.39002723733228356\n",
      "Epoch 209, Loss: 0.38961269817078614\n",
      "Epoch 210, Loss: 0.3891872841678362\n",
      "Epoch 211, Loss: 0.3888176112854633\n",
      "Epoch 212, Loss: 0.388525566282253\n",
      "Epoch 213, Loss: 0.3882717776150499\n",
      "Epoch 214, Loss: 0.3880440515147049\n",
      "Epoch 215, Loss: 0.387862585001217\n",
      "Epoch 216, Loss: 0.387583834285627\n",
      "Epoch 217, Loss: 0.38727927766628745\n",
      "Epoch 218, Loss: 0.38674755181842757\n",
      "Epoch 219, Loss: 0.38617218773867973\n",
      "Epoch 220, Loss: 0.385671971364715\n",
      "Epoch 221, Loss: 0.3852508892913001\n",
      "Epoch 222, Loss: 0.38489313481700776\n",
      "Epoch 223, Loss: 0.38463489615943863\n",
      "Epoch 224, Loss: 0.38458077109913663\n",
      "Epoch 225, Loss: 0.3848662849856914\n",
      "Epoch 226, Loss: 0.38599783236631224\n",
      "Epoch 227, Loss: 0.3864135501170448\n",
      "Epoch 228, Loss: 0.3853974938993627\n",
      "Epoch 229, Loss: 0.38253149111771073\n",
      "Epoch 230, Loss: 0.38364844621770994\n",
      "Epoch 231, Loss: 0.3846915895134654\n",
      "Epoch 232, Loss: 0.38200230401028346\n",
      "Epoch 233, Loss: 0.38185304959482896\n",
      "Epoch 234, Loss: 0.38274429647929015\n",
      "Epoch 235, Loss: 0.38137752792060725\n",
      "Epoch 236, Loss: 0.38019074656254054\n",
      "Epoch 237, Loss: 0.3814093311565111\n",
      "Epoch 238, Loss: 0.3801414178290193\n",
      "Epoch 239, Loss: 0.37895225953443806\n",
      "Epoch 240, Loss: 0.3792000840555673\n",
      "Epoch 241, Loss: 0.37902570591514806\n",
      "Epoch 242, Loss: 0.37849970765398594\n",
      "Epoch 243, Loss: 0.3772754575799269\n",
      "Epoch 244, Loss: 0.3774787124416871\n",
      "Epoch 245, Loss: 0.3775947328463316\n",
      "Epoch 246, Loss: 0.3764637156666282\n",
      "Epoch 247, Loss: 0.3760593075546222\n",
      "Epoch 248, Loss: 0.3755346698654471\n",
      "Epoch 249, Loss: 0.37567118343344674\n",
      "Epoch 250, Loss: 0.3751244338532459\n",
      "Epoch 251, Loss: 0.37416133878237956\n",
      "Epoch 252, Loss: 0.37393703408892076\n",
      "Epoch 253, Loss: 0.3731100618065438\n",
      "Epoch 254, Loss: 0.37311858841005596\n",
      "Epoch 255, Loss: 0.37331161292504156\n",
      "Epoch 256, Loss: 0.3730568609848404\n",
      "Epoch 257, Loss: 0.3735873516241633\n",
      "Epoch 258, Loss: 0.3727882247529421\n",
      "Epoch 259, Loss: 0.3716529046741008\n",
      "Epoch 260, Loss: 0.3702368630854696\n",
      "Epoch 261, Loss: 0.369612941623945\n",
      "Epoch 262, Loss: 0.3697896429015467\n",
      "Epoch 263, Loss: 0.37030763180265075\n",
      "Epoch 264, Loss: 0.37189601710577486\n",
      "Epoch 265, Loss: 0.37165466881889336\n",
      "Epoch 266, Loss: 0.369244515468025\n",
      "Epoch 267, Loss: 0.36663706083778325\n",
      "Epoch 268, Loss: 0.36732632467915977\n",
      "Epoch 269, Loss: 0.36958659445145653\n",
      "Epoch 270, Loss: 0.36764378300778155\n",
      "Epoch 271, Loss: 0.36576565946769235\n",
      "Epoch 272, Loss: 0.36380879235094543\n",
      "Epoch 273, Loss: 0.3637135302558055\n",
      "Epoch 274, Loss: 0.3644840673004721\n",
      "Epoch 275, Loss: 0.3646666862935567\n",
      "Epoch 276, Loss: 0.3654407183533329\n",
      "Epoch 277, Loss: 0.36376830235216084\n",
      "Epoch 278, Loss: 0.3621392296394155\n",
      "Epoch 279, Loss: 0.35975920829890695\n",
      "Epoch 280, Loss: 0.36048810072716236\n",
      "Epoch 281, Loss: 0.36376912161784825\n",
      "Epoch 282, Loss: 0.36300642631690544\n",
      "Epoch 283, Loss: 0.36311367230630404\n",
      "Epoch 284, Loss: 0.35774243680821954\n",
      "Epoch 285, Loss: 0.35782415129502876\n",
      "Epoch 286, Loss: 0.3613014211323692\n",
      "Epoch 287, Loss: 0.3592658084345812\n",
      "Epoch 288, Loss: 0.3572175113955848\n",
      "Epoch 289, Loss: 0.35451812228918334\n",
      "Epoch 290, Loss: 0.35527886569514633\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2537545983344535\n",
      "Test R^2 score: 0.3003611281566991\n",
      "Num of epochs: 291\n",
      "Epoch 1, Loss: 0.5880180803701348\n",
      "Epoch 2, Loss: 0.5857507280857251\n",
      "Epoch 3, Loss: 0.583689305705541\n",
      "Epoch 4, Loss: 0.5816902851658198\n",
      "Epoch 5, Loss: 0.5797494027536465\n",
      "Epoch 6, Loss: 0.5778654134319499\n",
      "Epoch 7, Loss: 0.5760413587775164\n",
      "Epoch 8, Loss: 0.5742836740341628\n",
      "Epoch 9, Loss: 0.5726111088508239\n",
      "Epoch 10, Loss: 0.5710040302485118\n",
      "Epoch 11, Loss: 0.5694673102008492\n",
      "Epoch 12, Loss: 0.5680007589731384\n",
      "Epoch 13, Loss: 0.5666092870449382\n",
      "Epoch 14, Loss: 0.5652902329057122\n",
      "Epoch 15, Loss: 0.5640448179141703\n",
      "Epoch 16, Loss: 0.5628742456534878\n",
      "Epoch 17, Loss: 0.5617845011337633\n",
      "Epoch 18, Loss: 0.5607808651501645\n",
      "Epoch 19, Loss: 0.5598758309509966\n",
      "Epoch 20, Loss: 0.5590503133913661\n",
      "Epoch 21, Loss: 0.5583179032864866\n",
      "Epoch 22, Loss: 0.5577165611960703\n",
      "Epoch 23, Loss: 0.5572052350861537\n",
      "Epoch 24, Loss: 0.556744187743086\n",
      "Epoch 25, Loss: 0.5564110265675152\n",
      "Epoch 26, Loss: 0.5561070612155388\n",
      "Epoch 27, Loss: 0.5558263612059225\n",
      "Epoch 28, Loss: 0.5555766863248176\n",
      "Epoch 29, Loss: 0.5553366663648837\n",
      "Epoch 30, Loss: 0.5550844088795326\n",
      "Epoch 31, Loss: 0.5548115443833486\n",
      "Epoch 32, Loss: 0.5545087983161759\n",
      "Epoch 33, Loss: 0.5541546639837239\n",
      "Epoch 34, Loss: 0.553700495761059\n",
      "Epoch 35, Loss: 0.5530498669130217\n",
      "Epoch 36, Loss: 0.5521324303826364\n",
      "Epoch 37, Loss: 0.5508761222781181\n",
      "Epoch 38, Loss: 0.5492447327372988\n",
      "Epoch 39, Loss: 0.547190520682894\n",
      "Epoch 40, Loss: 0.5446921517222195\n",
      "Epoch 41, Loss: 0.5416968288337964\n",
      "Epoch 42, Loss: 0.5382329944080491\n",
      "Epoch 43, Loss: 0.5345455221073335\n",
      "Epoch 44, Loss: 0.5306465985650568\n",
      "Epoch 45, Loss: 0.5270226525318796\n",
      "Epoch 46, Loss: 0.5244704629983403\n",
      "Epoch 47, Loss: 0.5235554007223876\n",
      "Epoch 48, Loss: 0.5227613209484164\n",
      "Epoch 49, Loss: 0.519964654023807\n",
      "Epoch 50, Loss: 0.5159377681146915\n",
      "Epoch 51, Loss: 0.5124769926721989\n",
      "Epoch 52, Loss: 0.5101864126731972\n",
      "Epoch 53, Loss: 0.5087817405715657\n",
      "Epoch 54, Loss: 0.5075595519167311\n",
      "Epoch 55, Loss: 0.5059593720447293\n",
      "Epoch 56, Loss: 0.5038355696440615\n",
      "Epoch 57, Loss: 0.5013535477284169\n",
      "Epoch 58, Loss: 0.4988796079112648\n",
      "Epoch 59, Loss: 0.4967633331824772\n",
      "Epoch 60, Loss: 0.4950900399554776\n",
      "Epoch 61, Loss: 0.49349079450661654\n",
      "Epoch 62, Loss: 0.49156822118806737\n",
      "Epoch 63, Loss: 0.4893918187014902\n",
      "Epoch 64, Loss: 0.48740017553575976\n",
      "Epoch 65, Loss: 0.48580745416531335\n",
      "Epoch 66, Loss: 0.48437120066967765\n",
      "Epoch 67, Loss: 0.4827399498709748\n",
      "Epoch 68, Loss: 0.48083606108757265\n",
      "Epoch 69, Loss: 0.4788923687813358\n",
      "Epoch 70, Loss: 0.4771726329663416\n",
      "Epoch 71, Loss: 0.4757248755820357\n",
      "Epoch 72, Loss: 0.4743312287522971\n",
      "Epoch 73, Loss: 0.4728491050785563\n",
      "Epoch 74, Loss: 0.47135203099337764\n",
      "Epoch 75, Loss: 0.47014510448628816\n",
      "Epoch 76, Loss: 0.4690866056496302\n",
      "Epoch 77, Loss: 0.4678498207754836\n",
      "Epoch 78, Loss: 0.46646417548828917\n",
      "Epoch 79, Loss: 0.4652127796609207\n",
      "Epoch 80, Loss: 0.46406820659789305\n",
      "Epoch 81, Loss: 0.4628742714097616\n",
      "Epoch 82, Loss: 0.46165831827139236\n",
      "Epoch 83, Loss: 0.4606304277335765\n",
      "Epoch 84, Loss: 0.45978968969743106\n",
      "Epoch 85, Loss: 0.4589187737516916\n",
      "Epoch 86, Loss: 0.4580152628929105\n",
      "Epoch 87, Loss: 0.4573381159949853\n",
      "Epoch 88, Loss: 0.4567628218913516\n",
      "Epoch 89, Loss: 0.4560350989764398\n",
      "Epoch 90, Loss: 0.45525883700714226\n",
      "Epoch 91, Loss: 0.4545301486277686\n",
      "Epoch 92, Loss: 0.453786383738578\n",
      "Epoch 93, Loss: 0.453044752710341\n",
      "Epoch 94, Loss: 0.45237591090536206\n",
      "Epoch 95, Loss: 0.4517282135696864\n",
      "Epoch 96, Loss: 0.45104304864802386\n",
      "Epoch 97, Loss: 0.45042031513692604\n",
      "Epoch 98, Loss: 0.449819262952107\n",
      "Epoch 99, Loss: 0.44913311017594626\n",
      "Epoch 100, Loss: 0.4484726722561184\n",
      "Epoch 101, Loss: 0.44782926201977996\n",
      "Epoch 102, Loss: 0.447171846911543\n",
      "Epoch 103, Loss: 0.44655155667670193\n",
      "Epoch 104, Loss: 0.4458898014630857\n",
      "Epoch 105, Loss: 0.4452123864054404\n",
      "Epoch 106, Loss: 0.4445563807029464\n",
      "Epoch 107, Loss: 0.4438726000601436\n",
      "Epoch 108, Loss: 0.4432179733847295\n",
      "Epoch 109, Loss: 0.44255140178433844\n",
      "Epoch 110, Loss: 0.441880300724766\n",
      "Epoch 111, Loss: 0.44121050925400795\n",
      "Epoch 112, Loss: 0.44050928990876675\n",
      "Epoch 113, Loss: 0.4398322949179798\n",
      "Epoch 114, Loss: 0.43912532872731463\n",
      "Epoch 115, Loss: 0.4384232044676328\n",
      "Epoch 116, Loss: 0.4376958510852174\n",
      "Epoch 117, Loss: 0.4369607906395528\n",
      "Epoch 118, Loss: 0.436197863526602\n",
      "Epoch 119, Loss: 0.43545112070479697\n",
      "Epoch 120, Loss: 0.4347223251729944\n",
      "Epoch 121, Loss: 0.43396909465379174\n",
      "Epoch 122, Loss: 0.4332352092340169\n",
      "Epoch 123, Loss: 0.43246403861620175\n",
      "Epoch 124, Loss: 0.43168146276829544\n",
      "Epoch 125, Loss: 0.43089086049223513\n",
      "Epoch 126, Loss: 0.4300932442400824\n",
      "Epoch 127, Loss: 0.42930634672981344\n",
      "Epoch 128, Loss: 0.42851558744418206\n",
      "Epoch 129, Loss: 0.42769532047152914\n",
      "Epoch 130, Loss: 0.42687159228326105\n",
      "Epoch 131, Loss: 0.42605793563571326\n",
      "Epoch 132, Loss: 0.42528823867427384\n",
      "Epoch 133, Loss: 0.42458822062558654\n",
      "Epoch 134, Loss: 0.42395346409893736\n",
      "Epoch 135, Loss: 0.4232265228344136\n",
      "Epoch 136, Loss: 0.422284457398153\n",
      "Epoch 137, Loss: 0.42152475016954005\n",
      "Epoch 138, Loss: 0.4209866707848275\n",
      "Epoch 139, Loss: 0.4203742318748968\n",
      "Epoch 140, Loss: 0.4195344423993085\n",
      "Epoch 141, Loss: 0.4186534442891595\n",
      "Epoch 142, Loss: 0.41793425587004995\n",
      "Epoch 143, Loss: 0.4174517169889668\n",
      "Epoch 144, Loss: 0.41708969655678524\n",
      "Epoch 145, Loss: 0.4164692371245626\n",
      "Epoch 146, Loss: 0.4154149227271529\n",
      "Epoch 147, Loss: 0.4146209585506349\n",
      "Epoch 148, Loss: 0.41420498681559265\n",
      "Epoch 149, Loss: 0.413989042567864\n",
      "Epoch 150, Loss: 0.41363535747777264\n",
      "Epoch 151, Loss: 0.4125702978690837\n",
      "Epoch 152, Loss: 0.4117026106912165\n",
      "Epoch 153, Loss: 0.41134839057811534\n",
      "Epoch 154, Loss: 0.41111610360522177\n",
      "Epoch 155, Loss: 0.4104398745867039\n",
      "Epoch 156, Loss: 0.4095367112244959\n",
      "Epoch 157, Loss: 0.4089906569966687\n",
      "Epoch 158, Loss: 0.40878325857825726\n",
      "Epoch 159, Loss: 0.4085088980918449\n",
      "Epoch 160, Loss: 0.40805626011367735\n",
      "Epoch 161, Loss: 0.40704065191206407\n",
      "Epoch 162, Loss: 0.4061518330443561\n",
      "Epoch 163, Loss: 0.40583870314675496\n",
      "Epoch 164, Loss: 0.4057951361417814\n",
      "Epoch 165, Loss: 0.4055444018399323\n",
      "Epoch 166, Loss: 0.40442226142571547\n",
      "Epoch 167, Loss: 0.40342513377933303\n",
      "Epoch 168, Loss: 0.40294724175162017\n",
      "Epoch 169, Loss: 0.40297183298541656\n",
      "Epoch 170, Loss: 0.40312995759739645\n",
      "Epoch 171, Loss: 0.4025426946825039\n",
      "Epoch 172, Loss: 0.4012668233535464\n",
      "Epoch 173, Loss: 0.4004199877881404\n",
      "Epoch 174, Loss: 0.40049902216235933\n",
      "Epoch 175, Loss: 0.4004839718560534\n",
      "Epoch 176, Loss: 0.3995050452585768\n",
      "Epoch 177, Loss: 0.3984600509544837\n",
      "Epoch 178, Loss: 0.3981472528966717\n",
      "Epoch 179, Loss: 0.3982389740863374\n",
      "Epoch 180, Loss: 0.3980067486514318\n",
      "Epoch 181, Loss: 0.3970742934253067\n",
      "Epoch 182, Loss: 0.39601855796379576\n",
      "Epoch 183, Loss: 0.395514198534237\n",
      "Epoch 184, Loss: 0.3954358635909695\n",
      "Epoch 185, Loss: 0.3955965672501223\n",
      "Epoch 186, Loss: 0.3954206205732448\n",
      "Epoch 187, Loss: 0.39457120787463534\n",
      "Epoch 188, Loss: 0.39311358245741335\n",
      "Epoch 189, Loss: 0.3922210891747491\n",
      "Epoch 190, Loss: 0.39203454336681265\n",
      "Epoch 191, Loss: 0.3922228937781933\n",
      "Epoch 192, Loss: 0.3926531022625347\n",
      "Epoch 193, Loss: 0.39243815189896125\n",
      "Epoch 194, Loss: 0.3910032920150028\n",
      "Epoch 195, Loss: 0.38901420354776883\n",
      "Epoch 196, Loss: 0.3884958990241448\n",
      "Epoch 197, Loss: 0.38917891817324124\n",
      "Epoch 198, Loss: 0.3893155466188013\n",
      "Epoch 199, Loss: 0.3883332545801555\n",
      "Epoch 200, Loss: 0.3862553334099396\n",
      "Epoch 201, Loss: 0.3850893314562824\n",
      "Epoch 202, Loss: 0.3850700413479816\n",
      "Epoch 203, Loss: 0.3856660791956967\n",
      "Epoch 204, Loss: 0.3865978938361598\n",
      "Epoch 205, Loss: 0.3847318915281666\n",
      "Epoch 206, Loss: 0.3826493479992934\n",
      "Epoch 207, Loss: 0.38102352810724244\n",
      "Epoch 208, Loss: 0.38054933889018605\n",
      "Epoch 209, Loss: 0.3813205763107382\n",
      "Epoch 210, Loss: 0.3833009173156108\n",
      "Epoch 211, Loss: 0.38485011998061086\n",
      "Epoch 212, Loss: 0.3790305612101631\n",
      "Epoch 213, Loss: 0.3771123006488678\n",
      "Epoch 214, Loss: 0.38029277421234065\n",
      "Epoch 215, Loss: 0.37981339631909394\n",
      "Epoch 216, Loss: 0.37695363889669065\n",
      "Epoch 217, Loss: 0.37419925073459953\n",
      "Epoch 218, Loss: 0.3764002208931525\n",
      "Epoch 219, Loss: 0.37867847950793\n",
      "Epoch 220, Loss: 0.37387221344445365\n",
      "Epoch 221, Loss: 0.371935421979686\n",
      "Epoch 222, Loss: 0.3740985884502918\n",
      "Epoch 223, Loss: 0.37429481004158494\n",
      "Epoch 224, Loss: 0.3712843556033021\n",
      "Epoch 225, Loss: 0.3688807910178937\n",
      "Epoch 226, Loss: 0.3694490627647094\n",
      "Epoch 227, Loss: 0.37068744300657896\n",
      "Epoch 228, Loss: 0.370580700032822\n",
      "Epoch 229, Loss: 0.36926874833623596\n",
      "Epoch 230, Loss: 0.3673359793908402\n",
      "Epoch 231, Loss: 0.36513626086361156\n",
      "Epoch 232, Loss: 0.3649825793838245\n",
      "Epoch 233, Loss: 0.3653822818673867\n",
      "Epoch 234, Loss: 0.3684090120725048\n",
      "Epoch 235, Loss: 0.37087399852683045\n",
      "Epoch 236, Loss: 0.37168337508921606\n",
      "Epoch 237, Loss: 0.36496267565534113\n",
      "Epoch 238, Loss: 0.3621086968309622\n",
      "Epoch 239, Loss: 0.36647758440188594\n",
      "Epoch 240, Loss: 0.3675673528829931\n",
      "Epoch 241, Loss: 0.3648986089007184\n",
      "Epoch 242, Loss: 0.36009533878033195\n",
      "Epoch 243, Loss: 0.3654905226779438\n",
      "Epoch 244, Loss: 0.36955433827830414\n",
      "Epoch 245, Loss: 0.36142067626052443\n",
      "Epoch 246, Loss: 0.3624630605029275\n",
      "Epoch 247, Loss: 0.36974535459549634\n",
      "Epoch 248, Loss: 0.36150687667695547\n",
      "Epoch 249, Loss: 0.36107705130894724\n",
      "Epoch 250, Loss: 0.3691803441552924\n",
      "Epoch 251, Loss: 0.3574834468317131\n",
      "Epoch 252, Loss: 0.36277060356359964\n",
      "Epoch 253, Loss: 0.365732475525829\n",
      "Epoch 254, Loss: 0.3564899782387913\n",
      "Epoch 255, Loss: 0.36489969106484965\n",
      "Epoch 256, Loss: 0.36351883205341207\n",
      "Epoch 257, Loss: 0.3571080982800488\n",
      "Epoch 258, Loss: 0.36723006793076557\n",
      "Epoch 259, Loss: 0.35872728608163507\n",
      "Epoch 260, Loss: 0.35751437465071795\n",
      "Epoch 261, Loss: 0.3616375603404863\n",
      "Epoch 262, Loss: 0.3541201486144125\n",
      "Epoch 263, Loss: 0.3578576313524798\n",
      "Epoch 264, Loss: 0.35657795567494077\n",
      "Epoch 265, Loss: 0.35318172345275095\n",
      "Epoch 266, Loss: 0.35580734224264887\n",
      "Epoch 267, Loss: 0.3538084977244858\n",
      "Epoch 268, Loss: 0.3519062586835937\n",
      "Epoch 269, Loss: 0.35366428263448263\n",
      "Epoch 270, Loss: 0.3519602009594356\n",
      "Epoch 271, Loss: 0.35106419109937537\n",
      "Epoch 272, Loss: 0.3517039120568006\n",
      "Epoch 273, Loss: 0.35152157439335735\n",
      "Epoch 274, Loss: 0.34993146199752057\n",
      "Epoch 275, Loss: 0.34972699280679015\n",
      "Epoch 276, Loss: 0.35008096056596194\n",
      "Epoch 277, Loss: 0.3504936181717271\n",
      "Epoch 278, Loss: 0.34914984951436684\n",
      "Epoch 279, Loss: 0.34827870997396443\n",
      "Epoch 280, Loss: 0.3480304889696324\n",
      "Epoch 281, Loss: 0.3477602813744816\n",
      "Epoch 282, Loss: 0.3481918773584812\n",
      "Epoch 283, Loss: 0.3481285765685032\n",
      "Epoch 284, Loss: 0.3490815040175886\n",
      "Epoch 285, Loss: 0.3492814662694112\n",
      "Epoch 286, Loss: 0.3500583259484867\n",
      "Epoch 287, Loss: 0.34906410872618904\n",
      "Epoch 288, Loss: 0.34814743104987\n",
      "Epoch 289, Loss: 0.34646874040940984\n",
      "Epoch 290, Loss: 0.3457496741038874\n",
      "Epoch 291, Loss: 0.3449198799464417\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2733090707834184\n",
      "Test R^2 score: 0.1839994475563832\n",
      "Num of epochs: 292\n",
      "Epoch 1, Loss: 0.580971283897335\n",
      "Epoch 2, Loss: 0.5789570877466281\n",
      "Epoch 3, Loss: 0.5770228938415203\n",
      "Epoch 4, Loss: 0.5751605193361293\n",
      "Epoch 5, Loss: 0.5733803317809879\n",
      "Epoch 6, Loss: 0.5716842979607553\n",
      "Epoch 7, Loss: 0.5700770114021565\n",
      "Epoch 8, Loss: 0.5685756311257889\n",
      "Epoch 9, Loss: 0.5671737732290245\n",
      "Epoch 10, Loss: 0.5658622233703459\n",
      "Epoch 11, Loss: 0.5646448304817528\n",
      "Epoch 12, Loss: 0.5635231567370267\n",
      "Epoch 13, Loss: 0.5624916287964875\n",
      "Epoch 14, Loss: 0.561549867754338\n",
      "Epoch 15, Loss: 0.5606969439763931\n",
      "Epoch 16, Loss: 0.5599310013719356\n",
      "Epoch 17, Loss: 0.5592491200064572\n",
      "Epoch 18, Loss: 0.558651127569361\n",
      "Epoch 19, Loss: 0.5581358787014653\n",
      "Epoch 20, Loss: 0.5576963084618726\n",
      "Epoch 21, Loss: 0.5573277031011031\n",
      "Epoch 22, Loss: 0.5570223386246989\n",
      "Epoch 23, Loss: 0.5567734676925623\n",
      "Epoch 24, Loss: 0.5565781139944468\n",
      "Epoch 25, Loss: 0.5564173200320756\n",
      "Epoch 26, Loss: 0.5562703289646264\n",
      "Epoch 27, Loss: 0.5561271306753981\n",
      "Epoch 28, Loss: 0.555976310648982\n",
      "Epoch 29, Loss: 0.5558023666132411\n",
      "Epoch 30, Loss: 0.5555889434185997\n",
      "Epoch 31, Loss: 0.5553244842026129\n",
      "Epoch 32, Loss: 0.554995679537822\n",
      "Epoch 33, Loss: 0.5545865893919197\n",
      "Epoch 34, Loss: 0.5540781569487476\n",
      "Epoch 35, Loss: 0.5534446385427791\n",
      "Epoch 36, Loss: 0.5526622819557853\n",
      "Epoch 37, Loss: 0.5517012305490925\n",
      "Epoch 38, Loss: 0.5505259578277458\n",
      "Epoch 39, Loss: 0.5490816555687476\n",
      "Epoch 40, Loss: 0.5473099477546605\n",
      "Epoch 41, Loss: 0.5451800374039961\n",
      "Epoch 42, Loss: 0.5427037697110221\n",
      "Epoch 43, Loss: 0.539924016083601\n",
      "Epoch 44, Loss: 0.5369993062378933\n",
      "Epoch 45, Loss: 0.5341683618436309\n",
      "Epoch 46, Loss: 0.5317829768344531\n",
      "Epoch 47, Loss: 0.529990723276824\n",
      "Epoch 48, Loss: 0.5282643230336098\n",
      "Epoch 49, Loss: 0.5257314264460426\n",
      "Epoch 50, Loss: 0.5224953328156898\n",
      "Epoch 51, Loss: 0.5192148492823284\n",
      "Epoch 52, Loss: 0.5164818724232777\n",
      "Epoch 53, Loss: 0.514340476850931\n",
      "Epoch 54, Loss: 0.512476207599569\n",
      "Epoch 55, Loss: 0.510369013164236\n",
      "Epoch 56, Loss: 0.5078850914349005\n",
      "Epoch 57, Loss: 0.505221963154569\n",
      "Epoch 58, Loss: 0.5027755352916318\n",
      "Epoch 59, Loss: 0.5007354572563106\n",
      "Epoch 60, Loss: 0.49864918808545367\n",
      "Epoch 61, Loss: 0.4959940772664328\n",
      "Epoch 62, Loss: 0.4930758104581593\n",
      "Epoch 63, Loss: 0.49052848960078876\n",
      "Epoch 64, Loss: 0.48824546682848263\n",
      "Epoch 65, Loss: 0.485659388474658\n",
      "Epoch 66, Loss: 0.4825978749578194\n",
      "Epoch 67, Loss: 0.4794791039198788\n",
      "Epoch 68, Loss: 0.47645900728216684\n",
      "Epoch 69, Loss: 0.4732339811853376\n",
      "Epoch 70, Loss: 0.4698260196071659\n",
      "Epoch 71, Loss: 0.46715531892203327\n",
      "Epoch 72, Loss: 0.4657932809467952\n",
      "Epoch 73, Loss: 0.4656892828123263\n",
      "Epoch 74, Loss: 0.46569648232383726\n",
      "Epoch 75, Loss: 0.4652587096338384\n",
      "Epoch 76, Loss: 0.46404927745438546\n",
      "Epoch 77, Loss: 0.46303676760889295\n",
      "Epoch 78, Loss: 0.4618200968681417\n",
      "Epoch 79, Loss: 0.4607654670762407\n",
      "Epoch 80, Loss: 0.4600322854332485\n",
      "Epoch 81, Loss: 0.45897370995650316\n",
      "Epoch 82, Loss: 0.4581581145648601\n",
      "Epoch 83, Loss: 0.45781689143759924\n",
      "Epoch 84, Loss: 0.45717041635569067\n",
      "Epoch 85, Loss: 0.4562269453207175\n",
      "Epoch 86, Loss: 0.45553091550821156\n",
      "Epoch 87, Loss: 0.45484626986854926\n",
      "Epoch 88, Loss: 0.45396808590449467\n",
      "Epoch 89, Loss: 0.4532612562849097\n",
      "Epoch 90, Loss: 0.45263494102351143\n",
      "Epoch 91, Loss: 0.4518807692047367\n",
      "Epoch 92, Loss: 0.4512113413537706\n",
      "Epoch 93, Loss: 0.45066003541551564\n",
      "Epoch 94, Loss: 0.44995234753708147\n",
      "Epoch 95, Loss: 0.44918592581865235\n",
      "Epoch 96, Loss: 0.44856122865319986\n",
      "Epoch 97, Loss: 0.4479064681496365\n",
      "Epoch 98, Loss: 0.4471553016762912\n",
      "Epoch 99, Loss: 0.4465177855585703\n",
      "Epoch 100, Loss: 0.4458244459508259\n",
      "Epoch 101, Loss: 0.4451069608470161\n",
      "Epoch 102, Loss: 0.4444164664267268\n",
      "Epoch 103, Loss: 0.44359955184920763\n",
      "Epoch 104, Loss: 0.44282418773358895\n",
      "Epoch 105, Loss: 0.44205702012455894\n",
      "Epoch 106, Loss: 0.4412649654357699\n",
      "Epoch 107, Loss: 0.4405106091645229\n",
      "Epoch 108, Loss: 0.43979450105952134\n",
      "Epoch 109, Loss: 0.43904956513489635\n",
      "Epoch 110, Loss: 0.43823267689647\n",
      "Epoch 111, Loss: 0.437514015381979\n",
      "Epoch 112, Loss: 0.43678299869717596\n",
      "Epoch 113, Loss: 0.4360225116053969\n",
      "Epoch 114, Loss: 0.43527094906278185\n",
      "Epoch 115, Loss: 0.4345147772461148\n",
      "Epoch 116, Loss: 0.4337290818999649\n",
      "Epoch 117, Loss: 0.43297902769942986\n",
      "Epoch 118, Loss: 0.43224213404473016\n",
      "Epoch 119, Loss: 0.4314754739755323\n",
      "Epoch 120, Loss: 0.430682400336802\n",
      "Epoch 121, Loss: 0.4298650201480402\n",
      "Epoch 122, Loss: 0.42908234030131487\n",
      "Epoch 123, Loss: 0.42827457126335217\n",
      "Epoch 124, Loss: 0.42746442175491556\n",
      "Epoch 125, Loss: 0.42669953181802306\n",
      "Epoch 126, Loss: 0.42598234904686577\n",
      "Epoch 127, Loss: 0.4253138330117777\n",
      "Epoch 128, Loss: 0.4247673982937892\n",
      "Epoch 129, Loss: 0.42429612509630127\n",
      "Epoch 130, Loss: 0.4235747146691491\n",
      "Epoch 131, Loss: 0.42244013269052477\n",
      "Epoch 132, Loss: 0.42181245905403575\n",
      "Epoch 133, Loss: 0.42150143579100474\n",
      "Epoch 134, Loss: 0.42065277365011866\n",
      "Epoch 135, Loss: 0.41963967000336544\n",
      "Epoch 136, Loss: 0.41913035114420794\n",
      "Epoch 137, Loss: 0.4186895696962129\n",
      "Epoch 138, Loss: 0.41782150170409194\n",
      "Epoch 139, Loss: 0.4170138601348441\n",
      "Epoch 140, Loss: 0.41653055908502995\n",
      "Epoch 141, Loss: 0.4161062723897633\n",
      "Epoch 142, Loss: 0.41541169436523034\n",
      "Epoch 143, Loss: 0.4146351722755218\n",
      "Epoch 144, Loss: 0.41397486065126704\n",
      "Epoch 145, Loss: 0.41346813223943085\n",
      "Epoch 146, Loss: 0.4130679367868952\n",
      "Epoch 147, Loss: 0.4126530175622293\n",
      "Epoch 148, Loss: 0.4121268933084657\n",
      "Epoch 149, Loss: 0.4113547480445373\n",
      "Epoch 150, Loss: 0.4105089578441048\n",
      "Epoch 151, Loss: 0.4097620750251652\n",
      "Epoch 152, Loss: 0.4092204180636498\n",
      "Epoch 153, Loss: 0.40882619733773307\n",
      "Epoch 154, Loss: 0.40856034559895943\n",
      "Epoch 155, Loss: 0.408335668774498\n",
      "Epoch 156, Loss: 0.4076079268379148\n",
      "Epoch 157, Loss: 0.4065868741586454\n",
      "Epoch 158, Loss: 0.40572848224051666\n",
      "Epoch 159, Loss: 0.4054751342388429\n",
      "Epoch 160, Loss: 0.40539718025687277\n",
      "Epoch 161, Loss: 0.4050326263861135\n",
      "Epoch 162, Loss: 0.4042088878182\n",
      "Epoch 163, Loss: 0.40334113115793574\n",
      "Epoch 164, Loss: 0.40291654682782246\n",
      "Epoch 165, Loss: 0.40283130992478033\n",
      "Epoch 166, Loss: 0.40277095447256234\n",
      "Epoch 167, Loss: 0.4025889269998789\n",
      "Epoch 168, Loss: 0.40175695127136174\n",
      "Epoch 169, Loss: 0.40081340519517206\n",
      "Epoch 170, Loss: 0.40031538465712746\n",
      "Epoch 171, Loss: 0.4002698762760757\n",
      "Epoch 172, Loss: 0.40027398992526203\n",
      "Epoch 173, Loss: 0.3999046167255497\n",
      "Epoch 174, Loss: 0.39917651063106785\n",
      "Epoch 175, Loss: 0.3984850499820112\n",
      "Epoch 176, Loss: 0.3980793745944597\n",
      "Epoch 177, Loss: 0.3978983653521749\n",
      "Epoch 178, Loss: 0.39781716618943974\n",
      "Epoch 179, Loss: 0.39773939721093693\n",
      "Epoch 180, Loss: 0.39743926717932493\n",
      "Epoch 181, Loss: 0.3970082209610312\n",
      "Epoch 182, Loss: 0.3962982567725969\n",
      "Epoch 183, Loss: 0.3956839463612594\n",
      "Epoch 184, Loss: 0.3952440489056159\n",
      "Epoch 185, Loss: 0.3950601941128765\n",
      "Epoch 186, Loss: 0.39516205921782627\n",
      "Epoch 187, Loss: 0.3953334848013379\n",
      "Epoch 188, Loss: 0.39544973064673405\n",
      "Epoch 189, Loss: 0.3947961125924522\n",
      "Epoch 190, Loss: 0.3937300109330774\n",
      "Epoch 191, Loss: 0.3931320798991437\n",
      "Epoch 192, Loss: 0.39337422893098284\n",
      "Epoch 193, Loss: 0.39371721872988263\n",
      "Epoch 194, Loss: 0.3933432983931667\n",
      "Epoch 195, Loss: 0.39248601107968406\n",
      "Epoch 196, Loss: 0.39164374069657765\n",
      "Epoch 197, Loss: 0.3915732318780534\n",
      "Epoch 198, Loss: 0.3920615104043744\n",
      "Epoch 199, Loss: 0.3920695298420718\n",
      "Epoch 200, Loss: 0.3916777539036686\n",
      "Epoch 201, Loss: 0.3906299781482107\n",
      "Epoch 202, Loss: 0.3900036829688938\n",
      "Epoch 203, Loss: 0.3901343315729434\n",
      "Epoch 204, Loss: 0.3903477829500439\n",
      "Epoch 205, Loss: 0.3904531863966386\n",
      "Epoch 206, Loss: 0.3899576972369027\n",
      "Epoch 207, Loss: 0.38937844695866286\n",
      "Epoch 208, Loss: 0.3886950116962869\n",
      "Epoch 209, Loss: 0.38847081336921174\n",
      "Epoch 210, Loss: 0.3884717531515457\n",
      "Epoch 211, Loss: 0.388622817580904\n",
      "Epoch 212, Loss: 0.388816883123159\n",
      "Epoch 213, Loss: 0.3887079116754122\n",
      "Epoch 214, Loss: 0.3882703000526036\n",
      "Epoch 215, Loss: 0.3874787078668199\n",
      "Epoch 216, Loss: 0.3870047080372134\n",
      "Epoch 217, Loss: 0.3868044363325642\n",
      "Epoch 218, Loss: 0.38683205688218847\n",
      "Epoch 219, Loss: 0.38678451903595923\n",
      "Epoch 220, Loss: 0.3866537020143116\n",
      "Epoch 221, Loss: 0.38645831885256404\n",
      "Epoch 222, Loss: 0.3861815449319881\n",
      "Epoch 223, Loss: 0.386078680524751\n",
      "Epoch 224, Loss: 0.3858901693688421\n",
      "Epoch 225, Loss: 0.38596013346417024\n",
      "Epoch 226, Loss: 0.38587223226965234\n",
      "Epoch 227, Loss: 0.3859511762968033\n",
      "Epoch 228, Loss: 0.38563696476383363\n",
      "Epoch 229, Loss: 0.3855858594669993\n",
      "Epoch 230, Loss: 0.38504175260102746\n",
      "Epoch 231, Loss: 0.3844702695617933\n",
      "Epoch 232, Loss: 0.3840148688594223\n",
      "Epoch 233, Loss: 0.38383833008408486\n",
      "Epoch 234, Loss: 0.38387854700117396\n",
      "Epoch 235, Loss: 0.38414877615429216\n",
      "Epoch 236, Loss: 0.384955035221987\n",
      "Epoch 237, Loss: 0.3861612289229979\n",
      "Epoch 238, Loss: 0.3862199552819534\n",
      "Epoch 239, Loss: 0.3842668544011437\n",
      "Epoch 240, Loss: 0.3828499444826745\n",
      "Epoch 241, Loss: 0.3829940443273088\n",
      "Epoch 242, Loss: 0.3836970522322673\n",
      "Epoch 243, Loss: 0.38378917897928816\n",
      "Epoch 244, Loss: 0.38262489159204593\n",
      "Epoch 245, Loss: 0.3819185835820523\n",
      "Epoch 246, Loss: 0.38223951626728675\n",
      "Epoch 247, Loss: 0.38298978398370775\n",
      "Epoch 248, Loss: 0.38374345814226535\n",
      "Epoch 249, Loss: 0.3825881651016054\n",
      "Epoch 250, Loss: 0.38125097243388245\n",
      "Epoch 251, Loss: 0.38098717526004894\n",
      "Epoch 252, Loss: 0.381422868215796\n",
      "Epoch 253, Loss: 0.3815716074888393\n",
      "Epoch 254, Loss: 0.3812842517850614\n",
      "Epoch 255, Loss: 0.38073078821396183\n",
      "Epoch 256, Loss: 0.3801593509458229\n",
      "Epoch 257, Loss: 0.3798521367806202\n",
      "Epoch 258, Loss: 0.3796171225169158\n",
      "Epoch 259, Loss: 0.37965627549746206\n",
      "Epoch 260, Loss: 0.3802554306053798\n",
      "Epoch 261, Loss: 0.3819350482285812\n",
      "Epoch 262, Loss: 0.38432883628955883\n",
      "Epoch 263, Loss: 0.3828881052833688\n",
      "Epoch 264, Loss: 0.37951748499088034\n",
      "Epoch 265, Loss: 0.3787711581058172\n",
      "Epoch 266, Loss: 0.3796563147465444\n",
      "Epoch 267, Loss: 0.38070689352336\n",
      "Epoch 268, Loss: 0.3796853775781407\n",
      "Epoch 269, Loss: 0.37828752792172243\n",
      "Epoch 270, Loss: 0.377717404541538\n",
      "Epoch 271, Loss: 0.3777609948894066\n",
      "Epoch 272, Loss: 0.37767747846984406\n",
      "Epoch 273, Loss: 0.3780170507268935\n",
      "Epoch 274, Loss: 0.3784513791009645\n",
      "Epoch 275, Loss: 0.3784752193336146\n",
      "Epoch 276, Loss: 0.37919876762715005\n",
      "Epoch 277, Loss: 0.37828809909221645\n",
      "Epoch 278, Loss: 0.37732814258972047\n",
      "Epoch 279, Loss: 0.37653739022393057\n",
      "Epoch 280, Loss: 0.3755627423135043\n",
      "Epoch 281, Loss: 0.3754181120432226\n",
      "Epoch 282, Loss: 0.37543085301501805\n",
      "Epoch 283, Loss: 0.375939662162924\n",
      "Epoch 284, Loss: 0.37804440671962847\n",
      "Epoch 285, Loss: 0.38132491391953205\n",
      "Epoch 286, Loss: 0.377526652393144\n",
      "Epoch 287, Loss: 0.3745567961102086\n",
      "Epoch 288, Loss: 0.3738992549626104\n",
      "Epoch 289, Loss: 0.37545145198933955\n",
      "Epoch 290, Loss: 0.3772419430837421\n",
      "Epoch 291, Loss: 0.37659455079878357\n",
      "Epoch 292, Loss: 0.3757785820816725\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.24346155885858495\n",
      "Test R^2 score: 0.3557754441094134\n",
      "Num of epochs: 293\n",
      "Epoch 1, Loss: 0.5840780380819209\n",
      "Epoch 2, Loss: 0.5821013184428786\n",
      "Epoch 3, Loss: 0.5802196240196892\n",
      "Epoch 4, Loss: 0.5784344746960335\n",
      "Epoch 5, Loss: 0.5767415221045501\n",
      "Epoch 6, Loss: 0.5751395336106465\n",
      "Epoch 7, Loss: 0.5736224912936461\n",
      "Epoch 8, Loss: 0.5721983625963231\n",
      "Epoch 9, Loss: 0.5708868713982176\n",
      "Epoch 10, Loss: 0.5696430980811696\n",
      "Epoch 11, Loss: 0.5684646037111324\n",
      "Epoch 12, Loss: 0.5673491686302462\n",
      "Epoch 13, Loss: 0.5662954287800366\n",
      "Epoch 14, Loss: 0.5653022003079047\n",
      "Epoch 15, Loss: 0.5643683241135671\n",
      "Epoch 16, Loss: 0.5634926937445355\n",
      "Epoch 17, Loss: 0.5626750779543934\n",
      "Epoch 18, Loss: 0.5619166316138425\n",
      "Epoch 19, Loss: 0.5612140898059405\n",
      "Epoch 20, Loss: 0.5605633829590266\n",
      "Epoch 21, Loss: 0.5599620839038366\n",
      "Epoch 22, Loss: 0.5594501199842681\n",
      "Epoch 23, Loss: 0.5589920704523165\n",
      "Epoch 24, Loss: 0.5585682469661696\n",
      "Epoch 25, Loss: 0.5581752836893632\n",
      "Epoch 26, Loss: 0.5578105477691596\n",
      "Epoch 27, Loss: 0.5574754578273273\n",
      "Epoch 28, Loss: 0.55717001386366\n",
      "Epoch 29, Loss: 0.5568932746260548\n",
      "Epoch 30, Loss: 0.5566498872755987\n",
      "Epoch 31, Loss: 0.556445626352154\n",
      "Epoch 32, Loss: 0.5562823564784035\n",
      "Epoch 33, Loss: 0.5561306675411872\n",
      "Epoch 34, Loss: 0.5559745417279246\n",
      "Epoch 35, Loss: 0.5558179162998117\n",
      "Epoch 36, Loss: 0.5556604153960935\n",
      "Epoch 37, Loss: 0.5554904767172077\n",
      "Epoch 38, Loss: 0.5553006020958136\n",
      "Epoch 39, Loss: 0.5550796573196297\n",
      "Epoch 40, Loss: 0.5548103894856095\n",
      "Epoch 41, Loss: 0.5544768457282327\n",
      "Epoch 42, Loss: 0.5540631770061525\n",
      "Epoch 43, Loss: 0.5535433345688671\n",
      "Epoch 44, Loss: 0.552895808824249\n",
      "Epoch 45, Loss: 0.5521050364948805\n",
      "Epoch 46, Loss: 0.5511358756266098\n",
      "Epoch 47, Loss: 0.549954815655796\n",
      "Epoch 48, Loss: 0.5485214788583362\n",
      "Epoch 49, Loss: 0.5468018891646533\n",
      "Epoch 50, Loss: 0.544758570548953\n",
      "Epoch 51, Loss: 0.5424104743252806\n",
      "Epoch 52, Loss: 0.5397697729276272\n",
      "Epoch 53, Loss: 0.5368986791555748\n",
      "Epoch 54, Loss: 0.5339502542752496\n",
      "Epoch 55, Loss: 0.5308699089616365\n",
      "Epoch 56, Loss: 0.5277202533721518\n",
      "Epoch 57, Loss: 0.5248517814946146\n",
      "Epoch 58, Loss: 0.5222190796248027\n",
      "Epoch 59, Loss: 0.5199009146646186\n",
      "Epoch 60, Loss: 0.5178188699757535\n",
      "Epoch 61, Loss: 0.5158116840766084\n",
      "Epoch 62, Loss: 0.5136744277948687\n",
      "Epoch 63, Loss: 0.5112834564118475\n",
      "Epoch 64, Loss: 0.5086881863394566\n",
      "Epoch 65, Loss: 0.5060952715425387\n",
      "Epoch 66, Loss: 0.5035634612213578\n",
      "Epoch 67, Loss: 0.5011791392251091\n",
      "Epoch 68, Loss: 0.49900886529298377\n",
      "Epoch 69, Loss: 0.4971273573123405\n",
      "Epoch 70, Loss: 0.49543133763128194\n",
      "Epoch 71, Loss: 0.49382598569913855\n",
      "Epoch 72, Loss: 0.49219697610119195\n",
      "Epoch 73, Loss: 0.49046229197518165\n",
      "Epoch 74, Loss: 0.48856925100225285\n",
      "Epoch 75, Loss: 0.48657917146045615\n",
      "Epoch 76, Loss: 0.48465386946072186\n",
      "Epoch 77, Loss: 0.48272351244243306\n",
      "Epoch 78, Loss: 0.4808284994419001\n",
      "Epoch 79, Loss: 0.4789832341111035\n",
      "Epoch 80, Loss: 0.47721062035249756\n",
      "Epoch 81, Loss: 0.4754488236247373\n",
      "Epoch 82, Loss: 0.47362881688271136\n",
      "Epoch 83, Loss: 0.4717215762285882\n",
      "Epoch 84, Loss: 0.4697151103378349\n",
      "Epoch 85, Loss: 0.46763568992296045\n",
      "Epoch 86, Loss: 0.4656312346841088\n",
      "Epoch 87, Loss: 0.46375409805666995\n",
      "Epoch 88, Loss: 0.4620774607146187\n",
      "Epoch 89, Loss: 0.46063308038443507\n",
      "Epoch 90, Loss: 0.45942922907859657\n",
      "Epoch 91, Loss: 0.4584554830975254\n",
      "Epoch 92, Loss: 0.4576009639220072\n",
      "Epoch 93, Loss: 0.4567445361035557\n",
      "Epoch 94, Loss: 0.45574493017635914\n",
      "Epoch 95, Loss: 0.4545777152274031\n",
      "Epoch 96, Loss: 0.4534625900498964\n",
      "Epoch 97, Loss: 0.4525719424483458\n",
      "Epoch 98, Loss: 0.45193051056593464\n",
      "Epoch 99, Loss: 0.45161112751205135\n",
      "Epoch 100, Loss: 0.4509261812308289\n",
      "Epoch 101, Loss: 0.44971017908906097\n",
      "Epoch 102, Loss: 0.4492478568557202\n",
      "Epoch 103, Loss: 0.4482507974965394\n",
      "Epoch 104, Loss: 0.44753818452943245\n",
      "Epoch 105, Loss: 0.44679593740659374\n",
      "Epoch 106, Loss: 0.44601717624070475\n",
      "Epoch 107, Loss: 0.4453845216834432\n",
      "Epoch 108, Loss: 0.44454335831441166\n",
      "Epoch 109, Loss: 0.4439929518709428\n",
      "Epoch 110, Loss: 0.4431812583979826\n",
      "Epoch 111, Loss: 0.44258141848895055\n",
      "Epoch 112, Loss: 0.44190189924472933\n",
      "Epoch 113, Loss: 0.44117871049003826\n",
      "Epoch 114, Loss: 0.4406140569586061\n",
      "Epoch 115, Loss: 0.439902588616811\n",
      "Epoch 116, Loss: 0.43919064630348\n",
      "Epoch 117, Loss: 0.43857218288101146\n",
      "Epoch 118, Loss: 0.43777622290431695\n",
      "Epoch 119, Loss: 0.43699976728921974\n",
      "Epoch 120, Loss: 0.4364100400689765\n",
      "Epoch 121, Loss: 0.43570218930717686\n",
      "Epoch 122, Loss: 0.4349636398115006\n",
      "Epoch 123, Loss: 0.4343901528658829\n",
      "Epoch 124, Loss: 0.43372468432004285\n",
      "Epoch 125, Loss: 0.43297830497471057\n",
      "Epoch 126, Loss: 0.4323691007669923\n",
      "Epoch 127, Loss: 0.43183794301506334\n",
      "Epoch 128, Loss: 0.4312227910898327\n",
      "Epoch 129, Loss: 0.43051347240607213\n",
      "Epoch 130, Loss: 0.4299288851959988\n",
      "Epoch 131, Loss: 0.4293998969521241\n",
      "Epoch 132, Loss: 0.4287400811441018\n",
      "Epoch 133, Loss: 0.42801604729275317\n",
      "Epoch 134, Loss: 0.42738191897918876\n",
      "Epoch 135, Loss: 0.42682247413983154\n",
      "Epoch 136, Loss: 0.42619219905457345\n",
      "Epoch 137, Loss: 0.4255477720096743\n",
      "Epoch 138, Loss: 0.4248580899050975\n",
      "Epoch 139, Loss: 0.42417164254720535\n",
      "Epoch 140, Loss: 0.42348927255260266\n",
      "Epoch 141, Loss: 0.42283070008436935\n",
      "Epoch 142, Loss: 0.4222031482702033\n",
      "Epoch 143, Loss: 0.4216954590965211\n",
      "Epoch 144, Loss: 0.4214560583181761\n",
      "Epoch 145, Loss: 0.42136999209768394\n",
      "Epoch 146, Loss: 0.42064292569103573\n",
      "Epoch 147, Loss: 0.4191649423675008\n",
      "Epoch 148, Loss: 0.4189063456448791\n",
      "Epoch 149, Loss: 0.4187366704100323\n",
      "Epoch 150, Loss: 0.4175164101282297\n",
      "Epoch 151, Loss: 0.41697582060879934\n",
      "Epoch 152, Loss: 0.41680898818599993\n",
      "Epoch 153, Loss: 0.41588975676786205\n",
      "Epoch 154, Loss: 0.41518866142927074\n",
      "Epoch 155, Loss: 0.4149406944837995\n",
      "Epoch 156, Loss: 0.4142618059526085\n",
      "Epoch 157, Loss: 0.41352928665168975\n",
      "Epoch 158, Loss: 0.41319699068469223\n",
      "Epoch 159, Loss: 0.4127783565854469\n",
      "Epoch 160, Loss: 0.4121727736461949\n",
      "Epoch 161, Loss: 0.4114662141487839\n",
      "Epoch 162, Loss: 0.41098567114631684\n",
      "Epoch 163, Loss: 0.41065421983173356\n",
      "Epoch 164, Loss: 0.4102789559057205\n",
      "Epoch 165, Loss: 0.40974616485439436\n",
      "Epoch 166, Loss: 0.40911657169796944\n",
      "Epoch 167, Loss: 0.40849629510906016\n",
      "Epoch 168, Loss: 0.4079468209937741\n",
      "Epoch 169, Loss: 0.4075497778521604\n",
      "Epoch 170, Loss: 0.4072485718851358\n",
      "Epoch 171, Loss: 0.40704175016657657\n",
      "Epoch 172, Loss: 0.4069239821007232\n",
      "Epoch 173, Loss: 0.40653404062928883\n",
      "Epoch 174, Loss: 0.4056579053078163\n",
      "Epoch 175, Loss: 0.4047747565798322\n",
      "Epoch 176, Loss: 0.40430216394180757\n",
      "Epoch 177, Loss: 0.40422190095420246\n",
      "Epoch 178, Loss: 0.4040491570720606\n",
      "Epoch 179, Loss: 0.4038325421428815\n",
      "Epoch 180, Loss: 0.4030547664880569\n",
      "Epoch 181, Loss: 0.4021857608855378\n",
      "Epoch 182, Loss: 0.4016398040044823\n",
      "Epoch 183, Loss: 0.40153846891464606\n",
      "Epoch 184, Loss: 0.40153455377253183\n",
      "Epoch 185, Loss: 0.4012738604299297\n",
      "Epoch 186, Loss: 0.40068437918823824\n",
      "Epoch 187, Loss: 0.39971213189549\n",
      "Epoch 188, Loss: 0.39900120894050534\n",
      "Epoch 189, Loss: 0.398588993219085\n",
      "Epoch 190, Loss: 0.39840097820969067\n",
      "Epoch 191, Loss: 0.3984836102900018\n",
      "Epoch 192, Loss: 0.39858994652979474\n",
      "Epoch 193, Loss: 0.39842022129067056\n",
      "Epoch 194, Loss: 0.3974166770491649\n",
      "Epoch 195, Loss: 0.396223254730205\n",
      "Epoch 196, Loss: 0.39592722565553545\n",
      "Epoch 197, Loss: 0.39614601918986103\n",
      "Epoch 198, Loss: 0.3959905057200036\n",
      "Epoch 199, Loss: 0.39508559684786254\n",
      "Epoch 200, Loss: 0.3942667763961968\n",
      "Epoch 201, Loss: 0.3938185609436768\n",
      "Epoch 202, Loss: 0.39370942209449644\n",
      "Epoch 203, Loss: 0.39365961081843304\n",
      "Epoch 204, Loss: 0.39351189998388175\n",
      "Epoch 205, Loss: 0.3933548905269469\n",
      "Epoch 206, Loss: 0.39260161979552965\n",
      "Epoch 207, Loss: 0.39181955791012285\n",
      "Epoch 208, Loss: 0.3911303112880014\n",
      "Epoch 209, Loss: 0.39069526040488145\n",
      "Epoch 210, Loss: 0.39046383394014145\n",
      "Epoch 211, Loss: 0.39044500018457917\n",
      "Epoch 212, Loss: 0.391027205350047\n",
      "Epoch 213, Loss: 0.3919390320672671\n",
      "Epoch 214, Loss: 0.39205001305705517\n",
      "Epoch 215, Loss: 0.3902253968024132\n",
      "Epoch 216, Loss: 0.3883447276675837\n",
      "Epoch 217, Loss: 0.38867384943628325\n",
      "Epoch 218, Loss: 0.3894482626654491\n",
      "Epoch 219, Loss: 0.38874402167332334\n",
      "Epoch 220, Loss: 0.38713736947744626\n",
      "Epoch 221, Loss: 0.38703065874457293\n",
      "Epoch 222, Loss: 0.3878316567459446\n",
      "Epoch 223, Loss: 0.38692894434724184\n",
      "Epoch 224, Loss: 0.38586491431156583\n",
      "Epoch 225, Loss: 0.38543907521375836\n",
      "Epoch 226, Loss: 0.38591943845300597\n",
      "Epoch 227, Loss: 0.38597501657356087\n",
      "Epoch 228, Loss: 0.3855529707375533\n",
      "Epoch 229, Loss: 0.38466151034261603\n",
      "Epoch 230, Loss: 0.38351879358682556\n",
      "Epoch 231, Loss: 0.38314514888160023\n",
      "Epoch 232, Loss: 0.3831057301291168\n",
      "Epoch 233, Loss: 0.38315846905284684\n",
      "Epoch 234, Loss: 0.3836122838532678\n",
      "Epoch 235, Loss: 0.38397024212088815\n",
      "Epoch 236, Loss: 0.3838503645454555\n",
      "Epoch 237, Loss: 0.3829515554925208\n",
      "Epoch 238, Loss: 0.38155852482105146\n",
      "Epoch 239, Loss: 0.3803574017275026\n",
      "Epoch 240, Loss: 0.38024316480112497\n",
      "Epoch 241, Loss: 0.38088541186417163\n",
      "Epoch 242, Loss: 0.3823528254733191\n",
      "Epoch 243, Loss: 0.38387441292745506\n",
      "Epoch 244, Loss: 0.381759596898249\n",
      "Epoch 245, Loss: 0.3791330582881386\n",
      "Epoch 246, Loss: 0.37826765459061307\n",
      "Epoch 247, Loss: 0.3798040391696166\n",
      "Epoch 248, Loss: 0.38145833967380044\n",
      "Epoch 249, Loss: 0.37941799803123977\n",
      "Epoch 250, Loss: 0.37722499708435675\n",
      "Epoch 251, Loss: 0.3767455720470416\n",
      "Epoch 252, Loss: 0.37770032206499643\n",
      "Epoch 253, Loss: 0.37869876411156744\n",
      "Epoch 254, Loss: 0.3778621406222083\n",
      "Epoch 255, Loss: 0.3763727453956741\n",
      "Epoch 256, Loss: 0.37531074920550855\n",
      "Epoch 257, Loss: 0.3749527901496446\n",
      "Epoch 258, Loss: 0.375581072588839\n",
      "Epoch 259, Loss: 0.3764287434053015\n",
      "Epoch 260, Loss: 0.3770965935639474\n",
      "Epoch 261, Loss: 0.3759333399909519\n",
      "Epoch 262, Loss: 0.3745647129328916\n",
      "Epoch 263, Loss: 0.3733792846186092\n",
      "Epoch 264, Loss: 0.3730655286029797\n",
      "Epoch 265, Loss: 0.3738156331525285\n",
      "Epoch 266, Loss: 0.3750761471366261\n",
      "Epoch 267, Loss: 0.37686492204239264\n",
      "Epoch 268, Loss: 0.3756920468733166\n",
      "Epoch 269, Loss: 0.3734641412784657\n",
      "Epoch 270, Loss: 0.3716287871731414\n",
      "Epoch 271, Loss: 0.3718521600008335\n",
      "Epoch 272, Loss: 0.37357251348249376\n",
      "Epoch 273, Loss: 0.3754666921215518\n",
      "Epoch 274, Loss: 0.3751925728979378\n",
      "Epoch 275, Loss: 0.3718635204691129\n",
      "Epoch 276, Loss: 0.3701796063855656\n",
      "Epoch 277, Loss: 0.3711615450318286\n",
      "Epoch 278, Loss: 0.3727668390186722\n",
      "Epoch 279, Loss: 0.37317339763786733\n",
      "Epoch 280, Loss: 0.3706235014256356\n",
      "Epoch 281, Loss: 0.3691789516352439\n",
      "Epoch 282, Loss: 0.3695933477312942\n",
      "Epoch 283, Loss: 0.37078195825019644\n",
      "Epoch 284, Loss: 0.37194882309270155\n",
      "Epoch 285, Loss: 0.37094562987599233\n",
      "Epoch 286, Loss: 0.3689841488803782\n",
      "Epoch 287, Loss: 0.36773583882941896\n",
      "Epoch 288, Loss: 0.3683778460858352\n",
      "Epoch 289, Loss: 0.36958984007298906\n",
      "Epoch 290, Loss: 0.3704972542649432\n",
      "Epoch 291, Loss: 0.37097145876386767\n",
      "Epoch 292, Loss: 0.3682326194820723\n",
      "Epoch 293, Loss: 0.36675984253577\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2578764424418327\n",
      "Test R^2 score: 0.2760142731785364\n",
      "Num of epochs: 294\n",
      "Epoch 1, Loss: 0.5842238990738385\n",
      "Epoch 2, Loss: 0.5829721820109659\n",
      "Epoch 3, Loss: 0.5817521981647373\n",
      "Epoch 4, Loss: 0.580563351917494\n",
      "Epoch 5, Loss: 0.5794091011143044\n",
      "Epoch 6, Loss: 0.5784124999823911\n",
      "Epoch 7, Loss: 0.5774800337192674\n",
      "Epoch 8, Loss: 0.5765650813760838\n",
      "Epoch 9, Loss: 0.5756661215889843\n",
      "Epoch 10, Loss: 0.5748098535853209\n",
      "Epoch 11, Loss: 0.5739735709196795\n",
      "Epoch 12, Loss: 0.5731655505029818\n",
      "Epoch 13, Loss: 0.572380575150819\n",
      "Epoch 14, Loss: 0.5716048712691016\n",
      "Epoch 15, Loss: 0.5708407999046938\n",
      "Epoch 16, Loss: 0.5700849314206594\n",
      "Epoch 17, Loss: 0.5693318021699356\n",
      "Epoch 18, Loss: 0.568585144506182\n",
      "Epoch 19, Loss: 0.567845141407391\n",
      "Epoch 20, Loss: 0.5671294758018695\n",
      "Epoch 21, Loss: 0.5664192724375156\n",
      "Epoch 22, Loss: 0.5657410497324067\n",
      "Epoch 23, Loss: 0.5650559212852608\n",
      "Epoch 24, Loss: 0.5643695386620243\n",
      "Epoch 25, Loss: 0.5637624930797005\n",
      "Epoch 26, Loss: 0.5631489454167918\n",
      "Epoch 27, Loss: 0.5625378013200955\n",
      "Epoch 28, Loss: 0.561927026752249\n",
      "Epoch 29, Loss: 0.5612945620936188\n",
      "Epoch 30, Loss: 0.560620399464727\n",
      "Epoch 31, Loss: 0.5599420454486066\n",
      "Epoch 32, Loss: 0.5592091778098225\n",
      "Epoch 33, Loss: 0.558360577981394\n",
      "Epoch 34, Loss: 0.5574682407570349\n",
      "Epoch 35, Loss: 0.556534981323051\n",
      "Epoch 36, Loss: 0.5554901011638257\n",
      "Epoch 37, Loss: 0.5542970008124114\n",
      "Epoch 38, Loss: 0.5529401955369071\n",
      "Epoch 39, Loss: 0.5513783998663462\n",
      "Epoch 40, Loss: 0.5495571304140527\n",
      "Epoch 41, Loss: 0.5473825823931006\n",
      "Epoch 42, Loss: 0.5447676519008553\n",
      "Epoch 43, Loss: 0.5415972396177328\n",
      "Epoch 44, Loss: 0.5378275006611104\n",
      "Epoch 45, Loss: 0.5335838998357333\n",
      "Epoch 46, Loss: 0.5291770151833517\n",
      "Epoch 47, Loss: 0.5253308343723004\n",
      "Epoch 48, Loss: 0.523197204319385\n",
      "Epoch 49, Loss: 0.5230115609359124\n",
      "Epoch 50, Loss: 0.5217315145360846\n",
      "Epoch 51, Loss: 0.5179936306646532\n",
      "Epoch 52, Loss: 0.5135483683934856\n",
      "Epoch 53, Loss: 0.5102340767397671\n",
      "Epoch 54, Loss: 0.5084749156218679\n",
      "Epoch 55, Loss: 0.5071689929981932\n",
      "Epoch 56, Loss: 0.5050761518565239\n",
      "Epoch 57, Loss: 0.502108776139062\n",
      "Epoch 58, Loss: 0.4989597705456682\n",
      "Epoch 59, Loss: 0.496500314236068\n",
      "Epoch 60, Loss: 0.4950176643100075\n",
      "Epoch 61, Loss: 0.4937605470424182\n",
      "Epoch 62, Loss: 0.49172425040631523\n",
      "Epoch 63, Loss: 0.4892097647520116\n",
      "Epoch 64, Loss: 0.4873274069709262\n",
      "Epoch 65, Loss: 0.4861589007122988\n",
      "Epoch 66, Loss: 0.48470095465140894\n",
      "Epoch 67, Loss: 0.48268159060705573\n",
      "Epoch 68, Loss: 0.4809218650393257\n",
      "Epoch 69, Loss: 0.479792234934201\n",
      "Epoch 70, Loss: 0.4785707403088564\n",
      "Epoch 71, Loss: 0.47697182571028285\n",
      "Epoch 72, Loss: 0.4755722607911774\n",
      "Epoch 73, Loss: 0.47452737547266455\n",
      "Epoch 74, Loss: 0.47321680420464995\n",
      "Epoch 75, Loss: 0.4716998899568078\n",
      "Epoch 76, Loss: 0.470414369899638\n",
      "Epoch 77, Loss: 0.46911096979410216\n",
      "Epoch 78, Loss: 0.4673957972749351\n",
      "Epoch 79, Loss: 0.4657117769166863\n",
      "Epoch 80, Loss: 0.464385504006948\n",
      "Epoch 81, Loss: 0.4630977794817624\n",
      "Epoch 82, Loss: 0.4617548984893559\n",
      "Epoch 83, Loss: 0.4604641374940138\n",
      "Epoch 84, Loss: 0.4593761152137143\n",
      "Epoch 85, Loss: 0.45864901364024024\n",
      "Epoch 86, Loss: 0.45804374570133843\n",
      "Epoch 87, Loss: 0.4573777670243586\n",
      "Epoch 88, Loss: 0.45667052093617316\n",
      "Epoch 89, Loss: 0.455838758824551\n",
      "Epoch 90, Loss: 0.4550070154519057\n",
      "Epoch 91, Loss: 0.4540919149050767\n",
      "Epoch 92, Loss: 0.4531602352517688\n",
      "Epoch 93, Loss: 0.45228347244934364\n",
      "Epoch 94, Loss: 0.45151610680615917\n",
      "Epoch 95, Loss: 0.45081982769835527\n",
      "Epoch 96, Loss: 0.4500954242037657\n",
      "Epoch 97, Loss: 0.44934738639380467\n",
      "Epoch 98, Loss: 0.44861456003953065\n",
      "Epoch 99, Loss: 0.44792852459965576\n",
      "Epoch 100, Loss: 0.4472525648850598\n",
      "Epoch 101, Loss: 0.44654850336540963\n",
      "Epoch 102, Loss: 0.44585736720941677\n",
      "Epoch 103, Loss: 0.445200705298536\n",
      "Epoch 104, Loss: 0.44456030242861583\n",
      "Epoch 105, Loss: 0.4439558478538983\n",
      "Epoch 106, Loss: 0.44336166045150205\n",
      "Epoch 107, Loss: 0.44275360062985897\n",
      "Epoch 108, Loss: 0.44213398720815056\n",
      "Epoch 109, Loss: 0.4415122048472018\n",
      "Epoch 110, Loss: 0.44089524051050977\n",
      "Epoch 111, Loss: 0.4402902725056623\n",
      "Epoch 112, Loss: 0.4397037893231777\n",
      "Epoch 113, Loss: 0.43925995713826055\n",
      "Epoch 114, Loss: 0.43874542896900093\n",
      "Epoch 115, Loss: 0.4381390740478116\n",
      "Epoch 116, Loss: 0.4371411009482984\n",
      "Epoch 117, Loss: 0.4365624361304398\n",
      "Epoch 118, Loss: 0.43626795723581585\n",
      "Epoch 119, Loss: 0.4354985642261685\n",
      "Epoch 120, Loss: 0.43467599676668106\n",
      "Epoch 121, Loss: 0.43410884057792554\n",
      "Epoch 122, Loss: 0.433689587973013\n",
      "Epoch 123, Loss: 0.4331945867359177\n",
      "Epoch 124, Loss: 0.4324619195413728\n",
      "Epoch 125, Loss: 0.43182144865369965\n",
      "Epoch 126, Loss: 0.43131221170475204\n",
      "Epoch 127, Loss: 0.43088926970732166\n",
      "Epoch 128, Loss: 0.4305192007419518\n",
      "Epoch 129, Loss: 0.4300596532917315\n",
      "Epoch 130, Loss: 0.42952661103109163\n",
      "Epoch 131, Loss: 0.4289263312358534\n",
      "Epoch 132, Loss: 0.4283999659918924\n",
      "Epoch 133, Loss: 0.42796157655417705\n",
      "Epoch 134, Loss: 0.42758653428604326\n",
      "Epoch 135, Loss: 0.427344000361228\n",
      "Epoch 136, Loss: 0.42708930926290145\n",
      "Epoch 137, Loss: 0.42703105637580513\n",
      "Epoch 138, Loss: 0.42626947881429555\n",
      "Epoch 139, Loss: 0.4253350991405008\n",
      "Epoch 140, Loss: 0.4247984611668795\n",
      "Epoch 141, Loss: 0.42470177467164927\n",
      "Epoch 142, Loss: 0.4243682899843518\n",
      "Epoch 143, Loss: 0.42354095856094026\n",
      "Epoch 144, Loss: 0.4229721179401083\n",
      "Epoch 145, Loss: 0.4228218191491496\n",
      "Epoch 146, Loss: 0.4226529401554386\n",
      "Epoch 147, Loss: 0.42231760825465914\n",
      "Epoch 148, Loss: 0.421577772764498\n",
      "Epoch 149, Loss: 0.420933945434787\n",
      "Epoch 150, Loss: 0.4206752672243213\n",
      "Epoch 151, Loss: 0.4205580926256881\n",
      "Epoch 152, Loss: 0.42031265528225775\n",
      "Epoch 153, Loss: 0.41963180459317495\n",
      "Epoch 154, Loss: 0.4189709564398995\n",
      "Epoch 155, Loss: 0.41858045433718044\n",
      "Epoch 156, Loss: 0.4183956176845139\n",
      "Epoch 157, Loss: 0.4182677402815499\n",
      "Epoch 158, Loss: 0.417823160074036\n",
      "Epoch 159, Loss: 0.4172348459930613\n",
      "Epoch 160, Loss: 0.41659183624974905\n",
      "Epoch 161, Loss: 0.41619496666184974\n",
      "Epoch 162, Loss: 0.41599085559445836\n",
      "Epoch 163, Loss: 0.41580755555530025\n",
      "Epoch 164, Loss: 0.4156389635651638\n",
      "Epoch 165, Loss: 0.4151881589676134\n",
      "Epoch 166, Loss: 0.41461328545238096\n",
      "Epoch 167, Loss: 0.413918362127423\n",
      "Epoch 168, Loss: 0.41337865464031404\n",
      "Epoch 169, Loss: 0.4129913979424232\n",
      "Epoch 170, Loss: 0.41274916897279385\n",
      "Epoch 171, Loss: 0.41281357030852506\n",
      "Epoch 172, Loss: 0.41345441900395136\n",
      "Epoch 173, Loss: 0.4150304995382742\n",
      "Epoch 174, Loss: 0.4129524105330989\n",
      "Epoch 175, Loss: 0.41086680308197404\n",
      "Epoch 176, Loss: 0.4117726401107577\n",
      "Epoch 177, Loss: 0.4118451541512277\n",
      "Epoch 178, Loss: 0.4102401829172019\n",
      "Epoch 179, Loss: 0.41010140551870616\n",
      "Epoch 180, Loss: 0.4106999562855826\n",
      "Epoch 181, Loss: 0.40950376291024987\n",
      "Epoch 182, Loss: 0.4087156883327489\n",
      "Epoch 183, Loss: 0.40918065255354014\n",
      "Epoch 184, Loss: 0.4089812387020088\n",
      "Epoch 185, Loss: 0.40764784576537416\n",
      "Epoch 186, Loss: 0.4075396498305949\n",
      "Epoch 187, Loss: 0.40774894160607533\n",
      "Epoch 188, Loss: 0.40699822041054523\n",
      "Epoch 189, Loss: 0.4062341356847887\n",
      "Epoch 190, Loss: 0.4061376709797416\n",
      "Epoch 191, Loss: 0.4060537891460571\n",
      "Epoch 192, Loss: 0.4056666844760313\n",
      "Epoch 193, Loss: 0.40503220330058387\n",
      "Epoch 194, Loss: 0.4046212521386242\n",
      "Epoch 195, Loss: 0.4044743392594699\n",
      "Epoch 196, Loss: 0.4043809370286042\n",
      "Epoch 197, Loss: 0.40433713924394105\n",
      "Epoch 198, Loss: 0.4040125155528607\n",
      "Epoch 199, Loss: 0.40366786363431045\n",
      "Epoch 200, Loss: 0.4030609959795966\n",
      "Epoch 201, Loss: 0.4025379008758087\n",
      "Epoch 202, Loss: 0.4021507281645296\n",
      "Epoch 203, Loss: 0.4019477525061002\n",
      "Epoch 204, Loss: 0.40189286309464395\n",
      "Epoch 205, Loss: 0.40192560114662834\n",
      "Epoch 206, Loss: 0.4022654299754998\n",
      "Epoch 207, Loss: 0.4024376620715781\n",
      "Epoch 208, Loss: 0.4028584789495043\n",
      "Epoch 209, Loss: 0.4014540343985674\n",
      "Epoch 210, Loss: 0.4000589439056448\n",
      "Epoch 211, Loss: 0.39959341559884987\n",
      "Epoch 212, Loss: 0.40014058190787605\n",
      "Epoch 213, Loss: 0.4007051302658305\n",
      "Epoch 214, Loss: 0.3997528952039854\n",
      "Epoch 215, Loss: 0.3986561493161409\n",
      "Epoch 216, Loss: 0.3980827809499595\n",
      "Epoch 217, Loss: 0.39820855238585384\n",
      "Epoch 218, Loss: 0.3986637744532858\n",
      "Epoch 219, Loss: 0.39869696452772324\n",
      "Epoch 220, Loss: 0.39820396834881594\n",
      "Epoch 221, Loss: 0.39700277854682176\n",
      "Epoch 222, Loss: 0.39639888273917956\n",
      "Epoch 223, Loss: 0.39649610079258735\n",
      "Epoch 224, Loss: 0.3968105383959839\n",
      "Epoch 225, Loss: 0.39706975258535826\n",
      "Epoch 226, Loss: 0.39648125558011243\n",
      "Epoch 227, Loss: 0.3955174951192283\n",
      "Epoch 228, Loss: 0.39471338807874196\n",
      "Epoch 229, Loss: 0.3944690957541206\n",
      "Epoch 230, Loss: 0.3946712736417183\n",
      "Epoch 231, Loss: 0.39494221122746065\n",
      "Epoch 232, Loss: 0.3951739373704002\n",
      "Epoch 233, Loss: 0.3948574606021183\n",
      "Epoch 234, Loss: 0.39407403343680864\n",
      "Epoch 235, Loss: 0.3930048355309797\n",
      "Epoch 236, Loss: 0.3924007299651201\n",
      "Epoch 237, Loss: 0.3923877615115738\n",
      "Epoch 238, Loss: 0.3926823036545826\n",
      "Epoch 239, Loss: 0.39332238622897847\n",
      "Epoch 240, Loss: 0.3935305680298059\n",
      "Epoch 241, Loss: 0.39324490303063675\n",
      "Epoch 242, Loss: 0.39184258480554385\n",
      "Epoch 243, Loss: 0.39070740784187674\n",
      "Epoch 244, Loss: 0.39025617353405867\n",
      "Epoch 245, Loss: 0.39050323495855915\n",
      "Epoch 246, Loss: 0.39114777868864814\n",
      "Epoch 247, Loss: 0.39151490886601575\n",
      "Epoch 248, Loss: 0.3910964600259218\n",
      "Epoch 249, Loss: 0.38983010476490465\n",
      "Epoch 250, Loss: 0.38875519515978857\n",
      "Epoch 251, Loss: 0.3882664046337469\n",
      "Epoch 252, Loss: 0.3885173969853561\n",
      "Epoch 253, Loss: 0.38922235429795554\n",
      "Epoch 254, Loss: 0.3896923948652014\n",
      "Epoch 255, Loss: 0.3894606020409595\n",
      "Epoch 256, Loss: 0.3882005603849129\n",
      "Epoch 257, Loss: 0.38705974534020193\n",
      "Epoch 258, Loss: 0.38627601094608943\n",
      "Epoch 259, Loss: 0.38640703296080725\n",
      "Epoch 260, Loss: 0.38717016210523125\n",
      "Epoch 261, Loss: 0.38768391628475474\n",
      "Epoch 262, Loss: 0.38780929465740577\n",
      "Epoch 263, Loss: 0.38667025406518873\n",
      "Epoch 264, Loss: 0.38538015252775853\n",
      "Epoch 265, Loss: 0.38438962582930153\n",
      "Epoch 266, Loss: 0.38446108389083045\n",
      "Epoch 267, Loss: 0.38548051674661443\n",
      "Epoch 268, Loss: 0.3856950368915978\n",
      "Epoch 269, Loss: 0.38556294200004315\n",
      "Epoch 270, Loss: 0.3842598742691201\n",
      "Epoch 271, Loss: 0.3828504893857397\n",
      "Epoch 272, Loss: 0.3824817630060436\n",
      "Epoch 273, Loss: 0.38300021104209203\n",
      "Epoch 274, Loss: 0.38364531953134895\n",
      "Epoch 275, Loss: 0.3835156075622716\n",
      "Epoch 276, Loss: 0.3828386764918818\n",
      "Epoch 277, Loss: 0.3816255541103025\n",
      "Epoch 278, Loss: 0.38075806664170475\n",
      "Epoch 279, Loss: 0.38044344369435695\n",
      "Epoch 280, Loss: 0.3806517793289361\n",
      "Epoch 281, Loss: 0.38100827558671135\n",
      "Epoch 282, Loss: 0.3815220081360765\n",
      "Epoch 283, Loss: 0.38226200927670945\n",
      "Epoch 284, Loss: 0.38184399608488934\n",
      "Epoch 285, Loss: 0.38129517490836606\n",
      "Epoch 286, Loss: 0.37966300665576347\n",
      "Epoch 287, Loss: 0.37827498164886275\n",
      "Epoch 288, Loss: 0.3782659409839319\n",
      "Epoch 289, Loss: 0.3792448006111969\n",
      "Epoch 290, Loss: 0.3807510221847068\n",
      "Epoch 291, Loss: 0.381072664447833\n",
      "Epoch 292, Loss: 0.3800374674834654\n",
      "Epoch 293, Loss: 0.3773864666629887\n",
      "Epoch 294, Loss: 0.3764422616481706\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.24019441838530237\n",
      "Test R^2 score: 0.37921112622020586\n",
      "Num of epochs: 295\n",
      "Epoch 1, Loss: 0.574876991880665\n",
      "Epoch 2, Loss: 0.5735776527284583\n",
      "Epoch 3, Loss: 0.5723008805699616\n",
      "Epoch 4, Loss: 0.571048679478071\n",
      "Epoch 5, Loss: 0.5698413208893239\n",
      "Epoch 6, Loss: 0.5687002621375913\n",
      "Epoch 7, Loss: 0.5675677262447754\n",
      "Epoch 8, Loss: 0.5664307950719578\n",
      "Epoch 9, Loss: 0.5653179367925838\n",
      "Epoch 10, Loss: 0.5642341532224937\n",
      "Epoch 11, Loss: 0.5632621846563678\n",
      "Epoch 12, Loss: 0.5623802216476724\n",
      "Epoch 13, Loss: 0.5615532112520909\n",
      "Epoch 14, Loss: 0.5607627160683707\n",
      "Epoch 15, Loss: 0.5600047929592743\n",
      "Epoch 16, Loss: 0.5592748051421399\n",
      "Epoch 17, Loss: 0.5585804917689444\n",
      "Epoch 18, Loss: 0.5579251643078088\n",
      "Epoch 19, Loss: 0.5573103506456002\n",
      "Epoch 20, Loss: 0.5567367470717959\n",
      "Epoch 21, Loss: 0.5562035434053806\n",
      "Epoch 22, Loss: 0.5557078526946178\n",
      "Epoch 23, Loss: 0.5552411070330073\n",
      "Epoch 24, Loss: 0.5547971482769505\n",
      "Epoch 25, Loss: 0.5543795523300684\n",
      "Epoch 26, Loss: 0.553955078125\n",
      "Epoch 27, Loss: 0.5535018499217698\n",
      "Epoch 28, Loss: 0.5529904800030182\n",
      "Epoch 29, Loss: 0.5523526116810895\n",
      "Epoch 30, Loss: 0.5514990275660611\n",
      "Epoch 31, Loss: 0.5503382964535227\n",
      "Epoch 32, Loss: 0.5488009734581636\n",
      "Epoch 33, Loss: 0.5469274223270159\n",
      "Epoch 34, Loss: 0.544765272163639\n",
      "Epoch 35, Loss: 0.5425415554040169\n",
      "Epoch 36, Loss: 0.5403921066689622\n",
      "Epoch 37, Loss: 0.5383759701775214\n",
      "Epoch 38, Loss: 0.5364608733725058\n",
      "Epoch 39, Loss: 0.5342825000857867\n",
      "Epoch 40, Loss: 0.5315796166141694\n",
      "Epoch 41, Loss: 0.528664580765963\n",
      "Epoch 42, Loss: 0.5260733950523329\n",
      "Epoch 43, Loss: 0.5238478176844475\n",
      "Epoch 44, Loss: 0.5218221020872251\n",
      "Epoch 45, Loss: 0.5197598807554885\n",
      "Epoch 46, Loss: 0.5175413874417667\n",
      "Epoch 47, Loss: 0.5152232309890328\n",
      "Epoch 48, Loss: 0.513074607419081\n",
      "Epoch 49, Loss: 0.5112238230450927\n",
      "Epoch 50, Loss: 0.5094094914185255\n",
      "Epoch 51, Loss: 0.5075613721373021\n",
      "Epoch 52, Loss: 0.5059010256554605\n",
      "Epoch 53, Loss: 0.5042968241767651\n",
      "Epoch 54, Loss: 0.502546946244682\n",
      "Epoch 55, Loss: 0.500775927249038\n",
      "Epoch 56, Loss: 0.4992256725231292\n",
      "Epoch 57, Loss: 0.4977278940799456\n",
      "Epoch 58, Loss: 0.4960515011796902\n",
      "Epoch 59, Loss: 0.4944567969323435\n",
      "Epoch 60, Loss: 0.49306131935631065\n",
      "Epoch 61, Loss: 0.4916336485584307\n",
      "Epoch 62, Loss: 0.49020759539772235\n",
      "Epoch 63, Loss: 0.48886877189986055\n",
      "Epoch 64, Loss: 0.48747543982236474\n",
      "Epoch 65, Loss: 0.4861766318790857\n",
      "Epoch 66, Loss: 0.4849930327445938\n",
      "Epoch 67, Loss: 0.48375309736162164\n",
      "Epoch 68, Loss: 0.48252810339540647\n",
      "Epoch 69, Loss: 0.4813804505395491\n",
      "Epoch 70, Loss: 0.4802177673069634\n",
      "Epoch 71, Loss: 0.47913208781432964\n",
      "Epoch 72, Loss: 0.4780583590770654\n",
      "Epoch 73, Loss: 0.4770327577339083\n",
      "Epoch 74, Loss: 0.47602936362207876\n",
      "Epoch 75, Loss: 0.4749606680898705\n",
      "Epoch 76, Loss: 0.47389880704333165\n",
      "Epoch 77, Loss: 0.4727983970328895\n",
      "Epoch 78, Loss: 0.4717246719296943\n",
      "Epoch 79, Loss: 0.4706449670596079\n",
      "Epoch 80, Loss: 0.4695694436583396\n",
      "Epoch 81, Loss: 0.4685131428258273\n",
      "Epoch 82, Loss: 0.46743049872488124\n",
      "Epoch 83, Loss: 0.46636360203503546\n",
      "Epoch 84, Loss: 0.4652733780841086\n",
      "Epoch 85, Loss: 0.46419072161905195\n",
      "Epoch 86, Loss: 0.4630708786130077\n",
      "Epoch 87, Loss: 0.46195764315876375\n",
      "Epoch 88, Loss: 0.46082836410862377\n",
      "Epoch 89, Loss: 0.45971423617889123\n",
      "Epoch 90, Loss: 0.4585800012870315\n",
      "Epoch 91, Loss: 0.4574761629669468\n",
      "Epoch 92, Loss: 0.45638598022584026\n",
      "Epoch 93, Loss: 0.45529120699826514\n",
      "Epoch 94, Loss: 0.45418951351842285\n",
      "Epoch 95, Loss: 0.4530974741500569\n",
      "Epoch 96, Loss: 0.45200901065132704\n",
      "Epoch 97, Loss: 0.4509220505022125\n",
      "Epoch 98, Loss: 0.4498224762592999\n",
      "Epoch 99, Loss: 0.44871411381949955\n",
      "Epoch 100, Loss: 0.44762471206110366\n",
      "Epoch 101, Loss: 0.4465399606567771\n",
      "Epoch 102, Loss: 0.44544525844539457\n",
      "Epoch 103, Loss: 0.444296179030175\n",
      "Epoch 104, Loss: 0.44313905930376174\n",
      "Epoch 105, Loss: 0.44203655847872514\n",
      "Epoch 106, Loss: 0.44098815697275273\n",
      "Epoch 107, Loss: 0.439995579236754\n",
      "Epoch 108, Loss: 0.4391444669350837\n",
      "Epoch 109, Loss: 0.4385099334592104\n",
      "Epoch 110, Loss: 0.43762155955775633\n",
      "Epoch 111, Loss: 0.43677329267044007\n",
      "Epoch 112, Loss: 0.4361985467555112\n",
      "Epoch 113, Loss: 0.43562376087838917\n",
      "Epoch 114, Loss: 0.4348221981123462\n",
      "Epoch 115, Loss: 0.4340735349907145\n",
      "Epoch 116, Loss: 0.43344335267420486\n",
      "Epoch 117, Loss: 0.43283086111185026\n",
      "Epoch 118, Loss: 0.4319704444132851\n",
      "Epoch 119, Loss: 0.43115541968971083\n",
      "Epoch 120, Loss: 0.4306794248163523\n",
      "Epoch 121, Loss: 0.430098597067891\n",
      "Epoch 122, Loss: 0.4293828577880147\n",
      "Epoch 123, Loss: 0.42876687695064775\n",
      "Epoch 124, Loss: 0.4281812797922005\n",
      "Epoch 125, Loss: 0.42748537175208623\n",
      "Epoch 126, Loss: 0.42677677208447234\n",
      "Epoch 127, Loss: 0.42614723365097956\n",
      "Epoch 128, Loss: 0.4255422218702855\n",
      "Epoch 129, Loss: 0.42484865509153447\n",
      "Epoch 130, Loss: 0.4240860571674784\n",
      "Epoch 131, Loss: 0.42336747410417436\n",
      "Epoch 132, Loss: 0.4226655264522163\n",
      "Epoch 133, Loss: 0.421986847638646\n",
      "Epoch 134, Loss: 0.4213725913145013\n",
      "Epoch 135, Loss: 0.42077541102208593\n",
      "Epoch 136, Loss: 0.42015323032075685\n",
      "Epoch 137, Loss: 0.41952879494742557\n",
      "Epoch 138, Loss: 0.41881536144468295\n",
      "Epoch 139, Loss: 0.4180669936470266\n",
      "Epoch 140, Loss: 0.4173636646725098\n",
      "Epoch 141, Loss: 0.41679701157114496\n",
      "Epoch 142, Loss: 0.41635132618840986\n",
      "Epoch 143, Loss: 0.4159108419495176\n",
      "Epoch 144, Loss: 0.4153879113258455\n",
      "Epoch 145, Loss: 0.41474232556288704\n",
      "Epoch 146, Loss: 0.4140964889971239\n",
      "Epoch 147, Loss: 0.41360167285001675\n",
      "Epoch 148, Loss: 0.4132415442331466\n",
      "Epoch 149, Loss: 0.4129452116222934\n",
      "Epoch 150, Loss: 0.41258295698899317\n",
      "Epoch 151, Loss: 0.4121740209126721\n",
      "Epoch 152, Loss: 0.41158532544956855\n",
      "Epoch 153, Loss: 0.4109764979898783\n",
      "Epoch 154, Loss: 0.4104994836344009\n",
      "Epoch 155, Loss: 0.4101709998975451\n",
      "Epoch 156, Loss: 0.40992441437219884\n",
      "Epoch 157, Loss: 0.40968808294119485\n",
      "Epoch 158, Loss: 0.4094923913968463\n",
      "Epoch 159, Loss: 0.40898781513563515\n",
      "Epoch 160, Loss: 0.4083664307350561\n",
      "Epoch 161, Loss: 0.4078237605093203\n",
      "Epoch 162, Loss: 0.4074999214242497\n",
      "Epoch 163, Loss: 0.4073302505181921\n",
      "Epoch 164, Loss: 0.4072453885563775\n",
      "Epoch 165, Loss: 0.4071316322533693\n",
      "Epoch 166, Loss: 0.4066180066241121\n",
      "Epoch 167, Loss: 0.40594250706028695\n",
      "Epoch 168, Loss: 0.4054511358591668\n",
      "Epoch 169, Loss: 0.40530926649440574\n",
      "Epoch 170, Loss: 0.4052380282088628\n",
      "Epoch 171, Loss: 0.4050313203380551\n",
      "Epoch 172, Loss: 0.40468945079318547\n",
      "Epoch 173, Loss: 0.40403377799660145\n",
      "Epoch 174, Loss: 0.40364039837859617\n",
      "Epoch 175, Loss: 0.4034263711542327\n",
      "Epoch 176, Loss: 0.40344952967974795\n",
      "Epoch 177, Loss: 0.4033073441681165\n",
      "Epoch 178, Loss: 0.4028386895756548\n",
      "Epoch 179, Loss: 0.4023215463678164\n",
      "Epoch 180, Loss: 0.4017380349312741\n",
      "Epoch 181, Loss: 0.40169877140986404\n",
      "Epoch 182, Loss: 0.40173549413931303\n",
      "Epoch 183, Loss: 0.40144056034718195\n",
      "Epoch 184, Loss: 0.4009352910374172\n",
      "Epoch 185, Loss: 0.4002375984843938\n",
      "Epoch 186, Loss: 0.3999556807463061\n",
      "Epoch 187, Loss: 0.39977962115285526\n",
      "Epoch 188, Loss: 0.3996412195548104\n",
      "Epoch 189, Loss: 0.39986567626080843\n",
      "Epoch 190, Loss: 0.39918102750582213\n",
      "Epoch 191, Loss: 0.3988376926391645\n",
      "Epoch 192, Loss: 0.3981792884833792\n",
      "Epoch 193, Loss: 0.3977737882586928\n",
      "Epoch 194, Loss: 0.39767090596169435\n",
      "Epoch 195, Loss: 0.3974326496227221\n",
      "Epoch 196, Loss: 0.39751405853026417\n",
      "Epoch 197, Loss: 0.397011261173731\n",
      "Epoch 198, Loss: 0.3965266726627453\n",
      "Epoch 199, Loss: 0.39617571537576457\n",
      "Epoch 200, Loss: 0.3958314489855168\n",
      "Epoch 201, Loss: 0.39560976951293486\n",
      "Epoch 202, Loss: 0.3956514262613472\n",
      "Epoch 203, Loss: 0.3956838333834892\n",
      "Epoch 204, Loss: 0.39577012017433083\n",
      "Epoch 205, Loss: 0.39582294107481214\n",
      "Epoch 206, Loss: 0.3949367403426654\n",
      "Epoch 207, Loss: 0.39434262289395083\n",
      "Epoch 208, Loss: 0.39423251408858223\n",
      "Epoch 209, Loss: 0.3945543452386535\n",
      "Epoch 210, Loss: 0.3948690460217493\n",
      "Epoch 211, Loss: 0.39436153500720095\n",
      "Epoch 212, Loss: 0.3935076209763856\n",
      "Epoch 213, Loss: 0.3930616295565737\n",
      "Epoch 214, Loss: 0.39307209271410787\n",
      "Epoch 215, Loss: 0.3934791246291193\n",
      "Epoch 216, Loss: 0.3928424837114625\n",
      "Epoch 217, Loss: 0.3923706911074659\n",
      "Epoch 218, Loss: 0.3918456650968634\n",
      "Epoch 219, Loss: 0.3918025958631453\n",
      "Epoch 220, Loss: 0.3917209129441159\n",
      "Epoch 221, Loss: 0.39157859753934515\n",
      "Epoch 222, Loss: 0.39110539460535104\n",
      "Epoch 223, Loss: 0.39090627080533213\n",
      "Epoch 224, Loss: 0.3904288562424223\n",
      "Epoch 225, Loss: 0.3901992957736454\n",
      "Epoch 226, Loss: 0.3900808167780136\n",
      "Epoch 227, Loss: 0.38978717599861484\n",
      "Epoch 228, Loss: 0.38975611372502567\n",
      "Epoch 229, Loss: 0.38961799521784257\n",
      "Epoch 230, Loss: 0.3896607514158954\n",
      "Epoch 231, Loss: 0.389869283172532\n",
      "Epoch 232, Loss: 0.38991470608534595\n",
      "Epoch 233, Loss: 0.38948797684110226\n",
      "Epoch 234, Loss: 0.38875935399126327\n",
      "Epoch 235, Loss: 0.38779945800393184\n",
      "Epoch 236, Loss: 0.3873132509486213\n",
      "Epoch 237, Loss: 0.3871794951799102\n",
      "Epoch 238, Loss: 0.38746372868382195\n",
      "Epoch 239, Loss: 0.3882392507515529\n",
      "Epoch 240, Loss: 0.3896114169247612\n",
      "Epoch 241, Loss: 0.38786577373697784\n",
      "Epoch 242, Loss: 0.3860790857843996\n",
      "Epoch 243, Loss: 0.3859852085664306\n",
      "Epoch 244, Loss: 0.38737751501595746\n",
      "Epoch 245, Loss: 0.3862929456409366\n",
      "Epoch 246, Loss: 0.3846267410811676\n",
      "Epoch 247, Loss: 0.38473963770752617\n",
      "Epoch 248, Loss: 0.3845990202705295\n",
      "Epoch 249, Loss: 0.38463921576267857\n",
      "Epoch 250, Loss: 0.38425712095995107\n",
      "Epoch 251, Loss: 0.38299781829073154\n",
      "Epoch 252, Loss: 0.38285930503113175\n",
      "Epoch 253, Loss: 0.3825818748983643\n",
      "Epoch 254, Loss: 0.38282842019122165\n",
      "Epoch 255, Loss: 0.3827700688727469\n",
      "Epoch 256, Loss: 0.3821552629201508\n",
      "Epoch 257, Loss: 0.3810103288461938\n",
      "Epoch 258, Loss: 0.3806864223499417\n",
      "Epoch 259, Loss: 0.3800306253264194\n",
      "Epoch 260, Loss: 0.37972452352098224\n",
      "Epoch 261, Loss: 0.3798530782717711\n",
      "Epoch 262, Loss: 0.37952578911714036\n",
      "Epoch 263, Loss: 0.3804963166513505\n",
      "Epoch 264, Loss: 0.38059507148977445\n",
      "Epoch 265, Loss: 0.379988197281397\n",
      "Epoch 266, Loss: 0.3790678682442461\n",
      "Epoch 267, Loss: 0.3769726921102476\n",
      "Epoch 268, Loss: 0.37630963125435807\n",
      "Epoch 269, Loss: 0.3764899179937552\n",
      "Epoch 270, Loss: 0.37700711985272534\n",
      "Epoch 271, Loss: 0.37757940101526316\n",
      "Epoch 272, Loss: 0.3782108059776689\n",
      "Epoch 273, Loss: 0.3763884430976909\n",
      "Epoch 274, Loss: 0.3742737890874079\n",
      "Epoch 275, Loss: 0.3740399110517803\n",
      "Epoch 276, Loss: 0.3746959128878981\n",
      "Epoch 277, Loss: 0.3750908463427753\n",
      "Epoch 278, Loss: 0.37413007446120694\n",
      "Epoch 279, Loss: 0.37279012342706114\n",
      "Epoch 280, Loss: 0.37181336749667054\n",
      "Epoch 281, Loss: 0.3710906781521194\n",
      "Epoch 282, Loss: 0.3718133274196768\n",
      "Epoch 283, Loss: 0.3720755989720407\n",
      "Epoch 284, Loss: 0.3735519505134957\n",
      "Epoch 285, Loss: 0.37510653810282035\n",
      "Epoch 286, Loss: 0.37170768949032923\n",
      "Epoch 287, Loss: 0.3701002373752075\n",
      "Epoch 288, Loss: 0.3699502090189024\n",
      "Epoch 289, Loss: 0.3708178649133612\n",
      "Epoch 290, Loss: 0.37006887155777496\n",
      "Epoch 291, Loss: 0.36776173107540994\n",
      "Epoch 292, Loss: 0.36762483403404145\n",
      "Epoch 293, Loss: 0.3679049969172833\n",
      "Epoch 294, Loss: 0.3684269298043464\n",
      "Epoch 295, Loss: 0.3705122356723882\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.24206159150911674\n",
      "Test R^2 score: 0.3625412045847139\n",
      "Num of epochs: 296\n",
      "Epoch 1, Loss: 0.5820583874821266\n",
      "Epoch 2, Loss: 0.58008444426206\n",
      "Epoch 3, Loss: 0.578286560784572\n",
      "Epoch 4, Loss: 0.5765707154967988\n",
      "Epoch 5, Loss: 0.574918463357703\n",
      "Epoch 6, Loss: 0.5733333430687586\n",
      "Epoch 7, Loss: 0.5718176588900866\n",
      "Epoch 8, Loss: 0.5703818135403201\n",
      "Epoch 9, Loss: 0.5690183718988704\n",
      "Epoch 10, Loss: 0.567727698132912\n",
      "Epoch 11, Loss: 0.5665112628271693\n",
      "Epoch 12, Loss: 0.565368385483725\n",
      "Epoch 13, Loss: 0.5643001996021232\n",
      "Epoch 14, Loss: 0.5633046699554503\n",
      "Epoch 15, Loss: 0.5623822618818174\n",
      "Epoch 16, Loss: 0.5615324865524262\n",
      "Epoch 17, Loss: 0.5607546378108434\n",
      "Epoch 18, Loss: 0.5600467803693611\n",
      "Epoch 19, Loss: 0.5594041188082622\n",
      "Epoch 20, Loss: 0.5588448233651452\n",
      "Epoch 21, Loss: 0.5583390675672552\n",
      "Epoch 22, Loss: 0.5578848602206484\n",
      "Epoch 23, Loss: 0.557483049015256\n",
      "Epoch 24, Loss: 0.5571325437408643\n",
      "Epoch 25, Loss: 0.5568560802358286\n",
      "Epoch 26, Loss: 0.5566182717636898\n",
      "Epoch 27, Loss: 0.5564102499222735\n",
      "Epoch 28, Loss: 0.5562277350095167\n",
      "Epoch 29, Loss: 0.5560657946298315\n",
      "Epoch 30, Loss: 0.5559229457208791\n",
      "Epoch 31, Loss: 0.5558213210869188\n",
      "Epoch 32, Loss: 0.5557283119640791\n",
      "Epoch 33, Loss: 0.5555851348976293\n",
      "Epoch 34, Loss: 0.5553804555432238\n",
      "Epoch 35, Loss: 0.5550846773280308\n",
      "Epoch 36, Loss: 0.5546837927466066\n",
      "Epoch 37, Loss: 0.5542027948070886\n",
      "Epoch 38, Loss: 0.5536189734569528\n",
      "Epoch 39, Loss: 0.552909634575855\n",
      "Epoch 40, Loss: 0.5520287042856566\n",
      "Epoch 41, Loss: 0.5509013322371271\n",
      "Epoch 42, Loss: 0.5494391410194758\n",
      "Epoch 43, Loss: 0.547560507422502\n",
      "Epoch 44, Loss: 0.5451748441945656\n",
      "Epoch 45, Loss: 0.542184414153978\n",
      "Epoch 46, Loss: 0.5385246911192642\n",
      "Epoch 47, Loss: 0.534366860801773\n",
      "Epoch 48, Loss: 0.5303396952843117\n",
      "Epoch 49, Loss: 0.5276981434501533\n",
      "Epoch 50, Loss: 0.5273483558736215\n",
      "Epoch 51, Loss: 0.5263128871900445\n",
      "Epoch 52, Loss: 0.5228000004124076\n",
      "Epoch 53, Loss: 0.5188690209867889\n",
      "Epoch 54, Loss: 0.5161187668782208\n",
      "Epoch 55, Loss: 0.5145608729764546\n",
      "Epoch 56, Loss: 0.5133403680162496\n",
      "Epoch 57, Loss: 0.5117117029534742\n",
      "Epoch 58, Loss: 0.5094174771062461\n",
      "Epoch 59, Loss: 0.50658903190134\n",
      "Epoch 60, Loss: 0.5037278443568709\n",
      "Epoch 61, Loss: 0.5014804440219632\n",
      "Epoch 62, Loss: 0.49997633639605804\n",
      "Epoch 63, Loss: 0.4983830233852081\n",
      "Epoch 64, Loss: 0.49607562234754243\n",
      "Epoch 65, Loss: 0.4935820970068424\n",
      "Epoch 66, Loss: 0.49167580724021376\n",
      "Epoch 67, Loss: 0.49026332632955005\n",
      "Epoch 68, Loss: 0.4887709488976772\n",
      "Epoch 69, Loss: 0.4868697402190093\n",
      "Epoch 70, Loss: 0.4848179330200499\n",
      "Epoch 71, Loss: 0.4831442116277032\n",
      "Epoch 72, Loss: 0.48191471700599925\n",
      "Epoch 73, Loss: 0.480524556090216\n",
      "Epoch 74, Loss: 0.47877744401801253\n",
      "Epoch 75, Loss: 0.477221720904261\n",
      "Epoch 76, Loss: 0.47608805318440645\n",
      "Epoch 77, Loss: 0.4749666290105335\n",
      "Epoch 78, Loss: 0.4736273696429368\n",
      "Epoch 79, Loss: 0.4723211629693224\n",
      "Epoch 80, Loss: 0.4712897163573123\n",
      "Epoch 81, Loss: 0.47027334005869886\n",
      "Epoch 82, Loss: 0.46904051043604655\n",
      "Epoch 83, Loss: 0.46787738640553966\n",
      "Epoch 84, Loss: 0.46689614234044746\n",
      "Epoch 85, Loss: 0.46583945756832007\n",
      "Epoch 86, Loss: 0.4646584919005639\n",
      "Epoch 87, Loss: 0.4635795102762678\n",
      "Epoch 88, Loss: 0.4626208939935702\n",
      "Epoch 89, Loss: 0.46153824661781734\n",
      "Epoch 90, Loss: 0.46043038354984317\n",
      "Epoch 91, Loss: 0.45948585548049514\n",
      "Epoch 92, Loss: 0.4585865650556459\n",
      "Epoch 93, Loss: 0.4576377268149184\n",
      "Epoch 94, Loss: 0.4568167941358341\n",
      "Epoch 95, Loss: 0.4562016971049837\n",
      "Epoch 96, Loss: 0.45547252149639866\n",
      "Epoch 97, Loss: 0.45460288974550056\n",
      "Epoch 98, Loss: 0.4537767130236993\n",
      "Epoch 99, Loss: 0.4529450157766332\n",
      "Epoch 100, Loss: 0.45208962307200834\n",
      "Epoch 101, Loss: 0.45128965285480604\n",
      "Epoch 102, Loss: 0.4505852853466882\n",
      "Epoch 103, Loss: 0.44992949608986854\n",
      "Epoch 104, Loss: 0.4492633465730459\n",
      "Epoch 105, Loss: 0.44864363966595144\n",
      "Epoch 106, Loss: 0.44806694311747747\n",
      "Epoch 107, Loss: 0.4474973786133436\n",
      "Epoch 108, Loss: 0.44693867423173095\n",
      "Epoch 109, Loss: 0.4463782857775566\n",
      "Epoch 110, Loss: 0.4457790707903631\n",
      "Epoch 111, Loss: 0.44515533350766157\n",
      "Epoch 112, Loss: 0.44452475424044746\n",
      "Epoch 113, Loss: 0.4438731875488696\n",
      "Epoch 114, Loss: 0.4432035331919199\n",
      "Epoch 115, Loss: 0.44256333800323927\n",
      "Epoch 116, Loss: 0.44191262223953076\n",
      "Epoch 117, Loss: 0.4412698788258027\n",
      "Epoch 118, Loss: 0.44060687034590645\n",
      "Epoch 119, Loss: 0.43996318462630807\n",
      "Epoch 120, Loss: 0.43929072452251045\n",
      "Epoch 121, Loss: 0.4386237562221179\n",
      "Epoch 122, Loss: 0.4379428427440964\n",
      "Epoch 123, Loss: 0.437253678325451\n",
      "Epoch 124, Loss: 0.436545369324828\n",
      "Epoch 125, Loss: 0.4357823475208051\n",
      "Epoch 126, Loss: 0.43506068305167866\n",
      "Epoch 127, Loss: 0.4343004224412406\n",
      "Epoch 128, Loss: 0.43356931462898163\n",
      "Epoch 129, Loss: 0.4328874041195327\n",
      "Epoch 130, Loss: 0.43219605694600144\n",
      "Epoch 131, Loss: 0.43153340315462907\n",
      "Epoch 132, Loss: 0.43090149439271275\n",
      "Epoch 133, Loss: 0.4302624583737501\n",
      "Epoch 134, Loss: 0.429615136035252\n",
      "Epoch 135, Loss: 0.4289937921899639\n",
      "Epoch 136, Loss: 0.4284015312371817\n",
      "Epoch 137, Loss: 0.4277959457047961\n",
      "Epoch 138, Loss: 0.42718510655679337\n",
      "Epoch 139, Loss: 0.4265801695073977\n",
      "Epoch 140, Loss: 0.42597122503869495\n",
      "Epoch 141, Loss: 0.42534944529395763\n",
      "Epoch 142, Loss: 0.42471294947167415\n",
      "Epoch 143, Loss: 0.42410200911835083\n",
      "Epoch 144, Loss: 0.4235353293494393\n",
      "Epoch 145, Loss: 0.4229811718641795\n",
      "Epoch 146, Loss: 0.42241736269770797\n",
      "Epoch 147, Loss: 0.4217558621913245\n",
      "Epoch 148, Loss: 0.42105846504904304\n",
      "Epoch 149, Loss: 0.42042885272446384\n",
      "Epoch 150, Loss: 0.41988823334536546\n",
      "Epoch 151, Loss: 0.41935604919617997\n",
      "Epoch 152, Loss: 0.4187821646336585\n",
      "Epoch 153, Loss: 0.4180744786096903\n",
      "Epoch 154, Loss: 0.41739670654934136\n",
      "Epoch 155, Loss: 0.41682850754316303\n",
      "Epoch 156, Loss: 0.41634899984014906\n",
      "Epoch 157, Loss: 0.41588282368360613\n",
      "Epoch 158, Loss: 0.4153180609532406\n",
      "Epoch 159, Loss: 0.41465193701627096\n",
      "Epoch 160, Loss: 0.4139437955169945\n",
      "Epoch 161, Loss: 0.4133700032112429\n",
      "Epoch 162, Loss: 0.41294522966483327\n",
      "Epoch 163, Loss: 0.4125729705829518\n",
      "Epoch 164, Loss: 0.4119526533460169\n",
      "Epoch 165, Loss: 0.4112318739621321\n",
      "Epoch 166, Loss: 0.4106106375587731\n",
      "Epoch 167, Loss: 0.4101431526636057\n",
      "Epoch 168, Loss: 0.40978136641501384\n",
      "Epoch 169, Loss: 0.40935290546343645\n",
      "Epoch 170, Loss: 0.4088143149065755\n",
      "Epoch 171, Loss: 0.408063107072189\n",
      "Epoch 172, Loss: 0.40731135521576106\n",
      "Epoch 173, Loss: 0.40673930704965183\n",
      "Epoch 174, Loss: 0.406342679235979\n",
      "Epoch 175, Loss: 0.40610407996313325\n",
      "Epoch 176, Loss: 0.40592391425253793\n",
      "Epoch 177, Loss: 0.4055578314032922\n",
      "Epoch 178, Loss: 0.4046176982759376\n",
      "Epoch 179, Loss: 0.40360002770527764\n",
      "Epoch 180, Loss: 0.40323741513508005\n",
      "Epoch 181, Loss: 0.4033289578229369\n",
      "Epoch 182, Loss: 0.40290349153097943\n",
      "Epoch 183, Loss: 0.401984860249009\n",
      "Epoch 184, Loss: 0.4012372811402086\n",
      "Epoch 185, Loss: 0.4011215237793474\n",
      "Epoch 186, Loss: 0.40093084967576775\n",
      "Epoch 187, Loss: 0.4001203787982791\n",
      "Epoch 188, Loss: 0.39929400740616117\n",
      "Epoch 189, Loss: 0.39899276862009064\n",
      "Epoch 190, Loss: 0.3988242609656969\n",
      "Epoch 191, Loss: 0.3984614533348732\n",
      "Epoch 192, Loss: 0.3977233620240802\n",
      "Epoch 193, Loss: 0.3970696587658035\n",
      "Epoch 194, Loss: 0.39675839355642534\n",
      "Epoch 195, Loss: 0.3966602067094125\n",
      "Epoch 196, Loss: 0.396398281277444\n",
      "Epoch 197, Loss: 0.39584372113634975\n",
      "Epoch 198, Loss: 0.3951848913502116\n",
      "Epoch 199, Loss: 0.3946077442607516\n",
      "Epoch 200, Loss: 0.39420331412934584\n",
      "Epoch 201, Loss: 0.3939759907765508\n",
      "Epoch 202, Loss: 0.39400847897386154\n",
      "Epoch 203, Loss: 0.39443828885031734\n",
      "Epoch 204, Loss: 0.39493426898709805\n",
      "Epoch 205, Loss: 0.394034894933791\n",
      "Epoch 206, Loss: 0.3922924311720411\n",
      "Epoch 207, Loss: 0.3918118566233041\n",
      "Epoch 208, Loss: 0.3923731216441606\n",
      "Epoch 209, Loss: 0.3920155189918765\n",
      "Epoch 210, Loss: 0.39072990916069805\n",
      "Epoch 211, Loss: 0.3902049858321708\n",
      "Epoch 212, Loss: 0.3904941148827329\n",
      "Epoch 213, Loss: 0.390534581210091\n",
      "Epoch 214, Loss: 0.3897320459291128\n",
      "Epoch 215, Loss: 0.38878842623879045\n",
      "Epoch 216, Loss: 0.38854508752143646\n",
      "Epoch 217, Loss: 0.3887685914209117\n",
      "Epoch 218, Loss: 0.3886176603451771\n",
      "Epoch 219, Loss: 0.38791504213557726\n",
      "Epoch 220, Loss: 0.38720104698761754\n",
      "Epoch 221, Loss: 0.3867486499055108\n",
      "Epoch 222, Loss: 0.3867600351509976\n",
      "Epoch 223, Loss: 0.38702684710280977\n",
      "Epoch 224, Loss: 0.3872787005179675\n",
      "Epoch 225, Loss: 0.38720739684502564\n",
      "Epoch 226, Loss: 0.3861688306697349\n",
      "Epoch 227, Loss: 0.3850086625784274\n",
      "Epoch 228, Loss: 0.38482766208019104\n",
      "Epoch 229, Loss: 0.38520311762963283\n",
      "Epoch 230, Loss: 0.3852972240776697\n",
      "Epoch 231, Loss: 0.38466162655771846\n",
      "Epoch 232, Loss: 0.38371109109755275\n",
      "Epoch 233, Loss: 0.383048451945766\n",
      "Epoch 234, Loss: 0.38288691828874916\n",
      "Epoch 235, Loss: 0.38303664515709607\n",
      "Epoch 236, Loss: 0.38342619381054843\n",
      "Epoch 237, Loss: 0.3842112037131706\n",
      "Epoch 238, Loss: 0.3841383608770144\n",
      "Epoch 239, Loss: 0.38291318698141874\n",
      "Epoch 240, Loss: 0.3811336605605644\n",
      "Epoch 241, Loss: 0.3810603662925073\n",
      "Epoch 242, Loss: 0.38221164181084566\n",
      "Epoch 243, Loss: 0.3819065467740301\n",
      "Epoch 244, Loss: 0.38049993915908265\n",
      "Epoch 245, Loss: 0.37943690786251083\n",
      "Epoch 246, Loss: 0.3799072297003526\n",
      "Epoch 247, Loss: 0.38084841981439554\n",
      "Epoch 248, Loss: 0.3803471372843908\n",
      "Epoch 249, Loss: 0.3788520341606352\n",
      "Epoch 250, Loss: 0.37788487447164915\n",
      "Epoch 251, Loss: 0.37828591288324503\n",
      "Epoch 252, Loss: 0.3791630258315514\n",
      "Epoch 253, Loss: 0.37916392973376656\n",
      "Epoch 254, Loss: 0.37794999257822104\n",
      "Epoch 255, Loss: 0.3764302476554522\n",
      "Epoch 256, Loss: 0.3759683385172493\n",
      "Epoch 257, Loss: 0.3761449659632096\n",
      "Epoch 258, Loss: 0.3764958350342557\n",
      "Epoch 259, Loss: 0.37691770397051694\n",
      "Epoch 260, Loss: 0.37672496472504796\n",
      "Epoch 261, Loss: 0.37573133125171676\n",
      "Epoch 262, Loss: 0.3743606720349463\n",
      "Epoch 263, Loss: 0.37330033644322036\n",
      "Epoch 264, Loss: 0.3728479384200713\n",
      "Epoch 265, Loss: 0.3728360883759904\n",
      "Epoch 266, Loss: 0.3735658121930684\n",
      "Epoch 267, Loss: 0.37515829639440706\n",
      "Epoch 268, Loss: 0.3770237792215945\n",
      "Epoch 269, Loss: 0.3753451507366907\n",
      "Epoch 270, Loss: 0.3714482471375411\n",
      "Epoch 271, Loss: 0.3706503176283958\n",
      "Epoch 272, Loss: 0.37301813384379545\n",
      "Epoch 273, Loss: 0.3731906873304634\n",
      "Epoch 274, Loss: 0.37029028797733604\n",
      "Epoch 275, Loss: 0.36862085473183437\n",
      "Epoch 276, Loss: 0.36981944082843876\n",
      "Epoch 277, Loss: 0.37159474334827836\n",
      "Epoch 278, Loss: 0.3704984005148335\n",
      "Epoch 279, Loss: 0.3678771502282585\n",
      "Epoch 280, Loss: 0.36674204651179143\n",
      "Epoch 281, Loss: 0.36749986794527756\n",
      "Epoch 282, Loss: 0.36875911959993135\n",
      "Epoch 283, Loss: 0.36879578888008374\n",
      "Epoch 284, Loss: 0.36731940801750784\n",
      "Epoch 285, Loss: 0.36514383101493353\n",
      "Epoch 286, Loss: 0.3643955450989017\n",
      "Epoch 287, Loss: 0.365420207517919\n",
      "Epoch 288, Loss: 0.3675786633543315\n",
      "Epoch 289, Loss: 0.3696455151796042\n",
      "Epoch 290, Loss: 0.36724021208608354\n",
      "Epoch 291, Loss: 0.36331307876779684\n",
      "Epoch 292, Loss: 0.3629636504216957\n",
      "Epoch 293, Loss: 0.3652442278017508\n",
      "Epoch 294, Loss: 0.3675610083264506\n",
      "Epoch 295, Loss: 0.365703404000055\n",
      "Epoch 296, Loss: 0.3621811154768012\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.25579723434702056\n",
      "Test R^2 score: 0.29127149022910853\n",
      "Num of epochs: 297\n",
      "Epoch 1, Loss: 0.5752149750177449\n",
      "Epoch 2, Loss: 0.573986265907065\n",
      "Epoch 3, Loss: 0.5727908227443086\n",
      "Epoch 4, Loss: 0.571652002058458\n",
      "Epoch 5, Loss: 0.5705454886068471\n",
      "Epoch 6, Loss: 0.5694613179624788\n",
      "Epoch 7, Loss: 0.5684199350085342\n",
      "Epoch 8, Loss: 0.5674064486860888\n",
      "Epoch 9, Loss: 0.5664224293469768\n",
      "Epoch 10, Loss: 0.5657286965172666\n",
      "Epoch 11, Loss: 0.5650259628913546\n",
      "Epoch 12, Loss: 0.5643299324739072\n",
      "Epoch 13, Loss: 0.5636661679936614\n",
      "Epoch 14, Loss: 0.5630099316393471\n",
      "Epoch 15, Loss: 0.5623679535901914\n",
      "Epoch 16, Loss: 0.5617437842551052\n",
      "Epoch 17, Loss: 0.5611444139459689\n",
      "Epoch 18, Loss: 0.5605845422084781\n",
      "Epoch 19, Loss: 0.5600469134043141\n",
      "Epoch 20, Loss: 0.5595337754282861\n",
      "Epoch 21, Loss: 0.5590465284510813\n",
      "Epoch 22, Loss: 0.5585922828068172\n",
      "Epoch 23, Loss: 0.5581697575477973\n",
      "Epoch 24, Loss: 0.5577762998059607\n",
      "Epoch 25, Loss: 0.5574110354871294\n",
      "Epoch 26, Loss: 0.55707412704511\n",
      "Epoch 27, Loss: 0.5567647427498461\n",
      "Epoch 28, Loss: 0.5564876145323856\n",
      "Epoch 29, Loss: 0.5562259400982816\n",
      "Epoch 30, Loss: 0.5559694225458804\n",
      "Epoch 31, Loss: 0.5556923267436762\n",
      "Epoch 32, Loss: 0.5554118463956206\n",
      "Epoch 33, Loss: 0.555113695845153\n",
      "Epoch 34, Loss: 0.5547851691424813\n",
      "Epoch 35, Loss: 0.5544048986360949\n",
      "Epoch 36, Loss: 0.5539493484839623\n",
      "Epoch 37, Loss: 0.553387475103402\n",
      "Epoch 38, Loss: 0.5526810475427557\n",
      "Epoch 39, Loss: 0.5517766358532131\n",
      "Epoch 40, Loss: 0.5506004144849925\n",
      "Epoch 41, Loss: 0.5490906111458332\n",
      "Epoch 42, Loss: 0.5471947961099699\n",
      "Epoch 43, Loss: 0.5448268684504655\n",
      "Epoch 44, Loss: 0.5418988396615451\n",
      "Epoch 45, Loss: 0.5383282788997003\n",
      "Epoch 46, Loss: 0.5340853926928981\n",
      "Epoch 47, Loss: 0.5295107363692141\n",
      "Epoch 48, Loss: 0.5257660896190157\n",
      "Epoch 49, Loss: 0.5245729912406764\n",
      "Epoch 50, Loss: 0.5247021670447054\n",
      "Epoch 51, Loss: 0.5222260419500723\n",
      "Epoch 52, Loss: 0.5181225774084867\n",
      "Epoch 53, Loss: 0.5147359002800608\n",
      "Epoch 54, Loss: 0.5129029353132352\n",
      "Epoch 55, Loss: 0.5119143687236034\n",
      "Epoch 56, Loss: 0.5108068071554782\n",
      "Epoch 57, Loss: 0.509034754615816\n",
      "Epoch 58, Loss: 0.5066396814718409\n",
      "Epoch 59, Loss: 0.5039784874998691\n",
      "Epoch 60, Loss: 0.5017963268426108\n",
      "Epoch 61, Loss: 0.5005893512182269\n",
      "Epoch 62, Loss: 0.5000197883504867\n",
      "Epoch 63, Loss: 0.4988541437232548\n",
      "Epoch 64, Loss: 0.4967070865611723\n",
      "Epoch 65, Loss: 0.49454409445523656\n",
      "Epoch 66, Loss: 0.4930526456463452\n",
      "Epoch 67, Loss: 0.4919635778016033\n",
      "Epoch 68, Loss: 0.49070657732228473\n",
      "Epoch 69, Loss: 0.4890125139425569\n",
      "Epoch 70, Loss: 0.48709946096895984\n",
      "Epoch 71, Loss: 0.4854568582139727\n",
      "Epoch 72, Loss: 0.4842784539264032\n",
      "Epoch 73, Loss: 0.48311569730480447\n",
      "Epoch 74, Loss: 0.4815164169204498\n",
      "Epoch 75, Loss: 0.4797557254199149\n",
      "Epoch 76, Loss: 0.4782542702194583\n",
      "Epoch 77, Loss: 0.47691825970460255\n",
      "Epoch 78, Loss: 0.47540930066377085\n",
      "Epoch 79, Loss: 0.47359976112429775\n",
      "Epoch 80, Loss: 0.4717298840336191\n",
      "Epoch 81, Loss: 0.47000614973874155\n",
      "Epoch 82, Loss: 0.4681968445136263\n",
      "Epoch 83, Loss: 0.4660613517997751\n",
      "Epoch 84, Loss: 0.46384796102732967\n",
      "Epoch 85, Loss: 0.4618656060446887\n",
      "Epoch 86, Loss: 0.46006336408071963\n",
      "Epoch 87, Loss: 0.45865640488442816\n",
      "Epoch 88, Loss: 0.45821696306879345\n",
      "Epoch 89, Loss: 0.45864542356437116\n",
      "Epoch 90, Loss: 0.45870609369573506\n",
      "Epoch 91, Loss: 0.4578231243944803\n",
      "Epoch 92, Loss: 0.4565587821302535\n",
      "Epoch 93, Loss: 0.4554332444500082\n",
      "Epoch 94, Loss: 0.45444280456922254\n",
      "Epoch 95, Loss: 0.45360777885458675\n",
      "Epoch 96, Loss: 0.45302955674594886\n",
      "Epoch 97, Loss: 0.45262233213340586\n",
      "Epoch 98, Loss: 0.4521383692236282\n",
      "Epoch 99, Loss: 0.4516407730479741\n",
      "Epoch 100, Loss: 0.45109499652030977\n",
      "Epoch 101, Loss: 0.45039866192967876\n",
      "Epoch 102, Loss: 0.4496621141564986\n",
      "Epoch 103, Loss: 0.4489240094079997\n",
      "Epoch 104, Loss: 0.44815070853981187\n",
      "Epoch 105, Loss: 0.44740771239752375\n",
      "Epoch 106, Loss: 0.4467821131383922\n",
      "Epoch 107, Loss: 0.4461519961570144\n",
      "Epoch 108, Loss: 0.4455345336446291\n",
      "Epoch 109, Loss: 0.44492391731523584\n",
      "Epoch 110, Loss: 0.4442053298989401\n",
      "Epoch 111, Loss: 0.44346627446504416\n",
      "Epoch 112, Loss: 0.4427384889841322\n",
      "Epoch 113, Loss: 0.44210301323368373\n",
      "Epoch 114, Loss: 0.44147634371673933\n",
      "Epoch 115, Loss: 0.4408649907015562\n",
      "Epoch 116, Loss: 0.4402717425540766\n",
      "Epoch 117, Loss: 0.4396268543587179\n",
      "Epoch 118, Loss: 0.4389506031140865\n",
      "Epoch 119, Loss: 0.4382853951487638\n",
      "Epoch 120, Loss: 0.43765428070747514\n",
      "Epoch 121, Loss: 0.43702856276459623\n",
      "Epoch 122, Loss: 0.43640305738855384\n",
      "Epoch 123, Loss: 0.4357666692691502\n",
      "Epoch 124, Loss: 0.43513587410853105\n",
      "Epoch 125, Loss: 0.4345032200831153\n",
      "Epoch 126, Loss: 0.4338752073640803\n",
      "Epoch 127, Loss: 0.4332381672010994\n",
      "Epoch 128, Loss: 0.4325881500487933\n",
      "Epoch 129, Loss: 0.4319436403538265\n",
      "Epoch 130, Loss: 0.43130849773217794\n",
      "Epoch 131, Loss: 0.430653613043758\n",
      "Epoch 132, Loss: 0.4300069488474025\n",
      "Epoch 133, Loss: 0.4293723424471108\n",
      "Epoch 134, Loss: 0.42874181892552815\n",
      "Epoch 135, Loss: 0.4281479042776186\n",
      "Epoch 136, Loss: 0.42751421553416813\n",
      "Epoch 137, Loss: 0.42686801421563775\n",
      "Epoch 138, Loss: 0.4262321429553396\n",
      "Epoch 139, Loss: 0.42564575419190986\n",
      "Epoch 140, Loss: 0.42507922191509895\n",
      "Epoch 141, Loss: 0.42451990162237874\n",
      "Epoch 142, Loss: 0.4239525853953827\n",
      "Epoch 143, Loss: 0.4233795992125876\n",
      "Epoch 144, Loss: 0.4228037219042071\n",
      "Epoch 145, Loss: 0.42225762076471357\n",
      "Epoch 146, Loss: 0.4217530533477116\n",
      "Epoch 147, Loss: 0.42126333965495044\n",
      "Epoch 148, Loss: 0.4207511343167224\n",
      "Epoch 149, Loss: 0.42022853565715557\n",
      "Epoch 150, Loss: 0.4197018423917559\n",
      "Epoch 151, Loss: 0.4191874980047774\n",
      "Epoch 152, Loss: 0.4186844802954827\n",
      "Epoch 153, Loss: 0.4182015065048371\n",
      "Epoch 154, Loss: 0.41774504905291754\n",
      "Epoch 155, Loss: 0.4173737149637233\n",
      "Epoch 156, Loss: 0.41714614063083905\n",
      "Epoch 157, Loss: 0.4169279491249577\n",
      "Epoch 158, Loss: 0.41631451467643055\n",
      "Epoch 159, Loss: 0.41559541998557165\n",
      "Epoch 160, Loss: 0.4155371695050455\n",
      "Epoch 161, Loss: 0.4151399736584165\n",
      "Epoch 162, Loss: 0.41439104541075306\n",
      "Epoch 163, Loss: 0.4141311948400991\n",
      "Epoch 164, Loss: 0.41380788064028196\n",
      "Epoch 165, Loss: 0.4131623145664544\n",
      "Epoch 166, Loss: 0.4127014932381745\n",
      "Epoch 167, Loss: 0.4124012135213097\n",
      "Epoch 168, Loss: 0.4120142858641824\n",
      "Epoch 169, Loss: 0.4114644577278785\n",
      "Epoch 170, Loss: 0.41099381079155506\n",
      "Epoch 171, Loss: 0.41065855603303225\n",
      "Epoch 172, Loss: 0.41036820157799253\n",
      "Epoch 173, Loss: 0.4099834077955173\n",
      "Epoch 174, Loss: 0.40952363046065826\n",
      "Epoch 175, Loss: 0.4090025889540905\n",
      "Epoch 176, Loss: 0.4084986844164186\n",
      "Epoch 177, Loss: 0.40815950005422186\n",
      "Epoch 178, Loss: 0.40800699514231387\n",
      "Epoch 179, Loss: 0.40822415092380426\n",
      "Epoch 180, Loss: 0.40809441903174354\n",
      "Epoch 181, Loss: 0.40687893820173693\n",
      "Epoch 182, Loss: 0.40616656326897366\n",
      "Epoch 183, Loss: 0.4064215151315285\n",
      "Epoch 184, Loss: 0.4060454587268384\n",
      "Epoch 185, Loss: 0.40507846416580584\n",
      "Epoch 186, Loss: 0.4049962946051175\n",
      "Epoch 187, Loss: 0.40506551533480056\n",
      "Epoch 188, Loss: 0.4041817173990264\n",
      "Epoch 189, Loss: 0.40373834554781585\n",
      "Epoch 190, Loss: 0.40376833215673014\n",
      "Epoch 191, Loss: 0.4031871178547886\n",
      "Epoch 192, Loss: 0.4026357276491656\n",
      "Epoch 193, Loss: 0.40244519704705584\n",
      "Epoch 194, Loss: 0.4021310892388152\n",
      "Epoch 195, Loss: 0.4015732581927694\n",
      "Epoch 196, Loss: 0.401134767088315\n",
      "Epoch 197, Loss: 0.40085848013986713\n",
      "Epoch 198, Loss: 0.40071699285430595\n",
      "Epoch 199, Loss: 0.40048586945364495\n",
      "Epoch 200, Loss: 0.4000838430272035\n",
      "Epoch 201, Loss: 0.3995150039824975\n",
      "Epoch 202, Loss: 0.39899237647696995\n",
      "Epoch 203, Loss: 0.3986179279873546\n",
      "Epoch 204, Loss: 0.3984805439156575\n",
      "Epoch 205, Loss: 0.39831885272936335\n",
      "Epoch 206, Loss: 0.39813475233077655\n",
      "Epoch 207, Loss: 0.39803465879672345\n",
      "Epoch 208, Loss: 0.3975698898161162\n",
      "Epoch 209, Loss: 0.3969652801616679\n",
      "Epoch 210, Loss: 0.39633076139596246\n",
      "Epoch 211, Loss: 0.39577640784999174\n",
      "Epoch 212, Loss: 0.39559362916879026\n",
      "Epoch 213, Loss: 0.39541434608250176\n",
      "Epoch 214, Loss: 0.39524042957718236\n",
      "Epoch 215, Loss: 0.3952031787294184\n",
      "Epoch 216, Loss: 0.39494847435425356\n",
      "Epoch 217, Loss: 0.3943589844754074\n",
      "Epoch 218, Loss: 0.39375277472835346\n",
      "Epoch 219, Loss: 0.39302764132774254\n",
      "Epoch 220, Loss: 0.39278890161029\n",
      "Epoch 221, Loss: 0.3929058434130744\n",
      "Epoch 222, Loss: 0.393017385518049\n",
      "Epoch 223, Loss: 0.3932477639286906\n",
      "Epoch 224, Loss: 0.39286738504645335\n",
      "Epoch 225, Loss: 0.3917709897314948\n",
      "Epoch 226, Loss: 0.39111173822334316\n",
      "Epoch 227, Loss: 0.3909790723180617\n",
      "Epoch 228, Loss: 0.39120956550163305\n",
      "Epoch 229, Loss: 0.39059087604247006\n",
      "Epoch 230, Loss: 0.3898411324514454\n",
      "Epoch 231, Loss: 0.38969577893699\n",
      "Epoch 232, Loss: 0.3894756000733327\n",
      "Epoch 233, Loss: 0.38978520720182824\n",
      "Epoch 234, Loss: 0.38988340554528117\n",
      "Epoch 235, Loss: 0.38994067330772786\n",
      "Epoch 236, Loss: 0.3893927593375527\n",
      "Epoch 237, Loss: 0.3881206341434957\n",
      "Epoch 238, Loss: 0.387674941289229\n",
      "Epoch 239, Loss: 0.3881869717816856\n",
      "Epoch 240, Loss: 0.3880831606515527\n",
      "Epoch 241, Loss: 0.38749353264979897\n",
      "Epoch 242, Loss: 0.3865480142406439\n",
      "Epoch 243, Loss: 0.38638082825563685\n",
      "Epoch 244, Loss: 0.38661793637413705\n",
      "Epoch 245, Loss: 0.3862714781854115\n",
      "Epoch 246, Loss: 0.38584471679947013\n",
      "Epoch 247, Loss: 0.3850779355111162\n",
      "Epoch 248, Loss: 0.38473531923177035\n",
      "Epoch 249, Loss: 0.3846544792635972\n",
      "Epoch 250, Loss: 0.3847368297355289\n",
      "Epoch 251, Loss: 0.38621316477983225\n",
      "Epoch 252, Loss: 0.3886124455242198\n",
      "Epoch 253, Loss: 0.38985856205813174\n",
      "Epoch 254, Loss: 0.38576239038026233\n",
      "Epoch 255, Loss: 0.3835024163618891\n",
      "Epoch 256, Loss: 0.3871882699892579\n",
      "Epoch 257, Loss: 0.3840265873692607\n",
      "Epoch 258, Loss: 0.3829761272203909\n",
      "Epoch 259, Loss: 0.3846685025554516\n",
      "Epoch 260, Loss: 0.38245680886176153\n",
      "Epoch 261, Loss: 0.38222123241265593\n",
      "Epoch 262, Loss: 0.38299097065951826\n",
      "Epoch 263, Loss: 0.38157090455092857\n",
      "Epoch 264, Loss: 0.38080119153174946\n",
      "Epoch 265, Loss: 0.3817019995981558\n",
      "Epoch 266, Loss: 0.38049388857280836\n",
      "Epoch 267, Loss: 0.3798320314646716\n",
      "Epoch 268, Loss: 0.37998986390674605\n",
      "Epoch 269, Loss: 0.380568466592076\n",
      "Epoch 270, Loss: 0.3795878974348437\n",
      "Epoch 271, Loss: 0.37871104058927774\n",
      "Epoch 272, Loss: 0.37828607044827806\n",
      "Epoch 273, Loss: 0.37854846304063894\n",
      "Epoch 274, Loss: 0.37875188062219833\n",
      "Epoch 275, Loss: 0.37955390008247536\n",
      "Epoch 276, Loss: 0.3800794979748916\n",
      "Epoch 277, Loss: 0.37929923531203524\n",
      "Epoch 278, Loss: 0.3782173461698898\n",
      "Epoch 279, Loss: 0.3766787029167646\n",
      "Epoch 280, Loss: 0.3766067771681165\n",
      "Epoch 281, Loss: 0.37682148507599167\n",
      "Epoch 282, Loss: 0.3772560641684251\n",
      "Epoch 283, Loss: 0.3774151910163555\n",
      "Epoch 284, Loss: 0.3768652185907272\n",
      "Epoch 285, Loss: 0.37649041273314565\n",
      "Epoch 286, Loss: 0.3754203744903488\n",
      "Epoch 287, Loss: 0.37502330469196227\n",
      "Epoch 288, Loss: 0.3743394557465509\n",
      "Epoch 289, Loss: 0.37394155696687376\n",
      "Epoch 290, Loss: 0.37388626252444307\n",
      "Epoch 291, Loss: 0.3736211341193356\n",
      "Epoch 292, Loss: 0.3752101269745657\n",
      "Epoch 293, Loss: 0.3814804685987543\n",
      "Epoch 294, Loss: 0.3895106059884215\n",
      "Epoch 295, Loss: 0.3827820395982309\n",
      "Epoch 296, Loss: 0.3750242980396605\n",
      "Epoch 297, Loss: 0.3826275203413707\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.245699107761284\n",
      "Test R^2 score: 0.343825339527457\n",
      "Num of epochs: 298\n",
      "Epoch 1, Loss: 0.5678046229419176\n",
      "Epoch 2, Loss: 0.5667826749993313\n",
      "Epoch 3, Loss: 0.5658127668020466\n",
      "Epoch 4, Loss: 0.5649049000332206\n",
      "Epoch 5, Loss: 0.5640465879441426\n",
      "Epoch 6, Loss: 0.5632425546251388\n",
      "Epoch 7, Loss: 0.5624864099768234\n",
      "Epoch 8, Loss: 0.5617747664872418\n",
      "Epoch 9, Loss: 0.5611181239307825\n",
      "Epoch 10, Loss: 0.5604994218790984\n",
      "Epoch 11, Loss: 0.5599308949219439\n",
      "Epoch 12, Loss: 0.5594218591424174\n",
      "Epoch 13, Loss: 0.5589614138362519\n",
      "Epoch 14, Loss: 0.558532284642778\n",
      "Epoch 15, Loss: 0.5581464243468733\n",
      "Epoch 16, Loss: 0.557798286064554\n",
      "Epoch 17, Loss: 0.5574849735253482\n",
      "Epoch 18, Loss: 0.5572063850201991\n",
      "Epoch 19, Loss: 0.5569573287815922\n",
      "Epoch 20, Loss: 0.556738620631488\n",
      "Epoch 21, Loss: 0.5565500553802444\n",
      "Epoch 22, Loss: 0.556380174170976\n",
      "Epoch 23, Loss: 0.5562258061494497\n",
      "Epoch 24, Loss: 0.5560986473680306\n",
      "Epoch 25, Loss: 0.5559931419193161\n",
      "Epoch 26, Loss: 0.5558766794627549\n",
      "Epoch 27, Loss: 0.5557528728182626\n",
      "Epoch 28, Loss: 0.5556198933884849\n",
      "Epoch 29, Loss: 0.5554644824587051\n",
      "Epoch 30, Loss: 0.5552781680801586\n",
      "Epoch 31, Loss: 0.5550535632826049\n",
      "Epoch 32, Loss: 0.5547718467519304\n",
      "Epoch 33, Loss: 0.5544140907534324\n",
      "Epoch 34, Loss: 0.5539665372292915\n",
      "Epoch 35, Loss: 0.5534148862883154\n",
      "Epoch 36, Loss: 0.5527539199231171\n",
      "Epoch 37, Loss: 0.5519753626442604\n",
      "Epoch 38, Loss: 0.5510639790691105\n",
      "Epoch 39, Loss: 0.5500383981392267\n",
      "Epoch 40, Loss: 0.5488712388884731\n",
      "Epoch 41, Loss: 0.5474884951702181\n",
      "Epoch 42, Loss: 0.5458346962608425\n",
      "Epoch 43, Loss: 0.5438339694727969\n",
      "Epoch 44, Loss: 0.5414094558775033\n",
      "Epoch 45, Loss: 0.5385899338284081\n",
      "Epoch 46, Loss: 0.5355360535043767\n",
      "Epoch 47, Loss: 0.5325387301710143\n",
      "Epoch 48, Loss: 0.5298419130924009\n",
      "Epoch 49, Loss: 0.5270966127353737\n",
      "Epoch 50, Loss: 0.523871313216376\n",
      "Epoch 51, Loss: 0.5203432033976502\n",
      "Epoch 52, Loss: 0.5169378675077394\n",
      "Epoch 53, Loss: 0.5138013553243649\n",
      "Epoch 54, Loss: 0.5107727041664449\n",
      "Epoch 55, Loss: 0.5078201880239851\n",
      "Epoch 56, Loss: 0.504979904549246\n",
      "Epoch 57, Loss: 0.5024547222956807\n",
      "Epoch 58, Loss: 0.500284739718352\n",
      "Epoch 59, Loss: 0.49835606869481225\n",
      "Epoch 60, Loss: 0.49630414451192195\n",
      "Epoch 61, Loss: 0.49393108885932996\n",
      "Epoch 62, Loss: 0.49127152905353505\n",
      "Epoch 63, Loss: 0.4884153715943199\n",
      "Epoch 64, Loss: 0.4853767373139645\n",
      "Epoch 65, Loss: 0.48223155047284727\n",
      "Epoch 66, Loss: 0.47918164361131704\n",
      "Epoch 67, Loss: 0.47649548794230273\n",
      "Epoch 68, Loss: 0.4740448250992964\n",
      "Epoch 69, Loss: 0.4717064607023326\n",
      "Epoch 70, Loss: 0.4695087014875789\n",
      "Epoch 71, Loss: 0.4675047387428625\n",
      "Epoch 72, Loss: 0.4657356617144105\n",
      "Epoch 73, Loss: 0.46442304534656836\n",
      "Epoch 74, Loss: 0.46367742572087595\n",
      "Epoch 75, Loss: 0.463301206934061\n",
      "Epoch 76, Loss: 0.4630533085416832\n",
      "Epoch 77, Loss: 0.4623281223947277\n",
      "Epoch 78, Loss: 0.46108151465185454\n",
      "Epoch 79, Loss: 0.4595593037322284\n",
      "Epoch 80, Loss: 0.45811215576547815\n",
      "Epoch 81, Loss: 0.456909147074538\n",
      "Epoch 82, Loss: 0.45602078689599823\n",
      "Epoch 83, Loss: 0.4553585743681261\n",
      "Epoch 84, Loss: 0.45484101171792973\n",
      "Epoch 85, Loss: 0.4544287046678652\n",
      "Epoch 86, Loss: 0.45401308571866533\n",
      "Epoch 87, Loss: 0.4535458189173046\n",
      "Epoch 88, Loss: 0.45298454146608946\n",
      "Epoch 89, Loss: 0.4522863387864859\n",
      "Epoch 90, Loss: 0.45145973501382464\n",
      "Epoch 91, Loss: 0.450580688498902\n",
      "Epoch 92, Loss: 0.44972373111297104\n",
      "Epoch 93, Loss: 0.44886960268719506\n",
      "Epoch 94, Loss: 0.4480173881160006\n",
      "Epoch 95, Loss: 0.44721814699007706\n",
      "Epoch 96, Loss: 0.4464342811764296\n",
      "Epoch 97, Loss: 0.4457179281867316\n",
      "Epoch 98, Loss: 0.4448276523830242\n",
      "Epoch 99, Loss: 0.44396697435005816\n",
      "Epoch 100, Loss: 0.4430312736561272\n",
      "Epoch 101, Loss: 0.44221683782299287\n",
      "Epoch 102, Loss: 0.4413886446522354\n",
      "Epoch 103, Loss: 0.44066995634877204\n",
      "Epoch 104, Loss: 0.4399267399552267\n",
      "Epoch 105, Loss: 0.4391857435810997\n",
      "Epoch 106, Loss: 0.4383954863154507\n",
      "Epoch 107, Loss: 0.43755781268565314\n",
      "Epoch 108, Loss: 0.4366948518714282\n",
      "Epoch 109, Loss: 0.435902420464683\n",
      "Epoch 110, Loss: 0.43512784361793655\n",
      "Epoch 111, Loss: 0.43441599988578256\n",
      "Epoch 112, Loss: 0.4336298850183797\n",
      "Epoch 113, Loss: 0.4328249051626451\n",
      "Epoch 114, Loss: 0.43202794506609327\n",
      "Epoch 115, Loss: 0.4311943681741931\n",
      "Epoch 116, Loss: 0.43043309460420165\n",
      "Epoch 117, Loss: 0.4297096073358986\n",
      "Epoch 118, Loss: 0.4289721342809078\n",
      "Epoch 119, Loss: 0.4282444390527685\n",
      "Epoch 120, Loss: 0.42751104368478937\n",
      "Epoch 121, Loss: 0.4267913840071762\n",
      "Epoch 122, Loss: 0.4260890967713361\n",
      "Epoch 123, Loss: 0.42539316392041054\n",
      "Epoch 124, Loss: 0.42469658188586235\n",
      "Epoch 125, Loss: 0.4240213648017538\n",
      "Epoch 126, Loss: 0.423343187646738\n",
      "Epoch 127, Loss: 0.4226809150705191\n",
      "Epoch 128, Loss: 0.4220162967432338\n",
      "Epoch 129, Loss: 0.42132978176227637\n",
      "Epoch 130, Loss: 0.42064110131359156\n",
      "Epoch 131, Loss: 0.4199961219619913\n",
      "Epoch 132, Loss: 0.4194006768167498\n",
      "Epoch 133, Loss: 0.4187762935411444\n",
      "Epoch 134, Loss: 0.4180350028319639\n",
      "Epoch 135, Loss: 0.4172612914356922\n",
      "Epoch 136, Loss: 0.41654363444964604\n",
      "Epoch 137, Loss: 0.41591007165158345\n",
      "Epoch 138, Loss: 0.4153307439558547\n",
      "Epoch 139, Loss: 0.41486785947925103\n",
      "Epoch 140, Loss: 0.4144668224490941\n",
      "Epoch 141, Loss: 0.4138151365621646\n",
      "Epoch 142, Loss: 0.41272819305012914\n",
      "Epoch 143, Loss: 0.41232635788052985\n",
      "Epoch 144, Loss: 0.4120699967648827\n",
      "Epoch 145, Loss: 0.4110299568454653\n",
      "Epoch 146, Loss: 0.4104717312905292\n",
      "Epoch 147, Loss: 0.41030209082875646\n",
      "Epoch 148, Loss: 0.4094268853307146\n",
      "Epoch 149, Loss: 0.4086595566165031\n",
      "Epoch 150, Loss: 0.4084008025689697\n",
      "Epoch 151, Loss: 0.4078282729566187\n",
      "Epoch 152, Loss: 0.4070530620156143\n",
      "Epoch 153, Loss: 0.4065736984892158\n",
      "Epoch 154, Loss: 0.40625284267311296\n",
      "Epoch 155, Loss: 0.4057423647822048\n",
      "Epoch 156, Loss: 0.4049617074006266\n",
      "Epoch 157, Loss: 0.40432617523611286\n",
      "Epoch 158, Loss: 0.4039341686346911\n",
      "Epoch 159, Loss: 0.40369661893583936\n",
      "Epoch 160, Loss: 0.4033293272770532\n",
      "Epoch 161, Loss: 0.40266181817606744\n",
      "Epoch 162, Loss: 0.4019154055500012\n",
      "Epoch 163, Loss: 0.40133507221870707\n",
      "Epoch 164, Loss: 0.4009585748605887\n",
      "Epoch 165, Loss: 0.400680158183398\n",
      "Epoch 166, Loss: 0.4003437666106524\n",
      "Epoch 167, Loss: 0.39990165440240305\n",
      "Epoch 168, Loss: 0.39926036311765156\n",
      "Epoch 169, Loss: 0.39864730920743535\n",
      "Epoch 170, Loss: 0.3981340786364385\n",
      "Epoch 171, Loss: 0.3977727206074888\n",
      "Epoch 172, Loss: 0.39755294822033393\n",
      "Epoch 173, Loss: 0.3974262381738391\n",
      "Epoch 174, Loss: 0.3973027319818292\n",
      "Epoch 175, Loss: 0.3966898644032627\n",
      "Epoch 176, Loss: 0.39574747241882424\n",
      "Epoch 177, Loss: 0.3950270002528973\n",
      "Epoch 178, Loss: 0.39499276616317375\n",
      "Epoch 179, Loss: 0.3949501344434985\n",
      "Epoch 180, Loss: 0.3942918145338938\n",
      "Epoch 181, Loss: 0.39352681934519446\n",
      "Epoch 182, Loss: 0.3929110202134133\n",
      "Epoch 183, Loss: 0.3926225134203947\n",
      "Epoch 184, Loss: 0.39257296278866544\n",
      "Epoch 185, Loss: 0.3923631335612398\n",
      "Epoch 186, Loss: 0.3918361769614535\n",
      "Epoch 187, Loss: 0.39099052493451764\n",
      "Epoch 188, Loss: 0.3903158872165719\n",
      "Epoch 189, Loss: 0.38992790964998475\n",
      "Epoch 190, Loss: 0.3898000971753883\n",
      "Epoch 191, Loss: 0.38975666808883436\n",
      "Epoch 192, Loss: 0.3894106873373558\n",
      "Epoch 193, Loss: 0.3888523507077951\n",
      "Epoch 194, Loss: 0.3879598680601811\n",
      "Epoch 195, Loss: 0.38723895216759774\n",
      "Epoch 196, Loss: 0.3868885438178368\n",
      "Epoch 197, Loss: 0.38678910357227286\n",
      "Epoch 198, Loss: 0.3866237947659187\n",
      "Epoch 199, Loss: 0.3862356964413417\n",
      "Epoch 200, Loss: 0.38548482687413665\n",
      "Epoch 201, Loss: 0.3847117119985782\n",
      "Epoch 202, Loss: 0.3841525775631792\n",
      "Epoch 203, Loss: 0.3838173465158764\n",
      "Epoch 204, Loss: 0.3836972852466715\n",
      "Epoch 205, Loss: 0.38374673935191467\n",
      "Epoch 206, Loss: 0.3836706041778354\n",
      "Epoch 207, Loss: 0.38339537407015073\n",
      "Epoch 208, Loss: 0.38233928236633064\n",
      "Epoch 209, Loss: 0.3814304471964813\n",
      "Epoch 210, Loss: 0.38102405606817374\n",
      "Epoch 211, Loss: 0.38099613179723757\n",
      "Epoch 212, Loss: 0.3811193508106111\n",
      "Epoch 213, Loss: 0.3808343732403693\n",
      "Epoch 214, Loss: 0.38007751809803886\n",
      "Epoch 215, Loss: 0.3791605695646483\n",
      "Epoch 216, Loss: 0.3786010692989405\n",
      "Epoch 217, Loss: 0.37845671424629984\n",
      "Epoch 218, Loss: 0.37854865986031694\n",
      "Epoch 219, Loss: 0.3784878967647929\n",
      "Epoch 220, Loss: 0.37799071772849635\n",
      "Epoch 221, Loss: 0.37729544241518664\n",
      "Epoch 222, Loss: 0.37647788573160396\n",
      "Epoch 223, Loss: 0.3758897160883295\n",
      "Epoch 224, Loss: 0.37563401508144745\n",
      "Epoch 225, Loss: 0.3754572067994561\n",
      "Epoch 226, Loss: 0.37521997596106454\n",
      "Epoch 227, Loss: 0.3751432423400012\n",
      "Epoch 228, Loss: 0.37511350980078234\n",
      "Epoch 229, Loss: 0.3748235088510824\n",
      "Epoch 230, Loss: 0.37373504277030145\n",
      "Epoch 231, Loss: 0.3729317372578315\n",
      "Epoch 232, Loss: 0.37262454267881345\n",
      "Epoch 233, Loss: 0.3723934702587068\n",
      "Epoch 234, Loss: 0.37233964678464054\n",
      "Epoch 235, Loss: 0.37284246306708435\n",
      "Epoch 236, Loss: 0.37291537458668356\n",
      "Epoch 237, Loss: 0.3724908329648567\n",
      "Epoch 238, Loss: 0.3710939106187975\n",
      "Epoch 239, Loss: 0.37018103539513886\n",
      "Epoch 240, Loss: 0.3698308838837249\n",
      "Epoch 241, Loss: 0.3698111000685686\n",
      "Epoch 242, Loss: 0.370101727084748\n",
      "Epoch 243, Loss: 0.36964249176497005\n",
      "Epoch 244, Loss: 0.36834445247581543\n",
      "Epoch 245, Loss: 0.36790578671990576\n",
      "Epoch 246, Loss: 0.3677681734637213\n",
      "Epoch 247, Loss: 0.367233841589275\n",
      "Epoch 248, Loss: 0.36725132975847186\n",
      "Epoch 249, Loss: 0.3676906344591237\n",
      "Epoch 250, Loss: 0.3665670875593961\n",
      "Epoch 251, Loss: 0.3663013397531797\n",
      "Epoch 252, Loss: 0.3663132994961504\n",
      "Epoch 253, Loss: 0.3653684971609503\n",
      "Epoch 254, Loss: 0.3644923868731705\n",
      "Epoch 255, Loss: 0.36466684974317704\n",
      "Epoch 256, Loss: 0.3640939175061309\n",
      "Epoch 257, Loss: 0.36349880718234884\n",
      "Epoch 258, Loss: 0.3639072848641474\n",
      "Epoch 259, Loss: 0.364234596310304\n",
      "Epoch 260, Loss: 0.365659639559773\n",
      "Epoch 261, Loss: 0.36771160624977367\n",
      "Epoch 262, Loss: 0.36502403689627677\n",
      "Epoch 263, Loss: 0.3617405985748772\n",
      "Epoch 264, Loss: 0.3626825054087086\n",
      "Epoch 265, Loss: 0.3634068261779264\n",
      "Epoch 266, Loss: 0.3625315446940401\n",
      "Epoch 267, Loss: 0.36170158675074865\n",
      "Epoch 268, Loss: 0.35994124376774694\n",
      "Epoch 269, Loss: 0.36209246236898623\n",
      "Epoch 270, Loss: 0.36313244633089775\n",
      "Epoch 271, Loss: 0.36019579821269343\n",
      "Epoch 272, Loss: 0.36169157564652943\n",
      "Epoch 273, Loss: 0.35944318124589114\n",
      "Epoch 274, Loss: 0.36191735551780113\n",
      "Epoch 275, Loss: 0.3586803232044322\n",
      "Epoch 276, Loss: 0.35831121895809126\n",
      "Epoch 277, Loss: 0.35941132071682386\n",
      "Epoch 278, Loss: 0.3575521138027518\n",
      "Epoch 279, Loss: 0.3584807506697801\n",
      "Epoch 280, Loss: 0.35711575515979566\n",
      "Epoch 281, Loss: 0.356669274607301\n",
      "Epoch 282, Loss: 0.35680885065978507\n",
      "Epoch 283, Loss: 0.35521835898442183\n",
      "Epoch 284, Loss: 0.35630272926807705\n",
      "Epoch 285, Loss: 0.35516501644541176\n",
      "Epoch 286, Loss: 0.3552552305047237\n",
      "Epoch 287, Loss: 0.3561793550081168\n",
      "Epoch 288, Loss: 0.3546486501381114\n",
      "Epoch 289, Loss: 0.35603237532085663\n",
      "Epoch 290, Loss: 0.3541339083088689\n",
      "Epoch 291, Loss: 0.3544761086592746\n",
      "Epoch 292, Loss: 0.35394381309051065\n",
      "Epoch 293, Loss: 0.35356517044118946\n",
      "Epoch 294, Loss: 0.3541924967415872\n",
      "Epoch 295, Loss: 0.35421205912270903\n",
      "Epoch 296, Loss: 0.35316763131037077\n",
      "Epoch 297, Loss: 0.35352839662865004\n",
      "Epoch 298, Loss: 0.35146791457318327\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2734664350616174\n",
      "Test R^2 score: 0.1933345871810389\n",
      "Num of epochs: 299\n",
      "Epoch 1, Loss: 0.5653707839248604\n",
      "Epoch 2, Loss: 0.5643120559705845\n",
      "Epoch 3, Loss: 0.5632919723188612\n",
      "Epoch 4, Loss: 0.5622839512766221\n",
      "Epoch 5, Loss: 0.561339771253466\n",
      "Epoch 6, Loss: 0.5604702834062362\n",
      "Epoch 7, Loss: 0.5596765813396134\n",
      "Epoch 8, Loss: 0.5589694380347286\n",
      "Epoch 9, Loss: 0.5583562813023706\n",
      "Epoch 10, Loss: 0.557820031037769\n",
      "Epoch 11, Loss: 0.5573602141057207\n",
      "Epoch 12, Loss: 0.5569759229065346\n",
      "Epoch 13, Loss: 0.5566700442386807\n",
      "Epoch 14, Loss: 0.5564384762634262\n",
      "Epoch 15, Loss: 0.5562829190060897\n",
      "Epoch 16, Loss: 0.5561894244524995\n",
      "Epoch 17, Loss: 0.5561510576697158\n",
      "Epoch 18, Loss: 0.5561572736968721\n",
      "Epoch 19, Loss: 0.5561952113911433\n",
      "Epoch 20, Loss: 0.5562505325572004\n",
      "Epoch 21, Loss: 0.5563096518088453\n",
      "Epoch 22, Loss: 0.55636129230316\n",
      "Epoch 23, Loss: 0.5563960826515799\n",
      "Epoch 24, Loss: 0.5564069023010664\n",
      "Epoch 25, Loss: 0.5563911548206931\n",
      "Epoch 26, Loss: 0.5563492932796917\n",
      "Epoch 27, Loss: 0.556284392290191\n",
      "Epoch 28, Loss: 0.5562029272156757\n",
      "Epoch 29, Loss: 0.5561115628396375\n",
      "Epoch 30, Loss: 0.556011205486546\n",
      "Epoch 31, Loss: 0.5559005368206289\n",
      "Epoch 32, Loss: 0.555779148512871\n",
      "Epoch 33, Loss: 0.5556460949183429\n",
      "Epoch 34, Loss: 0.5554996240461778\n",
      "Epoch 35, Loss: 0.5553347612425973\n",
      "Epoch 36, Loss: 0.5551416928470744\n",
      "Epoch 37, Loss: 0.5549043849254849\n",
      "Epoch 38, Loss: 0.5546080572701316\n",
      "Epoch 39, Loss: 0.5542456250360047\n",
      "Epoch 40, Loss: 0.5537986618601681\n",
      "Epoch 41, Loss: 0.5532481363595222\n",
      "Epoch 42, Loss: 0.5525615138767929\n",
      "Epoch 43, Loss: 0.5517133306616876\n",
      "Epoch 44, Loss: 0.5506679337181373\n",
      "Epoch 45, Loss: 0.5493889654769216\n",
      "Epoch 46, Loss: 0.5477991742059974\n",
      "Epoch 47, Loss: 0.5457570228911152\n",
      "Epoch 48, Loss: 0.5431368725338318\n",
      "Epoch 49, Loss: 0.5398197107993942\n",
      "Epoch 50, Loss: 0.5357541830101604\n",
      "Epoch 51, Loss: 0.531010714103167\n",
      "Epoch 52, Loss: 0.5257828393603219\n",
      "Epoch 53, Loss: 0.5205150267367666\n",
      "Epoch 54, Loss: 0.5160781718486243\n",
      "Epoch 55, Loss: 0.5136815639495865\n",
      "Epoch 56, Loss: 0.5127385875058634\n",
      "Epoch 57, Loss: 0.5100761432466061\n",
      "Epoch 58, Loss: 0.5051745341160393\n",
      "Epoch 59, Loss: 0.500095239151855\n",
      "Epoch 60, Loss: 0.49660173075113573\n",
      "Epoch 61, Loss: 0.4950984672904825\n",
      "Epoch 62, Loss: 0.4940965957024037\n",
      "Epoch 63, Loss: 0.492583388104557\n",
      "Epoch 64, Loss: 0.49036367770486333\n",
      "Epoch 65, Loss: 0.4877511007461758\n",
      "Epoch 66, Loss: 0.48526737089279387\n",
      "Epoch 67, Loss: 0.48351112362394605\n",
      "Epoch 68, Loss: 0.4823104019178724\n",
      "Epoch 69, Loss: 0.4807487540285942\n",
      "Epoch 70, Loss: 0.4785110784820682\n",
      "Epoch 71, Loss: 0.4762436003017219\n",
      "Epoch 72, Loss: 0.47451176836696946\n",
      "Epoch 73, Loss: 0.4733721615615816\n",
      "Epoch 74, Loss: 0.4722399336245359\n",
      "Epoch 75, Loss: 0.4708400226500424\n",
      "Epoch 76, Loss: 0.4694297153922946\n",
      "Epoch 77, Loss: 0.46826499643461506\n",
      "Epoch 78, Loss: 0.46726611825074743\n",
      "Epoch 79, Loss: 0.46620290467238235\n",
      "Epoch 80, Loss: 0.46504550049806204\n",
      "Epoch 81, Loss: 0.4638200113500212\n",
      "Epoch 82, Loss: 0.46273978306657865\n",
      "Epoch 83, Loss: 0.4618521683176914\n",
      "Epoch 84, Loss: 0.4609744816831638\n",
      "Epoch 85, Loss: 0.4600471367216109\n",
      "Epoch 86, Loss: 0.4591376839933504\n",
      "Epoch 87, Loss: 0.458234100725695\n",
      "Epoch 88, Loss: 0.45725948796927235\n",
      "Epoch 89, Loss: 0.45622178473822983\n",
      "Epoch 90, Loss: 0.45535243857382\n",
      "Epoch 91, Loss: 0.45460911760127887\n",
      "Epoch 92, Loss: 0.45379825430038745\n",
      "Epoch 93, Loss: 0.4530054625324974\n",
      "Epoch 94, Loss: 0.4523285574988868\n",
      "Epoch 95, Loss: 0.4516388924206988\n",
      "Epoch 96, Loss: 0.45092413239416484\n",
      "Epoch 97, Loss: 0.4502727417135071\n",
      "Epoch 98, Loss: 0.44963131079700464\n",
      "Epoch 99, Loss: 0.44898768577596265\n",
      "Epoch 100, Loss: 0.4484073608850448\n",
      "Epoch 101, Loss: 0.4478108443704095\n",
      "Epoch 102, Loss: 0.4472109665434912\n",
      "Epoch 103, Loss: 0.4466292505849404\n",
      "Epoch 104, Loss: 0.44596052702467237\n",
      "Epoch 105, Loss: 0.44535767175549296\n",
      "Epoch 106, Loss: 0.44474037963150215\n",
      "Epoch 107, Loss: 0.44412739649307786\n",
      "Epoch 108, Loss: 0.443562818055444\n",
      "Epoch 109, Loss: 0.4429255644453896\n",
      "Epoch 110, Loss: 0.4423394760900935\n",
      "Epoch 111, Loss: 0.44171857333913483\n",
      "Epoch 112, Loss: 0.4411273682958514\n",
      "Epoch 113, Loss: 0.4405164781133996\n",
      "Epoch 114, Loss: 0.4398789610244002\n",
      "Epoch 115, Loss: 0.43921917940089605\n",
      "Epoch 116, Loss: 0.43850150600248683\n",
      "Epoch 117, Loss: 0.4378192281920782\n",
      "Epoch 118, Loss: 0.43711867062636356\n",
      "Epoch 119, Loss: 0.43647622486792365\n",
      "Epoch 120, Loss: 0.4358235493972542\n",
      "Epoch 121, Loss: 0.43519057681228546\n",
      "Epoch 122, Loss: 0.43453804496382226\n",
      "Epoch 123, Loss: 0.4339222909107312\n",
      "Epoch 124, Loss: 0.43329152752269723\n",
      "Epoch 125, Loss: 0.432652146969865\n",
      "Epoch 126, Loss: 0.4320239613144108\n",
      "Epoch 127, Loss: 0.4313971061248703\n",
      "Epoch 128, Loss: 0.4307620051765052\n",
      "Epoch 129, Loss: 0.4301248925166507\n",
      "Epoch 130, Loss: 0.429482601903623\n",
      "Epoch 131, Loss: 0.42884136466536193\n",
      "Epoch 132, Loss: 0.42821423512511564\n",
      "Epoch 133, Loss: 0.4275995329382391\n",
      "Epoch 134, Loss: 0.4269863538035582\n",
      "Epoch 135, Loss: 0.42636051496036764\n",
      "Epoch 136, Loss: 0.42571984294478604\n",
      "Epoch 137, Loss: 0.4250739461016478\n",
      "Epoch 138, Loss: 0.42441934230309836\n",
      "Epoch 139, Loss: 0.42374289222540107\n",
      "Epoch 140, Loss: 0.4230752754012615\n",
      "Epoch 141, Loss: 0.42246395961828637\n",
      "Epoch 142, Loss: 0.4219595506500548\n",
      "Epoch 143, Loss: 0.42150348623537737\n",
      "Epoch 144, Loss: 0.4209285468641111\n",
      "Epoch 145, Loss: 0.42000453046784836\n",
      "Epoch 146, Loss: 0.4194451931114477\n",
      "Epoch 147, Loss: 0.4190768411104025\n",
      "Epoch 148, Loss: 0.41829415604605874\n",
      "Epoch 149, Loss: 0.4174961198694986\n",
      "Epoch 150, Loss: 0.416995099881653\n",
      "Epoch 151, Loss: 0.4164305216459183\n",
      "Epoch 152, Loss: 0.4156252143974038\n",
      "Epoch 153, Loss: 0.41480334600613733\n",
      "Epoch 154, Loss: 0.41417152840711385\n",
      "Epoch 155, Loss: 0.41361332768133174\n",
      "Epoch 156, Loss: 0.412957498409405\n",
      "Epoch 157, Loss: 0.41220968390657114\n",
      "Epoch 158, Loss: 0.41136979909047394\n",
      "Epoch 159, Loss: 0.41065108104657805\n",
      "Epoch 160, Loss: 0.41000385177942966\n",
      "Epoch 161, Loss: 0.4094424257734775\n",
      "Epoch 162, Loss: 0.4091639367761594\n",
      "Epoch 163, Loss: 0.4090402042208247\n",
      "Epoch 164, Loss: 0.40843945830385725\n",
      "Epoch 165, Loss: 0.4070407068248601\n",
      "Epoch 166, Loss: 0.40635327713683295\n",
      "Epoch 167, Loss: 0.4063707502348828\n",
      "Epoch 168, Loss: 0.40572372607532337\n",
      "Epoch 169, Loss: 0.40470053383005167\n",
      "Epoch 170, Loss: 0.404349116391702\n",
      "Epoch 171, Loss: 0.40414221196404126\n",
      "Epoch 172, Loss: 0.40328667156324877\n",
      "Epoch 173, Loss: 0.40249436531506183\n",
      "Epoch 174, Loss: 0.4022429627039429\n",
      "Epoch 175, Loss: 0.40191703686284186\n",
      "Epoch 176, Loss: 0.40113081085808217\n",
      "Epoch 177, Loss: 0.40045950692502014\n",
      "Epoch 178, Loss: 0.40011343316183856\n",
      "Epoch 179, Loss: 0.39981359444868414\n",
      "Epoch 180, Loss: 0.3993911363508793\n",
      "Epoch 181, Loss: 0.39872970338066394\n",
      "Epoch 182, Loss: 0.3981336669337818\n",
      "Epoch 183, Loss: 0.3976516453564445\n",
      "Epoch 184, Loss: 0.39728086549225244\n",
      "Epoch 185, Loss: 0.39707596339057444\n",
      "Epoch 186, Loss: 0.39703400573014314\n",
      "Epoch 187, Loss: 0.397185283927828\n",
      "Epoch 188, Loss: 0.39675014965052147\n",
      "Epoch 189, Loss: 0.39577247335805643\n",
      "Epoch 190, Loss: 0.39488855555308366\n",
      "Epoch 191, Loss: 0.3947165780972992\n",
      "Epoch 192, Loss: 0.39490408324359394\n",
      "Epoch 193, Loss: 0.3944772551196194\n",
      "Epoch 194, Loss: 0.39366248762896067\n",
      "Epoch 195, Loss: 0.39315902850760576\n",
      "Epoch 196, Loss: 0.3931468241627236\n",
      "Epoch 197, Loss: 0.3931069678945476\n",
      "Epoch 198, Loss: 0.39264680252216005\n",
      "Epoch 199, Loss: 0.3920298871365968\n",
      "Epoch 200, Loss: 0.3915903941248056\n",
      "Epoch 201, Loss: 0.391467806454643\n",
      "Epoch 202, Loss: 0.3913702912097618\n",
      "Epoch 203, Loss: 0.39111722451268843\n",
      "Epoch 204, Loss: 0.39069474551302313\n",
      "Epoch 205, Loss: 0.390198684755716\n",
      "Epoch 206, Loss: 0.38986777344341966\n",
      "Epoch 207, Loss: 0.3896205767850717\n",
      "Epoch 208, Loss: 0.38941929707590134\n",
      "Epoch 209, Loss: 0.3893183407041471\n",
      "Epoch 210, Loss: 0.3892910305306388\n",
      "Epoch 211, Loss: 0.38935416446005205\n",
      "Epoch 212, Loss: 0.38933359299462184\n",
      "Epoch 213, Loss: 0.3891211553580357\n",
      "Epoch 214, Loss: 0.38831635130368136\n",
      "Epoch 215, Loss: 0.38763707874254666\n",
      "Epoch 216, Loss: 0.3873616471489575\n",
      "Epoch 217, Loss: 0.387478073330377\n",
      "Epoch 218, Loss: 0.38777680585498636\n",
      "Epoch 219, Loss: 0.3875305825132274\n",
      "Epoch 220, Loss: 0.3870399566829175\n",
      "Epoch 221, Loss: 0.38634798791503866\n",
      "Epoch 222, Loss: 0.38598748628562013\n",
      "Epoch 223, Loss: 0.38602172766445375\n",
      "Epoch 224, Loss: 0.38621048327026014\n",
      "Epoch 225, Loss: 0.3862009724423015\n",
      "Epoch 226, Loss: 0.3858212546908384\n",
      "Epoch 227, Loss: 0.38540888039568116\n",
      "Epoch 228, Loss: 0.3849102658502626\n",
      "Epoch 229, Loss: 0.3847372945047231\n",
      "Epoch 230, Loss: 0.3848322892892838\n",
      "Epoch 231, Loss: 0.38479102965782214\n",
      "Epoch 232, Loss: 0.38462410662463314\n",
      "Epoch 233, Loss: 0.3842984573012176\n",
      "Epoch 234, Loss: 0.3839130346981905\n",
      "Epoch 235, Loss: 0.3836754589499877\n",
      "Epoch 236, Loss: 0.38355024444558367\n",
      "Epoch 237, Loss: 0.38345236726896387\n",
      "Epoch 238, Loss: 0.38346328692165993\n",
      "Epoch 239, Loss: 0.3837138094906692\n",
      "Epoch 240, Loss: 0.384101856688968\n",
      "Epoch 241, Loss: 0.38464762238506883\n",
      "Epoch 242, Loss: 0.38423666441839066\n",
      "Epoch 243, Loss: 0.38322724043844275\n",
      "Epoch 244, Loss: 0.38235348800149715\n",
      "Epoch 245, Loss: 0.3826215423445203\n",
      "Epoch 246, Loss: 0.38315382162963746\n",
      "Epoch 247, Loss: 0.3825979994226527\n",
      "Epoch 248, Loss: 0.3819116190570468\n",
      "Epoch 249, Loss: 0.38176761806256465\n",
      "Epoch 250, Loss: 0.3820425971906687\n",
      "Epoch 251, Loss: 0.38211831580952416\n",
      "Epoch 252, Loss: 0.38172507079017176\n",
      "Epoch 253, Loss: 0.38119777415537376\n",
      "Epoch 254, Loss: 0.3810147873143993\n",
      "Epoch 255, Loss: 0.3810849817572491\n",
      "Epoch 256, Loss: 0.3811740064707976\n",
      "Epoch 257, Loss: 0.38113188164548356\n",
      "Epoch 258, Loss: 0.38091281613746236\n",
      "Epoch 259, Loss: 0.3804936340152897\n",
      "Epoch 260, Loss: 0.3801941956108115\n",
      "Epoch 261, Loss: 0.3800406042478054\n",
      "Epoch 262, Loss: 0.38000680424847505\n",
      "Epoch 263, Loss: 0.38009829648977717\n",
      "Epoch 264, Loss: 0.3803153039958966\n",
      "Epoch 265, Loss: 0.3806368838179198\n",
      "Epoch 266, Loss: 0.3806427168207115\n",
      "Epoch 267, Loss: 0.380522867853988\n",
      "Epoch 268, Loss: 0.37966002376651775\n",
      "Epoch 269, Loss: 0.3790642713613862\n",
      "Epoch 270, Loss: 0.37900451487114156\n",
      "Epoch 271, Loss: 0.37935364256166254\n",
      "Epoch 272, Loss: 0.37974857812355356\n",
      "Epoch 273, Loss: 0.3794981472550652\n",
      "Epoch 274, Loss: 0.3791148997520066\n",
      "Epoch 275, Loss: 0.3785524584600559\n",
      "Epoch 276, Loss: 0.37818446676954054\n",
      "Epoch 277, Loss: 0.37812512295303236\n",
      "Epoch 278, Loss: 0.37824707110040623\n",
      "Epoch 279, Loss: 0.3786142935160048\n",
      "Epoch 280, Loss: 0.37899032132011945\n",
      "Epoch 281, Loss: 0.3793231008245414\n",
      "Epoch 282, Loss: 0.3786708257718481\n",
      "Epoch 283, Loss: 0.37802781203804386\n",
      "Epoch 284, Loss: 0.377307448605613\n",
      "Epoch 285, Loss: 0.37710580056351467\n",
      "Epoch 286, Loss: 0.3773602871005798\n",
      "Epoch 287, Loss: 0.3775896617690502\n",
      "Epoch 288, Loss: 0.37784752950780676\n",
      "Epoch 289, Loss: 0.3773915207283289\n",
      "Epoch 290, Loss: 0.376777232348405\n",
      "Epoch 291, Loss: 0.37624216977713104\n",
      "Epoch 292, Loss: 0.3761282676701895\n",
      "Epoch 293, Loss: 0.3761275149420105\n",
      "Epoch 294, Loss: 0.3762223072252974\n",
      "Epoch 295, Loss: 0.3766021082454447\n",
      "Epoch 296, Loss: 0.3768262303682724\n",
      "Epoch 297, Loss: 0.376878661870168\n",
      "Epoch 298, Loss: 0.37645573982284125\n",
      "Epoch 299, Loss: 0.375905632165047\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2661019911171705\n",
      "Test R^2 score: 0.22860426331906503\n",
      "Num of epochs: 300\n",
      "Epoch 1, Loss: 0.5910523266436626\n",
      "Epoch 2, Loss: 0.5886454251630596\n",
      "Epoch 3, Loss: 0.5863608801610956\n",
      "Epoch 4, Loss: 0.5841838789330055\n",
      "Epoch 5, Loss: 0.5821231539064\n",
      "Epoch 6, Loss: 0.5801649446090189\n",
      "Epoch 7, Loss: 0.5782954506005319\n",
      "Epoch 8, Loss: 0.5765141133419559\n",
      "Epoch 9, Loss: 0.5748175528535356\n",
      "Epoch 10, Loss: 0.5732041042486412\n",
      "Epoch 11, Loss: 0.5716758787851297\n",
      "Epoch 12, Loss: 0.5702232395500675\n",
      "Epoch 13, Loss: 0.5688628755424504\n",
      "Epoch 14, Loss: 0.5675776503285932\n",
      "Epoch 15, Loss: 0.5664676238384617\n",
      "Epoch 16, Loss: 0.5654630239407066\n",
      "Epoch 17, Loss: 0.5645514801818184\n",
      "Epoch 18, Loss: 0.5636919690817929\n",
      "Epoch 19, Loss: 0.5628844113241899\n",
      "Epoch 20, Loss: 0.5621336167591009\n",
      "Epoch 21, Loss: 0.5614406624197157\n",
      "Epoch 22, Loss: 0.5607969145076398\n",
      "Epoch 23, Loss: 0.5602067719770326\n",
      "Epoch 24, Loss: 0.5596975877492781\n",
      "Epoch 25, Loss: 0.5592479209827153\n",
      "Epoch 26, Loss: 0.5588385572383666\n",
      "Epoch 27, Loss: 0.558459979492363\n",
      "Epoch 28, Loss: 0.5581251192680138\n",
      "Epoch 29, Loss: 0.5578018924762413\n",
      "Epoch 30, Loss: 0.5575026145582943\n",
      "Epoch 31, Loss: 0.557237913682633\n",
      "Epoch 32, Loss: 0.556976618502041\n",
      "Epoch 33, Loss: 0.5567141300323418\n",
      "Epoch 34, Loss: 0.556442091488311\n",
      "Epoch 35, Loss: 0.5561556661103024\n",
      "Epoch 36, Loss: 0.5558537861589316\n",
      "Epoch 37, Loss: 0.5555212444068088\n",
      "Epoch 38, Loss: 0.5551424981090775\n",
      "Epoch 39, Loss: 0.5547072984627566\n",
      "Epoch 40, Loss: 0.5542010471128981\n",
      "Epoch 41, Loss: 0.5536065919976313\n",
      "Epoch 42, Loss: 0.5528841927695812\n",
      "Epoch 43, Loss: 0.5519943405497029\n",
      "Epoch 44, Loss: 0.5509074181595114\n",
      "Epoch 45, Loss: 0.5495373362143697\n",
      "Epoch 46, Loss: 0.5478626052913091\n",
      "Epoch 47, Loss: 0.5458168692204803\n",
      "Epoch 48, Loss: 0.5433230444844735\n",
      "Epoch 49, Loss: 0.5403128235321224\n",
      "Epoch 50, Loss: 0.5367452601031183\n",
      "Epoch 51, Loss: 0.5327485211126745\n",
      "Epoch 52, Loss: 0.5286888205302859\n",
      "Epoch 53, Loss: 0.5252425825438654\n",
      "Epoch 54, Loss: 0.523229329861461\n",
      "Epoch 55, Loss: 0.5225145259006159\n",
      "Epoch 56, Loss: 0.5209417198573174\n",
      "Epoch 57, Loss: 0.5180232886690819\n",
      "Epoch 58, Loss: 0.514996926381837\n",
      "Epoch 59, Loss: 0.5128192279567273\n",
      "Epoch 60, Loss: 0.5114292170154427\n",
      "Epoch 61, Loss: 0.510094284570544\n",
      "Epoch 62, Loss: 0.5081941784152576\n",
      "Epoch 63, Loss: 0.5056387224916908\n",
      "Epoch 64, Loss: 0.5026313563554239\n",
      "Epoch 65, Loss: 0.4996789855422472\n",
      "Epoch 66, Loss: 0.497390269369858\n",
      "Epoch 67, Loss: 0.4958302256008603\n",
      "Epoch 68, Loss: 0.4943843587237909\n",
      "Epoch 69, Loss: 0.4924014247234923\n",
      "Epoch 70, Loss: 0.4901276582472148\n",
      "Epoch 71, Loss: 0.4881008730553679\n",
      "Epoch 72, Loss: 0.48639105577323266\n",
      "Epoch 73, Loss: 0.484599953374888\n",
      "Epoch 74, Loss: 0.48241161999632937\n",
      "Epoch 75, Loss: 0.4799227985495527\n",
      "Epoch 76, Loss: 0.47751966877817187\n",
      "Epoch 77, Loss: 0.47546430595093686\n",
      "Epoch 78, Loss: 0.47355951744913544\n",
      "Epoch 79, Loss: 0.4714765091360807\n",
      "Epoch 80, Loss: 0.4695864843292711\n",
      "Epoch 81, Loss: 0.46829204441239397\n",
      "Epoch 82, Loss: 0.4673663540152919\n",
      "Epoch 83, Loss: 0.46630519046839725\n",
      "Epoch 84, Loss: 0.46501308850869766\n",
      "Epoch 85, Loss: 0.46394113051689717\n",
      "Epoch 86, Loss: 0.46336864785676274\n",
      "Epoch 87, Loss: 0.4621526412508284\n",
      "Epoch 88, Loss: 0.460692243468566\n",
      "Epoch 89, Loss: 0.45982985845925606\n",
      "Epoch 90, Loss: 0.45913984222371346\n",
      "Epoch 91, Loss: 0.45809380998903165\n",
      "Epoch 92, Loss: 0.4573611022816514\n",
      "Epoch 93, Loss: 0.4568004514457322\n",
      "Epoch 94, Loss: 0.45588430942833996\n",
      "Epoch 95, Loss: 0.4554012281250508\n",
      "Epoch 96, Loss: 0.4545605544540749\n",
      "Epoch 97, Loss: 0.4536981903531948\n",
      "Epoch 98, Loss: 0.4528937242845082\n",
      "Epoch 99, Loss: 0.45194393006831957\n",
      "Epoch 100, Loss: 0.45137156571460635\n",
      "Epoch 101, Loss: 0.4505869058070301\n",
      "Epoch 102, Loss: 0.45004011611146305\n",
      "Epoch 103, Loss: 0.449316660949993\n",
      "Epoch 104, Loss: 0.4486164865608041\n",
      "Epoch 105, Loss: 0.44785301916964404\n",
      "Epoch 106, Loss: 0.4471590673123433\n",
      "Epoch 107, Loss: 0.44649811237124154\n",
      "Epoch 108, Loss: 0.44589643507184934\n",
      "Epoch 109, Loss: 0.445241219688344\n",
      "Epoch 110, Loss: 0.4445758213968545\n",
      "Epoch 111, Loss: 0.44384819341276627\n",
      "Epoch 112, Loss: 0.44320326421995376\n",
      "Epoch 113, Loss: 0.44259237752996694\n",
      "Epoch 114, Loss: 0.44204121046821515\n",
      "Epoch 115, Loss: 0.4413723215212559\n",
      "Epoch 116, Loss: 0.4407152996467794\n",
      "Epoch 117, Loss: 0.4400457666989483\n",
      "Epoch 118, Loss: 0.43940885532768736\n",
      "Epoch 119, Loss: 0.4388469839093041\n",
      "Epoch 120, Loss: 0.4382098943929109\n",
      "Epoch 121, Loss: 0.4375356761827555\n",
      "Epoch 122, Loss: 0.4369380441290395\n",
      "Epoch 123, Loss: 0.43631835147904874\n",
      "Epoch 124, Loss: 0.4356764185919957\n",
      "Epoch 125, Loss: 0.43508397294846063\n",
      "Epoch 126, Loss: 0.43448223121468943\n",
      "Epoch 127, Loss: 0.43384410744217977\n",
      "Epoch 128, Loss: 0.43324674863085066\n",
      "Epoch 129, Loss: 0.4327038921329703\n",
      "Epoch 130, Loss: 0.43211340580096336\n",
      "Epoch 131, Loss: 0.4315129432151496\n",
      "Epoch 132, Loss: 0.43086973023961656\n",
      "Epoch 133, Loss: 0.4302378857540198\n",
      "Epoch 134, Loss: 0.42960528540862947\n",
      "Epoch 135, Loss: 0.4289808184174604\n",
      "Epoch 136, Loss: 0.4284089921611289\n",
      "Epoch 137, Loss: 0.4278703760771519\n",
      "Epoch 138, Loss: 0.4275338909312138\n",
      "Epoch 139, Loss: 0.42741898008749213\n",
      "Epoch 140, Loss: 0.42704876511710904\n",
      "Epoch 141, Loss: 0.42550660821241193\n",
      "Epoch 142, Loss: 0.4252807405205121\n",
      "Epoch 143, Loss: 0.42531744167195434\n",
      "Epoch 144, Loss: 0.4238502918546607\n",
      "Epoch 145, Loss: 0.42368861068825353\n",
      "Epoch 146, Loss: 0.42370726800347563\n",
      "Epoch 147, Loss: 0.4222216418259519\n",
      "Epoch 148, Loss: 0.4220509338872922\n",
      "Epoch 149, Loss: 0.421848649508919\n",
      "Epoch 150, Loss: 0.4205665253270701\n",
      "Epoch 151, Loss: 0.420582787916554\n",
      "Epoch 152, Loss: 0.4200805719044333\n",
      "Epoch 153, Loss: 0.41887883012296057\n",
      "Epoch 154, Loss: 0.4189060432863277\n",
      "Epoch 155, Loss: 0.41841643413594726\n",
      "Epoch 156, Loss: 0.41724666718808423\n",
      "Epoch 157, Loss: 0.4170156646480368\n",
      "Epoch 158, Loss: 0.41679929966744184\n",
      "Epoch 159, Loss: 0.4157016805312926\n",
      "Epoch 160, Loss: 0.4151185801008763\n",
      "Epoch 161, Loss: 0.4149887413485486\n",
      "Epoch 162, Loss: 0.4143871258418588\n",
      "Epoch 163, Loss: 0.4135644184198919\n",
      "Epoch 164, Loss: 0.41287758264360414\n",
      "Epoch 165, Loss: 0.412599245327931\n",
      "Epoch 166, Loss: 0.41241185445837036\n",
      "Epoch 167, Loss: 0.41195632479007516\n",
      "Epoch 168, Loss: 0.4111732227463535\n",
      "Epoch 169, Loss: 0.41036055789694664\n",
      "Epoch 170, Loss: 0.4098076565171057\n",
      "Epoch 171, Loss: 0.4094828026913448\n",
      "Epoch 172, Loss: 0.40921213390104294\n",
      "Epoch 173, Loss: 0.4089839713049994\n",
      "Epoch 174, Loss: 0.40848161241733677\n",
      "Epoch 175, Loss: 0.407877833515254\n",
      "Epoch 176, Loss: 0.40703272608747465\n",
      "Epoch 177, Loss: 0.4063332179006507\n",
      "Epoch 178, Loss: 0.405838335977044\n",
      "Epoch 179, Loss: 0.4055627181107982\n",
      "Epoch 180, Loss: 0.40601176832788566\n",
      "Epoch 181, Loss: 0.4071091590167761\n",
      "Epoch 182, Loss: 0.40744473767160944\n",
      "Epoch 183, Loss: 0.40411452083175\n",
      "Epoch 184, Loss: 0.4034485693845347\n",
      "Epoch 185, Loss: 0.40471550097121234\n",
      "Epoch 186, Loss: 0.4029568565480174\n",
      "Epoch 187, Loss: 0.4018417485839404\n",
      "Epoch 188, Loss: 0.4024999185822683\n",
      "Epoch 189, Loss: 0.4019483085914668\n",
      "Epoch 190, Loss: 0.40065392001505284\n",
      "Epoch 191, Loss: 0.40010162716534425\n",
      "Epoch 192, Loss: 0.40040303652995307\n",
      "Epoch 193, Loss: 0.40041872251593497\n",
      "Epoch 194, Loss: 0.3992388651160401\n",
      "Epoch 195, Loss: 0.39821661642090206\n",
      "Epoch 196, Loss: 0.39788553863456144\n",
      "Epoch 197, Loss: 0.39810022402792755\n",
      "Epoch 198, Loss: 0.3984046436301068\n",
      "Epoch 199, Loss: 0.397879377918085\n",
      "Epoch 200, Loss: 0.39705243311987864\n",
      "Epoch 201, Loss: 0.3957579210456193\n",
      "Epoch 202, Loss: 0.3951260643497892\n",
      "Epoch 203, Loss: 0.3952230487986941\n",
      "Epoch 204, Loss: 0.39590712746190143\n",
      "Epoch 205, Loss: 0.3977755114791523\n",
      "Epoch 206, Loss: 0.396537626852691\n",
      "Epoch 207, Loss: 0.39419596182464284\n",
      "Epoch 208, Loss: 0.39263936414436107\n",
      "Epoch 209, Loss: 0.39340801676963205\n",
      "Epoch 210, Loss: 0.3949016494175092\n",
      "Epoch 211, Loss: 0.39339546030520434\n",
      "Epoch 212, Loss: 0.3914232299837273\n",
      "Epoch 213, Loss: 0.390876078975934\n",
      "Epoch 214, Loss: 0.39155549803468614\n",
      "Epoch 215, Loss: 0.39201095756596366\n",
      "Epoch 216, Loss: 0.3903777484400064\n",
      "Epoch 217, Loss: 0.389179415926235\n",
      "Epoch 218, Loss: 0.38874829561773705\n",
      "Epoch 219, Loss: 0.3888813585259977\n",
      "Epoch 220, Loss: 0.3897983769250903\n",
      "Epoch 221, Loss: 0.3902408427484323\n",
      "Epoch 222, Loss: 0.3909139136952922\n",
      "Epoch 223, Loss: 0.3884670733965803\n",
      "Epoch 224, Loss: 0.3868332702920729\n",
      "Epoch 225, Loss: 0.3859122951477988\n",
      "Epoch 226, Loss: 0.38664100327842277\n",
      "Epoch 227, Loss: 0.388399747731012\n",
      "Epoch 228, Loss: 0.3885898791136866\n",
      "Epoch 229, Loss: 0.38766623515285203\n",
      "Epoch 230, Loss: 0.38457094873440617\n",
      "Epoch 231, Loss: 0.38391852682540845\n",
      "Epoch 232, Loss: 0.3848308759635379\n",
      "Epoch 233, Loss: 0.3853909402285744\n",
      "Epoch 234, Loss: 0.38508842211480526\n",
      "Epoch 235, Loss: 0.383200973831345\n",
      "Epoch 236, Loss: 0.38178508449182863\n",
      "Epoch 237, Loss: 0.38116714562173454\n",
      "Epoch 238, Loss: 0.38093259058754636\n",
      "Epoch 239, Loss: 0.3815289407167014\n",
      "Epoch 240, Loss: 0.3826330893358382\n",
      "Epoch 241, Loss: 0.3848246417798105\n",
      "Epoch 242, Loss: 0.38361659554939115\n",
      "Epoch 243, Loss: 0.38131065042569556\n",
      "Epoch 244, Loss: 0.37862175161329004\n",
      "Epoch 245, Loss: 0.3781280982465944\n",
      "Epoch 246, Loss: 0.3797831269708056\n",
      "Epoch 247, Loss: 0.38138737392325306\n",
      "Epoch 248, Loss: 0.38253225072145974\n",
      "Epoch 249, Loss: 0.37864713559283125\n",
      "Epoch 250, Loss: 0.3764022399067994\n",
      "Epoch 251, Loss: 0.37586916095472234\n",
      "Epoch 252, Loss: 0.37720439620206947\n",
      "Epoch 253, Loss: 0.37989601171161774\n",
      "Epoch 254, Loss: 0.3789008621933914\n",
      "Epoch 255, Loss: 0.3767631328675787\n",
      "Epoch 256, Loss: 0.37404648433425713\n",
      "Epoch 257, Loss: 0.3737494957005087\n",
      "Epoch 258, Loss: 0.37508655582321476\n",
      "Epoch 259, Loss: 0.37672231456536875\n",
      "Epoch 260, Loss: 0.37793083092174007\n",
      "Epoch 261, Loss: 0.37465276138726733\n",
      "Epoch 262, Loss: 0.3721693612970762\n",
      "Epoch 263, Loss: 0.3714546657038162\n",
      "Epoch 264, Loss: 0.372903326886375\n",
      "Epoch 265, Loss: 0.3758977634043726\n",
      "Epoch 266, Loss: 0.3766303780820921\n",
      "Epoch 267, Loss: 0.3738132613365177\n",
      "Epoch 268, Loss: 0.37012807784754187\n",
      "Epoch 269, Loss: 0.3699872234110306\n",
      "Epoch 270, Loss: 0.3726612914442136\n",
      "Epoch 271, Loss: 0.3751647706436506\n",
      "Epoch 272, Loss: 0.3737301186788458\n",
      "Epoch 273, Loss: 0.3694244585311937\n",
      "Epoch 274, Loss: 0.36794403948900706\n",
      "Epoch 275, Loss: 0.37000327257049415\n",
      "Epoch 276, Loss: 0.3719442158885808\n",
      "Epoch 277, Loss: 0.3712494975064149\n",
      "Epoch 278, Loss: 0.3684727717721938\n",
      "Epoch 279, Loss: 0.366573815167059\n",
      "Epoch 280, Loss: 0.36647122097865714\n",
      "Epoch 281, Loss: 0.36801075462766264\n",
      "Epoch 282, Loss: 0.3696693186670554\n",
      "Epoch 283, Loss: 0.3695161312309016\n",
      "Epoch 284, Loss: 0.3676069988135508\n",
      "Epoch 285, Loss: 0.365115222772577\n",
      "Epoch 286, Loss: 0.3643739326029564\n",
      "Epoch 287, Loss: 0.3653218373719806\n",
      "Epoch 288, Loss: 0.3668357300415037\n",
      "Epoch 289, Loss: 0.36929973826338425\n",
      "Epoch 290, Loss: 0.3684591229073822\n",
      "Epoch 291, Loss: 0.3656680342624919\n",
      "Epoch 292, Loss: 0.3631213461779085\n",
      "Epoch 293, Loss: 0.36289155218788177\n",
      "Epoch 294, Loss: 0.3641481004204231\n",
      "Epoch 295, Loss: 0.3662651937347213\n",
      "Epoch 296, Loss: 0.36738838625567993\n",
      "Epoch 297, Loss: 0.365818902301667\n",
      "Epoch 298, Loss: 0.3632953805123664\n",
      "Epoch 299, Loss: 0.36127052879082344\n",
      "Epoch 300, Loss: 0.3612252166192974\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.25426968935243843\n",
      "Test R^2 score: 0.305070488749613\n",
      "Completed.\n"
     ]
    }
   ],
   "source": [
    "for num_epochs in num_epochs_list:\n",
    "  print(f'Num of epochs: {num_epochs}')\n",
    "  \n",
    "  model = train_model(num_epochs)\n",
    "\n",
    "  print(\"Training completed.\")\n",
    "  print(\"Testing model...\")\n",
    "\n",
    "  test_pred, rmse, r2_score = test_model(model)\n",
    "  r2_scores_list.append(r2_score)\n",
    "  rmse_list.append(rmse)\n",
    "\n",
    "print(\"Completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the graph to visualise the relationship between epochs and r^2 score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.36602040368659494,\n",
       " -0.0525073900299845,\n",
       " -0.24252575767042395,\n",
       " -0.06905817392914027,\n",
       " -0.04821156181738773,\n",
       " -0.04903012202086254,\n",
       " -0.10518717046527304,\n",
       " -0.07919195349137242,\n",
       " -0.16257440605503515,\n",
       " -0.006492499076157787,\n",
       " -0.09902294404843393,\n",
       " -0.14442986025703008,\n",
       " -0.037702182567893705,\n",
       " -0.04599577528197929,\n",
       " -0.026426265948142125,\n",
       " -0.07838428787310725,\n",
       " -0.003945783343389131,\n",
       " -0.005236659441914648,\n",
       " -0.15624500963519972,\n",
       " -0.009408584576971024,\n",
       " -0.02280430351356888,\n",
       " 0.0016060845340539198,\n",
       " -0.005777301273682922,\n",
       " -0.008927439518905567,\n",
       " -0.00272775384404611,\n",
       " 0.00317436608412508,\n",
       " 0.007713634862911822,\n",
       " 0.06423003630458013,\n",
       " -0.015954426310469283,\n",
       " 0.021369056041318113,\n",
       " 0.006400275807526334,\n",
       " 0.005779184060019593,\n",
       " 0.09822127901911942,\n",
       " 0.016312948959951,\n",
       " 0.07569099231327808,\n",
       " 0.08405374365024093,\n",
       " 0.19314726837438823,\n",
       " 0.1286870043479032,\n",
       " 0.28225364998932306,\n",
       " 0.11915902827526781,\n",
       " 0.05539345631621556,\n",
       " 0.029990506413105744,\n",
       " 0.22213012326574005,\n",
       " 0.16073319864186214,\n",
       " 0.2871962573865998,\n",
       " 0.33707324776576764,\n",
       " 0.22204741580577708,\n",
       " 0.2506487875001098,\n",
       " 0.37804733635588106,\n",
       " 0.347391311214101,\n",
       " 0.3586790290017078,\n",
       " 0.3333546977324073,\n",
       " 0.27648488133934757,\n",
       " 0.3568222059490627,\n",
       " 0.3064139523305293,\n",
       " 0.3917816857335793,\n",
       " 0.3906646731649457,\n",
       " 0.421310139366671,\n",
       " 0.4535322032253295,\n",
       " 0.46165690480032934,\n",
       " 0.351312374241081,\n",
       " 0.3800394943913229,\n",
       " 0.4408104430522945,\n",
       " 0.462692737932308,\n",
       " 0.35735648970028727,\n",
       " 0.5013785804480692,\n",
       " 0.4423195790845283,\n",
       " 0.49077371772419087,\n",
       " 0.4633074607894256,\n",
       " 0.3816918160528826,\n",
       " 0.4981562017447203,\n",
       " 0.45464782472622184,\n",
       " 0.47311858059328016,\n",
       " 0.3746258074295084,\n",
       " 0.460212280519701,\n",
       " 0.495778022274542,\n",
       " 0.4804267868347989,\n",
       " 0.5114869628339827,\n",
       " 0.4798571113691376,\n",
       " 0.5068933431459464,\n",
       " 0.5146582253433278,\n",
       " 0.5008514993567187,\n",
       " 0.5058474935531625,\n",
       " 0.5035935125068194,\n",
       " 0.4959575342190069,\n",
       " 0.5090873566375718,\n",
       " 0.42985375603747533,\n",
       " 0.41786451073616276,\n",
       " 0.48006973980351675,\n",
       " 0.5118369095086713,\n",
       " 0.5047650588743443,\n",
       " 0.4955013438891375,\n",
       " 0.5065686482473732,\n",
       " 0.4940291350065739,\n",
       " 0.47393663845030987,\n",
       " 0.4878301843518427,\n",
       " 0.510576108932536,\n",
       " 0.49745017333526037,\n",
       " 0.5187373809098279,\n",
       " 0.5050079787065928,\n",
       " 0.49116813945293003,\n",
       " 0.5052357538650368,\n",
       " 0.5033164613646764,\n",
       " 0.4984371395558849,\n",
       " 0.5216925184737039,\n",
       " 0.4975180509207812,\n",
       " 0.5305071515355861,\n",
       " 0.5201860933447142,\n",
       " 0.5200787625566382,\n",
       " 0.5167742845111805,\n",
       " 0.49695111910299844,\n",
       " 0.5057391738255532,\n",
       " 0.44245873805583974,\n",
       " 0.49027589128890103,\n",
       " 0.48021106556694076,\n",
       " 0.5068778360239167,\n",
       " 0.5153316944076358,\n",
       " 0.5250782660057393,\n",
       " 0.4896994646121214,\n",
       " 0.5163179530608502,\n",
       " 0.5064188376006578,\n",
       " 0.48809564479229806,\n",
       " 0.49691205687922574,\n",
       " 0.49755096975970114,\n",
       " 0.49612735917945633,\n",
       " 0.464250891931237,\n",
       " 0.4792786563846296,\n",
       " 0.4942119418515379,\n",
       " 0.5126835020504172,\n",
       " 0.47174046832909444,\n",
       " 0.48382463002578674,\n",
       " 0.5181814430517355,\n",
       " 0.4981779950569151,\n",
       " 0.4913626708681507,\n",
       " 0.5147463592031389,\n",
       " 0.4823281332973294,\n",
       " 0.4643965130537868,\n",
       " 0.46961689813632146,\n",
       " 0.5009402481389025,\n",
       " 0.48375276695621966,\n",
       " 0.4714566872284449,\n",
       " 0.4209293460465778,\n",
       " 0.46529451088821633,\n",
       " 0.48187224288097885,\n",
       " 0.509805665322846,\n",
       " 0.49238755747677476,\n",
       " 0.4325020024761573,\n",
       " 0.4989962468923882,\n",
       " 0.48727588025134055,\n",
       " 0.4719718260603571,\n",
       " 0.43202178325766,\n",
       " 0.48185206413499493,\n",
       " 0.5124977095739494,\n",
       " 0.42205738306744695,\n",
       " 0.5108824357433084,\n",
       " 0.5084105716870584,\n",
       " 0.47176262284271464,\n",
       " 0.4161232249557088,\n",
       " 0.45741282666812216,\n",
       " 0.4521747678625083,\n",
       " 0.48791356212439974,\n",
       " 0.4923018376849578,\n",
       " 0.4605844248021362,\n",
       " 0.4793305941864424,\n",
       " 0.38794104879583624,\n",
       " 0.4453015857403224,\n",
       " 0.42814789516660245,\n",
       " 0.4078347160476235,\n",
       " 0.4484718183939172,\n",
       " 0.43925960594004315,\n",
       " 0.46097700967873156,\n",
       " 0.48070411873704294,\n",
       " 0.41211601567068507,\n",
       " 0.45189415081682405,\n",
       " 0.47348877588276084,\n",
       " 0.44423141119274745,\n",
       " 0.4343811913111232,\n",
       " 0.46262321160249875,\n",
       " 0.4248419155335765,\n",
       " 0.395190616466316,\n",
       " 0.4205526153830635,\n",
       " 0.42530947986621076,\n",
       " 0.3880998215095356,\n",
       " 0.33781165652025874,\n",
       " 0.47233039292793955,\n",
       " 0.31539474976695586,\n",
       " 0.4093548199336936,\n",
       " 0.4009606946156375,\n",
       " 0.4333964366052947,\n",
       " 0.41249634757328724,\n",
       " 0.47092170369733344,\n",
       " 0.4533025026210779,\n",
       " 0.42378533650835953,\n",
       " 0.40346203394812996,\n",
       " 0.45903591343772193,\n",
       " 0.35454473768306227,\n",
       " 0.44300112475681863,\n",
       " 0.40541057939775044,\n",
       " 0.43409763062167195,\n",
       " 0.4582013876879018,\n",
       " 0.3576587982758827,\n",
       " 0.4173909293350896,\n",
       " 0.4179970832796602,\n",
       " 0.26115444146566025,\n",
       " 0.3960913581088144,\n",
       " 0.4068294317118875,\n",
       " 0.43336570239206884,\n",
       " 0.4543082081546044,\n",
       " 0.4352530508413614,\n",
       " 0.36795626383129904,\n",
       " 0.4653397661339861,\n",
       " 0.3810121475380822,\n",
       " 0.38394629414458303,\n",
       " 0.40612950883717674,\n",
       " 0.38584155163007455,\n",
       " 0.42195950327200743,\n",
       " 0.3776987965636249,\n",
       " 0.4148512807221184,\n",
       " 0.39520305393383737,\n",
       " 0.35091698735781485,\n",
       " 0.399840421473604,\n",
       " 0.32771900913772467,\n",
       " 0.3902910916348128,\n",
       " 0.4230159746055679,\n",
       " 0.3210242131452251,\n",
       " 0.42595985676762416,\n",
       " 0.4026784426081279,\n",
       " 0.4506397259326806,\n",
       " 0.39587104482612445,\n",
       " 0.3377325520607548,\n",
       " 0.38191294363558187,\n",
       " 0.338444406968685,\n",
       " 0.3473407474707202,\n",
       " 0.3884575038012872,\n",
       " 0.31708969533120923,\n",
       " 0.31499618861969986,\n",
       " 0.32309107650398045,\n",
       " 0.28054367098416394,\n",
       " 0.3895534226880654,\n",
       " 0.4109461631124342,\n",
       " 0.42164490564423357,\n",
       " 0.37606537861073375,\n",
       " 0.3096361330408397,\n",
       " 0.3817562913058017,\n",
       " 0.3454226075180372,\n",
       " 0.34168913945367274,\n",
       " 0.42610039423262486,\n",
       " 0.33497409108269177,\n",
       " 0.3230549181895157,\n",
       " 0.40133163321805765,\n",
       " 0.3896531820833876,\n",
       " 0.30314656102370713,\n",
       " 0.3545465731729379,\n",
       " 0.3356668163721278,\n",
       " 0.2993634065259982,\n",
       " 0.40936966543075703,\n",
       " 0.3242632213176178,\n",
       " 0.33821888670876804,\n",
       " 0.37111559525882415,\n",
       " 0.38000008264349805,\n",
       " 0.3506453114579265,\n",
       " 0.3684816068813128,\n",
       " 0.3577661602584802,\n",
       " 0.3557638451482005,\n",
       " 0.397364946681645,\n",
       " 0.318403256115838,\n",
       " 0.3554075270601834,\n",
       " 0.347431018140394,\n",
       " 0.3163644267641653,\n",
       " 0.2376687252874778,\n",
       " 0.3015292767734808,\n",
       " 0.25178316338892154,\n",
       " 0.2505605507179862,\n",
       " 0.2301560073329464,\n",
       " 0.3569455061837701,\n",
       " 0.38408056716898237,\n",
       " 0.2569977851246969,\n",
       " 0.3060728047899948,\n",
       " 0.3699952110768611,\n",
       " 0.354778050697439,\n",
       " 0.21369346462191624,\n",
       " 0.2930113556625229,\n",
       " 0.31518044005101153,\n",
       " 0.26425168685428113,\n",
       " 0.3519521240924003,\n",
       " 0.30785661392995944,\n",
       " 0.28413191754075323,\n",
       " 0.3068929387911665,\n",
       " 0.30972181417146044,\n",
       " 0.3003611281566991,\n",
       " 0.1839994475563832,\n",
       " 0.3557754441094134,\n",
       " 0.2760142731785364,\n",
       " 0.37921112622020586,\n",
       " 0.3625412045847139,\n",
       " 0.29127149022910853,\n",
       " 0.343825339527457,\n",
       " 0.1933345871810389,\n",
       " 0.22860426331906503,\n",
       " 0.305070488749613]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_scores_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the line graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(num_epochs_list, r2_scores_list, color='b', linestyle='-')\n",
    "plt.title('num_epochs vs. R^2 score')\n",
    "plt.xlabel('num_epochs')\n",
    "plt.ylabel('r^2 score') \n",
    "plt.grid(True)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max R^2 score: 0.5305071515355861\n",
      "Corresponding RMSE: 0.20825765651948547\n",
      "Corresponding num_epochs: 107\n"
     ]
    }
   ],
   "source": [
    "max_r2_score = max(r2_scores_list)\n",
    "corresponding_rmse = rmse_list[r2_scores_list.index(max_r2_score)]\n",
    "corresponding_num_epochs = num_epochs_list[r2_scores_list.index(max_r2_score)]\n",
    "\n",
    "print(f'Max R^2 score: {max_r2_score}')\n",
    "print(f'Corresponding RMSE: {corresponding_rmse}')\n",
    "print(f'Corresponding num_epochs: {corresponding_num_epochs}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
