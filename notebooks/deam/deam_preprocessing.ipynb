{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEAM Dataset - Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Done on local computer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import ast\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set file directory variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../../utils')\n",
    "from paths import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify file count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that the number of .csv files in the './data/DEAM/features' directory matches the number number of .mp3 files in the './data/DEAM/MEMD_audio' directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_filenames(directory, file_format):\n",
    "    raw_file_list = os.listdir(directory)\n",
    "    raw_count = len(raw_file_list)\n",
    "    print(f\"Total files: {raw_count} \\nFiles: {raw_file_list}\\n\")\n",
    "    print(\"Processing files...\")\n",
    "    processed_list = []\n",
    "    for filename in raw_file_list:\n",
    "        if file_format in filename:\n",
    "            filename = filename.replace(f\".{file_format}\", \"\")\n",
    "            processed_list.append(filename)\n",
    "    \n",
    "    processed_count = len(processed_list)\n",
    "    print(f\"Total files: {processed_count} \\nFiles: {processed_list}\")\n",
    "    return processed_list, processed_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list, features_count = extract_filenames(get_deam_path('features'), \"csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_list, audio_count = extract_filenames(get_deam_path('MEMD_audio'), \"mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if set(features_list) == set(audio_list):\n",
    "    print(\"Features and Audio Files match!\")\n",
    "else:\n",
    "    diff = set(features_list) - set(audio_list)\n",
    "    print(\"Elements absent in audio:\", diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process the annotation dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read static song-level annotations with song_id from 1 to 2000 (2013 and 2014 only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_annotations = pd.read_csv(get_deam_path('annotations/annotations averaged per song/song_level/static_annotations_averaged_songs_1_2000.csv'))\n",
    "display(df_annotations)\n",
    "print(df_annotations.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map the valence and arousal values in the dataset, ranging from 1 to 9, to values ranging from -1 to 1, to follow convention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_va_value(value):\n",
    "  old_min = 1\n",
    "  old_max = 9\n",
    "\n",
    "  new_min = -1\n",
    "  new_max = 1\n",
    "\n",
    "  mapped_value = ((value - old_min) * (new_max - new_min) / (old_max - old_min)) + new_min\n",
    "  return mapped_value\n",
    "\n",
    "# Test the function\n",
    "for i in range(1, 10):\n",
    "    print(f\"Original value: {i}, Mapped value: {map_va_value(i)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_annotations['valence_mean_mapped'] = df_annotations[' valence_mean'].apply(map_va_value)\n",
    "df_annotations['arousal_mean_mapped'] = df_annotations[' arousal_mean'].apply(map_va_value)\n",
    "df_annotations = df_annotations.drop([' valence_mean', ' valence_std', ' arousal_mean', ' arousal_std'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_annotations.to_csv(get_deam_path('processed/annotations/deam_static_annotations.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_annotations = pd.read_csv(get_deam_path('processed/annotations/deam_static_annotations.csv'))\n",
    "df_annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process the Essentia features datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function to check for any non-float/int columns and deal with them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_essentia_features = pd.read_csv(get_deam_path('processed/features/essentia_features.csv'))\n",
    "df_essentia_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop the 'Unnamed: 0\t' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop Unnamed:0 column\n",
    "df_essentia_features = df_essentia_features[df_essentia_features.columns[1:]]\n",
    "df_essentia_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See what features are available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_essentia_features.columns.to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get song_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_ids = df_essentia_features['song_id'].values.tolist()\n",
    "print(song_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some features are irrelevant, or are metadata. Drop them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_columns = [col for col in df_essentia_features.columns if 'metadata' in col]\n",
    "df_essentia_features = df_essentia_features.drop(columns=metadata_columns)\n",
    "df_essentia_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find out if any columns are not of the type float or int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "df_essentia_features.select_dtypes(exclude=['int64', 'float64'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like there are 3 main types of column types:\n",
    "\n",
    "1. ndarray\n",
    "2. string\n",
    "3. float64 or int64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the columns whose type is ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.reset_option('display.max_columns')\n",
    "\n",
    "string_columns = ['tonal.chords_key',\n",
    "                  'tonal.chords_scale',\n",
    "                  'tonal.key_edma.key',\n",
    "                  'tonal.key_edma.scale',\n",
    "                  'tonal.key_krumhansl.key',\n",
    "                  'tonal.key_krumhansl.scale',\n",
    "                  'tonal.key_temperley.key',\n",
    "                  'tonal.key_temperley.scale'\n",
    "                  ]\n",
    "\n",
    "df_essentia_features_ndarray_columns = df_essentia_features.select_dtypes(exclude=['int64', 'float64'])\n",
    "ndarray_columns = df_essentia_features_ndarray_columns.columns.difference(string_columns)\n",
    "df_essentia_features_ndarray_columns = df_essentia_features_ndarray_columns[ndarray_columns]\n",
    "df_essentia_features_ndarray_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print one random value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_essentia_features_ndarray_columns['lowlevel.mfcc.icov'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flatten the columns whose values are ndarrays, like tonal.chords_histogram\n",
    "\n",
    "Credits to https://stackoverflow.com/questions/45704999/how-to-convert-vector-wrapped-as-string-to-numpy-array-in-pandas-dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_to_ndarray(str):\n",
    "  return np.fromstring(str.replace('\\n','')\n",
    "                       .replace('[','')\n",
    "                       .replace(']','')\n",
    "                       .replace('  ',' '), \n",
    "                       sep=' '\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_essentia_features_ndarray_columns = df_essentia_features_ndarray_columns.applymap(string_to_ndarray)\n",
    "df_essentia_features_ndarray_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print out that same value to ensure that it is properly converted to a ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_essentia_features_ndarray_columns['lowlevel.mfcc.icov'][0])\n",
    "print(type(df_essentia_features_ndarray_columns['lowlevel.mfcc.icov'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.reset_option('display.max_columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that all values are proper ndarrays, let's flatten these columns, define a function to flatten a column into multiple new columns containing float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_column(df, col):\n",
    "  print(col)\n",
    "  result_dict = {}\n",
    "  num_of_new_cols = max([len(i) for i in df[col]])\n",
    "  # num_of_new_cols = len(df[col][0])\n",
    "  num_of_rows = len(df[col])\n",
    "\n",
    "  for i in range(num_of_new_cols):\n",
    "    result_col_name = f'{col}_{i}'\n",
    "    result_dict[result_col_name] = []\n",
    "\n",
    "  for i in range(num_of_rows):\n",
    "    for j in range(num_of_new_cols):\n",
    "      result_col_name = f'{col}_{j}'\n",
    "\n",
    "      # do padding\n",
    "      if j >= len(df[col][i]):\n",
    "        value = 0\n",
    "      else:\n",
    "        value = df[col][i][j]\n",
    "      \n",
    "      result_dict[result_col_name].append(value)\n",
    "\n",
    "  return pd.DataFrame(result_dict)\n",
    "\n",
    "# test the function\n",
    "df = flatten_column(df_essentia_features_ndarray_columns, 'lowlevel.mfcc.icov')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the function to flatten all these columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndarray_columns = df_essentia_features_ndarray_columns.columns.to_list()\n",
    "df_ndarray_columns = []\n",
    "\n",
    "for column in ndarray_columns:\n",
    "  df_ndarray_column = flatten_column(df_essentia_features_ndarray_columns, column)\n",
    "  df_ndarray_columns.append(df_ndarray_column)\n",
    "\n",
    "df_essentia_features_ndarray_columns = pd.concat(df_ndarray_columns, axis=1)\n",
    "df_essentia_features_ndarray_columns.insert(0, column='song_id', value=song_ids)\n",
    "df_essentia_features_ndarray_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the string columns, convert these categorical data into numerical data, get the dataframe with only the string columns first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_essentia_features_string_columns = df_essentia_features[string_columns]\n",
    "df_essentia_features_string_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then use cat.codes attribute to convert these categorical columns into numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df_essentia_features_string_columns.columns:\n",
    "  df_essentia_features_string_columns[col] = df_essentia_features_string_columns[col].astype('category')\n",
    "  df_essentia_features_string_columns[col] = df_essentia_features_string_columns[col].cat.codes\n",
    "\n",
    "df_essentia_features_string_columns.insert(0, column='song_id', value=song_ids)\n",
    "df_essentia_features_string_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine the ndarray columns, string columns, and the rest of the dataframe together in one flattened dataframe with just numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_essentia_features_numerical_columns = df_essentia_features.select_dtypes(include=['int64', 'float64'])\n",
    "\n",
    "df_temp = pd.merge(df_essentia_features_numerical_columns, df_essentia_features_ndarray_columns, how='inner', on='song_id')\n",
    "df_essentia_features_flattened = pd.merge(df_temp, df_essentia_features_string_columns, how='inner', on='song_id')\n",
    "\n",
    "df_essentia_features_flattened"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export the flattened Essentia features dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_essentia_features_flattened.to_csv(get_deam_path('processed/features/essentia_features_flattened.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create separate, more distinct features dataframes extracted by Essentia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the features lsit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deam_essentia_best_features import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get song ids for songs in 2013 and 2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_path = get_deam_path('MEMD_audio')\n",
    "song_ids_temp = []\n",
    "\n",
    "# Iterate through all files in the directory\n",
    "for filename in os.listdir(audio_path):\n",
    "    # Check if the path is a file (not a subdirectory)\n",
    "    if os.path.isfile(os.path.join(audio_path, filename)):\n",
    "        song_ids_temp.append(int(filename[:-4]))\n",
    "\n",
    "song_ids_temp.sort()\n",
    "song_ids = []\n",
    "\n",
    "# remove all song_ids from 2015 (song_id 2001 onwards)\n",
    "for song_id in song_ids_temp:\n",
    "    if song_id <= 2000:\n",
    "        song_ids.append(song_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create separate feature dataset for best features for building arousal regressor\n",
    "According to https://ieeexplore-ieee-org.library.sutd.edu.sg:2443/stamp/stamp.jsp?tp=&arnumber=8001129"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_essentia_best_arousal_features = df_essentia_features_flattened[deam_essentia_best_arousal_features_flattened]\n",
    "df_essentia_best_arousal_features.insert(0, 'song_id', song_ids)\n",
    "df_essentia_best_arousal_features.to_csv(get_deam_path('processed/features/essentia_best_arousal_features.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the best feature dataset .csv for arousal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_essentia_best_arousal_features = pd.read_csv(get_deam_path('processed/features/essentia_best_arousal_features.csv'))\n",
    "\n",
    "# drop Unnamed:0 column\n",
    "df_essentia_best_arousal_features = df_essentia_best_arousal_features[df_essentia_best_arousal_features.columns[1:]]\n",
    "\n",
    "df_essentia_best_arousal_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create separate feature dataset for best features for building valence regressor\n",
    "According to https://ieeexplore-ieee-org.library.sutd.edu.sg:2443/stamp/stamp.jsp?tp=&arnumber=8001129"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_essentia_best_valence_features = df_essentia_features_flattened[deam_essentia_best_valence_features_flattened]\n",
    "df_essentia_best_valence_features.insert(0, 'song_id', song_ids)\n",
    "df_essentia_best_valence_features.to_csv(get_deam_path('processed/features/essentia_best_valence_features.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the best feature dataset .csv for valence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_essentia_best_valence_features = pd.read_csv(get_deam_path('processed/features/essentia_best_valence_features.csv'))\n",
    "\n",
    "# drop Unnamed:0 column\n",
    "df_essentia_best_valence_features = df_essentia_best_valence_features[df_essentia_best_valence_features.columns[1:]]\n",
    "\n",
    "df_essentia_best_valence_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create separate feature dataset for best overall features for detecting both arousal and valence\n",
    "\n",
    "According to https://ieeexplore-ieee-org.library.sutd.edu.sg:2443/stamp/stamp.jsp?tp=&arnumber=8001129"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_essentia_best_overall_features = df_essentia_features_flattened[deam_essentia_best_overall_features_flattened]\n",
    "df_essentia_best_overall_features.insert(0, 'song_id', song_ids)\n",
    "df_essentia_best_overall_features.to_csv(get_deam_path('processed/features/essentia_best_overall_features.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the best feature dataset .csv overall "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_essentia_best_overall_features = pd.read_csv(get_deam_path('processed/features/essentia_best_overall_features.csv'))\n",
    "\n",
    "# drop Unnamed:0 column\n",
    "df_essentia_best_overall_features = df_essentia_best_overall_features[df_essentia_best_overall_features.columns[1:]]\n",
    "\n",
    "df_essentia_best_overall_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrate Essentia features into openSMILE features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import openSMILE featuresets .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_deam_opensmile_compare2016_features = pd.read_csv(get_deam_path('processed/features/opensmile_compare2016_features.csv'))\n",
    "df_deam_opensmile_emobase_features = pd.read_csv(get_deam_path('processed/features/opensmile_emobase_features.csv'))\n",
    "df_deam_opensmile_gemaps_features = pd.read_csv(get_deam_path('processed/features/opensmile_gemaps_features.csv'))\n",
    "df_deam_opensmile_egemaps_features = pd.read_csv(get_deam_path('processed/features/opensmile_egemaps_features.csv'))\n",
    "\n",
    "# drop Unnamed:0 column\n",
    "df_deam_opensmile_compare2016_features = df_deam_opensmile_compare2016_features[df_deam_opensmile_compare2016_features.columns[1:]]\n",
    "df_deam_opensmile_emobase_features = df_deam_opensmile_emobase_features[df_deam_opensmile_emobase_features.columns[1:]]\n",
    "df_deam_opensmile_gemaps_features = df_deam_opensmile_gemaps_features[df_deam_opensmile_gemaps_features.columns[1:]]\n",
    "df_deam_opensmile_egemaps_features = df_deam_opensmile_egemaps_features[df_deam_opensmile_egemaps_features.columns[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_deam_opensmile_compare2016_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_deam_opensmile_emobase_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_deam_opensmile_gemaps_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_deam_opensmile_egemaps_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Integrate Essentia all features into openSMILE ComParE2016 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_deam_integrated_essentia_all_opensmile_compare2016 = pd.merge(df_essentia_features_flattened, df_deam_opensmile_compare2016_features, on='song_id', how='inner')\n",
    "\n",
    "# Identify identical columns for dropping\n",
    "identical_cols = [col for col in df_deam_integrated_essentia_all_opensmile_compare2016.columns if '_x' in col or '_y' in col]\n",
    "\n",
    "# Drop identical columns\n",
    "df_deam_integrated_essentia_all_opensmile_compare2016.drop(columns=identical_cols, inplace=True)\n",
    "\n",
    "df_deam_integrated_essentia_all_opensmile_compare2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_deam_integrated_essentia_all_opensmile_compare2016.to_csv(get_deam_path('processed/features/integrated/essentia_all_opensmile_compare2016_features.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Integrate Essentia all features into openSMILE emobase features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_deam_integrated_essentia_all_opensmile_emobase = pd.merge(df_essentia_features_flattened, df_deam_opensmile_emobase_features, on='song_id', how='inner')\n",
    "\n",
    "# Identify identical columns for dropping\n",
    "identical_cols = [col for col in df_deam_integrated_essentia_all_opensmile_emobase.columns if '_x' in col or '_y' in col]\n",
    "\n",
    "# Drop identical columns\n",
    "df_deam_integrated_essentia_all_opensmile_emobase.drop(columns=identical_cols, inplace=True)\n",
    "\n",
    "df_deam_integrated_essentia_all_opensmile_emobase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_deam_integrated_essentia_all_opensmile_emobase.to_csv(get_deam_path('processed/features/integrated/essentia_all_opensmile_emobase_features.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Integrate Essentia all features into openSMILE GeMAPS features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_deam_integrated_essentia_all_opensmile_gemaps = pd.merge(df_essentia_features_flattened, df_deam_opensmile_gemaps_features, on='song_id', how='inner')\n",
    "\n",
    "# Identify identical columns for dropping\n",
    "identical_cols = [col for col in df_deam_integrated_essentia_all_opensmile_gemaps.columns if '_x' in col or '_y' in col]\n",
    "\n",
    "# Drop identical columns\n",
    "df_deam_integrated_essentia_all_opensmile_gemaps.drop(columns=identical_cols, inplace=True)\n",
    "\n",
    "df_deam_integrated_essentia_all_opensmile_gemaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_deam_integrated_essentia_all_opensmile_gemaps.to_csv(get_deam_path('processed/features/integrated/essentia_all_opensmile_gemaps_features.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Integrate Essentia all features into openSMILE eGeMAPS features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_deam_integrated_essentia_all_opensmile_egemaps = pd.merge(df_essentia_features_flattened, df_deam_opensmile_egemaps_features, on='song_id', how='inner')\n",
    "\n",
    "# Identify identical columns for dropping\n",
    "identical_cols = [col for col in df_deam_integrated_essentia_all_opensmile_egemaps.columns if '_x' in col or '_y' in col]\n",
    "\n",
    "# Drop identical columns\n",
    "df_deam_integrated_essentia_all_opensmile_egemaps.drop(columns=identical_cols, inplace=True)\n",
    "\n",
    "df_deam_integrated_essentia_all_opensmile_egemaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_deam_integrated_essentia_all_opensmile_egemaps.to_csv(get_deam_path('processed/features/integrated/essentia_all_opensmile_egemaps_features.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Integrate Essentia best overall features into openSMILE ComParE2016 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_deam_integrated_essentia_best_overall_opensmile_compare2016 = pd.merge(df_essentia_best_overall_features, df_deam_opensmile_compare2016_features, on='song_id', how='inner')\n",
    "\n",
    "# Identify identical columns for dropping\n",
    "identical_cols = [col for col in df_deam_integrated_essentia_best_overall_opensmile_compare2016.columns if '_x' in col or '_y' in col]\n",
    "\n",
    "# Drop identical columns\n",
    "df_deam_integrated_essentia_best_overall_opensmile_compare2016.drop(columns=identical_cols, inplace=True)\n",
    "\n",
    "df_deam_integrated_essentia_best_overall_opensmile_compare2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_deam_integrated_essentia_best_overall_opensmile_compare2016.to_csv(get_deam_path('processed/features/integrated/essentia_best_overall_opensmile_compare2016_features.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Integrate Essentia best overall features into openSMILE emobase features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_deam_integrated_essentia_best_overall_opensmile_emobase = pd.merge(df_essentia_best_overall_features, df_deam_opensmile_emobase_features, on='song_id', how='inner')\n",
    "\n",
    "# Identify identical columns for dropping\n",
    "identical_cols = [col for col in df_deam_integrated_essentia_best_overall_opensmile_emobase.columns if '_x' in col or '_y' in col]\n",
    "\n",
    "# Drop identical columns\n",
    "df_deam_integrated_essentia_best_overall_opensmile_emobase.drop(columns=identical_cols, inplace=True)\n",
    "\n",
    "df_deam_integrated_essentia_best_overall_opensmile_emobase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_deam_integrated_essentia_best_overall_opensmile_emobase.to_csv(get_deam_path('processed/features/integrated/essentia_best_overall_opensmile_emobase_features.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Integrate Essentia best overall features into openSMILE GeMAPS features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_deam_integrated_essentia_best_overall_opensmile_gemaps = pd.merge(df_essentia_best_overall_features, df_deam_opensmile_gemaps_features, on='song_id', how='inner')\n",
    "\n",
    "# Identify identical columns for dropping\n",
    "identical_cols = [col for col in df_deam_integrated_essentia_best_overall_opensmile_gemaps.columns if '_x' in col or '_y' in col]\n",
    "\n",
    "# Drop identical columns\n",
    "df_deam_integrated_essentia_best_overall_opensmile_gemaps.drop(columns=identical_cols, inplace=True)\n",
    "\n",
    "df_deam_integrated_essentia_best_overall_opensmile_gemaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_deam_integrated_essentia_best_overall_opensmile_gemaps.to_csv(get_deam_path('processed/features/integrated/essentia_best_overall_opensmile_gemaps_features.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Integrate Essentia best overall features into openSMILE eGeMAPS features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_deam_integrated_essentia_best_overall_opensmile_egemaps = pd.merge(df_essentia_best_overall_features, df_deam_opensmile_egemaps_features, on='song_id', how='inner')\n",
    "\n",
    "# Identify identical columns for dropping\n",
    "identical_cols = [col for col in df_deam_integrated_essentia_best_overall_opensmile_egemaps.columns if '_x' in col or '_y' in col]\n",
    "\n",
    "# Drop identical columns\n",
    "df_deam_integrated_essentia_best_overall_opensmile_egemaps.drop(columns=identical_cols, inplace=True)\n",
    "\n",
    "df_deam_integrated_essentia_best_overall_opensmile_egemaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_deam_integrated_essentia_best_overall_opensmile_egemaps.to_csv(get_deam_path('processed/features/integrated/essentia_best_overall_opensmile_egemaps_features.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Standardisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essentia All + openSMILE ComParE2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform the selected columns\n",
    "df_deam_integrated_essentia_all_opensmile_compare2016_standardised = pd.DataFrame(scaler.fit_transform(df_deam_integrated_essentia_all_opensmile_compare2016), columns=df_deam_integrated_essentia_all_opensmile_compare2016.columns)\n",
    "\n",
    "df_deam_integrated_essentia_all_opensmile_compare2016_standardised = df_deam_integrated_essentia_all_opensmile_compare2016_standardised.drop('song_id', axis=1)\n",
    "df_deam_integrated_essentia_all_opensmile_compare2016_standardised.insert(0, column='song_id', value=song_ids)\n",
    "\n",
    "df_deam_integrated_essentia_all_opensmile_compare2016_standardised.to_csv(get_deam_path('processed/features/integrated/standardised_essentia_all_opensmile_compare2016_features.csv'))\n",
    "\n",
    "df_deam_integrated_essentia_all_opensmile_compare2016_standardised"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essentia All + openSMILE emobase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform the selected columns\n",
    "df_deam_integrated_essentia_all_opensmile_emobase_standardised = pd.DataFrame(scaler.fit_transform(df_deam_integrated_essentia_all_opensmile_emobase), columns=df_deam_integrated_essentia_all_opensmile_emobase.columns)\n",
    "\n",
    "df_deam_integrated_essentia_all_opensmile_emobase_standardised = df_deam_integrated_essentia_all_opensmile_emobase_standardised.drop('song_id', axis=1)\n",
    "df_deam_integrated_essentia_all_opensmile_emobase_standardised.insert(0, column='song_id', value=song_ids)\n",
    "\n",
    "df_deam_integrated_essentia_all_opensmile_emobase_standardised.to_csv(get_deam_path('processed/features/integrated/standardised_essentia_all_opensmile_emobase_features.csv'))\n",
    "\n",
    "df_deam_integrated_essentia_all_opensmile_emobase_standardised"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essentia All + openSMILE GeMAPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform the selected columns\n",
    "df_deam_integrated_essentia_all_opensmile_gemaps_standardised = pd.DataFrame(scaler.fit_transform(df_deam_integrated_essentia_all_opensmile_gemaps), columns=df_deam_integrated_essentia_all_opensmile_gemaps.columns)\n",
    "\n",
    "df_deam_integrated_essentia_all_opensmile_gemaps_standardised = df_deam_integrated_essentia_all_opensmile_gemaps_standardised.drop('song_id', axis=1)\n",
    "df_deam_integrated_essentia_all_opensmile_gemaps_standardised.insert(0, column='song_id', value=song_ids)\n",
    "\n",
    "df_deam_integrated_essentia_all_opensmile_gemaps_standardised.to_csv(get_deam_path('processed/features/integrated/standardised_essentia_all_opensmile_gemaps_features.csv'))\n",
    "\n",
    "df_deam_integrated_essentia_all_opensmile_gemaps_standardised"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essentia All + openSMILE eGeMAPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform the selected columns\n",
    "df_deam_integrated_essentia_all_opensmile_egemaps_standardised = pd.DataFrame(scaler.fit_transform(df_deam_integrated_essentia_all_opensmile_egemaps), columns=df_deam_integrated_essentia_all_opensmile_egemaps.columns)\n",
    "\n",
    "df_deam_integrated_essentia_all_opensmile_egemaps_standardised = df_deam_integrated_essentia_all_opensmile_egemaps_standardised.drop('song_id', axis=1)\n",
    "df_deam_integrated_essentia_all_opensmile_egemaps_standardised.insert(0, column='song_id', value=song_ids)\n",
    "\n",
    "df_deam_integrated_essentia_all_opensmile_egemaps_standardised.to_csv(get_deam_path('processed/features/integrated/standardised_essentia_all_opensmile_egemaps_features.csv'))\n",
    "\n",
    "df_deam_integrated_essentia_all_opensmile_egemaps_standardised"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essentia Best Overall + openSMILE ComParE2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform the selected columns\n",
    "df_deam_integrated_essentia_best_overall_opensmile_compare2016_standardised = pd.DataFrame(scaler.fit_transform(df_deam_integrated_essentia_best_overall_opensmile_compare2016), columns=df_deam_integrated_essentia_best_overall_opensmile_compare2016.columns)\n",
    "\n",
    "df_deam_integrated_essentia_best_overall_opensmile_compare2016_standardised = df_deam_integrated_essentia_best_overall_opensmile_compare2016_standardised.drop('song_id', axis=1)\n",
    "df_deam_integrated_essentia_best_overall_opensmile_compare2016_standardised.insert(0, column='song_id', value=song_ids)\n",
    "\n",
    "df_deam_integrated_essentia_best_overall_opensmile_compare2016_standardised.to_csv(get_deam_path('processed/features/integrated/standardised_essentia_best_overall_opensmile_compare2016_features.csv'))\n",
    "\n",
    "df_deam_integrated_essentia_best_overall_opensmile_compare2016_standardised"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essentia Best Overall + openSMILE emobase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform the selected columns\n",
    "df_deam_integrated_essentia_best_overall_opensmile_emobase_standardised = pd.DataFrame(scaler.fit_transform(df_deam_integrated_essentia_best_overall_opensmile_emobase), columns=df_deam_integrated_essentia_best_overall_opensmile_emobase.columns)\n",
    "\n",
    "df_deam_integrated_essentia_best_overall_opensmile_emobase_standardised = df_deam_integrated_essentia_best_overall_opensmile_emobase_standardised.drop('song_id', axis=1)\n",
    "df_deam_integrated_essentia_best_overall_opensmile_emobase_standardised.insert(0, column='song_id', value=song_ids)\n",
    "\n",
    "df_deam_integrated_essentia_best_overall_opensmile_emobase_standardised.to_csv(get_deam_path('processed/features/integrated/standardised_essentia_best_overall_opensmile_emobase_features.csv'))\n",
    "\n",
    "df_deam_integrated_essentia_best_overall_opensmile_emobase_standardised"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essentia Best Overall + openSMILE GeMAPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform the selected columns\n",
    "df_deam_integrated_essentia_best_overall_opensmile_gemaps_standardised = pd.DataFrame(scaler.fit_transform(df_deam_integrated_essentia_best_overall_opensmile_gemaps), columns=df_deam_integrated_essentia_best_overall_opensmile_gemaps.columns)\n",
    "\n",
    "df_deam_integrated_essentia_best_overall_opensmile_gemaps_standardised = df_deam_integrated_essentia_best_overall_opensmile_gemaps_standardised.drop('song_id', axis=1)\n",
    "df_deam_integrated_essentia_best_overall_opensmile_gemaps_standardised.insert(0, column='song_id', value=song_ids)\n",
    "\n",
    "df_deam_integrated_essentia_best_overall_opensmile_gemaps_standardised.to_csv(get_deam_path('processed/features/integrated/standardised_essentia_best_overall_opensmile_gemaps_features.csv'))\n",
    "\n",
    "df_deam_integrated_essentia_best_overall_opensmile_gemaps_standardised"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essentia Best Overall + openSMILE eGeMAPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform the selected columns\n",
    "df_deam_integrated_essentia_best_overall_opensmile_egemaps_standardised = pd.DataFrame(scaler.fit_transform(df_deam_integrated_essentia_best_overall_opensmile_egemaps), columns=df_deam_integrated_essentia_best_overall_opensmile_egemaps.columns)\n",
    "\n",
    "df_deam_integrated_essentia_best_overall_opensmile_egemaps_standardised = df_deam_integrated_essentia_best_overall_opensmile_egemaps_standardised.drop('song_id', axis=1)\n",
    "df_deam_integrated_essentia_best_overall_opensmile_egemaps_standardised.insert(0, column='song_id', value=song_ids)\n",
    "\n",
    "df_deam_integrated_essentia_best_overall_opensmile_egemaps_standardised.to_csv(get_deam_path('processed/features/integrated/standardised_essentia_best_overall_opensmile_egemaps_features.csv'))\n",
    "\n",
    "df_deam_integrated_essentia_best_overall_opensmile_egemaps_standardised"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essentia All + openSMILE ComParE2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform the selected columns\n",
    "df_deam_integrated_essentia_all_opensmile_compare2016_normalised = pd.DataFrame(scaler.fit_transform(df_deam_integrated_essentia_all_opensmile_compare2016), columns=df_deam_integrated_essentia_all_opensmile_compare2016.columns)\n",
    "\n",
    "df_deam_integrated_essentia_all_opensmile_compare2016_normalised = df_deam_integrated_essentia_all_opensmile_compare2016_normalised.drop('song_id', axis=1)\n",
    "df_deam_integrated_essentia_all_opensmile_compare2016_normalised.insert(0, column='song_id', value=song_ids)\n",
    "\n",
    "df_deam_integrated_essentia_all_opensmile_compare2016_normalised.to_csv(get_deam_path('processed/features/integrated/normalised_essentia_all_opensmile_compare2016_features.csv'))\n",
    "\n",
    "df_deam_integrated_essentia_all_opensmile_compare2016_normalised"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essentia All + openSMILE emobase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform the selected columns\n",
    "df_deam_integrated_essentia_all_opensmile_emobase_normalised = pd.DataFrame(scaler.fit_transform(df_deam_integrated_essentia_all_opensmile_emobase), columns=df_deam_integrated_essentia_all_opensmile_emobase.columns)\n",
    "\n",
    "df_deam_integrated_essentia_all_opensmile_emobase_normalised = df_deam_integrated_essentia_all_opensmile_emobase_normalised.drop('song_id', axis=1)\n",
    "df_deam_integrated_essentia_all_opensmile_emobase_normalised.insert(0, column='song_id', value=song_ids)\n",
    "\n",
    "df_deam_integrated_essentia_all_opensmile_emobase_normalised.to_csv(get_deam_path('processed/features/integrated/normalised_essentia_all_opensmile_emobase_features.csv'))\n",
    "\n",
    "df_deam_integrated_essentia_all_opensmile_emobase_normalised"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essentia All + openSMILE GeMAPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform the selected columns\n",
    "df_deam_integrated_essentia_all_opensmile_gemaps_normalised = pd.DataFrame(scaler.fit_transform(df_deam_integrated_essentia_all_opensmile_gemaps), columns=df_deam_integrated_essentia_all_opensmile_gemaps.columns)\n",
    "\n",
    "df_deam_integrated_essentia_all_opensmile_gemaps_normalised = df_deam_integrated_essentia_all_opensmile_gemaps_normalised.drop('song_id', axis=1)\n",
    "df_deam_integrated_essentia_all_opensmile_gemaps_normalised.insert(0, column='song_id', value=song_ids)\n",
    "\n",
    "df_deam_integrated_essentia_all_opensmile_gemaps_normalised.to_csv(get_deam_path('processed/features/integrated/normalised_essentia_all_opensmile_gemaps_features.csv'))\n",
    "\n",
    "df_deam_integrated_essentia_all_opensmile_gemaps_normalised"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essentia All + openSMILE eGeMAPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform the selected columns\n",
    "df_deam_integrated_essentia_all_opensmile_egemaps_normalised = pd.DataFrame(scaler.fit_transform(df_deam_integrated_essentia_all_opensmile_egemaps), columns=df_deam_integrated_essentia_all_opensmile_egemaps.columns)\n",
    "\n",
    "df_deam_integrated_essentia_all_opensmile_egemaps_normalised = df_deam_integrated_essentia_all_opensmile_egemaps_normalised.drop('song_id', axis=1)\n",
    "df_deam_integrated_essentia_all_opensmile_egemaps_normalised.insert(0, column='song_id', value=song_ids)\n",
    "\n",
    "df_deam_integrated_essentia_all_opensmile_egemaps_normalised.to_csv(get_deam_path('processed/features/integrated/normalised_essentia_all_opensmile_egemaps_features.csv'))\n",
    "\n",
    "df_deam_integrated_essentia_all_opensmile_egemaps_normalised"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essentia Best Overall + openSMILE ComParE2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform the selected columns\n",
    "df_deam_integrated_essentia_best_overall_opensmile_compare2016_normalised = pd.DataFrame(scaler.fit_transform(df_deam_integrated_essentia_best_overall_opensmile_compare2016), columns=df_deam_integrated_essentia_best_overall_opensmile_compare2016.columns)\n",
    "\n",
    "df_deam_integrated_essentia_best_overall_opensmile_compare2016_normalised = df_deam_integrated_essentia_best_overall_opensmile_compare2016_normalised.drop('song_id', axis=1)\n",
    "df_deam_integrated_essentia_best_overall_opensmile_compare2016_normalised.insert(0, column='song_id', value=song_ids)\n",
    "\n",
    "df_deam_integrated_essentia_best_overall_opensmile_compare2016_normalised.to_csv(get_deam_path('processed/features/integrated/normalised_essentia_best_overall_opensmile_compare2016_features.csv'))\n",
    "\n",
    "df_deam_integrated_essentia_best_overall_opensmile_compare2016_normalised"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essentia Best Overall + openSMILE emobase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform the selected columns\n",
    "df_deam_integrated_essentia_best_overall_opensmile_emobase_normalised = pd.DataFrame(scaler.fit_transform(df_deam_integrated_essentia_best_overall_opensmile_emobase), columns=df_deam_integrated_essentia_best_overall_opensmile_emobase.columns)\n",
    "\n",
    "df_deam_integrated_essentia_best_overall_opensmile_emobase_normalised = df_deam_integrated_essentia_best_overall_opensmile_emobase_normalised.drop('song_id', axis=1)\n",
    "df_deam_integrated_essentia_best_overall_opensmile_emobase_normalised.insert(0, column='song_id', value=song_ids)\n",
    "\n",
    "df_deam_integrated_essentia_best_overall_opensmile_emobase_normalised.to_csv(get_deam_path('processed/features/integrated/normalised_essentia_best_overall_opensmile_emobase_features.csv'))\n",
    "\n",
    "df_deam_integrated_essentia_best_overall_opensmile_emobase_normalised"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essentia Best Overall + openSMILE GeMAPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform the selected columns\n",
    "df_deam_integrated_essentia_best_overall_opensmile_gemaps_normalised = pd.DataFrame(scaler.fit_transform(df_deam_integrated_essentia_best_overall_opensmile_gemaps), columns=df_deam_integrated_essentia_best_overall_opensmile_gemaps.columns)\n",
    "\n",
    "df_deam_integrated_essentia_best_overall_opensmile_gemaps_normalised = df_deam_integrated_essentia_best_overall_opensmile_gemaps_normalised.drop('song_id', axis=1)\n",
    "df_deam_integrated_essentia_best_overall_opensmile_gemaps_normalised.insert(0, column='song_id', value=song_ids)\n",
    "\n",
    "df_deam_integrated_essentia_best_overall_opensmile_gemaps_normalised.to_csv(get_deam_path('processed/features/integrated/normalised_essentia_best_overall_opensmile_gemaps_features.csv'))\n",
    "\n",
    "df_deam_integrated_essentia_best_overall_opensmile_gemaps_normalised"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essentia Best Overall + openSMILE eGeMAPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform the selected columns\n",
    "df_deam_integrated_essentia_best_overall_opensmile_egemaps_normalised = pd.DataFrame(scaler.fit_transform(df_deam_integrated_essentia_best_overall_opensmile_egemaps), columns=df_deam_integrated_essentia_best_overall_opensmile_egemaps.columns)\n",
    "\n",
    "df_deam_integrated_essentia_best_overall_opensmile_egemaps_normalised = df_deam_integrated_essentia_best_overall_opensmile_egemaps_normalised.drop('song_id', axis=1)\n",
    "df_deam_integrated_essentia_best_overall_opensmile_egemaps_normalised.insert(0, column='song_id', value=song_ids)\n",
    "\n",
    "df_deam_integrated_essentia_best_overall_opensmile_egemaps_normalised.to_csv(get_deam_path('processed/features/integrated/normalised_essentia_best_overall_opensmile_egemaps_features.csv'))\n",
    "\n",
    "df_deam_integrated_essentia_best_overall_opensmile_egemaps_normalised"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter out only the mean features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_essentia_best_overall_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = df_essentia_best_overall_features.columns.to_list()\n",
    "feature_mean_cols = [col for col in col_names if 'dmean' not in col and 'dmean2' not in col and 'dvar' not in col and 'dvar2' not in col and 'max' not in col and 'median' not in col and 'min' not in col and 'stdev' not in col and 'var' not in col]\n",
    "print(feature_mean_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_essentia_best_overall_features_mean = df_essentia_best_overall_features[feature_mean_cols]\n",
    "df_essentia_best_overall_features_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_essentia_best_overall_features_mean.to_csv(get_deam_path('processed/features/essentia_best_overall_features_mean.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform the selected columns\n",
    "df_essentia_best_overall_features_mean_normalised = pd.DataFrame(scaler.fit_transform(df_essentia_best_overall_features_mean), columns=df_essentia_best_overall_features_mean.columns)\n",
    "\n",
    "df_essentia_best_overall_features_mean_normalised = df_essentia_best_overall_features_mean_normalised.drop('song_id', axis=1)\n",
    "df_essentia_best_overall_features_mean_normalised.insert(0, column='song_id', value=song_ids)\n",
    "\n",
    "df_essentia_best_overall_features_mean_normalised.to_csv(get_deam_path('processed/features/normalised_essentia_best_overall_features_mean.csv'))\n",
    "\n",
    "df_essentia_best_overall_features_mean_normalised"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform the selected columns\n",
    "df_essentia_best_overall_features_mean_standardised = pd.DataFrame(scaler.fit_transform(df_essentia_best_overall_features_mean), columns=df_essentia_best_overall_features_mean.columns)\n",
    "\n",
    "df_essentia_best_overall_features_mean_standardised = df_essentia_best_overall_features_mean_standardised.drop('song_id', axis=1)\n",
    "df_essentia_best_overall_features_mean_standardised.insert(0, column='song_id', value=song_ids)\n",
    "\n",
    "df_essentia_best_overall_features_mean_standardised.to_csv(get_deam_path('processed/features/standardised_essentia_best_overall_features_mean.csv'))\n",
    "\n",
    "df_essentia_best_overall_features_mean_standardised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_essentia_best_arousal_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = df_essentia_best_arousal_features.columns.to_list()\n",
    "feature_mean_cols = [col for col in col_names if 'dmean' not in col and 'dmean2' not in col and 'dvar' not in col and 'dvar2' not in col and 'max' not in col and 'median' not in col and 'min' not in col and 'stdev' not in col and 'var' not in col]\n",
    "print(feature_mean_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_essentia_best_arousal_features_mean = df_essentia_best_arousal_features[feature_mean_cols]\n",
    "df_essentia_best_arousal_features_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_essentia_best_arousal_features_mean.to_csv(get_deam_path('processed/features/essentia_best_arousal_features_mean.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform the selected columns\n",
    "df_essentia_best_arousal_features_mean_normalised = pd.DataFrame(scaler.fit_transform(df_essentia_best_arousal_features_mean), columns=df_essentia_best_arousal_features_mean.columns)\n",
    "\n",
    "df_essentia_best_arousal_features_mean_normalised = df_essentia_best_arousal_features_mean_normalised.drop('song_id', axis=1)\n",
    "df_essentia_best_arousal_features_mean_normalised.insert(0, column='song_id', value=song_ids)\n",
    "\n",
    "df_essentia_best_arousal_features_mean_normalised.to_csv(get_deam_path('processed/features/normalised_essentia_best_arousal_features_mean.csv'))\n",
    "\n",
    "df_essentia_best_arousal_features_mean_normalised"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform the selected columns\n",
    "df_essentia_best_arousal_features_mean_standardised = pd.DataFrame(scaler.fit_transform(df_essentia_best_arousal_features_mean), columns=df_essentia_best_arousal_features_mean.columns)\n",
    "\n",
    "df_essentia_best_arousal_features_mean_standardised = df_essentia_best_arousal_features_mean_standardised.drop('song_id', axis=1)\n",
    "df_essentia_best_arousal_features_mean_standardised.insert(0, column='song_id', value=song_ids)\n",
    "\n",
    "df_essentia_best_arousal_features_mean_standardised.to_csv(get_deam_path('processed/features/standardised_essentia_best_arousal_features_mean.csv'))\n",
    "\n",
    "df_essentia_best_arousal_features_mean_standardised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_essentia_best_valence_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = df_essentia_best_valence_features.columns.to_list()\n",
    "feature_mean_cols = [col for col in col_names if 'dmean' not in col and 'dmean2' not in col and 'dvar' not in col and 'dvar2' not in col and 'max' not in col and 'median' not in col and 'min' not in col and 'stdev' not in col and 'var' not in col]\n",
    "print(feature_mean_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_essentia_best_valence_features_mean = df_essentia_best_valence_features[feature_mean_cols]\n",
    "df_essentia_best_valence_features_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_essentia_best_valence_features_mean.to_csv(get_deam_path('processed/features/essentia_best_valence_features_mean.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform the selected columns\n",
    "df_essentia_best_valence_features_mean_normalised = pd.DataFrame(scaler.fit_transform(df_essentia_best_valence_features_mean), columns=df_essentia_best_valence_features_mean.columns)\n",
    "\n",
    "df_essentia_best_valence_features_mean_normalised = df_essentia_best_valence_features_mean_normalised.drop('song_id', axis=1)\n",
    "df_essentia_best_valence_features_mean_normalised.insert(0, column='song_id', value=song_ids)\n",
    "\n",
    "df_essentia_best_valence_features_mean_normalised.to_csv(get_deam_path('processed/features/normalised_essentia_best_valence_features_mean.csv'))\n",
    "\n",
    "df_essentia_best_valence_features_mean_normalised"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform the selected columns\n",
    "df_essentia_best_valence_features_mean_standardised = pd.DataFrame(scaler.fit_transform(df_essentia_best_valence_features_mean), columns=df_essentia_best_valence_features_mean.columns)\n",
    "\n",
    "df_essentia_best_valence_features_mean_standardised = df_essentia_best_valence_features_mean_standardised.drop('song_id', axis=1)\n",
    "df_essentia_best_valence_features_mean_standardised.insert(0, column='song_id', value=song_ids)\n",
    "\n",
    "df_essentia_best_valence_features_mean_standardised.to_csv(get_deam_path('processed/features/standardised_essentia_best_valence_features_mean.csv'))\n",
    "\n",
    "df_essentia_best_valence_features_mean_standardised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
