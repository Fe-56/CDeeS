{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEAM Dataset - Feed Forward Neural Network\n",
    "## Essentia Best All & openSMILE eGeMAPS Featureset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torcheval.metrics import R2Score\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import math\n",
    "\n",
    "import sys\n",
    "sys.path.insert(1, '../../utils')\n",
    "from paths import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import annotations dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song_id</th>\n",
       "      <th>valence_mean_mapped</th>\n",
       "      <th>arousal_mean_mapped</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.475</td>\n",
       "      <td>-0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.375</td>\n",
       "      <td>-0.425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>-0.150</td>\n",
       "      <td>0.075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1739</th>\n",
       "      <td>1996</td>\n",
       "      <td>-0.275</td>\n",
       "      <td>0.225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1740</th>\n",
       "      <td>1997</td>\n",
       "      <td>0.075</td>\n",
       "      <td>-0.275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1741</th>\n",
       "      <td>1998</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1742</th>\n",
       "      <td>1999</td>\n",
       "      <td>-0.100</td>\n",
       "      <td>0.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1743</th>\n",
       "      <td>2000</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1744 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      song_id  valence_mean_mapped  arousal_mean_mapped\n",
       "0           2               -0.475               -0.500\n",
       "1           3               -0.375               -0.425\n",
       "2           4                0.175                0.125\n",
       "3           5               -0.150                0.075\n",
       "4           7                0.200                0.350\n",
       "...       ...                  ...                  ...\n",
       "1739     1996               -0.275                0.225\n",
       "1740     1997                0.075               -0.275\n",
       "1741     1998                0.350                0.300\n",
       "1742     1999               -0.100                0.100\n",
       "1743     2000                0.200                0.250\n",
       "\n",
       "[1744 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_annotations = pd.read_csv(get_deam_path('processed/annotations/deam_static_annotations.csv'))\n",
    "df_annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the featureset\n",
    "\n",
    "This is where you should change between normalised and standardised, and untouched featuresets!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song_id</th>\n",
       "      <th>lowlevel.average_loudness</th>\n",
       "      <th>lowlevel.barkbands_crest.dmean</th>\n",
       "      <th>lowlevel.barkbands_crest.dmean2</th>\n",
       "      <th>lowlevel.barkbands_crest.dvar</th>\n",
       "      <th>lowlevel.barkbands_crest.dvar2</th>\n",
       "      <th>lowlevel.barkbands_crest.max</th>\n",
       "      <th>lowlevel.barkbands_crest.mean</th>\n",
       "      <th>lowlevel.barkbands_crest.median</th>\n",
       "      <th>lowlevel.barkbands_crest.min</th>\n",
       "      <th>...</th>\n",
       "      <th>slopeUV0-500_sma3nz_amean</th>\n",
       "      <th>slopeUV500-1500_sma3nz_amean</th>\n",
       "      <th>spectralFluxUV_sma3nz_amean</th>\n",
       "      <th>loudnessPeaksPerSec</th>\n",
       "      <th>VoicedSegmentsPerSec</th>\n",
       "      <th>MeanVoicedSegmentLengthSec</th>\n",
       "      <th>StddevVoicedSegmentLengthSec</th>\n",
       "      <th>MeanUnvoicedSegmentLength</th>\n",
       "      <th>StddevUnvoicedSegmentLength</th>\n",
       "      <th>equivalentSoundLevel_dBp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.972741</td>\n",
       "      <td>0.322732</td>\n",
       "      <td>0.345839</td>\n",
       "      <td>0.104501</td>\n",
       "      <td>0.145450</td>\n",
       "      <td>0.704285</td>\n",
       "      <td>0.376120</td>\n",
       "      <td>0.313025</td>\n",
       "      <td>0.154835</td>\n",
       "      <td>...</td>\n",
       "      <td>0.351559</td>\n",
       "      <td>0.600638</td>\n",
       "      <td>0.181705</td>\n",
       "      <td>0.264131</td>\n",
       "      <td>0.049256</td>\n",
       "      <td>0.069750</td>\n",
       "      <td>0.164484</td>\n",
       "      <td>0.027513</td>\n",
       "      <td>0.014235</td>\n",
       "      <td>0.594429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0.583679</td>\n",
       "      <td>0.205943</td>\n",
       "      <td>0.227717</td>\n",
       "      <td>0.096043</td>\n",
       "      <td>0.121328</td>\n",
       "      <td>0.970572</td>\n",
       "      <td>0.702144</td>\n",
       "      <td>0.582300</td>\n",
       "      <td>0.362288</td>\n",
       "      <td>...</td>\n",
       "      <td>0.126664</td>\n",
       "      <td>0.581319</td>\n",
       "      <td>0.212856</td>\n",
       "      <td>0.206415</td>\n",
       "      <td>0.329843</td>\n",
       "      <td>0.008219</td>\n",
       "      <td>0.024446</td>\n",
       "      <td>0.077423</td>\n",
       "      <td>0.056789</td>\n",
       "      <td>0.639348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0.990960</td>\n",
       "      <td>0.375110</td>\n",
       "      <td>0.387854</td>\n",
       "      <td>0.150212</td>\n",
       "      <td>0.190855</td>\n",
       "      <td>0.658252</td>\n",
       "      <td>0.336314</td>\n",
       "      <td>0.283905</td>\n",
       "      <td>0.164182</td>\n",
       "      <td>...</td>\n",
       "      <td>0.273067</td>\n",
       "      <td>0.606355</td>\n",
       "      <td>0.358312</td>\n",
       "      <td>0.349895</td>\n",
       "      <td>0.314678</td>\n",
       "      <td>0.009789</td>\n",
       "      <td>0.018589</td>\n",
       "      <td>0.040617</td>\n",
       "      <td>0.018047</td>\n",
       "      <td>0.741370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>0.914417</td>\n",
       "      <td>0.356523</td>\n",
       "      <td>0.363551</td>\n",
       "      <td>0.122697</td>\n",
       "      <td>0.149895</td>\n",
       "      <td>0.858083</td>\n",
       "      <td>0.392704</td>\n",
       "      <td>0.305499</td>\n",
       "      <td>0.277203</td>\n",
       "      <td>...</td>\n",
       "      <td>0.573717</td>\n",
       "      <td>0.384170</td>\n",
       "      <td>0.228007</td>\n",
       "      <td>0.256759</td>\n",
       "      <td>0.041739</td>\n",
       "      <td>0.081478</td>\n",
       "      <td>0.149317</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.018206</td>\n",
       "      <td>0.682132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>0.991187</td>\n",
       "      <td>0.256914</td>\n",
       "      <td>0.255848</td>\n",
       "      <td>0.139336</td>\n",
       "      <td>0.149169</td>\n",
       "      <td>0.824768</td>\n",
       "      <td>0.660008</td>\n",
       "      <td>0.574646</td>\n",
       "      <td>0.183156</td>\n",
       "      <td>...</td>\n",
       "      <td>0.264243</td>\n",
       "      <td>0.575046</td>\n",
       "      <td>0.362308</td>\n",
       "      <td>0.520714</td>\n",
       "      <td>0.060622</td>\n",
       "      <td>0.057195</td>\n",
       "      <td>0.142060</td>\n",
       "      <td>0.030864</td>\n",
       "      <td>0.021297</td>\n",
       "      <td>0.819566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1739</th>\n",
       "      <td>1996</td>\n",
       "      <td>0.996544</td>\n",
       "      <td>0.532901</td>\n",
       "      <td>0.553871</td>\n",
       "      <td>0.245012</td>\n",
       "      <td>0.263674</td>\n",
       "      <td>0.717103</td>\n",
       "      <td>0.318415</td>\n",
       "      <td>0.236341</td>\n",
       "      <td>0.243114</td>\n",
       "      <td>...</td>\n",
       "      <td>0.407510</td>\n",
       "      <td>0.426452</td>\n",
       "      <td>0.245619</td>\n",
       "      <td>0.619651</td>\n",
       "      <td>0.170727</td>\n",
       "      <td>0.020034</td>\n",
       "      <td>0.048555</td>\n",
       "      <td>0.024143</td>\n",
       "      <td>0.009844</td>\n",
       "      <td>0.640006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1740</th>\n",
       "      <td>1997</td>\n",
       "      <td>0.998184</td>\n",
       "      <td>0.351222</td>\n",
       "      <td>0.382376</td>\n",
       "      <td>0.123357</td>\n",
       "      <td>0.160645</td>\n",
       "      <td>0.605959</td>\n",
       "      <td>0.307426</td>\n",
       "      <td>0.253574</td>\n",
       "      <td>0.218863</td>\n",
       "      <td>...</td>\n",
       "      <td>0.409826</td>\n",
       "      <td>0.439188</td>\n",
       "      <td>0.155033</td>\n",
       "      <td>0.513858</td>\n",
       "      <td>0.144237</td>\n",
       "      <td>0.023835</td>\n",
       "      <td>0.051010</td>\n",
       "      <td>0.032222</td>\n",
       "      <td>0.021974</td>\n",
       "      <td>0.516482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1741</th>\n",
       "      <td>1998</td>\n",
       "      <td>0.911413</td>\n",
       "      <td>0.423552</td>\n",
       "      <td>0.429467</td>\n",
       "      <td>0.174821</td>\n",
       "      <td>0.189958</td>\n",
       "      <td>0.795025</td>\n",
       "      <td>0.269332</td>\n",
       "      <td>0.218253</td>\n",
       "      <td>0.095981</td>\n",
       "      <td>...</td>\n",
       "      <td>0.321734</td>\n",
       "      <td>0.510924</td>\n",
       "      <td>0.180579</td>\n",
       "      <td>0.506302</td>\n",
       "      <td>0.497215</td>\n",
       "      <td>0.005271</td>\n",
       "      <td>0.021518</td>\n",
       "      <td>0.045299</td>\n",
       "      <td>0.023471</td>\n",
       "      <td>0.599258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1742</th>\n",
       "      <td>1999</td>\n",
       "      <td>0.974887</td>\n",
       "      <td>0.395791</td>\n",
       "      <td>0.436942</td>\n",
       "      <td>0.118189</td>\n",
       "      <td>0.156440</td>\n",
       "      <td>0.638507</td>\n",
       "      <td>0.285916</td>\n",
       "      <td>0.238424</td>\n",
       "      <td>0.279791</td>\n",
       "      <td>...</td>\n",
       "      <td>0.384083</td>\n",
       "      <td>0.506933</td>\n",
       "      <td>0.183881</td>\n",
       "      <td>0.370283</td>\n",
       "      <td>0.413529</td>\n",
       "      <td>0.007011</td>\n",
       "      <td>0.014129</td>\n",
       "      <td>0.038426</td>\n",
       "      <td>0.021311</td>\n",
       "      <td>0.557897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1743</th>\n",
       "      <td>2000</td>\n",
       "      <td>0.965636</td>\n",
       "      <td>0.417235</td>\n",
       "      <td>0.449227</td>\n",
       "      <td>0.162883</td>\n",
       "      <td>0.205566</td>\n",
       "      <td>0.840740</td>\n",
       "      <td>0.292641</td>\n",
       "      <td>0.246279</td>\n",
       "      <td>0.197996</td>\n",
       "      <td>...</td>\n",
       "      <td>0.332454</td>\n",
       "      <td>0.604519</td>\n",
       "      <td>0.181125</td>\n",
       "      <td>0.501264</td>\n",
       "      <td>0.493198</td>\n",
       "      <td>0.004996</td>\n",
       "      <td>0.014090</td>\n",
       "      <td>0.055489</td>\n",
       "      <td>0.032671</td>\n",
       "      <td>0.600906</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1744 rows × 4602 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      song_id  lowlevel.average_loudness  lowlevel.barkbands_crest.dmean  \\\n",
       "0           2                   0.972741                        0.322732   \n",
       "1           3                   0.583679                        0.205943   \n",
       "2           4                   0.990960                        0.375110   \n",
       "3           5                   0.914417                        0.356523   \n",
       "4           7                   0.991187                        0.256914   \n",
       "...       ...                        ...                             ...   \n",
       "1739     1996                   0.996544                        0.532901   \n",
       "1740     1997                   0.998184                        0.351222   \n",
       "1741     1998                   0.911413                        0.423552   \n",
       "1742     1999                   0.974887                        0.395791   \n",
       "1743     2000                   0.965636                        0.417235   \n",
       "\n",
       "      lowlevel.barkbands_crest.dmean2  lowlevel.barkbands_crest.dvar  \\\n",
       "0                            0.345839                       0.104501   \n",
       "1                            0.227717                       0.096043   \n",
       "2                            0.387854                       0.150212   \n",
       "3                            0.363551                       0.122697   \n",
       "4                            0.255848                       0.139336   \n",
       "...                               ...                            ...   \n",
       "1739                         0.553871                       0.245012   \n",
       "1740                         0.382376                       0.123357   \n",
       "1741                         0.429467                       0.174821   \n",
       "1742                         0.436942                       0.118189   \n",
       "1743                         0.449227                       0.162883   \n",
       "\n",
       "      lowlevel.barkbands_crest.dvar2  lowlevel.barkbands_crest.max  \\\n",
       "0                           0.145450                      0.704285   \n",
       "1                           0.121328                      0.970572   \n",
       "2                           0.190855                      0.658252   \n",
       "3                           0.149895                      0.858083   \n",
       "4                           0.149169                      0.824768   \n",
       "...                              ...                           ...   \n",
       "1739                        0.263674                      0.717103   \n",
       "1740                        0.160645                      0.605959   \n",
       "1741                        0.189958                      0.795025   \n",
       "1742                        0.156440                      0.638507   \n",
       "1743                        0.205566                      0.840740   \n",
       "\n",
       "      lowlevel.barkbands_crest.mean  lowlevel.barkbands_crest.median  \\\n",
       "0                          0.376120                         0.313025   \n",
       "1                          0.702144                         0.582300   \n",
       "2                          0.336314                         0.283905   \n",
       "3                          0.392704                         0.305499   \n",
       "4                          0.660008                         0.574646   \n",
       "...                             ...                              ...   \n",
       "1739                       0.318415                         0.236341   \n",
       "1740                       0.307426                         0.253574   \n",
       "1741                       0.269332                         0.218253   \n",
       "1742                       0.285916                         0.238424   \n",
       "1743                       0.292641                         0.246279   \n",
       "\n",
       "      lowlevel.barkbands_crest.min  ...  slopeUV0-500_sma3nz_amean  \\\n",
       "0                         0.154835  ...                   0.351559   \n",
       "1                         0.362288  ...                   0.126664   \n",
       "2                         0.164182  ...                   0.273067   \n",
       "3                         0.277203  ...                   0.573717   \n",
       "4                         0.183156  ...                   0.264243   \n",
       "...                            ...  ...                        ...   \n",
       "1739                      0.243114  ...                   0.407510   \n",
       "1740                      0.218863  ...                   0.409826   \n",
       "1741                      0.095981  ...                   0.321734   \n",
       "1742                      0.279791  ...                   0.384083   \n",
       "1743                      0.197996  ...                   0.332454   \n",
       "\n",
       "      slopeUV500-1500_sma3nz_amean  spectralFluxUV_sma3nz_amean  \\\n",
       "0                         0.600638                     0.181705   \n",
       "1                         0.581319                     0.212856   \n",
       "2                         0.606355                     0.358312   \n",
       "3                         0.384170                     0.228007   \n",
       "4                         0.575046                     0.362308   \n",
       "...                            ...                          ...   \n",
       "1739                      0.426452                     0.245619   \n",
       "1740                      0.439188                     0.155033   \n",
       "1741                      0.510924                     0.180579   \n",
       "1742                      0.506933                     0.183881   \n",
       "1743                      0.604519                     0.181125   \n",
       "\n",
       "      loudnessPeaksPerSec  VoicedSegmentsPerSec  MeanVoicedSegmentLengthSec  \\\n",
       "0                0.264131              0.049256                    0.069750   \n",
       "1                0.206415              0.329843                    0.008219   \n",
       "2                0.349895              0.314678                    0.009789   \n",
       "3                0.256759              0.041739                    0.081478   \n",
       "4                0.520714              0.060622                    0.057195   \n",
       "...                   ...                   ...                         ...   \n",
       "1739             0.619651              0.170727                    0.020034   \n",
       "1740             0.513858              0.144237                    0.023835   \n",
       "1741             0.506302              0.497215                    0.005271   \n",
       "1742             0.370283              0.413529                    0.007011   \n",
       "1743             0.501264              0.493198                    0.004996   \n",
       "\n",
       "      StddevVoicedSegmentLengthSec  MeanUnvoicedSegmentLength  \\\n",
       "0                         0.164484                   0.027513   \n",
       "1                         0.024446                   0.077423   \n",
       "2                         0.018589                   0.040617   \n",
       "3                         0.149317                   0.028571   \n",
       "4                         0.142060                   0.030864   \n",
       "...                            ...                        ...   \n",
       "1739                      0.048555                   0.024143   \n",
       "1740                      0.051010                   0.032222   \n",
       "1741                      0.021518                   0.045299   \n",
       "1742                      0.014129                   0.038426   \n",
       "1743                      0.014090                   0.055489   \n",
       "\n",
       "      StddevUnvoicedSegmentLength  equivalentSoundLevel_dBp  \n",
       "0                        0.014235                  0.594429  \n",
       "1                        0.056789                  0.639348  \n",
       "2                        0.018047                  0.741370  \n",
       "3                        0.018206                  0.682132  \n",
       "4                        0.021297                  0.819566  \n",
       "...                           ...                       ...  \n",
       "1739                     0.009844                  0.640006  \n",
       "1740                     0.021974                  0.516482  \n",
       "1741                     0.023471                  0.599258  \n",
       "1742                     0.021311                  0.557897  \n",
       "1743                     0.032671                  0.600906  \n",
       "\n",
       "[1744 rows x 4602 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_essentia_all_opensmile_egemaps_features = pd.read_csv(get_deam_path('processed/features/integrated/normalised_essentia_all_opensmile_egemaps_features.csv'))\n",
    "\n",
    "# drop Unnamed:0 column\n",
    "df_essentia_all_opensmile_egemaps_features = df_essentia_all_opensmile_egemaps_features[df_essentia_all_opensmile_egemaps_features.columns[1:]]\n",
    "\n",
    "df_essentia_all_opensmile_egemaps_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1744 entries, 0 to 1743\n",
      "Data columns (total 4602 columns):\n",
      " #     Column                                           Dtype  \n",
      "---    ------                                           -----  \n",
      " 0     song_id                                          int64  \n",
      " 1     lowlevel.average_loudness                        float64\n",
      " 2     lowlevel.barkbands_crest.dmean                   float64\n",
      " 3     lowlevel.barkbands_crest.dmean2                  float64\n",
      " 4     lowlevel.barkbands_crest.dvar                    float64\n",
      " 5     lowlevel.barkbands_crest.dvar2                   float64\n",
      " 6     lowlevel.barkbands_crest.max                     float64\n",
      " 7     lowlevel.barkbands_crest.mean                    float64\n",
      " 8     lowlevel.barkbands_crest.median                  float64\n",
      " 9     lowlevel.barkbands_crest.min                     float64\n",
      " 10    lowlevel.barkbands_crest.stdev                   float64\n",
      " 11    lowlevel.barkbands_crest.var                     float64\n",
      " 12    lowlevel.barkbands_flatness_db.dmean             float64\n",
      " 13    lowlevel.barkbands_flatness_db.dmean2            float64\n",
      " 14    lowlevel.barkbands_flatness_db.dvar              float64\n",
      " 15    lowlevel.barkbands_flatness_db.dvar2             float64\n",
      " 16    lowlevel.barkbands_flatness_db.max               float64\n",
      " 17    lowlevel.barkbands_flatness_db.mean              float64\n",
      " 18    lowlevel.barkbands_flatness_db.median            float64\n",
      " 19    lowlevel.barkbands_flatness_db.min               float64\n",
      " 20    lowlevel.barkbands_flatness_db.stdev             float64\n",
      " 21    lowlevel.barkbands_flatness_db.var               float64\n",
      " 22    lowlevel.barkbands_kurtosis.dmean                float64\n",
      " 23    lowlevel.barkbands_kurtosis.dmean2               float64\n",
      " 24    lowlevel.barkbands_kurtosis.dvar                 float64\n",
      " 25    lowlevel.barkbands_kurtosis.dvar2                float64\n",
      " 26    lowlevel.barkbands_kurtosis.max                  float64\n",
      " 27    lowlevel.barkbands_kurtosis.mean                 float64\n",
      " 28    lowlevel.barkbands_kurtosis.median               float64\n",
      " 29    lowlevel.barkbands_kurtosis.min                  float64\n",
      " 30    lowlevel.barkbands_kurtosis.stdev                float64\n",
      " 31    lowlevel.barkbands_kurtosis.var                  float64\n",
      " 32    lowlevel.barkbands_skewness.dmean                float64\n",
      " 33    lowlevel.barkbands_skewness.dmean2               float64\n",
      " 34    lowlevel.barkbands_skewness.dvar                 float64\n",
      " 35    lowlevel.barkbands_skewness.dvar2                float64\n",
      " 36    lowlevel.barkbands_skewness.max                  float64\n",
      " 37    lowlevel.barkbands_skewness.mean                 float64\n",
      " 38    lowlevel.barkbands_skewness.median               float64\n",
      " 39    lowlevel.barkbands_skewness.min                  float64\n",
      " 40    lowlevel.barkbands_skewness.stdev                float64\n",
      " 41    lowlevel.barkbands_skewness.var                  float64\n",
      " 42    lowlevel.barkbands_spread.dmean                  float64\n",
      " 43    lowlevel.barkbands_spread.dmean2                 float64\n",
      " 44    lowlevel.barkbands_spread.dvar                   float64\n",
      " 45    lowlevel.barkbands_spread.dvar2                  float64\n",
      " 46    lowlevel.barkbands_spread.max                    float64\n",
      " 47    lowlevel.barkbands_spread.mean                   float64\n",
      " 48    lowlevel.barkbands_spread.median                 float64\n",
      " 49    lowlevel.barkbands_spread.min                    float64\n",
      " 50    lowlevel.barkbands_spread.stdev                  float64\n",
      " 51    lowlevel.barkbands_spread.var                    float64\n",
      " 52    lowlevel.dissonance.dmean                        float64\n",
      " 53    lowlevel.dissonance.dmean2                       float64\n",
      " 54    lowlevel.dissonance.dvar                         float64\n",
      " 55    lowlevel.dissonance.dvar2                        float64\n",
      " 56    lowlevel.dissonance.max                          float64\n",
      " 57    lowlevel.dissonance.mean                         float64\n",
      " 58    lowlevel.dissonance.median                       float64\n",
      " 59    lowlevel.dissonance.min                          float64\n",
      " 60    lowlevel.dissonance.stdev                        float64\n",
      " 61    lowlevel.dissonance.var                          float64\n",
      " 62    lowlevel.dynamic_complexity                      float64\n",
      " 63    lowlevel.erbbands_crest.dmean                    float64\n",
      " 64    lowlevel.erbbands_crest.dmean2                   float64\n",
      " 65    lowlevel.erbbands_crest.dvar                     float64\n",
      " 66    lowlevel.erbbands_crest.dvar2                    float64\n",
      " 67    lowlevel.erbbands_crest.max                      float64\n",
      " 68    lowlevel.erbbands_crest.mean                     float64\n",
      " 69    lowlevel.erbbands_crest.median                   float64\n",
      " 70    lowlevel.erbbands_crest.min                      float64\n",
      " 71    lowlevel.erbbands_crest.stdev                    float64\n",
      " 72    lowlevel.erbbands_crest.var                      float64\n",
      " 73    lowlevel.erbbands_flatness_db.dmean              float64\n",
      " 74    lowlevel.erbbands_flatness_db.dmean2             float64\n",
      " 75    lowlevel.erbbands_flatness_db.dvar               float64\n",
      " 76    lowlevel.erbbands_flatness_db.dvar2              float64\n",
      " 77    lowlevel.erbbands_flatness_db.max                float64\n",
      " 78    lowlevel.erbbands_flatness_db.mean               float64\n",
      " 79    lowlevel.erbbands_flatness_db.median             float64\n",
      " 80    lowlevel.erbbands_flatness_db.min                float64\n",
      " 81    lowlevel.erbbands_flatness_db.stdev              float64\n",
      " 82    lowlevel.erbbands_flatness_db.var                float64\n",
      " 83    lowlevel.erbbands_kurtosis.dmean                 float64\n",
      " 84    lowlevel.erbbands_kurtosis.dmean2                float64\n",
      " 85    lowlevel.erbbands_kurtosis.dvar                  float64\n",
      " 86    lowlevel.erbbands_kurtosis.dvar2                 float64\n",
      " 87    lowlevel.erbbands_kurtosis.max                   float64\n",
      " 88    lowlevel.erbbands_kurtosis.mean                  float64\n",
      " 89    lowlevel.erbbands_kurtosis.median                float64\n",
      " 90    lowlevel.erbbands_kurtosis.min                   float64\n",
      " 91    lowlevel.erbbands_kurtosis.stdev                 float64\n",
      " 92    lowlevel.erbbands_kurtosis.var                   float64\n",
      " 93    lowlevel.erbbands_skewness.dmean                 float64\n",
      " 94    lowlevel.erbbands_skewness.dmean2                float64\n",
      " 95    lowlevel.erbbands_skewness.dvar                  float64\n",
      " 96    lowlevel.erbbands_skewness.dvar2                 float64\n",
      " 97    lowlevel.erbbands_skewness.max                   float64\n",
      " 98    lowlevel.erbbands_skewness.mean                  float64\n",
      " 99    lowlevel.erbbands_skewness.median                float64\n",
      " 100   lowlevel.erbbands_skewness.min                   float64\n",
      " 101   lowlevel.erbbands_skewness.stdev                 float64\n",
      " 102   lowlevel.erbbands_skewness.var                   float64\n",
      " 103   lowlevel.erbbands_spread.dmean                   float64\n",
      " 104   lowlevel.erbbands_spread.dmean2                  float64\n",
      " 105   lowlevel.erbbands_spread.dvar                    float64\n",
      " 106   lowlevel.erbbands_spread.dvar2                   float64\n",
      " 107   lowlevel.erbbands_spread.max                     float64\n",
      " 108   lowlevel.erbbands_spread.mean                    float64\n",
      " 109   lowlevel.erbbands_spread.median                  float64\n",
      " 110   lowlevel.erbbands_spread.min                     float64\n",
      " 111   lowlevel.erbbands_spread.stdev                   float64\n",
      " 112   lowlevel.erbbands_spread.var                     float64\n",
      " 113   lowlevel.hfc.dmean                               float64\n",
      " 114   lowlevel.hfc.dmean2                              float64\n",
      " 115   lowlevel.hfc.dvar                                float64\n",
      " 116   lowlevel.hfc.dvar2                               float64\n",
      " 117   lowlevel.hfc.max                                 float64\n",
      " 118   lowlevel.hfc.mean                                float64\n",
      " 119   lowlevel.hfc.median                              float64\n",
      " 120   lowlevel.hfc.min                                 float64\n",
      " 121   lowlevel.hfc.stdev                               float64\n",
      " 122   lowlevel.hfc.var                                 float64\n",
      " 123   lowlevel.loudness_ebu128.integrated              float64\n",
      " 124   lowlevel.loudness_ebu128.loudness_range          float64\n",
      " 125   lowlevel.loudness_ebu128.momentary.dmean         float64\n",
      " 126   lowlevel.loudness_ebu128.momentary.dmean2        float64\n",
      " 127   lowlevel.loudness_ebu128.momentary.dvar          float64\n",
      " 128   lowlevel.loudness_ebu128.momentary.dvar2         float64\n",
      " 129   lowlevel.loudness_ebu128.momentary.max           float64\n",
      " 130   lowlevel.loudness_ebu128.momentary.mean          float64\n",
      " 131   lowlevel.loudness_ebu128.momentary.median        float64\n",
      " 132   lowlevel.loudness_ebu128.momentary.min           float64\n",
      " 133   lowlevel.loudness_ebu128.momentary.stdev         float64\n",
      " 134   lowlevel.loudness_ebu128.momentary.var           float64\n",
      " 135   lowlevel.loudness_ebu128.short_term.dmean        float64\n",
      " 136   lowlevel.loudness_ebu128.short_term.dmean2       float64\n",
      " 137   lowlevel.loudness_ebu128.short_term.dvar         float64\n",
      " 138   lowlevel.loudness_ebu128.short_term.dvar2        float64\n",
      " 139   lowlevel.loudness_ebu128.short_term.max          float64\n",
      " 140   lowlevel.loudness_ebu128.short_term.mean         float64\n",
      " 141   lowlevel.loudness_ebu128.short_term.median       float64\n",
      " 142   lowlevel.loudness_ebu128.short_term.min          float64\n",
      " 143   lowlevel.loudness_ebu128.short_term.stdev        float64\n",
      " 144   lowlevel.loudness_ebu128.short_term.var          float64\n",
      " 145   lowlevel.melbands_crest.dmean                    float64\n",
      " 146   lowlevel.melbands_crest.dmean2                   float64\n",
      " 147   lowlevel.melbands_crest.dvar                     float64\n",
      " 148   lowlevel.melbands_crest.dvar2                    float64\n",
      " 149   lowlevel.melbands_crest.max                      float64\n",
      " 150   lowlevel.melbands_crest.mean                     float64\n",
      " 151   lowlevel.melbands_crest.median                   float64\n",
      " 152   lowlevel.melbands_crest.min                      float64\n",
      " 153   lowlevel.melbands_crest.stdev                    float64\n",
      " 154   lowlevel.melbands_crest.var                      float64\n",
      " 155   lowlevel.melbands_flatness_db.dmean              float64\n",
      " 156   lowlevel.melbands_flatness_db.dmean2             float64\n",
      " 157   lowlevel.melbands_flatness_db.dvar               float64\n",
      " 158   lowlevel.melbands_flatness_db.dvar2              float64\n",
      " 159   lowlevel.melbands_flatness_db.max                float64\n",
      " 160   lowlevel.melbands_flatness_db.mean               float64\n",
      " 161   lowlevel.melbands_flatness_db.median             float64\n",
      " 162   lowlevel.melbands_flatness_db.min                float64\n",
      " 163   lowlevel.melbands_flatness_db.stdev              float64\n",
      " 164   lowlevel.melbands_flatness_db.var                float64\n",
      " 165   lowlevel.melbands_kurtosis.dmean                 float64\n",
      " 166   lowlevel.melbands_kurtosis.dmean2                float64\n",
      " 167   lowlevel.melbands_kurtosis.dvar                  float64\n",
      " 168   lowlevel.melbands_kurtosis.dvar2                 float64\n",
      " 169   lowlevel.melbands_kurtosis.max                   float64\n",
      " 170   lowlevel.melbands_kurtosis.mean                  float64\n",
      " 171   lowlevel.melbands_kurtosis.median                float64\n",
      " 172   lowlevel.melbands_kurtosis.min                   float64\n",
      " 173   lowlevel.melbands_kurtosis.stdev                 float64\n",
      " 174   lowlevel.melbands_kurtosis.var                   float64\n",
      " 175   lowlevel.melbands_skewness.dmean                 float64\n",
      " 176   lowlevel.melbands_skewness.dmean2                float64\n",
      " 177   lowlevel.melbands_skewness.dvar                  float64\n",
      " 178   lowlevel.melbands_skewness.dvar2                 float64\n",
      " 179   lowlevel.melbands_skewness.max                   float64\n",
      " 180   lowlevel.melbands_skewness.mean                  float64\n",
      " 181   lowlevel.melbands_skewness.median                float64\n",
      " 182   lowlevel.melbands_skewness.min                   float64\n",
      " 183   lowlevel.melbands_skewness.stdev                 float64\n",
      " 184   lowlevel.melbands_skewness.var                   float64\n",
      " 185   lowlevel.melbands_spread.dmean                   float64\n",
      " 186   lowlevel.melbands_spread.dmean2                  float64\n",
      " 187   lowlevel.melbands_spread.dvar                    float64\n",
      " 188   lowlevel.melbands_spread.dvar2                   float64\n",
      " 189   lowlevel.melbands_spread.max                     float64\n",
      " 190   lowlevel.melbands_spread.mean                    float64\n",
      " 191   lowlevel.melbands_spread.median                  float64\n",
      " 192   lowlevel.melbands_spread.min                     float64\n",
      " 193   lowlevel.melbands_spread.stdev                   float64\n",
      " 194   lowlevel.melbands_spread.var                     float64\n",
      " 195   lowlevel.pitch_salience.dmean                    float64\n",
      " 196   lowlevel.pitch_salience.dmean2                   float64\n",
      " 197   lowlevel.pitch_salience.dvar                     float64\n",
      " 198   lowlevel.pitch_salience.dvar2                    float64\n",
      " 199   lowlevel.pitch_salience.max                      float64\n",
      " 200   lowlevel.pitch_salience.mean                     float64\n",
      " 201   lowlevel.pitch_salience.median                   float64\n",
      " 202   lowlevel.pitch_salience.min                      float64\n",
      " 203   lowlevel.pitch_salience.stdev                    float64\n",
      " 204   lowlevel.pitch_salience.var                      float64\n",
      " 205   lowlevel.silence_rate_20dB.dmean                 float64\n",
      " 206   lowlevel.silence_rate_20dB.dmean2                float64\n",
      " 207   lowlevel.silence_rate_20dB.dvar                  float64\n",
      " 208   lowlevel.silence_rate_20dB.dvar2                 float64\n",
      " 209   lowlevel.silence_rate_20dB.max                   float64\n",
      " 210   lowlevel.silence_rate_20dB.mean                  float64\n",
      " 211   lowlevel.silence_rate_20dB.median                float64\n",
      " 212   lowlevel.silence_rate_20dB.min                   float64\n",
      " 213   lowlevel.silence_rate_20dB.stdev                 float64\n",
      " 214   lowlevel.silence_rate_20dB.var                   float64\n",
      " 215   lowlevel.silence_rate_30dB.dmean                 float64\n",
      " 216   lowlevel.silence_rate_30dB.dmean2                float64\n",
      " 217   lowlevel.silence_rate_30dB.dvar                  float64\n",
      " 218   lowlevel.silence_rate_30dB.dvar2                 float64\n",
      " 219   lowlevel.silence_rate_30dB.max                   float64\n",
      " 220   lowlevel.silence_rate_30dB.mean                  float64\n",
      " 221   lowlevel.silence_rate_30dB.median                float64\n",
      " 222   lowlevel.silence_rate_30dB.min                   float64\n",
      " 223   lowlevel.silence_rate_30dB.stdev                 float64\n",
      " 224   lowlevel.silence_rate_30dB.var                   float64\n",
      " 225   lowlevel.silence_rate_60dB.dmean                 float64\n",
      " 226   lowlevel.silence_rate_60dB.dmean2                float64\n",
      " 227   lowlevel.silence_rate_60dB.dvar                  float64\n",
      " 228   lowlevel.silence_rate_60dB.dvar2                 float64\n",
      " 229   lowlevel.silence_rate_60dB.max                   float64\n",
      " 230   lowlevel.silence_rate_60dB.mean                  float64\n",
      " 231   lowlevel.silence_rate_60dB.median                float64\n",
      " 232   lowlevel.silence_rate_60dB.min                   float64\n",
      " 233   lowlevel.silence_rate_60dB.stdev                 float64\n",
      " 234   lowlevel.silence_rate_60dB.var                   float64\n",
      " 235   lowlevel.spectral_centroid.dmean                 float64\n",
      " 236   lowlevel.spectral_centroid.dmean2                float64\n",
      " 237   lowlevel.spectral_centroid.dvar                  float64\n",
      " 238   lowlevel.spectral_centroid.dvar2                 float64\n",
      " 239   lowlevel.spectral_centroid.max                   float64\n",
      " 240   lowlevel.spectral_centroid.mean                  float64\n",
      " 241   lowlevel.spectral_centroid.median                float64\n",
      " 242   lowlevel.spectral_centroid.min                   float64\n",
      " 243   lowlevel.spectral_centroid.stdev                 float64\n",
      " 244   lowlevel.spectral_centroid.var                   float64\n",
      " 245   lowlevel.spectral_complexity.dmean               float64\n",
      " 246   lowlevel.spectral_complexity.dmean2              float64\n",
      " 247   lowlevel.spectral_complexity.dvar                float64\n",
      " 248   lowlevel.spectral_complexity.dvar2               float64\n",
      " 249   lowlevel.spectral_complexity.max                 float64\n",
      " 250   lowlevel.spectral_complexity.mean                float64\n",
      " 251   lowlevel.spectral_complexity.median              float64\n",
      " 252   lowlevel.spectral_complexity.min                 float64\n",
      " 253   lowlevel.spectral_complexity.stdev               float64\n",
      " 254   lowlevel.spectral_complexity.var                 float64\n",
      " 255   lowlevel.spectral_decrease.dmean                 float64\n",
      " 256   lowlevel.spectral_decrease.dmean2                float64\n",
      " 257   lowlevel.spectral_decrease.dvar                  float64\n",
      " 258   lowlevel.spectral_decrease.dvar2                 float64\n",
      " 259   lowlevel.spectral_decrease.max                   float64\n",
      " 260   lowlevel.spectral_decrease.mean                  float64\n",
      " 261   lowlevel.spectral_decrease.median                float64\n",
      " 262   lowlevel.spectral_decrease.min                   float64\n",
      " 263   lowlevel.spectral_decrease.stdev                 float64\n",
      " 264   lowlevel.spectral_decrease.var                   float64\n",
      " 265   lowlevel.spectral_energy.dmean                   float64\n",
      " 266   lowlevel.spectral_energy.dmean2                  float64\n",
      " 267   lowlevel.spectral_energy.dvar                    float64\n",
      " 268   lowlevel.spectral_energy.dvar2                   float64\n",
      " 269   lowlevel.spectral_energy.max                     float64\n",
      " 270   lowlevel.spectral_energy.mean                    float64\n",
      " 271   lowlevel.spectral_energy.median                  float64\n",
      " 272   lowlevel.spectral_energy.min                     float64\n",
      " 273   lowlevel.spectral_energy.stdev                   float64\n",
      " 274   lowlevel.spectral_energy.var                     float64\n",
      " 275   lowlevel.spectral_energyband_high.dmean          float64\n",
      " 276   lowlevel.spectral_energyband_high.dmean2         float64\n",
      " 277   lowlevel.spectral_energyband_high.dvar           float64\n",
      " 278   lowlevel.spectral_energyband_high.dvar2          float64\n",
      " 279   lowlevel.spectral_energyband_high.max            float64\n",
      " 280   lowlevel.spectral_energyband_high.mean           float64\n",
      " 281   lowlevel.spectral_energyband_high.median         float64\n",
      " 282   lowlevel.spectral_energyband_high.min            float64\n",
      " 283   lowlevel.spectral_energyband_high.stdev          float64\n",
      " 284   lowlevel.spectral_energyband_high.var            float64\n",
      " 285   lowlevel.spectral_energyband_low.dmean           float64\n",
      " 286   lowlevel.spectral_energyband_low.dmean2          float64\n",
      " 287   lowlevel.spectral_energyband_low.dvar            float64\n",
      " 288   lowlevel.spectral_energyband_low.dvar2           float64\n",
      " 289   lowlevel.spectral_energyband_low.max             float64\n",
      " 290   lowlevel.spectral_energyband_low.mean            float64\n",
      " 291   lowlevel.spectral_energyband_low.median          float64\n",
      " 292   lowlevel.spectral_energyband_low.min             float64\n",
      " 293   lowlevel.spectral_energyband_low.stdev           float64\n",
      " 294   lowlevel.spectral_energyband_low.var             float64\n",
      " 295   lowlevel.spectral_energyband_middle_high.dmean   float64\n",
      " 296   lowlevel.spectral_energyband_middle_high.dmean2  float64\n",
      " 297   lowlevel.spectral_energyband_middle_high.dvar    float64\n",
      " 298   lowlevel.spectral_energyband_middle_high.dvar2   float64\n",
      " 299   lowlevel.spectral_energyband_middle_high.max     float64\n",
      " 300   lowlevel.spectral_energyband_middle_high.mean    float64\n",
      " 301   lowlevel.spectral_energyband_middle_high.median  float64\n",
      " 302   lowlevel.spectral_energyband_middle_high.min     float64\n",
      " 303   lowlevel.spectral_energyband_middle_high.stdev   float64\n",
      " 304   lowlevel.spectral_energyband_middle_high.var     float64\n",
      " 305   lowlevel.spectral_energyband_middle_low.dmean    float64\n",
      " 306   lowlevel.spectral_energyband_middle_low.dmean2   float64\n",
      " 307   lowlevel.spectral_energyband_middle_low.dvar     float64\n",
      " 308   lowlevel.spectral_energyband_middle_low.dvar2    float64\n",
      " 309   lowlevel.spectral_energyband_middle_low.max      float64\n",
      " 310   lowlevel.spectral_energyband_middle_low.mean     float64\n",
      " 311   lowlevel.spectral_energyband_middle_low.median   float64\n",
      " 312   lowlevel.spectral_energyband_middle_low.min      float64\n",
      " 313   lowlevel.spectral_energyband_middle_low.stdev    float64\n",
      " 314   lowlevel.spectral_energyband_middle_low.var      float64\n",
      " 315   lowlevel.spectral_entropy.dmean                  float64\n",
      " 316   lowlevel.spectral_entropy.dmean2                 float64\n",
      " 317   lowlevel.spectral_entropy.dvar                   float64\n",
      " 318   lowlevel.spectral_entropy.dvar2                  float64\n",
      " 319   lowlevel.spectral_entropy.max                    float64\n",
      " 320   lowlevel.spectral_entropy.mean                   float64\n",
      " 321   lowlevel.spectral_entropy.median                 float64\n",
      " 322   lowlevel.spectral_entropy.min                    float64\n",
      " 323   lowlevel.spectral_entropy.stdev                  float64\n",
      " 324   lowlevel.spectral_entropy.var                    float64\n",
      " 325   lowlevel.spectral_flux.dmean                     float64\n",
      " 326   lowlevel.spectral_flux.dmean2                    float64\n",
      " 327   lowlevel.spectral_flux.dvar                      float64\n",
      " 328   lowlevel.spectral_flux.dvar2                     float64\n",
      " 329   lowlevel.spectral_flux.max                       float64\n",
      " 330   lowlevel.spectral_flux.mean                      float64\n",
      " 331   lowlevel.spectral_flux.median                    float64\n",
      " 332   lowlevel.spectral_flux.min                       float64\n",
      " 333   lowlevel.spectral_flux.stdev                     float64\n",
      " 334   lowlevel.spectral_flux.var                       float64\n",
      " 335   lowlevel.spectral_kurtosis.dmean                 float64\n",
      " 336   lowlevel.spectral_kurtosis.dmean2                float64\n",
      " 337   lowlevel.spectral_kurtosis.dvar                  float64\n",
      " 338   lowlevel.spectral_kurtosis.dvar2                 float64\n",
      " 339   lowlevel.spectral_kurtosis.max                   float64\n",
      " 340   lowlevel.spectral_kurtosis.mean                  float64\n",
      " 341   lowlevel.spectral_kurtosis.median                float64\n",
      " 342   lowlevel.spectral_kurtosis.min                   float64\n",
      " 343   lowlevel.spectral_kurtosis.stdev                 float64\n",
      " 344   lowlevel.spectral_kurtosis.var                   float64\n",
      " 345   lowlevel.spectral_rms.dmean                      float64\n",
      " 346   lowlevel.spectral_rms.dmean2                     float64\n",
      " 347   lowlevel.spectral_rms.dvar                       float64\n",
      " 348   lowlevel.spectral_rms.dvar2                      float64\n",
      " 349   lowlevel.spectral_rms.max                        float64\n",
      " 350   lowlevel.spectral_rms.mean                       float64\n",
      " 351   lowlevel.spectral_rms.median                     float64\n",
      " 352   lowlevel.spectral_rms.min                        float64\n",
      " 353   lowlevel.spectral_rms.stdev                      float64\n",
      " 354   lowlevel.spectral_rms.var                        float64\n",
      " 355   lowlevel.spectral_rolloff.dmean                  float64\n",
      " 356   lowlevel.spectral_rolloff.dmean2                 float64\n",
      " 357   lowlevel.spectral_rolloff.dvar                   float64\n",
      " 358   lowlevel.spectral_rolloff.dvar2                  float64\n",
      " 359   lowlevel.spectral_rolloff.max                    float64\n",
      " 360   lowlevel.spectral_rolloff.mean                   float64\n",
      " 361   lowlevel.spectral_rolloff.median                 float64\n",
      " 362   lowlevel.spectral_rolloff.min                    float64\n",
      " 363   lowlevel.spectral_rolloff.stdev                  float64\n",
      " 364   lowlevel.spectral_rolloff.var                    float64\n",
      " 365   lowlevel.spectral_skewness.dmean                 float64\n",
      " 366   lowlevel.spectral_skewness.dmean2                float64\n",
      " 367   lowlevel.spectral_skewness.dvar                  float64\n",
      " 368   lowlevel.spectral_skewness.dvar2                 float64\n",
      " 369   lowlevel.spectral_skewness.max                   float64\n",
      " 370   lowlevel.spectral_skewness.mean                  float64\n",
      " 371   lowlevel.spectral_skewness.median                float64\n",
      " 372   lowlevel.spectral_skewness.min                   float64\n",
      " 373   lowlevel.spectral_skewness.stdev                 float64\n",
      " 374   lowlevel.spectral_skewness.var                   float64\n",
      " 375   lowlevel.spectral_spread.dmean                   float64\n",
      " 376   lowlevel.spectral_spread.dmean2                  float64\n",
      " 377   lowlevel.spectral_spread.dvar                    float64\n",
      " 378   lowlevel.spectral_spread.dvar2                   float64\n",
      " 379   lowlevel.spectral_spread.max                     float64\n",
      " 380   lowlevel.spectral_spread.mean                    float64\n",
      " 381   lowlevel.spectral_spread.median                  float64\n",
      " 382   lowlevel.spectral_spread.min                     float64\n",
      " 383   lowlevel.spectral_spread.stdev                   float64\n",
      " 384   lowlevel.spectral_spread.var                     float64\n",
      " 385   lowlevel.spectral_strongpeak.dmean               float64\n",
      " 386   lowlevel.spectral_strongpeak.dmean2              float64\n",
      " 387   lowlevel.spectral_strongpeak.dvar                float64\n",
      " 388   lowlevel.spectral_strongpeak.dvar2               float64\n",
      " 389   lowlevel.spectral_strongpeak.max                 float64\n",
      " 390   lowlevel.spectral_strongpeak.mean                float64\n",
      " 391   lowlevel.spectral_strongpeak.median              float64\n",
      " 392   lowlevel.spectral_strongpeak.min                 float64\n",
      " 393   lowlevel.spectral_strongpeak.stdev               float64\n",
      " 394   lowlevel.spectral_strongpeak.var                 float64\n",
      " 395   lowlevel.zerocrossingrate.dmean                  float64\n",
      " 396   lowlevel.zerocrossingrate.dmean2                 float64\n",
      " 397   lowlevel.zerocrossingrate.dvar                   float64\n",
      " 398   lowlevel.zerocrossingrate.dvar2                  float64\n",
      " 399   lowlevel.zerocrossingrate.max                    float64\n",
      " 400   lowlevel.zerocrossingrate.mean                   float64\n",
      " 401   lowlevel.zerocrossingrate.median                 float64\n",
      " 402   lowlevel.zerocrossingrate.min                    float64\n",
      " 403   lowlevel.zerocrossingrate.stdev                  float64\n",
      " 404   lowlevel.zerocrossingrate.var                    float64\n",
      " 405   rhythm.beats_count                               float64\n",
      " 406   rhythm.beats_loudness.dmean                      float64\n",
      " 407   rhythm.beats_loudness.dmean2                     float64\n",
      " 408   rhythm.beats_loudness.dvar                       float64\n",
      " 409   rhythm.beats_loudness.dvar2                      float64\n",
      " 410   rhythm.beats_loudness.max                        float64\n",
      " 411   rhythm.beats_loudness.mean                       float64\n",
      " 412   rhythm.beats_loudness.median                     float64\n",
      " 413   rhythm.beats_loudness.min                        float64\n",
      " 414   rhythm.beats_loudness.stdev                      float64\n",
      " 415   rhythm.beats_loudness.var                        float64\n",
      " 416   rhythm.bpm                                       float64\n",
      " 417   rhythm.bpm_histogram_first_peak_bpm              float64\n",
      " 418   rhythm.bpm_histogram_first_peak_weight           float64\n",
      " 419   rhythm.bpm_histogram_second_peak_bpm             float64\n",
      " 420   rhythm.bpm_histogram_second_peak_spread          float64\n",
      " 421   rhythm.bpm_histogram_second_peak_weight          float64\n",
      " 422   rhythm.danceability                              float64\n",
      " 423   rhythm.onset_rate                                float64\n",
      " 424   tonal.chords_changes_rate                        float64\n",
      " 425   tonal.chords_number_rate                         float64\n",
      " 426   tonal.chords_strength.dmean                      float64\n",
      " 427   tonal.chords_strength.dmean2                     float64\n",
      " 428   tonal.chords_strength.dvar                       float64\n",
      " 429   tonal.chords_strength.dvar2                      float64\n",
      " 430   tonal.chords_strength.max                        float64\n",
      " 431   tonal.chords_strength.mean                       float64\n",
      " 432   tonal.chords_strength.median                     float64\n",
      " 433   tonal.chords_strength.min                        float64\n",
      " 434   tonal.chords_strength.stdev                      float64\n",
      " 435   tonal.chords_strength.var                        float64\n",
      " 436   tonal.hpcp_crest.dmean                           float64\n",
      " 437   tonal.hpcp_crest.dmean2                          float64\n",
      " 438   tonal.hpcp_crest.dvar                            float64\n",
      " 439   tonal.hpcp_crest.dvar2                           float64\n",
      " 440   tonal.hpcp_crest.max                             float64\n",
      " 441   tonal.hpcp_crest.mean                            float64\n",
      " 442   tonal.hpcp_crest.median                          float64\n",
      " 443   tonal.hpcp_crest.min                             float64\n",
      " 444   tonal.hpcp_crest.stdev                           float64\n",
      " 445   tonal.hpcp_crest.var                             float64\n",
      " 446   tonal.hpcp_entropy.dmean                         float64\n",
      " 447   tonal.hpcp_entropy.dmean2                        float64\n",
      " 448   tonal.hpcp_entropy.dvar                          float64\n",
      " 449   tonal.hpcp_entropy.dvar2                         float64\n",
      " 450   tonal.hpcp_entropy.max                           float64\n",
      " 451   tonal.hpcp_entropy.mean                          float64\n",
      " 452   tonal.hpcp_entropy.median                        float64\n",
      " 453   tonal.hpcp_entropy.min                           float64\n",
      " 454   tonal.hpcp_entropy.stdev                         float64\n",
      " 455   tonal.hpcp_entropy.var                           float64\n",
      " 456   tonal.key_edma.strength                          float64\n",
      " 457   tonal.key_krumhansl.strength                     float64\n",
      " 458   tonal.key_temperley.strength                     float64\n",
      " 459   tonal.tuning_diatonic_strength                   float64\n",
      " 460   tonal.tuning_equal_tempered_deviation            float64\n",
      " 461   tonal.tuning_frequency                           float64\n",
      " 462   tonal.tuning_nontempered_energy_ratio            float64\n",
      " 463   lowlevel.barkbands.dmean_0                       float64\n",
      " 464   lowlevel.barkbands.dmean_1                       float64\n",
      " 465   lowlevel.barkbands.dmean_2                       float64\n",
      " 466   lowlevel.barkbands.dmean_3                       float64\n",
      " 467   lowlevel.barkbands.dmean_4                       float64\n",
      " 468   lowlevel.barkbands.dmean_5                       float64\n",
      " 469   lowlevel.barkbands.dmean_6                       float64\n",
      " 470   lowlevel.barkbands.dmean_7                       float64\n",
      " 471   lowlevel.barkbands.dmean_8                       float64\n",
      " 472   lowlevel.barkbands.dmean_9                       float64\n",
      " 473   lowlevel.barkbands.dmean_10                      float64\n",
      " 474   lowlevel.barkbands.dmean_11                      float64\n",
      " 475   lowlevel.barkbands.dmean_12                      float64\n",
      " 476   lowlevel.barkbands.dmean_13                      float64\n",
      " 477   lowlevel.barkbands.dmean_14                      float64\n",
      " 478   lowlevel.barkbands.dmean_15                      float64\n",
      " 479   lowlevel.barkbands.dmean_16                      float64\n",
      " 480   lowlevel.barkbands.dmean_17                      float64\n",
      " 481   lowlevel.barkbands.dmean_18                      float64\n",
      " 482   lowlevel.barkbands.dmean_19                      float64\n",
      " 483   lowlevel.barkbands.dmean_20                      float64\n",
      " 484   lowlevel.barkbands.dmean_21                      float64\n",
      " 485   lowlevel.barkbands.dmean_22                      float64\n",
      " 486   lowlevel.barkbands.dmean_23                      float64\n",
      " 487   lowlevel.barkbands.dmean_24                      float64\n",
      " 488   lowlevel.barkbands.dmean_25                      float64\n",
      " 489   lowlevel.barkbands.dmean_26                      float64\n",
      " 490   lowlevel.barkbands.dmean2_0                      float64\n",
      " 491   lowlevel.barkbands.dmean2_1                      float64\n",
      " 492   lowlevel.barkbands.dmean2_2                      float64\n",
      " 493   lowlevel.barkbands.dmean2_3                      float64\n",
      " 494   lowlevel.barkbands.dmean2_4                      float64\n",
      " 495   lowlevel.barkbands.dmean2_5                      float64\n",
      " 496   lowlevel.barkbands.dmean2_6                      float64\n",
      " 497   lowlevel.barkbands.dmean2_7                      float64\n",
      " 498   lowlevel.barkbands.dmean2_8                      float64\n",
      " 499   lowlevel.barkbands.dmean2_9                      float64\n",
      " 500   lowlevel.barkbands.dmean2_10                     float64\n",
      " 501   lowlevel.barkbands.dmean2_11                     float64\n",
      " 502   lowlevel.barkbands.dmean2_12                     float64\n",
      " 503   lowlevel.barkbands.dmean2_13                     float64\n",
      " 504   lowlevel.barkbands.dmean2_14                     float64\n",
      " 505   lowlevel.barkbands.dmean2_15                     float64\n",
      " 506   lowlevel.barkbands.dmean2_16                     float64\n",
      " 507   lowlevel.barkbands.dmean2_17                     float64\n",
      " 508   lowlevel.barkbands.dmean2_18                     float64\n",
      " 509   lowlevel.barkbands.dmean2_19                     float64\n",
      " 510   lowlevel.barkbands.dmean2_20                     float64\n",
      " 511   lowlevel.barkbands.dmean2_21                     float64\n",
      " 512   lowlevel.barkbands.dmean2_22                     float64\n",
      " 513   lowlevel.barkbands.dmean2_23                     float64\n",
      " 514   lowlevel.barkbands.dmean2_24                     float64\n",
      " 515   lowlevel.barkbands.dmean2_25                     float64\n",
      " 516   lowlevel.barkbands.dmean2_26                     float64\n",
      " 517   lowlevel.barkbands.dvar_0                        float64\n",
      " 518   lowlevel.barkbands.dvar_1                        float64\n",
      " 519   lowlevel.barkbands.dvar_2                        float64\n",
      " 520   lowlevel.barkbands.dvar_3                        float64\n",
      " 521   lowlevel.barkbands.dvar_4                        float64\n",
      " 522   lowlevel.barkbands.dvar_5                        float64\n",
      " 523   lowlevel.barkbands.dvar_6                        float64\n",
      " 524   lowlevel.barkbands.dvar_7                        float64\n",
      " 525   lowlevel.barkbands.dvar_8                        float64\n",
      " 526   lowlevel.barkbands.dvar_9                        float64\n",
      " 527   lowlevel.barkbands.dvar_10                       float64\n",
      " 528   lowlevel.barkbands.dvar_11                       float64\n",
      " 529   lowlevel.barkbands.dvar_12                       float64\n",
      " 530   lowlevel.barkbands.dvar_13                       float64\n",
      " 531   lowlevel.barkbands.dvar_14                       float64\n",
      " 532   lowlevel.barkbands.dvar_15                       float64\n",
      " 533   lowlevel.barkbands.dvar_16                       float64\n",
      " 534   lowlevel.barkbands.dvar_17                       float64\n",
      " 535   lowlevel.barkbands.dvar_18                       float64\n",
      " 536   lowlevel.barkbands.dvar_19                       float64\n",
      " 537   lowlevel.barkbands.dvar_20                       float64\n",
      " 538   lowlevel.barkbands.dvar_21                       float64\n",
      " 539   lowlevel.barkbands.dvar_22                       float64\n",
      " 540   lowlevel.barkbands.dvar_23                       float64\n",
      " 541   lowlevel.barkbands.dvar_24                       float64\n",
      " 542   lowlevel.barkbands.dvar_25                       float64\n",
      " 543   lowlevel.barkbands.dvar_26                       float64\n",
      " 544   lowlevel.barkbands.dvar2_0                       float64\n",
      " 545   lowlevel.barkbands.dvar2_1                       float64\n",
      " 546   lowlevel.barkbands.dvar2_2                       float64\n",
      " 547   lowlevel.barkbands.dvar2_3                       float64\n",
      " 548   lowlevel.barkbands.dvar2_4                       float64\n",
      " 549   lowlevel.barkbands.dvar2_5                       float64\n",
      " 550   lowlevel.barkbands.dvar2_6                       float64\n",
      " 551   lowlevel.barkbands.dvar2_7                       float64\n",
      " 552   lowlevel.barkbands.dvar2_8                       float64\n",
      " 553   lowlevel.barkbands.dvar2_9                       float64\n",
      " 554   lowlevel.barkbands.dvar2_10                      float64\n",
      " 555   lowlevel.barkbands.dvar2_11                      float64\n",
      " 556   lowlevel.barkbands.dvar2_12                      float64\n",
      " 557   lowlevel.barkbands.dvar2_13                      float64\n",
      " 558   lowlevel.barkbands.dvar2_14                      float64\n",
      " 559   lowlevel.barkbands.dvar2_15                      float64\n",
      " 560   lowlevel.barkbands.dvar2_16                      float64\n",
      " 561   lowlevel.barkbands.dvar2_17                      float64\n",
      " 562   lowlevel.barkbands.dvar2_18                      float64\n",
      " 563   lowlevel.barkbands.dvar2_19                      float64\n",
      " 564   lowlevel.barkbands.dvar2_20                      float64\n",
      " 565   lowlevel.barkbands.dvar2_21                      float64\n",
      " 566   lowlevel.barkbands.dvar2_22                      float64\n",
      " 567   lowlevel.barkbands.dvar2_23                      float64\n",
      " 568   lowlevel.barkbands.dvar2_24                      float64\n",
      " 569   lowlevel.barkbands.dvar2_25                      float64\n",
      " 570   lowlevel.barkbands.dvar2_26                      float64\n",
      " 571   lowlevel.barkbands.max_0                         float64\n",
      " 572   lowlevel.barkbands.max_1                         float64\n",
      " 573   lowlevel.barkbands.max_2                         float64\n",
      " 574   lowlevel.barkbands.max_3                         float64\n",
      " 575   lowlevel.barkbands.max_4                         float64\n",
      " 576   lowlevel.barkbands.max_5                         float64\n",
      " 577   lowlevel.barkbands.max_6                         float64\n",
      " 578   lowlevel.barkbands.max_7                         float64\n",
      " 579   lowlevel.barkbands.max_8                         float64\n",
      " 580   lowlevel.barkbands.max_9                         float64\n",
      " 581   lowlevel.barkbands.max_10                        float64\n",
      " 582   lowlevel.barkbands.max_11                        float64\n",
      " 583   lowlevel.barkbands.max_12                        float64\n",
      " 584   lowlevel.barkbands.max_13                        float64\n",
      " 585   lowlevel.barkbands.max_14                        float64\n",
      " 586   lowlevel.barkbands.max_15                        float64\n",
      " 587   lowlevel.barkbands.max_16                        float64\n",
      " 588   lowlevel.barkbands.max_17                        float64\n",
      " 589   lowlevel.barkbands.max_18                        float64\n",
      " 590   lowlevel.barkbands.max_19                        float64\n",
      " 591   lowlevel.barkbands.max_20                        float64\n",
      " 592   lowlevel.barkbands.max_21                        float64\n",
      " 593   lowlevel.barkbands.max_22                        float64\n",
      " 594   lowlevel.barkbands.max_23                        float64\n",
      " 595   lowlevel.barkbands.max_24                        float64\n",
      " 596   lowlevel.barkbands.max_25                        float64\n",
      " 597   lowlevel.barkbands.max_26                        float64\n",
      " 598   lowlevel.barkbands.mean_0                        float64\n",
      " 599   lowlevel.barkbands.mean_1                        float64\n",
      " 600   lowlevel.barkbands.mean_2                        float64\n",
      " 601   lowlevel.barkbands.mean_3                        float64\n",
      " 602   lowlevel.barkbands.mean_4                        float64\n",
      " 603   lowlevel.barkbands.mean_5                        float64\n",
      " 604   lowlevel.barkbands.mean_6                        float64\n",
      " 605   lowlevel.barkbands.mean_7                        float64\n",
      " 606   lowlevel.barkbands.mean_8                        float64\n",
      " 607   lowlevel.barkbands.mean_9                        float64\n",
      " 608   lowlevel.barkbands.mean_10                       float64\n",
      " 609   lowlevel.barkbands.mean_11                       float64\n",
      " 610   lowlevel.barkbands.mean_12                       float64\n",
      " 611   lowlevel.barkbands.mean_13                       float64\n",
      " 612   lowlevel.barkbands.mean_14                       float64\n",
      " 613   lowlevel.barkbands.mean_15                       float64\n",
      " 614   lowlevel.barkbands.mean_16                       float64\n",
      " 615   lowlevel.barkbands.mean_17                       float64\n",
      " 616   lowlevel.barkbands.mean_18                       float64\n",
      " 617   lowlevel.barkbands.mean_19                       float64\n",
      " 618   lowlevel.barkbands.mean_20                       float64\n",
      " 619   lowlevel.barkbands.mean_21                       float64\n",
      " 620   lowlevel.barkbands.mean_22                       float64\n",
      " 621   lowlevel.barkbands.mean_23                       float64\n",
      " 622   lowlevel.barkbands.mean_24                       float64\n",
      " 623   lowlevel.barkbands.mean_25                       float64\n",
      " 624   lowlevel.barkbands.mean_26                       float64\n",
      " 625   lowlevel.barkbands.median_0                      float64\n",
      " 626   lowlevel.barkbands.median_1                      float64\n",
      " 627   lowlevel.barkbands.median_2                      float64\n",
      " 628   lowlevel.barkbands.median_3                      float64\n",
      " 629   lowlevel.barkbands.median_4                      float64\n",
      " 630   lowlevel.barkbands.median_5                      float64\n",
      " 631   lowlevel.barkbands.median_6                      float64\n",
      " 632   lowlevel.barkbands.median_7                      float64\n",
      " 633   lowlevel.barkbands.median_8                      float64\n",
      " 634   lowlevel.barkbands.median_9                      float64\n",
      " 635   lowlevel.barkbands.median_10                     float64\n",
      " 636   lowlevel.barkbands.median_11                     float64\n",
      " 637   lowlevel.barkbands.median_12                     float64\n",
      " 638   lowlevel.barkbands.median_13                     float64\n",
      " 639   lowlevel.barkbands.median_14                     float64\n",
      " 640   lowlevel.barkbands.median_15                     float64\n",
      " 641   lowlevel.barkbands.median_16                     float64\n",
      " 642   lowlevel.barkbands.median_17                     float64\n",
      " 643   lowlevel.barkbands.median_18                     float64\n",
      " 644   lowlevel.barkbands.median_19                     float64\n",
      " 645   lowlevel.barkbands.median_20                     float64\n",
      " 646   lowlevel.barkbands.median_21                     float64\n",
      " 647   lowlevel.barkbands.median_22                     float64\n",
      " 648   lowlevel.barkbands.median_23                     float64\n",
      " 649   lowlevel.barkbands.median_24                     float64\n",
      " 650   lowlevel.barkbands.median_25                     float64\n",
      " 651   lowlevel.barkbands.median_26                     float64\n",
      " 652   lowlevel.barkbands.min_0                         float64\n",
      " 653   lowlevel.barkbands.min_1                         float64\n",
      " 654   lowlevel.barkbands.min_2                         float64\n",
      " 655   lowlevel.barkbands.min_3                         float64\n",
      " 656   lowlevel.barkbands.min_4                         float64\n",
      " 657   lowlevel.barkbands.min_5                         float64\n",
      " 658   lowlevel.barkbands.min_6                         float64\n",
      " 659   lowlevel.barkbands.min_7                         float64\n",
      " 660   lowlevel.barkbands.min_8                         float64\n",
      " 661   lowlevel.barkbands.min_9                         float64\n",
      " 662   lowlevel.barkbands.min_10                        float64\n",
      " 663   lowlevel.barkbands.min_11                        float64\n",
      " 664   lowlevel.barkbands.min_12                        float64\n",
      " 665   lowlevel.barkbands.min_13                        float64\n",
      " 666   lowlevel.barkbands.min_14                        float64\n",
      " 667   lowlevel.barkbands.min_15                        float64\n",
      " 668   lowlevel.barkbands.min_16                        float64\n",
      " 669   lowlevel.barkbands.min_17                        float64\n",
      " 670   lowlevel.barkbands.min_18                        float64\n",
      " 671   lowlevel.barkbands.min_19                        float64\n",
      " 672   lowlevel.barkbands.min_20                        float64\n",
      " 673   lowlevel.barkbands.min_21                        float64\n",
      " 674   lowlevel.barkbands.min_22                        float64\n",
      " 675   lowlevel.barkbands.min_23                        float64\n",
      " 676   lowlevel.barkbands.min_24                        float64\n",
      " 677   lowlevel.barkbands.min_25                        float64\n",
      " 678   lowlevel.barkbands.min_26                        float64\n",
      " 679   lowlevel.barkbands.stdev_0                       float64\n",
      " 680   lowlevel.barkbands.stdev_1                       float64\n",
      " 681   lowlevel.barkbands.stdev_2                       float64\n",
      " 682   lowlevel.barkbands.stdev_3                       float64\n",
      " 683   lowlevel.barkbands.stdev_4                       float64\n",
      " 684   lowlevel.barkbands.stdev_5                       float64\n",
      " 685   lowlevel.barkbands.stdev_6                       float64\n",
      " 686   lowlevel.barkbands.stdev_7                       float64\n",
      " 687   lowlevel.barkbands.stdev_8                       float64\n",
      " 688   lowlevel.barkbands.stdev_9                       float64\n",
      " 689   lowlevel.barkbands.stdev_10                      float64\n",
      " 690   lowlevel.barkbands.stdev_11                      float64\n",
      " 691   lowlevel.barkbands.stdev_12                      float64\n",
      " 692   lowlevel.barkbands.stdev_13                      float64\n",
      " 693   lowlevel.barkbands.stdev_14                      float64\n",
      " 694   lowlevel.barkbands.stdev_15                      float64\n",
      " 695   lowlevel.barkbands.stdev_16                      float64\n",
      " 696   lowlevel.barkbands.stdev_17                      float64\n",
      " 697   lowlevel.barkbands.stdev_18                      float64\n",
      " 698   lowlevel.barkbands.stdev_19                      float64\n",
      " 699   lowlevel.barkbands.stdev_20                      float64\n",
      " 700   lowlevel.barkbands.stdev_21                      float64\n",
      " 701   lowlevel.barkbands.stdev_22                      float64\n",
      " 702   lowlevel.barkbands.stdev_23                      float64\n",
      " 703   lowlevel.barkbands.stdev_24                      float64\n",
      " 704   lowlevel.barkbands.stdev_25                      float64\n",
      " 705   lowlevel.barkbands.stdev_26                      float64\n",
      " 706   lowlevel.barkbands.var_0                         float64\n",
      " 707   lowlevel.barkbands.var_1                         float64\n",
      " 708   lowlevel.barkbands.var_2                         float64\n",
      " 709   lowlevel.barkbands.var_3                         float64\n",
      " 710   lowlevel.barkbands.var_4                         float64\n",
      " 711   lowlevel.barkbands.var_5                         float64\n",
      " 712   lowlevel.barkbands.var_6                         float64\n",
      " 713   lowlevel.barkbands.var_7                         float64\n",
      " 714   lowlevel.barkbands.var_8                         float64\n",
      " 715   lowlevel.barkbands.var_9                         float64\n",
      " 716   lowlevel.barkbands.var_10                        float64\n",
      " 717   lowlevel.barkbands.var_11                        float64\n",
      " 718   lowlevel.barkbands.var_12                        float64\n",
      " 719   lowlevel.barkbands.var_13                        float64\n",
      " 720   lowlevel.barkbands.var_14                        float64\n",
      " 721   lowlevel.barkbands.var_15                        float64\n",
      " 722   lowlevel.barkbands.var_16                        float64\n",
      " 723   lowlevel.barkbands.var_17                        float64\n",
      " 724   lowlevel.barkbands.var_18                        float64\n",
      " 725   lowlevel.barkbands.var_19                        float64\n",
      " 726   lowlevel.barkbands.var_20                        float64\n",
      " 727   lowlevel.barkbands.var_21                        float64\n",
      " 728   lowlevel.barkbands.var_22                        float64\n",
      " 729   lowlevel.barkbands.var_23                        float64\n",
      " 730   lowlevel.barkbands.var_24                        float64\n",
      " 731   lowlevel.barkbands.var_25                        float64\n",
      " 732   lowlevel.barkbands.var_26                        float64\n",
      " 733   lowlevel.erbbands.dmean_0                        float64\n",
      " 734   lowlevel.erbbands.dmean_1                        float64\n",
      " 735   lowlevel.erbbands.dmean_2                        float64\n",
      " 736   lowlevel.erbbands.dmean_3                        float64\n",
      " 737   lowlevel.erbbands.dmean_4                        float64\n",
      " 738   lowlevel.erbbands.dmean_5                        float64\n",
      " 739   lowlevel.erbbands.dmean_6                        float64\n",
      " 740   lowlevel.erbbands.dmean_7                        float64\n",
      " 741   lowlevel.erbbands.dmean_8                        float64\n",
      " 742   lowlevel.erbbands.dmean_9                        float64\n",
      " 743   lowlevel.erbbands.dmean_10                       float64\n",
      " 744   lowlevel.erbbands.dmean_11                       float64\n",
      " 745   lowlevel.erbbands.dmean_12                       float64\n",
      " 746   lowlevel.erbbands.dmean_13                       float64\n",
      " 747   lowlevel.erbbands.dmean_14                       float64\n",
      " 748   lowlevel.erbbands.dmean_15                       float64\n",
      " 749   lowlevel.erbbands.dmean_16                       float64\n",
      " 750   lowlevel.erbbands.dmean_17                       float64\n",
      " 751   lowlevel.erbbands.dmean_18                       float64\n",
      " 752   lowlevel.erbbands.dmean_19                       float64\n",
      " 753   lowlevel.erbbands.dmean_20                       float64\n",
      " 754   lowlevel.erbbands.dmean_21                       float64\n",
      " 755   lowlevel.erbbands.dmean_22                       float64\n",
      " 756   lowlevel.erbbands.dmean_23                       float64\n",
      " 757   lowlevel.erbbands.dmean_24                       float64\n",
      " 758   lowlevel.erbbands.dmean_25                       float64\n",
      " 759   lowlevel.erbbands.dmean_26                       float64\n",
      " 760   lowlevel.erbbands.dmean_27                       float64\n",
      " 761   lowlevel.erbbands.dmean_28                       float64\n",
      " 762   lowlevel.erbbands.dmean_29                       float64\n",
      " 763   lowlevel.erbbands.dmean_30                       float64\n",
      " 764   lowlevel.erbbands.dmean_31                       float64\n",
      " 765   lowlevel.erbbands.dmean_32                       float64\n",
      " 766   lowlevel.erbbands.dmean_33                       float64\n",
      " 767   lowlevel.erbbands.dmean_34                       float64\n",
      " 768   lowlevel.erbbands.dmean_35                       float64\n",
      " 769   lowlevel.erbbands.dmean_36                       float64\n",
      " 770   lowlevel.erbbands.dmean_37                       float64\n",
      " 771   lowlevel.erbbands.dmean_38                       float64\n",
      " 772   lowlevel.erbbands.dmean_39                       float64\n",
      " 773   lowlevel.erbbands.dmean2_0                       float64\n",
      " 774   lowlevel.erbbands.dmean2_1                       float64\n",
      " 775   lowlevel.erbbands.dmean2_2                       float64\n",
      " 776   lowlevel.erbbands.dmean2_3                       float64\n",
      " 777   lowlevel.erbbands.dmean2_4                       float64\n",
      " 778   lowlevel.erbbands.dmean2_5                       float64\n",
      " 779   lowlevel.erbbands.dmean2_6                       float64\n",
      " 780   lowlevel.erbbands.dmean2_7                       float64\n",
      " 781   lowlevel.erbbands.dmean2_8                       float64\n",
      " 782   lowlevel.erbbands.dmean2_9                       float64\n",
      " 783   lowlevel.erbbands.dmean2_10                      float64\n",
      " 784   lowlevel.erbbands.dmean2_11                      float64\n",
      " 785   lowlevel.erbbands.dmean2_12                      float64\n",
      " 786   lowlevel.erbbands.dmean2_13                      float64\n",
      " 787   lowlevel.erbbands.dmean2_14                      float64\n",
      " 788   lowlevel.erbbands.dmean2_15                      float64\n",
      " 789   lowlevel.erbbands.dmean2_16                      float64\n",
      " 790   lowlevel.erbbands.dmean2_17                      float64\n",
      " 791   lowlevel.erbbands.dmean2_18                      float64\n",
      " 792   lowlevel.erbbands.dmean2_19                      float64\n",
      " 793   lowlevel.erbbands.dmean2_20                      float64\n",
      " 794   lowlevel.erbbands.dmean2_21                      float64\n",
      " 795   lowlevel.erbbands.dmean2_22                      float64\n",
      " 796   lowlevel.erbbands.dmean2_23                      float64\n",
      " 797   lowlevel.erbbands.dmean2_24                      float64\n",
      " 798   lowlevel.erbbands.dmean2_25                      float64\n",
      " 799   lowlevel.erbbands.dmean2_26                      float64\n",
      " 800   lowlevel.erbbands.dmean2_27                      float64\n",
      " 801   lowlevel.erbbands.dmean2_28                      float64\n",
      " 802   lowlevel.erbbands.dmean2_29                      float64\n",
      " 803   lowlevel.erbbands.dmean2_30                      float64\n",
      " 804   lowlevel.erbbands.dmean2_31                      float64\n",
      " 805   lowlevel.erbbands.dmean2_32                      float64\n",
      " 806   lowlevel.erbbands.dmean2_33                      float64\n",
      " 807   lowlevel.erbbands.dmean2_34                      float64\n",
      " 808   lowlevel.erbbands.dmean2_35                      float64\n",
      " 809   lowlevel.erbbands.dmean2_36                      float64\n",
      " 810   lowlevel.erbbands.dmean2_37                      float64\n",
      " 811   lowlevel.erbbands.dmean2_38                      float64\n",
      " 812   lowlevel.erbbands.dmean2_39                      float64\n",
      " 813   lowlevel.erbbands.dvar_0                         float64\n",
      " 814   lowlevel.erbbands.dvar_1                         float64\n",
      " 815   lowlevel.erbbands.dvar_2                         float64\n",
      " 816   lowlevel.erbbands.dvar_3                         float64\n",
      " 817   lowlevel.erbbands.dvar_4                         float64\n",
      " 818   lowlevel.erbbands.dvar_5                         float64\n",
      " 819   lowlevel.erbbands.dvar_6                         float64\n",
      " 820   lowlevel.erbbands.dvar_7                         float64\n",
      " 821   lowlevel.erbbands.dvar_8                         float64\n",
      " 822   lowlevel.erbbands.dvar_9                         float64\n",
      " 823   lowlevel.erbbands.dvar_10                        float64\n",
      " 824   lowlevel.erbbands.dvar_11                        float64\n",
      " 825   lowlevel.erbbands.dvar_12                        float64\n",
      " 826   lowlevel.erbbands.dvar_13                        float64\n",
      " 827   lowlevel.erbbands.dvar_14                        float64\n",
      " 828   lowlevel.erbbands.dvar_15                        float64\n",
      " 829   lowlevel.erbbands.dvar_16                        float64\n",
      " 830   lowlevel.erbbands.dvar_17                        float64\n",
      " 831   lowlevel.erbbands.dvar_18                        float64\n",
      " 832   lowlevel.erbbands.dvar_19                        float64\n",
      " 833   lowlevel.erbbands.dvar_20                        float64\n",
      " 834   lowlevel.erbbands.dvar_21                        float64\n",
      " 835   lowlevel.erbbands.dvar_22                        float64\n",
      " 836   lowlevel.erbbands.dvar_23                        float64\n",
      " 837   lowlevel.erbbands.dvar_24                        float64\n",
      " 838   lowlevel.erbbands.dvar_25                        float64\n",
      " 839   lowlevel.erbbands.dvar_26                        float64\n",
      " 840   lowlevel.erbbands.dvar_27                        float64\n",
      " 841   lowlevel.erbbands.dvar_28                        float64\n",
      " 842   lowlevel.erbbands.dvar_29                        float64\n",
      " 843   lowlevel.erbbands.dvar_30                        float64\n",
      " 844   lowlevel.erbbands.dvar_31                        float64\n",
      " 845   lowlevel.erbbands.dvar_32                        float64\n",
      " 846   lowlevel.erbbands.dvar_33                        float64\n",
      " 847   lowlevel.erbbands.dvar_34                        float64\n",
      " 848   lowlevel.erbbands.dvar_35                        float64\n",
      " 849   lowlevel.erbbands.dvar_36                        float64\n",
      " 850   lowlevel.erbbands.dvar_37                        float64\n",
      " 851   lowlevel.erbbands.dvar_38                        float64\n",
      " 852   lowlevel.erbbands.dvar_39                        float64\n",
      " 853   lowlevel.erbbands.dvar2_0                        float64\n",
      " 854   lowlevel.erbbands.dvar2_1                        float64\n",
      " 855   lowlevel.erbbands.dvar2_2                        float64\n",
      " 856   lowlevel.erbbands.dvar2_3                        float64\n",
      " 857   lowlevel.erbbands.dvar2_4                        float64\n",
      " 858   lowlevel.erbbands.dvar2_5                        float64\n",
      " 859   lowlevel.erbbands.dvar2_6                        float64\n",
      " 860   lowlevel.erbbands.dvar2_7                        float64\n",
      " 861   lowlevel.erbbands.dvar2_8                        float64\n",
      " 862   lowlevel.erbbands.dvar2_9                        float64\n",
      " 863   lowlevel.erbbands.dvar2_10                       float64\n",
      " 864   lowlevel.erbbands.dvar2_11                       float64\n",
      " 865   lowlevel.erbbands.dvar2_12                       float64\n",
      " 866   lowlevel.erbbands.dvar2_13                       float64\n",
      " 867   lowlevel.erbbands.dvar2_14                       float64\n",
      " 868   lowlevel.erbbands.dvar2_15                       float64\n",
      " 869   lowlevel.erbbands.dvar2_16                       float64\n",
      " 870   lowlevel.erbbands.dvar2_17                       float64\n",
      " 871   lowlevel.erbbands.dvar2_18                       float64\n",
      " 872   lowlevel.erbbands.dvar2_19                       float64\n",
      " 873   lowlevel.erbbands.dvar2_20                       float64\n",
      " 874   lowlevel.erbbands.dvar2_21                       float64\n",
      " 875   lowlevel.erbbands.dvar2_22                       float64\n",
      " 876   lowlevel.erbbands.dvar2_23                       float64\n",
      " 877   lowlevel.erbbands.dvar2_24                       float64\n",
      " 878   lowlevel.erbbands.dvar2_25                       float64\n",
      " 879   lowlevel.erbbands.dvar2_26                       float64\n",
      " 880   lowlevel.erbbands.dvar2_27                       float64\n",
      " 881   lowlevel.erbbands.dvar2_28                       float64\n",
      " 882   lowlevel.erbbands.dvar2_29                       float64\n",
      " 883   lowlevel.erbbands.dvar2_30                       float64\n",
      " 884   lowlevel.erbbands.dvar2_31                       float64\n",
      " 885   lowlevel.erbbands.dvar2_32                       float64\n",
      " 886   lowlevel.erbbands.dvar2_33                       float64\n",
      " 887   lowlevel.erbbands.dvar2_34                       float64\n",
      " 888   lowlevel.erbbands.dvar2_35                       float64\n",
      " 889   lowlevel.erbbands.dvar2_36                       float64\n",
      " 890   lowlevel.erbbands.dvar2_37                       float64\n",
      " 891   lowlevel.erbbands.dvar2_38                       float64\n",
      " 892   lowlevel.erbbands.dvar2_39                       float64\n",
      " 893   lowlevel.erbbands.max_0                          float64\n",
      " 894   lowlevel.erbbands.max_1                          float64\n",
      " 895   lowlevel.erbbands.max_2                          float64\n",
      " 896   lowlevel.erbbands.max_3                          float64\n",
      " 897   lowlevel.erbbands.max_4                          float64\n",
      " 898   lowlevel.erbbands.max_5                          float64\n",
      " 899   lowlevel.erbbands.max_6                          float64\n",
      " 900   lowlevel.erbbands.max_7                          float64\n",
      " 901   lowlevel.erbbands.max_8                          float64\n",
      " 902   lowlevel.erbbands.max_9                          float64\n",
      " 903   lowlevel.erbbands.max_10                         float64\n",
      " 904   lowlevel.erbbands.max_11                         float64\n",
      " 905   lowlevel.erbbands.max_12                         float64\n",
      " 906   lowlevel.erbbands.max_13                         float64\n",
      " 907   lowlevel.erbbands.max_14                         float64\n",
      " 908   lowlevel.erbbands.max_15                         float64\n",
      " 909   lowlevel.erbbands.max_16                         float64\n",
      " 910   lowlevel.erbbands.max_17                         float64\n",
      " 911   lowlevel.erbbands.max_18                         float64\n",
      " 912   lowlevel.erbbands.max_19                         float64\n",
      " 913   lowlevel.erbbands.max_20                         float64\n",
      " 914   lowlevel.erbbands.max_21                         float64\n",
      " 915   lowlevel.erbbands.max_22                         float64\n",
      " 916   lowlevel.erbbands.max_23                         float64\n",
      " 917   lowlevel.erbbands.max_24                         float64\n",
      " 918   lowlevel.erbbands.max_25                         float64\n",
      " 919   lowlevel.erbbands.max_26                         float64\n",
      " 920   lowlevel.erbbands.max_27                         float64\n",
      " 921   lowlevel.erbbands.max_28                         float64\n",
      " 922   lowlevel.erbbands.max_29                         float64\n",
      " 923   lowlevel.erbbands.max_30                         float64\n",
      " 924   lowlevel.erbbands.max_31                         float64\n",
      " 925   lowlevel.erbbands.max_32                         float64\n",
      " 926   lowlevel.erbbands.max_33                         float64\n",
      " 927   lowlevel.erbbands.max_34                         float64\n",
      " 928   lowlevel.erbbands.max_35                         float64\n",
      " 929   lowlevel.erbbands.max_36                         float64\n",
      " 930   lowlevel.erbbands.max_37                         float64\n",
      " 931   lowlevel.erbbands.max_38                         float64\n",
      " 932   lowlevel.erbbands.max_39                         float64\n",
      " 933   lowlevel.erbbands.mean_0                         float64\n",
      " 934   lowlevel.erbbands.mean_1                         float64\n",
      " 935   lowlevel.erbbands.mean_2                         float64\n",
      " 936   lowlevel.erbbands.mean_3                         float64\n",
      " 937   lowlevel.erbbands.mean_4                         float64\n",
      " 938   lowlevel.erbbands.mean_5                         float64\n",
      " 939   lowlevel.erbbands.mean_6                         float64\n",
      " 940   lowlevel.erbbands.mean_7                         float64\n",
      " 941   lowlevel.erbbands.mean_8                         float64\n",
      " 942   lowlevel.erbbands.mean_9                         float64\n",
      " 943   lowlevel.erbbands.mean_10                        float64\n",
      " 944   lowlevel.erbbands.mean_11                        float64\n",
      " 945   lowlevel.erbbands.mean_12                        float64\n",
      " 946   lowlevel.erbbands.mean_13                        float64\n",
      " 947   lowlevel.erbbands.mean_14                        float64\n",
      " 948   lowlevel.erbbands.mean_15                        float64\n",
      " 949   lowlevel.erbbands.mean_16                        float64\n",
      " 950   lowlevel.erbbands.mean_17                        float64\n",
      " 951   lowlevel.erbbands.mean_18                        float64\n",
      " 952   lowlevel.erbbands.mean_19                        float64\n",
      " 953   lowlevel.erbbands.mean_20                        float64\n",
      " 954   lowlevel.erbbands.mean_21                        float64\n",
      " 955   lowlevel.erbbands.mean_22                        float64\n",
      " 956   lowlevel.erbbands.mean_23                        float64\n",
      " 957   lowlevel.erbbands.mean_24                        float64\n",
      " 958   lowlevel.erbbands.mean_25                        float64\n",
      " 959   lowlevel.erbbands.mean_26                        float64\n",
      " 960   lowlevel.erbbands.mean_27                        float64\n",
      " 961   lowlevel.erbbands.mean_28                        float64\n",
      " 962   lowlevel.erbbands.mean_29                        float64\n",
      " 963   lowlevel.erbbands.mean_30                        float64\n",
      " 964   lowlevel.erbbands.mean_31                        float64\n",
      " 965   lowlevel.erbbands.mean_32                        float64\n",
      " 966   lowlevel.erbbands.mean_33                        float64\n",
      " 967   lowlevel.erbbands.mean_34                        float64\n",
      " 968   lowlevel.erbbands.mean_35                        float64\n",
      " 969   lowlevel.erbbands.mean_36                        float64\n",
      " 970   lowlevel.erbbands.mean_37                        float64\n",
      " 971   lowlevel.erbbands.mean_38                        float64\n",
      " 972   lowlevel.erbbands.mean_39                        float64\n",
      " 973   lowlevel.erbbands.median_0                       float64\n",
      " 974   lowlevel.erbbands.median_1                       float64\n",
      " 975   lowlevel.erbbands.median_2                       float64\n",
      " 976   lowlevel.erbbands.median_3                       float64\n",
      " 977   lowlevel.erbbands.median_4                       float64\n",
      " 978   lowlevel.erbbands.median_5                       float64\n",
      " 979   lowlevel.erbbands.median_6                       float64\n",
      " 980   lowlevel.erbbands.median_7                       float64\n",
      " 981   lowlevel.erbbands.median_8                       float64\n",
      " 982   lowlevel.erbbands.median_9                       float64\n",
      " 983   lowlevel.erbbands.median_10                      float64\n",
      " 984   lowlevel.erbbands.median_11                      float64\n",
      " 985   lowlevel.erbbands.median_12                      float64\n",
      " 986   lowlevel.erbbands.median_13                      float64\n",
      " 987   lowlevel.erbbands.median_14                      float64\n",
      " 988   lowlevel.erbbands.median_15                      float64\n",
      " 989   lowlevel.erbbands.median_16                      float64\n",
      " 990   lowlevel.erbbands.median_17                      float64\n",
      " 991   lowlevel.erbbands.median_18                      float64\n",
      " 992   lowlevel.erbbands.median_19                      float64\n",
      " 993   lowlevel.erbbands.median_20                      float64\n",
      " 994   lowlevel.erbbands.median_21                      float64\n",
      " 995   lowlevel.erbbands.median_22                      float64\n",
      " 996   lowlevel.erbbands.median_23                      float64\n",
      " 997   lowlevel.erbbands.median_24                      float64\n",
      " 998   lowlevel.erbbands.median_25                      float64\n",
      " 999   lowlevel.erbbands.median_26                      float64\n",
      " 1000  lowlevel.erbbands.median_27                      float64\n",
      " 1001  lowlevel.erbbands.median_28                      float64\n",
      " 1002  lowlevel.erbbands.median_29                      float64\n",
      " 1003  lowlevel.erbbands.median_30                      float64\n",
      " 1004  lowlevel.erbbands.median_31                      float64\n",
      " 1005  lowlevel.erbbands.median_32                      float64\n",
      " 1006  lowlevel.erbbands.median_33                      float64\n",
      " 1007  lowlevel.erbbands.median_34                      float64\n",
      " 1008  lowlevel.erbbands.median_35                      float64\n",
      " 1009  lowlevel.erbbands.median_36                      float64\n",
      " 1010  lowlevel.erbbands.median_37                      float64\n",
      " 1011  lowlevel.erbbands.median_38                      float64\n",
      " 1012  lowlevel.erbbands.median_39                      float64\n",
      " 1013  lowlevel.erbbands.min_0                          float64\n",
      " 1014  lowlevel.erbbands.min_1                          float64\n",
      " 1015  lowlevel.erbbands.min_2                          float64\n",
      " 1016  lowlevel.erbbands.min_3                          float64\n",
      " 1017  lowlevel.erbbands.min_4                          float64\n",
      " 1018  lowlevel.erbbands.min_5                          float64\n",
      " 1019  lowlevel.erbbands.min_6                          float64\n",
      " 1020  lowlevel.erbbands.min_7                          float64\n",
      " 1021  lowlevel.erbbands.min_8                          float64\n",
      " 1022  lowlevel.erbbands.min_9                          float64\n",
      " 1023  lowlevel.erbbands.min_10                         float64\n",
      " 1024  lowlevel.erbbands.min_11                         float64\n",
      " 1025  lowlevel.erbbands.min_12                         float64\n",
      " 1026  lowlevel.erbbands.min_13                         float64\n",
      " 1027  lowlevel.erbbands.min_14                         float64\n",
      " 1028  lowlevel.erbbands.min_15                         float64\n",
      " 1029  lowlevel.erbbands.min_16                         float64\n",
      " 1030  lowlevel.erbbands.min_17                         float64\n",
      " 1031  lowlevel.erbbands.min_18                         float64\n",
      " 1032  lowlevel.erbbands.min_19                         float64\n",
      " 1033  lowlevel.erbbands.min_20                         float64\n",
      " 1034  lowlevel.erbbands.min_21                         float64\n",
      " 1035  lowlevel.erbbands.min_22                         float64\n",
      " 1036  lowlevel.erbbands.min_23                         float64\n",
      " 1037  lowlevel.erbbands.min_24                         float64\n",
      " 1038  lowlevel.erbbands.min_25                         float64\n",
      " 1039  lowlevel.erbbands.min_26                         float64\n",
      " 1040  lowlevel.erbbands.min_27                         float64\n",
      " 1041  lowlevel.erbbands.min_28                         float64\n",
      " 1042  lowlevel.erbbands.min_29                         float64\n",
      " 1043  lowlevel.erbbands.min_30                         float64\n",
      " 1044  lowlevel.erbbands.min_31                         float64\n",
      " 1045  lowlevel.erbbands.min_32                         float64\n",
      " 1046  lowlevel.erbbands.min_33                         float64\n",
      " 1047  lowlevel.erbbands.min_34                         float64\n",
      " 1048  lowlevel.erbbands.min_35                         float64\n",
      " 1049  lowlevel.erbbands.min_36                         float64\n",
      " 1050  lowlevel.erbbands.min_37                         float64\n",
      " 1051  lowlevel.erbbands.min_38                         float64\n",
      " 1052  lowlevel.erbbands.min_39                         float64\n",
      " 1053  lowlevel.erbbands.stdev_0                        float64\n",
      " 1054  lowlevel.erbbands.stdev_1                        float64\n",
      " 1055  lowlevel.erbbands.stdev_2                        float64\n",
      " 1056  lowlevel.erbbands.stdev_3                        float64\n",
      " 1057  lowlevel.erbbands.stdev_4                        float64\n",
      " 1058  lowlevel.erbbands.stdev_5                        float64\n",
      " 1059  lowlevel.erbbands.stdev_6                        float64\n",
      " 1060  lowlevel.erbbands.stdev_7                        float64\n",
      " 1061  lowlevel.erbbands.stdev_8                        float64\n",
      " 1062  lowlevel.erbbands.stdev_9                        float64\n",
      " 1063  lowlevel.erbbands.stdev_10                       float64\n",
      " 1064  lowlevel.erbbands.stdev_11                       float64\n",
      " 1065  lowlevel.erbbands.stdev_12                       float64\n",
      " 1066  lowlevel.erbbands.stdev_13                       float64\n",
      " 1067  lowlevel.erbbands.stdev_14                       float64\n",
      " 1068  lowlevel.erbbands.stdev_15                       float64\n",
      " 1069  lowlevel.erbbands.stdev_16                       float64\n",
      " 1070  lowlevel.erbbands.stdev_17                       float64\n",
      " 1071  lowlevel.erbbands.stdev_18                       float64\n",
      " 1072  lowlevel.erbbands.stdev_19                       float64\n",
      " 1073  lowlevel.erbbands.stdev_20                       float64\n",
      " 1074  lowlevel.erbbands.stdev_21                       float64\n",
      " 1075  lowlevel.erbbands.stdev_22                       float64\n",
      " 1076  lowlevel.erbbands.stdev_23                       float64\n",
      " 1077  lowlevel.erbbands.stdev_24                       float64\n",
      " 1078  lowlevel.erbbands.stdev_25                       float64\n",
      " 1079  lowlevel.erbbands.stdev_26                       float64\n",
      " 1080  lowlevel.erbbands.stdev_27                       float64\n",
      " 1081  lowlevel.erbbands.stdev_28                       float64\n",
      " 1082  lowlevel.erbbands.stdev_29                       float64\n",
      " 1083  lowlevel.erbbands.stdev_30                       float64\n",
      " 1084  lowlevel.erbbands.stdev_31                       float64\n",
      " 1085  lowlevel.erbbands.stdev_32                       float64\n",
      " 1086  lowlevel.erbbands.stdev_33                       float64\n",
      " 1087  lowlevel.erbbands.stdev_34                       float64\n",
      " 1088  lowlevel.erbbands.stdev_35                       float64\n",
      " 1089  lowlevel.erbbands.stdev_36                       float64\n",
      " 1090  lowlevel.erbbands.stdev_37                       float64\n",
      " 1091  lowlevel.erbbands.stdev_38                       float64\n",
      " 1092  lowlevel.erbbands.stdev_39                       float64\n",
      " 1093  lowlevel.erbbands.var_0                          float64\n",
      " 1094  lowlevel.erbbands.var_1                          float64\n",
      " 1095  lowlevel.erbbands.var_2                          float64\n",
      " 1096  lowlevel.erbbands.var_3                          float64\n",
      " 1097  lowlevel.erbbands.var_4                          float64\n",
      " 1098  lowlevel.erbbands.var_5                          float64\n",
      " 1099  lowlevel.erbbands.var_6                          float64\n",
      " 1100  lowlevel.erbbands.var_7                          float64\n",
      " 1101  lowlevel.erbbands.var_8                          float64\n",
      " 1102  lowlevel.erbbands.var_9                          float64\n",
      " 1103  lowlevel.erbbands.var_10                         float64\n",
      " 1104  lowlevel.erbbands.var_11                         float64\n",
      " 1105  lowlevel.erbbands.var_12                         float64\n",
      " 1106  lowlevel.erbbands.var_13                         float64\n",
      " 1107  lowlevel.erbbands.var_14                         float64\n",
      " 1108  lowlevel.erbbands.var_15                         float64\n",
      " 1109  lowlevel.erbbands.var_16                         float64\n",
      " 1110  lowlevel.erbbands.var_17                         float64\n",
      " 1111  lowlevel.erbbands.var_18                         float64\n",
      " 1112  lowlevel.erbbands.var_19                         float64\n",
      " 1113  lowlevel.erbbands.var_20                         float64\n",
      " 1114  lowlevel.erbbands.var_21                         float64\n",
      " 1115  lowlevel.erbbands.var_22                         float64\n",
      " 1116  lowlevel.erbbands.var_23                         float64\n",
      " 1117  lowlevel.erbbands.var_24                         float64\n",
      " 1118  lowlevel.erbbands.var_25                         float64\n",
      " 1119  lowlevel.erbbands.var_26                         float64\n",
      " 1120  lowlevel.erbbands.var_27                         float64\n",
      " 1121  lowlevel.erbbands.var_28                         float64\n",
      " 1122  lowlevel.erbbands.var_29                         float64\n",
      " 1123  lowlevel.erbbands.var_30                         float64\n",
      " 1124  lowlevel.erbbands.var_31                         float64\n",
      " 1125  lowlevel.erbbands.var_32                         float64\n",
      " 1126  lowlevel.erbbands.var_33                         float64\n",
      " 1127  lowlevel.erbbands.var_34                         float64\n",
      " 1128  lowlevel.erbbands.var_35                         float64\n",
      " 1129  lowlevel.erbbands.var_36                         float64\n",
      " 1130  lowlevel.erbbands.var_37                         float64\n",
      " 1131  lowlevel.erbbands.var_38                         float64\n",
      " 1132  lowlevel.erbbands.var_39                         float64\n",
      " 1133  lowlevel.gfcc.cov_0                              float64\n",
      " 1134  lowlevel.gfcc.cov_1                              float64\n",
      " 1135  lowlevel.gfcc.cov_2                              float64\n",
      " 1136  lowlevel.gfcc.cov_3                              float64\n",
      " 1137  lowlevel.gfcc.cov_4                              float64\n",
      " 1138  lowlevel.gfcc.cov_5                              float64\n",
      " 1139  lowlevel.gfcc.cov_6                              float64\n",
      " 1140  lowlevel.gfcc.cov_7                              float64\n",
      " 1141  lowlevel.gfcc.cov_8                              float64\n",
      " 1142  lowlevel.gfcc.cov_9                              float64\n",
      " 1143  lowlevel.gfcc.cov_10                             float64\n",
      " 1144  lowlevel.gfcc.cov_11                             float64\n",
      " 1145  lowlevel.gfcc.cov_12                             float64\n",
      " 1146  lowlevel.gfcc.cov_13                             float64\n",
      " 1147  lowlevel.gfcc.cov_14                             float64\n",
      " 1148  lowlevel.gfcc.cov_15                             float64\n",
      " 1149  lowlevel.gfcc.cov_16                             float64\n",
      " 1150  lowlevel.gfcc.cov_17                             float64\n",
      " 1151  lowlevel.gfcc.cov_18                             float64\n",
      " 1152  lowlevel.gfcc.cov_19                             float64\n",
      " 1153  lowlevel.gfcc.cov_20                             float64\n",
      " 1154  lowlevel.gfcc.cov_21                             float64\n",
      " 1155  lowlevel.gfcc.cov_22                             float64\n",
      " 1156  lowlevel.gfcc.cov_23                             float64\n",
      " 1157  lowlevel.gfcc.cov_24                             float64\n",
      " 1158  lowlevel.gfcc.cov_25                             float64\n",
      " 1159  lowlevel.gfcc.cov_26                             float64\n",
      " 1160  lowlevel.gfcc.cov_27                             float64\n",
      " 1161  lowlevel.gfcc.cov_28                             float64\n",
      " 1162  lowlevel.gfcc.cov_29                             float64\n",
      " 1163  lowlevel.gfcc.cov_30                             float64\n",
      " 1164  lowlevel.gfcc.cov_31                             float64\n",
      " 1165  lowlevel.gfcc.cov_32                             float64\n",
      " 1166  lowlevel.gfcc.cov_33                             float64\n",
      " 1167  lowlevel.gfcc.cov_34                             float64\n",
      " 1168  lowlevel.gfcc.cov_35                             float64\n",
      " 1169  lowlevel.gfcc.cov_36                             float64\n",
      " 1170  lowlevel.gfcc.cov_37                             float64\n",
      " 1171  lowlevel.gfcc.cov_38                             float64\n",
      " 1172  lowlevel.gfcc.cov_39                             float64\n",
      " 1173  lowlevel.gfcc.cov_40                             float64\n",
      " 1174  lowlevel.gfcc.cov_41                             float64\n",
      " 1175  lowlevel.gfcc.cov_42                             float64\n",
      " 1176  lowlevel.gfcc.cov_43                             float64\n",
      " 1177  lowlevel.gfcc.cov_44                             float64\n",
      " 1178  lowlevel.gfcc.cov_45                             float64\n",
      " 1179  lowlevel.gfcc.cov_46                             float64\n",
      " 1180  lowlevel.gfcc.cov_47                             float64\n",
      " 1181  lowlevel.gfcc.cov_48                             float64\n",
      " 1182  lowlevel.gfcc.cov_49                             float64\n",
      " 1183  lowlevel.gfcc.cov_50                             float64\n",
      " 1184  lowlevel.gfcc.cov_51                             float64\n",
      " 1185  lowlevel.gfcc.cov_52                             float64\n",
      " 1186  lowlevel.gfcc.cov_53                             float64\n",
      " 1187  lowlevel.gfcc.cov_54                             float64\n",
      " 1188  lowlevel.gfcc.cov_55                             float64\n",
      " 1189  lowlevel.gfcc.cov_56                             float64\n",
      " 1190  lowlevel.gfcc.cov_57                             float64\n",
      " 1191  lowlevel.gfcc.cov_58                             float64\n",
      " 1192  lowlevel.gfcc.cov_59                             float64\n",
      " 1193  lowlevel.gfcc.cov_60                             float64\n",
      " 1194  lowlevel.gfcc.cov_61                             float64\n",
      " 1195  lowlevel.gfcc.cov_62                             float64\n",
      " 1196  lowlevel.gfcc.cov_63                             float64\n",
      " 1197  lowlevel.gfcc.cov_64                             float64\n",
      " 1198  lowlevel.gfcc.cov_65                             float64\n",
      " 1199  lowlevel.gfcc.cov_66                             float64\n",
      " 1200  lowlevel.gfcc.cov_67                             float64\n",
      " 1201  lowlevel.gfcc.cov_68                             float64\n",
      " 1202  lowlevel.gfcc.cov_69                             float64\n",
      " 1203  lowlevel.gfcc.cov_70                             float64\n",
      " 1204  lowlevel.gfcc.cov_71                             float64\n",
      " 1205  lowlevel.gfcc.cov_72                             float64\n",
      " 1206  lowlevel.gfcc.cov_73                             float64\n",
      " 1207  lowlevel.gfcc.cov_74                             float64\n",
      " 1208  lowlevel.gfcc.cov_75                             float64\n",
      " 1209  lowlevel.gfcc.cov_76                             float64\n",
      " 1210  lowlevel.gfcc.cov_77                             float64\n",
      " 1211  lowlevel.gfcc.cov_78                             float64\n",
      " 1212  lowlevel.gfcc.cov_79                             float64\n",
      " 1213  lowlevel.gfcc.cov_80                             float64\n",
      " 1214  lowlevel.gfcc.cov_81                             float64\n",
      " 1215  lowlevel.gfcc.cov_82                             float64\n",
      " 1216  lowlevel.gfcc.cov_83                             float64\n",
      " 1217  lowlevel.gfcc.cov_84                             float64\n",
      " 1218  lowlevel.gfcc.cov_85                             float64\n",
      " 1219  lowlevel.gfcc.cov_86                             float64\n",
      " 1220  lowlevel.gfcc.cov_87                             float64\n",
      " 1221  lowlevel.gfcc.cov_88                             float64\n",
      " 1222  lowlevel.gfcc.cov_89                             float64\n",
      " 1223  lowlevel.gfcc.cov_90                             float64\n",
      " 1224  lowlevel.gfcc.cov_91                             float64\n",
      " 1225  lowlevel.gfcc.cov_92                             float64\n",
      " 1226  lowlevel.gfcc.cov_93                             float64\n",
      " 1227  lowlevel.gfcc.cov_94                             float64\n",
      " 1228  lowlevel.gfcc.cov_95                             float64\n",
      " 1229  lowlevel.gfcc.cov_96                             float64\n",
      " 1230  lowlevel.gfcc.cov_97                             float64\n",
      " 1231  lowlevel.gfcc.cov_98                             float64\n",
      " 1232  lowlevel.gfcc.cov_99                             float64\n",
      " 1233  lowlevel.gfcc.cov_100                            float64\n",
      " 1234  lowlevel.gfcc.cov_101                            float64\n",
      " 1235  lowlevel.gfcc.cov_102                            float64\n",
      " 1236  lowlevel.gfcc.cov_103                            float64\n",
      " 1237  lowlevel.gfcc.cov_104                            float64\n",
      " 1238  lowlevel.gfcc.cov_105                            float64\n",
      " 1239  lowlevel.gfcc.cov_106                            float64\n",
      " 1240  lowlevel.gfcc.cov_107                            float64\n",
      " 1241  lowlevel.gfcc.cov_108                            float64\n",
      " 1242  lowlevel.gfcc.cov_109                            float64\n",
      " 1243  lowlevel.gfcc.cov_110                            float64\n",
      " 1244  lowlevel.gfcc.cov_111                            float64\n",
      " 1245  lowlevel.gfcc.cov_112                            float64\n",
      " 1246  lowlevel.gfcc.cov_113                            float64\n",
      " 1247  lowlevel.gfcc.cov_114                            float64\n",
      " 1248  lowlevel.gfcc.cov_115                            float64\n",
      " 1249  lowlevel.gfcc.cov_116                            float64\n",
      " 1250  lowlevel.gfcc.cov_117                            float64\n",
      " 1251  lowlevel.gfcc.cov_118                            float64\n",
      " 1252  lowlevel.gfcc.cov_119                            float64\n",
      " 1253  lowlevel.gfcc.cov_120                            float64\n",
      " 1254  lowlevel.gfcc.cov_121                            float64\n",
      " 1255  lowlevel.gfcc.cov_122                            float64\n",
      " 1256  lowlevel.gfcc.cov_123                            float64\n",
      " 1257  lowlevel.gfcc.cov_124                            float64\n",
      " 1258  lowlevel.gfcc.cov_125                            float64\n",
      " 1259  lowlevel.gfcc.cov_126                            float64\n",
      " 1260  lowlevel.gfcc.cov_127                            float64\n",
      " 1261  lowlevel.gfcc.cov_128                            float64\n",
      " 1262  lowlevel.gfcc.cov_129                            float64\n",
      " 1263  lowlevel.gfcc.cov_130                            float64\n",
      " 1264  lowlevel.gfcc.cov_131                            float64\n",
      " 1265  lowlevel.gfcc.cov_132                            float64\n",
      " 1266  lowlevel.gfcc.cov_133                            float64\n",
      " 1267  lowlevel.gfcc.cov_134                            float64\n",
      " 1268  lowlevel.gfcc.cov_135                            float64\n",
      " 1269  lowlevel.gfcc.cov_136                            float64\n",
      " 1270  lowlevel.gfcc.cov_137                            float64\n",
      " 1271  lowlevel.gfcc.cov_138                            float64\n",
      " 1272  lowlevel.gfcc.cov_139                            float64\n",
      " 1273  lowlevel.gfcc.cov_140                            float64\n",
      " 1274  lowlevel.gfcc.cov_141                            float64\n",
      " 1275  lowlevel.gfcc.cov_142                            float64\n",
      " 1276  lowlevel.gfcc.cov_143                            float64\n",
      " 1277  lowlevel.gfcc.cov_144                            float64\n",
      " 1278  lowlevel.gfcc.cov_145                            float64\n",
      " 1279  lowlevel.gfcc.cov_146                            float64\n",
      " 1280  lowlevel.gfcc.cov_147                            float64\n",
      " 1281  lowlevel.gfcc.cov_148                            float64\n",
      " 1282  lowlevel.gfcc.cov_149                            float64\n",
      " 1283  lowlevel.gfcc.cov_150                            float64\n",
      " 1284  lowlevel.gfcc.cov_151                            float64\n",
      " 1285  lowlevel.gfcc.cov_152                            float64\n",
      " 1286  lowlevel.gfcc.cov_153                            float64\n",
      " 1287  lowlevel.gfcc.cov_154                            float64\n",
      " 1288  lowlevel.gfcc.cov_155                            float64\n",
      " 1289  lowlevel.gfcc.cov_156                            float64\n",
      " 1290  lowlevel.gfcc.cov_157                            float64\n",
      " 1291  lowlevel.gfcc.cov_158                            float64\n",
      " 1292  lowlevel.gfcc.cov_159                            float64\n",
      " 1293  lowlevel.gfcc.cov_160                            float64\n",
      " 1294  lowlevel.gfcc.cov_161                            float64\n",
      " 1295  lowlevel.gfcc.cov_162                            float64\n",
      " 1296  lowlevel.gfcc.cov_163                            float64\n",
      " 1297  lowlevel.gfcc.cov_164                            float64\n",
      " 1298  lowlevel.gfcc.cov_165                            float64\n",
      " 1299  lowlevel.gfcc.cov_166                            float64\n",
      " 1300  lowlevel.gfcc.cov_167                            float64\n",
      " 1301  lowlevel.gfcc.cov_168                            float64\n",
      " 1302  lowlevel.gfcc.icov_0                             float64\n",
      " 1303  lowlevel.gfcc.icov_1                             float64\n",
      " 1304  lowlevel.gfcc.icov_2                             float64\n",
      " 1305  lowlevel.gfcc.icov_3                             float64\n",
      " 1306  lowlevel.gfcc.icov_4                             float64\n",
      " 1307  lowlevel.gfcc.icov_5                             float64\n",
      " 1308  lowlevel.gfcc.icov_6                             float64\n",
      " 1309  lowlevel.gfcc.icov_7                             float64\n",
      " 1310  lowlevel.gfcc.icov_8                             float64\n",
      " 1311  lowlevel.gfcc.icov_9                             float64\n",
      " 1312  lowlevel.gfcc.icov_10                            float64\n",
      " 1313  lowlevel.gfcc.icov_11                            float64\n",
      " 1314  lowlevel.gfcc.icov_12                            float64\n",
      " 1315  lowlevel.gfcc.icov_13                            float64\n",
      " 1316  lowlevel.gfcc.icov_14                            float64\n",
      " 1317  lowlevel.gfcc.icov_15                            float64\n",
      " 1318  lowlevel.gfcc.icov_16                            float64\n",
      " 1319  lowlevel.gfcc.icov_17                            float64\n",
      " 1320  lowlevel.gfcc.icov_18                            float64\n",
      " 1321  lowlevel.gfcc.icov_19                            float64\n",
      " 1322  lowlevel.gfcc.icov_20                            float64\n",
      " 1323  lowlevel.gfcc.icov_21                            float64\n",
      " 1324  lowlevel.gfcc.icov_22                            float64\n",
      " 1325  lowlevel.gfcc.icov_23                            float64\n",
      " 1326  lowlevel.gfcc.icov_24                            float64\n",
      " 1327  lowlevel.gfcc.icov_25                            float64\n",
      " 1328  lowlevel.gfcc.icov_26                            float64\n",
      " 1329  lowlevel.gfcc.icov_27                            float64\n",
      " 1330  lowlevel.gfcc.icov_28                            float64\n",
      " 1331  lowlevel.gfcc.icov_29                            float64\n",
      " 1332  lowlevel.gfcc.icov_30                            float64\n",
      " 1333  lowlevel.gfcc.icov_31                            float64\n",
      " 1334  lowlevel.gfcc.icov_32                            float64\n",
      " 1335  lowlevel.gfcc.icov_33                            float64\n",
      " 1336  lowlevel.gfcc.icov_34                            float64\n",
      " 1337  lowlevel.gfcc.icov_35                            float64\n",
      " 1338  lowlevel.gfcc.icov_36                            float64\n",
      " 1339  lowlevel.gfcc.icov_37                            float64\n",
      " 1340  lowlevel.gfcc.icov_38                            float64\n",
      " 1341  lowlevel.gfcc.icov_39                            float64\n",
      " 1342  lowlevel.gfcc.icov_40                            float64\n",
      " 1343  lowlevel.gfcc.icov_41                            float64\n",
      " 1344  lowlevel.gfcc.icov_42                            float64\n",
      " 1345  lowlevel.gfcc.icov_43                            float64\n",
      " 1346  lowlevel.gfcc.icov_44                            float64\n",
      " 1347  lowlevel.gfcc.icov_45                            float64\n",
      " 1348  lowlevel.gfcc.icov_46                            float64\n",
      " 1349  lowlevel.gfcc.icov_47                            float64\n",
      " 1350  lowlevel.gfcc.icov_48                            float64\n",
      " 1351  lowlevel.gfcc.icov_49                            float64\n",
      " 1352  lowlevel.gfcc.icov_50                            float64\n",
      " 1353  lowlevel.gfcc.icov_51                            float64\n",
      " 1354  lowlevel.gfcc.icov_52                            float64\n",
      " 1355  lowlevel.gfcc.icov_53                            float64\n",
      " 1356  lowlevel.gfcc.icov_54                            float64\n",
      " 1357  lowlevel.gfcc.icov_55                            float64\n",
      " 1358  lowlevel.gfcc.icov_56                            float64\n",
      " 1359  lowlevel.gfcc.icov_57                            float64\n",
      " 1360  lowlevel.gfcc.icov_58                            float64\n",
      " 1361  lowlevel.gfcc.icov_59                            float64\n",
      " 1362  lowlevel.gfcc.icov_60                            float64\n",
      " 1363  lowlevel.gfcc.icov_61                            float64\n",
      " 1364  lowlevel.gfcc.icov_62                            float64\n",
      " 1365  lowlevel.gfcc.icov_63                            float64\n",
      " 1366  lowlevel.gfcc.icov_64                            float64\n",
      " 1367  lowlevel.gfcc.icov_65                            float64\n",
      " 1368  lowlevel.gfcc.icov_66                            float64\n",
      " 1369  lowlevel.gfcc.icov_67                            float64\n",
      " 1370  lowlevel.gfcc.icov_68                            float64\n",
      " 1371  lowlevel.gfcc.icov_69                            float64\n",
      " 1372  lowlevel.gfcc.icov_70                            float64\n",
      " 1373  lowlevel.gfcc.icov_71                            float64\n",
      " 1374  lowlevel.gfcc.icov_72                            float64\n",
      " 1375  lowlevel.gfcc.icov_73                            float64\n",
      " 1376  lowlevel.gfcc.icov_74                            float64\n",
      " 1377  lowlevel.gfcc.icov_75                            float64\n",
      " 1378  lowlevel.gfcc.icov_76                            float64\n",
      " 1379  lowlevel.gfcc.icov_77                            float64\n",
      " 1380  lowlevel.gfcc.icov_78                            float64\n",
      " 1381  lowlevel.gfcc.icov_79                            float64\n",
      " 1382  lowlevel.gfcc.icov_80                            float64\n",
      " 1383  lowlevel.gfcc.icov_81                            float64\n",
      " 1384  lowlevel.gfcc.icov_82                            float64\n",
      " 1385  lowlevel.gfcc.icov_83                            float64\n",
      " 1386  lowlevel.gfcc.icov_84                            float64\n",
      " 1387  lowlevel.gfcc.icov_85                            float64\n",
      " 1388  lowlevel.gfcc.icov_86                            float64\n",
      " 1389  lowlevel.gfcc.icov_87                            float64\n",
      " 1390  lowlevel.gfcc.icov_88                            float64\n",
      " 1391  lowlevel.gfcc.icov_89                            float64\n",
      " 1392  lowlevel.gfcc.icov_90                            float64\n",
      " 1393  lowlevel.gfcc.icov_91                            float64\n",
      " 1394  lowlevel.gfcc.icov_92                            float64\n",
      " 1395  lowlevel.gfcc.icov_93                            float64\n",
      " 1396  lowlevel.gfcc.icov_94                            float64\n",
      " 1397  lowlevel.gfcc.icov_95                            float64\n",
      " 1398  lowlevel.gfcc.icov_96                            float64\n",
      " 1399  lowlevel.gfcc.icov_97                            float64\n",
      " 1400  lowlevel.gfcc.icov_98                            float64\n",
      " 1401  lowlevel.gfcc.icov_99                            float64\n",
      " 1402  lowlevel.gfcc.icov_100                           float64\n",
      " 1403  lowlevel.gfcc.icov_101                           float64\n",
      " 1404  lowlevel.gfcc.icov_102                           float64\n",
      " 1405  lowlevel.gfcc.icov_103                           float64\n",
      " 1406  lowlevel.gfcc.icov_104                           float64\n",
      " 1407  lowlevel.gfcc.icov_105                           float64\n",
      " 1408  lowlevel.gfcc.icov_106                           float64\n",
      " 1409  lowlevel.gfcc.icov_107                           float64\n",
      " 1410  lowlevel.gfcc.icov_108                           float64\n",
      " 1411  lowlevel.gfcc.icov_109                           float64\n",
      " 1412  lowlevel.gfcc.icov_110                           float64\n",
      " 1413  lowlevel.gfcc.icov_111                           float64\n",
      " 1414  lowlevel.gfcc.icov_112                           float64\n",
      " 1415  lowlevel.gfcc.icov_113                           float64\n",
      " 1416  lowlevel.gfcc.icov_114                           float64\n",
      " 1417  lowlevel.gfcc.icov_115                           float64\n",
      " 1418  lowlevel.gfcc.icov_116                           float64\n",
      " 1419  lowlevel.gfcc.icov_117                           float64\n",
      " 1420  lowlevel.gfcc.icov_118                           float64\n",
      " 1421  lowlevel.gfcc.icov_119                           float64\n",
      " 1422  lowlevel.gfcc.icov_120                           float64\n",
      " 1423  lowlevel.gfcc.icov_121                           float64\n",
      " 1424  lowlevel.gfcc.icov_122                           float64\n",
      " 1425  lowlevel.gfcc.icov_123                           float64\n",
      " 1426  lowlevel.gfcc.icov_124                           float64\n",
      " 1427  lowlevel.gfcc.icov_125                           float64\n",
      " 1428  lowlevel.gfcc.icov_126                           float64\n",
      " 1429  lowlevel.gfcc.icov_127                           float64\n",
      " 1430  lowlevel.gfcc.icov_128                           float64\n",
      " 1431  lowlevel.gfcc.icov_129                           float64\n",
      " 1432  lowlevel.gfcc.icov_130                           float64\n",
      " 1433  lowlevel.gfcc.icov_131                           float64\n",
      " 1434  lowlevel.gfcc.icov_132                           float64\n",
      " 1435  lowlevel.gfcc.icov_133                           float64\n",
      " 1436  lowlevel.gfcc.icov_134                           float64\n",
      " 1437  lowlevel.gfcc.icov_135                           float64\n",
      " 1438  lowlevel.gfcc.icov_136                           float64\n",
      " 1439  lowlevel.gfcc.icov_137                           float64\n",
      " 1440  lowlevel.gfcc.icov_138                           float64\n",
      " 1441  lowlevel.gfcc.icov_139                           float64\n",
      " 1442  lowlevel.gfcc.icov_140                           float64\n",
      " 1443  lowlevel.gfcc.icov_141                           float64\n",
      " 1444  lowlevel.gfcc.icov_142                           float64\n",
      " 1445  lowlevel.gfcc.icov_143                           float64\n",
      " 1446  lowlevel.gfcc.icov_144                           float64\n",
      " 1447  lowlevel.gfcc.icov_145                           float64\n",
      " 1448  lowlevel.gfcc.icov_146                           float64\n",
      " 1449  lowlevel.gfcc.icov_147                           float64\n",
      " 1450  lowlevel.gfcc.icov_148                           float64\n",
      " 1451  lowlevel.gfcc.icov_149                           float64\n",
      " 1452  lowlevel.gfcc.icov_150                           float64\n",
      " 1453  lowlevel.gfcc.icov_151                           float64\n",
      " 1454  lowlevel.gfcc.icov_152                           float64\n",
      " 1455  lowlevel.gfcc.icov_153                           float64\n",
      " 1456  lowlevel.gfcc.icov_154                           float64\n",
      " 1457  lowlevel.gfcc.icov_155                           float64\n",
      " 1458  lowlevel.gfcc.icov_156                           float64\n",
      " 1459  lowlevel.gfcc.icov_157                           float64\n",
      " 1460  lowlevel.gfcc.icov_158                           float64\n",
      " 1461  lowlevel.gfcc.icov_159                           float64\n",
      " 1462  lowlevel.gfcc.icov_160                           float64\n",
      " 1463  lowlevel.gfcc.icov_161                           float64\n",
      " 1464  lowlevel.gfcc.icov_162                           float64\n",
      " 1465  lowlevel.gfcc.icov_163                           float64\n",
      " 1466  lowlevel.gfcc.icov_164                           float64\n",
      " 1467  lowlevel.gfcc.icov_165                           float64\n",
      " 1468  lowlevel.gfcc.icov_166                           float64\n",
      " 1469  lowlevel.gfcc.icov_167                           float64\n",
      " 1470  lowlevel.gfcc.icov_168                           float64\n",
      " 1471  lowlevel.gfcc.mean_0                             float64\n",
      " 1472  lowlevel.gfcc.mean_1                             float64\n",
      " 1473  lowlevel.gfcc.mean_2                             float64\n",
      " 1474  lowlevel.gfcc.mean_3                             float64\n",
      " 1475  lowlevel.gfcc.mean_4                             float64\n",
      " 1476  lowlevel.gfcc.mean_5                             float64\n",
      " 1477  lowlevel.gfcc.mean_6                             float64\n",
      " 1478  lowlevel.gfcc.mean_7                             float64\n",
      " 1479  lowlevel.gfcc.mean_8                             float64\n",
      " 1480  lowlevel.gfcc.mean_9                             float64\n",
      " 1481  lowlevel.gfcc.mean_10                            float64\n",
      " 1482  lowlevel.gfcc.mean_11                            float64\n",
      " 1483  lowlevel.gfcc.mean_12                            float64\n",
      " 1484  lowlevel.melbands.dmean_0                        float64\n",
      " 1485  lowlevel.melbands.dmean_1                        float64\n",
      " 1486  lowlevel.melbands.dmean_2                        float64\n",
      " 1487  lowlevel.melbands.dmean_3                        float64\n",
      " 1488  lowlevel.melbands.dmean_4                        float64\n",
      " 1489  lowlevel.melbands.dmean_5                        float64\n",
      " 1490  lowlevel.melbands.dmean_6                        float64\n",
      " 1491  lowlevel.melbands.dmean_7                        float64\n",
      " 1492  lowlevel.melbands.dmean_8                        float64\n",
      " 1493  lowlevel.melbands.dmean_9                        float64\n",
      " 1494  lowlevel.melbands.dmean_10                       float64\n",
      " 1495  lowlevel.melbands.dmean_11                       float64\n",
      " 1496  lowlevel.melbands.dmean_12                       float64\n",
      " 1497  lowlevel.melbands.dmean_13                       float64\n",
      " 1498  lowlevel.melbands.dmean_14                       float64\n",
      " 1499  lowlevel.melbands.dmean_15                       float64\n",
      " 1500  lowlevel.melbands.dmean_16                       float64\n",
      " 1501  lowlevel.melbands.dmean_17                       float64\n",
      " 1502  lowlevel.melbands.dmean_18                       float64\n",
      " 1503  lowlevel.melbands.dmean_19                       float64\n",
      " 1504  lowlevel.melbands.dmean_20                       float64\n",
      " 1505  lowlevel.melbands.dmean_21                       float64\n",
      " 1506  lowlevel.melbands.dmean_22                       float64\n",
      " 1507  lowlevel.melbands.dmean_23                       float64\n",
      " 1508  lowlevel.melbands.dmean_24                       float64\n",
      " 1509  lowlevel.melbands.dmean_25                       float64\n",
      " 1510  lowlevel.melbands.dmean_26                       float64\n",
      " 1511  lowlevel.melbands.dmean_27                       float64\n",
      " 1512  lowlevel.melbands.dmean_28                       float64\n",
      " 1513  lowlevel.melbands.dmean_29                       float64\n",
      " 1514  lowlevel.melbands.dmean_30                       float64\n",
      " 1515  lowlevel.melbands.dmean_31                       float64\n",
      " 1516  lowlevel.melbands.dmean_32                       float64\n",
      " 1517  lowlevel.melbands.dmean_33                       float64\n",
      " 1518  lowlevel.melbands.dmean_34                       float64\n",
      " 1519  lowlevel.melbands.dmean_35                       float64\n",
      " 1520  lowlevel.melbands.dmean_36                       float64\n",
      " 1521  lowlevel.melbands.dmean_37                       float64\n",
      " 1522  lowlevel.melbands.dmean_38                       float64\n",
      " 1523  lowlevel.melbands.dmean_39                       float64\n",
      " 1524  lowlevel.melbands.dmean2_0                       float64\n",
      " 1525  lowlevel.melbands.dmean2_1                       float64\n",
      " 1526  lowlevel.melbands.dmean2_2                       float64\n",
      " 1527  lowlevel.melbands.dmean2_3                       float64\n",
      " 1528  lowlevel.melbands.dmean2_4                       float64\n",
      " 1529  lowlevel.melbands.dmean2_5                       float64\n",
      " 1530  lowlevel.melbands.dmean2_6                       float64\n",
      " 1531  lowlevel.melbands.dmean2_7                       float64\n",
      " 1532  lowlevel.melbands.dmean2_8                       float64\n",
      " 1533  lowlevel.melbands.dmean2_9                       float64\n",
      " 1534  lowlevel.melbands.dmean2_10                      float64\n",
      " 1535  lowlevel.melbands.dmean2_11                      float64\n",
      " 1536  lowlevel.melbands.dmean2_12                      float64\n",
      " 1537  lowlevel.melbands.dmean2_13                      float64\n",
      " 1538  lowlevel.melbands.dmean2_14                      float64\n",
      " 1539  lowlevel.melbands.dmean2_15                      float64\n",
      " 1540  lowlevel.melbands.dmean2_16                      float64\n",
      " 1541  lowlevel.melbands.dmean2_17                      float64\n",
      " 1542  lowlevel.melbands.dmean2_18                      float64\n",
      " 1543  lowlevel.melbands.dmean2_19                      float64\n",
      " 1544  lowlevel.melbands.dmean2_20                      float64\n",
      " 1545  lowlevel.melbands.dmean2_21                      float64\n",
      " 1546  lowlevel.melbands.dmean2_22                      float64\n",
      " 1547  lowlevel.melbands.dmean2_23                      float64\n",
      " 1548  lowlevel.melbands.dmean2_24                      float64\n",
      " 1549  lowlevel.melbands.dmean2_25                      float64\n",
      " 1550  lowlevel.melbands.dmean2_26                      float64\n",
      " 1551  lowlevel.melbands.dmean2_27                      float64\n",
      " 1552  lowlevel.melbands.dmean2_28                      float64\n",
      " 1553  lowlevel.melbands.dmean2_29                      float64\n",
      " 1554  lowlevel.melbands.dmean2_30                      float64\n",
      " 1555  lowlevel.melbands.dmean2_31                      float64\n",
      " 1556  lowlevel.melbands.dmean2_32                      float64\n",
      " 1557  lowlevel.melbands.dmean2_33                      float64\n",
      " 1558  lowlevel.melbands.dmean2_34                      float64\n",
      " 1559  lowlevel.melbands.dmean2_35                      float64\n",
      " 1560  lowlevel.melbands.dmean2_36                      float64\n",
      " 1561  lowlevel.melbands.dmean2_37                      float64\n",
      " 1562  lowlevel.melbands.dmean2_38                      float64\n",
      " 1563  lowlevel.melbands.dmean2_39                      float64\n",
      " 1564  lowlevel.melbands.dvar_0                         float64\n",
      " 1565  lowlevel.melbands.dvar_1                         float64\n",
      " 1566  lowlevel.melbands.dvar_2                         float64\n",
      " 1567  lowlevel.melbands.dvar_3                         float64\n",
      " 1568  lowlevel.melbands.dvar_4                         float64\n",
      " 1569  lowlevel.melbands.dvar_5                         float64\n",
      " 1570  lowlevel.melbands.dvar_6                         float64\n",
      " 1571  lowlevel.melbands.dvar_7                         float64\n",
      " 1572  lowlevel.melbands.dvar_8                         float64\n",
      " 1573  lowlevel.melbands.dvar_9                         float64\n",
      " 1574  lowlevel.melbands.dvar_10                        float64\n",
      " 1575  lowlevel.melbands.dvar_11                        float64\n",
      " 1576  lowlevel.melbands.dvar_12                        float64\n",
      " 1577  lowlevel.melbands.dvar_13                        float64\n",
      " 1578  lowlevel.melbands.dvar_14                        float64\n",
      " 1579  lowlevel.melbands.dvar_15                        float64\n",
      " 1580  lowlevel.melbands.dvar_16                        float64\n",
      " 1581  lowlevel.melbands.dvar_17                        float64\n",
      " 1582  lowlevel.melbands.dvar_18                        float64\n",
      " 1583  lowlevel.melbands.dvar_19                        float64\n",
      " 1584  lowlevel.melbands.dvar_20                        float64\n",
      " 1585  lowlevel.melbands.dvar_21                        float64\n",
      " 1586  lowlevel.melbands.dvar_22                        float64\n",
      " 1587  lowlevel.melbands.dvar_23                        float64\n",
      " 1588  lowlevel.melbands.dvar_24                        float64\n",
      " 1589  lowlevel.melbands.dvar_25                        float64\n",
      " 1590  lowlevel.melbands.dvar_26                        float64\n",
      " 1591  lowlevel.melbands.dvar_27                        float64\n",
      " 1592  lowlevel.melbands.dvar_28                        float64\n",
      " 1593  lowlevel.melbands.dvar_29                        float64\n",
      " 1594  lowlevel.melbands.dvar_30                        float64\n",
      " 1595  lowlevel.melbands.dvar_31                        float64\n",
      " 1596  lowlevel.melbands.dvar_32                        float64\n",
      " 1597  lowlevel.melbands.dvar_33                        float64\n",
      " 1598  lowlevel.melbands.dvar_34                        float64\n",
      " 1599  lowlevel.melbands.dvar_35                        float64\n",
      " 1600  lowlevel.melbands.dvar_36                        float64\n",
      " 1601  lowlevel.melbands.dvar_37                        float64\n",
      " 1602  lowlevel.melbands.dvar_38                        float64\n",
      " 1603  lowlevel.melbands.dvar_39                        float64\n",
      " 1604  lowlevel.melbands.dvar2_0                        float64\n",
      " 1605  lowlevel.melbands.dvar2_1                        float64\n",
      " 1606  lowlevel.melbands.dvar2_2                        float64\n",
      " 1607  lowlevel.melbands.dvar2_3                        float64\n",
      " 1608  lowlevel.melbands.dvar2_4                        float64\n",
      " 1609  lowlevel.melbands.dvar2_5                        float64\n",
      " 1610  lowlevel.melbands.dvar2_6                        float64\n",
      " 1611  lowlevel.melbands.dvar2_7                        float64\n",
      " 1612  lowlevel.melbands.dvar2_8                        float64\n",
      " 1613  lowlevel.melbands.dvar2_9                        float64\n",
      " 1614  lowlevel.melbands.dvar2_10                       float64\n",
      " 1615  lowlevel.melbands.dvar2_11                       float64\n",
      " 1616  lowlevel.melbands.dvar2_12                       float64\n",
      " 1617  lowlevel.melbands.dvar2_13                       float64\n",
      " 1618  lowlevel.melbands.dvar2_14                       float64\n",
      " 1619  lowlevel.melbands.dvar2_15                       float64\n",
      " 1620  lowlevel.melbands.dvar2_16                       float64\n",
      " 1621  lowlevel.melbands.dvar2_17                       float64\n",
      " 1622  lowlevel.melbands.dvar2_18                       float64\n",
      " 1623  lowlevel.melbands.dvar2_19                       float64\n",
      " 1624  lowlevel.melbands.dvar2_20                       float64\n",
      " 1625  lowlevel.melbands.dvar2_21                       float64\n",
      " 1626  lowlevel.melbands.dvar2_22                       float64\n",
      " 1627  lowlevel.melbands.dvar2_23                       float64\n",
      " 1628  lowlevel.melbands.dvar2_24                       float64\n",
      " 1629  lowlevel.melbands.dvar2_25                       float64\n",
      " 1630  lowlevel.melbands.dvar2_26                       float64\n",
      " 1631  lowlevel.melbands.dvar2_27                       float64\n",
      " 1632  lowlevel.melbands.dvar2_28                       float64\n",
      " 1633  lowlevel.melbands.dvar2_29                       float64\n",
      " 1634  lowlevel.melbands.dvar2_30                       float64\n",
      " 1635  lowlevel.melbands.dvar2_31                       float64\n",
      " 1636  lowlevel.melbands.dvar2_32                       float64\n",
      " 1637  lowlevel.melbands.dvar2_33                       float64\n",
      " 1638  lowlevel.melbands.dvar2_34                       float64\n",
      " 1639  lowlevel.melbands.dvar2_35                       float64\n",
      " 1640  lowlevel.melbands.dvar2_36                       float64\n",
      " 1641  lowlevel.melbands.dvar2_37                       float64\n",
      " 1642  lowlevel.melbands.dvar2_38                       float64\n",
      " 1643  lowlevel.melbands.dvar2_39                       float64\n",
      " 1644  lowlevel.melbands.max_0                          float64\n",
      " 1645  lowlevel.melbands.max_1                          float64\n",
      " 1646  lowlevel.melbands.max_2                          float64\n",
      " 1647  lowlevel.melbands.max_3                          float64\n",
      " 1648  lowlevel.melbands.max_4                          float64\n",
      " 1649  lowlevel.melbands.max_5                          float64\n",
      " 1650  lowlevel.melbands.max_6                          float64\n",
      " 1651  lowlevel.melbands.max_7                          float64\n",
      " 1652  lowlevel.melbands.max_8                          float64\n",
      " 1653  lowlevel.melbands.max_9                          float64\n",
      " 1654  lowlevel.melbands.max_10                         float64\n",
      " 1655  lowlevel.melbands.max_11                         float64\n",
      " 1656  lowlevel.melbands.max_12                         float64\n",
      " 1657  lowlevel.melbands.max_13                         float64\n",
      " 1658  lowlevel.melbands.max_14                         float64\n",
      " 1659  lowlevel.melbands.max_15                         float64\n",
      " 1660  lowlevel.melbands.max_16                         float64\n",
      " 1661  lowlevel.melbands.max_17                         float64\n",
      " 1662  lowlevel.melbands.max_18                         float64\n",
      " 1663  lowlevel.melbands.max_19                         float64\n",
      " 1664  lowlevel.melbands.max_20                         float64\n",
      " 1665  lowlevel.melbands.max_21                         float64\n",
      " 1666  lowlevel.melbands.max_22                         float64\n",
      " 1667  lowlevel.melbands.max_23                         float64\n",
      " 1668  lowlevel.melbands.max_24                         float64\n",
      " 1669  lowlevel.melbands.max_25                         float64\n",
      " 1670  lowlevel.melbands.max_26                         float64\n",
      " 1671  lowlevel.melbands.max_27                         float64\n",
      " 1672  lowlevel.melbands.max_28                         float64\n",
      " 1673  lowlevel.melbands.max_29                         float64\n",
      " 1674  lowlevel.melbands.max_30                         float64\n",
      " 1675  lowlevel.melbands.max_31                         float64\n",
      " 1676  lowlevel.melbands.max_32                         float64\n",
      " 1677  lowlevel.melbands.max_33                         float64\n",
      " 1678  lowlevel.melbands.max_34                         float64\n",
      " 1679  lowlevel.melbands.max_35                         float64\n",
      " 1680  lowlevel.melbands.max_36                         float64\n",
      " 1681  lowlevel.melbands.max_37                         float64\n",
      " 1682  lowlevel.melbands.max_38                         float64\n",
      " 1683  lowlevel.melbands.max_39                         float64\n",
      " 1684  lowlevel.melbands.mean_0                         float64\n",
      " 1685  lowlevel.melbands.mean_1                         float64\n",
      " 1686  lowlevel.melbands.mean_2                         float64\n",
      " 1687  lowlevel.melbands.mean_3                         float64\n",
      " 1688  lowlevel.melbands.mean_4                         float64\n",
      " 1689  lowlevel.melbands.mean_5                         float64\n",
      " 1690  lowlevel.melbands.mean_6                         float64\n",
      " 1691  lowlevel.melbands.mean_7                         float64\n",
      " 1692  lowlevel.melbands.mean_8                         float64\n",
      " 1693  lowlevel.melbands.mean_9                         float64\n",
      " 1694  lowlevel.melbands.mean_10                        float64\n",
      " 1695  lowlevel.melbands.mean_11                        float64\n",
      " 1696  lowlevel.melbands.mean_12                        float64\n",
      " 1697  lowlevel.melbands.mean_13                        float64\n",
      " 1698  lowlevel.melbands.mean_14                        float64\n",
      " 1699  lowlevel.melbands.mean_15                        float64\n",
      " 1700  lowlevel.melbands.mean_16                        float64\n",
      " 1701  lowlevel.melbands.mean_17                        float64\n",
      " 1702  lowlevel.melbands.mean_18                        float64\n",
      " 1703  lowlevel.melbands.mean_19                        float64\n",
      " 1704  lowlevel.melbands.mean_20                        float64\n",
      " 1705  lowlevel.melbands.mean_21                        float64\n",
      " 1706  lowlevel.melbands.mean_22                        float64\n",
      " 1707  lowlevel.melbands.mean_23                        float64\n",
      " 1708  lowlevel.melbands.mean_24                        float64\n",
      " 1709  lowlevel.melbands.mean_25                        float64\n",
      " 1710  lowlevel.melbands.mean_26                        float64\n",
      " 1711  lowlevel.melbands.mean_27                        float64\n",
      " 1712  lowlevel.melbands.mean_28                        float64\n",
      " 1713  lowlevel.melbands.mean_29                        float64\n",
      " 1714  lowlevel.melbands.mean_30                        float64\n",
      " 1715  lowlevel.melbands.mean_31                        float64\n",
      " 1716  lowlevel.melbands.mean_32                        float64\n",
      " 1717  lowlevel.melbands.mean_33                        float64\n",
      " 1718  lowlevel.melbands.mean_34                        float64\n",
      " 1719  lowlevel.melbands.mean_35                        float64\n",
      " 1720  lowlevel.melbands.mean_36                        float64\n",
      " 1721  lowlevel.melbands.mean_37                        float64\n",
      " 1722  lowlevel.melbands.mean_38                        float64\n",
      " 1723  lowlevel.melbands.mean_39                        float64\n",
      " 1724  lowlevel.melbands.median_0                       float64\n",
      " 1725  lowlevel.melbands.median_1                       float64\n",
      " 1726  lowlevel.melbands.median_2                       float64\n",
      " 1727  lowlevel.melbands.median_3                       float64\n",
      " 1728  lowlevel.melbands.median_4                       float64\n",
      " 1729  lowlevel.melbands.median_5                       float64\n",
      " 1730  lowlevel.melbands.median_6                       float64\n",
      " 1731  lowlevel.melbands.median_7                       float64\n",
      " 1732  lowlevel.melbands.median_8                       float64\n",
      " 1733  lowlevel.melbands.median_9                       float64\n",
      " 1734  lowlevel.melbands.median_10                      float64\n",
      " 1735  lowlevel.melbands.median_11                      float64\n",
      " 1736  lowlevel.melbands.median_12                      float64\n",
      " 1737  lowlevel.melbands.median_13                      float64\n",
      " 1738  lowlevel.melbands.median_14                      float64\n",
      " 1739  lowlevel.melbands.median_15                      float64\n",
      " 1740  lowlevel.melbands.median_16                      float64\n",
      " 1741  lowlevel.melbands.median_17                      float64\n",
      " 1742  lowlevel.melbands.median_18                      float64\n",
      " 1743  lowlevel.melbands.median_19                      float64\n",
      " 1744  lowlevel.melbands.median_20                      float64\n",
      " 1745  lowlevel.melbands.median_21                      float64\n",
      " 1746  lowlevel.melbands.median_22                      float64\n",
      " 1747  lowlevel.melbands.median_23                      float64\n",
      " 1748  lowlevel.melbands.median_24                      float64\n",
      " 1749  lowlevel.melbands.median_25                      float64\n",
      " 1750  lowlevel.melbands.median_26                      float64\n",
      " 1751  lowlevel.melbands.median_27                      float64\n",
      " 1752  lowlevel.melbands.median_28                      float64\n",
      " 1753  lowlevel.melbands.median_29                      float64\n",
      " 1754  lowlevel.melbands.median_30                      float64\n",
      " 1755  lowlevel.melbands.median_31                      float64\n",
      " 1756  lowlevel.melbands.median_32                      float64\n",
      " 1757  lowlevel.melbands.median_33                      float64\n",
      " 1758  lowlevel.melbands.median_34                      float64\n",
      " 1759  lowlevel.melbands.median_35                      float64\n",
      " 1760  lowlevel.melbands.median_36                      float64\n",
      " 1761  lowlevel.melbands.median_37                      float64\n",
      " 1762  lowlevel.melbands.median_38                      float64\n",
      " 1763  lowlevel.melbands.median_39                      float64\n",
      " 1764  lowlevel.melbands.min_0                          float64\n",
      " 1765  lowlevel.melbands.min_1                          float64\n",
      " 1766  lowlevel.melbands.min_2                          float64\n",
      " 1767  lowlevel.melbands.min_3                          float64\n",
      " 1768  lowlevel.melbands.min_4                          float64\n",
      " 1769  lowlevel.melbands.min_5                          float64\n",
      " 1770  lowlevel.melbands.min_6                          float64\n",
      " 1771  lowlevel.melbands.min_7                          float64\n",
      " 1772  lowlevel.melbands.min_8                          float64\n",
      " 1773  lowlevel.melbands.min_9                          float64\n",
      " 1774  lowlevel.melbands.min_10                         float64\n",
      " 1775  lowlevel.melbands.min_11                         float64\n",
      " 1776  lowlevel.melbands.min_12                         float64\n",
      " 1777  lowlevel.melbands.min_13                         float64\n",
      " 1778  lowlevel.melbands.min_14                         float64\n",
      " 1779  lowlevel.melbands.min_15                         float64\n",
      " 1780  lowlevel.melbands.min_16                         float64\n",
      " 1781  lowlevel.melbands.min_17                         float64\n",
      " 1782  lowlevel.melbands.min_18                         float64\n",
      " 1783  lowlevel.melbands.min_19                         float64\n",
      " 1784  lowlevel.melbands.min_20                         float64\n",
      " 1785  lowlevel.melbands.min_21                         float64\n",
      " 1786  lowlevel.melbands.min_22                         float64\n",
      " 1787  lowlevel.melbands.min_23                         float64\n",
      " 1788  lowlevel.melbands.min_24                         float64\n",
      " 1789  lowlevel.melbands.min_25                         float64\n",
      " 1790  lowlevel.melbands.min_26                         float64\n",
      " 1791  lowlevel.melbands.min_27                         float64\n",
      " 1792  lowlevel.melbands.min_28                         float64\n",
      " 1793  lowlevel.melbands.min_29                         float64\n",
      " 1794  lowlevel.melbands.min_30                         float64\n",
      " 1795  lowlevel.melbands.min_31                         float64\n",
      " 1796  lowlevel.melbands.min_32                         float64\n",
      " 1797  lowlevel.melbands.min_33                         float64\n",
      " 1798  lowlevel.melbands.min_34                         float64\n",
      " 1799  lowlevel.melbands.min_35                         float64\n",
      " 1800  lowlevel.melbands.min_36                         float64\n",
      " 1801  lowlevel.melbands.min_37                         float64\n",
      " 1802  lowlevel.melbands.min_38                         float64\n",
      " 1803  lowlevel.melbands.min_39                         float64\n",
      " 1804  lowlevel.melbands.stdev_0                        float64\n",
      " 1805  lowlevel.melbands.stdev_1                        float64\n",
      " 1806  lowlevel.melbands.stdev_2                        float64\n",
      " 1807  lowlevel.melbands.stdev_3                        float64\n",
      " 1808  lowlevel.melbands.stdev_4                        float64\n",
      " 1809  lowlevel.melbands.stdev_5                        float64\n",
      " 1810  lowlevel.melbands.stdev_6                        float64\n",
      " 1811  lowlevel.melbands.stdev_7                        float64\n",
      " 1812  lowlevel.melbands.stdev_8                        float64\n",
      " 1813  lowlevel.melbands.stdev_9                        float64\n",
      " 1814  lowlevel.melbands.stdev_10                       float64\n",
      " 1815  lowlevel.melbands.stdev_11                       float64\n",
      " 1816  lowlevel.melbands.stdev_12                       float64\n",
      " 1817  lowlevel.melbands.stdev_13                       float64\n",
      " 1818  lowlevel.melbands.stdev_14                       float64\n",
      " 1819  lowlevel.melbands.stdev_15                       float64\n",
      " 1820  lowlevel.melbands.stdev_16                       float64\n",
      " 1821  lowlevel.melbands.stdev_17                       float64\n",
      " 1822  lowlevel.melbands.stdev_18                       float64\n",
      " 1823  lowlevel.melbands.stdev_19                       float64\n",
      " 1824  lowlevel.melbands.stdev_20                       float64\n",
      " 1825  lowlevel.melbands.stdev_21                       float64\n",
      " 1826  lowlevel.melbands.stdev_22                       float64\n",
      " 1827  lowlevel.melbands.stdev_23                       float64\n",
      " 1828  lowlevel.melbands.stdev_24                       float64\n",
      " 1829  lowlevel.melbands.stdev_25                       float64\n",
      " 1830  lowlevel.melbands.stdev_26                       float64\n",
      " 1831  lowlevel.melbands.stdev_27                       float64\n",
      " 1832  lowlevel.melbands.stdev_28                       float64\n",
      " 1833  lowlevel.melbands.stdev_29                       float64\n",
      " 1834  lowlevel.melbands.stdev_30                       float64\n",
      " 1835  lowlevel.melbands.stdev_31                       float64\n",
      " 1836  lowlevel.melbands.stdev_32                       float64\n",
      " 1837  lowlevel.melbands.stdev_33                       float64\n",
      " 1838  lowlevel.melbands.stdev_34                       float64\n",
      " 1839  lowlevel.melbands.stdev_35                       float64\n",
      " 1840  lowlevel.melbands.stdev_36                       float64\n",
      " 1841  lowlevel.melbands.stdev_37                       float64\n",
      " 1842  lowlevel.melbands.stdev_38                       float64\n",
      " 1843  lowlevel.melbands.stdev_39                       float64\n",
      " 1844  lowlevel.melbands.var_0                          float64\n",
      " 1845  lowlevel.melbands.var_1                          float64\n",
      " 1846  lowlevel.melbands.var_2                          float64\n",
      " 1847  lowlevel.melbands.var_3                          float64\n",
      " 1848  lowlevel.melbands.var_4                          float64\n",
      " 1849  lowlevel.melbands.var_5                          float64\n",
      " 1850  lowlevel.melbands.var_6                          float64\n",
      " 1851  lowlevel.melbands.var_7                          float64\n",
      " 1852  lowlevel.melbands.var_8                          float64\n",
      " 1853  lowlevel.melbands.var_9                          float64\n",
      " 1854  lowlevel.melbands.var_10                         float64\n",
      " 1855  lowlevel.melbands.var_11                         float64\n",
      " 1856  lowlevel.melbands.var_12                         float64\n",
      " 1857  lowlevel.melbands.var_13                         float64\n",
      " 1858  lowlevel.melbands.var_14                         float64\n",
      " 1859  lowlevel.melbands.var_15                         float64\n",
      " 1860  lowlevel.melbands.var_16                         float64\n",
      " 1861  lowlevel.melbands.var_17                         float64\n",
      " 1862  lowlevel.melbands.var_18                         float64\n",
      " 1863  lowlevel.melbands.var_19                         float64\n",
      " 1864  lowlevel.melbands.var_20                         float64\n",
      " 1865  lowlevel.melbands.var_21                         float64\n",
      " 1866  lowlevel.melbands.var_22                         float64\n",
      " 1867  lowlevel.melbands.var_23                         float64\n",
      " 1868  lowlevel.melbands.var_24                         float64\n",
      " 1869  lowlevel.melbands.var_25                         float64\n",
      " 1870  lowlevel.melbands.var_26                         float64\n",
      " 1871  lowlevel.melbands.var_27                         float64\n",
      " 1872  lowlevel.melbands.var_28                         float64\n",
      " 1873  lowlevel.melbands.var_29                         float64\n",
      " 1874  lowlevel.melbands.var_30                         float64\n",
      " 1875  lowlevel.melbands.var_31                         float64\n",
      " 1876  lowlevel.melbands.var_32                         float64\n",
      " 1877  lowlevel.melbands.var_33                         float64\n",
      " 1878  lowlevel.melbands.var_34                         float64\n",
      " 1879  lowlevel.melbands.var_35                         float64\n",
      " 1880  lowlevel.melbands.var_36                         float64\n",
      " 1881  lowlevel.melbands.var_37                         float64\n",
      " 1882  lowlevel.melbands.var_38                         float64\n",
      " 1883  lowlevel.melbands.var_39                         float64\n",
      " 1884  lowlevel.melbands128.dmean_0                     float64\n",
      " 1885  lowlevel.melbands128.dmean_1                     float64\n",
      " 1886  lowlevel.melbands128.dmean_2                     float64\n",
      " 1887  lowlevel.melbands128.dmean_3                     float64\n",
      " 1888  lowlevel.melbands128.dmean_4                     float64\n",
      " 1889  lowlevel.melbands128.dmean_5                     float64\n",
      " 1890  lowlevel.melbands128.dmean_6                     float64\n",
      " 1891  lowlevel.melbands128.dmean_7                     float64\n",
      " 1892  lowlevel.melbands128.dmean_8                     float64\n",
      " 1893  lowlevel.melbands128.dmean_9                     float64\n",
      " 1894  lowlevel.melbands128.dmean_10                    float64\n",
      " 1895  lowlevel.melbands128.dmean_11                    float64\n",
      " 1896  lowlevel.melbands128.dmean_12                    float64\n",
      " 1897  lowlevel.melbands128.dmean_13                    float64\n",
      " 1898  lowlevel.melbands128.dmean_14                    float64\n",
      " 1899  lowlevel.melbands128.dmean_15                    float64\n",
      " 1900  lowlevel.melbands128.dmean_16                    float64\n",
      " 1901  lowlevel.melbands128.dmean_17                    float64\n",
      " 1902  lowlevel.melbands128.dmean_18                    float64\n",
      " 1903  lowlevel.melbands128.dmean_19                    float64\n",
      " 1904  lowlevel.melbands128.dmean_20                    float64\n",
      " 1905  lowlevel.melbands128.dmean_21                    float64\n",
      " 1906  lowlevel.melbands128.dmean_22                    float64\n",
      " 1907  lowlevel.melbands128.dmean_23                    float64\n",
      " 1908  lowlevel.melbands128.dmean_24                    float64\n",
      " 1909  lowlevel.melbands128.dmean_25                    float64\n",
      " 1910  lowlevel.melbands128.dmean_26                    float64\n",
      " 1911  lowlevel.melbands128.dmean_27                    float64\n",
      " 1912  lowlevel.melbands128.dmean_28                    float64\n",
      " 1913  lowlevel.melbands128.dmean_29                    float64\n",
      " 1914  lowlevel.melbands128.dmean_30                    float64\n",
      " 1915  lowlevel.melbands128.dmean_31                    float64\n",
      " 1916  lowlevel.melbands128.dmean_32                    float64\n",
      " 1917  lowlevel.melbands128.dmean_33                    float64\n",
      " 1918  lowlevel.melbands128.dmean_34                    float64\n",
      " 1919  lowlevel.melbands128.dmean_35                    float64\n",
      " 1920  lowlevel.melbands128.dmean_36                    float64\n",
      " 1921  lowlevel.melbands128.dmean_37                    float64\n",
      " 1922  lowlevel.melbands128.dmean_38                    float64\n",
      " 1923  lowlevel.melbands128.dmean_39                    float64\n",
      " 1924  lowlevel.melbands128.dmean_40                    float64\n",
      " 1925  lowlevel.melbands128.dmean_41                    float64\n",
      " 1926  lowlevel.melbands128.dmean_42                    float64\n",
      " 1927  lowlevel.melbands128.dmean_43                    float64\n",
      " 1928  lowlevel.melbands128.dmean_44                    float64\n",
      " 1929  lowlevel.melbands128.dmean_45                    float64\n",
      " 1930  lowlevel.melbands128.dmean_46                    float64\n",
      " 1931  lowlevel.melbands128.dmean_47                    float64\n",
      " 1932  lowlevel.melbands128.dmean_48                    float64\n",
      " 1933  lowlevel.melbands128.dmean_49                    float64\n",
      " 1934  lowlevel.melbands128.dmean_50                    float64\n",
      " 1935  lowlevel.melbands128.dmean_51                    float64\n",
      " 1936  lowlevel.melbands128.dmean_52                    float64\n",
      " 1937  lowlevel.melbands128.dmean_53                    float64\n",
      " 1938  lowlevel.melbands128.dmean_54                    float64\n",
      " 1939  lowlevel.melbands128.dmean_55                    float64\n",
      " 1940  lowlevel.melbands128.dmean_56                    float64\n",
      " 1941  lowlevel.melbands128.dmean_57                    float64\n",
      " 1942  lowlevel.melbands128.dmean_58                    float64\n",
      " 1943  lowlevel.melbands128.dmean_59                    float64\n",
      " 1944  lowlevel.melbands128.dmean_60                    float64\n",
      " 1945  lowlevel.melbands128.dmean_61                    float64\n",
      " 1946  lowlevel.melbands128.dmean_62                    float64\n",
      " 1947  lowlevel.melbands128.dmean_63                    float64\n",
      " 1948  lowlevel.melbands128.dmean_64                    float64\n",
      " 1949  lowlevel.melbands128.dmean_65                    float64\n",
      " 1950  lowlevel.melbands128.dmean_66                    float64\n",
      " 1951  lowlevel.melbands128.dmean_67                    float64\n",
      " 1952  lowlevel.melbands128.dmean_68                    float64\n",
      " 1953  lowlevel.melbands128.dmean_69                    float64\n",
      " 1954  lowlevel.melbands128.dmean_70                    float64\n",
      " 1955  lowlevel.melbands128.dmean_71                    float64\n",
      " 1956  lowlevel.melbands128.dmean_72                    float64\n",
      " 1957  lowlevel.melbands128.dmean_73                    float64\n",
      " 1958  lowlevel.melbands128.dmean_74                    float64\n",
      " 1959  lowlevel.melbands128.dmean_75                    float64\n",
      " 1960  lowlevel.melbands128.dmean_76                    float64\n",
      " 1961  lowlevel.melbands128.dmean_77                    float64\n",
      " 1962  lowlevel.melbands128.dmean_78                    float64\n",
      " 1963  lowlevel.melbands128.dmean_79                    float64\n",
      " 1964  lowlevel.melbands128.dmean_80                    float64\n",
      " 1965  lowlevel.melbands128.dmean_81                    float64\n",
      " 1966  lowlevel.melbands128.dmean_82                    float64\n",
      " 1967  lowlevel.melbands128.dmean_83                    float64\n",
      " 1968  lowlevel.melbands128.dmean_84                    float64\n",
      " 1969  lowlevel.melbands128.dmean_85                    float64\n",
      " 1970  lowlevel.melbands128.dmean_86                    float64\n",
      " 1971  lowlevel.melbands128.dmean_87                    float64\n",
      " 1972  lowlevel.melbands128.dmean_88                    float64\n",
      " 1973  lowlevel.melbands128.dmean_89                    float64\n",
      " 1974  lowlevel.melbands128.dmean_90                    float64\n",
      " 1975  lowlevel.melbands128.dmean_91                    float64\n",
      " 1976  lowlevel.melbands128.dmean_92                    float64\n",
      " 1977  lowlevel.melbands128.dmean_93                    float64\n",
      " 1978  lowlevel.melbands128.dmean_94                    float64\n",
      " 1979  lowlevel.melbands128.dmean_95                    float64\n",
      " 1980  lowlevel.melbands128.dmean_96                    float64\n",
      " 1981  lowlevel.melbands128.dmean_97                    float64\n",
      " 1982  lowlevel.melbands128.dmean_98                    float64\n",
      " 1983  lowlevel.melbands128.dmean_99                    float64\n",
      " 1984  lowlevel.melbands128.dmean_100                   float64\n",
      " 1985  lowlevel.melbands128.dmean_101                   float64\n",
      " 1986  lowlevel.melbands128.dmean_102                   float64\n",
      " 1987  lowlevel.melbands128.dmean_103                   float64\n",
      " 1988  lowlevel.melbands128.dmean_104                   float64\n",
      " 1989  lowlevel.melbands128.dmean_105                   float64\n",
      " 1990  lowlevel.melbands128.dmean_106                   float64\n",
      " 1991  lowlevel.melbands128.dmean_107                   float64\n",
      " 1992  lowlevel.melbands128.dmean_108                   float64\n",
      " 1993  lowlevel.melbands128.dmean_109                   float64\n",
      " 1994  lowlevel.melbands128.dmean_110                   float64\n",
      " 1995  lowlevel.melbands128.dmean_111                   float64\n",
      " 1996  lowlevel.melbands128.dmean_112                   float64\n",
      " 1997  lowlevel.melbands128.dmean_113                   float64\n",
      " 1998  lowlevel.melbands128.dmean_114                   float64\n",
      " 1999  lowlevel.melbands128.dmean_115                   float64\n",
      " 2000  lowlevel.melbands128.dmean_116                   float64\n",
      " 2001  lowlevel.melbands128.dmean_117                   float64\n",
      " 2002  lowlevel.melbands128.dmean_118                   float64\n",
      " 2003  lowlevel.melbands128.dmean_119                   float64\n",
      " 2004  lowlevel.melbands128.dmean_120                   float64\n",
      " 2005  lowlevel.melbands128.dmean_121                   float64\n",
      " 2006  lowlevel.melbands128.dmean_122                   float64\n",
      " 2007  lowlevel.melbands128.dmean_123                   float64\n",
      " 2008  lowlevel.melbands128.dmean_124                   float64\n",
      " 2009  lowlevel.melbands128.dmean_125                   float64\n",
      " 2010  lowlevel.melbands128.dmean_126                   float64\n",
      " 2011  lowlevel.melbands128.dmean_127                   float64\n",
      " 2012  lowlevel.melbands128.dmean2_0                    float64\n",
      " 2013  lowlevel.melbands128.dmean2_1                    float64\n",
      " 2014  lowlevel.melbands128.dmean2_2                    float64\n",
      " 2015  lowlevel.melbands128.dmean2_3                    float64\n",
      " 2016  lowlevel.melbands128.dmean2_4                    float64\n",
      " 2017  lowlevel.melbands128.dmean2_5                    float64\n",
      " 2018  lowlevel.melbands128.dmean2_6                    float64\n",
      " 2019  lowlevel.melbands128.dmean2_7                    float64\n",
      " 2020  lowlevel.melbands128.dmean2_8                    float64\n",
      " 2021  lowlevel.melbands128.dmean2_9                    float64\n",
      " 2022  lowlevel.melbands128.dmean2_10                   float64\n",
      " 2023  lowlevel.melbands128.dmean2_11                   float64\n",
      " 2024  lowlevel.melbands128.dmean2_12                   float64\n",
      " 2025  lowlevel.melbands128.dmean2_13                   float64\n",
      " 2026  lowlevel.melbands128.dmean2_14                   float64\n",
      " 2027  lowlevel.melbands128.dmean2_15                   float64\n",
      " 2028  lowlevel.melbands128.dmean2_16                   float64\n",
      " 2029  lowlevel.melbands128.dmean2_17                   float64\n",
      " 2030  lowlevel.melbands128.dmean2_18                   float64\n",
      " 2031  lowlevel.melbands128.dmean2_19                   float64\n",
      " 2032  lowlevel.melbands128.dmean2_20                   float64\n",
      " 2033  lowlevel.melbands128.dmean2_21                   float64\n",
      " 2034  lowlevel.melbands128.dmean2_22                   float64\n",
      " 2035  lowlevel.melbands128.dmean2_23                   float64\n",
      " 2036  lowlevel.melbands128.dmean2_24                   float64\n",
      " 2037  lowlevel.melbands128.dmean2_25                   float64\n",
      " 2038  lowlevel.melbands128.dmean2_26                   float64\n",
      " 2039  lowlevel.melbands128.dmean2_27                   float64\n",
      " 2040  lowlevel.melbands128.dmean2_28                   float64\n",
      " 2041  lowlevel.melbands128.dmean2_29                   float64\n",
      " 2042  lowlevel.melbands128.dmean2_30                   float64\n",
      " 2043  lowlevel.melbands128.dmean2_31                   float64\n",
      " 2044  lowlevel.melbands128.dmean2_32                   float64\n",
      " 2045  lowlevel.melbands128.dmean2_33                   float64\n",
      " 2046  lowlevel.melbands128.dmean2_34                   float64\n",
      " 2047  lowlevel.melbands128.dmean2_35                   float64\n",
      " 2048  lowlevel.melbands128.dmean2_36                   float64\n",
      " 2049  lowlevel.melbands128.dmean2_37                   float64\n",
      " 2050  lowlevel.melbands128.dmean2_38                   float64\n",
      " 2051  lowlevel.melbands128.dmean2_39                   float64\n",
      " 2052  lowlevel.melbands128.dmean2_40                   float64\n",
      " 2053  lowlevel.melbands128.dmean2_41                   float64\n",
      " 2054  lowlevel.melbands128.dmean2_42                   float64\n",
      " 2055  lowlevel.melbands128.dmean2_43                   float64\n",
      " 2056  lowlevel.melbands128.dmean2_44                   float64\n",
      " 2057  lowlevel.melbands128.dmean2_45                   float64\n",
      " 2058  lowlevel.melbands128.dmean2_46                   float64\n",
      " 2059  lowlevel.melbands128.dmean2_47                   float64\n",
      " 2060  lowlevel.melbands128.dmean2_48                   float64\n",
      " 2061  lowlevel.melbands128.dmean2_49                   float64\n",
      " 2062  lowlevel.melbands128.dmean2_50                   float64\n",
      " 2063  lowlevel.melbands128.dmean2_51                   float64\n",
      " 2064  lowlevel.melbands128.dmean2_52                   float64\n",
      " 2065  lowlevel.melbands128.dmean2_53                   float64\n",
      " 2066  lowlevel.melbands128.dmean2_54                   float64\n",
      " 2067  lowlevel.melbands128.dmean2_55                   float64\n",
      " 2068  lowlevel.melbands128.dmean2_56                   float64\n",
      " 2069  lowlevel.melbands128.dmean2_57                   float64\n",
      " 2070  lowlevel.melbands128.dmean2_58                   float64\n",
      " 2071  lowlevel.melbands128.dmean2_59                   float64\n",
      " 2072  lowlevel.melbands128.dmean2_60                   float64\n",
      " 2073  lowlevel.melbands128.dmean2_61                   float64\n",
      " 2074  lowlevel.melbands128.dmean2_62                   float64\n",
      " 2075  lowlevel.melbands128.dmean2_63                   float64\n",
      " 2076  lowlevel.melbands128.dmean2_64                   float64\n",
      " 2077  lowlevel.melbands128.dmean2_65                   float64\n",
      " 2078  lowlevel.melbands128.dmean2_66                   float64\n",
      " 2079  lowlevel.melbands128.dmean2_67                   float64\n",
      " 2080  lowlevel.melbands128.dmean2_68                   float64\n",
      " 2081  lowlevel.melbands128.dmean2_69                   float64\n",
      " 2082  lowlevel.melbands128.dmean2_70                   float64\n",
      " 2083  lowlevel.melbands128.dmean2_71                   float64\n",
      " 2084  lowlevel.melbands128.dmean2_72                   float64\n",
      " 2085  lowlevel.melbands128.dmean2_73                   float64\n",
      " 2086  lowlevel.melbands128.dmean2_74                   float64\n",
      " 2087  lowlevel.melbands128.dmean2_75                   float64\n",
      " 2088  lowlevel.melbands128.dmean2_76                   float64\n",
      " 2089  lowlevel.melbands128.dmean2_77                   float64\n",
      " 2090  lowlevel.melbands128.dmean2_78                   float64\n",
      " 2091  lowlevel.melbands128.dmean2_79                   float64\n",
      " 2092  lowlevel.melbands128.dmean2_80                   float64\n",
      " 2093  lowlevel.melbands128.dmean2_81                   float64\n",
      " 2094  lowlevel.melbands128.dmean2_82                   float64\n",
      " 2095  lowlevel.melbands128.dmean2_83                   float64\n",
      " 2096  lowlevel.melbands128.dmean2_84                   float64\n",
      " 2097  lowlevel.melbands128.dmean2_85                   float64\n",
      " 2098  lowlevel.melbands128.dmean2_86                   float64\n",
      " 2099  lowlevel.melbands128.dmean2_87                   float64\n",
      " 2100  lowlevel.melbands128.dmean2_88                   float64\n",
      " 2101  lowlevel.melbands128.dmean2_89                   float64\n",
      " 2102  lowlevel.melbands128.dmean2_90                   float64\n",
      " 2103  lowlevel.melbands128.dmean2_91                   float64\n",
      " 2104  lowlevel.melbands128.dmean2_92                   float64\n",
      " 2105  lowlevel.melbands128.dmean2_93                   float64\n",
      " 2106  lowlevel.melbands128.dmean2_94                   float64\n",
      " 2107  lowlevel.melbands128.dmean2_95                   float64\n",
      " 2108  lowlevel.melbands128.dmean2_96                   float64\n",
      " 2109  lowlevel.melbands128.dmean2_97                   float64\n",
      " 2110  lowlevel.melbands128.dmean2_98                   float64\n",
      " 2111  lowlevel.melbands128.dmean2_99                   float64\n",
      " 2112  lowlevel.melbands128.dmean2_100                  float64\n",
      " 2113  lowlevel.melbands128.dmean2_101                  float64\n",
      " 2114  lowlevel.melbands128.dmean2_102                  float64\n",
      " 2115  lowlevel.melbands128.dmean2_103                  float64\n",
      " 2116  lowlevel.melbands128.dmean2_104                  float64\n",
      " 2117  lowlevel.melbands128.dmean2_105                  float64\n",
      " 2118  lowlevel.melbands128.dmean2_106                  float64\n",
      " 2119  lowlevel.melbands128.dmean2_107                  float64\n",
      " 2120  lowlevel.melbands128.dmean2_108                  float64\n",
      " 2121  lowlevel.melbands128.dmean2_109                  float64\n",
      " 2122  lowlevel.melbands128.dmean2_110                  float64\n",
      " 2123  lowlevel.melbands128.dmean2_111                  float64\n",
      " 2124  lowlevel.melbands128.dmean2_112                  float64\n",
      " 2125  lowlevel.melbands128.dmean2_113                  float64\n",
      " 2126  lowlevel.melbands128.dmean2_114                  float64\n",
      " 2127  lowlevel.melbands128.dmean2_115                  float64\n",
      " 2128  lowlevel.melbands128.dmean2_116                  float64\n",
      " 2129  lowlevel.melbands128.dmean2_117                  float64\n",
      " 2130  lowlevel.melbands128.dmean2_118                  float64\n",
      " 2131  lowlevel.melbands128.dmean2_119                  float64\n",
      " 2132  lowlevel.melbands128.dmean2_120                  float64\n",
      " 2133  lowlevel.melbands128.dmean2_121                  float64\n",
      " 2134  lowlevel.melbands128.dmean2_122                  float64\n",
      " 2135  lowlevel.melbands128.dmean2_123                  float64\n",
      " 2136  lowlevel.melbands128.dmean2_124                  float64\n",
      " 2137  lowlevel.melbands128.dmean2_125                  float64\n",
      " 2138  lowlevel.melbands128.dmean2_126                  float64\n",
      " 2139  lowlevel.melbands128.dmean2_127                  float64\n",
      " 2140  lowlevel.melbands128.dvar_0                      float64\n",
      " 2141  lowlevel.melbands128.dvar_1                      float64\n",
      " 2142  lowlevel.melbands128.dvar_2                      float64\n",
      " 2143  lowlevel.melbands128.dvar_3                      float64\n",
      " 2144  lowlevel.melbands128.dvar_4                      float64\n",
      " 2145  lowlevel.melbands128.dvar_5                      float64\n",
      " 2146  lowlevel.melbands128.dvar_6                      float64\n",
      " 2147  lowlevel.melbands128.dvar_7                      float64\n",
      " 2148  lowlevel.melbands128.dvar_8                      float64\n",
      " 2149  lowlevel.melbands128.dvar_9                      float64\n",
      " 2150  lowlevel.melbands128.dvar_10                     float64\n",
      " 2151  lowlevel.melbands128.dvar_11                     float64\n",
      " 2152  lowlevel.melbands128.dvar_12                     float64\n",
      " 2153  lowlevel.melbands128.dvar_13                     float64\n",
      " 2154  lowlevel.melbands128.dvar_14                     float64\n",
      " 2155  lowlevel.melbands128.dvar_15                     float64\n",
      " 2156  lowlevel.melbands128.dvar_16                     float64\n",
      " 2157  lowlevel.melbands128.dvar_17                     float64\n",
      " 2158  lowlevel.melbands128.dvar_18                     float64\n",
      " 2159  lowlevel.melbands128.dvar_19                     float64\n",
      " 2160  lowlevel.melbands128.dvar_20                     float64\n",
      " 2161  lowlevel.melbands128.dvar_21                     float64\n",
      " 2162  lowlevel.melbands128.dvar_22                     float64\n",
      " 2163  lowlevel.melbands128.dvar_23                     float64\n",
      " 2164  lowlevel.melbands128.dvar_24                     float64\n",
      " 2165  lowlevel.melbands128.dvar_25                     float64\n",
      " 2166  lowlevel.melbands128.dvar_26                     float64\n",
      " 2167  lowlevel.melbands128.dvar_27                     float64\n",
      " 2168  lowlevel.melbands128.dvar_28                     float64\n",
      " 2169  lowlevel.melbands128.dvar_29                     float64\n",
      " 2170  lowlevel.melbands128.dvar_30                     float64\n",
      " 2171  lowlevel.melbands128.dvar_31                     float64\n",
      " 2172  lowlevel.melbands128.dvar_32                     float64\n",
      " 2173  lowlevel.melbands128.dvar_33                     float64\n",
      " 2174  lowlevel.melbands128.dvar_34                     float64\n",
      " 2175  lowlevel.melbands128.dvar_35                     float64\n",
      " 2176  lowlevel.melbands128.dvar_36                     float64\n",
      " 2177  lowlevel.melbands128.dvar_37                     float64\n",
      " 2178  lowlevel.melbands128.dvar_38                     float64\n",
      " 2179  lowlevel.melbands128.dvar_39                     float64\n",
      " 2180  lowlevel.melbands128.dvar_40                     float64\n",
      " 2181  lowlevel.melbands128.dvar_41                     float64\n",
      " 2182  lowlevel.melbands128.dvar_42                     float64\n",
      " 2183  lowlevel.melbands128.dvar_43                     float64\n",
      " 2184  lowlevel.melbands128.dvar_44                     float64\n",
      " 2185  lowlevel.melbands128.dvar_45                     float64\n",
      " 2186  lowlevel.melbands128.dvar_46                     float64\n",
      " 2187  lowlevel.melbands128.dvar_47                     float64\n",
      " 2188  lowlevel.melbands128.dvar_48                     float64\n",
      " 2189  lowlevel.melbands128.dvar_49                     float64\n",
      " 2190  lowlevel.melbands128.dvar_50                     float64\n",
      " 2191  lowlevel.melbands128.dvar_51                     float64\n",
      " 2192  lowlevel.melbands128.dvar_52                     float64\n",
      " 2193  lowlevel.melbands128.dvar_53                     float64\n",
      " 2194  lowlevel.melbands128.dvar_54                     float64\n",
      " 2195  lowlevel.melbands128.dvar_55                     float64\n",
      " 2196  lowlevel.melbands128.dvar_56                     float64\n",
      " 2197  lowlevel.melbands128.dvar_57                     float64\n",
      " 2198  lowlevel.melbands128.dvar_58                     float64\n",
      " 2199  lowlevel.melbands128.dvar_59                     float64\n",
      " 2200  lowlevel.melbands128.dvar_60                     float64\n",
      " 2201  lowlevel.melbands128.dvar_61                     float64\n",
      " 2202  lowlevel.melbands128.dvar_62                     float64\n",
      " 2203  lowlevel.melbands128.dvar_63                     float64\n",
      " 2204  lowlevel.melbands128.dvar_64                     float64\n",
      " 2205  lowlevel.melbands128.dvar_65                     float64\n",
      " 2206  lowlevel.melbands128.dvar_66                     float64\n",
      " 2207  lowlevel.melbands128.dvar_67                     float64\n",
      " 2208  lowlevel.melbands128.dvar_68                     float64\n",
      " 2209  lowlevel.melbands128.dvar_69                     float64\n",
      " 2210  lowlevel.melbands128.dvar_70                     float64\n",
      " 2211  lowlevel.melbands128.dvar_71                     float64\n",
      " 2212  lowlevel.melbands128.dvar_72                     float64\n",
      " 2213  lowlevel.melbands128.dvar_73                     float64\n",
      " 2214  lowlevel.melbands128.dvar_74                     float64\n",
      " 2215  lowlevel.melbands128.dvar_75                     float64\n",
      " 2216  lowlevel.melbands128.dvar_76                     float64\n",
      " 2217  lowlevel.melbands128.dvar_77                     float64\n",
      " 2218  lowlevel.melbands128.dvar_78                     float64\n",
      " 2219  lowlevel.melbands128.dvar_79                     float64\n",
      " 2220  lowlevel.melbands128.dvar_80                     float64\n",
      " 2221  lowlevel.melbands128.dvar_81                     float64\n",
      " 2222  lowlevel.melbands128.dvar_82                     float64\n",
      " 2223  lowlevel.melbands128.dvar_83                     float64\n",
      " 2224  lowlevel.melbands128.dvar_84                     float64\n",
      " 2225  lowlevel.melbands128.dvar_85                     float64\n",
      " 2226  lowlevel.melbands128.dvar_86                     float64\n",
      " 2227  lowlevel.melbands128.dvar_87                     float64\n",
      " 2228  lowlevel.melbands128.dvar_88                     float64\n",
      " 2229  lowlevel.melbands128.dvar_89                     float64\n",
      " 2230  lowlevel.melbands128.dvar_90                     float64\n",
      " 2231  lowlevel.melbands128.dvar_91                     float64\n",
      " 2232  lowlevel.melbands128.dvar_92                     float64\n",
      " 2233  lowlevel.melbands128.dvar_93                     float64\n",
      " 2234  lowlevel.melbands128.dvar_94                     float64\n",
      " 2235  lowlevel.melbands128.dvar_95                     float64\n",
      " 2236  lowlevel.melbands128.dvar_96                     float64\n",
      " 2237  lowlevel.melbands128.dvar_97                     float64\n",
      " 2238  lowlevel.melbands128.dvar_98                     float64\n",
      " 2239  lowlevel.melbands128.dvar_99                     float64\n",
      " 2240  lowlevel.melbands128.dvar_100                    float64\n",
      " 2241  lowlevel.melbands128.dvar_101                    float64\n",
      " 2242  lowlevel.melbands128.dvar_102                    float64\n",
      " 2243  lowlevel.melbands128.dvar_103                    float64\n",
      " 2244  lowlevel.melbands128.dvar_104                    float64\n",
      " 2245  lowlevel.melbands128.dvar_105                    float64\n",
      " 2246  lowlevel.melbands128.dvar_106                    float64\n",
      " 2247  lowlevel.melbands128.dvar_107                    float64\n",
      " 2248  lowlevel.melbands128.dvar_108                    float64\n",
      " 2249  lowlevel.melbands128.dvar_109                    float64\n",
      " 2250  lowlevel.melbands128.dvar_110                    float64\n",
      " 2251  lowlevel.melbands128.dvar_111                    float64\n",
      " 2252  lowlevel.melbands128.dvar_112                    float64\n",
      " 2253  lowlevel.melbands128.dvar_113                    float64\n",
      " 2254  lowlevel.melbands128.dvar_114                    float64\n",
      " 2255  lowlevel.melbands128.dvar_115                    float64\n",
      " 2256  lowlevel.melbands128.dvar_116                    float64\n",
      " 2257  lowlevel.melbands128.dvar_117                    float64\n",
      " 2258  lowlevel.melbands128.dvar_118                    float64\n",
      " 2259  lowlevel.melbands128.dvar_119                    float64\n",
      " 2260  lowlevel.melbands128.dvar_120                    float64\n",
      " 2261  lowlevel.melbands128.dvar_121                    float64\n",
      " 2262  lowlevel.melbands128.dvar_122                    float64\n",
      " 2263  lowlevel.melbands128.dvar_123                    float64\n",
      " 2264  lowlevel.melbands128.dvar_124                    float64\n",
      " 2265  lowlevel.melbands128.dvar_125                    float64\n",
      " 2266  lowlevel.melbands128.dvar_126                    float64\n",
      " 2267  lowlevel.melbands128.dvar_127                    float64\n",
      " 2268  lowlevel.melbands128.dvar2_0                     float64\n",
      " 2269  lowlevel.melbands128.dvar2_1                     float64\n",
      " 2270  lowlevel.melbands128.dvar2_2                     float64\n",
      " 2271  lowlevel.melbands128.dvar2_3                     float64\n",
      " 2272  lowlevel.melbands128.dvar2_4                     float64\n",
      " 2273  lowlevel.melbands128.dvar2_5                     float64\n",
      " 2274  lowlevel.melbands128.dvar2_6                     float64\n",
      " 2275  lowlevel.melbands128.dvar2_7                     float64\n",
      " 2276  lowlevel.melbands128.dvar2_8                     float64\n",
      " 2277  lowlevel.melbands128.dvar2_9                     float64\n",
      " 2278  lowlevel.melbands128.dvar2_10                    float64\n",
      " 2279  lowlevel.melbands128.dvar2_11                    float64\n",
      " 2280  lowlevel.melbands128.dvar2_12                    float64\n",
      " 2281  lowlevel.melbands128.dvar2_13                    float64\n",
      " 2282  lowlevel.melbands128.dvar2_14                    float64\n",
      " 2283  lowlevel.melbands128.dvar2_15                    float64\n",
      " 2284  lowlevel.melbands128.dvar2_16                    float64\n",
      " 2285  lowlevel.melbands128.dvar2_17                    float64\n",
      " 2286  lowlevel.melbands128.dvar2_18                    float64\n",
      " 2287  lowlevel.melbands128.dvar2_19                    float64\n",
      " 2288  lowlevel.melbands128.dvar2_20                    float64\n",
      " 2289  lowlevel.melbands128.dvar2_21                    float64\n",
      " 2290  lowlevel.melbands128.dvar2_22                    float64\n",
      " 2291  lowlevel.melbands128.dvar2_23                    float64\n",
      " 2292  lowlevel.melbands128.dvar2_24                    float64\n",
      " 2293  lowlevel.melbands128.dvar2_25                    float64\n",
      " 2294  lowlevel.melbands128.dvar2_26                    float64\n",
      " 2295  lowlevel.melbands128.dvar2_27                    float64\n",
      " 2296  lowlevel.melbands128.dvar2_28                    float64\n",
      " 2297  lowlevel.melbands128.dvar2_29                    float64\n",
      " 2298  lowlevel.melbands128.dvar2_30                    float64\n",
      " 2299  lowlevel.melbands128.dvar2_31                    float64\n",
      " 2300  lowlevel.melbands128.dvar2_32                    float64\n",
      " 2301  lowlevel.melbands128.dvar2_33                    float64\n",
      " 2302  lowlevel.melbands128.dvar2_34                    float64\n",
      " 2303  lowlevel.melbands128.dvar2_35                    float64\n",
      " 2304  lowlevel.melbands128.dvar2_36                    float64\n",
      " 2305  lowlevel.melbands128.dvar2_37                    float64\n",
      " 2306  lowlevel.melbands128.dvar2_38                    float64\n",
      " 2307  lowlevel.melbands128.dvar2_39                    float64\n",
      " 2308  lowlevel.melbands128.dvar2_40                    float64\n",
      " 2309  lowlevel.melbands128.dvar2_41                    float64\n",
      " 2310  lowlevel.melbands128.dvar2_42                    float64\n",
      " 2311  lowlevel.melbands128.dvar2_43                    float64\n",
      " 2312  lowlevel.melbands128.dvar2_44                    float64\n",
      " 2313  lowlevel.melbands128.dvar2_45                    float64\n",
      " 2314  lowlevel.melbands128.dvar2_46                    float64\n",
      " 2315  lowlevel.melbands128.dvar2_47                    float64\n",
      " 2316  lowlevel.melbands128.dvar2_48                    float64\n",
      " 2317  lowlevel.melbands128.dvar2_49                    float64\n",
      " 2318  lowlevel.melbands128.dvar2_50                    float64\n",
      " 2319  lowlevel.melbands128.dvar2_51                    float64\n",
      " 2320  lowlevel.melbands128.dvar2_52                    float64\n",
      " 2321  lowlevel.melbands128.dvar2_53                    float64\n",
      " 2322  lowlevel.melbands128.dvar2_54                    float64\n",
      " 2323  lowlevel.melbands128.dvar2_55                    float64\n",
      " 2324  lowlevel.melbands128.dvar2_56                    float64\n",
      " 2325  lowlevel.melbands128.dvar2_57                    float64\n",
      " 2326  lowlevel.melbands128.dvar2_58                    float64\n",
      " 2327  lowlevel.melbands128.dvar2_59                    float64\n",
      " 2328  lowlevel.melbands128.dvar2_60                    float64\n",
      " 2329  lowlevel.melbands128.dvar2_61                    float64\n",
      " 2330  lowlevel.melbands128.dvar2_62                    float64\n",
      " 2331  lowlevel.melbands128.dvar2_63                    float64\n",
      " 2332  lowlevel.melbands128.dvar2_64                    float64\n",
      " 2333  lowlevel.melbands128.dvar2_65                    float64\n",
      " 2334  lowlevel.melbands128.dvar2_66                    float64\n",
      " 2335  lowlevel.melbands128.dvar2_67                    float64\n",
      " 2336  lowlevel.melbands128.dvar2_68                    float64\n",
      " 2337  lowlevel.melbands128.dvar2_69                    float64\n",
      " 2338  lowlevel.melbands128.dvar2_70                    float64\n",
      " 2339  lowlevel.melbands128.dvar2_71                    float64\n",
      " 2340  lowlevel.melbands128.dvar2_72                    float64\n",
      " 2341  lowlevel.melbands128.dvar2_73                    float64\n",
      " 2342  lowlevel.melbands128.dvar2_74                    float64\n",
      " 2343  lowlevel.melbands128.dvar2_75                    float64\n",
      " 2344  lowlevel.melbands128.dvar2_76                    float64\n",
      " 2345  lowlevel.melbands128.dvar2_77                    float64\n",
      " 2346  lowlevel.melbands128.dvar2_78                    float64\n",
      " 2347  lowlevel.melbands128.dvar2_79                    float64\n",
      " 2348  lowlevel.melbands128.dvar2_80                    float64\n",
      " 2349  lowlevel.melbands128.dvar2_81                    float64\n",
      " 2350  lowlevel.melbands128.dvar2_82                    float64\n",
      " 2351  lowlevel.melbands128.dvar2_83                    float64\n",
      " 2352  lowlevel.melbands128.dvar2_84                    float64\n",
      " 2353  lowlevel.melbands128.dvar2_85                    float64\n",
      " 2354  lowlevel.melbands128.dvar2_86                    float64\n",
      " 2355  lowlevel.melbands128.dvar2_87                    float64\n",
      " 2356  lowlevel.melbands128.dvar2_88                    float64\n",
      " 2357  lowlevel.melbands128.dvar2_89                    float64\n",
      " 2358  lowlevel.melbands128.dvar2_90                    float64\n",
      " 2359  lowlevel.melbands128.dvar2_91                    float64\n",
      " 2360  lowlevel.melbands128.dvar2_92                    float64\n",
      " 2361  lowlevel.melbands128.dvar2_93                    float64\n",
      " 2362  lowlevel.melbands128.dvar2_94                    float64\n",
      " 2363  lowlevel.melbands128.dvar2_95                    float64\n",
      " 2364  lowlevel.melbands128.dvar2_96                    float64\n",
      " 2365  lowlevel.melbands128.dvar2_97                    float64\n",
      " 2366  lowlevel.melbands128.dvar2_98                    float64\n",
      " 2367  lowlevel.melbands128.dvar2_99                    float64\n",
      " 2368  lowlevel.melbands128.dvar2_100                   float64\n",
      " 2369  lowlevel.melbands128.dvar2_101                   float64\n",
      " 2370  lowlevel.melbands128.dvar2_102                   float64\n",
      " 2371  lowlevel.melbands128.dvar2_103                   float64\n",
      " 2372  lowlevel.melbands128.dvar2_104                   float64\n",
      " 2373  lowlevel.melbands128.dvar2_105                   float64\n",
      " 2374  lowlevel.melbands128.dvar2_106                   float64\n",
      " 2375  lowlevel.melbands128.dvar2_107                   float64\n",
      " 2376  lowlevel.melbands128.dvar2_108                   float64\n",
      " 2377  lowlevel.melbands128.dvar2_109                   float64\n",
      " 2378  lowlevel.melbands128.dvar2_110                   float64\n",
      " 2379  lowlevel.melbands128.dvar2_111                   float64\n",
      " 2380  lowlevel.melbands128.dvar2_112                   float64\n",
      " 2381  lowlevel.melbands128.dvar2_113                   float64\n",
      " 2382  lowlevel.melbands128.dvar2_114                   float64\n",
      " 2383  lowlevel.melbands128.dvar2_115                   float64\n",
      " 2384  lowlevel.melbands128.dvar2_116                   float64\n",
      " 2385  lowlevel.melbands128.dvar2_117                   float64\n",
      " 2386  lowlevel.melbands128.dvar2_118                   float64\n",
      " 2387  lowlevel.melbands128.dvar2_119                   float64\n",
      " 2388  lowlevel.melbands128.dvar2_120                   float64\n",
      " 2389  lowlevel.melbands128.dvar2_121                   float64\n",
      " 2390  lowlevel.melbands128.dvar2_122                   float64\n",
      " 2391  lowlevel.melbands128.dvar2_123                   float64\n",
      " 2392  lowlevel.melbands128.dvar2_124                   float64\n",
      " 2393  lowlevel.melbands128.dvar2_125                   float64\n",
      " 2394  lowlevel.melbands128.dvar2_126                   float64\n",
      " 2395  lowlevel.melbands128.dvar2_127                   float64\n",
      " 2396  lowlevel.melbands128.max_0                       float64\n",
      " 2397  lowlevel.melbands128.max_1                       float64\n",
      " 2398  lowlevel.melbands128.max_2                       float64\n",
      " 2399  lowlevel.melbands128.max_3                       float64\n",
      " 2400  lowlevel.melbands128.max_4                       float64\n",
      " 2401  lowlevel.melbands128.max_5                       float64\n",
      " 2402  lowlevel.melbands128.max_6                       float64\n",
      " 2403  lowlevel.melbands128.max_7                       float64\n",
      " 2404  lowlevel.melbands128.max_8                       float64\n",
      " 2405  lowlevel.melbands128.max_9                       float64\n",
      " 2406  lowlevel.melbands128.max_10                      float64\n",
      " 2407  lowlevel.melbands128.max_11                      float64\n",
      " 2408  lowlevel.melbands128.max_12                      float64\n",
      " 2409  lowlevel.melbands128.max_13                      float64\n",
      " 2410  lowlevel.melbands128.max_14                      float64\n",
      " 2411  lowlevel.melbands128.max_15                      float64\n",
      " 2412  lowlevel.melbands128.max_16                      float64\n",
      " 2413  lowlevel.melbands128.max_17                      float64\n",
      " 2414  lowlevel.melbands128.max_18                      float64\n",
      " 2415  lowlevel.melbands128.max_19                      float64\n",
      " 2416  lowlevel.melbands128.max_20                      float64\n",
      " 2417  lowlevel.melbands128.max_21                      float64\n",
      " 2418  lowlevel.melbands128.max_22                      float64\n",
      " 2419  lowlevel.melbands128.max_23                      float64\n",
      " 2420  lowlevel.melbands128.max_24                      float64\n",
      " 2421  lowlevel.melbands128.max_25                      float64\n",
      " 2422  lowlevel.melbands128.max_26                      float64\n",
      " 2423  lowlevel.melbands128.max_27                      float64\n",
      " 2424  lowlevel.melbands128.max_28                      float64\n",
      " 2425  lowlevel.melbands128.max_29                      float64\n",
      " 2426  lowlevel.melbands128.max_30                      float64\n",
      " 2427  lowlevel.melbands128.max_31                      float64\n",
      " 2428  lowlevel.melbands128.max_32                      float64\n",
      " 2429  lowlevel.melbands128.max_33                      float64\n",
      " 2430  lowlevel.melbands128.max_34                      float64\n",
      " 2431  lowlevel.melbands128.max_35                      float64\n",
      " 2432  lowlevel.melbands128.max_36                      float64\n",
      " 2433  lowlevel.melbands128.max_37                      float64\n",
      " 2434  lowlevel.melbands128.max_38                      float64\n",
      " 2435  lowlevel.melbands128.max_39                      float64\n",
      " 2436  lowlevel.melbands128.max_40                      float64\n",
      " 2437  lowlevel.melbands128.max_41                      float64\n",
      " 2438  lowlevel.melbands128.max_42                      float64\n",
      " 2439  lowlevel.melbands128.max_43                      float64\n",
      " 2440  lowlevel.melbands128.max_44                      float64\n",
      " 2441  lowlevel.melbands128.max_45                      float64\n",
      " 2442  lowlevel.melbands128.max_46                      float64\n",
      " 2443  lowlevel.melbands128.max_47                      float64\n",
      " 2444  lowlevel.melbands128.max_48                      float64\n",
      " 2445  lowlevel.melbands128.max_49                      float64\n",
      " 2446  lowlevel.melbands128.max_50                      float64\n",
      " 2447  lowlevel.melbands128.max_51                      float64\n",
      " 2448  lowlevel.melbands128.max_52                      float64\n",
      " 2449  lowlevel.melbands128.max_53                      float64\n",
      " 2450  lowlevel.melbands128.max_54                      float64\n",
      " 2451  lowlevel.melbands128.max_55                      float64\n",
      " 2452  lowlevel.melbands128.max_56                      float64\n",
      " 2453  lowlevel.melbands128.max_57                      float64\n",
      " 2454  lowlevel.melbands128.max_58                      float64\n",
      " 2455  lowlevel.melbands128.max_59                      float64\n",
      " 2456  lowlevel.melbands128.max_60                      float64\n",
      " 2457  lowlevel.melbands128.max_61                      float64\n",
      " 2458  lowlevel.melbands128.max_62                      float64\n",
      " 2459  lowlevel.melbands128.max_63                      float64\n",
      " 2460  lowlevel.melbands128.max_64                      float64\n",
      " 2461  lowlevel.melbands128.max_65                      float64\n",
      " 2462  lowlevel.melbands128.max_66                      float64\n",
      " 2463  lowlevel.melbands128.max_67                      float64\n",
      " 2464  lowlevel.melbands128.max_68                      float64\n",
      " 2465  lowlevel.melbands128.max_69                      float64\n",
      " 2466  lowlevel.melbands128.max_70                      float64\n",
      " 2467  lowlevel.melbands128.max_71                      float64\n",
      " 2468  lowlevel.melbands128.max_72                      float64\n",
      " 2469  lowlevel.melbands128.max_73                      float64\n",
      " 2470  lowlevel.melbands128.max_74                      float64\n",
      " 2471  lowlevel.melbands128.max_75                      float64\n",
      " 2472  lowlevel.melbands128.max_76                      float64\n",
      " 2473  lowlevel.melbands128.max_77                      float64\n",
      " 2474  lowlevel.melbands128.max_78                      float64\n",
      " 2475  lowlevel.melbands128.max_79                      float64\n",
      " 2476  lowlevel.melbands128.max_80                      float64\n",
      " 2477  lowlevel.melbands128.max_81                      float64\n",
      " 2478  lowlevel.melbands128.max_82                      float64\n",
      " 2479  lowlevel.melbands128.max_83                      float64\n",
      " 2480  lowlevel.melbands128.max_84                      float64\n",
      " 2481  lowlevel.melbands128.max_85                      float64\n",
      " 2482  lowlevel.melbands128.max_86                      float64\n",
      " 2483  lowlevel.melbands128.max_87                      float64\n",
      " 2484  lowlevel.melbands128.max_88                      float64\n",
      " 2485  lowlevel.melbands128.max_89                      float64\n",
      " 2486  lowlevel.melbands128.max_90                      float64\n",
      " 2487  lowlevel.melbands128.max_91                      float64\n",
      " 2488  lowlevel.melbands128.max_92                      float64\n",
      " 2489  lowlevel.melbands128.max_93                      float64\n",
      " 2490  lowlevel.melbands128.max_94                      float64\n",
      " 2491  lowlevel.melbands128.max_95                      float64\n",
      " 2492  lowlevel.melbands128.max_96                      float64\n",
      " 2493  lowlevel.melbands128.max_97                      float64\n",
      " 2494  lowlevel.melbands128.max_98                      float64\n",
      " 2495  lowlevel.melbands128.max_99                      float64\n",
      " 2496  lowlevel.melbands128.max_100                     float64\n",
      " 2497  lowlevel.melbands128.max_101                     float64\n",
      " 2498  lowlevel.melbands128.max_102                     float64\n",
      " 2499  lowlevel.melbands128.max_103                     float64\n",
      " 2500  lowlevel.melbands128.max_104                     float64\n",
      " 2501  lowlevel.melbands128.max_105                     float64\n",
      " 2502  lowlevel.melbands128.max_106                     float64\n",
      " 2503  lowlevel.melbands128.max_107                     float64\n",
      " 2504  lowlevel.melbands128.max_108                     float64\n",
      " 2505  lowlevel.melbands128.max_109                     float64\n",
      " 2506  lowlevel.melbands128.max_110                     float64\n",
      " 2507  lowlevel.melbands128.max_111                     float64\n",
      " 2508  lowlevel.melbands128.max_112                     float64\n",
      " 2509  lowlevel.melbands128.max_113                     float64\n",
      " 2510  lowlevel.melbands128.max_114                     float64\n",
      " 2511  lowlevel.melbands128.max_115                     float64\n",
      " 2512  lowlevel.melbands128.max_116                     float64\n",
      " 2513  lowlevel.melbands128.max_117                     float64\n",
      " 2514  lowlevel.melbands128.max_118                     float64\n",
      " 2515  lowlevel.melbands128.max_119                     float64\n",
      " 2516  lowlevel.melbands128.max_120                     float64\n",
      " 2517  lowlevel.melbands128.max_121                     float64\n",
      " 2518  lowlevel.melbands128.max_122                     float64\n",
      " 2519  lowlevel.melbands128.max_123                     float64\n",
      " 2520  lowlevel.melbands128.max_124                     float64\n",
      " 2521  lowlevel.melbands128.max_125                     float64\n",
      " 2522  lowlevel.melbands128.max_126                     float64\n",
      " 2523  lowlevel.melbands128.max_127                     float64\n",
      " 2524  lowlevel.melbands128.mean_0                      float64\n",
      " 2525  lowlevel.melbands128.mean_1                      float64\n",
      " 2526  lowlevel.melbands128.mean_2                      float64\n",
      " 2527  lowlevel.melbands128.mean_3                      float64\n",
      " 2528  lowlevel.melbands128.mean_4                      float64\n",
      " 2529  lowlevel.melbands128.mean_5                      float64\n",
      " 2530  lowlevel.melbands128.mean_6                      float64\n",
      " 2531  lowlevel.melbands128.mean_7                      float64\n",
      " 2532  lowlevel.melbands128.mean_8                      float64\n",
      " 2533  lowlevel.melbands128.mean_9                      float64\n",
      " 2534  lowlevel.melbands128.mean_10                     float64\n",
      " 2535  lowlevel.melbands128.mean_11                     float64\n",
      " 2536  lowlevel.melbands128.mean_12                     float64\n",
      " 2537  lowlevel.melbands128.mean_13                     float64\n",
      " 2538  lowlevel.melbands128.mean_14                     float64\n",
      " 2539  lowlevel.melbands128.mean_15                     float64\n",
      " 2540  lowlevel.melbands128.mean_16                     float64\n",
      " 2541  lowlevel.melbands128.mean_17                     float64\n",
      " 2542  lowlevel.melbands128.mean_18                     float64\n",
      " 2543  lowlevel.melbands128.mean_19                     float64\n",
      " 2544  lowlevel.melbands128.mean_20                     float64\n",
      " 2545  lowlevel.melbands128.mean_21                     float64\n",
      " 2546  lowlevel.melbands128.mean_22                     float64\n",
      " 2547  lowlevel.melbands128.mean_23                     float64\n",
      " 2548  lowlevel.melbands128.mean_24                     float64\n",
      " 2549  lowlevel.melbands128.mean_25                     float64\n",
      " 2550  lowlevel.melbands128.mean_26                     float64\n",
      " 2551  lowlevel.melbands128.mean_27                     float64\n",
      " 2552  lowlevel.melbands128.mean_28                     float64\n",
      " 2553  lowlevel.melbands128.mean_29                     float64\n",
      " 2554  lowlevel.melbands128.mean_30                     float64\n",
      " 2555  lowlevel.melbands128.mean_31                     float64\n",
      " 2556  lowlevel.melbands128.mean_32                     float64\n",
      " 2557  lowlevel.melbands128.mean_33                     float64\n",
      " 2558  lowlevel.melbands128.mean_34                     float64\n",
      " 2559  lowlevel.melbands128.mean_35                     float64\n",
      " 2560  lowlevel.melbands128.mean_36                     float64\n",
      " 2561  lowlevel.melbands128.mean_37                     float64\n",
      " 2562  lowlevel.melbands128.mean_38                     float64\n",
      " 2563  lowlevel.melbands128.mean_39                     float64\n",
      " 2564  lowlevel.melbands128.mean_40                     float64\n",
      " 2565  lowlevel.melbands128.mean_41                     float64\n",
      " 2566  lowlevel.melbands128.mean_42                     float64\n",
      " 2567  lowlevel.melbands128.mean_43                     float64\n",
      " 2568  lowlevel.melbands128.mean_44                     float64\n",
      " 2569  lowlevel.melbands128.mean_45                     float64\n",
      " 2570  lowlevel.melbands128.mean_46                     float64\n",
      " 2571  lowlevel.melbands128.mean_47                     float64\n",
      " 2572  lowlevel.melbands128.mean_48                     float64\n",
      " 2573  lowlevel.melbands128.mean_49                     float64\n",
      " 2574  lowlevel.melbands128.mean_50                     float64\n",
      " 2575  lowlevel.melbands128.mean_51                     float64\n",
      " 2576  lowlevel.melbands128.mean_52                     float64\n",
      " 2577  lowlevel.melbands128.mean_53                     float64\n",
      " 2578  lowlevel.melbands128.mean_54                     float64\n",
      " 2579  lowlevel.melbands128.mean_55                     float64\n",
      " 2580  lowlevel.melbands128.mean_56                     float64\n",
      " 2581  lowlevel.melbands128.mean_57                     float64\n",
      " 2582  lowlevel.melbands128.mean_58                     float64\n",
      " 2583  lowlevel.melbands128.mean_59                     float64\n",
      " 2584  lowlevel.melbands128.mean_60                     float64\n",
      " 2585  lowlevel.melbands128.mean_61                     float64\n",
      " 2586  lowlevel.melbands128.mean_62                     float64\n",
      " 2587  lowlevel.melbands128.mean_63                     float64\n",
      " 2588  lowlevel.melbands128.mean_64                     float64\n",
      " 2589  lowlevel.melbands128.mean_65                     float64\n",
      " 2590  lowlevel.melbands128.mean_66                     float64\n",
      " 2591  lowlevel.melbands128.mean_67                     float64\n",
      " 2592  lowlevel.melbands128.mean_68                     float64\n",
      " 2593  lowlevel.melbands128.mean_69                     float64\n",
      " 2594  lowlevel.melbands128.mean_70                     float64\n",
      " 2595  lowlevel.melbands128.mean_71                     float64\n",
      " 2596  lowlevel.melbands128.mean_72                     float64\n",
      " 2597  lowlevel.melbands128.mean_73                     float64\n",
      " 2598  lowlevel.melbands128.mean_74                     float64\n",
      " 2599  lowlevel.melbands128.mean_75                     float64\n",
      " 2600  lowlevel.melbands128.mean_76                     float64\n",
      " 2601  lowlevel.melbands128.mean_77                     float64\n",
      " 2602  lowlevel.melbands128.mean_78                     float64\n",
      " 2603  lowlevel.melbands128.mean_79                     float64\n",
      " 2604  lowlevel.melbands128.mean_80                     float64\n",
      " 2605  lowlevel.melbands128.mean_81                     float64\n",
      " 2606  lowlevel.melbands128.mean_82                     float64\n",
      " 2607  lowlevel.melbands128.mean_83                     float64\n",
      " 2608  lowlevel.melbands128.mean_84                     float64\n",
      " 2609  lowlevel.melbands128.mean_85                     float64\n",
      " 2610  lowlevel.melbands128.mean_86                     float64\n",
      " 2611  lowlevel.melbands128.mean_87                     float64\n",
      " 2612  lowlevel.melbands128.mean_88                     float64\n",
      " 2613  lowlevel.melbands128.mean_89                     float64\n",
      " 2614  lowlevel.melbands128.mean_90                     float64\n",
      " 2615  lowlevel.melbands128.mean_91                     float64\n",
      " 2616  lowlevel.melbands128.mean_92                     float64\n",
      " 2617  lowlevel.melbands128.mean_93                     float64\n",
      " 2618  lowlevel.melbands128.mean_94                     float64\n",
      " 2619  lowlevel.melbands128.mean_95                     float64\n",
      " 2620  lowlevel.melbands128.mean_96                     float64\n",
      " 2621  lowlevel.melbands128.mean_97                     float64\n",
      " 2622  lowlevel.melbands128.mean_98                     float64\n",
      " 2623  lowlevel.melbands128.mean_99                     float64\n",
      " 2624  lowlevel.melbands128.mean_100                    float64\n",
      " 2625  lowlevel.melbands128.mean_101                    float64\n",
      " 2626  lowlevel.melbands128.mean_102                    float64\n",
      " 2627  lowlevel.melbands128.mean_103                    float64\n",
      " 2628  lowlevel.melbands128.mean_104                    float64\n",
      " 2629  lowlevel.melbands128.mean_105                    float64\n",
      " 2630  lowlevel.melbands128.mean_106                    float64\n",
      " 2631  lowlevel.melbands128.mean_107                    float64\n",
      " 2632  lowlevel.melbands128.mean_108                    float64\n",
      " 2633  lowlevel.melbands128.mean_109                    float64\n",
      " 2634  lowlevel.melbands128.mean_110                    float64\n",
      " 2635  lowlevel.melbands128.mean_111                    float64\n",
      " 2636  lowlevel.melbands128.mean_112                    float64\n",
      " 2637  lowlevel.melbands128.mean_113                    float64\n",
      " 2638  lowlevel.melbands128.mean_114                    float64\n",
      " 2639  lowlevel.melbands128.mean_115                    float64\n",
      " 2640  lowlevel.melbands128.mean_116                    float64\n",
      " 2641  lowlevel.melbands128.mean_117                    float64\n",
      " 2642  lowlevel.melbands128.mean_118                    float64\n",
      " 2643  lowlevel.melbands128.mean_119                    float64\n",
      " 2644  lowlevel.melbands128.mean_120                    float64\n",
      " 2645  lowlevel.melbands128.mean_121                    float64\n",
      " 2646  lowlevel.melbands128.mean_122                    float64\n",
      " 2647  lowlevel.melbands128.mean_123                    float64\n",
      " 2648  lowlevel.melbands128.mean_124                    float64\n",
      " 2649  lowlevel.melbands128.mean_125                    float64\n",
      " 2650  lowlevel.melbands128.mean_126                    float64\n",
      " 2651  lowlevel.melbands128.mean_127                    float64\n",
      " 2652  lowlevel.melbands128.median_0                    float64\n",
      " 2653  lowlevel.melbands128.median_1                    float64\n",
      " 2654  lowlevel.melbands128.median_2                    float64\n",
      " 2655  lowlevel.melbands128.median_3                    float64\n",
      " 2656  lowlevel.melbands128.median_4                    float64\n",
      " 2657  lowlevel.melbands128.median_5                    float64\n",
      " 2658  lowlevel.melbands128.median_6                    float64\n",
      " 2659  lowlevel.melbands128.median_7                    float64\n",
      " 2660  lowlevel.melbands128.median_8                    float64\n",
      " 2661  lowlevel.melbands128.median_9                    float64\n",
      " 2662  lowlevel.melbands128.median_10                   float64\n",
      " 2663  lowlevel.melbands128.median_11                   float64\n",
      " 2664  lowlevel.melbands128.median_12                   float64\n",
      " 2665  lowlevel.melbands128.median_13                   float64\n",
      " 2666  lowlevel.melbands128.median_14                   float64\n",
      " 2667  lowlevel.melbands128.median_15                   float64\n",
      " 2668  lowlevel.melbands128.median_16                   float64\n",
      " 2669  lowlevel.melbands128.median_17                   float64\n",
      " 2670  lowlevel.melbands128.median_18                   float64\n",
      " 2671  lowlevel.melbands128.median_19                   float64\n",
      " 2672  lowlevel.melbands128.median_20                   float64\n",
      " 2673  lowlevel.melbands128.median_21                   float64\n",
      " 2674  lowlevel.melbands128.median_22                   float64\n",
      " 2675  lowlevel.melbands128.median_23                   float64\n",
      " 2676  lowlevel.melbands128.median_24                   float64\n",
      " 2677  lowlevel.melbands128.median_25                   float64\n",
      " 2678  lowlevel.melbands128.median_26                   float64\n",
      " 2679  lowlevel.melbands128.median_27                   float64\n",
      " 2680  lowlevel.melbands128.median_28                   float64\n",
      " 2681  lowlevel.melbands128.median_29                   float64\n",
      " 2682  lowlevel.melbands128.median_30                   float64\n",
      " 2683  lowlevel.melbands128.median_31                   float64\n",
      " 2684  lowlevel.melbands128.median_32                   float64\n",
      " 2685  lowlevel.melbands128.median_33                   float64\n",
      " 2686  lowlevel.melbands128.median_34                   float64\n",
      " 2687  lowlevel.melbands128.median_35                   float64\n",
      " 2688  lowlevel.melbands128.median_36                   float64\n",
      " 2689  lowlevel.melbands128.median_37                   float64\n",
      " 2690  lowlevel.melbands128.median_38                   float64\n",
      " 2691  lowlevel.melbands128.median_39                   float64\n",
      " 2692  lowlevel.melbands128.median_40                   float64\n",
      " 2693  lowlevel.melbands128.median_41                   float64\n",
      " 2694  lowlevel.melbands128.median_42                   float64\n",
      " 2695  lowlevel.melbands128.median_43                   float64\n",
      " 2696  lowlevel.melbands128.median_44                   float64\n",
      " 2697  lowlevel.melbands128.median_45                   float64\n",
      " 2698  lowlevel.melbands128.median_46                   float64\n",
      " 2699  lowlevel.melbands128.median_47                   float64\n",
      " 2700  lowlevel.melbands128.median_48                   float64\n",
      " 2701  lowlevel.melbands128.median_49                   float64\n",
      " 2702  lowlevel.melbands128.median_50                   float64\n",
      " 2703  lowlevel.melbands128.median_51                   float64\n",
      " 2704  lowlevel.melbands128.median_52                   float64\n",
      " 2705  lowlevel.melbands128.median_53                   float64\n",
      " 2706  lowlevel.melbands128.median_54                   float64\n",
      " 2707  lowlevel.melbands128.median_55                   float64\n",
      " 2708  lowlevel.melbands128.median_56                   float64\n",
      " 2709  lowlevel.melbands128.median_57                   float64\n",
      " 2710  lowlevel.melbands128.median_58                   float64\n",
      " 2711  lowlevel.melbands128.median_59                   float64\n",
      " 2712  lowlevel.melbands128.median_60                   float64\n",
      " 2713  lowlevel.melbands128.median_61                   float64\n",
      " 2714  lowlevel.melbands128.median_62                   float64\n",
      " 2715  lowlevel.melbands128.median_63                   float64\n",
      " 2716  lowlevel.melbands128.median_64                   float64\n",
      " 2717  lowlevel.melbands128.median_65                   float64\n",
      " 2718  lowlevel.melbands128.median_66                   float64\n",
      " 2719  lowlevel.melbands128.median_67                   float64\n",
      " 2720  lowlevel.melbands128.median_68                   float64\n",
      " 2721  lowlevel.melbands128.median_69                   float64\n",
      " 2722  lowlevel.melbands128.median_70                   float64\n",
      " 2723  lowlevel.melbands128.median_71                   float64\n",
      " 2724  lowlevel.melbands128.median_72                   float64\n",
      " 2725  lowlevel.melbands128.median_73                   float64\n",
      " 2726  lowlevel.melbands128.median_74                   float64\n",
      " 2727  lowlevel.melbands128.median_75                   float64\n",
      " 2728  lowlevel.melbands128.median_76                   float64\n",
      " 2729  lowlevel.melbands128.median_77                   float64\n",
      " 2730  lowlevel.melbands128.median_78                   float64\n",
      " 2731  lowlevel.melbands128.median_79                   float64\n",
      " 2732  lowlevel.melbands128.median_80                   float64\n",
      " 2733  lowlevel.melbands128.median_81                   float64\n",
      " 2734  lowlevel.melbands128.median_82                   float64\n",
      " 2735  lowlevel.melbands128.median_83                   float64\n",
      " 2736  lowlevel.melbands128.median_84                   float64\n",
      " 2737  lowlevel.melbands128.median_85                   float64\n",
      " 2738  lowlevel.melbands128.median_86                   float64\n",
      " 2739  lowlevel.melbands128.median_87                   float64\n",
      " 2740  lowlevel.melbands128.median_88                   float64\n",
      " 2741  lowlevel.melbands128.median_89                   float64\n",
      " 2742  lowlevel.melbands128.median_90                   float64\n",
      " 2743  lowlevel.melbands128.median_91                   float64\n",
      " 2744  lowlevel.melbands128.median_92                   float64\n",
      " 2745  lowlevel.melbands128.median_93                   float64\n",
      " 2746  lowlevel.melbands128.median_94                   float64\n",
      " 2747  lowlevel.melbands128.median_95                   float64\n",
      " 2748  lowlevel.melbands128.median_96                   float64\n",
      " 2749  lowlevel.melbands128.median_97                   float64\n",
      " 2750  lowlevel.melbands128.median_98                   float64\n",
      " 2751  lowlevel.melbands128.median_99                   float64\n",
      " 2752  lowlevel.melbands128.median_100                  float64\n",
      " 2753  lowlevel.melbands128.median_101                  float64\n",
      " 2754  lowlevel.melbands128.median_102                  float64\n",
      " 2755  lowlevel.melbands128.median_103                  float64\n",
      " 2756  lowlevel.melbands128.median_104                  float64\n",
      " 2757  lowlevel.melbands128.median_105                  float64\n",
      " 2758  lowlevel.melbands128.median_106                  float64\n",
      " 2759  lowlevel.melbands128.median_107                  float64\n",
      " 2760  lowlevel.melbands128.median_108                  float64\n",
      " 2761  lowlevel.melbands128.median_109                  float64\n",
      " 2762  lowlevel.melbands128.median_110                  float64\n",
      " 2763  lowlevel.melbands128.median_111                  float64\n",
      " 2764  lowlevel.melbands128.median_112                  float64\n",
      " 2765  lowlevel.melbands128.median_113                  float64\n",
      " 2766  lowlevel.melbands128.median_114                  float64\n",
      " 2767  lowlevel.melbands128.median_115                  float64\n",
      " 2768  lowlevel.melbands128.median_116                  float64\n",
      " 2769  lowlevel.melbands128.median_117                  float64\n",
      " 2770  lowlevel.melbands128.median_118                  float64\n",
      " 2771  lowlevel.melbands128.median_119                  float64\n",
      " 2772  lowlevel.melbands128.median_120                  float64\n",
      " 2773  lowlevel.melbands128.median_121                  float64\n",
      " 2774  lowlevel.melbands128.median_122                  float64\n",
      " 2775  lowlevel.melbands128.median_123                  float64\n",
      " 2776  lowlevel.melbands128.median_124                  float64\n",
      " 2777  lowlevel.melbands128.median_125                  float64\n",
      " 2778  lowlevel.melbands128.median_126                  float64\n",
      " 2779  lowlevel.melbands128.median_127                  float64\n",
      " 2780  lowlevel.melbands128.min_0                       float64\n",
      " 2781  lowlevel.melbands128.min_1                       float64\n",
      " 2782  lowlevel.melbands128.min_2                       float64\n",
      " 2783  lowlevel.melbands128.min_3                       float64\n",
      " 2784  lowlevel.melbands128.min_4                       float64\n",
      " 2785  lowlevel.melbands128.min_5                       float64\n",
      " 2786  lowlevel.melbands128.min_6                       float64\n",
      " 2787  lowlevel.melbands128.min_7                       float64\n",
      " 2788  lowlevel.melbands128.min_8                       float64\n",
      " 2789  lowlevel.melbands128.min_9                       float64\n",
      " 2790  lowlevel.melbands128.min_10                      float64\n",
      " 2791  lowlevel.melbands128.min_11                      float64\n",
      " 2792  lowlevel.melbands128.min_12                      float64\n",
      " 2793  lowlevel.melbands128.min_13                      float64\n",
      " 2794  lowlevel.melbands128.min_14                      float64\n",
      " 2795  lowlevel.melbands128.min_15                      float64\n",
      " 2796  lowlevel.melbands128.min_16                      float64\n",
      " 2797  lowlevel.melbands128.min_17                      float64\n",
      " 2798  lowlevel.melbands128.min_18                      float64\n",
      " 2799  lowlevel.melbands128.min_19                      float64\n",
      " 2800  lowlevel.melbands128.min_20                      float64\n",
      " 2801  lowlevel.melbands128.min_21                      float64\n",
      " 2802  lowlevel.melbands128.min_22                      float64\n",
      " 2803  lowlevel.melbands128.min_23                      float64\n",
      " 2804  lowlevel.melbands128.min_24                      float64\n",
      " 2805  lowlevel.melbands128.min_25                      float64\n",
      " 2806  lowlevel.melbands128.min_26                      float64\n",
      " 2807  lowlevel.melbands128.min_27                      float64\n",
      " 2808  lowlevel.melbands128.min_28                      float64\n",
      " 2809  lowlevel.melbands128.min_29                      float64\n",
      " 2810  lowlevel.melbands128.min_30                      float64\n",
      " 2811  lowlevel.melbands128.min_31                      float64\n",
      " 2812  lowlevel.melbands128.min_32                      float64\n",
      " 2813  lowlevel.melbands128.min_33                      float64\n",
      " 2814  lowlevel.melbands128.min_34                      float64\n",
      " 2815  lowlevel.melbands128.min_35                      float64\n",
      " 2816  lowlevel.melbands128.min_36                      float64\n",
      " 2817  lowlevel.melbands128.min_37                      float64\n",
      " 2818  lowlevel.melbands128.min_38                      float64\n",
      " 2819  lowlevel.melbands128.min_39                      float64\n",
      " 2820  lowlevel.melbands128.min_40                      float64\n",
      " 2821  lowlevel.melbands128.min_41                      float64\n",
      " 2822  lowlevel.melbands128.min_42                      float64\n",
      " 2823  lowlevel.melbands128.min_43                      float64\n",
      " 2824  lowlevel.melbands128.min_44                      float64\n",
      " 2825  lowlevel.melbands128.min_45                      float64\n",
      " 2826  lowlevel.melbands128.min_46                      float64\n",
      " 2827  lowlevel.melbands128.min_47                      float64\n",
      " 2828  lowlevel.melbands128.min_48                      float64\n",
      " 2829  lowlevel.melbands128.min_49                      float64\n",
      " 2830  lowlevel.melbands128.min_50                      float64\n",
      " 2831  lowlevel.melbands128.min_51                      float64\n",
      " 2832  lowlevel.melbands128.min_52                      float64\n",
      " 2833  lowlevel.melbands128.min_53                      float64\n",
      " 2834  lowlevel.melbands128.min_54                      float64\n",
      " 2835  lowlevel.melbands128.min_55                      float64\n",
      " 2836  lowlevel.melbands128.min_56                      float64\n",
      " 2837  lowlevel.melbands128.min_57                      float64\n",
      " 2838  lowlevel.melbands128.min_58                      float64\n",
      " 2839  lowlevel.melbands128.min_59                      float64\n",
      " 2840  lowlevel.melbands128.min_60                      float64\n",
      " 2841  lowlevel.melbands128.min_61                      float64\n",
      " 2842  lowlevel.melbands128.min_62                      float64\n",
      " 2843  lowlevel.melbands128.min_63                      float64\n",
      " 2844  lowlevel.melbands128.min_64                      float64\n",
      " 2845  lowlevel.melbands128.min_65                      float64\n",
      " 2846  lowlevel.melbands128.min_66                      float64\n",
      " 2847  lowlevel.melbands128.min_67                      float64\n",
      " 2848  lowlevel.melbands128.min_68                      float64\n",
      " 2849  lowlevel.melbands128.min_69                      float64\n",
      " 2850  lowlevel.melbands128.min_70                      float64\n",
      " 2851  lowlevel.melbands128.min_71                      float64\n",
      " 2852  lowlevel.melbands128.min_72                      float64\n",
      " 2853  lowlevel.melbands128.min_73                      float64\n",
      " 2854  lowlevel.melbands128.min_74                      float64\n",
      " 2855  lowlevel.melbands128.min_75                      float64\n",
      " 2856  lowlevel.melbands128.min_76                      float64\n",
      " 2857  lowlevel.melbands128.min_77                      float64\n",
      " 2858  lowlevel.melbands128.min_78                      float64\n",
      " 2859  lowlevel.melbands128.min_79                      float64\n",
      " 2860  lowlevel.melbands128.min_80                      float64\n",
      " 2861  lowlevel.melbands128.min_81                      float64\n",
      " 2862  lowlevel.melbands128.min_82                      float64\n",
      " 2863  lowlevel.melbands128.min_83                      float64\n",
      " 2864  lowlevel.melbands128.min_84                      float64\n",
      " 2865  lowlevel.melbands128.min_85                      float64\n",
      " 2866  lowlevel.melbands128.min_86                      float64\n",
      " 2867  lowlevel.melbands128.min_87                      float64\n",
      " 2868  lowlevel.melbands128.min_88                      float64\n",
      " 2869  lowlevel.melbands128.min_89                      float64\n",
      " 2870  lowlevel.melbands128.min_90                      float64\n",
      " 2871  lowlevel.melbands128.min_91                      float64\n",
      " 2872  lowlevel.melbands128.min_92                      float64\n",
      " 2873  lowlevel.melbands128.min_93                      float64\n",
      " 2874  lowlevel.melbands128.min_94                      float64\n",
      " 2875  lowlevel.melbands128.min_95                      float64\n",
      " 2876  lowlevel.melbands128.min_96                      float64\n",
      " 2877  lowlevel.melbands128.min_97                      float64\n",
      " 2878  lowlevel.melbands128.min_98                      float64\n",
      " 2879  lowlevel.melbands128.min_99                      float64\n",
      " 2880  lowlevel.melbands128.min_100                     float64\n",
      " 2881  lowlevel.melbands128.min_101                     float64\n",
      " 2882  lowlevel.melbands128.min_102                     float64\n",
      " 2883  lowlevel.melbands128.min_103                     float64\n",
      " 2884  lowlevel.melbands128.min_104                     float64\n",
      " 2885  lowlevel.melbands128.min_105                     float64\n",
      " 2886  lowlevel.melbands128.min_106                     float64\n",
      " 2887  lowlevel.melbands128.min_107                     float64\n",
      " 2888  lowlevel.melbands128.min_108                     float64\n",
      " 2889  lowlevel.melbands128.min_109                     float64\n",
      " 2890  lowlevel.melbands128.min_110                     float64\n",
      " 2891  lowlevel.melbands128.min_111                     float64\n",
      " 2892  lowlevel.melbands128.min_112                     float64\n",
      " 2893  lowlevel.melbands128.min_113                     float64\n",
      " 2894  lowlevel.melbands128.min_114                     float64\n",
      " 2895  lowlevel.melbands128.min_115                     float64\n",
      " 2896  lowlevel.melbands128.min_116                     float64\n",
      " 2897  lowlevel.melbands128.min_117                     float64\n",
      " 2898  lowlevel.melbands128.min_118                     float64\n",
      " 2899  lowlevel.melbands128.min_119                     float64\n",
      " 2900  lowlevel.melbands128.min_120                     float64\n",
      " 2901  lowlevel.melbands128.min_121                     float64\n",
      " 2902  lowlevel.melbands128.min_122                     float64\n",
      " 2903  lowlevel.melbands128.min_123                     float64\n",
      " 2904  lowlevel.melbands128.min_124                     float64\n",
      " 2905  lowlevel.melbands128.min_125                     float64\n",
      " 2906  lowlevel.melbands128.min_126                     float64\n",
      " 2907  lowlevel.melbands128.min_127                     float64\n",
      " 2908  lowlevel.melbands128.stdev_0                     float64\n",
      " 2909  lowlevel.melbands128.stdev_1                     float64\n",
      " 2910  lowlevel.melbands128.stdev_2                     float64\n",
      " 2911  lowlevel.melbands128.stdev_3                     float64\n",
      " 2912  lowlevel.melbands128.stdev_4                     float64\n",
      " 2913  lowlevel.melbands128.stdev_5                     float64\n",
      " 2914  lowlevel.melbands128.stdev_6                     float64\n",
      " 2915  lowlevel.melbands128.stdev_7                     float64\n",
      " 2916  lowlevel.melbands128.stdev_8                     float64\n",
      " 2917  lowlevel.melbands128.stdev_9                     float64\n",
      " 2918  lowlevel.melbands128.stdev_10                    float64\n",
      " 2919  lowlevel.melbands128.stdev_11                    float64\n",
      " 2920  lowlevel.melbands128.stdev_12                    float64\n",
      " 2921  lowlevel.melbands128.stdev_13                    float64\n",
      " 2922  lowlevel.melbands128.stdev_14                    float64\n",
      " 2923  lowlevel.melbands128.stdev_15                    float64\n",
      " 2924  lowlevel.melbands128.stdev_16                    float64\n",
      " 2925  lowlevel.melbands128.stdev_17                    float64\n",
      " 2926  lowlevel.melbands128.stdev_18                    float64\n",
      " 2927  lowlevel.melbands128.stdev_19                    float64\n",
      " 2928  lowlevel.melbands128.stdev_20                    float64\n",
      " 2929  lowlevel.melbands128.stdev_21                    float64\n",
      " 2930  lowlevel.melbands128.stdev_22                    float64\n",
      " 2931  lowlevel.melbands128.stdev_23                    float64\n",
      " 2932  lowlevel.melbands128.stdev_24                    float64\n",
      " 2933  lowlevel.melbands128.stdev_25                    float64\n",
      " 2934  lowlevel.melbands128.stdev_26                    float64\n",
      " 2935  lowlevel.melbands128.stdev_27                    float64\n",
      " 2936  lowlevel.melbands128.stdev_28                    float64\n",
      " 2937  lowlevel.melbands128.stdev_29                    float64\n",
      " 2938  lowlevel.melbands128.stdev_30                    float64\n",
      " 2939  lowlevel.melbands128.stdev_31                    float64\n",
      " 2940  lowlevel.melbands128.stdev_32                    float64\n",
      " 2941  lowlevel.melbands128.stdev_33                    float64\n",
      " 2942  lowlevel.melbands128.stdev_34                    float64\n",
      " 2943  lowlevel.melbands128.stdev_35                    float64\n",
      " 2944  lowlevel.melbands128.stdev_36                    float64\n",
      " 2945  lowlevel.melbands128.stdev_37                    float64\n",
      " 2946  lowlevel.melbands128.stdev_38                    float64\n",
      " 2947  lowlevel.melbands128.stdev_39                    float64\n",
      " 2948  lowlevel.melbands128.stdev_40                    float64\n",
      " 2949  lowlevel.melbands128.stdev_41                    float64\n",
      " 2950  lowlevel.melbands128.stdev_42                    float64\n",
      " 2951  lowlevel.melbands128.stdev_43                    float64\n",
      " 2952  lowlevel.melbands128.stdev_44                    float64\n",
      " 2953  lowlevel.melbands128.stdev_45                    float64\n",
      " 2954  lowlevel.melbands128.stdev_46                    float64\n",
      " 2955  lowlevel.melbands128.stdev_47                    float64\n",
      " 2956  lowlevel.melbands128.stdev_48                    float64\n",
      " 2957  lowlevel.melbands128.stdev_49                    float64\n",
      " 2958  lowlevel.melbands128.stdev_50                    float64\n",
      " 2959  lowlevel.melbands128.stdev_51                    float64\n",
      " 2960  lowlevel.melbands128.stdev_52                    float64\n",
      " 2961  lowlevel.melbands128.stdev_53                    float64\n",
      " 2962  lowlevel.melbands128.stdev_54                    float64\n",
      " 2963  lowlevel.melbands128.stdev_55                    float64\n",
      " 2964  lowlevel.melbands128.stdev_56                    float64\n",
      " 2965  lowlevel.melbands128.stdev_57                    float64\n",
      " 2966  lowlevel.melbands128.stdev_58                    float64\n",
      " 2967  lowlevel.melbands128.stdev_59                    float64\n",
      " 2968  lowlevel.melbands128.stdev_60                    float64\n",
      " 2969  lowlevel.melbands128.stdev_61                    float64\n",
      " 2970  lowlevel.melbands128.stdev_62                    float64\n",
      " 2971  lowlevel.melbands128.stdev_63                    float64\n",
      " 2972  lowlevel.melbands128.stdev_64                    float64\n",
      " 2973  lowlevel.melbands128.stdev_65                    float64\n",
      " 2974  lowlevel.melbands128.stdev_66                    float64\n",
      " 2975  lowlevel.melbands128.stdev_67                    float64\n",
      " 2976  lowlevel.melbands128.stdev_68                    float64\n",
      " 2977  lowlevel.melbands128.stdev_69                    float64\n",
      " 2978  lowlevel.melbands128.stdev_70                    float64\n",
      " 2979  lowlevel.melbands128.stdev_71                    float64\n",
      " 2980  lowlevel.melbands128.stdev_72                    float64\n",
      " 2981  lowlevel.melbands128.stdev_73                    float64\n",
      " 2982  lowlevel.melbands128.stdev_74                    float64\n",
      " 2983  lowlevel.melbands128.stdev_75                    float64\n",
      " 2984  lowlevel.melbands128.stdev_76                    float64\n",
      " 2985  lowlevel.melbands128.stdev_77                    float64\n",
      " 2986  lowlevel.melbands128.stdev_78                    float64\n",
      " 2987  lowlevel.melbands128.stdev_79                    float64\n",
      " 2988  lowlevel.melbands128.stdev_80                    float64\n",
      " 2989  lowlevel.melbands128.stdev_81                    float64\n",
      " 2990  lowlevel.melbands128.stdev_82                    float64\n",
      " 2991  lowlevel.melbands128.stdev_83                    float64\n",
      " 2992  lowlevel.melbands128.stdev_84                    float64\n",
      " 2993  lowlevel.melbands128.stdev_85                    float64\n",
      " 2994  lowlevel.melbands128.stdev_86                    float64\n",
      " 2995  lowlevel.melbands128.stdev_87                    float64\n",
      " 2996  lowlevel.melbands128.stdev_88                    float64\n",
      " 2997  lowlevel.melbands128.stdev_89                    float64\n",
      " 2998  lowlevel.melbands128.stdev_90                    float64\n",
      " 2999  lowlevel.melbands128.stdev_91                    float64\n",
      " 3000  lowlevel.melbands128.stdev_92                    float64\n",
      " 3001  lowlevel.melbands128.stdev_93                    float64\n",
      " 3002  lowlevel.melbands128.stdev_94                    float64\n",
      " 3003  lowlevel.melbands128.stdev_95                    float64\n",
      " 3004  lowlevel.melbands128.stdev_96                    float64\n",
      " 3005  lowlevel.melbands128.stdev_97                    float64\n",
      " 3006  lowlevel.melbands128.stdev_98                    float64\n",
      " 3007  lowlevel.melbands128.stdev_99                    float64\n",
      " 3008  lowlevel.melbands128.stdev_100                   float64\n",
      " 3009  lowlevel.melbands128.stdev_101                   float64\n",
      " 3010  lowlevel.melbands128.stdev_102                   float64\n",
      " 3011  lowlevel.melbands128.stdev_103                   float64\n",
      " 3012  lowlevel.melbands128.stdev_104                   float64\n",
      " 3013  lowlevel.melbands128.stdev_105                   float64\n",
      " 3014  lowlevel.melbands128.stdev_106                   float64\n",
      " 3015  lowlevel.melbands128.stdev_107                   float64\n",
      " 3016  lowlevel.melbands128.stdev_108                   float64\n",
      " 3017  lowlevel.melbands128.stdev_109                   float64\n",
      " 3018  lowlevel.melbands128.stdev_110                   float64\n",
      " 3019  lowlevel.melbands128.stdev_111                   float64\n",
      " 3020  lowlevel.melbands128.stdev_112                   float64\n",
      " 3021  lowlevel.melbands128.stdev_113                   float64\n",
      " 3022  lowlevel.melbands128.stdev_114                   float64\n",
      " 3023  lowlevel.melbands128.stdev_115                   float64\n",
      " 3024  lowlevel.melbands128.stdev_116                   float64\n",
      " 3025  lowlevel.melbands128.stdev_117                   float64\n",
      " 3026  lowlevel.melbands128.stdev_118                   float64\n",
      " 3027  lowlevel.melbands128.stdev_119                   float64\n",
      " 3028  lowlevel.melbands128.stdev_120                   float64\n",
      " 3029  lowlevel.melbands128.stdev_121                   float64\n",
      " 3030  lowlevel.melbands128.stdev_122                   float64\n",
      " 3031  lowlevel.melbands128.stdev_123                   float64\n",
      " 3032  lowlevel.melbands128.stdev_124                   float64\n",
      " 3033  lowlevel.melbands128.stdev_125                   float64\n",
      " 3034  lowlevel.melbands128.stdev_126                   float64\n",
      " 3035  lowlevel.melbands128.stdev_127                   float64\n",
      " 3036  lowlevel.melbands128.var_0                       float64\n",
      " 3037  lowlevel.melbands128.var_1                       float64\n",
      " 3038  lowlevel.melbands128.var_2                       float64\n",
      " 3039  lowlevel.melbands128.var_3                       float64\n",
      " 3040  lowlevel.melbands128.var_4                       float64\n",
      " 3041  lowlevel.melbands128.var_5                       float64\n",
      " 3042  lowlevel.melbands128.var_6                       float64\n",
      " 3043  lowlevel.melbands128.var_7                       float64\n",
      " 3044  lowlevel.melbands128.var_8                       float64\n",
      " 3045  lowlevel.melbands128.var_9                       float64\n",
      " 3046  lowlevel.melbands128.var_10                      float64\n",
      " 3047  lowlevel.melbands128.var_11                      float64\n",
      " 3048  lowlevel.melbands128.var_12                      float64\n",
      " 3049  lowlevel.melbands128.var_13                      float64\n",
      " 3050  lowlevel.melbands128.var_14                      float64\n",
      " 3051  lowlevel.melbands128.var_15                      float64\n",
      " 3052  lowlevel.melbands128.var_16                      float64\n",
      " 3053  lowlevel.melbands128.var_17                      float64\n",
      " 3054  lowlevel.melbands128.var_18                      float64\n",
      " 3055  lowlevel.melbands128.var_19                      float64\n",
      " 3056  lowlevel.melbands128.var_20                      float64\n",
      " 3057  lowlevel.melbands128.var_21                      float64\n",
      " 3058  lowlevel.melbands128.var_22                      float64\n",
      " 3059  lowlevel.melbands128.var_23                      float64\n",
      " 3060  lowlevel.melbands128.var_24                      float64\n",
      " 3061  lowlevel.melbands128.var_25                      float64\n",
      " 3062  lowlevel.melbands128.var_26                      float64\n",
      " 3063  lowlevel.melbands128.var_27                      float64\n",
      " 3064  lowlevel.melbands128.var_28                      float64\n",
      " 3065  lowlevel.melbands128.var_29                      float64\n",
      " 3066  lowlevel.melbands128.var_30                      float64\n",
      " 3067  lowlevel.melbands128.var_31                      float64\n",
      " 3068  lowlevel.melbands128.var_32                      float64\n",
      " 3069  lowlevel.melbands128.var_33                      float64\n",
      " 3070  lowlevel.melbands128.var_34                      float64\n",
      " 3071  lowlevel.melbands128.var_35                      float64\n",
      " 3072  lowlevel.melbands128.var_36                      float64\n",
      " 3073  lowlevel.melbands128.var_37                      float64\n",
      " 3074  lowlevel.melbands128.var_38                      float64\n",
      " 3075  lowlevel.melbands128.var_39                      float64\n",
      " 3076  lowlevel.melbands128.var_40                      float64\n",
      " 3077  lowlevel.melbands128.var_41                      float64\n",
      " 3078  lowlevel.melbands128.var_42                      float64\n",
      " 3079  lowlevel.melbands128.var_43                      float64\n",
      " 3080  lowlevel.melbands128.var_44                      float64\n",
      " 3081  lowlevel.melbands128.var_45                      float64\n",
      " 3082  lowlevel.melbands128.var_46                      float64\n",
      " 3083  lowlevel.melbands128.var_47                      float64\n",
      " 3084  lowlevel.melbands128.var_48                      float64\n",
      " 3085  lowlevel.melbands128.var_49                      float64\n",
      " 3086  lowlevel.melbands128.var_50                      float64\n",
      " 3087  lowlevel.melbands128.var_51                      float64\n",
      " 3088  lowlevel.melbands128.var_52                      float64\n",
      " 3089  lowlevel.melbands128.var_53                      float64\n",
      " 3090  lowlevel.melbands128.var_54                      float64\n",
      " 3091  lowlevel.melbands128.var_55                      float64\n",
      " 3092  lowlevel.melbands128.var_56                      float64\n",
      " 3093  lowlevel.melbands128.var_57                      float64\n",
      " 3094  lowlevel.melbands128.var_58                      float64\n",
      " 3095  lowlevel.melbands128.var_59                      float64\n",
      " 3096  lowlevel.melbands128.var_60                      float64\n",
      " 3097  lowlevel.melbands128.var_61                      float64\n",
      " 3098  lowlevel.melbands128.var_62                      float64\n",
      " 3099  lowlevel.melbands128.var_63                      float64\n",
      " 3100  lowlevel.melbands128.var_64                      float64\n",
      " 3101  lowlevel.melbands128.var_65                      float64\n",
      " 3102  lowlevel.melbands128.var_66                      float64\n",
      " 3103  lowlevel.melbands128.var_67                      float64\n",
      " 3104  lowlevel.melbands128.var_68                      float64\n",
      " 3105  lowlevel.melbands128.var_69                      float64\n",
      " 3106  lowlevel.melbands128.var_70                      float64\n",
      " 3107  lowlevel.melbands128.var_71                      float64\n",
      " 3108  lowlevel.melbands128.var_72                      float64\n",
      " 3109  lowlevel.melbands128.var_73                      float64\n",
      " 3110  lowlevel.melbands128.var_74                      float64\n",
      " 3111  lowlevel.melbands128.var_75                      float64\n",
      " 3112  lowlevel.melbands128.var_76                      float64\n",
      " 3113  lowlevel.melbands128.var_77                      float64\n",
      " 3114  lowlevel.melbands128.var_78                      float64\n",
      " 3115  lowlevel.melbands128.var_79                      float64\n",
      " 3116  lowlevel.melbands128.var_80                      float64\n",
      " 3117  lowlevel.melbands128.var_81                      float64\n",
      " 3118  lowlevel.melbands128.var_82                      float64\n",
      " 3119  lowlevel.melbands128.var_83                      float64\n",
      " 3120  lowlevel.melbands128.var_84                      float64\n",
      " 3121  lowlevel.melbands128.var_85                      float64\n",
      " 3122  lowlevel.melbands128.var_86                      float64\n",
      " 3123  lowlevel.melbands128.var_87                      float64\n",
      " 3124  lowlevel.melbands128.var_88                      float64\n",
      " 3125  lowlevel.melbands128.var_89                      float64\n",
      " 3126  lowlevel.melbands128.var_90                      float64\n",
      " 3127  lowlevel.melbands128.var_91                      float64\n",
      " 3128  lowlevel.melbands128.var_92                      float64\n",
      " 3129  lowlevel.melbands128.var_93                      float64\n",
      " 3130  lowlevel.melbands128.var_94                      float64\n",
      " 3131  lowlevel.melbands128.var_95                      float64\n",
      " 3132  lowlevel.melbands128.var_96                      float64\n",
      " 3133  lowlevel.melbands128.var_97                      float64\n",
      " 3134  lowlevel.melbands128.var_98                      float64\n",
      " 3135  lowlevel.melbands128.var_99                      float64\n",
      " 3136  lowlevel.melbands128.var_100                     float64\n",
      " 3137  lowlevel.melbands128.var_101                     float64\n",
      " 3138  lowlevel.melbands128.var_102                     float64\n",
      " 3139  lowlevel.melbands128.var_103                     float64\n",
      " 3140  lowlevel.melbands128.var_104                     float64\n",
      " 3141  lowlevel.melbands128.var_105                     float64\n",
      " 3142  lowlevel.melbands128.var_106                     float64\n",
      " 3143  lowlevel.melbands128.var_107                     float64\n",
      " 3144  lowlevel.melbands128.var_108                     float64\n",
      " 3145  lowlevel.melbands128.var_109                     float64\n",
      " 3146  lowlevel.melbands128.var_110                     float64\n",
      " 3147  lowlevel.melbands128.var_111                     float64\n",
      " 3148  lowlevel.melbands128.var_112                     float64\n",
      " 3149  lowlevel.melbands128.var_113                     float64\n",
      " 3150  lowlevel.melbands128.var_114                     float64\n",
      " 3151  lowlevel.melbands128.var_115                     float64\n",
      " 3152  lowlevel.melbands128.var_116                     float64\n",
      " 3153  lowlevel.melbands128.var_117                     float64\n",
      " 3154  lowlevel.melbands128.var_118                     float64\n",
      " 3155  lowlevel.melbands128.var_119                     float64\n",
      " 3156  lowlevel.melbands128.var_120                     float64\n",
      " 3157  lowlevel.melbands128.var_121                     float64\n",
      " 3158  lowlevel.melbands128.var_122                     float64\n",
      " 3159  lowlevel.melbands128.var_123                     float64\n",
      " 3160  lowlevel.melbands128.var_124                     float64\n",
      " 3161  lowlevel.melbands128.var_125                     float64\n",
      " 3162  lowlevel.melbands128.var_126                     float64\n",
      " 3163  lowlevel.melbands128.var_127                     float64\n",
      " 3164  lowlevel.mfcc.cov_0                              float64\n",
      " 3165  lowlevel.mfcc.cov_1                              float64\n",
      " 3166  lowlevel.mfcc.cov_2                              float64\n",
      " 3167  lowlevel.mfcc.cov_3                              float64\n",
      " 3168  lowlevel.mfcc.cov_4                              float64\n",
      " 3169  lowlevel.mfcc.cov_5                              float64\n",
      " 3170  lowlevel.mfcc.cov_6                              float64\n",
      " 3171  lowlevel.mfcc.cov_7                              float64\n",
      " 3172  lowlevel.mfcc.cov_8                              float64\n",
      " 3173  lowlevel.mfcc.cov_9                              float64\n",
      " 3174  lowlevel.mfcc.cov_10                             float64\n",
      " 3175  lowlevel.mfcc.cov_11                             float64\n",
      " 3176  lowlevel.mfcc.cov_12                             float64\n",
      " 3177  lowlevel.mfcc.cov_13                             float64\n",
      " 3178  lowlevel.mfcc.cov_14                             float64\n",
      " 3179  lowlevel.mfcc.cov_15                             float64\n",
      " 3180  lowlevel.mfcc.cov_16                             float64\n",
      " 3181  lowlevel.mfcc.cov_17                             float64\n",
      " 3182  lowlevel.mfcc.cov_18                             float64\n",
      " 3183  lowlevel.mfcc.cov_19                             float64\n",
      " 3184  lowlevel.mfcc.cov_20                             float64\n",
      " 3185  lowlevel.mfcc.cov_21                             float64\n",
      " 3186  lowlevel.mfcc.cov_22                             float64\n",
      " 3187  lowlevel.mfcc.cov_23                             float64\n",
      " 3188  lowlevel.mfcc.cov_24                             float64\n",
      " 3189  lowlevel.mfcc.cov_25                             float64\n",
      " 3190  lowlevel.mfcc.cov_26                             float64\n",
      " 3191  lowlevel.mfcc.cov_27                             float64\n",
      " 3192  lowlevel.mfcc.cov_28                             float64\n",
      " 3193  lowlevel.mfcc.cov_29                             float64\n",
      " 3194  lowlevel.mfcc.cov_30                             float64\n",
      " 3195  lowlevel.mfcc.cov_31                             float64\n",
      " 3196  lowlevel.mfcc.cov_32                             float64\n",
      " 3197  lowlevel.mfcc.cov_33                             float64\n",
      " 3198  lowlevel.mfcc.cov_34                             float64\n",
      " 3199  lowlevel.mfcc.cov_35                             float64\n",
      " 3200  lowlevel.mfcc.cov_36                             float64\n",
      " 3201  lowlevel.mfcc.cov_37                             float64\n",
      " 3202  lowlevel.mfcc.cov_38                             float64\n",
      " 3203  lowlevel.mfcc.cov_39                             float64\n",
      " 3204  lowlevel.mfcc.cov_40                             float64\n",
      " 3205  lowlevel.mfcc.cov_41                             float64\n",
      " 3206  lowlevel.mfcc.cov_42                             float64\n",
      " 3207  lowlevel.mfcc.cov_43                             float64\n",
      " 3208  lowlevel.mfcc.cov_44                             float64\n",
      " 3209  lowlevel.mfcc.cov_45                             float64\n",
      " 3210  lowlevel.mfcc.cov_46                             float64\n",
      " 3211  lowlevel.mfcc.cov_47                             float64\n",
      " 3212  lowlevel.mfcc.cov_48                             float64\n",
      " 3213  lowlevel.mfcc.cov_49                             float64\n",
      " 3214  lowlevel.mfcc.cov_50                             float64\n",
      " 3215  lowlevel.mfcc.cov_51                             float64\n",
      " 3216  lowlevel.mfcc.cov_52                             float64\n",
      " 3217  lowlevel.mfcc.cov_53                             float64\n",
      " 3218  lowlevel.mfcc.cov_54                             float64\n",
      " 3219  lowlevel.mfcc.cov_55                             float64\n",
      " 3220  lowlevel.mfcc.cov_56                             float64\n",
      " 3221  lowlevel.mfcc.cov_57                             float64\n",
      " 3222  lowlevel.mfcc.cov_58                             float64\n",
      " 3223  lowlevel.mfcc.cov_59                             float64\n",
      " 3224  lowlevel.mfcc.cov_60                             float64\n",
      " 3225  lowlevel.mfcc.cov_61                             float64\n",
      " 3226  lowlevel.mfcc.cov_62                             float64\n",
      " 3227  lowlevel.mfcc.cov_63                             float64\n",
      " 3228  lowlevel.mfcc.cov_64                             float64\n",
      " 3229  lowlevel.mfcc.cov_65                             float64\n",
      " 3230  lowlevel.mfcc.cov_66                             float64\n",
      " 3231  lowlevel.mfcc.cov_67                             float64\n",
      " 3232  lowlevel.mfcc.cov_68                             float64\n",
      " 3233  lowlevel.mfcc.cov_69                             float64\n",
      " 3234  lowlevel.mfcc.cov_70                             float64\n",
      " 3235  lowlevel.mfcc.cov_71                             float64\n",
      " 3236  lowlevel.mfcc.cov_72                             float64\n",
      " 3237  lowlevel.mfcc.cov_73                             float64\n",
      " 3238  lowlevel.mfcc.cov_74                             float64\n",
      " 3239  lowlevel.mfcc.cov_75                             float64\n",
      " 3240  lowlevel.mfcc.cov_76                             float64\n",
      " 3241  lowlevel.mfcc.cov_77                             float64\n",
      " 3242  lowlevel.mfcc.cov_78                             float64\n",
      " 3243  lowlevel.mfcc.cov_79                             float64\n",
      " 3244  lowlevel.mfcc.cov_80                             float64\n",
      " 3245  lowlevel.mfcc.cov_81                             float64\n",
      " 3246  lowlevel.mfcc.cov_82                             float64\n",
      " 3247  lowlevel.mfcc.cov_83                             float64\n",
      " 3248  lowlevel.mfcc.cov_84                             float64\n",
      " 3249  lowlevel.mfcc.cov_85                             float64\n",
      " 3250  lowlevel.mfcc.cov_86                             float64\n",
      " 3251  lowlevel.mfcc.cov_87                             float64\n",
      " 3252  lowlevel.mfcc.cov_88                             float64\n",
      " 3253  lowlevel.mfcc.cov_89                             float64\n",
      " 3254  lowlevel.mfcc.cov_90                             float64\n",
      " 3255  lowlevel.mfcc.cov_91                             float64\n",
      " 3256  lowlevel.mfcc.cov_92                             float64\n",
      " 3257  lowlevel.mfcc.cov_93                             float64\n",
      " 3258  lowlevel.mfcc.cov_94                             float64\n",
      " 3259  lowlevel.mfcc.cov_95                             float64\n",
      " 3260  lowlevel.mfcc.cov_96                             float64\n",
      " 3261  lowlevel.mfcc.cov_97                             float64\n",
      " 3262  lowlevel.mfcc.cov_98                             float64\n",
      " 3263  lowlevel.mfcc.cov_99                             float64\n",
      " 3264  lowlevel.mfcc.cov_100                            float64\n",
      " 3265  lowlevel.mfcc.cov_101                            float64\n",
      " 3266  lowlevel.mfcc.cov_102                            float64\n",
      " 3267  lowlevel.mfcc.cov_103                            float64\n",
      " 3268  lowlevel.mfcc.cov_104                            float64\n",
      " 3269  lowlevel.mfcc.cov_105                            float64\n",
      " 3270  lowlevel.mfcc.cov_106                            float64\n",
      " 3271  lowlevel.mfcc.cov_107                            float64\n",
      " 3272  lowlevel.mfcc.cov_108                            float64\n",
      " 3273  lowlevel.mfcc.cov_109                            float64\n",
      " 3274  lowlevel.mfcc.cov_110                            float64\n",
      " 3275  lowlevel.mfcc.cov_111                            float64\n",
      " 3276  lowlevel.mfcc.cov_112                            float64\n",
      " 3277  lowlevel.mfcc.cov_113                            float64\n",
      " 3278  lowlevel.mfcc.cov_114                            float64\n",
      " 3279  lowlevel.mfcc.cov_115                            float64\n",
      " 3280  lowlevel.mfcc.cov_116                            float64\n",
      " 3281  lowlevel.mfcc.cov_117                            float64\n",
      " 3282  lowlevel.mfcc.cov_118                            float64\n",
      " 3283  lowlevel.mfcc.cov_119                            float64\n",
      " 3284  lowlevel.mfcc.cov_120                            float64\n",
      " 3285  lowlevel.mfcc.cov_121                            float64\n",
      " 3286  lowlevel.mfcc.cov_122                            float64\n",
      " 3287  lowlevel.mfcc.cov_123                            float64\n",
      " 3288  lowlevel.mfcc.cov_124                            float64\n",
      " 3289  lowlevel.mfcc.cov_125                            float64\n",
      " 3290  lowlevel.mfcc.cov_126                            float64\n",
      " 3291  lowlevel.mfcc.cov_127                            float64\n",
      " 3292  lowlevel.mfcc.cov_128                            float64\n",
      " 3293  lowlevel.mfcc.cov_129                            float64\n",
      " 3294  lowlevel.mfcc.cov_130                            float64\n",
      " 3295  lowlevel.mfcc.cov_131                            float64\n",
      " 3296  lowlevel.mfcc.cov_132                            float64\n",
      " 3297  lowlevel.mfcc.cov_133                            float64\n",
      " 3298  lowlevel.mfcc.cov_134                            float64\n",
      " 3299  lowlevel.mfcc.cov_135                            float64\n",
      " 3300  lowlevel.mfcc.cov_136                            float64\n",
      " 3301  lowlevel.mfcc.cov_137                            float64\n",
      " 3302  lowlevel.mfcc.cov_138                            float64\n",
      " 3303  lowlevel.mfcc.cov_139                            float64\n",
      " 3304  lowlevel.mfcc.cov_140                            float64\n",
      " 3305  lowlevel.mfcc.cov_141                            float64\n",
      " 3306  lowlevel.mfcc.cov_142                            float64\n",
      " 3307  lowlevel.mfcc.cov_143                            float64\n",
      " 3308  lowlevel.mfcc.cov_144                            float64\n",
      " 3309  lowlevel.mfcc.cov_145                            float64\n",
      " 3310  lowlevel.mfcc.cov_146                            float64\n",
      " 3311  lowlevel.mfcc.cov_147                            float64\n",
      " 3312  lowlevel.mfcc.cov_148                            float64\n",
      " 3313  lowlevel.mfcc.cov_149                            float64\n",
      " 3314  lowlevel.mfcc.cov_150                            float64\n",
      " 3315  lowlevel.mfcc.cov_151                            float64\n",
      " 3316  lowlevel.mfcc.cov_152                            float64\n",
      " 3317  lowlevel.mfcc.cov_153                            float64\n",
      " 3318  lowlevel.mfcc.cov_154                            float64\n",
      " 3319  lowlevel.mfcc.cov_155                            float64\n",
      " 3320  lowlevel.mfcc.cov_156                            float64\n",
      " 3321  lowlevel.mfcc.cov_157                            float64\n",
      " 3322  lowlevel.mfcc.cov_158                            float64\n",
      " 3323  lowlevel.mfcc.cov_159                            float64\n",
      " 3324  lowlevel.mfcc.cov_160                            float64\n",
      " 3325  lowlevel.mfcc.cov_161                            float64\n",
      " 3326  lowlevel.mfcc.cov_162                            float64\n",
      " 3327  lowlevel.mfcc.cov_163                            float64\n",
      " 3328  lowlevel.mfcc.cov_164                            float64\n",
      " 3329  lowlevel.mfcc.cov_165                            float64\n",
      " 3330  lowlevel.mfcc.cov_166                            float64\n",
      " 3331  lowlevel.mfcc.cov_167                            float64\n",
      " 3332  lowlevel.mfcc.cov_168                            float64\n",
      " 3333  lowlevel.mfcc.icov_0                             float64\n",
      " 3334  lowlevel.mfcc.icov_1                             float64\n",
      " 3335  lowlevel.mfcc.icov_2                             float64\n",
      " 3336  lowlevel.mfcc.icov_3                             float64\n",
      " 3337  lowlevel.mfcc.icov_4                             float64\n",
      " 3338  lowlevel.mfcc.icov_5                             float64\n",
      " 3339  lowlevel.mfcc.icov_6                             float64\n",
      " 3340  lowlevel.mfcc.icov_7                             float64\n",
      " 3341  lowlevel.mfcc.icov_8                             float64\n",
      " 3342  lowlevel.mfcc.icov_9                             float64\n",
      " 3343  lowlevel.mfcc.icov_10                            float64\n",
      " 3344  lowlevel.mfcc.icov_11                            float64\n",
      " 3345  lowlevel.mfcc.icov_12                            float64\n",
      " 3346  lowlevel.mfcc.icov_13                            float64\n",
      " 3347  lowlevel.mfcc.icov_14                            float64\n",
      " 3348  lowlevel.mfcc.icov_15                            float64\n",
      " 3349  lowlevel.mfcc.icov_16                            float64\n",
      " 3350  lowlevel.mfcc.icov_17                            float64\n",
      " 3351  lowlevel.mfcc.icov_18                            float64\n",
      " 3352  lowlevel.mfcc.icov_19                            float64\n",
      " 3353  lowlevel.mfcc.icov_20                            float64\n",
      " 3354  lowlevel.mfcc.icov_21                            float64\n",
      " 3355  lowlevel.mfcc.icov_22                            float64\n",
      " 3356  lowlevel.mfcc.icov_23                            float64\n",
      " 3357  lowlevel.mfcc.icov_24                            float64\n",
      " 3358  lowlevel.mfcc.icov_25                            float64\n",
      " 3359  lowlevel.mfcc.icov_26                            float64\n",
      " 3360  lowlevel.mfcc.icov_27                            float64\n",
      " 3361  lowlevel.mfcc.icov_28                            float64\n",
      " 3362  lowlevel.mfcc.icov_29                            float64\n",
      " 3363  lowlevel.mfcc.icov_30                            float64\n",
      " 3364  lowlevel.mfcc.icov_31                            float64\n",
      " 3365  lowlevel.mfcc.icov_32                            float64\n",
      " 3366  lowlevel.mfcc.icov_33                            float64\n",
      " 3367  lowlevel.mfcc.icov_34                            float64\n",
      " 3368  lowlevel.mfcc.icov_35                            float64\n",
      " 3369  lowlevel.mfcc.icov_36                            float64\n",
      " 3370  lowlevel.mfcc.icov_37                            float64\n",
      " 3371  lowlevel.mfcc.icov_38                            float64\n",
      " 3372  lowlevel.mfcc.icov_39                            float64\n",
      " 3373  lowlevel.mfcc.icov_40                            float64\n",
      " 3374  lowlevel.mfcc.icov_41                            float64\n",
      " 3375  lowlevel.mfcc.icov_42                            float64\n",
      " 3376  lowlevel.mfcc.icov_43                            float64\n",
      " 3377  lowlevel.mfcc.icov_44                            float64\n",
      " 3378  lowlevel.mfcc.icov_45                            float64\n",
      " 3379  lowlevel.mfcc.icov_46                            float64\n",
      " 3380  lowlevel.mfcc.icov_47                            float64\n",
      " 3381  lowlevel.mfcc.icov_48                            float64\n",
      " 3382  lowlevel.mfcc.icov_49                            float64\n",
      " 3383  lowlevel.mfcc.icov_50                            float64\n",
      " 3384  lowlevel.mfcc.icov_51                            float64\n",
      " 3385  lowlevel.mfcc.icov_52                            float64\n",
      " 3386  lowlevel.mfcc.icov_53                            float64\n",
      " 3387  lowlevel.mfcc.icov_54                            float64\n",
      " 3388  lowlevel.mfcc.icov_55                            float64\n",
      " 3389  lowlevel.mfcc.icov_56                            float64\n",
      " 3390  lowlevel.mfcc.icov_57                            float64\n",
      " 3391  lowlevel.mfcc.icov_58                            float64\n",
      " 3392  lowlevel.mfcc.icov_59                            float64\n",
      " 3393  lowlevel.mfcc.icov_60                            float64\n",
      " 3394  lowlevel.mfcc.icov_61                            float64\n",
      " 3395  lowlevel.mfcc.icov_62                            float64\n",
      " 3396  lowlevel.mfcc.icov_63                            float64\n",
      " 3397  lowlevel.mfcc.icov_64                            float64\n",
      " 3398  lowlevel.mfcc.icov_65                            float64\n",
      " 3399  lowlevel.mfcc.icov_66                            float64\n",
      " 3400  lowlevel.mfcc.icov_67                            float64\n",
      " 3401  lowlevel.mfcc.icov_68                            float64\n",
      " 3402  lowlevel.mfcc.icov_69                            float64\n",
      " 3403  lowlevel.mfcc.icov_70                            float64\n",
      " 3404  lowlevel.mfcc.icov_71                            float64\n",
      " 3405  lowlevel.mfcc.icov_72                            float64\n",
      " 3406  lowlevel.mfcc.icov_73                            float64\n",
      " 3407  lowlevel.mfcc.icov_74                            float64\n",
      " 3408  lowlevel.mfcc.icov_75                            float64\n",
      " 3409  lowlevel.mfcc.icov_76                            float64\n",
      " 3410  lowlevel.mfcc.icov_77                            float64\n",
      " 3411  lowlevel.mfcc.icov_78                            float64\n",
      " 3412  lowlevel.mfcc.icov_79                            float64\n",
      " 3413  lowlevel.mfcc.icov_80                            float64\n",
      " 3414  lowlevel.mfcc.icov_81                            float64\n",
      " 3415  lowlevel.mfcc.icov_82                            float64\n",
      " 3416  lowlevel.mfcc.icov_83                            float64\n",
      " 3417  lowlevel.mfcc.icov_84                            float64\n",
      " 3418  lowlevel.mfcc.icov_85                            float64\n",
      " 3419  lowlevel.mfcc.icov_86                            float64\n",
      " 3420  lowlevel.mfcc.icov_87                            float64\n",
      " 3421  lowlevel.mfcc.icov_88                            float64\n",
      " 3422  lowlevel.mfcc.icov_89                            float64\n",
      " 3423  lowlevel.mfcc.icov_90                            float64\n",
      " 3424  lowlevel.mfcc.icov_91                            float64\n",
      " 3425  lowlevel.mfcc.icov_92                            float64\n",
      " 3426  lowlevel.mfcc.icov_93                            float64\n",
      " 3427  lowlevel.mfcc.icov_94                            float64\n",
      " 3428  lowlevel.mfcc.icov_95                            float64\n",
      " 3429  lowlevel.mfcc.icov_96                            float64\n",
      " 3430  lowlevel.mfcc.icov_97                            float64\n",
      " 3431  lowlevel.mfcc.icov_98                            float64\n",
      " 3432  lowlevel.mfcc.icov_99                            float64\n",
      " 3433  lowlevel.mfcc.icov_100                           float64\n",
      " 3434  lowlevel.mfcc.icov_101                           float64\n",
      " 3435  lowlevel.mfcc.icov_102                           float64\n",
      " 3436  lowlevel.mfcc.icov_103                           float64\n",
      " 3437  lowlevel.mfcc.icov_104                           float64\n",
      " 3438  lowlevel.mfcc.icov_105                           float64\n",
      " 3439  lowlevel.mfcc.icov_106                           float64\n",
      " 3440  lowlevel.mfcc.icov_107                           float64\n",
      " 3441  lowlevel.mfcc.icov_108                           float64\n",
      " 3442  lowlevel.mfcc.icov_109                           float64\n",
      " 3443  lowlevel.mfcc.icov_110                           float64\n",
      " 3444  lowlevel.mfcc.icov_111                           float64\n",
      " 3445  lowlevel.mfcc.icov_112                           float64\n",
      " 3446  lowlevel.mfcc.icov_113                           float64\n",
      " 3447  lowlevel.mfcc.icov_114                           float64\n",
      " 3448  lowlevel.mfcc.icov_115                           float64\n",
      " 3449  lowlevel.mfcc.icov_116                           float64\n",
      " 3450  lowlevel.mfcc.icov_117                           float64\n",
      " 3451  lowlevel.mfcc.icov_118                           float64\n",
      " 3452  lowlevel.mfcc.icov_119                           float64\n",
      " 3453  lowlevel.mfcc.icov_120                           float64\n",
      " 3454  lowlevel.mfcc.icov_121                           float64\n",
      " 3455  lowlevel.mfcc.icov_122                           float64\n",
      " 3456  lowlevel.mfcc.icov_123                           float64\n",
      " 3457  lowlevel.mfcc.icov_124                           float64\n",
      " 3458  lowlevel.mfcc.icov_125                           float64\n",
      " 3459  lowlevel.mfcc.icov_126                           float64\n",
      " 3460  lowlevel.mfcc.icov_127                           float64\n",
      " 3461  lowlevel.mfcc.icov_128                           float64\n",
      " 3462  lowlevel.mfcc.icov_129                           float64\n",
      " 3463  lowlevel.mfcc.icov_130                           float64\n",
      " 3464  lowlevel.mfcc.icov_131                           float64\n",
      " 3465  lowlevel.mfcc.icov_132                           float64\n",
      " 3466  lowlevel.mfcc.icov_133                           float64\n",
      " 3467  lowlevel.mfcc.icov_134                           float64\n",
      " 3468  lowlevel.mfcc.icov_135                           float64\n",
      " 3469  lowlevel.mfcc.icov_136                           float64\n",
      " 3470  lowlevel.mfcc.icov_137                           float64\n",
      " 3471  lowlevel.mfcc.icov_138                           float64\n",
      " 3472  lowlevel.mfcc.icov_139                           float64\n",
      " 3473  lowlevel.mfcc.icov_140                           float64\n",
      " 3474  lowlevel.mfcc.icov_141                           float64\n",
      " 3475  lowlevel.mfcc.icov_142                           float64\n",
      " 3476  lowlevel.mfcc.icov_143                           float64\n",
      " 3477  lowlevel.mfcc.icov_144                           float64\n",
      " 3478  lowlevel.mfcc.icov_145                           float64\n",
      " 3479  lowlevel.mfcc.icov_146                           float64\n",
      " 3480  lowlevel.mfcc.icov_147                           float64\n",
      " 3481  lowlevel.mfcc.icov_148                           float64\n",
      " 3482  lowlevel.mfcc.icov_149                           float64\n",
      " 3483  lowlevel.mfcc.icov_150                           float64\n",
      " 3484  lowlevel.mfcc.icov_151                           float64\n",
      " 3485  lowlevel.mfcc.icov_152                           float64\n",
      " 3486  lowlevel.mfcc.icov_153                           float64\n",
      " 3487  lowlevel.mfcc.icov_154                           float64\n",
      " 3488  lowlevel.mfcc.icov_155                           float64\n",
      " 3489  lowlevel.mfcc.icov_156                           float64\n",
      " 3490  lowlevel.mfcc.icov_157                           float64\n",
      " 3491  lowlevel.mfcc.icov_158                           float64\n",
      " 3492  lowlevel.mfcc.icov_159                           float64\n",
      " 3493  lowlevel.mfcc.icov_160                           float64\n",
      " 3494  lowlevel.mfcc.icov_161                           float64\n",
      " 3495  lowlevel.mfcc.icov_162                           float64\n",
      " 3496  lowlevel.mfcc.icov_163                           float64\n",
      " 3497  lowlevel.mfcc.icov_164                           float64\n",
      " 3498  lowlevel.mfcc.icov_165                           float64\n",
      " 3499  lowlevel.mfcc.icov_166                           float64\n",
      " 3500  lowlevel.mfcc.icov_167                           float64\n",
      " 3501  lowlevel.mfcc.icov_168                           float64\n",
      " 3502  lowlevel.mfcc.mean_0                             float64\n",
      " 3503  lowlevel.mfcc.mean_1                             float64\n",
      " 3504  lowlevel.mfcc.mean_2                             float64\n",
      " 3505  lowlevel.mfcc.mean_3                             float64\n",
      " 3506  lowlevel.mfcc.mean_4                             float64\n",
      " 3507  lowlevel.mfcc.mean_5                             float64\n",
      " 3508  lowlevel.mfcc.mean_6                             float64\n",
      " 3509  lowlevel.mfcc.mean_7                             float64\n",
      " 3510  lowlevel.mfcc.mean_8                             float64\n",
      " 3511  lowlevel.mfcc.mean_9                             float64\n",
      " 3512  lowlevel.mfcc.mean_10                            float64\n",
      " 3513  lowlevel.mfcc.mean_11                            float64\n",
      " 3514  lowlevel.mfcc.mean_12                            float64\n",
      " 3515  lowlevel.spectral_contrast_coeffs.dmean_0        float64\n",
      " 3516  lowlevel.spectral_contrast_coeffs.dmean_1        float64\n",
      " 3517  lowlevel.spectral_contrast_coeffs.dmean_2        float64\n",
      " 3518  lowlevel.spectral_contrast_coeffs.dmean_3        float64\n",
      " 3519  lowlevel.spectral_contrast_coeffs.dmean_4        float64\n",
      " 3520  lowlevel.spectral_contrast_coeffs.dmean_5        float64\n",
      " 3521  lowlevel.spectral_contrast_coeffs.dmean2_0       float64\n",
      " 3522  lowlevel.spectral_contrast_coeffs.dmean2_1       float64\n",
      " 3523  lowlevel.spectral_contrast_coeffs.dmean2_2       float64\n",
      " 3524  lowlevel.spectral_contrast_coeffs.dmean2_3       float64\n",
      " 3525  lowlevel.spectral_contrast_coeffs.dmean2_4       float64\n",
      " 3526  lowlevel.spectral_contrast_coeffs.dmean2_5       float64\n",
      " 3527  lowlevel.spectral_contrast_coeffs.dvar_0         float64\n",
      " 3528  lowlevel.spectral_contrast_coeffs.dvar_1         float64\n",
      " 3529  lowlevel.spectral_contrast_coeffs.dvar_2         float64\n",
      " 3530  lowlevel.spectral_contrast_coeffs.dvar_3         float64\n",
      " 3531  lowlevel.spectral_contrast_coeffs.dvar_4         float64\n",
      " 3532  lowlevel.spectral_contrast_coeffs.dvar_5         float64\n",
      " 3533  lowlevel.spectral_contrast_coeffs.dvar2_0        float64\n",
      " 3534  lowlevel.spectral_contrast_coeffs.dvar2_1        float64\n",
      " 3535  lowlevel.spectral_contrast_coeffs.dvar2_2        float64\n",
      " 3536  lowlevel.spectral_contrast_coeffs.dvar2_3        float64\n",
      " 3537  lowlevel.spectral_contrast_coeffs.dvar2_4        float64\n",
      " 3538  lowlevel.spectral_contrast_coeffs.dvar2_5        float64\n",
      " 3539  lowlevel.spectral_contrast_coeffs.max_0          float64\n",
      " 3540  lowlevel.spectral_contrast_coeffs.max_1          float64\n",
      " 3541  lowlevel.spectral_contrast_coeffs.max_2          float64\n",
      " 3542  lowlevel.spectral_contrast_coeffs.max_3          float64\n",
      " 3543  lowlevel.spectral_contrast_coeffs.max_4          float64\n",
      " 3544  lowlevel.spectral_contrast_coeffs.max_5          float64\n",
      " 3545  lowlevel.spectral_contrast_coeffs.mean_0         float64\n",
      " 3546  lowlevel.spectral_contrast_coeffs.mean_1         float64\n",
      " 3547  lowlevel.spectral_contrast_coeffs.mean_2         float64\n",
      " 3548  lowlevel.spectral_contrast_coeffs.mean_3         float64\n",
      " 3549  lowlevel.spectral_contrast_coeffs.mean_4         float64\n",
      " 3550  lowlevel.spectral_contrast_coeffs.mean_5         float64\n",
      " 3551  lowlevel.spectral_contrast_coeffs.median_0       float64\n",
      " 3552  lowlevel.spectral_contrast_coeffs.median_1       float64\n",
      " 3553  lowlevel.spectral_contrast_coeffs.median_2       float64\n",
      " 3554  lowlevel.spectral_contrast_coeffs.median_3       float64\n",
      " 3555  lowlevel.spectral_contrast_coeffs.median_4       float64\n",
      " 3556  lowlevel.spectral_contrast_coeffs.median_5       float64\n",
      " 3557  lowlevel.spectral_contrast_coeffs.min_0          float64\n",
      " 3558  lowlevel.spectral_contrast_coeffs.min_1          float64\n",
      " 3559  lowlevel.spectral_contrast_coeffs.min_2          float64\n",
      " 3560  lowlevel.spectral_contrast_coeffs.min_3          float64\n",
      " 3561  lowlevel.spectral_contrast_coeffs.min_4          float64\n",
      " 3562  lowlevel.spectral_contrast_coeffs.min_5          float64\n",
      " 3563  lowlevel.spectral_contrast_coeffs.stdev_0        float64\n",
      " 3564  lowlevel.spectral_contrast_coeffs.stdev_1        float64\n",
      " 3565  lowlevel.spectral_contrast_coeffs.stdev_2        float64\n",
      " 3566  lowlevel.spectral_contrast_coeffs.stdev_3        float64\n",
      " 3567  lowlevel.spectral_contrast_coeffs.stdev_4        float64\n",
      " 3568  lowlevel.spectral_contrast_coeffs.stdev_5        float64\n",
      " 3569  lowlevel.spectral_contrast_coeffs.var_0          float64\n",
      " 3570  lowlevel.spectral_contrast_coeffs.var_1          float64\n",
      " 3571  lowlevel.spectral_contrast_coeffs.var_2          float64\n",
      " 3572  lowlevel.spectral_contrast_coeffs.var_3          float64\n",
      " 3573  lowlevel.spectral_contrast_coeffs.var_4          float64\n",
      " 3574  lowlevel.spectral_contrast_coeffs.var_5          float64\n",
      " 3575  lowlevel.spectral_contrast_valleys.dmean_0       float64\n",
      " 3576  lowlevel.spectral_contrast_valleys.dmean_1       float64\n",
      " 3577  lowlevel.spectral_contrast_valleys.dmean_2       float64\n",
      " 3578  lowlevel.spectral_contrast_valleys.dmean_3       float64\n",
      " 3579  lowlevel.spectral_contrast_valleys.dmean_4       float64\n",
      " 3580  lowlevel.spectral_contrast_valleys.dmean_5       float64\n",
      " 3581  lowlevel.spectral_contrast_valleys.dmean2_0      float64\n",
      " 3582  lowlevel.spectral_contrast_valleys.dmean2_1      float64\n",
      " 3583  lowlevel.spectral_contrast_valleys.dmean2_2      float64\n",
      " 3584  lowlevel.spectral_contrast_valleys.dmean2_3      float64\n",
      " 3585  lowlevel.spectral_contrast_valleys.dmean2_4      float64\n",
      " 3586  lowlevel.spectral_contrast_valleys.dmean2_5      float64\n",
      " 3587  lowlevel.spectral_contrast_valleys.dvar_0        float64\n",
      " 3588  lowlevel.spectral_contrast_valleys.dvar_1        float64\n",
      " 3589  lowlevel.spectral_contrast_valleys.dvar_2        float64\n",
      " 3590  lowlevel.spectral_contrast_valleys.dvar_3        float64\n",
      " 3591  lowlevel.spectral_contrast_valleys.dvar_4        float64\n",
      " 3592  lowlevel.spectral_contrast_valleys.dvar_5        float64\n",
      " 3593  lowlevel.spectral_contrast_valleys.dvar2_0       float64\n",
      " 3594  lowlevel.spectral_contrast_valleys.dvar2_1       float64\n",
      " 3595  lowlevel.spectral_contrast_valleys.dvar2_2       float64\n",
      " 3596  lowlevel.spectral_contrast_valleys.dvar2_3       float64\n",
      " 3597  lowlevel.spectral_contrast_valleys.dvar2_4       float64\n",
      " 3598  lowlevel.spectral_contrast_valleys.dvar2_5       float64\n",
      " 3599  lowlevel.spectral_contrast_valleys.max_0         float64\n",
      " 3600  lowlevel.spectral_contrast_valleys.max_1         float64\n",
      " 3601  lowlevel.spectral_contrast_valleys.max_2         float64\n",
      " 3602  lowlevel.spectral_contrast_valleys.max_3         float64\n",
      " 3603  lowlevel.spectral_contrast_valleys.max_4         float64\n",
      " 3604  lowlevel.spectral_contrast_valleys.max_5         float64\n",
      " 3605  lowlevel.spectral_contrast_valleys.mean_0        float64\n",
      " 3606  lowlevel.spectral_contrast_valleys.mean_1        float64\n",
      " 3607  lowlevel.spectral_contrast_valleys.mean_2        float64\n",
      " 3608  lowlevel.spectral_contrast_valleys.mean_3        float64\n",
      " 3609  lowlevel.spectral_contrast_valleys.mean_4        float64\n",
      " 3610  lowlevel.spectral_contrast_valleys.mean_5        float64\n",
      " 3611  lowlevel.spectral_contrast_valleys.median_0      float64\n",
      " 3612  lowlevel.spectral_contrast_valleys.median_1      float64\n",
      " 3613  lowlevel.spectral_contrast_valleys.median_2      float64\n",
      " 3614  lowlevel.spectral_contrast_valleys.median_3      float64\n",
      " 3615  lowlevel.spectral_contrast_valleys.median_4      float64\n",
      " 3616  lowlevel.spectral_contrast_valleys.median_5      float64\n",
      " 3617  lowlevel.spectral_contrast_valleys.min_0         float64\n",
      " 3618  lowlevel.spectral_contrast_valleys.min_1         float64\n",
      " 3619  lowlevel.spectral_contrast_valleys.min_2         float64\n",
      " 3620  lowlevel.spectral_contrast_valleys.min_3         float64\n",
      " 3621  lowlevel.spectral_contrast_valleys.min_4         float64\n",
      " 3622  lowlevel.spectral_contrast_valleys.min_5         float64\n",
      " 3623  lowlevel.spectral_contrast_valleys.stdev_0       float64\n",
      " 3624  lowlevel.spectral_contrast_valleys.stdev_1       float64\n",
      " 3625  lowlevel.spectral_contrast_valleys.stdev_2       float64\n",
      " 3626  lowlevel.spectral_contrast_valleys.stdev_3       float64\n",
      " 3627  lowlevel.spectral_contrast_valleys.stdev_4       float64\n",
      " 3628  lowlevel.spectral_contrast_valleys.stdev_5       float64\n",
      " 3629  lowlevel.spectral_contrast_valleys.var_0         float64\n",
      " 3630  lowlevel.spectral_contrast_valleys.var_1         float64\n",
      " 3631  lowlevel.spectral_contrast_valleys.var_2         float64\n",
      " 3632  lowlevel.spectral_contrast_valleys.var_3         float64\n",
      " 3633  lowlevel.spectral_contrast_valleys.var_4         float64\n",
      " 3634  lowlevel.spectral_contrast_valleys.var_5         float64\n",
      " 3635  rhythm.beats_loudness_band_ratio.dmean_0         float64\n",
      " 3636  rhythm.beats_loudness_band_ratio.dmean_1         float64\n",
      " 3637  rhythm.beats_loudness_band_ratio.dmean_2         float64\n",
      " 3638  rhythm.beats_loudness_band_ratio.dmean_3         float64\n",
      " 3639  rhythm.beats_loudness_band_ratio.dmean_4         float64\n",
      " 3640  rhythm.beats_loudness_band_ratio.dmean_5         float64\n",
      " 3641  rhythm.beats_loudness_band_ratio.dmean2_0        float64\n",
      " 3642  rhythm.beats_loudness_band_ratio.dmean2_1        float64\n",
      " 3643  rhythm.beats_loudness_band_ratio.dmean2_2        float64\n",
      " 3644  rhythm.beats_loudness_band_ratio.dmean2_3        float64\n",
      " 3645  rhythm.beats_loudness_band_ratio.dmean2_4        float64\n",
      " 3646  rhythm.beats_loudness_band_ratio.dmean2_5        float64\n",
      " 3647  rhythm.beats_loudness_band_ratio.dvar_0          float64\n",
      " 3648  rhythm.beats_loudness_band_ratio.dvar_1          float64\n",
      " 3649  rhythm.beats_loudness_band_ratio.dvar_2          float64\n",
      " 3650  rhythm.beats_loudness_band_ratio.dvar_3          float64\n",
      " 3651  rhythm.beats_loudness_band_ratio.dvar_4          float64\n",
      " 3652  rhythm.beats_loudness_band_ratio.dvar_5          float64\n",
      " 3653  rhythm.beats_loudness_band_ratio.dvar2_0         float64\n",
      " 3654  rhythm.beats_loudness_band_ratio.dvar2_1         float64\n",
      " 3655  rhythm.beats_loudness_band_ratio.dvar2_2         float64\n",
      " 3656  rhythm.beats_loudness_band_ratio.dvar2_3         float64\n",
      " 3657  rhythm.beats_loudness_band_ratio.dvar2_4         float64\n",
      " 3658  rhythm.beats_loudness_band_ratio.dvar2_5         float64\n",
      " 3659  rhythm.beats_loudness_band_ratio.max_0           float64\n",
      " 3660  rhythm.beats_loudness_band_ratio.max_1           float64\n",
      " 3661  rhythm.beats_loudness_band_ratio.max_2           float64\n",
      " 3662  rhythm.beats_loudness_band_ratio.max_3           float64\n",
      " 3663  rhythm.beats_loudness_band_ratio.max_4           float64\n",
      " 3664  rhythm.beats_loudness_band_ratio.max_5           float64\n",
      " 3665  rhythm.beats_loudness_band_ratio.mean_0          float64\n",
      " 3666  rhythm.beats_loudness_band_ratio.mean_1          float64\n",
      " 3667  rhythm.beats_loudness_band_ratio.mean_2          float64\n",
      " 3668  rhythm.beats_loudness_band_ratio.mean_3          float64\n",
      " 3669  rhythm.beats_loudness_band_ratio.mean_4          float64\n",
      " 3670  rhythm.beats_loudness_band_ratio.mean_5          float64\n",
      " 3671  rhythm.beats_loudness_band_ratio.median_0        float64\n",
      " 3672  rhythm.beats_loudness_band_ratio.median_1        float64\n",
      " 3673  rhythm.beats_loudness_band_ratio.median_2        float64\n",
      " 3674  rhythm.beats_loudness_band_ratio.median_3        float64\n",
      " 3675  rhythm.beats_loudness_band_ratio.median_4        float64\n",
      " 3676  rhythm.beats_loudness_band_ratio.median_5        float64\n",
      " 3677  rhythm.beats_loudness_band_ratio.min_0           float64\n",
      " 3678  rhythm.beats_loudness_band_ratio.min_1           float64\n",
      " 3679  rhythm.beats_loudness_band_ratio.min_2           float64\n",
      " 3680  rhythm.beats_loudness_band_ratio.min_3           float64\n",
      " 3681  rhythm.beats_loudness_band_ratio.min_4           float64\n",
      " 3682  rhythm.beats_loudness_band_ratio.min_5           float64\n",
      " 3683  rhythm.beats_loudness_band_ratio.stdev_0         float64\n",
      " 3684  rhythm.beats_loudness_band_ratio.stdev_1         float64\n",
      " 3685  rhythm.beats_loudness_band_ratio.stdev_2         float64\n",
      " 3686  rhythm.beats_loudness_band_ratio.stdev_3         float64\n",
      " 3687  rhythm.beats_loudness_band_ratio.stdev_4         float64\n",
      " 3688  rhythm.beats_loudness_band_ratio.stdev_5         float64\n",
      " 3689  rhythm.beats_loudness_band_ratio.var_0           float64\n",
      " 3690  rhythm.beats_loudness_band_ratio.var_1           float64\n",
      " 3691  rhythm.beats_loudness_band_ratio.var_2           float64\n",
      " 3692  rhythm.beats_loudness_band_ratio.var_3           float64\n",
      " 3693  rhythm.beats_loudness_band_ratio.var_4           float64\n",
      " 3694  rhythm.beats_loudness_band_ratio.var_5           float64\n",
      " 3695  rhythm.beats_position_0                          float64\n",
      " 3696  rhythm.beats_position_1                          float64\n",
      " 3697  rhythm.beats_position_2                          float64\n",
      " 3698  rhythm.beats_position_3                          float64\n",
      " 3699  rhythm.beats_position_4                          float64\n",
      " 3700  rhythm.beats_position_5                          float64\n",
      " 3701  rhythm.beats_position_6                          float64\n",
      " 3702  rhythm.beats_position_7                          float64\n",
      " 3703  rhythm.beats_position_8                          float64\n",
      " 3704  rhythm.beats_position_9                          float64\n",
      " 3705  rhythm.beats_position_10                         float64\n",
      " 3706  rhythm.beats_position_11                         float64\n",
      " 3707  rhythm.beats_position_12                         float64\n",
      " 3708  rhythm.beats_position_13                         float64\n",
      " 3709  rhythm.beats_position_14                         float64\n",
      " 3710  rhythm.beats_position_15                         float64\n",
      " 3711  rhythm.beats_position_16                         float64\n",
      " 3712  rhythm.beats_position_17                         float64\n",
      " 3713  rhythm.beats_position_18                         float64\n",
      " 3714  rhythm.beats_position_19                         float64\n",
      " 3715  rhythm.beats_position_20                         float64\n",
      " 3716  rhythm.beats_position_21                         float64\n",
      " 3717  rhythm.beats_position_22                         float64\n",
      " 3718  rhythm.beats_position_23                         float64\n",
      " 3719  rhythm.beats_position_24                         float64\n",
      " 3720  rhythm.beats_position_25                         float64\n",
      " 3721  rhythm.beats_position_26                         float64\n",
      " 3722  rhythm.beats_position_27                         float64\n",
      " 3723  rhythm.beats_position_28                         float64\n",
      " 3724  rhythm.beats_position_29                         float64\n",
      " 3725  rhythm.beats_position_30                         float64\n",
      " 3726  rhythm.beats_position_31                         float64\n",
      " 3727  rhythm.beats_position_32                         float64\n",
      " 3728  rhythm.beats_position_33                         float64\n",
      " 3729  rhythm.beats_position_34                         float64\n",
      " 3730  rhythm.beats_position_35                         float64\n",
      " 3731  rhythm.beats_position_36                         float64\n",
      " 3732  rhythm.beats_position_37                         float64\n",
      " 3733  rhythm.beats_position_38                         float64\n",
      " 3734  rhythm.beats_position_39                         float64\n",
      " 3735  rhythm.beats_position_40                         float64\n",
      " 3736  rhythm.beats_position_41                         float64\n",
      " 3737  rhythm.beats_position_42                         float64\n",
      " 3738  rhythm.beats_position_43                         float64\n",
      " 3739  rhythm.beats_position_44                         float64\n",
      " 3740  rhythm.beats_position_45                         float64\n",
      " 3741  rhythm.beats_position_46                         float64\n",
      " 3742  rhythm.beats_position_47                         float64\n",
      " 3743  rhythm.beats_position_48                         float64\n",
      " 3744  rhythm.beats_position_49                         float64\n",
      " 3745  rhythm.beats_position_50                         float64\n",
      " 3746  rhythm.beats_position_51                         float64\n",
      " 3747  rhythm.beats_position_52                         float64\n",
      " 3748  rhythm.beats_position_53                         float64\n",
      " 3749  rhythm.beats_position_54                         float64\n",
      " 3750  rhythm.beats_position_55                         float64\n",
      " 3751  rhythm.beats_position_56                         float64\n",
      " 3752  rhythm.beats_position_57                         float64\n",
      " 3753  rhythm.beats_position_58                         float64\n",
      " 3754  rhythm.beats_position_59                         float64\n",
      " 3755  rhythm.beats_position_60                         float64\n",
      " 3756  rhythm.beats_position_61                         float64\n",
      " 3757  rhythm.beats_position_62                         float64\n",
      " 3758  rhythm.beats_position_63                         float64\n",
      " 3759  rhythm.beats_position_64                         float64\n",
      " 3760  rhythm.beats_position_65                         float64\n",
      " 3761  rhythm.beats_position_66                         float64\n",
      " 3762  rhythm.beats_position_67                         float64\n",
      " 3763  rhythm.beats_position_68                         float64\n",
      " 3764  rhythm.beats_position_69                         float64\n",
      " 3765  rhythm.beats_position_70                         float64\n",
      " 3766  rhythm.beats_position_71                         float64\n",
      " 3767  rhythm.beats_position_72                         float64\n",
      " 3768  rhythm.beats_position_73                         float64\n",
      " 3769  rhythm.beats_position_74                         float64\n",
      " 3770  rhythm.beats_position_75                         float64\n",
      " 3771  rhythm.beats_position_76                         float64\n",
      " 3772  rhythm.beats_position_77                         float64\n",
      " 3773  rhythm.beats_position_78                         float64\n",
      " 3774  rhythm.beats_position_79                         float64\n",
      " 3775  rhythm.beats_position_80                         float64\n",
      " 3776  rhythm.beats_position_81                         float64\n",
      " 3777  rhythm.beats_position_82                         float64\n",
      " 3778  rhythm.beats_position_83                         float64\n",
      " 3779  rhythm.beats_position_84                         float64\n",
      " 3780  rhythm.beats_position_85                         float64\n",
      " 3781  rhythm.beats_position_86                         float64\n",
      " 3782  rhythm.beats_position_87                         float64\n",
      " 3783  rhythm.beats_position_88                         float64\n",
      " 3784  rhythm.beats_position_89                         float64\n",
      " 3785  rhythm.beats_position_90                         float64\n",
      " 3786  rhythm.beats_position_91                         float64\n",
      " 3787  rhythm.beats_position_92                         float64\n",
      " 3788  rhythm.beats_position_93                         float64\n",
      " 3789  rhythm.beats_position_94                         float64\n",
      " 3790  rhythm.beats_position_95                         float64\n",
      " 3791  rhythm.beats_position_96                         float64\n",
      " 3792  rhythm.beats_position_97                         float64\n",
      " 3793  rhythm.beats_position_98                         float64\n",
      " 3794  rhythm.beats_position_99                         float64\n",
      " 3795  rhythm.beats_position_100                        float64\n",
      " 3796  rhythm.beats_position_101                        float64\n",
      " 3797  rhythm.beats_position_102                        float64\n",
      " 3798  rhythm.beats_position_103                        float64\n",
      " 3799  rhythm.beats_position_104                        float64\n",
      " 3800  rhythm.beats_position_105                        float64\n",
      " 3801  rhythm.beats_position_106                        float64\n",
      " 3802  rhythm.beats_position_107                        float64\n",
      " 3803  rhythm.beats_position_108                        float64\n",
      " 3804  rhythm.beats_position_109                        float64\n",
      " 3805  rhythm.beats_position_110                        float64\n",
      " 3806  rhythm.beats_position_111                        float64\n",
      " 3807  rhythm.beats_position_112                        float64\n",
      " 3808  rhythm.beats_position_113                        float64\n",
      " 3809  rhythm.beats_position_114                        float64\n",
      " 3810  rhythm.beats_position_115                        float64\n",
      " 3811  rhythm.beats_position_116                        float64\n",
      " 3812  rhythm.beats_position_117                        float64\n",
      " 3813  rhythm.beats_position_118                        float64\n",
      " 3814  rhythm.beats_position_119                        float64\n",
      " 3815  rhythm.beats_position_120                        float64\n",
      " 3816  rhythm.beats_position_121                        float64\n",
      " 3817  rhythm.beats_position_122                        float64\n",
      " 3818  rhythm.beats_position_123                        float64\n",
      " 3819  rhythm.beats_position_124                        float64\n",
      " 3820  rhythm.beats_position_125                        float64\n",
      " 3821  rhythm.beats_position_126                        float64\n",
      " 3822  rhythm.beats_position_127                        float64\n",
      " 3823  rhythm.beats_position_128                        float64\n",
      " 3824  rhythm.beats_position_129                        float64\n",
      " 3825  rhythm.beats_position_130                        float64\n",
      " 3826  rhythm.beats_position_131                        float64\n",
      " 3827  rhythm.beats_position_132                        float64\n",
      " 3828  rhythm.beats_position_133                        float64\n",
      " 3829  rhythm.beats_position_134                        float64\n",
      " 3830  rhythm.beats_position_135                        float64\n",
      " 3831  rhythm.beats_position_136                        float64\n",
      " 3832  rhythm.beats_position_137                        float64\n",
      " 3833  rhythm.beats_position_138                        float64\n",
      " 3834  rhythm.beats_position_139                        float64\n",
      " 3835  rhythm.beats_position_140                        float64\n",
      " 3836  rhythm.bpm_histogram_0                           float64\n",
      " 3837  rhythm.bpm_histogram_1                           float64\n",
      " 3838  rhythm.bpm_histogram_2                           float64\n",
      " 3839  rhythm.bpm_histogram_3                           float64\n",
      " 3840  rhythm.bpm_histogram_4                           float64\n",
      " 3841  rhythm.bpm_histogram_5                           float64\n",
      " 3842  rhythm.bpm_histogram_6                           float64\n",
      " 3843  rhythm.bpm_histogram_7                           float64\n",
      " 3844  rhythm.bpm_histogram_8                           float64\n",
      " 3845  rhythm.bpm_histogram_9                           float64\n",
      " 3846  rhythm.bpm_histogram_10                          float64\n",
      " 3847  rhythm.bpm_histogram_11                          float64\n",
      " 3848  rhythm.bpm_histogram_12                          float64\n",
      " 3849  rhythm.bpm_histogram_13                          float64\n",
      " 3850  rhythm.bpm_histogram_14                          float64\n",
      " 3851  rhythm.bpm_histogram_15                          float64\n",
      " 3852  rhythm.bpm_histogram_16                          float64\n",
      " 3853  rhythm.bpm_histogram_17                          float64\n",
      " 3854  rhythm.bpm_histogram_18                          float64\n",
      " 3855  rhythm.bpm_histogram_19                          float64\n",
      " 3856  rhythm.bpm_histogram_20                          float64\n",
      " 3857  rhythm.bpm_histogram_21                          float64\n",
      " 3858  rhythm.bpm_histogram_22                          float64\n",
      " 3859  rhythm.bpm_histogram_23                          float64\n",
      " 3860  rhythm.bpm_histogram_24                          float64\n",
      " 3861  rhythm.bpm_histogram_25                          float64\n",
      " 3862  rhythm.bpm_histogram_26                          float64\n",
      " 3863  rhythm.bpm_histogram_27                          float64\n",
      " 3864  rhythm.bpm_histogram_28                          float64\n",
      " 3865  rhythm.bpm_histogram_29                          float64\n",
      " 3866  rhythm.bpm_histogram_30                          float64\n",
      " 3867  rhythm.bpm_histogram_31                          float64\n",
      " 3868  rhythm.bpm_histogram_32                          float64\n",
      " 3869  rhythm.bpm_histogram_33                          float64\n",
      " 3870  rhythm.bpm_histogram_34                          float64\n",
      " 3871  rhythm.bpm_histogram_35                          float64\n",
      " 3872  rhythm.bpm_histogram_36                          float64\n",
      " 3873  rhythm.bpm_histogram_37                          float64\n",
      " 3874  rhythm.bpm_histogram_38                          float64\n",
      " 3875  rhythm.bpm_histogram_39                          float64\n",
      " 3876  rhythm.bpm_histogram_40                          float64\n",
      " 3877  rhythm.bpm_histogram_41                          float64\n",
      " 3878  rhythm.bpm_histogram_42                          float64\n",
      " 3879  rhythm.bpm_histogram_43                          float64\n",
      " 3880  rhythm.bpm_histogram_44                          float64\n",
      " 3881  rhythm.bpm_histogram_45                          float64\n",
      " 3882  rhythm.bpm_histogram_46                          float64\n",
      " 3883  rhythm.bpm_histogram_47                          float64\n",
      " 3884  rhythm.bpm_histogram_48                          float64\n",
      " 3885  rhythm.bpm_histogram_49                          float64\n",
      " 3886  rhythm.bpm_histogram_50                          float64\n",
      " 3887  rhythm.bpm_histogram_51                          float64\n",
      " 3888  rhythm.bpm_histogram_52                          float64\n",
      " 3889  rhythm.bpm_histogram_53                          float64\n",
      " 3890  rhythm.bpm_histogram_54                          float64\n",
      " 3891  rhythm.bpm_histogram_55                          float64\n",
      " 3892  rhythm.bpm_histogram_56                          float64\n",
      " 3893  rhythm.bpm_histogram_57                          float64\n",
      " 3894  rhythm.bpm_histogram_58                          float64\n",
      " 3895  rhythm.bpm_histogram_59                          float64\n",
      " 3896  rhythm.bpm_histogram_60                          float64\n",
      " 3897  rhythm.bpm_histogram_61                          float64\n",
      " 3898  rhythm.bpm_histogram_62                          float64\n",
      " 3899  rhythm.bpm_histogram_63                          float64\n",
      " 3900  rhythm.bpm_histogram_64                          float64\n",
      " 3901  rhythm.bpm_histogram_65                          float64\n",
      " 3902  rhythm.bpm_histogram_66                          float64\n",
      " 3903  rhythm.bpm_histogram_67                          float64\n",
      " 3904  rhythm.bpm_histogram_68                          float64\n",
      " 3905  rhythm.bpm_histogram_69                          float64\n",
      " 3906  rhythm.bpm_histogram_70                          float64\n",
      " 3907  rhythm.bpm_histogram_71                          float64\n",
      " 3908  rhythm.bpm_histogram_72                          float64\n",
      " 3909  rhythm.bpm_histogram_73                          float64\n",
      " 3910  rhythm.bpm_histogram_74                          float64\n",
      " 3911  rhythm.bpm_histogram_75                          float64\n",
      " 3912  rhythm.bpm_histogram_76                          float64\n",
      " 3913  rhythm.bpm_histogram_77                          float64\n",
      " 3914  rhythm.bpm_histogram_78                          float64\n",
      " 3915  rhythm.bpm_histogram_79                          float64\n",
      " 3916  rhythm.bpm_histogram_80                          float64\n",
      " 3917  rhythm.bpm_histogram_81                          float64\n",
      " 3918  rhythm.bpm_histogram_82                          float64\n",
      " 3919  rhythm.bpm_histogram_83                          float64\n",
      " 3920  rhythm.bpm_histogram_84                          float64\n",
      " 3921  rhythm.bpm_histogram_85                          float64\n",
      " 3922  rhythm.bpm_histogram_86                          float64\n",
      " 3923  rhythm.bpm_histogram_87                          float64\n",
      " 3924  rhythm.bpm_histogram_88                          float64\n",
      " 3925  rhythm.bpm_histogram_89                          float64\n",
      " 3926  rhythm.bpm_histogram_90                          float64\n",
      " 3927  rhythm.bpm_histogram_91                          float64\n",
      " 3928  rhythm.bpm_histogram_92                          float64\n",
      " 3929  rhythm.bpm_histogram_93                          float64\n",
      " 3930  rhythm.bpm_histogram_94                          float64\n",
      " 3931  rhythm.bpm_histogram_95                          float64\n",
      " 3932  rhythm.bpm_histogram_96                          float64\n",
      " 3933  rhythm.bpm_histogram_97                          float64\n",
      " 3934  rhythm.bpm_histogram_98                          float64\n",
      " 3935  rhythm.bpm_histogram_99                          float64\n",
      " 3936  rhythm.bpm_histogram_100                         float64\n",
      " 3937  rhythm.bpm_histogram_101                         float64\n",
      " 3938  rhythm.bpm_histogram_102                         float64\n",
      " 3939  rhythm.bpm_histogram_103                         float64\n",
      " 3940  rhythm.bpm_histogram_104                         float64\n",
      " 3941  rhythm.bpm_histogram_105                         float64\n",
      " 3942  rhythm.bpm_histogram_106                         float64\n",
      " 3943  rhythm.bpm_histogram_107                         float64\n",
      " 3944  rhythm.bpm_histogram_108                         float64\n",
      " 3945  rhythm.bpm_histogram_109                         float64\n",
      " 3946  rhythm.bpm_histogram_110                         float64\n",
      " 3947  rhythm.bpm_histogram_111                         float64\n",
      " 3948  rhythm.bpm_histogram_112                         float64\n",
      " 3949  rhythm.bpm_histogram_113                         float64\n",
      " 3950  rhythm.bpm_histogram_114                         float64\n",
      " 3951  rhythm.bpm_histogram_115                         float64\n",
      " 3952  rhythm.bpm_histogram_116                         float64\n",
      " 3953  rhythm.bpm_histogram_117                         float64\n",
      " 3954  rhythm.bpm_histogram_118                         float64\n",
      " 3955  rhythm.bpm_histogram_119                         float64\n",
      " 3956  rhythm.bpm_histogram_120                         float64\n",
      " 3957  rhythm.bpm_histogram_121                         float64\n",
      " 3958  rhythm.bpm_histogram_122                         float64\n",
      " 3959  rhythm.bpm_histogram_123                         float64\n",
      " 3960  rhythm.bpm_histogram_124                         float64\n",
      " 3961  rhythm.bpm_histogram_125                         float64\n",
      " 3962  rhythm.bpm_histogram_126                         float64\n",
      " 3963  rhythm.bpm_histogram_127                         float64\n",
      " 3964  rhythm.bpm_histogram_128                         float64\n",
      " 3965  rhythm.bpm_histogram_129                         float64\n",
      " 3966  rhythm.bpm_histogram_130                         float64\n",
      " 3967  rhythm.bpm_histogram_131                         float64\n",
      " 3968  rhythm.bpm_histogram_132                         float64\n",
      " 3969  rhythm.bpm_histogram_133                         float64\n",
      " 3970  rhythm.bpm_histogram_134                         float64\n",
      " 3971  rhythm.bpm_histogram_135                         float64\n",
      " 3972  rhythm.bpm_histogram_136                         float64\n",
      " 3973  rhythm.bpm_histogram_137                         float64\n",
      " 3974  rhythm.bpm_histogram_138                         float64\n",
      " 3975  rhythm.bpm_histogram_139                         float64\n",
      " 3976  rhythm.bpm_histogram_140                         float64\n",
      " 3977  rhythm.bpm_histogram_141                         float64\n",
      " 3978  rhythm.bpm_histogram_142                         float64\n",
      " 3979  rhythm.bpm_histogram_143                         float64\n",
      " 3980  rhythm.bpm_histogram_144                         float64\n",
      " 3981  rhythm.bpm_histogram_145                         float64\n",
      " 3982  rhythm.bpm_histogram_146                         float64\n",
      " 3983  rhythm.bpm_histogram_147                         float64\n",
      " 3984  rhythm.bpm_histogram_148                         float64\n",
      " 3985  rhythm.bpm_histogram_149                         float64\n",
      " 3986  rhythm.bpm_histogram_150                         float64\n",
      " 3987  rhythm.bpm_histogram_151                         float64\n",
      " 3988  rhythm.bpm_histogram_152                         float64\n",
      " 3989  rhythm.bpm_histogram_153                         float64\n",
      " 3990  rhythm.bpm_histogram_154                         float64\n",
      " 3991  rhythm.bpm_histogram_155                         float64\n",
      " 3992  rhythm.bpm_histogram_156                         float64\n",
      " 3993  rhythm.bpm_histogram_157                         float64\n",
      " 3994  rhythm.bpm_histogram_158                         float64\n",
      " 3995  rhythm.bpm_histogram_159                         float64\n",
      " 3996  rhythm.bpm_histogram_160                         float64\n",
      " 3997  rhythm.bpm_histogram_161                         float64\n",
      " 3998  rhythm.bpm_histogram_162                         float64\n",
      " 3999  rhythm.bpm_histogram_163                         float64\n",
      " 4000  rhythm.bpm_histogram_164                         float64\n",
      " 4001  rhythm.bpm_histogram_165                         float64\n",
      " 4002  rhythm.bpm_histogram_166                         float64\n",
      " 4003  rhythm.bpm_histogram_167                         float64\n",
      " 4004  rhythm.bpm_histogram_168                         float64\n",
      " 4005  rhythm.bpm_histogram_169                         float64\n",
      " 4006  rhythm.bpm_histogram_170                         float64\n",
      " 4007  rhythm.bpm_histogram_171                         float64\n",
      " 4008  rhythm.bpm_histogram_172                         float64\n",
      " 4009  rhythm.bpm_histogram_173                         float64\n",
      " 4010  rhythm.bpm_histogram_174                         float64\n",
      " 4011  rhythm.bpm_histogram_175                         float64\n",
      " 4012  rhythm.bpm_histogram_176                         float64\n",
      " 4013  rhythm.bpm_histogram_177                         float64\n",
      " 4014  rhythm.bpm_histogram_178                         float64\n",
      " 4015  rhythm.bpm_histogram_179                         float64\n",
      " 4016  rhythm.bpm_histogram_180                         float64\n",
      " 4017  rhythm.bpm_histogram_181                         float64\n",
      " 4018  rhythm.bpm_histogram_182                         float64\n",
      " 4019  rhythm.bpm_histogram_183                         float64\n",
      " 4020  rhythm.bpm_histogram_184                         float64\n",
      " 4021  rhythm.bpm_histogram_185                         float64\n",
      " 4022  rhythm.bpm_histogram_186                         float64\n",
      " 4023  rhythm.bpm_histogram_187                         float64\n",
      " 4024  rhythm.bpm_histogram_188                         float64\n",
      " 4025  rhythm.bpm_histogram_189                         float64\n",
      " 4026  rhythm.bpm_histogram_190                         float64\n",
      " 4027  rhythm.bpm_histogram_191                         float64\n",
      " 4028  rhythm.bpm_histogram_192                         float64\n",
      " 4029  rhythm.bpm_histogram_193                         float64\n",
      " 4030  rhythm.bpm_histogram_194                         float64\n",
      " 4031  rhythm.bpm_histogram_195                         float64\n",
      " 4032  rhythm.bpm_histogram_196                         float64\n",
      " 4033  rhythm.bpm_histogram_197                         float64\n",
      " 4034  rhythm.bpm_histogram_198                         float64\n",
      " 4035  rhythm.bpm_histogram_199                         float64\n",
      " 4036  rhythm.bpm_histogram_200                         float64\n",
      " 4037  rhythm.bpm_histogram_201                         float64\n",
      " 4038  rhythm.bpm_histogram_202                         float64\n",
      " 4039  rhythm.bpm_histogram_203                         float64\n",
      " 4040  rhythm.bpm_histogram_204                         float64\n",
      " 4041  rhythm.bpm_histogram_205                         float64\n",
      " 4042  rhythm.bpm_histogram_206                         float64\n",
      " 4043  rhythm.bpm_histogram_207                         float64\n",
      " 4044  rhythm.bpm_histogram_208                         float64\n",
      " 4045  rhythm.bpm_histogram_209                         float64\n",
      " 4046  rhythm.bpm_histogram_210                         float64\n",
      " 4047  rhythm.bpm_histogram_211                         float64\n",
      " 4048  rhythm.bpm_histogram_212                         float64\n",
      " 4049  rhythm.bpm_histogram_213                         float64\n",
      " 4050  rhythm.bpm_histogram_214                         float64\n",
      " 4051  rhythm.bpm_histogram_215                         float64\n",
      " 4052  rhythm.bpm_histogram_216                         float64\n",
      " 4053  rhythm.bpm_histogram_217                         float64\n",
      " 4054  rhythm.bpm_histogram_218                         float64\n",
      " 4055  rhythm.bpm_histogram_219                         float64\n",
      " 4056  rhythm.bpm_histogram_220                         float64\n",
      " 4057  rhythm.bpm_histogram_221                         float64\n",
      " 4058  rhythm.bpm_histogram_222                         float64\n",
      " 4059  rhythm.bpm_histogram_223                         float64\n",
      " 4060  rhythm.bpm_histogram_224                         float64\n",
      " 4061  rhythm.bpm_histogram_225                         float64\n",
      " 4062  rhythm.bpm_histogram_226                         float64\n",
      " 4063  rhythm.bpm_histogram_227                         float64\n",
      " 4064  rhythm.bpm_histogram_228                         float64\n",
      " 4065  rhythm.bpm_histogram_229                         float64\n",
      " 4066  rhythm.bpm_histogram_230                         float64\n",
      " 4067  rhythm.bpm_histogram_231                         float64\n",
      " 4068  rhythm.bpm_histogram_232                         float64\n",
      " 4069  rhythm.bpm_histogram_233                         float64\n",
      " 4070  rhythm.bpm_histogram_234                         float64\n",
      " 4071  rhythm.bpm_histogram_235                         float64\n",
      " 4072  rhythm.bpm_histogram_236                         float64\n",
      " 4073  rhythm.bpm_histogram_237                         float64\n",
      " 4074  rhythm.bpm_histogram_238                         float64\n",
      " 4075  rhythm.bpm_histogram_239                         float64\n",
      " 4076  rhythm.bpm_histogram_240                         float64\n",
      " 4077  rhythm.bpm_histogram_241                         float64\n",
      " 4078  rhythm.bpm_histogram_242                         float64\n",
      " 4079  rhythm.bpm_histogram_243                         float64\n",
      " 4080  rhythm.bpm_histogram_244                         float64\n",
      " 4081  rhythm.bpm_histogram_245                         float64\n",
      " 4082  rhythm.bpm_histogram_246                         float64\n",
      " 4083  rhythm.bpm_histogram_247                         float64\n",
      " 4084  rhythm.bpm_histogram_248                         float64\n",
      " 4085  rhythm.bpm_histogram_249                         float64\n",
      " 4086  tonal.chords_histogram_0                         float64\n",
      " 4087  tonal.chords_histogram_1                         float64\n",
      " 4088  tonal.chords_histogram_2                         float64\n",
      " 4089  tonal.chords_histogram_3                         float64\n",
      " 4090  tonal.chords_histogram_4                         float64\n",
      " 4091  tonal.chords_histogram_5                         float64\n",
      " 4092  tonal.chords_histogram_6                         float64\n",
      " 4093  tonal.chords_histogram_7                         float64\n",
      " 4094  tonal.chords_histogram_8                         float64\n",
      " 4095  tonal.chords_histogram_9                         float64\n",
      " 4096  tonal.chords_histogram_10                        float64\n",
      " 4097  tonal.chords_histogram_11                        float64\n",
      " 4098  tonal.chords_histogram_12                        float64\n",
      " 4099  tonal.chords_histogram_13                        float64\n",
      " 4100  tonal.chords_histogram_14                        float64\n",
      " 4101  tonal.chords_histogram_15                        float64\n",
      " 4102  tonal.chords_histogram_16                        float64\n",
      " 4103  tonal.chords_histogram_17                        float64\n",
      " 4104  tonal.chords_histogram_18                        float64\n",
      " 4105  tonal.chords_histogram_19                        float64\n",
      " 4106  tonal.chords_histogram_20                        float64\n",
      " 4107  tonal.chords_histogram_21                        float64\n",
      " 4108  tonal.chords_histogram_22                        float64\n",
      " 4109  tonal.chords_histogram_23                        float64\n",
      " 4110  tonal.hpcp.dmean_0                               float64\n",
      " 4111  tonal.hpcp.dmean_1                               float64\n",
      " 4112  tonal.hpcp.dmean_2                               float64\n",
      " 4113  tonal.hpcp.dmean_3                               float64\n",
      " 4114  tonal.hpcp.dmean_4                               float64\n",
      " 4115  tonal.hpcp.dmean_5                               float64\n",
      " 4116  tonal.hpcp.dmean_6                               float64\n",
      " 4117  tonal.hpcp.dmean_7                               float64\n",
      " 4118  tonal.hpcp.dmean_8                               float64\n",
      " 4119  tonal.hpcp.dmean_9                               float64\n",
      " 4120  tonal.hpcp.dmean_10                              float64\n",
      " 4121  tonal.hpcp.dmean_11                              float64\n",
      " 4122  tonal.hpcp.dmean_12                              float64\n",
      " 4123  tonal.hpcp.dmean_13                              float64\n",
      " 4124  tonal.hpcp.dmean_14                              float64\n",
      " 4125  tonal.hpcp.dmean_15                              float64\n",
      " 4126  tonal.hpcp.dmean_16                              float64\n",
      " 4127  tonal.hpcp.dmean_17                              float64\n",
      " 4128  tonal.hpcp.dmean_18                              float64\n",
      " 4129  tonal.hpcp.dmean_19                              float64\n",
      " 4130  tonal.hpcp.dmean_20                              float64\n",
      " 4131  tonal.hpcp.dmean_21                              float64\n",
      " 4132  tonal.hpcp.dmean_22                              float64\n",
      " 4133  tonal.hpcp.dmean_23                              float64\n",
      " 4134  tonal.hpcp.dmean_24                              float64\n",
      " 4135  tonal.hpcp.dmean_25                              float64\n",
      " 4136  tonal.hpcp.dmean_26                              float64\n",
      " 4137  tonal.hpcp.dmean_27                              float64\n",
      " 4138  tonal.hpcp.dmean_28                              float64\n",
      " 4139  tonal.hpcp.dmean_29                              float64\n",
      " 4140  tonal.hpcp.dmean_30                              float64\n",
      " 4141  tonal.hpcp.dmean_31                              float64\n",
      " 4142  tonal.hpcp.dmean_32                              float64\n",
      " 4143  tonal.hpcp.dmean_33                              float64\n",
      " 4144  tonal.hpcp.dmean_34                              float64\n",
      " 4145  tonal.hpcp.dmean_35                              float64\n",
      " 4146  tonal.hpcp.dmean2_0                              float64\n",
      " 4147  tonal.hpcp.dmean2_1                              float64\n",
      " 4148  tonal.hpcp.dmean2_2                              float64\n",
      " 4149  tonal.hpcp.dmean2_3                              float64\n",
      " 4150  tonal.hpcp.dmean2_4                              float64\n",
      " 4151  tonal.hpcp.dmean2_5                              float64\n",
      " 4152  tonal.hpcp.dmean2_6                              float64\n",
      " 4153  tonal.hpcp.dmean2_7                              float64\n",
      " 4154  tonal.hpcp.dmean2_8                              float64\n",
      " 4155  tonal.hpcp.dmean2_9                              float64\n",
      " 4156  tonal.hpcp.dmean2_10                             float64\n",
      " 4157  tonal.hpcp.dmean2_11                             float64\n",
      " 4158  tonal.hpcp.dmean2_12                             float64\n",
      " 4159  tonal.hpcp.dmean2_13                             float64\n",
      " 4160  tonal.hpcp.dmean2_14                             float64\n",
      " 4161  tonal.hpcp.dmean2_15                             float64\n",
      " 4162  tonal.hpcp.dmean2_16                             float64\n",
      " 4163  tonal.hpcp.dmean2_17                             float64\n",
      " 4164  tonal.hpcp.dmean2_18                             float64\n",
      " 4165  tonal.hpcp.dmean2_19                             float64\n",
      " 4166  tonal.hpcp.dmean2_20                             float64\n",
      " 4167  tonal.hpcp.dmean2_21                             float64\n",
      " 4168  tonal.hpcp.dmean2_22                             float64\n",
      " 4169  tonal.hpcp.dmean2_23                             float64\n",
      " 4170  tonal.hpcp.dmean2_24                             float64\n",
      " 4171  tonal.hpcp.dmean2_25                             float64\n",
      " 4172  tonal.hpcp.dmean2_26                             float64\n",
      " 4173  tonal.hpcp.dmean2_27                             float64\n",
      " 4174  tonal.hpcp.dmean2_28                             float64\n",
      " 4175  tonal.hpcp.dmean2_29                             float64\n",
      " 4176  tonal.hpcp.dmean2_30                             float64\n",
      " 4177  tonal.hpcp.dmean2_31                             float64\n",
      " 4178  tonal.hpcp.dmean2_32                             float64\n",
      " 4179  tonal.hpcp.dmean2_33                             float64\n",
      " 4180  tonal.hpcp.dmean2_34                             float64\n",
      " 4181  tonal.hpcp.dmean2_35                             float64\n",
      " 4182  tonal.hpcp.dvar_0                                float64\n",
      " 4183  tonal.hpcp.dvar_1                                float64\n",
      " 4184  tonal.hpcp.dvar_2                                float64\n",
      " 4185  tonal.hpcp.dvar_3                                float64\n",
      " 4186  tonal.hpcp.dvar_4                                float64\n",
      " 4187  tonal.hpcp.dvar_5                                float64\n",
      " 4188  tonal.hpcp.dvar_6                                float64\n",
      " 4189  tonal.hpcp.dvar_7                                float64\n",
      " 4190  tonal.hpcp.dvar_8                                float64\n",
      " 4191  tonal.hpcp.dvar_9                                float64\n",
      " 4192  tonal.hpcp.dvar_10                               float64\n",
      " 4193  tonal.hpcp.dvar_11                               float64\n",
      " 4194  tonal.hpcp.dvar_12                               float64\n",
      " 4195  tonal.hpcp.dvar_13                               float64\n",
      " 4196  tonal.hpcp.dvar_14                               float64\n",
      " 4197  tonal.hpcp.dvar_15                               float64\n",
      " 4198  tonal.hpcp.dvar_16                               float64\n",
      " 4199  tonal.hpcp.dvar_17                               float64\n",
      " 4200  tonal.hpcp.dvar_18                               float64\n",
      " 4201  tonal.hpcp.dvar_19                               float64\n",
      " 4202  tonal.hpcp.dvar_20                               float64\n",
      " 4203  tonal.hpcp.dvar_21                               float64\n",
      " 4204  tonal.hpcp.dvar_22                               float64\n",
      " 4205  tonal.hpcp.dvar_23                               float64\n",
      " 4206  tonal.hpcp.dvar_24                               float64\n",
      " 4207  tonal.hpcp.dvar_25                               float64\n",
      " 4208  tonal.hpcp.dvar_26                               float64\n",
      " 4209  tonal.hpcp.dvar_27                               float64\n",
      " 4210  tonal.hpcp.dvar_28                               float64\n",
      " 4211  tonal.hpcp.dvar_29                               float64\n",
      " 4212  tonal.hpcp.dvar_30                               float64\n",
      " 4213  tonal.hpcp.dvar_31                               float64\n",
      " 4214  tonal.hpcp.dvar_32                               float64\n",
      " 4215  tonal.hpcp.dvar_33                               float64\n",
      " 4216  tonal.hpcp.dvar_34                               float64\n",
      " 4217  tonal.hpcp.dvar_35                               float64\n",
      " 4218  tonal.hpcp.dvar2_0                               float64\n",
      " 4219  tonal.hpcp.dvar2_1                               float64\n",
      " 4220  tonal.hpcp.dvar2_2                               float64\n",
      " 4221  tonal.hpcp.dvar2_3                               float64\n",
      " 4222  tonal.hpcp.dvar2_4                               float64\n",
      " 4223  tonal.hpcp.dvar2_5                               float64\n",
      " 4224  tonal.hpcp.dvar2_6                               float64\n",
      " 4225  tonal.hpcp.dvar2_7                               float64\n",
      " 4226  tonal.hpcp.dvar2_8                               float64\n",
      " 4227  tonal.hpcp.dvar2_9                               float64\n",
      " 4228  tonal.hpcp.dvar2_10                              float64\n",
      " 4229  tonal.hpcp.dvar2_11                              float64\n",
      " 4230  tonal.hpcp.dvar2_12                              float64\n",
      " 4231  tonal.hpcp.dvar2_13                              float64\n",
      " 4232  tonal.hpcp.dvar2_14                              float64\n",
      " 4233  tonal.hpcp.dvar2_15                              float64\n",
      " 4234  tonal.hpcp.dvar2_16                              float64\n",
      " 4235  tonal.hpcp.dvar2_17                              float64\n",
      " 4236  tonal.hpcp.dvar2_18                              float64\n",
      " 4237  tonal.hpcp.dvar2_19                              float64\n",
      " 4238  tonal.hpcp.dvar2_20                              float64\n",
      " 4239  tonal.hpcp.dvar2_21                              float64\n",
      " 4240  tonal.hpcp.dvar2_22                              float64\n",
      " 4241  tonal.hpcp.dvar2_23                              float64\n",
      " 4242  tonal.hpcp.dvar2_24                              float64\n",
      " 4243  tonal.hpcp.dvar2_25                              float64\n",
      " 4244  tonal.hpcp.dvar2_26                              float64\n",
      " 4245  tonal.hpcp.dvar2_27                              float64\n",
      " 4246  tonal.hpcp.dvar2_28                              float64\n",
      " 4247  tonal.hpcp.dvar2_29                              float64\n",
      " 4248  tonal.hpcp.dvar2_30                              float64\n",
      " 4249  tonal.hpcp.dvar2_31                              float64\n",
      " 4250  tonal.hpcp.dvar2_32                              float64\n",
      " 4251  tonal.hpcp.dvar2_33                              float64\n",
      " 4252  tonal.hpcp.dvar2_34                              float64\n",
      " 4253  tonal.hpcp.dvar2_35                              float64\n",
      " 4254  tonal.hpcp.max_0                                 float64\n",
      " 4255  tonal.hpcp.max_1                                 float64\n",
      " 4256  tonal.hpcp.max_2                                 float64\n",
      " 4257  tonal.hpcp.max_3                                 float64\n",
      " 4258  tonal.hpcp.max_4                                 float64\n",
      " 4259  tonal.hpcp.max_5                                 float64\n",
      " 4260  tonal.hpcp.max_6                                 float64\n",
      " 4261  tonal.hpcp.max_7                                 float64\n",
      " 4262  tonal.hpcp.max_8                                 float64\n",
      " 4263  tonal.hpcp.max_9                                 float64\n",
      " 4264  tonal.hpcp.max_10                                float64\n",
      " 4265  tonal.hpcp.max_11                                float64\n",
      " 4266  tonal.hpcp.max_12                                float64\n",
      " 4267  tonal.hpcp.max_13                                float64\n",
      " 4268  tonal.hpcp.max_14                                float64\n",
      " 4269  tonal.hpcp.max_15                                float64\n",
      " 4270  tonal.hpcp.max_16                                float64\n",
      " 4271  tonal.hpcp.max_17                                float64\n",
      " 4272  tonal.hpcp.max_18                                float64\n",
      " 4273  tonal.hpcp.max_19                                float64\n",
      " 4274  tonal.hpcp.max_20                                float64\n",
      " 4275  tonal.hpcp.max_21                                float64\n",
      " 4276  tonal.hpcp.max_22                                float64\n",
      " 4277  tonal.hpcp.max_23                                float64\n",
      " 4278  tonal.hpcp.max_24                                float64\n",
      " 4279  tonal.hpcp.max_25                                float64\n",
      " 4280  tonal.hpcp.max_26                                float64\n",
      " 4281  tonal.hpcp.max_27                                float64\n",
      " 4282  tonal.hpcp.max_28                                float64\n",
      " 4283  tonal.hpcp.max_29                                float64\n",
      " 4284  tonal.hpcp.max_30                                float64\n",
      " 4285  tonal.hpcp.max_31                                float64\n",
      " 4286  tonal.hpcp.max_32                                float64\n",
      " 4287  tonal.hpcp.max_33                                float64\n",
      " 4288  tonal.hpcp.max_34                                float64\n",
      " 4289  tonal.hpcp.max_35                                float64\n",
      " 4290  tonal.hpcp.mean_0                                float64\n",
      " 4291  tonal.hpcp.mean_1                                float64\n",
      " 4292  tonal.hpcp.mean_2                                float64\n",
      " 4293  tonal.hpcp.mean_3                                float64\n",
      " 4294  tonal.hpcp.mean_4                                float64\n",
      " 4295  tonal.hpcp.mean_5                                float64\n",
      " 4296  tonal.hpcp.mean_6                                float64\n",
      " 4297  tonal.hpcp.mean_7                                float64\n",
      " 4298  tonal.hpcp.mean_8                                float64\n",
      " 4299  tonal.hpcp.mean_9                                float64\n",
      " 4300  tonal.hpcp.mean_10                               float64\n",
      " 4301  tonal.hpcp.mean_11                               float64\n",
      " 4302  tonal.hpcp.mean_12                               float64\n",
      " 4303  tonal.hpcp.mean_13                               float64\n",
      " 4304  tonal.hpcp.mean_14                               float64\n",
      " 4305  tonal.hpcp.mean_15                               float64\n",
      " 4306  tonal.hpcp.mean_16                               float64\n",
      " 4307  tonal.hpcp.mean_17                               float64\n",
      " 4308  tonal.hpcp.mean_18                               float64\n",
      " 4309  tonal.hpcp.mean_19                               float64\n",
      " 4310  tonal.hpcp.mean_20                               float64\n",
      " 4311  tonal.hpcp.mean_21                               float64\n",
      " 4312  tonal.hpcp.mean_22                               float64\n",
      " 4313  tonal.hpcp.mean_23                               float64\n",
      " 4314  tonal.hpcp.mean_24                               float64\n",
      " 4315  tonal.hpcp.mean_25                               float64\n",
      " 4316  tonal.hpcp.mean_26                               float64\n",
      " 4317  tonal.hpcp.mean_27                               float64\n",
      " 4318  tonal.hpcp.mean_28                               float64\n",
      " 4319  tonal.hpcp.mean_29                               float64\n",
      " 4320  tonal.hpcp.mean_30                               float64\n",
      " 4321  tonal.hpcp.mean_31                               float64\n",
      " 4322  tonal.hpcp.mean_32                               float64\n",
      " 4323  tonal.hpcp.mean_33                               float64\n",
      " 4324  tonal.hpcp.mean_34                               float64\n",
      " 4325  tonal.hpcp.mean_35                               float64\n",
      " 4326  tonal.hpcp.median_0                              float64\n",
      " 4327  tonal.hpcp.median_1                              float64\n",
      " 4328  tonal.hpcp.median_2                              float64\n",
      " 4329  tonal.hpcp.median_3                              float64\n",
      " 4330  tonal.hpcp.median_4                              float64\n",
      " 4331  tonal.hpcp.median_5                              float64\n",
      " 4332  tonal.hpcp.median_6                              float64\n",
      " 4333  tonal.hpcp.median_7                              float64\n",
      " 4334  tonal.hpcp.median_8                              float64\n",
      " 4335  tonal.hpcp.median_9                              float64\n",
      " 4336  tonal.hpcp.median_10                             float64\n",
      " 4337  tonal.hpcp.median_11                             float64\n",
      " 4338  tonal.hpcp.median_12                             float64\n",
      " 4339  tonal.hpcp.median_13                             float64\n",
      " 4340  tonal.hpcp.median_14                             float64\n",
      " 4341  tonal.hpcp.median_15                             float64\n",
      " 4342  tonal.hpcp.median_16                             float64\n",
      " 4343  tonal.hpcp.median_17                             float64\n",
      " 4344  tonal.hpcp.median_18                             float64\n",
      " 4345  tonal.hpcp.median_19                             float64\n",
      " 4346  tonal.hpcp.median_20                             float64\n",
      " 4347  tonal.hpcp.median_21                             float64\n",
      " 4348  tonal.hpcp.median_22                             float64\n",
      " 4349  tonal.hpcp.median_23                             float64\n",
      " 4350  tonal.hpcp.median_24                             float64\n",
      " 4351  tonal.hpcp.median_25                             float64\n",
      " 4352  tonal.hpcp.median_26                             float64\n",
      " 4353  tonal.hpcp.median_27                             float64\n",
      " 4354  tonal.hpcp.median_28                             float64\n",
      " 4355  tonal.hpcp.median_29                             float64\n",
      " 4356  tonal.hpcp.median_30                             float64\n",
      " 4357  tonal.hpcp.median_31                             float64\n",
      " 4358  tonal.hpcp.median_32                             float64\n",
      " 4359  tonal.hpcp.median_33                             float64\n",
      " 4360  tonal.hpcp.median_34                             float64\n",
      " 4361  tonal.hpcp.median_35                             float64\n",
      " 4362  tonal.hpcp.min_0                                 float64\n",
      " 4363  tonal.hpcp.min_1                                 float64\n",
      " 4364  tonal.hpcp.min_2                                 float64\n",
      " 4365  tonal.hpcp.min_3                                 float64\n",
      " 4366  tonal.hpcp.min_4                                 float64\n",
      " 4367  tonal.hpcp.min_5                                 float64\n",
      " 4368  tonal.hpcp.min_6                                 float64\n",
      " 4369  tonal.hpcp.min_7                                 float64\n",
      " 4370  tonal.hpcp.min_8                                 float64\n",
      " 4371  tonal.hpcp.min_9                                 float64\n",
      " 4372  tonal.hpcp.min_10                                float64\n",
      " 4373  tonal.hpcp.min_11                                float64\n",
      " 4374  tonal.hpcp.min_12                                float64\n",
      " 4375  tonal.hpcp.min_13                                float64\n",
      " 4376  tonal.hpcp.min_14                                float64\n",
      " 4377  tonal.hpcp.min_15                                float64\n",
      " 4378  tonal.hpcp.min_16                                float64\n",
      " 4379  tonal.hpcp.min_17                                float64\n",
      " 4380  tonal.hpcp.min_18                                float64\n",
      " 4381  tonal.hpcp.min_19                                float64\n",
      " 4382  tonal.hpcp.min_20                                float64\n",
      " 4383  tonal.hpcp.min_21                                float64\n",
      " 4384  tonal.hpcp.min_22                                float64\n",
      " 4385  tonal.hpcp.min_23                                float64\n",
      " 4386  tonal.hpcp.min_24                                float64\n",
      " 4387  tonal.hpcp.min_25                                float64\n",
      " 4388  tonal.hpcp.min_26                                float64\n",
      " 4389  tonal.hpcp.min_27                                float64\n",
      " 4390  tonal.hpcp.min_28                                float64\n",
      " 4391  tonal.hpcp.min_29                                float64\n",
      " 4392  tonal.hpcp.min_30                                float64\n",
      " 4393  tonal.hpcp.min_31                                float64\n",
      " 4394  tonal.hpcp.min_32                                float64\n",
      " 4395  tonal.hpcp.min_33                                float64\n",
      " 4396  tonal.hpcp.min_34                                float64\n",
      " 4397  tonal.hpcp.min_35                                float64\n",
      " 4398  tonal.hpcp.stdev_0                               float64\n",
      " 4399  tonal.hpcp.stdev_1                               float64\n",
      " 4400  tonal.hpcp.stdev_2                               float64\n",
      " 4401  tonal.hpcp.stdev_3                               float64\n",
      " 4402  tonal.hpcp.stdev_4                               float64\n",
      " 4403  tonal.hpcp.stdev_5                               float64\n",
      " 4404  tonal.hpcp.stdev_6                               float64\n",
      " 4405  tonal.hpcp.stdev_7                               float64\n",
      " 4406  tonal.hpcp.stdev_8                               float64\n",
      " 4407  tonal.hpcp.stdev_9                               float64\n",
      " 4408  tonal.hpcp.stdev_10                              float64\n",
      " 4409  tonal.hpcp.stdev_11                              float64\n",
      " 4410  tonal.hpcp.stdev_12                              float64\n",
      " 4411  tonal.hpcp.stdev_13                              float64\n",
      " 4412  tonal.hpcp.stdev_14                              float64\n",
      " 4413  tonal.hpcp.stdev_15                              float64\n",
      " 4414  tonal.hpcp.stdev_16                              float64\n",
      " 4415  tonal.hpcp.stdev_17                              float64\n",
      " 4416  tonal.hpcp.stdev_18                              float64\n",
      " 4417  tonal.hpcp.stdev_19                              float64\n",
      " 4418  tonal.hpcp.stdev_20                              float64\n",
      " 4419  tonal.hpcp.stdev_21                              float64\n",
      " 4420  tonal.hpcp.stdev_22                              float64\n",
      " 4421  tonal.hpcp.stdev_23                              float64\n",
      " 4422  tonal.hpcp.stdev_24                              float64\n",
      " 4423  tonal.hpcp.stdev_25                              float64\n",
      " 4424  tonal.hpcp.stdev_26                              float64\n",
      " 4425  tonal.hpcp.stdev_27                              float64\n",
      " 4426  tonal.hpcp.stdev_28                              float64\n",
      " 4427  tonal.hpcp.stdev_29                              float64\n",
      " 4428  tonal.hpcp.stdev_30                              float64\n",
      " 4429  tonal.hpcp.stdev_31                              float64\n",
      " 4430  tonal.hpcp.stdev_32                              float64\n",
      " 4431  tonal.hpcp.stdev_33                              float64\n",
      " 4432  tonal.hpcp.stdev_34                              float64\n",
      " 4433  tonal.hpcp.stdev_35                              float64\n",
      " 4434  tonal.hpcp.var_0                                 float64\n",
      " 4435  tonal.hpcp.var_1                                 float64\n",
      " 4436  tonal.hpcp.var_2                                 float64\n",
      " 4437  tonal.hpcp.var_3                                 float64\n",
      " 4438  tonal.hpcp.var_4                                 float64\n",
      " 4439  tonal.hpcp.var_5                                 float64\n",
      " 4440  tonal.hpcp.var_6                                 float64\n",
      " 4441  tonal.hpcp.var_7                                 float64\n",
      " 4442  tonal.hpcp.var_8                                 float64\n",
      " 4443  tonal.hpcp.var_9                                 float64\n",
      " 4444  tonal.hpcp.var_10                                float64\n",
      " 4445  tonal.hpcp.var_11                                float64\n",
      " 4446  tonal.hpcp.var_12                                float64\n",
      " 4447  tonal.hpcp.var_13                                float64\n",
      " 4448  tonal.hpcp.var_14                                float64\n",
      " 4449  tonal.hpcp.var_15                                float64\n",
      " 4450  tonal.hpcp.var_16                                float64\n",
      " 4451  tonal.hpcp.var_17                                float64\n",
      " 4452  tonal.hpcp.var_18                                float64\n",
      " 4453  tonal.hpcp.var_19                                float64\n",
      " 4454  tonal.hpcp.var_20                                float64\n",
      " 4455  tonal.hpcp.var_21                                float64\n",
      " 4456  tonal.hpcp.var_22                                float64\n",
      " 4457  tonal.hpcp.var_23                                float64\n",
      " 4458  tonal.hpcp.var_24                                float64\n",
      " 4459  tonal.hpcp.var_25                                float64\n",
      " 4460  tonal.hpcp.var_26                                float64\n",
      " 4461  tonal.hpcp.var_27                                float64\n",
      " 4462  tonal.hpcp.var_28                                float64\n",
      " 4463  tonal.hpcp.var_29                                float64\n",
      " 4464  tonal.hpcp.var_30                                float64\n",
      " 4465  tonal.hpcp.var_31                                float64\n",
      " 4466  tonal.hpcp.var_32                                float64\n",
      " 4467  tonal.hpcp.var_33                                float64\n",
      " 4468  tonal.hpcp.var_34                                float64\n",
      " 4469  tonal.hpcp.var_35                                float64\n",
      " 4470  tonal.thpcp_0                                    float64\n",
      " 4471  tonal.thpcp_1                                    float64\n",
      " 4472  tonal.thpcp_2                                    float64\n",
      " 4473  tonal.thpcp_3                                    float64\n",
      " 4474  tonal.thpcp_4                                    float64\n",
      " 4475  tonal.thpcp_5                                    float64\n",
      " 4476  tonal.thpcp_6                                    float64\n",
      " 4477  tonal.thpcp_7                                    float64\n",
      " 4478  tonal.thpcp_8                                    float64\n",
      " 4479  tonal.thpcp_9                                    float64\n",
      " 4480  tonal.thpcp_10                                   float64\n",
      " 4481  tonal.thpcp_11                                   float64\n",
      " 4482  tonal.thpcp_12                                   float64\n",
      " 4483  tonal.thpcp_13                                   float64\n",
      " 4484  tonal.thpcp_14                                   float64\n",
      " 4485  tonal.thpcp_15                                   float64\n",
      " 4486  tonal.thpcp_16                                   float64\n",
      " 4487  tonal.thpcp_17                                   float64\n",
      " 4488  tonal.thpcp_18                                   float64\n",
      " 4489  tonal.thpcp_19                                   float64\n",
      " 4490  tonal.thpcp_20                                   float64\n",
      " 4491  tonal.thpcp_21                                   float64\n",
      " 4492  tonal.thpcp_22                                   float64\n",
      " 4493  tonal.thpcp_23                                   float64\n",
      " 4494  tonal.thpcp_24                                   float64\n",
      " 4495  tonal.thpcp_25                                   float64\n",
      " 4496  tonal.thpcp_26                                   float64\n",
      " 4497  tonal.thpcp_27                                   float64\n",
      " 4498  tonal.thpcp_28                                   float64\n",
      " 4499  tonal.thpcp_29                                   float64\n",
      " 4500  tonal.thpcp_30                                   float64\n",
      " 4501  tonal.thpcp_31                                   float64\n",
      " 4502  tonal.thpcp_32                                   float64\n",
      " 4503  tonal.thpcp_33                                   float64\n",
      " 4504  tonal.thpcp_34                                   float64\n",
      " 4505  tonal.thpcp_35                                   float64\n",
      " 4506  tonal.chords_key                                 float64\n",
      " 4507  tonal.chords_scale                               float64\n",
      " 4508  tonal.key_edma.key                               float64\n",
      " 4509  tonal.key_edma.scale                             float64\n",
      " 4510  tonal.key_krumhansl.key                          float64\n",
      " 4511  tonal.key_krumhansl.scale                        float64\n",
      " 4512  tonal.key_temperley.key                          float64\n",
      " 4513  tonal.key_temperley.scale                        float64\n",
      " 4514  F0semitoneFrom27.5Hz_sma3nz_amean                float64\n",
      " 4515  F0semitoneFrom27.5Hz_sma3nz_stddevNorm           float64\n",
      " 4516  F0semitoneFrom27.5Hz_sma3nz_percentile20.0       float64\n",
      " 4517  F0semitoneFrom27.5Hz_sma3nz_percentile50.0       float64\n",
      " 4518  F0semitoneFrom27.5Hz_sma3nz_percentile80.0       float64\n",
      " 4519  F0semitoneFrom27.5Hz_sma3nz_pctlrange0-2         float64\n",
      " 4520  F0semitoneFrom27.5Hz_sma3nz_meanRisingSlope      float64\n",
      " 4521  F0semitoneFrom27.5Hz_sma3nz_stddevRisingSlope    float64\n",
      " 4522  F0semitoneFrom27.5Hz_sma3nz_meanFallingSlope     float64\n",
      " 4523  F0semitoneFrom27.5Hz_sma3nz_stddevFallingSlope   float64\n",
      " 4524  loudness_sma3_amean                              float64\n",
      " 4525  loudness_sma3_stddevNorm                         float64\n",
      " 4526  loudness_sma3_percentile20.0                     float64\n",
      " 4527  loudness_sma3_percentile50.0                     float64\n",
      " 4528  loudness_sma3_percentile80.0                     float64\n",
      " 4529  loudness_sma3_pctlrange0-2                       float64\n",
      " 4530  loudness_sma3_meanRisingSlope                    float64\n",
      " 4531  loudness_sma3_stddevRisingSlope                  float64\n",
      " 4532  loudness_sma3_meanFallingSlope                   float64\n",
      " 4533  loudness_sma3_stddevFallingSlope                 float64\n",
      " 4534  spectralFlux_sma3_amean                          float64\n",
      " 4535  spectralFlux_sma3_stddevNorm                     float64\n",
      " 4536  mfcc1_sma3_amean                                 float64\n",
      " 4537  mfcc1_sma3_stddevNorm                            float64\n",
      " 4538  mfcc2_sma3_amean                                 float64\n",
      " 4539  mfcc2_sma3_stddevNorm                            float64\n",
      " 4540  mfcc3_sma3_amean                                 float64\n",
      " 4541  mfcc3_sma3_stddevNorm                            float64\n",
      " 4542  mfcc4_sma3_amean                                 float64\n",
      " 4543  mfcc4_sma3_stddevNorm                            float64\n",
      " 4544  jitterLocal_sma3nz_amean                         float64\n",
      " 4545  jitterLocal_sma3nz_stddevNorm                    float64\n",
      " 4546  shimmerLocaldB_sma3nz_amean                      float64\n",
      " 4547  shimmerLocaldB_sma3nz_stddevNorm                 float64\n",
      " 4548  HNRdBACF_sma3nz_amean                            float64\n",
      " 4549  HNRdBACF_sma3nz_stddevNorm                       float64\n",
      " 4550  logRelF0-H1-H2_sma3nz_amean                      float64\n",
      " 4551  logRelF0-H1-H2_sma3nz_stddevNorm                 float64\n",
      " 4552  logRelF0-H1-A3_sma3nz_amean                      float64\n",
      " 4553  logRelF0-H1-A3_sma3nz_stddevNorm                 float64\n",
      " 4554  F1frequency_sma3nz_amean                         float64\n",
      " 4555  F1frequency_sma3nz_stddevNorm                    float64\n",
      " 4556  F1bandwidth_sma3nz_amean                         float64\n",
      " 4557  F1bandwidth_sma3nz_stddevNorm                    float64\n",
      " 4558  F1amplitudeLogRelF0_sma3nz_amean                 float64\n",
      " 4559  F1amplitudeLogRelF0_sma3nz_stddevNorm            float64\n",
      " 4560  F2frequency_sma3nz_amean                         float64\n",
      " 4561  F2frequency_sma3nz_stddevNorm                    float64\n",
      " 4562  F2bandwidth_sma3nz_amean                         float64\n",
      " 4563  F2bandwidth_sma3nz_stddevNorm                    float64\n",
      " 4564  F2amplitudeLogRelF0_sma3nz_amean                 float64\n",
      " 4565  F2amplitudeLogRelF0_sma3nz_stddevNorm            float64\n",
      " 4566  F3frequency_sma3nz_amean                         float64\n",
      " 4567  F3frequency_sma3nz_stddevNorm                    float64\n",
      " 4568  F3bandwidth_sma3nz_amean                         float64\n",
      " 4569  F3bandwidth_sma3nz_stddevNorm                    float64\n",
      " 4570  F3amplitudeLogRelF0_sma3nz_amean                 float64\n",
      " 4571  F3amplitudeLogRelF0_sma3nz_stddevNorm            float64\n",
      " 4572  alphaRatioV_sma3nz_amean                         float64\n",
      " 4573  alphaRatioV_sma3nz_stddevNorm                    float64\n",
      " 4574  hammarbergIndexV_sma3nz_amean                    float64\n",
      " 4575  hammarbergIndexV_sma3nz_stddevNorm               float64\n",
      " 4576  slopeV0-500_sma3nz_amean                         float64\n",
      " 4577  slopeV0-500_sma3nz_stddevNorm                    float64\n",
      " 4578  slopeV500-1500_sma3nz_amean                      float64\n",
      " 4579  slopeV500-1500_sma3nz_stddevNorm                 float64\n",
      " 4580  spectralFluxV_sma3nz_amean                       float64\n",
      " 4581  spectralFluxV_sma3nz_stddevNorm                  float64\n",
      " 4582  mfcc1V_sma3nz_amean                              float64\n",
      " 4583  mfcc1V_sma3nz_stddevNorm                         float64\n",
      " 4584  mfcc2V_sma3nz_amean                              float64\n",
      " 4585  mfcc2V_sma3nz_stddevNorm                         float64\n",
      " 4586  mfcc3V_sma3nz_amean                              float64\n",
      " 4587  mfcc3V_sma3nz_stddevNorm                         float64\n",
      " 4588  mfcc4V_sma3nz_amean                              float64\n",
      " 4589  mfcc4V_sma3nz_stddevNorm                         float64\n",
      " 4590  alphaRatioUV_sma3nz_amean                        float64\n",
      " 4591  hammarbergIndexUV_sma3nz_amean                   float64\n",
      " 4592  slopeUV0-500_sma3nz_amean                        float64\n",
      " 4593  slopeUV500-1500_sma3nz_amean                     float64\n",
      " 4594  spectralFluxUV_sma3nz_amean                      float64\n",
      " 4595  loudnessPeaksPerSec                              float64\n",
      " 4596  VoicedSegmentsPerSec                             float64\n",
      " 4597  MeanVoicedSegmentLengthSec                       float64\n",
      " 4598  StddevVoicedSegmentLengthSec                     float64\n",
      " 4599  MeanUnvoicedSegmentLength                        float64\n",
      " 4600  StddevUnvoicedSegmentLength                      float64\n",
      " 4601  equivalentSoundLevel_dBp                         float64\n",
      "dtypes: float64(4601), int64(1)\n",
      "memory usage: 61.2 MB\n"
     ]
    }
   ],
   "source": [
    "df_essentia_all_opensmile_egemaps_features.info(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join both the featureset and annotation set together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lowlevel.average_loudness</th>\n",
       "      <th>lowlevel.barkbands_crest.dmean</th>\n",
       "      <th>lowlevel.barkbands_crest.dmean2</th>\n",
       "      <th>lowlevel.barkbands_crest.dvar</th>\n",
       "      <th>lowlevel.barkbands_crest.dvar2</th>\n",
       "      <th>lowlevel.barkbands_crest.max</th>\n",
       "      <th>lowlevel.barkbands_crest.mean</th>\n",
       "      <th>lowlevel.barkbands_crest.median</th>\n",
       "      <th>lowlevel.barkbands_crest.min</th>\n",
       "      <th>lowlevel.barkbands_crest.stdev</th>\n",
       "      <th>...</th>\n",
       "      <th>spectralFluxUV_sma3nz_amean</th>\n",
       "      <th>loudnessPeaksPerSec</th>\n",
       "      <th>VoicedSegmentsPerSec</th>\n",
       "      <th>MeanVoicedSegmentLengthSec</th>\n",
       "      <th>StddevVoicedSegmentLengthSec</th>\n",
       "      <th>MeanUnvoicedSegmentLength</th>\n",
       "      <th>StddevUnvoicedSegmentLength</th>\n",
       "      <th>equivalentSoundLevel_dBp</th>\n",
       "      <th>valence_mean_mapped</th>\n",
       "      <th>arousal_mean_mapped</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.972741</td>\n",
       "      <td>0.322732</td>\n",
       "      <td>0.345839</td>\n",
       "      <td>0.104501</td>\n",
       "      <td>0.145450</td>\n",
       "      <td>0.704285</td>\n",
       "      <td>0.376120</td>\n",
       "      <td>0.313025</td>\n",
       "      <td>0.154835</td>\n",
       "      <td>0.299859</td>\n",
       "      <td>...</td>\n",
       "      <td>0.181705</td>\n",
       "      <td>0.264131</td>\n",
       "      <td>0.049256</td>\n",
       "      <td>0.069750</td>\n",
       "      <td>0.164484</td>\n",
       "      <td>0.027513</td>\n",
       "      <td>0.014235</td>\n",
       "      <td>0.594429</td>\n",
       "      <td>-0.475</td>\n",
       "      <td>-0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.583679</td>\n",
       "      <td>0.205943</td>\n",
       "      <td>0.227717</td>\n",
       "      <td>0.096043</td>\n",
       "      <td>0.121328</td>\n",
       "      <td>0.970572</td>\n",
       "      <td>0.702144</td>\n",
       "      <td>0.582300</td>\n",
       "      <td>0.362288</td>\n",
       "      <td>0.483374</td>\n",
       "      <td>...</td>\n",
       "      <td>0.212856</td>\n",
       "      <td>0.206415</td>\n",
       "      <td>0.329843</td>\n",
       "      <td>0.008219</td>\n",
       "      <td>0.024446</td>\n",
       "      <td>0.077423</td>\n",
       "      <td>0.056789</td>\n",
       "      <td>0.639348</td>\n",
       "      <td>-0.375</td>\n",
       "      <td>-0.425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.990960</td>\n",
       "      <td>0.375110</td>\n",
       "      <td>0.387854</td>\n",
       "      <td>0.150212</td>\n",
       "      <td>0.190855</td>\n",
       "      <td>0.658252</td>\n",
       "      <td>0.336314</td>\n",
       "      <td>0.283905</td>\n",
       "      <td>0.164182</td>\n",
       "      <td>0.283623</td>\n",
       "      <td>...</td>\n",
       "      <td>0.358312</td>\n",
       "      <td>0.349895</td>\n",
       "      <td>0.314678</td>\n",
       "      <td>0.009789</td>\n",
       "      <td>0.018589</td>\n",
       "      <td>0.040617</td>\n",
       "      <td>0.018047</td>\n",
       "      <td>0.741370</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.914417</td>\n",
       "      <td>0.356523</td>\n",
       "      <td>0.363551</td>\n",
       "      <td>0.122697</td>\n",
       "      <td>0.149895</td>\n",
       "      <td>0.858083</td>\n",
       "      <td>0.392704</td>\n",
       "      <td>0.305499</td>\n",
       "      <td>0.277203</td>\n",
       "      <td>0.385212</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228007</td>\n",
       "      <td>0.256759</td>\n",
       "      <td>0.041739</td>\n",
       "      <td>0.081478</td>\n",
       "      <td>0.149317</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.018206</td>\n",
       "      <td>0.682132</td>\n",
       "      <td>-0.150</td>\n",
       "      <td>0.075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.991187</td>\n",
       "      <td>0.256914</td>\n",
       "      <td>0.255848</td>\n",
       "      <td>0.139336</td>\n",
       "      <td>0.149169</td>\n",
       "      <td>0.824768</td>\n",
       "      <td>0.660008</td>\n",
       "      <td>0.574646</td>\n",
       "      <td>0.183156</td>\n",
       "      <td>0.326380</td>\n",
       "      <td>...</td>\n",
       "      <td>0.362308</td>\n",
       "      <td>0.520714</td>\n",
       "      <td>0.060622</td>\n",
       "      <td>0.057195</td>\n",
       "      <td>0.142060</td>\n",
       "      <td>0.030864</td>\n",
       "      <td>0.021297</td>\n",
       "      <td>0.819566</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1739</th>\n",
       "      <td>0.996544</td>\n",
       "      <td>0.532901</td>\n",
       "      <td>0.553871</td>\n",
       "      <td>0.245012</td>\n",
       "      <td>0.263674</td>\n",
       "      <td>0.717103</td>\n",
       "      <td>0.318415</td>\n",
       "      <td>0.236341</td>\n",
       "      <td>0.243114</td>\n",
       "      <td>0.343265</td>\n",
       "      <td>...</td>\n",
       "      <td>0.245619</td>\n",
       "      <td>0.619651</td>\n",
       "      <td>0.170727</td>\n",
       "      <td>0.020034</td>\n",
       "      <td>0.048555</td>\n",
       "      <td>0.024143</td>\n",
       "      <td>0.009844</td>\n",
       "      <td>0.640006</td>\n",
       "      <td>-0.275</td>\n",
       "      <td>0.225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1740</th>\n",
       "      <td>0.998184</td>\n",
       "      <td>0.351222</td>\n",
       "      <td>0.382376</td>\n",
       "      <td>0.123357</td>\n",
       "      <td>0.160645</td>\n",
       "      <td>0.605959</td>\n",
       "      <td>0.307426</td>\n",
       "      <td>0.253574</td>\n",
       "      <td>0.218863</td>\n",
       "      <td>0.283298</td>\n",
       "      <td>...</td>\n",
       "      <td>0.155033</td>\n",
       "      <td>0.513858</td>\n",
       "      <td>0.144237</td>\n",
       "      <td>0.023835</td>\n",
       "      <td>0.051010</td>\n",
       "      <td>0.032222</td>\n",
       "      <td>0.021974</td>\n",
       "      <td>0.516482</td>\n",
       "      <td>0.075</td>\n",
       "      <td>-0.275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1741</th>\n",
       "      <td>0.911413</td>\n",
       "      <td>0.423552</td>\n",
       "      <td>0.429467</td>\n",
       "      <td>0.174821</td>\n",
       "      <td>0.189958</td>\n",
       "      <td>0.795025</td>\n",
       "      <td>0.269332</td>\n",
       "      <td>0.218253</td>\n",
       "      <td>0.095981</td>\n",
       "      <td>0.334333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.180579</td>\n",
       "      <td>0.506302</td>\n",
       "      <td>0.497215</td>\n",
       "      <td>0.005271</td>\n",
       "      <td>0.021518</td>\n",
       "      <td>0.045299</td>\n",
       "      <td>0.023471</td>\n",
       "      <td>0.599258</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1742</th>\n",
       "      <td>0.974887</td>\n",
       "      <td>0.395791</td>\n",
       "      <td>0.436942</td>\n",
       "      <td>0.118189</td>\n",
       "      <td>0.156440</td>\n",
       "      <td>0.638507</td>\n",
       "      <td>0.285916</td>\n",
       "      <td>0.238424</td>\n",
       "      <td>0.279791</td>\n",
       "      <td>0.190968</td>\n",
       "      <td>...</td>\n",
       "      <td>0.183881</td>\n",
       "      <td>0.370283</td>\n",
       "      <td>0.413529</td>\n",
       "      <td>0.007011</td>\n",
       "      <td>0.014129</td>\n",
       "      <td>0.038426</td>\n",
       "      <td>0.021311</td>\n",
       "      <td>0.557897</td>\n",
       "      <td>-0.100</td>\n",
       "      <td>0.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1743</th>\n",
       "      <td>0.965636</td>\n",
       "      <td>0.417235</td>\n",
       "      <td>0.449227</td>\n",
       "      <td>0.162883</td>\n",
       "      <td>0.205566</td>\n",
       "      <td>0.840740</td>\n",
       "      <td>0.292641</td>\n",
       "      <td>0.246279</td>\n",
       "      <td>0.197996</td>\n",
       "      <td>0.275618</td>\n",
       "      <td>...</td>\n",
       "      <td>0.181125</td>\n",
       "      <td>0.501264</td>\n",
       "      <td>0.493198</td>\n",
       "      <td>0.004996</td>\n",
       "      <td>0.014090</td>\n",
       "      <td>0.055489</td>\n",
       "      <td>0.032671</td>\n",
       "      <td>0.600906</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1744 rows × 4603 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      lowlevel.average_loudness  lowlevel.barkbands_crest.dmean  \\\n",
       "0                      0.972741                        0.322732   \n",
       "1                      0.583679                        0.205943   \n",
       "2                      0.990960                        0.375110   \n",
       "3                      0.914417                        0.356523   \n",
       "4                      0.991187                        0.256914   \n",
       "...                         ...                             ...   \n",
       "1739                   0.996544                        0.532901   \n",
       "1740                   0.998184                        0.351222   \n",
       "1741                   0.911413                        0.423552   \n",
       "1742                   0.974887                        0.395791   \n",
       "1743                   0.965636                        0.417235   \n",
       "\n",
       "      lowlevel.barkbands_crest.dmean2  lowlevel.barkbands_crest.dvar  \\\n",
       "0                            0.345839                       0.104501   \n",
       "1                            0.227717                       0.096043   \n",
       "2                            0.387854                       0.150212   \n",
       "3                            0.363551                       0.122697   \n",
       "4                            0.255848                       0.139336   \n",
       "...                               ...                            ...   \n",
       "1739                         0.553871                       0.245012   \n",
       "1740                         0.382376                       0.123357   \n",
       "1741                         0.429467                       0.174821   \n",
       "1742                         0.436942                       0.118189   \n",
       "1743                         0.449227                       0.162883   \n",
       "\n",
       "      lowlevel.barkbands_crest.dvar2  lowlevel.barkbands_crest.max  \\\n",
       "0                           0.145450                      0.704285   \n",
       "1                           0.121328                      0.970572   \n",
       "2                           0.190855                      0.658252   \n",
       "3                           0.149895                      0.858083   \n",
       "4                           0.149169                      0.824768   \n",
       "...                              ...                           ...   \n",
       "1739                        0.263674                      0.717103   \n",
       "1740                        0.160645                      0.605959   \n",
       "1741                        0.189958                      0.795025   \n",
       "1742                        0.156440                      0.638507   \n",
       "1743                        0.205566                      0.840740   \n",
       "\n",
       "      lowlevel.barkbands_crest.mean  lowlevel.barkbands_crest.median  \\\n",
       "0                          0.376120                         0.313025   \n",
       "1                          0.702144                         0.582300   \n",
       "2                          0.336314                         0.283905   \n",
       "3                          0.392704                         0.305499   \n",
       "4                          0.660008                         0.574646   \n",
       "...                             ...                              ...   \n",
       "1739                       0.318415                         0.236341   \n",
       "1740                       0.307426                         0.253574   \n",
       "1741                       0.269332                         0.218253   \n",
       "1742                       0.285916                         0.238424   \n",
       "1743                       0.292641                         0.246279   \n",
       "\n",
       "      lowlevel.barkbands_crest.min  lowlevel.barkbands_crest.stdev  ...  \\\n",
       "0                         0.154835                        0.299859  ...   \n",
       "1                         0.362288                        0.483374  ...   \n",
       "2                         0.164182                        0.283623  ...   \n",
       "3                         0.277203                        0.385212  ...   \n",
       "4                         0.183156                        0.326380  ...   \n",
       "...                            ...                             ...  ...   \n",
       "1739                      0.243114                        0.343265  ...   \n",
       "1740                      0.218863                        0.283298  ...   \n",
       "1741                      0.095981                        0.334333  ...   \n",
       "1742                      0.279791                        0.190968  ...   \n",
       "1743                      0.197996                        0.275618  ...   \n",
       "\n",
       "      spectralFluxUV_sma3nz_amean  loudnessPeaksPerSec  VoicedSegmentsPerSec  \\\n",
       "0                        0.181705             0.264131              0.049256   \n",
       "1                        0.212856             0.206415              0.329843   \n",
       "2                        0.358312             0.349895              0.314678   \n",
       "3                        0.228007             0.256759              0.041739   \n",
       "4                        0.362308             0.520714              0.060622   \n",
       "...                           ...                  ...                   ...   \n",
       "1739                     0.245619             0.619651              0.170727   \n",
       "1740                     0.155033             0.513858              0.144237   \n",
       "1741                     0.180579             0.506302              0.497215   \n",
       "1742                     0.183881             0.370283              0.413529   \n",
       "1743                     0.181125             0.501264              0.493198   \n",
       "\n",
       "      MeanVoicedSegmentLengthSec  StddevVoicedSegmentLengthSec  \\\n",
       "0                       0.069750                      0.164484   \n",
       "1                       0.008219                      0.024446   \n",
       "2                       0.009789                      0.018589   \n",
       "3                       0.081478                      0.149317   \n",
       "4                       0.057195                      0.142060   \n",
       "...                          ...                           ...   \n",
       "1739                    0.020034                      0.048555   \n",
       "1740                    0.023835                      0.051010   \n",
       "1741                    0.005271                      0.021518   \n",
       "1742                    0.007011                      0.014129   \n",
       "1743                    0.004996                      0.014090   \n",
       "\n",
       "      MeanUnvoicedSegmentLength  StddevUnvoicedSegmentLength  \\\n",
       "0                      0.027513                     0.014235   \n",
       "1                      0.077423                     0.056789   \n",
       "2                      0.040617                     0.018047   \n",
       "3                      0.028571                     0.018206   \n",
       "4                      0.030864                     0.021297   \n",
       "...                         ...                          ...   \n",
       "1739                   0.024143                     0.009844   \n",
       "1740                   0.032222                     0.021974   \n",
       "1741                   0.045299                     0.023471   \n",
       "1742                   0.038426                     0.021311   \n",
       "1743                   0.055489                     0.032671   \n",
       "\n",
       "      equivalentSoundLevel_dBp  valence_mean_mapped  arousal_mean_mapped  \n",
       "0                     0.594429               -0.475               -0.500  \n",
       "1                     0.639348               -0.375               -0.425  \n",
       "2                     0.741370                0.175                0.125  \n",
       "3                     0.682132               -0.150                0.075  \n",
       "4                     0.819566                0.200                0.350  \n",
       "...                        ...                  ...                  ...  \n",
       "1739                  0.640006               -0.275                0.225  \n",
       "1740                  0.516482                0.075               -0.275  \n",
       "1741                  0.599258                0.350                0.300  \n",
       "1742                  0.557897               -0.100                0.100  \n",
       "1743                  0.600906                0.200                0.250  \n",
       "\n",
       "[1744 rows x 4603 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_essentia_all_opensmile_egemaps_whole = pd.merge(df_essentia_all_opensmile_egemaps_features, df_annotations, how='inner', on='song_id')\n",
    "df_essentia_all_opensmile_egemaps_whole = df_essentia_all_opensmile_egemaps_whole.drop('song_id', axis=1)\n",
    "df_essentia_all_opensmile_egemaps_whole"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare dataframes for the neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform splitting of the dataframe into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lowlevel.average_loudness</th>\n",
       "      <th>lowlevel.barkbands_crest.dmean</th>\n",
       "      <th>lowlevel.barkbands_crest.dmean2</th>\n",
       "      <th>lowlevel.barkbands_crest.dvar</th>\n",
       "      <th>lowlevel.barkbands_crest.dvar2</th>\n",
       "      <th>lowlevel.barkbands_crest.max</th>\n",
       "      <th>lowlevel.barkbands_crest.mean</th>\n",
       "      <th>lowlevel.barkbands_crest.median</th>\n",
       "      <th>lowlevel.barkbands_crest.min</th>\n",
       "      <th>lowlevel.barkbands_crest.stdev</th>\n",
       "      <th>...</th>\n",
       "      <th>slopeUV0-500_sma3nz_amean</th>\n",
       "      <th>slopeUV500-1500_sma3nz_amean</th>\n",
       "      <th>spectralFluxUV_sma3nz_amean</th>\n",
       "      <th>loudnessPeaksPerSec</th>\n",
       "      <th>VoicedSegmentsPerSec</th>\n",
       "      <th>MeanVoicedSegmentLengthSec</th>\n",
       "      <th>StddevVoicedSegmentLengthSec</th>\n",
       "      <th>MeanUnvoicedSegmentLength</th>\n",
       "      <th>StddevUnvoicedSegmentLength</th>\n",
       "      <th>equivalentSoundLevel_dBp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.972741</td>\n",
       "      <td>0.322732</td>\n",
       "      <td>0.345839</td>\n",
       "      <td>0.104501</td>\n",
       "      <td>0.145450</td>\n",
       "      <td>0.704285</td>\n",
       "      <td>0.376120</td>\n",
       "      <td>0.313025</td>\n",
       "      <td>0.154835</td>\n",
       "      <td>0.299859</td>\n",
       "      <td>...</td>\n",
       "      <td>0.351559</td>\n",
       "      <td>0.600638</td>\n",
       "      <td>0.181705</td>\n",
       "      <td>0.264131</td>\n",
       "      <td>0.049256</td>\n",
       "      <td>0.069750</td>\n",
       "      <td>0.164484</td>\n",
       "      <td>0.027513</td>\n",
       "      <td>0.014235</td>\n",
       "      <td>0.594429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.583679</td>\n",
       "      <td>0.205943</td>\n",
       "      <td>0.227717</td>\n",
       "      <td>0.096043</td>\n",
       "      <td>0.121328</td>\n",
       "      <td>0.970572</td>\n",
       "      <td>0.702144</td>\n",
       "      <td>0.582300</td>\n",
       "      <td>0.362288</td>\n",
       "      <td>0.483374</td>\n",
       "      <td>...</td>\n",
       "      <td>0.126664</td>\n",
       "      <td>0.581319</td>\n",
       "      <td>0.212856</td>\n",
       "      <td>0.206415</td>\n",
       "      <td>0.329843</td>\n",
       "      <td>0.008219</td>\n",
       "      <td>0.024446</td>\n",
       "      <td>0.077423</td>\n",
       "      <td>0.056789</td>\n",
       "      <td>0.639348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.990960</td>\n",
       "      <td>0.375110</td>\n",
       "      <td>0.387854</td>\n",
       "      <td>0.150212</td>\n",
       "      <td>0.190855</td>\n",
       "      <td>0.658252</td>\n",
       "      <td>0.336314</td>\n",
       "      <td>0.283905</td>\n",
       "      <td>0.164182</td>\n",
       "      <td>0.283623</td>\n",
       "      <td>...</td>\n",
       "      <td>0.273067</td>\n",
       "      <td>0.606355</td>\n",
       "      <td>0.358312</td>\n",
       "      <td>0.349895</td>\n",
       "      <td>0.314678</td>\n",
       "      <td>0.009789</td>\n",
       "      <td>0.018589</td>\n",
       "      <td>0.040617</td>\n",
       "      <td>0.018047</td>\n",
       "      <td>0.741370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.914417</td>\n",
       "      <td>0.356523</td>\n",
       "      <td>0.363551</td>\n",
       "      <td>0.122697</td>\n",
       "      <td>0.149895</td>\n",
       "      <td>0.858083</td>\n",
       "      <td>0.392704</td>\n",
       "      <td>0.305499</td>\n",
       "      <td>0.277203</td>\n",
       "      <td>0.385212</td>\n",
       "      <td>...</td>\n",
       "      <td>0.573717</td>\n",
       "      <td>0.384170</td>\n",
       "      <td>0.228007</td>\n",
       "      <td>0.256759</td>\n",
       "      <td>0.041739</td>\n",
       "      <td>0.081478</td>\n",
       "      <td>0.149317</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.018206</td>\n",
       "      <td>0.682132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.991187</td>\n",
       "      <td>0.256914</td>\n",
       "      <td>0.255848</td>\n",
       "      <td>0.139336</td>\n",
       "      <td>0.149169</td>\n",
       "      <td>0.824768</td>\n",
       "      <td>0.660008</td>\n",
       "      <td>0.574646</td>\n",
       "      <td>0.183156</td>\n",
       "      <td>0.326380</td>\n",
       "      <td>...</td>\n",
       "      <td>0.264243</td>\n",
       "      <td>0.575046</td>\n",
       "      <td>0.362308</td>\n",
       "      <td>0.520714</td>\n",
       "      <td>0.060622</td>\n",
       "      <td>0.057195</td>\n",
       "      <td>0.142060</td>\n",
       "      <td>0.030864</td>\n",
       "      <td>0.021297</td>\n",
       "      <td>0.819566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1739</th>\n",
       "      <td>0.996544</td>\n",
       "      <td>0.532901</td>\n",
       "      <td>0.553871</td>\n",
       "      <td>0.245012</td>\n",
       "      <td>0.263674</td>\n",
       "      <td>0.717103</td>\n",
       "      <td>0.318415</td>\n",
       "      <td>0.236341</td>\n",
       "      <td>0.243114</td>\n",
       "      <td>0.343265</td>\n",
       "      <td>...</td>\n",
       "      <td>0.407510</td>\n",
       "      <td>0.426452</td>\n",
       "      <td>0.245619</td>\n",
       "      <td>0.619651</td>\n",
       "      <td>0.170727</td>\n",
       "      <td>0.020034</td>\n",
       "      <td>0.048555</td>\n",
       "      <td>0.024143</td>\n",
       "      <td>0.009844</td>\n",
       "      <td>0.640006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1740</th>\n",
       "      <td>0.998184</td>\n",
       "      <td>0.351222</td>\n",
       "      <td>0.382376</td>\n",
       "      <td>0.123357</td>\n",
       "      <td>0.160645</td>\n",
       "      <td>0.605959</td>\n",
       "      <td>0.307426</td>\n",
       "      <td>0.253574</td>\n",
       "      <td>0.218863</td>\n",
       "      <td>0.283298</td>\n",
       "      <td>...</td>\n",
       "      <td>0.409826</td>\n",
       "      <td>0.439188</td>\n",
       "      <td>0.155033</td>\n",
       "      <td>0.513858</td>\n",
       "      <td>0.144237</td>\n",
       "      <td>0.023835</td>\n",
       "      <td>0.051010</td>\n",
       "      <td>0.032222</td>\n",
       "      <td>0.021974</td>\n",
       "      <td>0.516482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1741</th>\n",
       "      <td>0.911413</td>\n",
       "      <td>0.423552</td>\n",
       "      <td>0.429467</td>\n",
       "      <td>0.174821</td>\n",
       "      <td>0.189958</td>\n",
       "      <td>0.795025</td>\n",
       "      <td>0.269332</td>\n",
       "      <td>0.218253</td>\n",
       "      <td>0.095981</td>\n",
       "      <td>0.334333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.321734</td>\n",
       "      <td>0.510924</td>\n",
       "      <td>0.180579</td>\n",
       "      <td>0.506302</td>\n",
       "      <td>0.497215</td>\n",
       "      <td>0.005271</td>\n",
       "      <td>0.021518</td>\n",
       "      <td>0.045299</td>\n",
       "      <td>0.023471</td>\n",
       "      <td>0.599258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1742</th>\n",
       "      <td>0.974887</td>\n",
       "      <td>0.395791</td>\n",
       "      <td>0.436942</td>\n",
       "      <td>0.118189</td>\n",
       "      <td>0.156440</td>\n",
       "      <td>0.638507</td>\n",
       "      <td>0.285916</td>\n",
       "      <td>0.238424</td>\n",
       "      <td>0.279791</td>\n",
       "      <td>0.190968</td>\n",
       "      <td>...</td>\n",
       "      <td>0.384083</td>\n",
       "      <td>0.506933</td>\n",
       "      <td>0.183881</td>\n",
       "      <td>0.370283</td>\n",
       "      <td>0.413529</td>\n",
       "      <td>0.007011</td>\n",
       "      <td>0.014129</td>\n",
       "      <td>0.038426</td>\n",
       "      <td>0.021311</td>\n",
       "      <td>0.557897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1743</th>\n",
       "      <td>0.965636</td>\n",
       "      <td>0.417235</td>\n",
       "      <td>0.449227</td>\n",
       "      <td>0.162883</td>\n",
       "      <td>0.205566</td>\n",
       "      <td>0.840740</td>\n",
       "      <td>0.292641</td>\n",
       "      <td>0.246279</td>\n",
       "      <td>0.197996</td>\n",
       "      <td>0.275618</td>\n",
       "      <td>...</td>\n",
       "      <td>0.332454</td>\n",
       "      <td>0.604519</td>\n",
       "      <td>0.181125</td>\n",
       "      <td>0.501264</td>\n",
       "      <td>0.493198</td>\n",
       "      <td>0.004996</td>\n",
       "      <td>0.014090</td>\n",
       "      <td>0.055489</td>\n",
       "      <td>0.032671</td>\n",
       "      <td>0.600906</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1744 rows × 4601 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      lowlevel.average_loudness  lowlevel.barkbands_crest.dmean  \\\n",
       "0                      0.972741                        0.322732   \n",
       "1                      0.583679                        0.205943   \n",
       "2                      0.990960                        0.375110   \n",
       "3                      0.914417                        0.356523   \n",
       "4                      0.991187                        0.256914   \n",
       "...                         ...                             ...   \n",
       "1739                   0.996544                        0.532901   \n",
       "1740                   0.998184                        0.351222   \n",
       "1741                   0.911413                        0.423552   \n",
       "1742                   0.974887                        0.395791   \n",
       "1743                   0.965636                        0.417235   \n",
       "\n",
       "      lowlevel.barkbands_crest.dmean2  lowlevel.barkbands_crest.dvar  \\\n",
       "0                            0.345839                       0.104501   \n",
       "1                            0.227717                       0.096043   \n",
       "2                            0.387854                       0.150212   \n",
       "3                            0.363551                       0.122697   \n",
       "4                            0.255848                       0.139336   \n",
       "...                               ...                            ...   \n",
       "1739                         0.553871                       0.245012   \n",
       "1740                         0.382376                       0.123357   \n",
       "1741                         0.429467                       0.174821   \n",
       "1742                         0.436942                       0.118189   \n",
       "1743                         0.449227                       0.162883   \n",
       "\n",
       "      lowlevel.barkbands_crest.dvar2  lowlevel.barkbands_crest.max  \\\n",
       "0                           0.145450                      0.704285   \n",
       "1                           0.121328                      0.970572   \n",
       "2                           0.190855                      0.658252   \n",
       "3                           0.149895                      0.858083   \n",
       "4                           0.149169                      0.824768   \n",
       "...                              ...                           ...   \n",
       "1739                        0.263674                      0.717103   \n",
       "1740                        0.160645                      0.605959   \n",
       "1741                        0.189958                      0.795025   \n",
       "1742                        0.156440                      0.638507   \n",
       "1743                        0.205566                      0.840740   \n",
       "\n",
       "      lowlevel.barkbands_crest.mean  lowlevel.barkbands_crest.median  \\\n",
       "0                          0.376120                         0.313025   \n",
       "1                          0.702144                         0.582300   \n",
       "2                          0.336314                         0.283905   \n",
       "3                          0.392704                         0.305499   \n",
       "4                          0.660008                         0.574646   \n",
       "...                             ...                              ...   \n",
       "1739                       0.318415                         0.236341   \n",
       "1740                       0.307426                         0.253574   \n",
       "1741                       0.269332                         0.218253   \n",
       "1742                       0.285916                         0.238424   \n",
       "1743                       0.292641                         0.246279   \n",
       "\n",
       "      lowlevel.barkbands_crest.min  lowlevel.barkbands_crest.stdev  ...  \\\n",
       "0                         0.154835                        0.299859  ...   \n",
       "1                         0.362288                        0.483374  ...   \n",
       "2                         0.164182                        0.283623  ...   \n",
       "3                         0.277203                        0.385212  ...   \n",
       "4                         0.183156                        0.326380  ...   \n",
       "...                            ...                             ...  ...   \n",
       "1739                      0.243114                        0.343265  ...   \n",
       "1740                      0.218863                        0.283298  ...   \n",
       "1741                      0.095981                        0.334333  ...   \n",
       "1742                      0.279791                        0.190968  ...   \n",
       "1743                      0.197996                        0.275618  ...   \n",
       "\n",
       "      slopeUV0-500_sma3nz_amean  slopeUV500-1500_sma3nz_amean  \\\n",
       "0                      0.351559                      0.600638   \n",
       "1                      0.126664                      0.581319   \n",
       "2                      0.273067                      0.606355   \n",
       "3                      0.573717                      0.384170   \n",
       "4                      0.264243                      0.575046   \n",
       "...                         ...                           ...   \n",
       "1739                   0.407510                      0.426452   \n",
       "1740                   0.409826                      0.439188   \n",
       "1741                   0.321734                      0.510924   \n",
       "1742                   0.384083                      0.506933   \n",
       "1743                   0.332454                      0.604519   \n",
       "\n",
       "      spectralFluxUV_sma3nz_amean  loudnessPeaksPerSec  VoicedSegmentsPerSec  \\\n",
       "0                        0.181705             0.264131              0.049256   \n",
       "1                        0.212856             0.206415              0.329843   \n",
       "2                        0.358312             0.349895              0.314678   \n",
       "3                        0.228007             0.256759              0.041739   \n",
       "4                        0.362308             0.520714              0.060622   \n",
       "...                           ...                  ...                   ...   \n",
       "1739                     0.245619             0.619651              0.170727   \n",
       "1740                     0.155033             0.513858              0.144237   \n",
       "1741                     0.180579             0.506302              0.497215   \n",
       "1742                     0.183881             0.370283              0.413529   \n",
       "1743                     0.181125             0.501264              0.493198   \n",
       "\n",
       "      MeanVoicedSegmentLengthSec  StddevVoicedSegmentLengthSec  \\\n",
       "0                       0.069750                      0.164484   \n",
       "1                       0.008219                      0.024446   \n",
       "2                       0.009789                      0.018589   \n",
       "3                       0.081478                      0.149317   \n",
       "4                       0.057195                      0.142060   \n",
       "...                          ...                           ...   \n",
       "1739                    0.020034                      0.048555   \n",
       "1740                    0.023835                      0.051010   \n",
       "1741                    0.005271                      0.021518   \n",
       "1742                    0.007011                      0.014129   \n",
       "1743                    0.004996                      0.014090   \n",
       "\n",
       "      MeanUnvoicedSegmentLength  StddevUnvoicedSegmentLength  \\\n",
       "0                      0.027513                     0.014235   \n",
       "1                      0.077423                     0.056789   \n",
       "2                      0.040617                     0.018047   \n",
       "3                      0.028571                     0.018206   \n",
       "4                      0.030864                     0.021297   \n",
       "...                         ...                          ...   \n",
       "1739                   0.024143                     0.009844   \n",
       "1740                   0.032222                     0.021974   \n",
       "1741                   0.045299                     0.023471   \n",
       "1742                   0.038426                     0.021311   \n",
       "1743                   0.055489                     0.032671   \n",
       "\n",
       "      equivalentSoundLevel_dBp  \n",
       "0                     0.594429  \n",
       "1                     0.639348  \n",
       "2                     0.741370  \n",
       "3                     0.682132  \n",
       "4                     0.819566  \n",
       "...                        ...  \n",
       "1739                  0.640006  \n",
       "1740                  0.516482  \n",
       "1741                  0.599258  \n",
       "1742                  0.557897  \n",
       "1743                  0.600906  \n",
       "\n",
       "[1744 rows x 4601 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = df_essentia_all_opensmile_egemaps_features.drop('song_id', axis=1)\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>valence_mean_mapped</th>\n",
       "      <th>arousal_mean_mapped</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.475</td>\n",
       "      <td>-0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.375</td>\n",
       "      <td>-0.425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.175</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.150</td>\n",
       "      <td>0.075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.200</td>\n",
       "      <td>0.350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1739</th>\n",
       "      <td>-0.275</td>\n",
       "      <td>0.225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1740</th>\n",
       "      <td>0.075</td>\n",
       "      <td>-0.275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1741</th>\n",
       "      <td>0.350</td>\n",
       "      <td>0.300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1742</th>\n",
       "      <td>-0.100</td>\n",
       "      <td>0.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1743</th>\n",
       "      <td>0.200</td>\n",
       "      <td>0.250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1744 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      valence_mean_mapped  arousal_mean_mapped\n",
       "0                  -0.475               -0.500\n",
       "1                  -0.375               -0.425\n",
       "2                   0.175                0.125\n",
       "3                  -0.150                0.075\n",
       "4                   0.200                0.350\n",
       "...                   ...                  ...\n",
       "1739               -0.275                0.225\n",
       "1740                0.075               -0.275\n",
       "1741                0.350                0.300\n",
       "1742               -0.100                0.100\n",
       "1743                0.200                0.250\n",
       "\n",
       "[1744 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets = df_annotations.drop('song_id', axis=1)\n",
    "targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform 80-20 train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, targets, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create tensors for X_train and X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float64)\n",
    "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create tensors for Y_train and Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float64)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define neural network parameters and instantitate neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 1\n",
    "hidden_size = 20 \n",
    "output_size = 2  # Output size for valence and arousal\n",
    "learning_rate = 0.001\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 137"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set a random seed to ensure consistent initial weights of the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x113933e50>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the seed\n",
    "seed = 42\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_size, math.ceil((input_size**0.5) * 2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(math.ceil((input_size**0.5) * 2), math.ceil((input_size**0.5) * 2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(math.ceil((input_size**0.5) * 2), math.ceil((input_size**0.5) * 2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(math.ceil((input_size**0.5) * 2), math.ceil((input_size**0.5) * 2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(math.ceil((input_size**0.5) * 2), math.ceil((input_size**0.5) * 2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(math.ceil((input_size**0.5) * 2), math.ceil((input_size**0.5) * 2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(math.ceil((input_size**0.5) * 2), math.ceil((input_size**0.5) * 2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(math.ceil((input_size**0.5) * 2), math.ceil((input_size**0.5) * 2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(math.ceil((input_size**0.5) * 2), math.ceil((input_size**0.5) * 2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(math.ceil((input_size**0.5) * 2), math.ceil((input_size**0.5) * 2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(math.ceil((input_size**0.5) * 2), math.ceil((input_size**0.5) * 2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(math.ceil((input_size**0.5) * 2), 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare input_train_data and target_train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1395, 4601])\n"
     ]
    }
   ],
   "source": [
    "input_train_data = X_train_tensor.float()\n",
    "\n",
    "# input_train_data = input_train_data.view(input_train_data.shape[1], -1)\n",
    "print(input_train_data.shape)\n",
    "\n",
    "target_train_labels = y_train_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(num_epochs):\n",
    "  model = NeuralNetwork(input_size=input_train_data.shape[1])\n",
    "  optimiser = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "  \n",
    "  for epoch in range(num_epochs):\n",
    "    optimiser.zero_grad()\n",
    "    \n",
    "    # forward pass\n",
    "    output = model(input_train_data)\n",
    "\n",
    "    # calculate loss\n",
    "    loss = torch.sqrt(criterion(output.float(), target_train_labels.float()))\n",
    "\n",
    "    # backward pass\n",
    "    loss.backward()\n",
    "    # update weights\n",
    "    optimiser.step()\n",
    "\n",
    "    print(f'Epoch {epoch + 1}, Loss: {math.sqrt(loss.item())}')\n",
    "\n",
    "  print(\"Training completed.\")\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Training completed.\n"
     ]
    }
   ],
   "source": [
    "model = train_model(num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare input_test_data and target_test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([349, 4601])\n"
     ]
    }
   ],
   "source": [
    "input_test_data = X_test_tensor.float()\n",
    "\n",
    "# input_test_data = input_test_data.view(input_test_data.shape[1], -1)\n",
    "print(input_test_data.shape)\n",
    "\n",
    "target_test_labels = y_test_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(trained_model):\n",
    "  with torch.no_grad():\n",
    "    test_pred = trained_model(input_test_data)\n",
    "    test_loss = criterion(test_pred.float(), target_test_labels)\n",
    "\n",
    "    # Separate the output into valence and arousal\n",
    "    valence_pred = test_pred[:, 0]\n",
    "    arousal_pred = test_pred[:, 1]\n",
    "        \n",
    "    valence_target = target_test_labels[:, 0]\n",
    "    arousal_target = target_test_labels[:, 1]\n",
    "\n",
    "     # Calculate RMSE for valence and arousal separately\n",
    "    valence_rmse = math.sqrt(mean_squared_error(valence_pred, valence_target))\n",
    "    arousal_rmse = math.sqrt(mean_squared_error(arousal_pred, arousal_target))\n",
    "\n",
    "  rmse = math.sqrt(test_loss.item())\n",
    "  print(f'Test RMSE: {rmse}')\n",
    "\n",
    "  print(f'Valence RMSE: {valence_rmse}')\n",
    "  print(f'Arousal RMSE: {arousal_rmse}')\n",
    "\n",
    "  metric = R2Score(multioutput=\"raw_values\")\n",
    "  metric.update(test_pred, target_test_labels)\n",
    "  adjusted_r2_score = metric.compute()\n",
    "  print(f'Test R^2 score: {adjusted_r2_score}')\n",
    "\n",
    "  # metric = R2Score(multioutput=\"raw_values\", num_regressors=input_test_data.shape[1])\n",
    "  # metric.update(test_pred, target_test_labels)\n",
    "  # adjusted_r2_score = metric.compute()\n",
    "  # print(f'Test Adjusted R^2 score: {adjusted_r2_score}')\n",
    "\n",
    "  metric = R2Score()\n",
    "  metric.update(test_pred, target_test_labels)\n",
    "  r2_score = metric.compute()\n",
    "  print(f'Test R^2 score (overall): {r2_score}')\n",
    "  return test_pred, rmse, adjusted_r2_score, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.21112116739526332\n",
      "Valence RMSE: 0.197782721122043\n",
      "Arousal RMSE: 0.22366557596160783\n",
      "Test R^2 score: tensor([0.5259, 0.5047], dtype=torch.float64)\n",
      "Test R^2 score (overall): 0.5152923686522382\n"
     ]
    }
   ],
   "source": [
    "test_pred, rmse, adjusted_r2_score, r2_score = test_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), '../../models/deam_feedforward_nn_essentia_all_opensmile_egemaps_normalised.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "True values (test set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1500, -0.1500],\n",
       "        [-0.3000, -0.1000],\n",
       "        [ 0.2000,  0.3500],\n",
       "        [ 0.2250,  0.4500],\n",
       "        [-0.1750, -0.2000],\n",
       "        [-0.5250, -0.3000],\n",
       "        [-0.2500, -0.7750],\n",
       "        [ 0.3000,  0.3000],\n",
       "        [-0.1750, -0.4000],\n",
       "        [ 0.4500,  0.1500],\n",
       "        [ 0.1750,  0.0250],\n",
       "        [-0.1750, -0.0250],\n",
       "        [-0.0500, -0.3000],\n",
       "        [ 0.1250,  0.3000],\n",
       "        [-0.0750, -0.1500],\n",
       "        [-0.2000, -0.2750],\n",
       "        [-0.6000, -0.2250],\n",
       "        [ 0.1500, -0.2000],\n",
       "        [ 0.2750,  0.6000],\n",
       "        [-0.1500, -0.4500],\n",
       "        [-0.2250, -0.6250],\n",
       "        [-0.0250, -0.4500],\n",
       "        [-0.5250, -0.1250],\n",
       "        [ 0.0000,  0.3250],\n",
       "        [ 0.1250,  0.3750],\n",
       "        [ 0.1500, -0.2500],\n",
       "        [ 0.4500,  0.3250],\n",
       "        [ 0.2500,  0.2250],\n",
       "        [-0.1000,  0.0750],\n",
       "        [ 0.4250,  0.1250],\n",
       "        [-0.4500, -0.3500],\n",
       "        [-0.0500,  0.3750],\n",
       "        [-0.4750, -0.2000],\n",
       "        [-0.2750, -0.4000],\n",
       "        [-0.4000, -0.2250],\n",
       "        [ 0.1000, -0.4500],\n",
       "        [-0.2250, -0.6750],\n",
       "        [ 0.3000,  0.1250],\n",
       "        [-0.2000, -0.2250],\n",
       "        [ 0.2500,  0.3750],\n",
       "        [-0.3250, -0.4750],\n",
       "        [ 0.2250,  0.2000],\n",
       "        [ 0.0500,  0.1250],\n",
       "        [-0.5750, -0.6000],\n",
       "        [-0.1250, -0.3500],\n",
       "        [ 0.5000,  0.6000],\n",
       "        [-0.1500,  0.3250],\n",
       "        [-0.1750,  0.0250],\n",
       "        [-0.2750, -0.3250],\n",
       "        [ 0.2500,  0.3500],\n",
       "        [-0.3250, -0.7500],\n",
       "        [ 0.3000,  0.4000],\n",
       "        [ 0.0250,  0.2000],\n",
       "        [ 0.3750,  0.2250],\n",
       "        [-0.4250, -0.3750],\n",
       "        [-0.4250, -0.2500],\n",
       "        [-0.5250, -0.1750],\n",
       "        [-0.0500, -0.1500],\n",
       "        [ 0.1250, -0.1000],\n",
       "        [-0.3250, -0.5000],\n",
       "        [-0.4000, -0.0750],\n",
       "        [ 0.1500, -0.0500],\n",
       "        [-0.3000, -0.6500],\n",
       "        [-0.7000, -0.3750],\n",
       "        [ 0.5500,  0.2500],\n",
       "        [-0.2000, -0.1500],\n",
       "        [ 0.0750,  0.0750],\n",
       "        [-0.3000, -0.4000],\n",
       "        [-0.4250, -0.3750],\n",
       "        [-0.5750, -0.1000],\n",
       "        [ 0.2750, -0.1250],\n",
       "        [-0.1750, -0.2000],\n",
       "        [-0.2750, -0.6250],\n",
       "        [-0.4750, -0.3750],\n",
       "        [ 0.2750,  0.1250],\n",
       "        [ 0.3250,  0.4250],\n",
       "        [-0.3000, -0.1500],\n",
       "        [ 0.0500,  0.0750],\n",
       "        [ 0.2750, -0.2500],\n",
       "        [-0.3000, -0.6500],\n",
       "        [-0.3000,  0.2250],\n",
       "        [-0.4000, -0.0500],\n",
       "        [-0.0250, -0.3500],\n",
       "        [ 0.0000, -0.0500],\n",
       "        [-0.3000, -0.1000],\n",
       "        [ 0.3500, -0.3750],\n",
       "        [ 0.0250,  0.2000],\n",
       "        [-0.2500, -0.2250],\n",
       "        [ 0.0000, -0.3250],\n",
       "        [ 0.1500,  0.0000],\n",
       "        [-0.3500, -0.4750],\n",
       "        [-0.1750, -0.1250],\n",
       "        [-0.6750, -0.6000],\n",
       "        [ 0.2500,  0.2750],\n",
       "        [-0.3000, -0.5750],\n",
       "        [-0.1750, -0.5250],\n",
       "        [ 0.2750,  0.3250],\n",
       "        [ 0.3250, -0.1000],\n",
       "        [ 0.1000,  0.1750],\n",
       "        [-0.0750,  0.2000],\n",
       "        [ 0.2250, -0.3250],\n",
       "        [ 0.3750,  0.5500],\n",
       "        [-0.5250, -0.2500],\n",
       "        [-0.1000,  0.1500],\n",
       "        [ 0.1250,  0.1000],\n",
       "        [-0.3750, -0.3250],\n",
       "        [-0.4750, -0.3500],\n",
       "        [-0.2750, -0.2750],\n",
       "        [-0.2000, -0.0750],\n",
       "        [ 0.2750,  0.6000],\n",
       "        [-0.0500, -0.2500],\n",
       "        [-0.0500,  0.2500],\n",
       "        [-0.4750, -0.2000],\n",
       "        [-0.0250,  0.2000],\n",
       "        [-0.0750,  0.1500],\n",
       "        [ 0.6000,  0.6500],\n",
       "        [ 0.3250,  0.1500],\n",
       "        [-0.3500,  0.0000],\n",
       "        [ 0.2500,  0.2000],\n",
       "        [-0.1500,  0.3750],\n",
       "        [ 0.2250,  0.1000],\n",
       "        [ 0.2750, -0.4250],\n",
       "        [-0.0750,  0.6250],\n",
       "        [-0.1750, -0.3000],\n",
       "        [-0.0750, -0.6500],\n",
       "        [-0.1250,  0.1000],\n",
       "        [ 0.0000, -0.0250],\n",
       "        [ 0.0500,  0.0500],\n",
       "        [-0.1000,  0.0250],\n",
       "        [ 0.2000, -0.0750],\n",
       "        [-0.2750,  0.2250],\n",
       "        [-0.3750,  0.1250],\n",
       "        [-0.0750,  0.0500],\n",
       "        [ 0.3000,  0.0000],\n",
       "        [ 0.2000,  0.3000],\n",
       "        [ 0.3500,  0.1000],\n",
       "        [ 0.5750,  0.6000],\n",
       "        [-0.2750,  0.1250],\n",
       "        [ 0.0750, -0.3500],\n",
       "        [-0.0750, -0.3750],\n",
       "        [ 0.3750,  0.1000],\n",
       "        [ 0.0500, -0.0750],\n",
       "        [-0.4000, -0.0500],\n",
       "        [-0.1750, -0.2750],\n",
       "        [ 0.2000, -0.1750],\n",
       "        [ 0.2750,  0.1000],\n",
       "        [-0.0500, -0.2750],\n",
       "        [-0.3000, -0.4000],\n",
       "        [-0.1250, -0.0500],\n",
       "        [ 0.0250, -0.3500],\n",
       "        [-0.2000, -0.8500],\n",
       "        [ 0.1500,  0.0250],\n",
       "        [ 0.2250, -0.4000],\n",
       "        [-0.1250, -0.2000],\n",
       "        [ 0.3500,  0.1000],\n",
       "        [-0.2000,  0.0000],\n",
       "        [ 0.0250, -0.3500],\n",
       "        [-0.2250,  0.0000],\n",
       "        [-0.0750,  0.1250],\n",
       "        [-0.1000,  0.2000],\n",
       "        [-0.2500, -0.6000],\n",
       "        [ 0.2250,  0.1000],\n",
       "        [ 0.0250,  0.4250],\n",
       "        [-0.2250, -0.2500],\n",
       "        [ 0.1750,  0.3000],\n",
       "        [-0.1500,  0.0500],\n",
       "        [-0.3500, -0.0500],\n",
       "        [-0.4000,  0.2250],\n",
       "        [-0.1000,  0.1500],\n",
       "        [ 0.0000, -0.4750],\n",
       "        [-0.1500, -0.4500],\n",
       "        [ 0.1500,  0.2250],\n",
       "        [ 0.2250,  0.0750],\n",
       "        [ 0.3500,  0.0750],\n",
       "        [ 0.5250,  0.3750],\n",
       "        [ 0.2500,  0.2000],\n",
       "        [ 0.3500,  0.2000],\n",
       "        [-0.0250, -0.3000],\n",
       "        [-0.4000,  0.0750],\n",
       "        [-0.1500,  0.4750],\n",
       "        [-0.4750, -0.6750],\n",
       "        [-0.0750, -0.1750],\n",
       "        [-0.5250, -0.3750],\n",
       "        [ 0.2750, -0.2750],\n",
       "        [ 0.6000,  0.4000],\n",
       "        [-0.4250, -0.5500],\n",
       "        [-0.1500, -0.5750],\n",
       "        [ 0.2250,  0.4500],\n",
       "        [ 0.6500,  0.7000],\n",
       "        [ 0.1750,  0.3250],\n",
       "        [-0.2750, -0.1250],\n",
       "        [-0.2500, -0.4000],\n",
       "        [-0.0250, -0.1250],\n",
       "        [-0.0250, -0.2500],\n",
       "        [-0.1500, -0.3750],\n",
       "        [ 0.3500,  0.4000],\n",
       "        [ 0.5750, -0.4250],\n",
       "        [-0.0750,  0.0750],\n",
       "        [-0.0500, -0.1250],\n",
       "        [ 0.0750,  0.2000],\n",
       "        [-0.1500, -0.0500],\n",
       "        [-0.1500, -0.3000],\n",
       "        [-0.0500,  0.2500],\n",
       "        [-0.3000, -0.4250],\n",
       "        [-0.3000, -0.3500],\n",
       "        [-0.4000, -0.1000],\n",
       "        [-0.1500, -0.5750],\n",
       "        [-0.0750, -0.3750],\n",
       "        [-0.3500, -0.3500],\n",
       "        [ 0.2250,  0.2250],\n",
       "        [ 0.1250,  0.0000],\n",
       "        [-0.1750, -0.2000],\n",
       "        [-0.0750, -0.3000],\n",
       "        [ 0.5000,  0.4000],\n",
       "        [-0.2000, -0.2250],\n",
       "        [-0.2000, -0.4750],\n",
       "        [ 0.3000,  0.1750],\n",
       "        [ 0.1250,  0.0000],\n",
       "        [ 0.1750,  0.4750],\n",
       "        [ 0.1750, -0.2500],\n",
       "        [-0.1250,  0.4250],\n",
       "        [ 0.2000,  0.4750],\n",
       "        [-0.3000, -0.4000],\n",
       "        [-0.1250, -0.5250],\n",
       "        [-0.5750, -0.0750],\n",
       "        [ 0.1750, -0.0250],\n",
       "        [ 0.4000,  0.3500],\n",
       "        [-0.2500,  0.0000],\n",
       "        [-0.4750, -0.3000],\n",
       "        [ 0.1250,  0.2750],\n",
       "        [ 0.0750,  0.1750],\n",
       "        [ 0.3750,  0.1500],\n",
       "        [-0.1750, -0.2250],\n",
       "        [ 0.1250,  0.2750],\n",
       "        [-0.4500, -0.3250],\n",
       "        [ 0.3000,  0.0750],\n",
       "        [-0.3000,  0.0250],\n",
       "        [-0.3250, -0.5250],\n",
       "        [-0.1250, -0.0250],\n",
       "        [ 0.1250,  0.2000],\n",
       "        [-0.3750,  0.0500],\n",
       "        [-0.3250, -0.0500],\n",
       "        [ 0.0500,  0.3000],\n",
       "        [-0.5500, -0.3250],\n",
       "        [-0.2750, -0.3000],\n",
       "        [-0.2750, -0.5500],\n",
       "        [-0.1750, -0.5750],\n",
       "        [ 0.4500,  0.3000],\n",
       "        [-0.2500,  0.1250],\n",
       "        [-0.1000, -0.3250],\n",
       "        [ 0.1250,  0.2250],\n",
       "        [ 0.4750,  0.2750],\n",
       "        [-0.2250, -0.0250],\n",
       "        [ 0.3750,  0.3500],\n",
       "        [ 0.0000,  0.1750],\n",
       "        [-0.4250, -0.1000],\n",
       "        [ 0.1000, -0.1000],\n",
       "        [ 0.2000,  0.1500],\n",
       "        [ 0.1250,  0.0250],\n",
       "        [-0.2500,  0.1750],\n",
       "        [-0.3250, -0.6500],\n",
       "        [-0.0750, -0.3000],\n",
       "        [ 0.0750, -0.1500],\n",
       "        [ 0.5250,  0.5250],\n",
       "        [-0.0750,  0.2250],\n",
       "        [-0.1750,  0.0000],\n",
       "        [ 0.3000, -0.0500],\n",
       "        [-0.3500, -0.4000],\n",
       "        [-0.2250, -0.2000],\n",
       "        [ 0.4750,  0.5500],\n",
       "        [ 0.1000, -0.4750],\n",
       "        [-0.1250,  0.0000],\n",
       "        [-0.3000,  0.0000],\n",
       "        [-0.2750, -0.4500],\n",
       "        [-0.1500, -0.3000],\n",
       "        [ 0.1500, -0.1250],\n",
       "        [ 0.0500, -0.1250],\n",
       "        [ 0.0750,  0.1750],\n",
       "        [-0.1250, -0.1250],\n",
       "        [ 0.5750,  0.2500],\n",
       "        [-0.3750, -0.0500],\n",
       "        [ 0.2250,  0.1000],\n",
       "        [ 0.3250, -0.2000],\n",
       "        [ 0.4750,  0.4500],\n",
       "        [-0.1750, -0.4000],\n",
       "        [ 0.3500,  0.3750],\n",
       "        [-0.4000,  0.1250],\n",
       "        [-0.1500, -0.2750],\n",
       "        [ 0.5750, -0.3750],\n",
       "        [-0.2500,  0.2000],\n",
       "        [ 0.0000,  0.1500],\n",
       "        [ 0.4500, -0.1250],\n",
       "        [-0.1000, -0.0250],\n",
       "        [ 0.1500,  0.0750],\n",
       "        [ 0.2000, -0.1000],\n",
       "        [ 0.0500,  0.0250],\n",
       "        [ 0.3500,  0.4250],\n",
       "        [-0.3500, -0.5500],\n",
       "        [-0.4250, -0.6000],\n",
       "        [ 0.1750,  0.5500],\n",
       "        [ 0.2000,  0.0250],\n",
       "        [-0.2250, -0.1250],\n",
       "        [ 0.2500,  0.1750],\n",
       "        [-0.3750, -0.0500],\n",
       "        [-0.4750, -0.4500],\n",
       "        [-0.3250, -0.5500],\n",
       "        [-0.1250,  0.1750],\n",
       "        [-0.2500, -0.0500],\n",
       "        [ 0.0000,  0.1250],\n",
       "        [-0.6250, -0.1500],\n",
       "        [-0.4250, -0.5500],\n",
       "        [ 0.0250, -0.2000],\n",
       "        [ 0.3250,  0.3750],\n",
       "        [ 0.1750,  0.1500],\n",
       "        [-0.1750, -0.6500],\n",
       "        [ 0.0750,  0.4250],\n",
       "        [-0.4500, -0.3750],\n",
       "        [-0.1250, -0.1750],\n",
       "        [ 0.0500, -0.3000],\n",
       "        [-0.0500,  0.3750],\n",
       "        [-0.2750,  0.0500],\n",
       "        [-0.4750, -0.3250],\n",
       "        [ 0.0000, -0.3000],\n",
       "        [ 0.3750, -0.1000],\n",
       "        [ 0.1750,  0.1000],\n",
       "        [-0.2250, -0.5500],\n",
       "        [ 0.1500,  0.2250],\n",
       "        [-0.6250, -0.5750],\n",
       "        [ 0.0750, -0.2750],\n",
       "        [ 0.3500,  0.6250],\n",
       "        [-0.0500,  0.2500],\n",
       "        [ 0.0750,  0.3500],\n",
       "        [ 0.2000, -0.3000],\n",
       "        [ 0.2000, -0.1500],\n",
       "        [-0.0250, -0.1500],\n",
       "        [-0.3000, -0.1000],\n",
       "        [-0.1250,  0.1000],\n",
       "        [-0.6750, -0.6250],\n",
       "        [-0.0750, -0.1250],\n",
       "        [ 0.2750,  0.2000],\n",
       "        [ 0.0250,  0.0500],\n",
       "        [-0.4750, -0.1500],\n",
       "        [-0.1500, -0.0500],\n",
       "        [ 0.2000,  0.0250],\n",
       "        [-0.1750,  0.1750],\n",
       "        [ 0.2750,  0.2250],\n",
       "        [ 0.2500,  0.2500],\n",
       "        [-0.1750, -0.2250],\n",
       "        [-0.5750, -0.7000]], dtype=torch.float64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.1251e-01,  1.1965e-01],\n",
       "        [-2.6359e-01, -3.3029e-01],\n",
       "        [ 1.5169e-01,  1.4880e-01],\n",
       "        [ 1.5888e-01,  1.5344e-01],\n",
       "        [-1.0908e-01, -1.4203e-01],\n",
       "        [-2.9090e-01, -3.6469e-01],\n",
       "        [-4.6414e-01, -5.8547e-01],\n",
       "        [ 1.5880e-01,  1.5339e-01],\n",
       "        [-3.2098e-01, -4.0302e-01],\n",
       "        [ 1.6056e-01,  1.5441e-01],\n",
       "        [ 1.5392e-01,  1.5023e-01],\n",
       "        [-1.7891e-01, -2.2407e-01],\n",
       "        [-4.0625e-01, -5.1168e-01],\n",
       "        [ 1.5809e-01,  1.5299e-01],\n",
       "        [-2.1414e-02, -3.8488e-02],\n",
       "        [-2.5645e-02, -4.3521e-02],\n",
       "        [-3.9858e-01, -5.0193e-01],\n",
       "        [-1.5185e-01, -1.9181e-01],\n",
       "        [ 1.5707e-01,  1.5236e-01],\n",
       "        [-3.3592e-01, -4.2207e-01],\n",
       "        [-4.8604e-01, -6.1336e-01],\n",
       "        [-2.6872e-01, -3.3676e-01],\n",
       "        [-2.3645e-01, -2.9609e-01],\n",
       "        [ 1.5495e-01,  1.5085e-01],\n",
       "        [ 1.6138e-01,  1.5488e-01],\n",
       "        [-1.2912e-01, -1.6534e-01],\n",
       "        [ 1.6033e-01,  1.5429e-01],\n",
       "        [ 1.3978e-01,  1.4102e-01],\n",
       "        [ 1.5807e-01,  1.5297e-01],\n",
       "        [ 1.5658e-01,  1.5201e-01],\n",
       "        [-4.8616e-01, -6.1352e-01],\n",
       "        [-2.2376e-02, -3.9633e-02],\n",
       "        [-1.0391e-01, -1.3601e-01],\n",
       "        [-1.2644e-01, -1.6223e-01],\n",
       "        [-3.2258e-01, -4.0506e-01],\n",
       "        [-1.7089e-01, -2.1438e-01],\n",
       "        [-5.0697e-01, -6.4006e-01],\n",
       "        [ 1.5791e-01,  1.5289e-01],\n",
       "        [ 1.5153e-02,  4.8071e-03],\n",
       "        [ 3.4137e-03, -9.6806e-03],\n",
       "        [-2.8785e-01, -3.6085e-01],\n",
       "        [ 5.4188e-02,  5.2592e-02],\n",
       "        [ 4.8892e-02,  4.6287e-02],\n",
       "        [-2.8599e-01, -3.5849e-01],\n",
       "        [-1.3172e-01, -1.6837e-01],\n",
       "        [ 1.5980e-01,  1.5397e-01],\n",
       "        [ 1.5853e-01,  1.5324e-01],\n",
       "        [ 7.4294e-02,  7.6234e-02],\n",
       "        [-2.1095e-01, -2.6411e-01],\n",
       "        [ 1.5557e-01,  1.5129e-01],\n",
       "        [-3.7263e-01, -4.6887e-01],\n",
       "        [ 1.5478e-01,  1.5074e-01],\n",
       "        [-5.6491e-02, -8.0182e-02],\n",
       "        [ 1.6030e-01,  1.5427e-01],\n",
       "        [-6.3749e-04, -1.4405e-02],\n",
       "        [-6.6622e-02, -9.2243e-02],\n",
       "        [-3.5988e-01, -4.5263e-01],\n",
       "        [-2.8558e-02, -4.6969e-02],\n",
       "        [ 7.8151e-02,  8.0663e-02],\n",
       "        [-3.1644e-01, -3.9723e-01],\n",
       "        [-2.1866e-01, -2.7377e-01],\n",
       "        [ 1.4972e-01,  1.4753e-01],\n",
       "        [-4.5969e-01, -5.7981e-01],\n",
       "        [-3.5949e-01, -4.5212e-01],\n",
       "        [ 1.5224e-01,  1.4915e-01],\n",
       "        [-1.2176e-01, -1.5679e-01],\n",
       "        [ 1.5267e-01,  1.4943e-01],\n",
       "        [-2.0863e-01, -2.6120e-01],\n",
       "        [ 1.4804e-01,  1.4645e-01],\n",
       "        [-3.6318e-01, -4.5682e-01],\n",
       "        [-1.6366e-01, -2.0569e-01],\n",
       "        [-1.8160e-01, -2.2739e-01],\n",
       "        [-4.7596e-01, -6.0053e-01],\n",
       "        [-2.9348e-01, -3.6794e-01],\n",
       "        [ 1.4422e-01,  1.4429e-01],\n",
       "        [ 1.5667e-01,  1.5208e-01],\n",
       "        [-2.2770e-01, -2.8511e-01],\n",
       "        [ 6.5140e-02,  6.5470e-02],\n",
       "        [-1.5567e-01, -1.9624e-01],\n",
       "        [-3.0517e-01, -3.8284e-01],\n",
       "        [-9.6372e-02, -1.2724e-01],\n",
       "        [-1.0291e-01, -1.3484e-01],\n",
       "        [ 1.4403e-01,  1.4414e-01],\n",
       "        [ 1.5103e-01,  1.4837e-01],\n",
       "        [-4.4339e-02, -6.5719e-02],\n",
       "        [ 1.5150e-01,  1.4867e-01],\n",
       "        [ 1.6100e-01,  1.5465e-01],\n",
       "        [-1.1971e-02, -2.7528e-02],\n",
       "        [-1.1790e-01, -1.5229e-01],\n",
       "        [ 1.5102e-01,  1.4835e-01],\n",
       "        [-5.4085e-01, -6.8324e-01],\n",
       "        [ 1.5364e-01,  1.5006e-01],\n",
       "        [-4.2579e-01, -5.3659e-01],\n",
       "        [ 1.4388e-01,  1.4409e-01],\n",
       "        [-4.4607e-01, -5.6244e-01],\n",
       "        [-2.4567e-01, -3.0770e-01],\n",
       "        [ 3.9471e-02,  3.4791e-02],\n",
       "        [-1.0980e-01, -1.4287e-01],\n",
       "        [ 3.7955e-02,  3.2933e-02],\n",
       "        [ 6.7927e-02,  6.8769e-02],\n",
       "        [ 1.5550e-01,  1.5124e-01],\n",
       "        [ 1.5209e-01,  1.4906e-01],\n",
       "        [-3.1703e-01, -3.9801e-01],\n",
       "        [ 1.5523e-01,  1.5104e-01],\n",
       "        [-4.2860e-02, -6.3957e-02],\n",
       "        [-2.2093e-01, -2.7659e-01],\n",
       "        [-1.4764e-01, -1.8693e-01],\n",
       "        [-2.6595e-01, -3.3326e-01],\n",
       "        [-2.7654e-01, -3.4660e-01],\n",
       "        [ 1.5773e-01,  1.5279e-01],\n",
       "        [-3.4536e-02, -5.4055e-02],\n",
       "        [ 1.5153e-01,  1.4868e-01],\n",
       "        [-3.6540e-01, -4.5967e-01],\n",
       "        [ 9.5857e-02,  1.0083e-01],\n",
       "        [ 1.2767e-01,  1.3225e-01],\n",
       "        [ 1.6039e-01,  1.5432e-01],\n",
       "        [ 4.6499e-02,  4.3437e-02],\n",
       "        [-1.0203e-01, -1.3380e-01],\n",
       "        [ 1.5628e-01,  1.5181e-01],\n",
       "        [ 1.5834e-01,  1.5313e-01],\n",
       "        [ 1.5402e-01,  1.5029e-01],\n",
       "        [ 1.1489e-01,  1.2192e-01],\n",
       "        [ 1.6024e-01,  1.5423e-01],\n",
       "        [-3.8429e-01, -4.8368e-01],\n",
       "        [-2.7725e-01, -3.4747e-01],\n",
       "        [ 1.5644e-01,  1.5192e-01],\n",
       "        [ 1.5558e-01,  1.5130e-01],\n",
       "        [ 1.5849e-01,  1.5322e-01],\n",
       "        [ 1.6041e-01,  1.5433e-01],\n",
       "        [ 1.5675e-01,  1.5214e-01],\n",
       "        [-9.7280e-02, -1.2828e-01],\n",
       "        [-1.0895e-01, -1.4187e-01],\n",
       "        [ 1.5086e-01,  1.4825e-01],\n",
       "        [ 1.0333e-01,  1.0925e-01],\n",
       "        [ 1.6183e-01,  1.5515e-01],\n",
       "        [-1.3544e-01, -1.7269e-01],\n",
       "        [ 1.5643e-01,  1.5191e-01],\n",
       "        [ 1.5216e-01,  1.4910e-01],\n",
       "        [ 2.1917e-02,  1.3152e-02],\n",
       "        [-1.6103e-01, -2.0252e-01],\n",
       "        [ 1.4050e-02,  3.4901e-03],\n",
       "        [ 1.2417e-01,  1.2970e-01],\n",
       "        [-3.7037e-01, -4.6597e-01],\n",
       "        [-3.8053e-01, -4.7892e-01],\n",
       "        [ 1.5754e-01,  1.5268e-01],\n",
       "        [ 1.5677e-01,  1.5215e-01],\n",
       "        [-2.9716e-02, -4.8342e-02],\n",
       "        [-3.0554e-01, -3.8333e-01],\n",
       "        [ 1.5209e-01,  1.4905e-01],\n",
       "        [ 1.5744e-01,  1.5261e-01],\n",
       "        [ 1.3213e-01,  1.3549e-01],\n",
       "        [ 1.7527e-02,  7.7263e-03],\n",
       "        [-1.4395e-01, -1.8261e-01],\n",
       "        [-5.2508e-02, -7.5435e-02],\n",
       "        [ 6.6880e-02,  6.7541e-02],\n",
       "        [-1.3029e-01, -1.6673e-01],\n",
       "        [-2.7667e-01, -3.4675e-01],\n",
       "        [-1.3506e-01, -1.7225e-01],\n",
       "        [ 6.3364e-02,  6.3403e-02],\n",
       "        [-1.3987e-01, -1.7787e-01],\n",
       "        [-4.3268e-01, -5.4537e-01],\n",
       "        [ 7.0022e-02,  7.1195e-02],\n",
       "        [ 1.5631e-01,  1.5183e-01],\n",
       "        [-1.0752e-01, -1.4021e-01],\n",
       "        [ 1.4568e-01,  1.4509e-01],\n",
       "        [-2.0443e-01, -2.5594e-01],\n",
       "        [-4.1443e-01, -5.2212e-01],\n",
       "        [ 1.5866e-01,  1.5332e-01],\n",
       "        [-8.4673e-03, -2.3479e-02],\n",
       "        [-2.2549e-01, -2.8231e-01],\n",
       "        [-4.5334e-01, -5.7172e-01],\n",
       "        [ 1.5605e-01,  1.5164e-01],\n",
       "        [ 1.5514e-01,  1.5098e-01],\n",
       "        [ 1.3704e-01,  1.3904e-01],\n",
       "        [ 1.5475e-01,  1.5073e-01],\n",
       "        [ 1.4481e-01,  1.4454e-01],\n",
       "        [ 1.5270e-01,  1.4945e-01],\n",
       "        [ 1.6071e-01,  1.5448e-01],\n",
       "        [-1.8998e-01, -2.3782e-01],\n",
       "        [ 1.6045e-01,  1.5435e-01],\n",
       "        [-3.4198e-01, -4.2980e-01],\n",
       "        [-1.7384e-01, -2.1795e-01],\n",
       "        [-3.2085e-01, -4.0286e-01],\n",
       "        [ 3.1253e-02,  2.4657e-02],\n",
       "        [ 1.6134e-01,  1.5486e-01],\n",
       "        [-3.5984e-01, -4.5255e-01],\n",
       "        [-3.1743e-01, -3.9851e-01],\n",
       "        [ 1.6028e-01,  1.5426e-01],\n",
       "        [ 1.5852e-01,  1.5324e-01],\n",
       "        [ 1.5879e-01,  1.5339e-01],\n",
       "        [-3.5263e-01, -4.4338e-01],\n",
       "        [-2.4365e-01, -3.0515e-01],\n",
       "        [-1.7157e-01, -2.1518e-01],\n",
       "        [-4.8380e-03, -1.9291e-02],\n",
       "        [-2.7633e-01, -3.4631e-01],\n",
       "        [ 1.6168e-01,  1.5506e-01],\n",
       "        [ 1.6037e-01,  1.5431e-01],\n",
       "        [ 1.2034e-02,  9.6244e-04],\n",
       "        [ 1.4127e-01,  1.4232e-01],\n",
       "        [-8.6124e-02, -1.1532e-01],\n",
       "        [-2.5155e-02, -4.2927e-02],\n",
       "        [-6.1784e-02, -8.6477e-02],\n",
       "        [ 1.5637e-01,  1.5187e-01],\n",
       "        [-3.7224e-01, -4.6836e-01],\n",
       "        [-2.3991e-01, -3.0041e-01],\n",
       "        [ 1.5464e-01,  1.5066e-01],\n",
       "        [-4.9432e-01, -6.2394e-01],\n",
       "        [-3.1234e-01, -3.9202e-01],\n",
       "        [-3.2604e-02, -5.1774e-02],\n",
       "        [ 1.5907e-01,  1.5355e-01],\n",
       "        [ 1.6045e-01,  1.5435e-01],\n",
       "        [-1.6145e-01, -2.0303e-01],\n",
       "        [-3.2997e-01, -4.1448e-01],\n",
       "        [ 1.6036e-01,  1.5430e-01],\n",
       "        [-2.7889e-01, -3.4954e-01],\n",
       "        [-3.3443e-02, -5.2771e-02],\n",
       "        [ 1.5640e-01,  1.5189e-01],\n",
       "        [ 1.5207e-01,  1.4904e-01],\n",
       "        [-1.6976e-01, -2.1301e-01],\n",
       "        [ 2.4854e-02,  1.6777e-02],\n",
       "        [ 1.4897e-01,  1.4702e-01],\n",
       "        [-9.0839e-02, -1.2079e-01],\n",
       "        [-2.0894e-01, -2.6158e-01],\n",
       "        [-1.7243e-03, -1.5672e-02],\n",
       "        [-3.4306e-01, -4.3120e-01],\n",
       "        [ 1.5163e-01,  1.4876e-01],\n",
       "        [ 1.5882e-01,  1.5340e-01],\n",
       "        [-1.0640e-01, -1.3889e-01],\n",
       "        [-3.6406e-01, -4.5793e-01],\n",
       "        [ 1.6127e-01,  1.5481e-01],\n",
       "        [ 1.4253e-01,  1.4315e-01],\n",
       "        [ 1.5582e-01,  1.5148e-01],\n",
       "        [-3.4995e-01, -4.3992e-01],\n",
       "        [ 1.5882e-01,  1.5341e-01],\n",
       "        [-1.7024e-01, -2.1360e-01],\n",
       "        [-2.5133e-02, -4.2912e-02],\n",
       "        [ 7.5746e-02,  7.7883e-02],\n",
       "        [-2.8822e-01, -3.6131e-01],\n",
       "        [ 1.3058e-01,  1.3433e-01],\n",
       "        [ 1.3996e-01,  1.4117e-01],\n",
       "        [-3.1485e-01, -3.9521e-01],\n",
       "        [-3.8273e-01, -4.8173e-01],\n",
       "        [ 1.6141e-01,  1.5490e-01],\n",
       "        [-3.6176e-01, -4.5500e-01],\n",
       "        [-2.8761e-01, -3.6054e-01],\n",
       "        [-2.6867e-01, -3.3666e-01],\n",
       "        [ 1.4725e-01,  1.4596e-01],\n",
       "        [ 1.5952e-01,  1.5381e-01],\n",
       "        [-9.6644e-02, -1.2755e-01],\n",
       "        [-1.2845e-01, -1.6457e-01],\n",
       "        [ 7.9801e-02,  8.2487e-02],\n",
       "        [ 1.6211e-01,  1.5531e-01],\n",
       "        [-1.9376e-01, -2.4254e-01],\n",
       "        [ 1.6168e-01,  1.5506e-01],\n",
       "        [ 1.5992e-01,  1.5404e-01],\n",
       "        [-2.6974e-01, -3.3804e-01],\n",
       "        [-1.9316e-01, -2.4180e-01],\n",
       "        [-2.2649e-01, -2.8361e-01],\n",
       "        [ 1.5438e-01,  1.5050e-01],\n",
       "        [ 1.3219e-01,  1.3553e-01],\n",
       "        [-3.1719e-01, -3.9820e-01],\n",
       "        [-2.0749e-01, -2.5976e-01],\n",
       "        [ 1.6067e-01,  1.5446e-01],\n",
       "        [ 1.4619e-01,  1.4532e-01],\n",
       "        [-5.9301e-02, -8.3509e-02],\n",
       "        [ 1.6125e-01,  1.5480e-01],\n",
       "        [-1.8835e-01, -2.3579e-01],\n",
       "        [ 7.5766e-02,  7.7987e-02],\n",
       "        [-2.2639e-01, -2.8347e-01],\n",
       "        [ 1.5952e-01,  1.5381e-01],\n",
       "        [ 9.1813e-03, -2.5418e-03],\n",
       "        [ 1.6311e-02,  6.2403e-03],\n",
       "        [-3.4519e-01, -4.3391e-01],\n",
       "        [-4.6964e-01, -5.9248e-01],\n",
       "        [-2.3358e-01, -2.9250e-01],\n",
       "        [ 5.4797e-02,  5.3313e-02],\n",
       "        [ 1.5896e-01,  1.5348e-01],\n",
       "        [ 1.6156e-01,  1.5499e-01],\n",
       "        [ 2.1456e-02,  1.2585e-02],\n",
       "        [ 1.4618e-01,  1.4528e-01],\n",
       "        [-2.9992e-01, -3.7615e-01],\n",
       "        [ 1.6306e-01,  1.5587e-01],\n",
       "        [ 6.3224e-02,  6.3256e-02],\n",
       "        [ 1.5726e-01,  1.5249e-01],\n",
       "        [-3.4075e-01, -4.2822e-01],\n",
       "        [ 1.6128e-01,  1.5482e-01],\n",
       "        [-2.5766e-01, -3.2284e-01],\n",
       "        [-2.4945e-01, -3.1245e-01],\n",
       "        [ 1.6221e-01,  1.5537e-01],\n",
       "        [ 1.2959e-01,  1.3359e-01],\n",
       "        [ 1.6069e-01,  1.5448e-01],\n",
       "        [ 1.4628e-01,  1.4538e-01],\n",
       "        [ 7.7475e-02,  7.9757e-02],\n",
       "        [ 1.5510e-01,  1.5095e-01],\n",
       "        [ 3.0185e-02,  2.3362e-02],\n",
       "        [-6.3058e-02, -8.7991e-02],\n",
       "        [ 1.5826e-01,  1.5308e-01],\n",
       "        [-5.8415e-01, -7.3841e-01],\n",
       "        [-3.7255e-01, -4.6876e-01],\n",
       "        [ 1.6291e-01,  1.5578e-01],\n",
       "        [ 1.4988e-01,  1.4764e-01],\n",
       "        [-1.5789e-01, -1.9885e-01],\n",
       "        [ 1.3512e-01,  1.3761e-01],\n",
       "        [-1.8910e-01, -2.3672e-01],\n",
       "        [ 9.1392e-02,  9.5895e-02],\n",
       "        [-3.2923e-01, -4.1354e-01],\n",
       "        [-8.2462e-02, -1.1104e-01],\n",
       "        [-1.5454e-01, -1.9496e-01],\n",
       "        [ 1.5829e-01,  1.5310e-01],\n",
       "        [-4.0327e-01, -5.0788e-01],\n",
       "        [-4.6940e-01, -5.9218e-01],\n",
       "        [-2.8814e-02, -4.7277e-02],\n",
       "        [-1.4504e-02, -3.0475e-02],\n",
       "        [ 1.4459e-01,  1.4446e-01],\n",
       "        [-4.0551e-01, -5.1075e-01],\n",
       "        [ 1.5918e-01,  1.5361e-01],\n",
       "        [-3.5838e-01, -4.5069e-01],\n",
       "        [-7.1446e-02, -9.7983e-02],\n",
       "        [-1.0455e-01, -1.3674e-01],\n",
       "        [ 7.3505e-02,  7.5274e-02],\n",
       "        [ 1.6102e-02,  5.9845e-03],\n",
       "        [-2.0209e-01, -2.5299e-01],\n",
       "        [-1.9616e-01, -2.4558e-01],\n",
       "        [ 1.0742e-01,  1.1404e-01],\n",
       "        [ 1.6336e-01,  1.5605e-01],\n",
       "        [-2.5903e-01, -3.2453e-01],\n",
       "        [ 1.6269e-01,  1.5565e-01],\n",
       "        [-2.8715e-01, -3.5996e-01],\n",
       "        [-4.0253e-02, -6.0867e-02],\n",
       "        [ 1.4120e-01,  1.4224e-01],\n",
       "        [-4.2111e-03, -1.8572e-02],\n",
       "        [ 1.5597e-01,  1.5158e-01],\n",
       "        [ 8.2883e-02,  8.6211e-02],\n",
       "        [ 1.5681e-01,  1.5218e-01],\n",
       "        [-1.0325e-01, -1.3522e-01],\n",
       "        [ 2.1102e-03, -1.1203e-02],\n",
       "        [ 1.5853e-01,  1.5324e-01],\n",
       "        [-1.0128e-01, -1.3293e-01],\n",
       "        [ 1.0673e-01,  1.1322e-01],\n",
       "        [ 1.5711e-01,  1.5238e-01],\n",
       "        [ 1.2888e-01,  1.3308e-01],\n",
       "        [-3.1670e-01, -3.9756e-01],\n",
       "        [ 6.4178e-02,  6.4360e-02],\n",
       "        [ 1.4874e-01,  1.4689e-01],\n",
       "        [ 1.5295e-01,  1.4962e-01],\n",
       "        [ 1.5177e-01,  1.4886e-01],\n",
       "        [ 1.6223e-01,  1.5538e-01],\n",
       "        [-1.5144e-01, -1.9133e-01],\n",
       "        [-3.5185e-01, -4.4236e-01]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse relationship between epochs and r^2 score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create lists to store the epochs and R^2 scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs_list = [i for i in range(1, 301)]\n",
    "r2_scores_list = []\n",
    "rmse_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conduct training and testing for each num_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of epochs: 1\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.3150954950457759\n",
      "Test R^2 score: -0.08130789191335341\n",
      "Num of epochs: 2\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.31090152245473723\n",
      "Test R^2 score: -0.053207219358976876\n",
      "Num of epochs: 3\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.3076213203079838\n",
      "Test R^2 score: -0.031331766796814264\n",
      "Num of epochs: 4\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.3051880822787037\n",
      "Test R^2 score: -0.015236610982118481\n",
      "Num of epochs: 5\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.30355569854728487\n",
      "Test R^2 score: -0.00444679250162916\n",
      "Num of epochs: 6\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.30287040927318604\n",
      "Test R^2 score: 0.00018785050973924022\n",
      "Num of epochs: 7\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.3027710134542383\n",
      "Test R^2 score: 0.000948174097381127\n",
      "Num of epochs: 8\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.302747860963559\n",
      "Test R^2 score: 0.0011356302631368997\n",
      "Num of epochs: 9\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.3025676999886819\n",
      "Test R^2 score: 0.0023032763847067317\n",
      "Num of epochs: 10\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.30223721165840695\n",
      "Test R^2 score: 0.004427031657866343\n",
      "Num of epochs: 11\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.30177729451908314\n",
      "Test R^2 score: 0.0073639977343665786\n",
      "Num of epochs: 12\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.30118891095212064\n",
      "Test R^2 score: 0.011077887625765004\n",
      "Num of epochs: 13\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.3003171842898969\n",
      "Test R^2 score: 0.016592852133862634\n",
      "Num of epochs: 14\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.29866155232045005\n",
      "Test R^2 score: 0.027130840133325007\n",
      "Num of epochs: 15\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.29539178460580673\n",
      "Test R^2 score: 0.047955824661566115\n",
      "Num of epochs: 16\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2895724604373972\n",
      "Test R^2 score: 0.08474059205313716\n",
      "Num of epochs: 17\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2811881665521167\n",
      "Test R^2 score: 0.13676852576280407\n",
      "Num of epochs: 18\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2708847247937381\n",
      "Test R^2 score: 0.1990980567803159\n",
      "Num of epochs: 19\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2603732799504748\n",
      "Test R^2 score: 0.2609027919615022\n",
      "Num of epochs: 20\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2584809917739845\n",
      "Test R^2 score: 0.2722639019415289\n",
      "Num of epochs: 21\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2615798517334369\n",
      "Test R^2 score: 0.25464274609303456\n",
      "Num of epochs: 22\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2576815227125812\n",
      "Test R^2 score: 0.2763147234406286\n",
      "Num of epochs: 23\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.25596449519587744\n",
      "Test R^2 score: 0.28620327135508106\n",
      "Num of epochs: 24\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.24617013320911785\n",
      "Test R^2 score: 0.339758459892728\n",
      "Num of epochs: 25\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.24376395963718145\n",
      "Test R^2 score: 0.35266620150637\n",
      "Num of epochs: 26\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.24705763118709387\n",
      "Test R^2 score: 0.33341686591484654\n",
      "Num of epochs: 27\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.24493164003064435\n",
      "Test R^2 score: 0.34499248048582837\n",
      "Num of epochs: 28\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2396162299013057\n",
      "Test R^2 score: 0.3738030940355503\n",
      "Num of epochs: 29\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2372023208839481\n",
      "Test R^2 score: 0.38672828782295\n",
      "Num of epochs: 30\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.23928938963420548\n",
      "Test R^2 score: 0.3759666488540271\n",
      "Num of epochs: 31\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.23652621904773563\n",
      "Test R^2 score: 0.3904894812551848\n",
      "Num of epochs: 32\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.23717888263521056\n",
      "Test R^2 score: 0.38771327813080425\n",
      "Num of epochs: 33\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.24112820758636785\n",
      "Test R^2 score: 0.36587906118287705\n",
      "Num of epochs: 34\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.23464689225984617\n",
      "Test R^2 score: 0.40021558430218834\n",
      "Num of epochs: 35\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.23158505115360084\n",
      "Test R^2 score: 0.41572831663141363\n",
      "Num of epochs: 36\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.23528254832973444\n",
      "Test R^2 score: 0.3962113919532084\n",
      "Num of epochs: 37\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2299917535727154\n",
      "Test R^2 score: 0.42269671264603004\n",
      "Num of epochs: 38\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22698060176018603\n",
      "Test R^2 score: 0.4384114414328082\n",
      "Num of epochs: 39\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2311420160843567\n",
      "Test R^2 score: 0.4172805607293688\n",
      "Num of epochs: 40\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.23010807230914807\n",
      "Test R^2 score: 0.4228420713801373\n",
      "Num of epochs: 41\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2265823375816546\n",
      "Test R^2 score: 0.44096051096622085\n",
      "Num of epochs: 42\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.23372110962673875\n",
      "Test R^2 score: 0.40425046479860566\n",
      "Num of epochs: 43\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.23043524758136957\n",
      "Test R^2 score: 0.42099331093842857\n",
      "Num of epochs: 44\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22483630478317124\n",
      "Test R^2 score: 0.4494475292540413\n",
      "Num of epochs: 45\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.23096693005786587\n",
      "Test R^2 score: 0.4180059898035685\n",
      "Num of epochs: 46\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22510429073309274\n",
      "Test R^2 score: 0.4472844624465423\n",
      "Num of epochs: 47\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21916269472174868\n",
      "Test R^2 score: 0.4758654746131652\n",
      "Num of epochs: 48\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22378820842243805\n",
      "Test R^2 score: 0.4531156921942268\n",
      "Num of epochs: 49\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22658978591471915\n",
      "Test R^2 score: 0.4395045385321926\n",
      "Num of epochs: 50\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21905751457796246\n",
      "Test R^2 score: 0.4770319017835061\n",
      "Num of epochs: 51\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22320787830725775\n",
      "Test R^2 score: 0.4573368695632056\n",
      "Num of epochs: 52\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22732007392023112\n",
      "Test R^2 score: 0.437410134930681\n",
      "Num of epochs: 53\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22062279627183704\n",
      "Test R^2 score: 0.4702620943457101\n",
      "Num of epochs: 54\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22464338817381638\n",
      "Test R^2 score: 0.45035826663097867\n",
      "Num of epochs: 55\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22380889539502588\n",
      "Test R^2 score: 0.45429632405221704\n",
      "Num of epochs: 56\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21811739265696614\n",
      "Test R^2 score: 0.4818615409307476\n",
      "Num of epochs: 57\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22128968227071844\n",
      "Test R^2 score: 0.46659656284677986\n",
      "Num of epochs: 58\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2216363130710299\n",
      "Test R^2 score: 0.46499177938007347\n",
      "Num of epochs: 59\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21759875141675344\n",
      "Test R^2 score: 0.4842465762601702\n",
      "Num of epochs: 60\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22239643280066432\n",
      "Test R^2 score: 0.46095978301937834\n",
      "Num of epochs: 61\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2203192040691485\n",
      "Test R^2 score: 0.47124184312787765\n",
      "Num of epochs: 62\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2175625682754735\n",
      "Test R^2 score: 0.48476687806126784\n",
      "Num of epochs: 63\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22159912496001416\n",
      "Test R^2 score: 0.4655319144507931\n",
      "Num of epochs: 64\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21755581381164904\n",
      "Test R^2 score: 0.4849276327804087\n",
      "Num of epochs: 65\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21708429559942885\n",
      "Test R^2 score: 0.4871931865717825\n",
      "Num of epochs: 66\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2217670888757508\n",
      "Test R^2 score: 0.4647064960115019\n",
      "Num of epochs: 67\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2164821875645027\n",
      "Test R^2 score: 0.4900891219135701\n",
      "Num of epochs: 68\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22019179058916744\n",
      "Test R^2 score: 0.4721915217807401\n",
      "Num of epochs: 69\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21629443515356991\n",
      "Test R^2 score: 0.49077299099520827\n",
      "Num of epochs: 70\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21675849739761785\n",
      "Test R^2 score: 0.4886100937242728\n",
      "Num of epochs: 71\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2178002041785247\n",
      "Test R^2 score: 0.4837093506529376\n",
      "Num of epochs: 72\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21564066141244492\n",
      "Test R^2 score: 0.4941292697603028\n",
      "Num of epochs: 73\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22379215971997932\n",
      "Test R^2 score: 0.45505606189678854\n",
      "Num of epochs: 74\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21713751406449325\n",
      "Test R^2 score: 0.48732331626475\n",
      "Num of epochs: 75\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.23936901812594513\n",
      "Test R^2 score: 0.37709320932371115\n",
      "Num of epochs: 76\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2142233553434745\n",
      "Test R^2 score: 0.5006663263559245\n",
      "Num of epochs: 77\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21529441469943988\n",
      "Test R^2 score: 0.49547205665656185\n",
      "Num of epochs: 78\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22885758162637088\n",
      "Test R^2 score: 0.43053451014246547\n",
      "Num of epochs: 79\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22083067745624102\n",
      "Test R^2 score: 0.46968008788696974\n",
      "Num of epochs: 80\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21850166928691356\n",
      "Test R^2 score: 0.48117644377385377\n",
      "Num of epochs: 81\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22349217832798537\n",
      "Test R^2 score: 0.4566074323881224\n",
      "Num of epochs: 82\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22420498728422436\n",
      "Test R^2 score: 0.4531473752264795\n",
      "Num of epochs: 83\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2137026150259865\n",
      "Test R^2 score: 0.5029223597330532\n",
      "Num of epochs: 84\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21336294362446762\n",
      "Test R^2 score: 0.5045198204517183\n",
      "Num of epochs: 85\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22529660703938514\n",
      "Test R^2 score: 0.4475364086156613\n",
      "Num of epochs: 86\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21623563015893885\n",
      "Test R^2 score: 0.4912902798330205\n",
      "Num of epochs: 87\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21525906827166097\n",
      "Test R^2 score: 0.4964158001275788\n",
      "Num of epochs: 88\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22316524256680384\n",
      "Test R^2 score: 0.4582558901976437\n",
      "Num of epochs: 89\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21972965529825816\n",
      "Test R^2 score: 0.4750332385009889\n",
      "Num of epochs: 90\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21361951448092403\n",
      "Test R^2 score: 0.5037809244918738\n",
      "Num of epochs: 91\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2162697168676644\n",
      "Test R^2 score: 0.4914134699196723\n",
      "Num of epochs: 92\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2208044009701981\n",
      "Test R^2 score: 0.4697872957218661\n",
      "Num of epochs: 93\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2138428990550292\n",
      "Test R^2 score: 0.5029095562890409\n",
      "Num of epochs: 94\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21569066096236625\n",
      "Test R^2 score: 0.494369441231148\n",
      "Num of epochs: 95\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22234331307962918\n",
      "Test R^2 score: 0.4626077327391633\n",
      "Num of epochs: 96\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21362523717079393\n",
      "Test R^2 score: 0.5038483572633133\n",
      "Num of epochs: 97\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21479191749634263\n",
      "Test R^2 score: 0.4984783601785043\n",
      "Num of epochs: 98\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21871972234418785\n",
      "Test R^2 score: 0.47992816649266096\n",
      "Num of epochs: 99\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21348959696891762\n",
      "Test R^2 score: 0.5045320768058841\n",
      "Num of epochs: 100\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21496087932546806\n",
      "Test R^2 score: 0.49780556485877137\n",
      "Num of epochs: 101\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22029153731585693\n",
      "Test R^2 score: 0.47251234454532487\n",
      "Num of epochs: 102\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2138938418625227\n",
      "Test R^2 score: 0.5027237469190777\n",
      "Num of epochs: 103\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21593447703161397\n",
      "Test R^2 score: 0.49318937714340016\n",
      "Num of epochs: 104\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2166139595087317\n",
      "Test R^2 score: 0.4899179009298466\n",
      "Num of epochs: 105\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2128412908388936\n",
      "Test R^2 score: 0.5074645887824376\n",
      "Num of epochs: 106\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2176092289707002\n",
      "Test R^2 score: 0.4852144264196342\n",
      "Num of epochs: 107\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2151404714745451\n",
      "Test R^2 score: 0.496956800774172\n",
      "Num of epochs: 108\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21440899185665596\n",
      "Test R^2 score: 0.5004364782138162\n",
      "Num of epochs: 109\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2187922417824373\n",
      "Test R^2 score: 0.47989573392040835\n",
      "Num of epochs: 110\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21250474025678684\n",
      "Test R^2 score: 0.509151186007655\n",
      "Num of epochs: 111\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21822696537191905\n",
      "Test R^2 score: 0.48249843084998695\n",
      "Num of epochs: 112\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21317374341841036\n",
      "Test R^2 score: 0.5061175757556869\n",
      "Num of epochs: 113\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21475393677051322\n",
      "Test R^2 score: 0.498834325260232\n",
      "Num of epochs: 114\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21824481908019225\n",
      "Test R^2 score: 0.48243544910287767\n",
      "Num of epochs: 115\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21242027064820937\n",
      "Test R^2 score: 0.5094647019439327\n",
      "Num of epochs: 116\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2256406837187015\n",
      "Test R^2 score: 0.4467974982761484\n",
      "Num of epochs: 117\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21250068865596464\n",
      "Test R^2 score: 0.5087247360890033\n",
      "Num of epochs: 118\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.217850965761688\n",
      "Test R^2 score: 0.4841539191475638\n",
      "Num of epochs: 119\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2174815241009953\n",
      "Test R^2 score: 0.48598159082308484\n",
      "Num of epochs: 120\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21438953175441158\n",
      "Test R^2 score: 0.5007394638428897\n",
      "Num of epochs: 121\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.23424095751525123\n",
      "Test R^2 score: 0.4031909975696018\n",
      "Num of epochs: 122\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21195145719860045\n",
      "Test R^2 score: 0.5112362747018646\n",
      "Num of epochs: 123\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2114458378760872\n",
      "Test R^2 score: 0.5136611688343748\n",
      "Num of epochs: 124\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22247603561449011\n",
      "Test R^2 score: 0.46194243900596105\n",
      "Num of epochs: 125\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21156606532982383\n",
      "Test R^2 score: 0.5133884787255856\n",
      "Num of epochs: 126\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2140214292357226\n",
      "Test R^2 score: 0.5025123465664478\n",
      "Num of epochs: 127\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2307388237663892\n",
      "Test R^2 score: 0.4209934505579185\n",
      "Num of epochs: 128\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2131981590949124\n",
      "Test R^2 score: 0.5058279956341178\n",
      "Num of epochs: 129\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21282986366496304\n",
      "Test R^2 score: 0.5075030594512195\n",
      "Num of epochs: 130\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2197496797126126\n",
      "Test R^2 score: 0.47510054567907856\n",
      "Num of epochs: 131\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2111523941029126\n",
      "Test R^2 score: 0.5150335166687102\n",
      "Num of epochs: 132\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2132972826209593\n",
      "Test R^2 score: 0.505521978208959\n",
      "Num of epochs: 133\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22519239799461271\n",
      "Test R^2 score: 0.4486881359438095\n",
      "Num of epochs: 134\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21457143264492493\n",
      "Test R^2 score: 0.4998124001357702\n",
      "Num of epochs: 135\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21730839372101476\n",
      "Test R^2 score: 0.4868865477730445\n",
      "Num of epochs: 136\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2155819089341548\n",
      "Test R^2 score: 0.49492101682177053\n",
      "Num of epochs: 137\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21112116739526332\n",
      "Test R^2 score: 0.5152923686522382\n",
      "Num of epochs: 138\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21682146751645098\n",
      "Test R^2 score: 0.4890512931143805\n",
      "Num of epochs: 139\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21780907484321302\n",
      "Test R^2 score: 0.4844837722453457\n",
      "Num of epochs: 140\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21431505072035686\n",
      "Test R^2 score: 0.5009428699927062\n",
      "Num of epochs: 141\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22231981444661642\n",
      "Test R^2 score: 0.46297215825404925\n",
      "Num of epochs: 142\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21133700759935492\n",
      "Test R^2 score: 0.5143851311808719\n",
      "Num of epochs: 143\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21265046018886719\n",
      "Test R^2 score: 0.5084913741733825\n",
      "Num of epochs: 144\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2194601851044682\n",
      "Test R^2 score: 0.47671298235113957\n",
      "Num of epochs: 145\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21404862860036153\n",
      "Test R^2 score: 0.5023436301975743\n",
      "Num of epochs: 146\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22157048266432355\n",
      "Test R^2 score: 0.4665969213034791\n",
      "Num of epochs: 147\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21269717652195277\n",
      "Test R^2 score: 0.5083096481156524\n",
      "Num of epochs: 148\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21361429912506658\n",
      "Test R^2 score: 0.5040628636502787\n",
      "Num of epochs: 149\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21687571404897452\n",
      "Test R^2 score: 0.48886627799691246\n",
      "Num of epochs: 150\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2135115278001272\n",
      "Test R^2 score: 0.5045087344856616\n",
      "Num of epochs: 151\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2210985611223121\n",
      "Test R^2 score: 0.4687334530925304\n",
      "Num of epochs: 152\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21300126930633842\n",
      "Test R^2 score: 0.5068958302316007\n",
      "Num of epochs: 153\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21921940827561567\n",
      "Test R^2 score: 0.4777617724969699\n",
      "Num of epochs: 154\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21254068049942626\n",
      "Test R^2 score: 0.5089377852170449\n",
      "Num of epochs: 155\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21547492643542698\n",
      "Test R^2 score: 0.49541697086552405\n",
      "Num of epochs: 156\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21787056325052\n",
      "Test R^2 score: 0.4841640145407395\n",
      "Num of epochs: 157\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.213685680534681\n",
      "Test R^2 score: 0.5036917708193185\n",
      "Num of epochs: 158\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22276183394177784\n",
      "Test R^2 score: 0.46074043786063146\n",
      "Num of epochs: 159\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21338191000249637\n",
      "Test R^2 score: 0.504843161813556\n",
      "Num of epochs: 160\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2254167723604985\n",
      "Test R^2 score: 0.4477920839385261\n",
      "Num of epochs: 161\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21285821484251857\n",
      "Test R^2 score: 0.5073137768569589\n",
      "Num of epochs: 162\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2173099741955708\n",
      "Test R^2 score: 0.4867306049935086\n",
      "Num of epochs: 163\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21508464263221594\n",
      "Test R^2 score: 0.4971796659549319\n",
      "Num of epochs: 164\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21283167564883063\n",
      "Test R^2 score: 0.5076547597422503\n",
      "Num of epochs: 165\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2219523124748685\n",
      "Test R^2 score: 0.46474192439164913\n",
      "Num of epochs: 166\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21392849273842707\n",
      "Test R^2 score: 0.5026560161648398\n",
      "Num of epochs: 167\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22595436159884474\n",
      "Test R^2 score: 0.44520491343316165\n",
      "Num of epochs: 168\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2134284917583235\n",
      "Test R^2 score: 0.5046386000179881\n",
      "Num of epochs: 169\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22165902752720337\n",
      "Test R^2 score: 0.465948251073539\n",
      "Num of epochs: 170\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21333662127031658\n",
      "Test R^2 score: 0.5051762609504655\n",
      "Num of epochs: 171\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21404254930955693\n",
      "Test R^2 score: 0.5020248295732203\n",
      "Num of epochs: 172\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22282749216294404\n",
      "Test R^2 score: 0.46032479291644746\n",
      "Num of epochs: 173\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21413357214077203\n",
      "Test R^2 score: 0.501432240798326\n",
      "Num of epochs: 174\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22448615629077584\n",
      "Test R^2 score: 0.4524646467845581\n",
      "Num of epochs: 175\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2135745774735484\n",
      "Test R^2 score: 0.504210517467121\n",
      "Num of epochs: 176\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21589398613744906\n",
      "Test R^2 score: 0.4935171353791382\n",
      "Num of epochs: 177\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2248472696131126\n",
      "Test R^2 score: 0.4505240610435144\n",
      "Num of epochs: 178\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21578697278097175\n",
      "Test R^2 score: 0.4935499850089136\n",
      "Num of epochs: 179\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Epoch 179, Loss: 0.42867030340024453\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22724048459243565\n",
      "Test R^2 score: 0.438928847267185\n",
      "Num of epochs: 180\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Epoch 179, Loss: 0.42867030340024453\n",
      "Epoch 180, Loss: 0.42665902048327814\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2140064214407028\n",
      "Test R^2 score: 0.5020999688885095\n",
      "Num of epochs: 181\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Epoch 179, Loss: 0.42867030340024453\n",
      "Epoch 180, Loss: 0.42665902048327814\n",
      "Epoch 181, Loss: 0.4160041986606613\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21623929278857812\n",
      "Test R^2 score: 0.49189840119854933\n",
      "Num of epochs: 182\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Epoch 179, Loss: 0.42867030340024453\n",
      "Epoch 180, Loss: 0.42665902048327814\n",
      "Epoch 181, Loss: 0.4160041986606613\n",
      "Epoch 182, Loss: 0.42380692389414293\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.23969977398825618\n",
      "Test R^2 score: 0.37525267903062326\n",
      "Num of epochs: 183\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Epoch 179, Loss: 0.42867030340024453\n",
      "Epoch 180, Loss: 0.42665902048327814\n",
      "Epoch 181, Loss: 0.4160041986606613\n",
      "Epoch 182, Loss: 0.42380692389414293\n",
      "Epoch 183, Loss: 0.4367609764525626\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21412306985697083\n",
      "Test R^2 score: 0.5011815167595887\n",
      "Num of epochs: 184\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Epoch 179, Loss: 0.42867030340024453\n",
      "Epoch 180, Loss: 0.42665902048327814\n",
      "Epoch 181, Loss: 0.4160041986606613\n",
      "Epoch 182, Loss: 0.42380692389414293\n",
      "Epoch 183, Loss: 0.4367609764525626\n",
      "Epoch 184, Loss: 0.42557170506243686\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21271434253925528\n",
      "Test R^2 score: 0.5077018425115615\n",
      "Num of epochs: 185\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Epoch 179, Loss: 0.42867030340024453\n",
      "Epoch 180, Loss: 0.42665902048327814\n",
      "Epoch 181, Loss: 0.4160041986606613\n",
      "Epoch 182, Loss: 0.42380692389414293\n",
      "Epoch 183, Loss: 0.4367609764525626\n",
      "Epoch 184, Loss: 0.42557170506243686\n",
      "Epoch 185, Loss: 0.42106826790053603\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22649275422852777\n",
      "Test R^2 score: 0.44263001207714553\n",
      "Num of epochs: 186\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Epoch 179, Loss: 0.42867030340024453\n",
      "Epoch 180, Loss: 0.42665902048327814\n",
      "Epoch 181, Loss: 0.4160041986606613\n",
      "Epoch 182, Loss: 0.42380692389414293\n",
      "Epoch 183, Loss: 0.4367609764525626\n",
      "Epoch 184, Loss: 0.42557170506243686\n",
      "Epoch 185, Loss: 0.42106826790053603\n",
      "Epoch 186, Loss: 0.42573876125176086\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21616652840294162\n",
      "Test R^2 score: 0.49265862944198685\n",
      "Num of epochs: 187\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Epoch 179, Loss: 0.42867030340024453\n",
      "Epoch 180, Loss: 0.42665902048327814\n",
      "Epoch 181, Loss: 0.4160041986606613\n",
      "Epoch 182, Loss: 0.42380692389414293\n",
      "Epoch 183, Loss: 0.4367609764525626\n",
      "Epoch 184, Loss: 0.42557170506243686\n",
      "Epoch 185, Loss: 0.42106826790053603\n",
      "Epoch 186, Loss: 0.42573876125176086\n",
      "Epoch 187, Loss: 0.41925407360374856\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21666734076094957\n",
      "Test R^2 score: 0.4901453320982067\n",
      "Num of epochs: 188\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Epoch 179, Loss: 0.42867030340024453\n",
      "Epoch 180, Loss: 0.42665902048327814\n",
      "Epoch 181, Loss: 0.4160041986606613\n",
      "Epoch 182, Loss: 0.42380692389414293\n",
      "Epoch 183, Loss: 0.4367609764525626\n",
      "Epoch 184, Loss: 0.42557170506243686\n",
      "Epoch 185, Loss: 0.42106826790053603\n",
      "Epoch 186, Loss: 0.42573876125176086\n",
      "Epoch 187, Loss: 0.41925407360374856\n",
      "Epoch 188, Loss: 0.4183384695092418\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22461198032533497\n",
      "Test R^2 score: 0.4515978203693445\n",
      "Num of epochs: 189\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Epoch 179, Loss: 0.42867030340024453\n",
      "Epoch 180, Loss: 0.42665902048327814\n",
      "Epoch 181, Loss: 0.4160041986606613\n",
      "Epoch 182, Loss: 0.42380692389414293\n",
      "Epoch 183, Loss: 0.4367609764525626\n",
      "Epoch 184, Loss: 0.42557170506243686\n",
      "Epoch 185, Loss: 0.42106826790053603\n",
      "Epoch 186, Loss: 0.42573876125176086\n",
      "Epoch 187, Loss: 0.41925407360374856\n",
      "Epoch 188, Loss: 0.4183384695092418\n",
      "Epoch 189, Loss: 0.4218813047997579\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21329509801107682\n",
      "Test R^2 score: 0.5049417508682542\n",
      "Num of epochs: 190\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Epoch 179, Loss: 0.42867030340024453\n",
      "Epoch 180, Loss: 0.42665902048327814\n",
      "Epoch 181, Loss: 0.4160041986606613\n",
      "Epoch 182, Loss: 0.42380692389414293\n",
      "Epoch 183, Loss: 0.4367609764525626\n",
      "Epoch 184, Loss: 0.42557170506243686\n",
      "Epoch 185, Loss: 0.42106826790053603\n",
      "Epoch 186, Loss: 0.42573876125176086\n",
      "Epoch 187, Loss: 0.41925407360374856\n",
      "Epoch 188, Loss: 0.4183384695092418\n",
      "Epoch 189, Loss: 0.4218813047997579\n",
      "Epoch 190, Loss: 0.4197713005325469\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21412281210312187\n",
      "Test R^2 score: 0.5012701181707842\n",
      "Num of epochs: 191\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Epoch 179, Loss: 0.42867030340024453\n",
      "Epoch 180, Loss: 0.42665902048327814\n",
      "Epoch 181, Loss: 0.4160041986606613\n",
      "Epoch 182, Loss: 0.42380692389414293\n",
      "Epoch 183, Loss: 0.4367609764525626\n",
      "Epoch 184, Loss: 0.42557170506243686\n",
      "Epoch 185, Loss: 0.42106826790053603\n",
      "Epoch 186, Loss: 0.42573876125176086\n",
      "Epoch 187, Loss: 0.41925407360374856\n",
      "Epoch 188, Loss: 0.4183384695092418\n",
      "Epoch 189, Loss: 0.4218813047997579\n",
      "Epoch 190, Loss: 0.4197713005325469\n",
      "Epoch 191, Loss: 0.417197451669247\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22571358345155232\n",
      "Test R^2 score: 0.4460856011487701\n",
      "Num of epochs: 192\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Epoch 179, Loss: 0.42867030340024453\n",
      "Epoch 180, Loss: 0.42665902048327814\n",
      "Epoch 181, Loss: 0.4160041986606613\n",
      "Epoch 182, Loss: 0.42380692389414293\n",
      "Epoch 183, Loss: 0.4367609764525626\n",
      "Epoch 184, Loss: 0.42557170506243686\n",
      "Epoch 185, Loss: 0.42106826790053603\n",
      "Epoch 186, Loss: 0.42573876125176086\n",
      "Epoch 187, Loss: 0.41925407360374856\n",
      "Epoch 188, Loss: 0.4183384695092418\n",
      "Epoch 189, Loss: 0.4218813047997579\n",
      "Epoch 190, Loss: 0.4197713005325469\n",
      "Epoch 191, Loss: 0.417197451669247\n",
      "Epoch 192, Loss: 0.41998586832409235\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2185343703469157\n",
      "Test R^2 score: 0.4815055336659881\n",
      "Num of epochs: 193\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Epoch 179, Loss: 0.42867030340024453\n",
      "Epoch 180, Loss: 0.42665902048327814\n",
      "Epoch 181, Loss: 0.4160041986606613\n",
      "Epoch 182, Loss: 0.42380692389414293\n",
      "Epoch 183, Loss: 0.4367609764525626\n",
      "Epoch 184, Loss: 0.42557170506243686\n",
      "Epoch 185, Loss: 0.42106826790053603\n",
      "Epoch 186, Loss: 0.42573876125176086\n",
      "Epoch 187, Loss: 0.41925407360374856\n",
      "Epoch 188, Loss: 0.4183384695092418\n",
      "Epoch 189, Loss: 0.4218813047997579\n",
      "Epoch 190, Loss: 0.4197713005325469\n",
      "Epoch 191, Loss: 0.417197451669247\n",
      "Epoch 192, Loss: 0.41998586832409235\n",
      "Epoch 193, Loss: 0.4198630180807017\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22119792204598324\n",
      "Test R^2 score: 0.46832951589455685\n",
      "Num of epochs: 194\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Epoch 179, Loss: 0.42867030340024453\n",
      "Epoch 180, Loss: 0.42665902048327814\n",
      "Epoch 181, Loss: 0.4160041986606613\n",
      "Epoch 182, Loss: 0.42380692389414293\n",
      "Epoch 183, Loss: 0.4367609764525626\n",
      "Epoch 184, Loss: 0.42557170506243686\n",
      "Epoch 185, Loss: 0.42106826790053603\n",
      "Epoch 186, Loss: 0.42573876125176086\n",
      "Epoch 187, Loss: 0.41925407360374856\n",
      "Epoch 188, Loss: 0.4183384695092418\n",
      "Epoch 189, Loss: 0.4218813047997579\n",
      "Epoch 190, Loss: 0.4197713005325469\n",
      "Epoch 191, Loss: 0.417197451669247\n",
      "Epoch 192, Loss: 0.41998586832409235\n",
      "Epoch 193, Loss: 0.4198630180807017\n",
      "Epoch 194, Loss: 0.4146118298837611\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21803746756409925\n",
      "Test R^2 score: 0.4833602948024797\n",
      "Num of epochs: 195\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Epoch 179, Loss: 0.42867030340024453\n",
      "Epoch 180, Loss: 0.42665902048327814\n",
      "Epoch 181, Loss: 0.4160041986606613\n",
      "Epoch 182, Loss: 0.42380692389414293\n",
      "Epoch 183, Loss: 0.4367609764525626\n",
      "Epoch 184, Loss: 0.42557170506243686\n",
      "Epoch 185, Loss: 0.42106826790053603\n",
      "Epoch 186, Loss: 0.42573876125176086\n",
      "Epoch 187, Loss: 0.41925407360374856\n",
      "Epoch 188, Loss: 0.4183384695092418\n",
      "Epoch 189, Loss: 0.4218813047997579\n",
      "Epoch 190, Loss: 0.4197713005325469\n",
      "Epoch 191, Loss: 0.417197451669247\n",
      "Epoch 192, Loss: 0.41998586832409235\n",
      "Epoch 193, Loss: 0.4198630180807017\n",
      "Epoch 194, Loss: 0.4146118298837611\n",
      "Epoch 195, Loss: 0.41413205840097117\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21482941972878833\n",
      "Test R^2 score: 0.49832067810758257\n",
      "Num of epochs: 196\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Epoch 179, Loss: 0.42867030340024453\n",
      "Epoch 180, Loss: 0.42665902048327814\n",
      "Epoch 181, Loss: 0.4160041986606613\n",
      "Epoch 182, Loss: 0.42380692389414293\n",
      "Epoch 183, Loss: 0.4367609764525626\n",
      "Epoch 184, Loss: 0.42557170506243686\n",
      "Epoch 185, Loss: 0.42106826790053603\n",
      "Epoch 186, Loss: 0.42573876125176086\n",
      "Epoch 187, Loss: 0.41925407360374856\n",
      "Epoch 188, Loss: 0.4183384695092418\n",
      "Epoch 189, Loss: 0.4218813047997579\n",
      "Epoch 190, Loss: 0.4197713005325469\n",
      "Epoch 191, Loss: 0.417197451669247\n",
      "Epoch 192, Loss: 0.41998586832409235\n",
      "Epoch 193, Loss: 0.4198630180807017\n",
      "Epoch 194, Loss: 0.4146118298837611\n",
      "Epoch 195, Loss: 0.41413205840097117\n",
      "Epoch 196, Loss: 0.4155607826414292\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22112722612065214\n",
      "Test R^2 score: 0.4685175066420575\n",
      "Num of epochs: 197\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Epoch 179, Loss: 0.42867030340024453\n",
      "Epoch 180, Loss: 0.42665902048327814\n",
      "Epoch 181, Loss: 0.4160041986606613\n",
      "Epoch 182, Loss: 0.42380692389414293\n",
      "Epoch 183, Loss: 0.4367609764525626\n",
      "Epoch 184, Loss: 0.42557170506243686\n",
      "Epoch 185, Loss: 0.42106826790053603\n",
      "Epoch 186, Loss: 0.42573876125176086\n",
      "Epoch 187, Loss: 0.41925407360374856\n",
      "Epoch 188, Loss: 0.4183384695092418\n",
      "Epoch 189, Loss: 0.4218813047997579\n",
      "Epoch 190, Loss: 0.4197713005325469\n",
      "Epoch 191, Loss: 0.417197451669247\n",
      "Epoch 192, Loss: 0.41998586832409235\n",
      "Epoch 193, Loss: 0.4198630180807017\n",
      "Epoch 194, Loss: 0.4146118298837611\n",
      "Epoch 195, Loss: 0.41413205840097117\n",
      "Epoch 196, Loss: 0.4155607826414292\n",
      "Epoch 197, Loss: 0.414238532452658\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2178020565931981\n",
      "Test R^2 score: 0.4844404662486379\n",
      "Num of epochs: 198\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Epoch 179, Loss: 0.42867030340024453\n",
      "Epoch 180, Loss: 0.42665902048327814\n",
      "Epoch 181, Loss: 0.4160041986606613\n",
      "Epoch 182, Loss: 0.42380692389414293\n",
      "Epoch 183, Loss: 0.4367609764525626\n",
      "Epoch 184, Loss: 0.42557170506243686\n",
      "Epoch 185, Loss: 0.42106826790053603\n",
      "Epoch 186, Loss: 0.42573876125176086\n",
      "Epoch 187, Loss: 0.41925407360374856\n",
      "Epoch 188, Loss: 0.4183384695092418\n",
      "Epoch 189, Loss: 0.4218813047997579\n",
      "Epoch 190, Loss: 0.4197713005325469\n",
      "Epoch 191, Loss: 0.417197451669247\n",
      "Epoch 192, Loss: 0.41998586832409235\n",
      "Epoch 193, Loss: 0.4198630180807017\n",
      "Epoch 194, Loss: 0.4146118298837611\n",
      "Epoch 195, Loss: 0.41413205840097117\n",
      "Epoch 196, Loss: 0.4155607826414292\n",
      "Epoch 197, Loss: 0.414238532452658\n",
      "Epoch 198, Loss: 0.41297339310852155\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21623363065572188\n",
      "Test R^2 score: 0.4918075128302132\n",
      "Num of epochs: 199\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Epoch 179, Loss: 0.42867030340024453\n",
      "Epoch 180, Loss: 0.42665902048327814\n",
      "Epoch 181, Loss: 0.4160041986606613\n",
      "Epoch 182, Loss: 0.42380692389414293\n",
      "Epoch 183, Loss: 0.4367609764525626\n",
      "Epoch 184, Loss: 0.42557170506243686\n",
      "Epoch 185, Loss: 0.42106826790053603\n",
      "Epoch 186, Loss: 0.42573876125176086\n",
      "Epoch 187, Loss: 0.41925407360374856\n",
      "Epoch 188, Loss: 0.4183384695092418\n",
      "Epoch 189, Loss: 0.4218813047997579\n",
      "Epoch 190, Loss: 0.4197713005325469\n",
      "Epoch 191, Loss: 0.417197451669247\n",
      "Epoch 192, Loss: 0.41998586832409235\n",
      "Epoch 193, Loss: 0.4198630180807017\n",
      "Epoch 194, Loss: 0.4146118298837611\n",
      "Epoch 195, Loss: 0.41413205840097117\n",
      "Epoch 196, Loss: 0.4155607826414292\n",
      "Epoch 197, Loss: 0.414238532452658\n",
      "Epoch 198, Loss: 0.41297339310852155\n",
      "Epoch 199, Loss: 0.4123900845056213\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22000634071018244\n",
      "Test R^2 score: 0.4740701721794912\n",
      "Num of epochs: 200\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Epoch 179, Loss: 0.42867030340024453\n",
      "Epoch 180, Loss: 0.42665902048327814\n",
      "Epoch 181, Loss: 0.4160041986606613\n",
      "Epoch 182, Loss: 0.42380692389414293\n",
      "Epoch 183, Loss: 0.4367609764525626\n",
      "Epoch 184, Loss: 0.42557170506243686\n",
      "Epoch 185, Loss: 0.42106826790053603\n",
      "Epoch 186, Loss: 0.42573876125176086\n",
      "Epoch 187, Loss: 0.41925407360374856\n",
      "Epoch 188, Loss: 0.4183384695092418\n",
      "Epoch 189, Loss: 0.4218813047997579\n",
      "Epoch 190, Loss: 0.4197713005325469\n",
      "Epoch 191, Loss: 0.417197451669247\n",
      "Epoch 192, Loss: 0.41998586832409235\n",
      "Epoch 193, Loss: 0.4198630180807017\n",
      "Epoch 194, Loss: 0.4146118298837611\n",
      "Epoch 195, Loss: 0.41413205840097117\n",
      "Epoch 196, Loss: 0.4155607826414292\n",
      "Epoch 197, Loss: 0.414238532452658\n",
      "Epoch 198, Loss: 0.41297339310852155\n",
      "Epoch 199, Loss: 0.4123900845056213\n",
      "Epoch 200, Loss: 0.4134311180746695\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21645077201110308\n",
      "Test R^2 score: 0.49100051883251505\n",
      "Num of epochs: 201\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Epoch 179, Loss: 0.42867030340024453\n",
      "Epoch 180, Loss: 0.42665902048327814\n",
      "Epoch 181, Loss: 0.4160041986606613\n",
      "Epoch 182, Loss: 0.42380692389414293\n",
      "Epoch 183, Loss: 0.4367609764525626\n",
      "Epoch 184, Loss: 0.42557170506243686\n",
      "Epoch 185, Loss: 0.42106826790053603\n",
      "Epoch 186, Loss: 0.42573876125176086\n",
      "Epoch 187, Loss: 0.41925407360374856\n",
      "Epoch 188, Loss: 0.4183384695092418\n",
      "Epoch 189, Loss: 0.4218813047997579\n",
      "Epoch 190, Loss: 0.4197713005325469\n",
      "Epoch 191, Loss: 0.417197451669247\n",
      "Epoch 192, Loss: 0.41998586832409235\n",
      "Epoch 193, Loss: 0.4198630180807017\n",
      "Epoch 194, Loss: 0.4146118298837611\n",
      "Epoch 195, Loss: 0.41413205840097117\n",
      "Epoch 196, Loss: 0.4155607826414292\n",
      "Epoch 197, Loss: 0.414238532452658\n",
      "Epoch 198, Loss: 0.41297339310852155\n",
      "Epoch 199, Loss: 0.4123900845056213\n",
      "Epoch 200, Loss: 0.4134311180746695\n",
      "Epoch 201, Loss: 0.4127689164145939\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22255506323264554\n",
      "Test R^2 score: 0.46206589885106575\n",
      "Num of epochs: 202\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Epoch 179, Loss: 0.42867030340024453\n",
      "Epoch 180, Loss: 0.42665902048327814\n",
      "Epoch 181, Loss: 0.4160041986606613\n",
      "Epoch 182, Loss: 0.42380692389414293\n",
      "Epoch 183, Loss: 0.4367609764525626\n",
      "Epoch 184, Loss: 0.42557170506243686\n",
      "Epoch 185, Loss: 0.42106826790053603\n",
      "Epoch 186, Loss: 0.42573876125176086\n",
      "Epoch 187, Loss: 0.41925407360374856\n",
      "Epoch 188, Loss: 0.4183384695092418\n",
      "Epoch 189, Loss: 0.4218813047997579\n",
      "Epoch 190, Loss: 0.4197713005325469\n",
      "Epoch 191, Loss: 0.417197451669247\n",
      "Epoch 192, Loss: 0.41998586832409235\n",
      "Epoch 193, Loss: 0.4198630180807017\n",
      "Epoch 194, Loss: 0.4146118298837611\n",
      "Epoch 195, Loss: 0.41413205840097117\n",
      "Epoch 196, Loss: 0.4155607826414292\n",
      "Epoch 197, Loss: 0.414238532452658\n",
      "Epoch 198, Loss: 0.41297339310852155\n",
      "Epoch 199, Loss: 0.4123900845056213\n",
      "Epoch 200, Loss: 0.4134311180746695\n",
      "Epoch 201, Loss: 0.4127689164145939\n",
      "Epoch 202, Loss: 0.41232720715179455\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2182800087955451\n",
      "Test R^2 score: 0.48256372067813796\n",
      "Num of epochs: 203\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Epoch 179, Loss: 0.42867030340024453\n",
      "Epoch 180, Loss: 0.42665902048327814\n",
      "Epoch 181, Loss: 0.4160041986606613\n",
      "Epoch 182, Loss: 0.42380692389414293\n",
      "Epoch 183, Loss: 0.4367609764525626\n",
      "Epoch 184, Loss: 0.42557170506243686\n",
      "Epoch 185, Loss: 0.42106826790053603\n",
      "Epoch 186, Loss: 0.42573876125176086\n",
      "Epoch 187, Loss: 0.41925407360374856\n",
      "Epoch 188, Loss: 0.4183384695092418\n",
      "Epoch 189, Loss: 0.4218813047997579\n",
      "Epoch 190, Loss: 0.4197713005325469\n",
      "Epoch 191, Loss: 0.417197451669247\n",
      "Epoch 192, Loss: 0.41998586832409235\n",
      "Epoch 193, Loss: 0.4198630180807017\n",
      "Epoch 194, Loss: 0.4146118298837611\n",
      "Epoch 195, Loss: 0.41413205840097117\n",
      "Epoch 196, Loss: 0.4155607826414292\n",
      "Epoch 197, Loss: 0.414238532452658\n",
      "Epoch 198, Loss: 0.41297339310852155\n",
      "Epoch 199, Loss: 0.4123900845056213\n",
      "Epoch 200, Loss: 0.4134311180746695\n",
      "Epoch 201, Loss: 0.4127689164145939\n",
      "Epoch 202, Loss: 0.41232720715179455\n",
      "Epoch 203, Loss: 0.41150345937125327\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22018858397417046\n",
      "Test R^2 score: 0.47332375975070123\n",
      "Num of epochs: 204\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Epoch 179, Loss: 0.42867030340024453\n",
      "Epoch 180, Loss: 0.42665902048327814\n",
      "Epoch 181, Loss: 0.4160041986606613\n",
      "Epoch 182, Loss: 0.42380692389414293\n",
      "Epoch 183, Loss: 0.4367609764525626\n",
      "Epoch 184, Loss: 0.42557170506243686\n",
      "Epoch 185, Loss: 0.42106826790053603\n",
      "Epoch 186, Loss: 0.42573876125176086\n",
      "Epoch 187, Loss: 0.41925407360374856\n",
      "Epoch 188, Loss: 0.4183384695092418\n",
      "Epoch 189, Loss: 0.4218813047997579\n",
      "Epoch 190, Loss: 0.4197713005325469\n",
      "Epoch 191, Loss: 0.417197451669247\n",
      "Epoch 192, Loss: 0.41998586832409235\n",
      "Epoch 193, Loss: 0.4198630180807017\n",
      "Epoch 194, Loss: 0.4146118298837611\n",
      "Epoch 195, Loss: 0.41413205840097117\n",
      "Epoch 196, Loss: 0.4155607826414292\n",
      "Epoch 197, Loss: 0.414238532452658\n",
      "Epoch 198, Loss: 0.41297339310852155\n",
      "Epoch 199, Loss: 0.4123900845056213\n",
      "Epoch 200, Loss: 0.4134311180746695\n",
      "Epoch 201, Loss: 0.4127689164145939\n",
      "Epoch 202, Loss: 0.41232720715179455\n",
      "Epoch 203, Loss: 0.41150345937125327\n",
      "Epoch 204, Loss: 0.4115020652257978\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21652326236868952\n",
      "Test R^2 score: 0.4905775555677588\n",
      "Num of epochs: 205\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Epoch 179, Loss: 0.42867030340024453\n",
      "Epoch 180, Loss: 0.42665902048327814\n",
      "Epoch 181, Loss: 0.4160041986606613\n",
      "Epoch 182, Loss: 0.42380692389414293\n",
      "Epoch 183, Loss: 0.4367609764525626\n",
      "Epoch 184, Loss: 0.42557170506243686\n",
      "Epoch 185, Loss: 0.42106826790053603\n",
      "Epoch 186, Loss: 0.42573876125176086\n",
      "Epoch 187, Loss: 0.41925407360374856\n",
      "Epoch 188, Loss: 0.4183384695092418\n",
      "Epoch 189, Loss: 0.4218813047997579\n",
      "Epoch 190, Loss: 0.4197713005325469\n",
      "Epoch 191, Loss: 0.417197451669247\n",
      "Epoch 192, Loss: 0.41998586832409235\n",
      "Epoch 193, Loss: 0.4198630180807017\n",
      "Epoch 194, Loss: 0.4146118298837611\n",
      "Epoch 195, Loss: 0.41413205840097117\n",
      "Epoch 196, Loss: 0.4155607826414292\n",
      "Epoch 197, Loss: 0.414238532452658\n",
      "Epoch 198, Loss: 0.41297339310852155\n",
      "Epoch 199, Loss: 0.4123900845056213\n",
      "Epoch 200, Loss: 0.4134311180746695\n",
      "Epoch 201, Loss: 0.4127689164145939\n",
      "Epoch 202, Loss: 0.41232720715179455\n",
      "Epoch 203, Loss: 0.41150345937125327\n",
      "Epoch 204, Loss: 0.4115020652257978\n",
      "Epoch 205, Loss: 0.411078297677327\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22142986854242946\n",
      "Test R^2 score: 0.46723067418706143\n",
      "Num of epochs: 206\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Epoch 179, Loss: 0.42867030340024453\n",
      "Epoch 180, Loss: 0.42665902048327814\n",
      "Epoch 181, Loss: 0.4160041986606613\n",
      "Epoch 182, Loss: 0.42380692389414293\n",
      "Epoch 183, Loss: 0.4367609764525626\n",
      "Epoch 184, Loss: 0.42557170506243686\n",
      "Epoch 185, Loss: 0.42106826790053603\n",
      "Epoch 186, Loss: 0.42573876125176086\n",
      "Epoch 187, Loss: 0.41925407360374856\n",
      "Epoch 188, Loss: 0.4183384695092418\n",
      "Epoch 189, Loss: 0.4218813047997579\n",
      "Epoch 190, Loss: 0.4197713005325469\n",
      "Epoch 191, Loss: 0.417197451669247\n",
      "Epoch 192, Loss: 0.41998586832409235\n",
      "Epoch 193, Loss: 0.4198630180807017\n",
      "Epoch 194, Loss: 0.4146118298837611\n",
      "Epoch 195, Loss: 0.41413205840097117\n",
      "Epoch 196, Loss: 0.4155607826414292\n",
      "Epoch 197, Loss: 0.414238532452658\n",
      "Epoch 198, Loss: 0.41297339310852155\n",
      "Epoch 199, Loss: 0.4123900845056213\n",
      "Epoch 200, Loss: 0.4134311180746695\n",
      "Epoch 201, Loss: 0.4127689164145939\n",
      "Epoch 202, Loss: 0.41232720715179455\n",
      "Epoch 203, Loss: 0.41150345937125327\n",
      "Epoch 204, Loss: 0.4115020652257978\n",
      "Epoch 205, Loss: 0.411078297677327\n",
      "Epoch 206, Loss: 0.4110567108542411\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21745498160205126\n",
      "Test R^2 score: 0.4863684112179101\n",
      "Num of epochs: 207\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Epoch 179, Loss: 0.42867030340024453\n",
      "Epoch 180, Loss: 0.42665902048327814\n",
      "Epoch 181, Loss: 0.4160041986606613\n",
      "Epoch 182, Loss: 0.42380692389414293\n",
      "Epoch 183, Loss: 0.4367609764525626\n",
      "Epoch 184, Loss: 0.42557170506243686\n",
      "Epoch 185, Loss: 0.42106826790053603\n",
      "Epoch 186, Loss: 0.42573876125176086\n",
      "Epoch 187, Loss: 0.41925407360374856\n",
      "Epoch 188, Loss: 0.4183384695092418\n",
      "Epoch 189, Loss: 0.4218813047997579\n",
      "Epoch 190, Loss: 0.4197713005325469\n",
      "Epoch 191, Loss: 0.417197451669247\n",
      "Epoch 192, Loss: 0.41998586832409235\n",
      "Epoch 193, Loss: 0.4198630180807017\n",
      "Epoch 194, Loss: 0.4146118298837611\n",
      "Epoch 195, Loss: 0.41413205840097117\n",
      "Epoch 196, Loss: 0.4155607826414292\n",
      "Epoch 197, Loss: 0.414238532452658\n",
      "Epoch 198, Loss: 0.41297339310852155\n",
      "Epoch 199, Loss: 0.4123900845056213\n",
      "Epoch 200, Loss: 0.4134311180746695\n",
      "Epoch 201, Loss: 0.4127689164145939\n",
      "Epoch 202, Loss: 0.41232720715179455\n",
      "Epoch 203, Loss: 0.41150345937125327\n",
      "Epoch 204, Loss: 0.4115020652257978\n",
      "Epoch 205, Loss: 0.411078297677327\n",
      "Epoch 206, Loss: 0.4110567108542411\n",
      "Epoch 207, Loss: 0.4114023806357039\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22454096841598783\n",
      "Test R^2 score: 0.4522353864320205\n",
      "Num of epochs: 208\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Epoch 179, Loss: 0.42867030340024453\n",
      "Epoch 180, Loss: 0.42665902048327814\n",
      "Epoch 181, Loss: 0.4160041986606613\n",
      "Epoch 182, Loss: 0.42380692389414293\n",
      "Epoch 183, Loss: 0.4367609764525626\n",
      "Epoch 184, Loss: 0.42557170506243686\n",
      "Epoch 185, Loss: 0.42106826790053603\n",
      "Epoch 186, Loss: 0.42573876125176086\n",
      "Epoch 187, Loss: 0.41925407360374856\n",
      "Epoch 188, Loss: 0.4183384695092418\n",
      "Epoch 189, Loss: 0.4218813047997579\n",
      "Epoch 190, Loss: 0.4197713005325469\n",
      "Epoch 191, Loss: 0.417197451669247\n",
      "Epoch 192, Loss: 0.41998586832409235\n",
      "Epoch 193, Loss: 0.4198630180807017\n",
      "Epoch 194, Loss: 0.4146118298837611\n",
      "Epoch 195, Loss: 0.41413205840097117\n",
      "Epoch 196, Loss: 0.4155607826414292\n",
      "Epoch 197, Loss: 0.414238532452658\n",
      "Epoch 198, Loss: 0.41297339310852155\n",
      "Epoch 199, Loss: 0.4123900845056213\n",
      "Epoch 200, Loss: 0.4134311180746695\n",
      "Epoch 201, Loss: 0.4127689164145939\n",
      "Epoch 202, Loss: 0.41232720715179455\n",
      "Epoch 203, Loss: 0.41150345937125327\n",
      "Epoch 204, Loss: 0.4115020652257978\n",
      "Epoch 205, Loss: 0.411078297677327\n",
      "Epoch 206, Loss: 0.4110567108542411\n",
      "Epoch 207, Loss: 0.4114023806357039\n",
      "Epoch 208, Loss: 0.41371932293434216\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2188839207860371\n",
      "Test R^2 score: 0.4796275725125862\n",
      "Num of epochs: 209\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Epoch 179, Loss: 0.42867030340024453\n",
      "Epoch 180, Loss: 0.42665902048327814\n",
      "Epoch 181, Loss: 0.4160041986606613\n",
      "Epoch 182, Loss: 0.42380692389414293\n",
      "Epoch 183, Loss: 0.4367609764525626\n",
      "Epoch 184, Loss: 0.42557170506243686\n",
      "Epoch 185, Loss: 0.42106826790053603\n",
      "Epoch 186, Loss: 0.42573876125176086\n",
      "Epoch 187, Loss: 0.41925407360374856\n",
      "Epoch 188, Loss: 0.4183384695092418\n",
      "Epoch 189, Loss: 0.4218813047997579\n",
      "Epoch 190, Loss: 0.4197713005325469\n",
      "Epoch 191, Loss: 0.417197451669247\n",
      "Epoch 192, Loss: 0.41998586832409235\n",
      "Epoch 193, Loss: 0.4198630180807017\n",
      "Epoch 194, Loss: 0.4146118298837611\n",
      "Epoch 195, Loss: 0.41413205840097117\n",
      "Epoch 196, Loss: 0.4155607826414292\n",
      "Epoch 197, Loss: 0.414238532452658\n",
      "Epoch 198, Loss: 0.41297339310852155\n",
      "Epoch 199, Loss: 0.4123900845056213\n",
      "Epoch 200, Loss: 0.4134311180746695\n",
      "Epoch 201, Loss: 0.4127689164145939\n",
      "Epoch 202, Loss: 0.41232720715179455\n",
      "Epoch 203, Loss: 0.41150345937125327\n",
      "Epoch 204, Loss: 0.4115020652257978\n",
      "Epoch 205, Loss: 0.411078297677327\n",
      "Epoch 206, Loss: 0.4110567108542411\n",
      "Epoch 207, Loss: 0.4114023806357039\n",
      "Epoch 208, Loss: 0.41371932293434216\n",
      "Epoch 209, Loss: 0.41813952085771794\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.236551655279667\n",
      "Test R^2 score: 0.39185741266230767\n",
      "Num of epochs: 210\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Epoch 179, Loss: 0.42867030340024453\n",
      "Epoch 180, Loss: 0.42665902048327814\n",
      "Epoch 181, Loss: 0.4160041986606613\n",
      "Epoch 182, Loss: 0.42380692389414293\n",
      "Epoch 183, Loss: 0.4367609764525626\n",
      "Epoch 184, Loss: 0.42557170506243686\n",
      "Epoch 185, Loss: 0.42106826790053603\n",
      "Epoch 186, Loss: 0.42573876125176086\n",
      "Epoch 187, Loss: 0.41925407360374856\n",
      "Epoch 188, Loss: 0.4183384695092418\n",
      "Epoch 189, Loss: 0.4218813047997579\n",
      "Epoch 190, Loss: 0.4197713005325469\n",
      "Epoch 191, Loss: 0.417197451669247\n",
      "Epoch 192, Loss: 0.41998586832409235\n",
      "Epoch 193, Loss: 0.4198630180807017\n",
      "Epoch 194, Loss: 0.4146118298837611\n",
      "Epoch 195, Loss: 0.41413205840097117\n",
      "Epoch 196, Loss: 0.4155607826414292\n",
      "Epoch 197, Loss: 0.414238532452658\n",
      "Epoch 198, Loss: 0.41297339310852155\n",
      "Epoch 199, Loss: 0.4123900845056213\n",
      "Epoch 200, Loss: 0.4134311180746695\n",
      "Epoch 201, Loss: 0.4127689164145939\n",
      "Epoch 202, Loss: 0.41232720715179455\n",
      "Epoch 203, Loss: 0.41150345937125327\n",
      "Epoch 204, Loss: 0.4115020652257978\n",
      "Epoch 205, Loss: 0.411078297677327\n",
      "Epoch 206, Loss: 0.4110567108542411\n",
      "Epoch 207, Loss: 0.4114023806357039\n",
      "Epoch 208, Loss: 0.41371932293434216\n",
      "Epoch 209, Loss: 0.41813952085771794\n",
      "Epoch 210, Loss: 0.42511728996367454\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2211747110458674\n",
      "Test R^2 score: 0.46870809998560586\n",
      "Num of epochs: 211\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Epoch 179, Loss: 0.42867030340024453\n",
      "Epoch 180, Loss: 0.42665902048327814\n",
      "Epoch 181, Loss: 0.4160041986606613\n",
      "Epoch 182, Loss: 0.42380692389414293\n",
      "Epoch 183, Loss: 0.4367609764525626\n",
      "Epoch 184, Loss: 0.42557170506243686\n",
      "Epoch 185, Loss: 0.42106826790053603\n",
      "Epoch 186, Loss: 0.42573876125176086\n",
      "Epoch 187, Loss: 0.41925407360374856\n",
      "Epoch 188, Loss: 0.4183384695092418\n",
      "Epoch 189, Loss: 0.4218813047997579\n",
      "Epoch 190, Loss: 0.4197713005325469\n",
      "Epoch 191, Loss: 0.417197451669247\n",
      "Epoch 192, Loss: 0.41998586832409235\n",
      "Epoch 193, Loss: 0.4198630180807017\n",
      "Epoch 194, Loss: 0.4146118298837611\n",
      "Epoch 195, Loss: 0.41413205840097117\n",
      "Epoch 196, Loss: 0.4155607826414292\n",
      "Epoch 197, Loss: 0.414238532452658\n",
      "Epoch 198, Loss: 0.41297339310852155\n",
      "Epoch 199, Loss: 0.4123900845056213\n",
      "Epoch 200, Loss: 0.4134311180746695\n",
      "Epoch 201, Loss: 0.4127689164145939\n",
      "Epoch 202, Loss: 0.41232720715179455\n",
      "Epoch 203, Loss: 0.41150345937125327\n",
      "Epoch 204, Loss: 0.4115020652257978\n",
      "Epoch 205, Loss: 0.411078297677327\n",
      "Epoch 206, Loss: 0.4110567108542411\n",
      "Epoch 207, Loss: 0.4114023806357039\n",
      "Epoch 208, Loss: 0.41371932293434216\n",
      "Epoch 209, Loss: 0.41813952085771794\n",
      "Epoch 210, Loss: 0.42511728996367454\n",
      "Epoch 211, Loss: 0.42635158522503447\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22664753318961314\n",
      "Test R^2 score: 0.4419159307386303\n",
      "Num of epochs: 212\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Epoch 179, Loss: 0.42867030340024453\n",
      "Epoch 180, Loss: 0.42665902048327814\n",
      "Epoch 181, Loss: 0.4160041986606613\n",
      "Epoch 182, Loss: 0.42380692389414293\n",
      "Epoch 183, Loss: 0.4367609764525626\n",
      "Epoch 184, Loss: 0.42557170506243686\n",
      "Epoch 185, Loss: 0.42106826790053603\n",
      "Epoch 186, Loss: 0.42573876125176086\n",
      "Epoch 187, Loss: 0.41925407360374856\n",
      "Epoch 188, Loss: 0.4183384695092418\n",
      "Epoch 189, Loss: 0.4218813047997579\n",
      "Epoch 190, Loss: 0.4197713005325469\n",
      "Epoch 191, Loss: 0.417197451669247\n",
      "Epoch 192, Loss: 0.41998586832409235\n",
      "Epoch 193, Loss: 0.4198630180807017\n",
      "Epoch 194, Loss: 0.4146118298837611\n",
      "Epoch 195, Loss: 0.41413205840097117\n",
      "Epoch 196, Loss: 0.4155607826414292\n",
      "Epoch 197, Loss: 0.414238532452658\n",
      "Epoch 198, Loss: 0.41297339310852155\n",
      "Epoch 199, Loss: 0.4123900845056213\n",
      "Epoch 200, Loss: 0.4134311180746695\n",
      "Epoch 201, Loss: 0.4127689164145939\n",
      "Epoch 202, Loss: 0.41232720715179455\n",
      "Epoch 203, Loss: 0.41150345937125327\n",
      "Epoch 204, Loss: 0.4115020652257978\n",
      "Epoch 205, Loss: 0.411078297677327\n",
      "Epoch 206, Loss: 0.4110567108542411\n",
      "Epoch 207, Loss: 0.4114023806357039\n",
      "Epoch 208, Loss: 0.41371932293434216\n",
      "Epoch 209, Loss: 0.41813952085771794\n",
      "Epoch 210, Loss: 0.42511728996367454\n",
      "Epoch 211, Loss: 0.42635158522503447\n",
      "Epoch 212, Loss: 0.419673136297028\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21672963159808128\n",
      "Test R^2 score: 0.48963498398547417\n",
      "Num of epochs: 213\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Epoch 179, Loss: 0.42867030340024453\n",
      "Epoch 180, Loss: 0.42665902048327814\n",
      "Epoch 181, Loss: 0.4160041986606613\n",
      "Epoch 182, Loss: 0.42380692389414293\n",
      "Epoch 183, Loss: 0.4367609764525626\n",
      "Epoch 184, Loss: 0.42557170506243686\n",
      "Epoch 185, Loss: 0.42106826790053603\n",
      "Epoch 186, Loss: 0.42573876125176086\n",
      "Epoch 187, Loss: 0.41925407360374856\n",
      "Epoch 188, Loss: 0.4183384695092418\n",
      "Epoch 189, Loss: 0.4218813047997579\n",
      "Epoch 190, Loss: 0.4197713005325469\n",
      "Epoch 191, Loss: 0.417197451669247\n",
      "Epoch 192, Loss: 0.41998586832409235\n",
      "Epoch 193, Loss: 0.4198630180807017\n",
      "Epoch 194, Loss: 0.4146118298837611\n",
      "Epoch 195, Loss: 0.41413205840097117\n",
      "Epoch 196, Loss: 0.4155607826414292\n",
      "Epoch 197, Loss: 0.414238532452658\n",
      "Epoch 198, Loss: 0.41297339310852155\n",
      "Epoch 199, Loss: 0.4123900845056213\n",
      "Epoch 200, Loss: 0.4134311180746695\n",
      "Epoch 201, Loss: 0.4127689164145939\n",
      "Epoch 202, Loss: 0.41232720715179455\n",
      "Epoch 203, Loss: 0.41150345937125327\n",
      "Epoch 204, Loss: 0.4115020652257978\n",
      "Epoch 205, Loss: 0.411078297677327\n",
      "Epoch 206, Loss: 0.4110567108542411\n",
      "Epoch 207, Loss: 0.4114023806357039\n",
      "Epoch 208, Loss: 0.41371932293434216\n",
      "Epoch 209, Loss: 0.41813952085771794\n",
      "Epoch 210, Loss: 0.42511728996367454\n",
      "Epoch 211, Loss: 0.42635158522503447\n",
      "Epoch 212, Loss: 0.419673136297028\n",
      "Epoch 213, Loss: 0.41005224089892217\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22014164178057322\n",
      "Test R^2 score: 0.47410399856288726\n",
      "Num of epochs: 214\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Epoch 179, Loss: 0.42867030340024453\n",
      "Epoch 180, Loss: 0.42665902048327814\n",
      "Epoch 181, Loss: 0.4160041986606613\n",
      "Epoch 182, Loss: 0.42380692389414293\n",
      "Epoch 183, Loss: 0.4367609764525626\n",
      "Epoch 184, Loss: 0.42557170506243686\n",
      "Epoch 185, Loss: 0.42106826790053603\n",
      "Epoch 186, Loss: 0.42573876125176086\n",
      "Epoch 187, Loss: 0.41925407360374856\n",
      "Epoch 188, Loss: 0.4183384695092418\n",
      "Epoch 189, Loss: 0.4218813047997579\n",
      "Epoch 190, Loss: 0.4197713005325469\n",
      "Epoch 191, Loss: 0.417197451669247\n",
      "Epoch 192, Loss: 0.41998586832409235\n",
      "Epoch 193, Loss: 0.4198630180807017\n",
      "Epoch 194, Loss: 0.4146118298837611\n",
      "Epoch 195, Loss: 0.41413205840097117\n",
      "Epoch 196, Loss: 0.4155607826414292\n",
      "Epoch 197, Loss: 0.414238532452658\n",
      "Epoch 198, Loss: 0.41297339310852155\n",
      "Epoch 199, Loss: 0.4123900845056213\n",
      "Epoch 200, Loss: 0.4134311180746695\n",
      "Epoch 201, Loss: 0.4127689164145939\n",
      "Epoch 202, Loss: 0.41232720715179455\n",
      "Epoch 203, Loss: 0.41150345937125327\n",
      "Epoch 204, Loss: 0.4115020652257978\n",
      "Epoch 205, Loss: 0.411078297677327\n",
      "Epoch 206, Loss: 0.4110567108542411\n",
      "Epoch 207, Loss: 0.4114023806357039\n",
      "Epoch 208, Loss: 0.41371932293434216\n",
      "Epoch 209, Loss: 0.41813952085771794\n",
      "Epoch 210, Loss: 0.42511728996367454\n",
      "Epoch 211, Loss: 0.42635158522503447\n",
      "Epoch 212, Loss: 0.419673136297028\n",
      "Epoch 213, Loss: 0.41005224089892217\n",
      "Epoch 214, Loss: 0.4205638856971283\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.239939676420289\n",
      "Test R^2 score: 0.3744616205422112\n",
      "Num of epochs: 215\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Epoch 179, Loss: 0.42867030340024453\n",
      "Epoch 180, Loss: 0.42665902048327814\n",
      "Epoch 181, Loss: 0.4160041986606613\n",
      "Epoch 182, Loss: 0.42380692389414293\n",
      "Epoch 183, Loss: 0.4367609764525626\n",
      "Epoch 184, Loss: 0.42557170506243686\n",
      "Epoch 185, Loss: 0.42106826790053603\n",
      "Epoch 186, Loss: 0.42573876125176086\n",
      "Epoch 187, Loss: 0.41925407360374856\n",
      "Epoch 188, Loss: 0.4183384695092418\n",
      "Epoch 189, Loss: 0.4218813047997579\n",
      "Epoch 190, Loss: 0.4197713005325469\n",
      "Epoch 191, Loss: 0.417197451669247\n",
      "Epoch 192, Loss: 0.41998586832409235\n",
      "Epoch 193, Loss: 0.4198630180807017\n",
      "Epoch 194, Loss: 0.4146118298837611\n",
      "Epoch 195, Loss: 0.41413205840097117\n",
      "Epoch 196, Loss: 0.4155607826414292\n",
      "Epoch 197, Loss: 0.414238532452658\n",
      "Epoch 198, Loss: 0.41297339310852155\n",
      "Epoch 199, Loss: 0.4123900845056213\n",
      "Epoch 200, Loss: 0.4134311180746695\n",
      "Epoch 201, Loss: 0.4127689164145939\n",
      "Epoch 202, Loss: 0.41232720715179455\n",
      "Epoch 203, Loss: 0.41150345937125327\n",
      "Epoch 204, Loss: 0.4115020652257978\n",
      "Epoch 205, Loss: 0.411078297677327\n",
      "Epoch 206, Loss: 0.4110567108542411\n",
      "Epoch 207, Loss: 0.4114023806357039\n",
      "Epoch 208, Loss: 0.41371932293434216\n",
      "Epoch 209, Loss: 0.41813952085771794\n",
      "Epoch 210, Loss: 0.42511728996367454\n",
      "Epoch 211, Loss: 0.42635158522503447\n",
      "Epoch 212, Loss: 0.419673136297028\n",
      "Epoch 213, Loss: 0.41005224089892217\n",
      "Epoch 214, Loss: 0.4205638856971283\n",
      "Epoch 215, Loss: 0.4288454648496258\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2172501588651001\n",
      "Test R^2 score: 0.4871465678381168\n",
      "Num of epochs: 216\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Epoch 179, Loss: 0.42867030340024453\n",
      "Epoch 180, Loss: 0.42665902048327814\n",
      "Epoch 181, Loss: 0.4160041986606613\n",
      "Epoch 182, Loss: 0.42380692389414293\n",
      "Epoch 183, Loss: 0.4367609764525626\n",
      "Epoch 184, Loss: 0.42557170506243686\n",
      "Epoch 185, Loss: 0.42106826790053603\n",
      "Epoch 186, Loss: 0.42573876125176086\n",
      "Epoch 187, Loss: 0.41925407360374856\n",
      "Epoch 188, Loss: 0.4183384695092418\n",
      "Epoch 189, Loss: 0.4218813047997579\n",
      "Epoch 190, Loss: 0.4197713005325469\n",
      "Epoch 191, Loss: 0.417197451669247\n",
      "Epoch 192, Loss: 0.41998586832409235\n",
      "Epoch 193, Loss: 0.4198630180807017\n",
      "Epoch 194, Loss: 0.4146118298837611\n",
      "Epoch 195, Loss: 0.41413205840097117\n",
      "Epoch 196, Loss: 0.4155607826414292\n",
      "Epoch 197, Loss: 0.414238532452658\n",
      "Epoch 198, Loss: 0.41297339310852155\n",
      "Epoch 199, Loss: 0.4123900845056213\n",
      "Epoch 200, Loss: 0.4134311180746695\n",
      "Epoch 201, Loss: 0.4127689164145939\n",
      "Epoch 202, Loss: 0.41232720715179455\n",
      "Epoch 203, Loss: 0.41150345937125327\n",
      "Epoch 204, Loss: 0.4115020652257978\n",
      "Epoch 205, Loss: 0.411078297677327\n",
      "Epoch 206, Loss: 0.4110567108542411\n",
      "Epoch 207, Loss: 0.4114023806357039\n",
      "Epoch 208, Loss: 0.41371932293434216\n",
      "Epoch 209, Loss: 0.41813952085771794\n",
      "Epoch 210, Loss: 0.42511728996367454\n",
      "Epoch 211, Loss: 0.42635158522503447\n",
      "Epoch 212, Loss: 0.419673136297028\n",
      "Epoch 213, Loss: 0.41005224089892217\n",
      "Epoch 214, Loss: 0.4205638856971283\n",
      "Epoch 215, Loss: 0.4288454648496258\n",
      "Epoch 216, Loss: 0.416730043439161\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21487606124582528\n",
      "Test R^2 score: 0.4983434236781004\n",
      "Num of epochs: 217\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Epoch 179, Loss: 0.42867030340024453\n",
      "Epoch 180, Loss: 0.42665902048327814\n",
      "Epoch 181, Loss: 0.4160041986606613\n",
      "Epoch 182, Loss: 0.42380692389414293\n",
      "Epoch 183, Loss: 0.4367609764525626\n",
      "Epoch 184, Loss: 0.42557170506243686\n",
      "Epoch 185, Loss: 0.42106826790053603\n",
      "Epoch 186, Loss: 0.42573876125176086\n",
      "Epoch 187, Loss: 0.41925407360374856\n",
      "Epoch 188, Loss: 0.4183384695092418\n",
      "Epoch 189, Loss: 0.4218813047997579\n",
      "Epoch 190, Loss: 0.4197713005325469\n",
      "Epoch 191, Loss: 0.417197451669247\n",
      "Epoch 192, Loss: 0.41998586832409235\n",
      "Epoch 193, Loss: 0.4198630180807017\n",
      "Epoch 194, Loss: 0.4146118298837611\n",
      "Epoch 195, Loss: 0.41413205840097117\n",
      "Epoch 196, Loss: 0.4155607826414292\n",
      "Epoch 197, Loss: 0.414238532452658\n",
      "Epoch 198, Loss: 0.41297339310852155\n",
      "Epoch 199, Loss: 0.4123900845056213\n",
      "Epoch 200, Loss: 0.4134311180746695\n",
      "Epoch 201, Loss: 0.4127689164145939\n",
      "Epoch 202, Loss: 0.41232720715179455\n",
      "Epoch 203, Loss: 0.41150345937125327\n",
      "Epoch 204, Loss: 0.4115020652257978\n",
      "Epoch 205, Loss: 0.411078297677327\n",
      "Epoch 206, Loss: 0.4110567108542411\n",
      "Epoch 207, Loss: 0.4114023806357039\n",
      "Epoch 208, Loss: 0.41371932293434216\n",
      "Epoch 209, Loss: 0.41813952085771794\n",
      "Epoch 210, Loss: 0.42511728996367454\n",
      "Epoch 211, Loss: 0.42635158522503447\n",
      "Epoch 212, Loss: 0.419673136297028\n",
      "Epoch 213, Loss: 0.41005224089892217\n",
      "Epoch 214, Loss: 0.4205638856971283\n",
      "Epoch 215, Loss: 0.4288454648496258\n",
      "Epoch 216, Loss: 0.416730043439161\n",
      "Epoch 217, Loss: 0.4131035226095487\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2288242198990335\n",
      "Test R^2 score: 0.43134831332041873\n",
      "Num of epochs: 218\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Epoch 179, Loss: 0.42867030340024453\n",
      "Epoch 180, Loss: 0.42665902048327814\n",
      "Epoch 181, Loss: 0.4160041986606613\n",
      "Epoch 182, Loss: 0.42380692389414293\n",
      "Epoch 183, Loss: 0.4367609764525626\n",
      "Epoch 184, Loss: 0.42557170506243686\n",
      "Epoch 185, Loss: 0.42106826790053603\n",
      "Epoch 186, Loss: 0.42573876125176086\n",
      "Epoch 187, Loss: 0.41925407360374856\n",
      "Epoch 188, Loss: 0.4183384695092418\n",
      "Epoch 189, Loss: 0.4218813047997579\n",
      "Epoch 190, Loss: 0.4197713005325469\n",
      "Epoch 191, Loss: 0.417197451669247\n",
      "Epoch 192, Loss: 0.41998586832409235\n",
      "Epoch 193, Loss: 0.4198630180807017\n",
      "Epoch 194, Loss: 0.4146118298837611\n",
      "Epoch 195, Loss: 0.41413205840097117\n",
      "Epoch 196, Loss: 0.4155607826414292\n",
      "Epoch 197, Loss: 0.414238532452658\n",
      "Epoch 198, Loss: 0.41297339310852155\n",
      "Epoch 199, Loss: 0.4123900845056213\n",
      "Epoch 200, Loss: 0.4134311180746695\n",
      "Epoch 201, Loss: 0.4127689164145939\n",
      "Epoch 202, Loss: 0.41232720715179455\n",
      "Epoch 203, Loss: 0.41150345937125327\n",
      "Epoch 204, Loss: 0.4115020652257978\n",
      "Epoch 205, Loss: 0.411078297677327\n",
      "Epoch 206, Loss: 0.4110567108542411\n",
      "Epoch 207, Loss: 0.4114023806357039\n",
      "Epoch 208, Loss: 0.41371932293434216\n",
      "Epoch 209, Loss: 0.41813952085771794\n",
      "Epoch 210, Loss: 0.42511728996367454\n",
      "Epoch 211, Loss: 0.42635158522503447\n",
      "Epoch 212, Loss: 0.419673136297028\n",
      "Epoch 213, Loss: 0.41005224089892217\n",
      "Epoch 214, Loss: 0.4205638856971283\n",
      "Epoch 215, Loss: 0.4288454648496258\n",
      "Epoch 216, Loss: 0.416730043439161\n",
      "Epoch 217, Loss: 0.4131035226095487\n",
      "Epoch 218, Loss: 0.41919050177663497\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2169729102400522\n",
      "Test R^2 score: 0.4892117709385873\n",
      "Num of epochs: 219\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Epoch 179, Loss: 0.42867030340024453\n",
      "Epoch 180, Loss: 0.42665902048327814\n",
      "Epoch 181, Loss: 0.4160041986606613\n",
      "Epoch 182, Loss: 0.42380692389414293\n",
      "Epoch 183, Loss: 0.4367609764525626\n",
      "Epoch 184, Loss: 0.42557170506243686\n",
      "Epoch 185, Loss: 0.42106826790053603\n",
      "Epoch 186, Loss: 0.42573876125176086\n",
      "Epoch 187, Loss: 0.41925407360374856\n",
      "Epoch 188, Loss: 0.4183384695092418\n",
      "Epoch 189, Loss: 0.4218813047997579\n",
      "Epoch 190, Loss: 0.4197713005325469\n",
      "Epoch 191, Loss: 0.417197451669247\n",
      "Epoch 192, Loss: 0.41998586832409235\n",
      "Epoch 193, Loss: 0.4198630180807017\n",
      "Epoch 194, Loss: 0.4146118298837611\n",
      "Epoch 195, Loss: 0.41413205840097117\n",
      "Epoch 196, Loss: 0.4155607826414292\n",
      "Epoch 197, Loss: 0.414238532452658\n",
      "Epoch 198, Loss: 0.41297339310852155\n",
      "Epoch 199, Loss: 0.4123900845056213\n",
      "Epoch 200, Loss: 0.4134311180746695\n",
      "Epoch 201, Loss: 0.4127689164145939\n",
      "Epoch 202, Loss: 0.41232720715179455\n",
      "Epoch 203, Loss: 0.41150345937125327\n",
      "Epoch 204, Loss: 0.4115020652257978\n",
      "Epoch 205, Loss: 0.411078297677327\n",
      "Epoch 206, Loss: 0.4110567108542411\n",
      "Epoch 207, Loss: 0.4114023806357039\n",
      "Epoch 208, Loss: 0.41371932293434216\n",
      "Epoch 209, Loss: 0.41813952085771794\n",
      "Epoch 210, Loss: 0.42511728996367454\n",
      "Epoch 211, Loss: 0.42635158522503447\n",
      "Epoch 212, Loss: 0.419673136297028\n",
      "Epoch 213, Loss: 0.41005224089892217\n",
      "Epoch 214, Loss: 0.4205638856971283\n",
      "Epoch 215, Loss: 0.4288454648496258\n",
      "Epoch 216, Loss: 0.416730043439161\n",
      "Epoch 217, Loss: 0.4131035226095487\n",
      "Epoch 218, Loss: 0.41919050177663497\n",
      "Epoch 219, Loss: 0.41341632229404196\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21468027294418898\n",
      "Test R^2 score: 0.499681202527148\n",
      "Num of epochs: 220\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Epoch 179, Loss: 0.42867030340024453\n",
      "Epoch 180, Loss: 0.42665902048327814\n",
      "Epoch 181, Loss: 0.4160041986606613\n",
      "Epoch 182, Loss: 0.42380692389414293\n",
      "Epoch 183, Loss: 0.4367609764525626\n",
      "Epoch 184, Loss: 0.42557170506243686\n",
      "Epoch 185, Loss: 0.42106826790053603\n",
      "Epoch 186, Loss: 0.42573876125176086\n",
      "Epoch 187, Loss: 0.41925407360374856\n",
      "Epoch 188, Loss: 0.4183384695092418\n",
      "Epoch 189, Loss: 0.4218813047997579\n",
      "Epoch 190, Loss: 0.4197713005325469\n",
      "Epoch 191, Loss: 0.417197451669247\n",
      "Epoch 192, Loss: 0.41998586832409235\n",
      "Epoch 193, Loss: 0.4198630180807017\n",
      "Epoch 194, Loss: 0.4146118298837611\n",
      "Epoch 195, Loss: 0.41413205840097117\n",
      "Epoch 196, Loss: 0.4155607826414292\n",
      "Epoch 197, Loss: 0.414238532452658\n",
      "Epoch 198, Loss: 0.41297339310852155\n",
      "Epoch 199, Loss: 0.4123900845056213\n",
      "Epoch 200, Loss: 0.4134311180746695\n",
      "Epoch 201, Loss: 0.4127689164145939\n",
      "Epoch 202, Loss: 0.41232720715179455\n",
      "Epoch 203, Loss: 0.41150345937125327\n",
      "Epoch 204, Loss: 0.4115020652257978\n",
      "Epoch 205, Loss: 0.411078297677327\n",
      "Epoch 206, Loss: 0.4110567108542411\n",
      "Epoch 207, Loss: 0.4114023806357039\n",
      "Epoch 208, Loss: 0.41371932293434216\n",
      "Epoch 209, Loss: 0.41813952085771794\n",
      "Epoch 210, Loss: 0.42511728996367454\n",
      "Epoch 211, Loss: 0.42635158522503447\n",
      "Epoch 212, Loss: 0.419673136297028\n",
      "Epoch 213, Loss: 0.41005224089892217\n",
      "Epoch 214, Loss: 0.4205638856971283\n",
      "Epoch 215, Loss: 0.4288454648496258\n",
      "Epoch 216, Loss: 0.416730043439161\n",
      "Epoch 217, Loss: 0.4131035226095487\n",
      "Epoch 218, Loss: 0.41919050177663497\n",
      "Epoch 219, Loss: 0.41341632229404196\n",
      "Epoch 220, Loss: 0.411337015720657\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22176874410240016\n",
      "Test R^2 score: 0.4658803634551907\n",
      "Num of epochs: 221\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Epoch 179, Loss: 0.42867030340024453\n",
      "Epoch 180, Loss: 0.42665902048327814\n",
      "Epoch 181, Loss: 0.4160041986606613\n",
      "Epoch 182, Loss: 0.42380692389414293\n",
      "Epoch 183, Loss: 0.4367609764525626\n",
      "Epoch 184, Loss: 0.42557170506243686\n",
      "Epoch 185, Loss: 0.42106826790053603\n",
      "Epoch 186, Loss: 0.42573876125176086\n",
      "Epoch 187, Loss: 0.41925407360374856\n",
      "Epoch 188, Loss: 0.4183384695092418\n",
      "Epoch 189, Loss: 0.4218813047997579\n",
      "Epoch 190, Loss: 0.4197713005325469\n",
      "Epoch 191, Loss: 0.417197451669247\n",
      "Epoch 192, Loss: 0.41998586832409235\n",
      "Epoch 193, Loss: 0.4198630180807017\n",
      "Epoch 194, Loss: 0.4146118298837611\n",
      "Epoch 195, Loss: 0.41413205840097117\n",
      "Epoch 196, Loss: 0.4155607826414292\n",
      "Epoch 197, Loss: 0.414238532452658\n",
      "Epoch 198, Loss: 0.41297339310852155\n",
      "Epoch 199, Loss: 0.4123900845056213\n",
      "Epoch 200, Loss: 0.4134311180746695\n",
      "Epoch 201, Loss: 0.4127689164145939\n",
      "Epoch 202, Loss: 0.41232720715179455\n",
      "Epoch 203, Loss: 0.41150345937125327\n",
      "Epoch 204, Loss: 0.4115020652257978\n",
      "Epoch 205, Loss: 0.411078297677327\n",
      "Epoch 206, Loss: 0.4110567108542411\n",
      "Epoch 207, Loss: 0.4114023806357039\n",
      "Epoch 208, Loss: 0.41371932293434216\n",
      "Epoch 209, Loss: 0.41813952085771794\n",
      "Epoch 210, Loss: 0.42511728996367454\n",
      "Epoch 211, Loss: 0.42635158522503447\n",
      "Epoch 212, Loss: 0.419673136297028\n",
      "Epoch 213, Loss: 0.41005224089892217\n",
      "Epoch 214, Loss: 0.4205638856971283\n",
      "Epoch 215, Loss: 0.4288454648496258\n",
      "Epoch 216, Loss: 0.416730043439161\n",
      "Epoch 217, Loss: 0.4131035226095487\n",
      "Epoch 218, Loss: 0.41919050177663497\n",
      "Epoch 219, Loss: 0.41341632229404196\n",
      "Epoch 220, Loss: 0.411337015720657\n",
      "Epoch 221, Loss: 0.4153124279254653\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21459395278832427\n",
      "Test R^2 score: 0.4998898436139997\n",
      "Num of epochs: 222\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Epoch 179, Loss: 0.42867030340024453\n",
      "Epoch 180, Loss: 0.42665902048327814\n",
      "Epoch 181, Loss: 0.4160041986606613\n",
      "Epoch 182, Loss: 0.42380692389414293\n",
      "Epoch 183, Loss: 0.4367609764525626\n",
      "Epoch 184, Loss: 0.42557170506243686\n",
      "Epoch 185, Loss: 0.42106826790053603\n",
      "Epoch 186, Loss: 0.42573876125176086\n",
      "Epoch 187, Loss: 0.41925407360374856\n",
      "Epoch 188, Loss: 0.4183384695092418\n",
      "Epoch 189, Loss: 0.4218813047997579\n",
      "Epoch 190, Loss: 0.4197713005325469\n",
      "Epoch 191, Loss: 0.417197451669247\n",
      "Epoch 192, Loss: 0.41998586832409235\n",
      "Epoch 193, Loss: 0.4198630180807017\n",
      "Epoch 194, Loss: 0.4146118298837611\n",
      "Epoch 195, Loss: 0.41413205840097117\n",
      "Epoch 196, Loss: 0.4155607826414292\n",
      "Epoch 197, Loss: 0.414238532452658\n",
      "Epoch 198, Loss: 0.41297339310852155\n",
      "Epoch 199, Loss: 0.4123900845056213\n",
      "Epoch 200, Loss: 0.4134311180746695\n",
      "Epoch 201, Loss: 0.4127689164145939\n",
      "Epoch 202, Loss: 0.41232720715179455\n",
      "Epoch 203, Loss: 0.41150345937125327\n",
      "Epoch 204, Loss: 0.4115020652257978\n",
      "Epoch 205, Loss: 0.411078297677327\n",
      "Epoch 206, Loss: 0.4110567108542411\n",
      "Epoch 207, Loss: 0.4114023806357039\n",
      "Epoch 208, Loss: 0.41371932293434216\n",
      "Epoch 209, Loss: 0.41813952085771794\n",
      "Epoch 210, Loss: 0.42511728996367454\n",
      "Epoch 211, Loss: 0.42635158522503447\n",
      "Epoch 212, Loss: 0.419673136297028\n",
      "Epoch 213, Loss: 0.41005224089892217\n",
      "Epoch 214, Loss: 0.4205638856971283\n",
      "Epoch 215, Loss: 0.4288454648496258\n",
      "Epoch 216, Loss: 0.416730043439161\n",
      "Epoch 217, Loss: 0.4131035226095487\n",
      "Epoch 218, Loss: 0.41919050177663497\n",
      "Epoch 219, Loss: 0.41341632229404196\n",
      "Epoch 220, Loss: 0.411337015720657\n",
      "Epoch 221, Loss: 0.4153124279254653\n",
      "Epoch 222, Loss: 0.4104582809838288\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21712669493456324\n",
      "Test R^2 score: 0.48851793026347434\n",
      "Num of epochs: 223\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Epoch 179, Loss: 0.42867030340024453\n",
      "Epoch 180, Loss: 0.42665902048327814\n",
      "Epoch 181, Loss: 0.4160041986606613\n",
      "Epoch 182, Loss: 0.42380692389414293\n",
      "Epoch 183, Loss: 0.4367609764525626\n",
      "Epoch 184, Loss: 0.42557170506243686\n",
      "Epoch 185, Loss: 0.42106826790053603\n",
      "Epoch 186, Loss: 0.42573876125176086\n",
      "Epoch 187, Loss: 0.41925407360374856\n",
      "Epoch 188, Loss: 0.4183384695092418\n",
      "Epoch 189, Loss: 0.4218813047997579\n",
      "Epoch 190, Loss: 0.4197713005325469\n",
      "Epoch 191, Loss: 0.417197451669247\n",
      "Epoch 192, Loss: 0.41998586832409235\n",
      "Epoch 193, Loss: 0.4198630180807017\n",
      "Epoch 194, Loss: 0.4146118298837611\n",
      "Epoch 195, Loss: 0.41413205840097117\n",
      "Epoch 196, Loss: 0.4155607826414292\n",
      "Epoch 197, Loss: 0.414238532452658\n",
      "Epoch 198, Loss: 0.41297339310852155\n",
      "Epoch 199, Loss: 0.4123900845056213\n",
      "Epoch 200, Loss: 0.4134311180746695\n",
      "Epoch 201, Loss: 0.4127689164145939\n",
      "Epoch 202, Loss: 0.41232720715179455\n",
      "Epoch 203, Loss: 0.41150345937125327\n",
      "Epoch 204, Loss: 0.4115020652257978\n",
      "Epoch 205, Loss: 0.411078297677327\n",
      "Epoch 206, Loss: 0.4110567108542411\n",
      "Epoch 207, Loss: 0.4114023806357039\n",
      "Epoch 208, Loss: 0.41371932293434216\n",
      "Epoch 209, Loss: 0.41813952085771794\n",
      "Epoch 210, Loss: 0.42511728996367454\n",
      "Epoch 211, Loss: 0.42635158522503447\n",
      "Epoch 212, Loss: 0.419673136297028\n",
      "Epoch 213, Loss: 0.41005224089892217\n",
      "Epoch 214, Loss: 0.4205638856971283\n",
      "Epoch 215, Loss: 0.4288454648496258\n",
      "Epoch 216, Loss: 0.416730043439161\n",
      "Epoch 217, Loss: 0.4131035226095487\n",
      "Epoch 218, Loss: 0.41919050177663497\n",
      "Epoch 219, Loss: 0.41341632229404196\n",
      "Epoch 220, Loss: 0.411337015720657\n",
      "Epoch 221, Loss: 0.4153124279254653\n",
      "Epoch 222, Loss: 0.4104582809838288\n",
      "Epoch 223, Loss: 0.4101367219181661\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2311438726370465\n",
      "Test R^2 score: 0.4199261144227355\n",
      "Num of epochs: 224\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Epoch 179, Loss: 0.42867030340024453\n",
      "Epoch 180, Loss: 0.42665902048327814\n",
      "Epoch 181, Loss: 0.4160041986606613\n",
      "Epoch 182, Loss: 0.42380692389414293\n",
      "Epoch 183, Loss: 0.4367609764525626\n",
      "Epoch 184, Loss: 0.42557170506243686\n",
      "Epoch 185, Loss: 0.42106826790053603\n",
      "Epoch 186, Loss: 0.42573876125176086\n",
      "Epoch 187, Loss: 0.41925407360374856\n",
      "Epoch 188, Loss: 0.4183384695092418\n",
      "Epoch 189, Loss: 0.4218813047997579\n",
      "Epoch 190, Loss: 0.4197713005325469\n",
      "Epoch 191, Loss: 0.417197451669247\n",
      "Epoch 192, Loss: 0.41998586832409235\n",
      "Epoch 193, Loss: 0.4198630180807017\n",
      "Epoch 194, Loss: 0.4146118298837611\n",
      "Epoch 195, Loss: 0.41413205840097117\n",
      "Epoch 196, Loss: 0.4155607826414292\n",
      "Epoch 197, Loss: 0.414238532452658\n",
      "Epoch 198, Loss: 0.41297339310852155\n",
      "Epoch 199, Loss: 0.4123900845056213\n",
      "Epoch 200, Loss: 0.4134311180746695\n",
      "Epoch 201, Loss: 0.4127689164145939\n",
      "Epoch 202, Loss: 0.41232720715179455\n",
      "Epoch 203, Loss: 0.41150345937125327\n",
      "Epoch 204, Loss: 0.4115020652257978\n",
      "Epoch 205, Loss: 0.411078297677327\n",
      "Epoch 206, Loss: 0.4110567108542411\n",
      "Epoch 207, Loss: 0.4114023806357039\n",
      "Epoch 208, Loss: 0.41371932293434216\n",
      "Epoch 209, Loss: 0.41813952085771794\n",
      "Epoch 210, Loss: 0.42511728996367454\n",
      "Epoch 211, Loss: 0.42635158522503447\n",
      "Epoch 212, Loss: 0.419673136297028\n",
      "Epoch 213, Loss: 0.41005224089892217\n",
      "Epoch 214, Loss: 0.4205638856971283\n",
      "Epoch 215, Loss: 0.4288454648496258\n",
      "Epoch 216, Loss: 0.416730043439161\n",
      "Epoch 217, Loss: 0.4131035226095487\n",
      "Epoch 218, Loss: 0.41919050177663497\n",
      "Epoch 219, Loss: 0.41341632229404196\n",
      "Epoch 220, Loss: 0.411337015720657\n",
      "Epoch 221, Loss: 0.4153124279254653\n",
      "Epoch 222, Loss: 0.4104582809838288\n",
      "Epoch 223, Loss: 0.4101367219181661\n",
      "Epoch 224, Loss: 0.4157081327260397\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22046543218992673\n",
      "Test R^2 score: 0.4730602899040089\n",
      "Num of epochs: 225\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Epoch 179, Loss: 0.42867030340024453\n",
      "Epoch 180, Loss: 0.42665902048327814\n",
      "Epoch 181, Loss: 0.4160041986606613\n",
      "Epoch 182, Loss: 0.42380692389414293\n",
      "Epoch 183, Loss: 0.4367609764525626\n",
      "Epoch 184, Loss: 0.42557170506243686\n",
      "Epoch 185, Loss: 0.42106826790053603\n",
      "Epoch 186, Loss: 0.42573876125176086\n",
      "Epoch 187, Loss: 0.41925407360374856\n",
      "Epoch 188, Loss: 0.4183384695092418\n",
      "Epoch 189, Loss: 0.4218813047997579\n",
      "Epoch 190, Loss: 0.4197713005325469\n",
      "Epoch 191, Loss: 0.417197451669247\n",
      "Epoch 192, Loss: 0.41998586832409235\n",
      "Epoch 193, Loss: 0.4198630180807017\n",
      "Epoch 194, Loss: 0.4146118298837611\n",
      "Epoch 195, Loss: 0.41413205840097117\n",
      "Epoch 196, Loss: 0.4155607826414292\n",
      "Epoch 197, Loss: 0.414238532452658\n",
      "Epoch 198, Loss: 0.41297339310852155\n",
      "Epoch 199, Loss: 0.4123900845056213\n",
      "Epoch 200, Loss: 0.4134311180746695\n",
      "Epoch 201, Loss: 0.4127689164145939\n",
      "Epoch 202, Loss: 0.41232720715179455\n",
      "Epoch 203, Loss: 0.41150345937125327\n",
      "Epoch 204, Loss: 0.4115020652257978\n",
      "Epoch 205, Loss: 0.411078297677327\n",
      "Epoch 206, Loss: 0.4110567108542411\n",
      "Epoch 207, Loss: 0.4114023806357039\n",
      "Epoch 208, Loss: 0.41371932293434216\n",
      "Epoch 209, Loss: 0.41813952085771794\n",
      "Epoch 210, Loss: 0.42511728996367454\n",
      "Epoch 211, Loss: 0.42635158522503447\n",
      "Epoch 212, Loss: 0.419673136297028\n",
      "Epoch 213, Loss: 0.41005224089892217\n",
      "Epoch 214, Loss: 0.4205638856971283\n",
      "Epoch 215, Loss: 0.4288454648496258\n",
      "Epoch 216, Loss: 0.416730043439161\n",
      "Epoch 217, Loss: 0.4131035226095487\n",
      "Epoch 218, Loss: 0.41919050177663497\n",
      "Epoch 219, Loss: 0.41341632229404196\n",
      "Epoch 220, Loss: 0.411337015720657\n",
      "Epoch 221, Loss: 0.4153124279254653\n",
      "Epoch 222, Loss: 0.4104582809838288\n",
      "Epoch 223, Loss: 0.4101367219181661\n",
      "Epoch 224, Loss: 0.4157081327260397\n",
      "Epoch 225, Loss: 0.4144226163660391\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22242632377574642\n",
      "Test R^2 score: 0.46295439135471617\n",
      "Num of epochs: 226\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Epoch 179, Loss: 0.42867030340024453\n",
      "Epoch 180, Loss: 0.42665902048327814\n",
      "Epoch 181, Loss: 0.4160041986606613\n",
      "Epoch 182, Loss: 0.42380692389414293\n",
      "Epoch 183, Loss: 0.4367609764525626\n",
      "Epoch 184, Loss: 0.42557170506243686\n",
      "Epoch 185, Loss: 0.42106826790053603\n",
      "Epoch 186, Loss: 0.42573876125176086\n",
      "Epoch 187, Loss: 0.41925407360374856\n",
      "Epoch 188, Loss: 0.4183384695092418\n",
      "Epoch 189, Loss: 0.4218813047997579\n",
      "Epoch 190, Loss: 0.4197713005325469\n",
      "Epoch 191, Loss: 0.417197451669247\n",
      "Epoch 192, Loss: 0.41998586832409235\n",
      "Epoch 193, Loss: 0.4198630180807017\n",
      "Epoch 194, Loss: 0.4146118298837611\n",
      "Epoch 195, Loss: 0.41413205840097117\n",
      "Epoch 196, Loss: 0.4155607826414292\n",
      "Epoch 197, Loss: 0.414238532452658\n",
      "Epoch 198, Loss: 0.41297339310852155\n",
      "Epoch 199, Loss: 0.4123900845056213\n",
      "Epoch 200, Loss: 0.4134311180746695\n",
      "Epoch 201, Loss: 0.4127689164145939\n",
      "Epoch 202, Loss: 0.41232720715179455\n",
      "Epoch 203, Loss: 0.41150345937125327\n",
      "Epoch 204, Loss: 0.4115020652257978\n",
      "Epoch 205, Loss: 0.411078297677327\n",
      "Epoch 206, Loss: 0.4110567108542411\n",
      "Epoch 207, Loss: 0.4114023806357039\n",
      "Epoch 208, Loss: 0.41371932293434216\n",
      "Epoch 209, Loss: 0.41813952085771794\n",
      "Epoch 210, Loss: 0.42511728996367454\n",
      "Epoch 211, Loss: 0.42635158522503447\n",
      "Epoch 212, Loss: 0.419673136297028\n",
      "Epoch 213, Loss: 0.41005224089892217\n",
      "Epoch 214, Loss: 0.4205638856971283\n",
      "Epoch 215, Loss: 0.4288454648496258\n",
      "Epoch 216, Loss: 0.416730043439161\n",
      "Epoch 217, Loss: 0.4131035226095487\n",
      "Epoch 218, Loss: 0.41919050177663497\n",
      "Epoch 219, Loss: 0.41341632229404196\n",
      "Epoch 220, Loss: 0.411337015720657\n",
      "Epoch 221, Loss: 0.4153124279254653\n",
      "Epoch 222, Loss: 0.4104582809838288\n",
      "Epoch 223, Loss: 0.4101367219181661\n",
      "Epoch 224, Loss: 0.4157081327260397\n",
      "Epoch 225, Loss: 0.4144226163660391\n",
      "Epoch 226, Loss: 0.4098329995970875\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22199801540517064\n",
      "Test R^2 score: 0.46472639419772543\n",
      "Num of epochs: 227\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Epoch 179, Loss: 0.42867030340024453\n",
      "Epoch 180, Loss: 0.42665902048327814\n",
      "Epoch 181, Loss: 0.4160041986606613\n",
      "Epoch 182, Loss: 0.42380692389414293\n",
      "Epoch 183, Loss: 0.4367609764525626\n",
      "Epoch 184, Loss: 0.42557170506243686\n",
      "Epoch 185, Loss: 0.42106826790053603\n",
      "Epoch 186, Loss: 0.42573876125176086\n",
      "Epoch 187, Loss: 0.41925407360374856\n",
      "Epoch 188, Loss: 0.4183384695092418\n",
      "Epoch 189, Loss: 0.4218813047997579\n",
      "Epoch 190, Loss: 0.4197713005325469\n",
      "Epoch 191, Loss: 0.417197451669247\n",
      "Epoch 192, Loss: 0.41998586832409235\n",
      "Epoch 193, Loss: 0.4198630180807017\n",
      "Epoch 194, Loss: 0.4146118298837611\n",
      "Epoch 195, Loss: 0.41413205840097117\n",
      "Epoch 196, Loss: 0.4155607826414292\n",
      "Epoch 197, Loss: 0.414238532452658\n",
      "Epoch 198, Loss: 0.41297339310852155\n",
      "Epoch 199, Loss: 0.4123900845056213\n",
      "Epoch 200, Loss: 0.4134311180746695\n",
      "Epoch 201, Loss: 0.4127689164145939\n",
      "Epoch 202, Loss: 0.41232720715179455\n",
      "Epoch 203, Loss: 0.41150345937125327\n",
      "Epoch 204, Loss: 0.4115020652257978\n",
      "Epoch 205, Loss: 0.411078297677327\n",
      "Epoch 206, Loss: 0.4110567108542411\n",
      "Epoch 207, Loss: 0.4114023806357039\n",
      "Epoch 208, Loss: 0.41371932293434216\n",
      "Epoch 209, Loss: 0.41813952085771794\n",
      "Epoch 210, Loss: 0.42511728996367454\n",
      "Epoch 211, Loss: 0.42635158522503447\n",
      "Epoch 212, Loss: 0.419673136297028\n",
      "Epoch 213, Loss: 0.41005224089892217\n",
      "Epoch 214, Loss: 0.4205638856971283\n",
      "Epoch 215, Loss: 0.4288454648496258\n",
      "Epoch 216, Loss: 0.416730043439161\n",
      "Epoch 217, Loss: 0.4131035226095487\n",
      "Epoch 218, Loss: 0.41919050177663497\n",
      "Epoch 219, Loss: 0.41341632229404196\n",
      "Epoch 220, Loss: 0.411337015720657\n",
      "Epoch 221, Loss: 0.4153124279254653\n",
      "Epoch 222, Loss: 0.4104582809838288\n",
      "Epoch 223, Loss: 0.4101367219181661\n",
      "Epoch 224, Loss: 0.4157081327260397\n",
      "Epoch 225, Loss: 0.4144226163660391\n",
      "Epoch 226, Loss: 0.4098329995970875\n",
      "Epoch 227, Loss: 0.40775029376666666\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22031485227028882\n",
      "Test R^2 score: 0.4729530204855426\n",
      "Num of epochs: 228\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Epoch 179, Loss: 0.42867030340024453\n",
      "Epoch 180, Loss: 0.42665902048327814\n",
      "Epoch 181, Loss: 0.4160041986606613\n",
      "Epoch 182, Loss: 0.42380692389414293\n",
      "Epoch 183, Loss: 0.4367609764525626\n",
      "Epoch 184, Loss: 0.42557170506243686\n",
      "Epoch 185, Loss: 0.42106826790053603\n",
      "Epoch 186, Loss: 0.42573876125176086\n",
      "Epoch 187, Loss: 0.41925407360374856\n",
      "Epoch 188, Loss: 0.4183384695092418\n",
      "Epoch 189, Loss: 0.4218813047997579\n",
      "Epoch 190, Loss: 0.4197713005325469\n",
      "Epoch 191, Loss: 0.417197451669247\n",
      "Epoch 192, Loss: 0.41998586832409235\n",
      "Epoch 193, Loss: 0.4198630180807017\n",
      "Epoch 194, Loss: 0.4146118298837611\n",
      "Epoch 195, Loss: 0.41413205840097117\n",
      "Epoch 196, Loss: 0.4155607826414292\n",
      "Epoch 197, Loss: 0.414238532452658\n",
      "Epoch 198, Loss: 0.41297339310852155\n",
      "Epoch 199, Loss: 0.4123900845056213\n",
      "Epoch 200, Loss: 0.4134311180746695\n",
      "Epoch 201, Loss: 0.4127689164145939\n",
      "Epoch 202, Loss: 0.41232720715179455\n",
      "Epoch 203, Loss: 0.41150345937125327\n",
      "Epoch 204, Loss: 0.4115020652257978\n",
      "Epoch 205, Loss: 0.411078297677327\n",
      "Epoch 206, Loss: 0.4110567108542411\n",
      "Epoch 207, Loss: 0.4114023806357039\n",
      "Epoch 208, Loss: 0.41371932293434216\n",
      "Epoch 209, Loss: 0.41813952085771794\n",
      "Epoch 210, Loss: 0.42511728996367454\n",
      "Epoch 211, Loss: 0.42635158522503447\n",
      "Epoch 212, Loss: 0.419673136297028\n",
      "Epoch 213, Loss: 0.41005224089892217\n",
      "Epoch 214, Loss: 0.4205638856971283\n",
      "Epoch 215, Loss: 0.4288454648496258\n",
      "Epoch 216, Loss: 0.416730043439161\n",
      "Epoch 217, Loss: 0.4131035226095487\n",
      "Epoch 218, Loss: 0.41919050177663497\n",
      "Epoch 219, Loss: 0.41341632229404196\n",
      "Epoch 220, Loss: 0.411337015720657\n",
      "Epoch 221, Loss: 0.4153124279254653\n",
      "Epoch 222, Loss: 0.4104582809838288\n",
      "Epoch 223, Loss: 0.4101367219181661\n",
      "Epoch 224, Loss: 0.4157081327260397\n",
      "Epoch 225, Loss: 0.4144226163660391\n",
      "Epoch 226, Loss: 0.4098329995970875\n",
      "Epoch 227, Loss: 0.40775029376666666\n",
      "Epoch 228, Loss: 0.41429755898335924\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.23001549778825023\n",
      "Test R^2 score: 0.4249368674029983\n",
      "Num of epochs: 229\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Epoch 179, Loss: 0.42867030340024453\n",
      "Epoch 180, Loss: 0.42665902048327814\n",
      "Epoch 181, Loss: 0.4160041986606613\n",
      "Epoch 182, Loss: 0.42380692389414293\n",
      "Epoch 183, Loss: 0.4367609764525626\n",
      "Epoch 184, Loss: 0.42557170506243686\n",
      "Epoch 185, Loss: 0.42106826790053603\n",
      "Epoch 186, Loss: 0.42573876125176086\n",
      "Epoch 187, Loss: 0.41925407360374856\n",
      "Epoch 188, Loss: 0.4183384695092418\n",
      "Epoch 189, Loss: 0.4218813047997579\n",
      "Epoch 190, Loss: 0.4197713005325469\n",
      "Epoch 191, Loss: 0.417197451669247\n",
      "Epoch 192, Loss: 0.41998586832409235\n",
      "Epoch 193, Loss: 0.4198630180807017\n",
      "Epoch 194, Loss: 0.4146118298837611\n",
      "Epoch 195, Loss: 0.41413205840097117\n",
      "Epoch 196, Loss: 0.4155607826414292\n",
      "Epoch 197, Loss: 0.414238532452658\n",
      "Epoch 198, Loss: 0.41297339310852155\n",
      "Epoch 199, Loss: 0.4123900845056213\n",
      "Epoch 200, Loss: 0.4134311180746695\n",
      "Epoch 201, Loss: 0.4127689164145939\n",
      "Epoch 202, Loss: 0.41232720715179455\n",
      "Epoch 203, Loss: 0.41150345937125327\n",
      "Epoch 204, Loss: 0.4115020652257978\n",
      "Epoch 205, Loss: 0.411078297677327\n",
      "Epoch 206, Loss: 0.4110567108542411\n",
      "Epoch 207, Loss: 0.4114023806357039\n",
      "Epoch 208, Loss: 0.41371932293434216\n",
      "Epoch 209, Loss: 0.41813952085771794\n",
      "Epoch 210, Loss: 0.42511728996367454\n",
      "Epoch 211, Loss: 0.42635158522503447\n",
      "Epoch 212, Loss: 0.419673136297028\n",
      "Epoch 213, Loss: 0.41005224089892217\n",
      "Epoch 214, Loss: 0.4205638856971283\n",
      "Epoch 215, Loss: 0.4288454648496258\n",
      "Epoch 216, Loss: 0.416730043439161\n",
      "Epoch 217, Loss: 0.4131035226095487\n",
      "Epoch 218, Loss: 0.41919050177663497\n",
      "Epoch 219, Loss: 0.41341632229404196\n",
      "Epoch 220, Loss: 0.411337015720657\n",
      "Epoch 221, Loss: 0.4153124279254653\n",
      "Epoch 222, Loss: 0.4104582809838288\n",
      "Epoch 223, Loss: 0.4101367219181661\n",
      "Epoch 224, Loss: 0.4157081327260397\n",
      "Epoch 225, Loss: 0.4144226163660391\n",
      "Epoch 226, Loss: 0.4098329995970875\n",
      "Epoch 227, Loss: 0.40775029376666666\n",
      "Epoch 228, Loss: 0.41429755898335924\n",
      "Epoch 229, Loss: 0.41521591906294136\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21657420530461793\n",
      "Test R^2 score: 0.49001953136480253\n",
      "Num of epochs: 230\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Epoch 179, Loss: 0.42867030340024453\n",
      "Epoch 180, Loss: 0.42665902048327814\n",
      "Epoch 181, Loss: 0.4160041986606613\n",
      "Epoch 182, Loss: 0.42380692389414293\n",
      "Epoch 183, Loss: 0.4367609764525626\n",
      "Epoch 184, Loss: 0.42557170506243686\n",
      "Epoch 185, Loss: 0.42106826790053603\n",
      "Epoch 186, Loss: 0.42573876125176086\n",
      "Epoch 187, Loss: 0.41925407360374856\n",
      "Epoch 188, Loss: 0.4183384695092418\n",
      "Epoch 189, Loss: 0.4218813047997579\n",
      "Epoch 190, Loss: 0.4197713005325469\n",
      "Epoch 191, Loss: 0.417197451669247\n",
      "Epoch 192, Loss: 0.41998586832409235\n",
      "Epoch 193, Loss: 0.4198630180807017\n",
      "Epoch 194, Loss: 0.4146118298837611\n",
      "Epoch 195, Loss: 0.41413205840097117\n",
      "Epoch 196, Loss: 0.4155607826414292\n",
      "Epoch 197, Loss: 0.414238532452658\n",
      "Epoch 198, Loss: 0.41297339310852155\n",
      "Epoch 199, Loss: 0.4123900845056213\n",
      "Epoch 200, Loss: 0.4134311180746695\n",
      "Epoch 201, Loss: 0.4127689164145939\n",
      "Epoch 202, Loss: 0.41232720715179455\n",
      "Epoch 203, Loss: 0.41150345937125327\n",
      "Epoch 204, Loss: 0.4115020652257978\n",
      "Epoch 205, Loss: 0.411078297677327\n",
      "Epoch 206, Loss: 0.4110567108542411\n",
      "Epoch 207, Loss: 0.4114023806357039\n",
      "Epoch 208, Loss: 0.41371932293434216\n",
      "Epoch 209, Loss: 0.41813952085771794\n",
      "Epoch 210, Loss: 0.42511728996367454\n",
      "Epoch 211, Loss: 0.42635158522503447\n",
      "Epoch 212, Loss: 0.419673136297028\n",
      "Epoch 213, Loss: 0.41005224089892217\n",
      "Epoch 214, Loss: 0.4205638856971283\n",
      "Epoch 215, Loss: 0.4288454648496258\n",
      "Epoch 216, Loss: 0.416730043439161\n",
      "Epoch 217, Loss: 0.4131035226095487\n",
      "Epoch 218, Loss: 0.41919050177663497\n",
      "Epoch 219, Loss: 0.41341632229404196\n",
      "Epoch 220, Loss: 0.411337015720657\n",
      "Epoch 221, Loss: 0.4153124279254653\n",
      "Epoch 222, Loss: 0.4104582809838288\n",
      "Epoch 223, Loss: 0.4101367219181661\n",
      "Epoch 224, Loss: 0.4157081327260397\n",
      "Epoch 225, Loss: 0.4144226163660391\n",
      "Epoch 226, Loss: 0.4098329995970875\n",
      "Epoch 227, Loss: 0.40775029376666666\n",
      "Epoch 228, Loss: 0.41429755898335924\n",
      "Epoch 229, Loss: 0.41521591906294136\n",
      "Epoch 230, Loss: 0.4099844981670613\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21733921042293225\n",
      "Test R^2 score: 0.4869250989803459\n",
      "Num of epochs: 231\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Epoch 179, Loss: 0.42867030340024453\n",
      "Epoch 180, Loss: 0.42665902048327814\n",
      "Epoch 181, Loss: 0.4160041986606613\n",
      "Epoch 182, Loss: 0.42380692389414293\n",
      "Epoch 183, Loss: 0.4367609764525626\n",
      "Epoch 184, Loss: 0.42557170506243686\n",
      "Epoch 185, Loss: 0.42106826790053603\n",
      "Epoch 186, Loss: 0.42573876125176086\n",
      "Epoch 187, Loss: 0.41925407360374856\n",
      "Epoch 188, Loss: 0.4183384695092418\n",
      "Epoch 189, Loss: 0.4218813047997579\n",
      "Epoch 190, Loss: 0.4197713005325469\n",
      "Epoch 191, Loss: 0.417197451669247\n",
      "Epoch 192, Loss: 0.41998586832409235\n",
      "Epoch 193, Loss: 0.4198630180807017\n",
      "Epoch 194, Loss: 0.4146118298837611\n",
      "Epoch 195, Loss: 0.41413205840097117\n",
      "Epoch 196, Loss: 0.4155607826414292\n",
      "Epoch 197, Loss: 0.414238532452658\n",
      "Epoch 198, Loss: 0.41297339310852155\n",
      "Epoch 199, Loss: 0.4123900845056213\n",
      "Epoch 200, Loss: 0.4134311180746695\n",
      "Epoch 201, Loss: 0.4127689164145939\n",
      "Epoch 202, Loss: 0.41232720715179455\n",
      "Epoch 203, Loss: 0.41150345937125327\n",
      "Epoch 204, Loss: 0.4115020652257978\n",
      "Epoch 205, Loss: 0.411078297677327\n",
      "Epoch 206, Loss: 0.4110567108542411\n",
      "Epoch 207, Loss: 0.4114023806357039\n",
      "Epoch 208, Loss: 0.41371932293434216\n",
      "Epoch 209, Loss: 0.41813952085771794\n",
      "Epoch 210, Loss: 0.42511728996367454\n",
      "Epoch 211, Loss: 0.42635158522503447\n",
      "Epoch 212, Loss: 0.419673136297028\n",
      "Epoch 213, Loss: 0.41005224089892217\n",
      "Epoch 214, Loss: 0.4205638856971283\n",
      "Epoch 215, Loss: 0.4288454648496258\n",
      "Epoch 216, Loss: 0.416730043439161\n",
      "Epoch 217, Loss: 0.4131035226095487\n",
      "Epoch 218, Loss: 0.41919050177663497\n",
      "Epoch 219, Loss: 0.41341632229404196\n",
      "Epoch 220, Loss: 0.411337015720657\n",
      "Epoch 221, Loss: 0.4153124279254653\n",
      "Epoch 222, Loss: 0.4104582809838288\n",
      "Epoch 223, Loss: 0.4101367219181661\n",
      "Epoch 224, Loss: 0.4157081327260397\n",
      "Epoch 225, Loss: 0.4144226163660391\n",
      "Epoch 226, Loss: 0.4098329995970875\n",
      "Epoch 227, Loss: 0.40775029376666666\n",
      "Epoch 228, Loss: 0.41429755898335924\n",
      "Epoch 229, Loss: 0.41521591906294136\n",
      "Epoch 230, Loss: 0.4099844981670613\n",
      "Epoch 231, Loss: 0.4074908343553954\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.23174406897047264\n",
      "Test R^2 score: 0.41727297843915406\n",
      "Num of epochs: 232\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Epoch 179, Loss: 0.42867030340024453\n",
      "Epoch 180, Loss: 0.42665902048327814\n",
      "Epoch 181, Loss: 0.4160041986606613\n",
      "Epoch 182, Loss: 0.42380692389414293\n",
      "Epoch 183, Loss: 0.4367609764525626\n",
      "Epoch 184, Loss: 0.42557170506243686\n",
      "Epoch 185, Loss: 0.42106826790053603\n",
      "Epoch 186, Loss: 0.42573876125176086\n",
      "Epoch 187, Loss: 0.41925407360374856\n",
      "Epoch 188, Loss: 0.4183384695092418\n",
      "Epoch 189, Loss: 0.4218813047997579\n",
      "Epoch 190, Loss: 0.4197713005325469\n",
      "Epoch 191, Loss: 0.417197451669247\n",
      "Epoch 192, Loss: 0.41998586832409235\n",
      "Epoch 193, Loss: 0.4198630180807017\n",
      "Epoch 194, Loss: 0.4146118298837611\n",
      "Epoch 195, Loss: 0.41413205840097117\n",
      "Epoch 196, Loss: 0.4155607826414292\n",
      "Epoch 197, Loss: 0.414238532452658\n",
      "Epoch 198, Loss: 0.41297339310852155\n",
      "Epoch 199, Loss: 0.4123900845056213\n",
      "Epoch 200, Loss: 0.4134311180746695\n",
      "Epoch 201, Loss: 0.4127689164145939\n",
      "Epoch 202, Loss: 0.41232720715179455\n",
      "Epoch 203, Loss: 0.41150345937125327\n",
      "Epoch 204, Loss: 0.4115020652257978\n",
      "Epoch 205, Loss: 0.411078297677327\n",
      "Epoch 206, Loss: 0.4110567108542411\n",
      "Epoch 207, Loss: 0.4114023806357039\n",
      "Epoch 208, Loss: 0.41371932293434216\n",
      "Epoch 209, Loss: 0.41813952085771794\n",
      "Epoch 210, Loss: 0.42511728996367454\n",
      "Epoch 211, Loss: 0.42635158522503447\n",
      "Epoch 212, Loss: 0.419673136297028\n",
      "Epoch 213, Loss: 0.41005224089892217\n",
      "Epoch 214, Loss: 0.4205638856971283\n",
      "Epoch 215, Loss: 0.4288454648496258\n",
      "Epoch 216, Loss: 0.416730043439161\n",
      "Epoch 217, Loss: 0.4131035226095487\n",
      "Epoch 218, Loss: 0.41919050177663497\n",
      "Epoch 219, Loss: 0.41341632229404196\n",
      "Epoch 220, Loss: 0.411337015720657\n",
      "Epoch 221, Loss: 0.4153124279254653\n",
      "Epoch 222, Loss: 0.4104582809838288\n",
      "Epoch 223, Loss: 0.4101367219181661\n",
      "Epoch 224, Loss: 0.4157081327260397\n",
      "Epoch 225, Loss: 0.4144226163660391\n",
      "Epoch 226, Loss: 0.4098329995970875\n",
      "Epoch 227, Loss: 0.40775029376666666\n",
      "Epoch 228, Loss: 0.41429755898335924\n",
      "Epoch 229, Loss: 0.41521591906294136\n",
      "Epoch 230, Loss: 0.4099844981670613\n",
      "Epoch 231, Loss: 0.4074908343553954\n",
      "Epoch 232, Loss: 0.41404155462298753\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22266764634857938\n",
      "Test R^2 score: 0.4626588300528194\n",
      "Num of epochs: 233\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Epoch 179, Loss: 0.42867030340024453\n",
      "Epoch 180, Loss: 0.42665902048327814\n",
      "Epoch 181, Loss: 0.4160041986606613\n",
      "Epoch 182, Loss: 0.42380692389414293\n",
      "Epoch 183, Loss: 0.4367609764525626\n",
      "Epoch 184, Loss: 0.42557170506243686\n",
      "Epoch 185, Loss: 0.42106826790053603\n",
      "Epoch 186, Loss: 0.42573876125176086\n",
      "Epoch 187, Loss: 0.41925407360374856\n",
      "Epoch 188, Loss: 0.4183384695092418\n",
      "Epoch 189, Loss: 0.4218813047997579\n",
      "Epoch 190, Loss: 0.4197713005325469\n",
      "Epoch 191, Loss: 0.417197451669247\n",
      "Epoch 192, Loss: 0.41998586832409235\n",
      "Epoch 193, Loss: 0.4198630180807017\n",
      "Epoch 194, Loss: 0.4146118298837611\n",
      "Epoch 195, Loss: 0.41413205840097117\n",
      "Epoch 196, Loss: 0.4155607826414292\n",
      "Epoch 197, Loss: 0.414238532452658\n",
      "Epoch 198, Loss: 0.41297339310852155\n",
      "Epoch 199, Loss: 0.4123900845056213\n",
      "Epoch 200, Loss: 0.4134311180746695\n",
      "Epoch 201, Loss: 0.4127689164145939\n",
      "Epoch 202, Loss: 0.41232720715179455\n",
      "Epoch 203, Loss: 0.41150345937125327\n",
      "Epoch 204, Loss: 0.4115020652257978\n",
      "Epoch 205, Loss: 0.411078297677327\n",
      "Epoch 206, Loss: 0.4110567108542411\n",
      "Epoch 207, Loss: 0.4114023806357039\n",
      "Epoch 208, Loss: 0.41371932293434216\n",
      "Epoch 209, Loss: 0.41813952085771794\n",
      "Epoch 210, Loss: 0.42511728996367454\n",
      "Epoch 211, Loss: 0.42635158522503447\n",
      "Epoch 212, Loss: 0.419673136297028\n",
      "Epoch 213, Loss: 0.41005224089892217\n",
      "Epoch 214, Loss: 0.4205638856971283\n",
      "Epoch 215, Loss: 0.4288454648496258\n",
      "Epoch 216, Loss: 0.416730043439161\n",
      "Epoch 217, Loss: 0.4131035226095487\n",
      "Epoch 218, Loss: 0.41919050177663497\n",
      "Epoch 219, Loss: 0.41341632229404196\n",
      "Epoch 220, Loss: 0.411337015720657\n",
      "Epoch 221, Loss: 0.4153124279254653\n",
      "Epoch 222, Loss: 0.4104582809838288\n",
      "Epoch 223, Loss: 0.4101367219181661\n",
      "Epoch 224, Loss: 0.4157081327260397\n",
      "Epoch 225, Loss: 0.4144226163660391\n",
      "Epoch 226, Loss: 0.4098329995970875\n",
      "Epoch 227, Loss: 0.40775029376666666\n",
      "Epoch 228, Loss: 0.41429755898335924\n",
      "Epoch 229, Loss: 0.41521591906294136\n",
      "Epoch 230, Loss: 0.4099844981670613\n",
      "Epoch 231, Loss: 0.4074908343553954\n",
      "Epoch 232, Loss: 0.41404155462298753\n",
      "Epoch 233, Loss: 0.41428398110821113\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22562268043273997\n",
      "Test R^2 score: 0.447488119319251\n",
      "Num of epochs: 234\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Epoch 179, Loss: 0.42867030340024453\n",
      "Epoch 180, Loss: 0.42665902048327814\n",
      "Epoch 181, Loss: 0.4160041986606613\n",
      "Epoch 182, Loss: 0.42380692389414293\n",
      "Epoch 183, Loss: 0.4367609764525626\n",
      "Epoch 184, Loss: 0.42557170506243686\n",
      "Epoch 185, Loss: 0.42106826790053603\n",
      "Epoch 186, Loss: 0.42573876125176086\n",
      "Epoch 187, Loss: 0.41925407360374856\n",
      "Epoch 188, Loss: 0.4183384695092418\n",
      "Epoch 189, Loss: 0.4218813047997579\n",
      "Epoch 190, Loss: 0.4197713005325469\n",
      "Epoch 191, Loss: 0.417197451669247\n",
      "Epoch 192, Loss: 0.41998586832409235\n",
      "Epoch 193, Loss: 0.4198630180807017\n",
      "Epoch 194, Loss: 0.4146118298837611\n",
      "Epoch 195, Loss: 0.41413205840097117\n",
      "Epoch 196, Loss: 0.4155607826414292\n",
      "Epoch 197, Loss: 0.414238532452658\n",
      "Epoch 198, Loss: 0.41297339310852155\n",
      "Epoch 199, Loss: 0.4123900845056213\n",
      "Epoch 200, Loss: 0.4134311180746695\n",
      "Epoch 201, Loss: 0.4127689164145939\n",
      "Epoch 202, Loss: 0.41232720715179455\n",
      "Epoch 203, Loss: 0.41150345937125327\n",
      "Epoch 204, Loss: 0.4115020652257978\n",
      "Epoch 205, Loss: 0.411078297677327\n",
      "Epoch 206, Loss: 0.4110567108542411\n",
      "Epoch 207, Loss: 0.4114023806357039\n",
      "Epoch 208, Loss: 0.41371932293434216\n",
      "Epoch 209, Loss: 0.41813952085771794\n",
      "Epoch 210, Loss: 0.42511728996367454\n",
      "Epoch 211, Loss: 0.42635158522503447\n",
      "Epoch 212, Loss: 0.419673136297028\n",
      "Epoch 213, Loss: 0.41005224089892217\n",
      "Epoch 214, Loss: 0.4205638856971283\n",
      "Epoch 215, Loss: 0.4288454648496258\n",
      "Epoch 216, Loss: 0.416730043439161\n",
      "Epoch 217, Loss: 0.4131035226095487\n",
      "Epoch 218, Loss: 0.41919050177663497\n",
      "Epoch 219, Loss: 0.41341632229404196\n",
      "Epoch 220, Loss: 0.411337015720657\n",
      "Epoch 221, Loss: 0.4153124279254653\n",
      "Epoch 222, Loss: 0.4104582809838288\n",
      "Epoch 223, Loss: 0.4101367219181661\n",
      "Epoch 224, Loss: 0.4157081327260397\n",
      "Epoch 225, Loss: 0.4144226163660391\n",
      "Epoch 226, Loss: 0.4098329995970875\n",
      "Epoch 227, Loss: 0.40775029376666666\n",
      "Epoch 228, Loss: 0.41429755898335924\n",
      "Epoch 229, Loss: 0.41521591906294136\n",
      "Epoch 230, Loss: 0.4099844981670613\n",
      "Epoch 231, Loss: 0.4074908343553954\n",
      "Epoch 232, Loss: 0.41404155462298753\n",
      "Epoch 233, Loss: 0.41428398110821113\n",
      "Epoch 234, Loss: 0.411010796569875\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21953439018821547\n",
      "Test R^2 score: 0.47665578916954343\n",
      "Num of epochs: 235\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Epoch 179, Loss: 0.42867030340024453\n",
      "Epoch 180, Loss: 0.42665902048327814\n",
      "Epoch 181, Loss: 0.4160041986606613\n",
      "Epoch 182, Loss: 0.42380692389414293\n",
      "Epoch 183, Loss: 0.4367609764525626\n",
      "Epoch 184, Loss: 0.42557170506243686\n",
      "Epoch 185, Loss: 0.42106826790053603\n",
      "Epoch 186, Loss: 0.42573876125176086\n",
      "Epoch 187, Loss: 0.41925407360374856\n",
      "Epoch 188, Loss: 0.4183384695092418\n",
      "Epoch 189, Loss: 0.4218813047997579\n",
      "Epoch 190, Loss: 0.4197713005325469\n",
      "Epoch 191, Loss: 0.417197451669247\n",
      "Epoch 192, Loss: 0.41998586832409235\n",
      "Epoch 193, Loss: 0.4198630180807017\n",
      "Epoch 194, Loss: 0.4146118298837611\n",
      "Epoch 195, Loss: 0.41413205840097117\n",
      "Epoch 196, Loss: 0.4155607826414292\n",
      "Epoch 197, Loss: 0.414238532452658\n",
      "Epoch 198, Loss: 0.41297339310852155\n",
      "Epoch 199, Loss: 0.4123900845056213\n",
      "Epoch 200, Loss: 0.4134311180746695\n",
      "Epoch 201, Loss: 0.4127689164145939\n",
      "Epoch 202, Loss: 0.41232720715179455\n",
      "Epoch 203, Loss: 0.41150345937125327\n",
      "Epoch 204, Loss: 0.4115020652257978\n",
      "Epoch 205, Loss: 0.411078297677327\n",
      "Epoch 206, Loss: 0.4110567108542411\n",
      "Epoch 207, Loss: 0.4114023806357039\n",
      "Epoch 208, Loss: 0.41371932293434216\n",
      "Epoch 209, Loss: 0.41813952085771794\n",
      "Epoch 210, Loss: 0.42511728996367454\n",
      "Epoch 211, Loss: 0.42635158522503447\n",
      "Epoch 212, Loss: 0.419673136297028\n",
      "Epoch 213, Loss: 0.41005224089892217\n",
      "Epoch 214, Loss: 0.4205638856971283\n",
      "Epoch 215, Loss: 0.4288454648496258\n",
      "Epoch 216, Loss: 0.416730043439161\n",
      "Epoch 217, Loss: 0.4131035226095487\n",
      "Epoch 218, Loss: 0.41919050177663497\n",
      "Epoch 219, Loss: 0.41341632229404196\n",
      "Epoch 220, Loss: 0.411337015720657\n",
      "Epoch 221, Loss: 0.4153124279254653\n",
      "Epoch 222, Loss: 0.4104582809838288\n",
      "Epoch 223, Loss: 0.4101367219181661\n",
      "Epoch 224, Loss: 0.4157081327260397\n",
      "Epoch 225, Loss: 0.4144226163660391\n",
      "Epoch 226, Loss: 0.4098329995970875\n",
      "Epoch 227, Loss: 0.40775029376666666\n",
      "Epoch 228, Loss: 0.41429755898335924\n",
      "Epoch 229, Loss: 0.41521591906294136\n",
      "Epoch 230, Loss: 0.4099844981670613\n",
      "Epoch 231, Loss: 0.4074908343553954\n",
      "Epoch 232, Loss: 0.41404155462298753\n",
      "Epoch 233, Loss: 0.41428398110821113\n",
      "Epoch 234, Loss: 0.411010796569875\n",
      "Epoch 235, Loss: 0.40626047194262166\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2207242019129961\n",
      "Test R^2 score: 0.47122057823909536\n",
      "Num of epochs: 236\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Epoch 179, Loss: 0.42867030340024453\n",
      "Epoch 180, Loss: 0.42665902048327814\n",
      "Epoch 181, Loss: 0.4160041986606613\n",
      "Epoch 182, Loss: 0.42380692389414293\n",
      "Epoch 183, Loss: 0.4367609764525626\n",
      "Epoch 184, Loss: 0.42557170506243686\n",
      "Epoch 185, Loss: 0.42106826790053603\n",
      "Epoch 186, Loss: 0.42573876125176086\n",
      "Epoch 187, Loss: 0.41925407360374856\n",
      "Epoch 188, Loss: 0.4183384695092418\n",
      "Epoch 189, Loss: 0.4218813047997579\n",
      "Epoch 190, Loss: 0.4197713005325469\n",
      "Epoch 191, Loss: 0.417197451669247\n",
      "Epoch 192, Loss: 0.41998586832409235\n",
      "Epoch 193, Loss: 0.4198630180807017\n",
      "Epoch 194, Loss: 0.4146118298837611\n",
      "Epoch 195, Loss: 0.41413205840097117\n",
      "Epoch 196, Loss: 0.4155607826414292\n",
      "Epoch 197, Loss: 0.414238532452658\n",
      "Epoch 198, Loss: 0.41297339310852155\n",
      "Epoch 199, Loss: 0.4123900845056213\n",
      "Epoch 200, Loss: 0.4134311180746695\n",
      "Epoch 201, Loss: 0.4127689164145939\n",
      "Epoch 202, Loss: 0.41232720715179455\n",
      "Epoch 203, Loss: 0.41150345937125327\n",
      "Epoch 204, Loss: 0.4115020652257978\n",
      "Epoch 205, Loss: 0.411078297677327\n",
      "Epoch 206, Loss: 0.4110567108542411\n",
      "Epoch 207, Loss: 0.4114023806357039\n",
      "Epoch 208, Loss: 0.41371932293434216\n",
      "Epoch 209, Loss: 0.41813952085771794\n",
      "Epoch 210, Loss: 0.42511728996367454\n",
      "Epoch 211, Loss: 0.42635158522503447\n",
      "Epoch 212, Loss: 0.419673136297028\n",
      "Epoch 213, Loss: 0.41005224089892217\n",
      "Epoch 214, Loss: 0.4205638856971283\n",
      "Epoch 215, Loss: 0.4288454648496258\n",
      "Epoch 216, Loss: 0.416730043439161\n",
      "Epoch 217, Loss: 0.4131035226095487\n",
      "Epoch 218, Loss: 0.41919050177663497\n",
      "Epoch 219, Loss: 0.41341632229404196\n",
      "Epoch 220, Loss: 0.411337015720657\n",
      "Epoch 221, Loss: 0.4153124279254653\n",
      "Epoch 222, Loss: 0.4104582809838288\n",
      "Epoch 223, Loss: 0.4101367219181661\n",
      "Epoch 224, Loss: 0.4157081327260397\n",
      "Epoch 225, Loss: 0.4144226163660391\n",
      "Epoch 226, Loss: 0.4098329995970875\n",
      "Epoch 227, Loss: 0.40775029376666666\n",
      "Epoch 228, Loss: 0.41429755898335924\n",
      "Epoch 229, Loss: 0.41521591906294136\n",
      "Epoch 230, Loss: 0.4099844981670613\n",
      "Epoch 231, Loss: 0.4074908343553954\n",
      "Epoch 232, Loss: 0.41404155462298753\n",
      "Epoch 233, Loss: 0.41428398110821113\n",
      "Epoch 234, Loss: 0.411010796569875\n",
      "Epoch 235, Loss: 0.40626047194262166\n",
      "Epoch 236, Loss: 0.409034666887797\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.23390388469250484\n",
      "Test R^2 score: 0.40548343233314993\n",
      "Num of epochs: 237\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Epoch 179, Loss: 0.42867030340024453\n",
      "Epoch 180, Loss: 0.42665902048327814\n",
      "Epoch 181, Loss: 0.4160041986606613\n",
      "Epoch 182, Loss: 0.42380692389414293\n",
      "Epoch 183, Loss: 0.4367609764525626\n",
      "Epoch 184, Loss: 0.42557170506243686\n",
      "Epoch 185, Loss: 0.42106826790053603\n",
      "Epoch 186, Loss: 0.42573876125176086\n",
      "Epoch 187, Loss: 0.41925407360374856\n",
      "Epoch 188, Loss: 0.4183384695092418\n",
      "Epoch 189, Loss: 0.4218813047997579\n",
      "Epoch 190, Loss: 0.4197713005325469\n",
      "Epoch 191, Loss: 0.417197451669247\n",
      "Epoch 192, Loss: 0.41998586832409235\n",
      "Epoch 193, Loss: 0.4198630180807017\n",
      "Epoch 194, Loss: 0.4146118298837611\n",
      "Epoch 195, Loss: 0.41413205840097117\n",
      "Epoch 196, Loss: 0.4155607826414292\n",
      "Epoch 197, Loss: 0.414238532452658\n",
      "Epoch 198, Loss: 0.41297339310852155\n",
      "Epoch 199, Loss: 0.4123900845056213\n",
      "Epoch 200, Loss: 0.4134311180746695\n",
      "Epoch 201, Loss: 0.4127689164145939\n",
      "Epoch 202, Loss: 0.41232720715179455\n",
      "Epoch 203, Loss: 0.41150345937125327\n",
      "Epoch 204, Loss: 0.4115020652257978\n",
      "Epoch 205, Loss: 0.411078297677327\n",
      "Epoch 206, Loss: 0.4110567108542411\n",
      "Epoch 207, Loss: 0.4114023806357039\n",
      "Epoch 208, Loss: 0.41371932293434216\n",
      "Epoch 209, Loss: 0.41813952085771794\n",
      "Epoch 210, Loss: 0.42511728996367454\n",
      "Epoch 211, Loss: 0.42635158522503447\n",
      "Epoch 212, Loss: 0.419673136297028\n",
      "Epoch 213, Loss: 0.41005224089892217\n",
      "Epoch 214, Loss: 0.4205638856971283\n",
      "Epoch 215, Loss: 0.4288454648496258\n",
      "Epoch 216, Loss: 0.416730043439161\n",
      "Epoch 217, Loss: 0.4131035226095487\n",
      "Epoch 218, Loss: 0.41919050177663497\n",
      "Epoch 219, Loss: 0.41341632229404196\n",
      "Epoch 220, Loss: 0.411337015720657\n",
      "Epoch 221, Loss: 0.4153124279254653\n",
      "Epoch 222, Loss: 0.4104582809838288\n",
      "Epoch 223, Loss: 0.4101367219181661\n",
      "Epoch 224, Loss: 0.4157081327260397\n",
      "Epoch 225, Loss: 0.4144226163660391\n",
      "Epoch 226, Loss: 0.4098329995970875\n",
      "Epoch 227, Loss: 0.40775029376666666\n",
      "Epoch 228, Loss: 0.41429755898335924\n",
      "Epoch 229, Loss: 0.41521591906294136\n",
      "Epoch 230, Loss: 0.4099844981670613\n",
      "Epoch 231, Loss: 0.4074908343553954\n",
      "Epoch 232, Loss: 0.41404155462298753\n",
      "Epoch 233, Loss: 0.41428398110821113\n",
      "Epoch 234, Loss: 0.411010796569875\n",
      "Epoch 235, Loss: 0.40626047194262166\n",
      "Epoch 236, Loss: 0.409034666887797\n",
      "Epoch 237, Loss: 0.4158159770891869\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21937709518331425\n",
      "Test R^2 score: 0.4768931662846588\n",
      "Num of epochs: 238\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Epoch 179, Loss: 0.42867030340024453\n",
      "Epoch 180, Loss: 0.42665902048327814\n",
      "Epoch 181, Loss: 0.4160041986606613\n",
      "Epoch 182, Loss: 0.42380692389414293\n",
      "Epoch 183, Loss: 0.4367609764525626\n",
      "Epoch 184, Loss: 0.42557170506243686\n",
      "Epoch 185, Loss: 0.42106826790053603\n",
      "Epoch 186, Loss: 0.42573876125176086\n",
      "Epoch 187, Loss: 0.41925407360374856\n",
      "Epoch 188, Loss: 0.4183384695092418\n",
      "Epoch 189, Loss: 0.4218813047997579\n",
      "Epoch 190, Loss: 0.4197713005325469\n",
      "Epoch 191, Loss: 0.417197451669247\n",
      "Epoch 192, Loss: 0.41998586832409235\n",
      "Epoch 193, Loss: 0.4198630180807017\n",
      "Epoch 194, Loss: 0.4146118298837611\n",
      "Epoch 195, Loss: 0.41413205840097117\n",
      "Epoch 196, Loss: 0.4155607826414292\n",
      "Epoch 197, Loss: 0.414238532452658\n",
      "Epoch 198, Loss: 0.41297339310852155\n",
      "Epoch 199, Loss: 0.4123900845056213\n",
      "Epoch 200, Loss: 0.4134311180746695\n",
      "Epoch 201, Loss: 0.4127689164145939\n",
      "Epoch 202, Loss: 0.41232720715179455\n",
      "Epoch 203, Loss: 0.41150345937125327\n",
      "Epoch 204, Loss: 0.4115020652257978\n",
      "Epoch 205, Loss: 0.411078297677327\n",
      "Epoch 206, Loss: 0.4110567108542411\n",
      "Epoch 207, Loss: 0.4114023806357039\n",
      "Epoch 208, Loss: 0.41371932293434216\n",
      "Epoch 209, Loss: 0.41813952085771794\n",
      "Epoch 210, Loss: 0.42511728996367454\n",
      "Epoch 211, Loss: 0.42635158522503447\n",
      "Epoch 212, Loss: 0.419673136297028\n",
      "Epoch 213, Loss: 0.41005224089892217\n",
      "Epoch 214, Loss: 0.4205638856971283\n",
      "Epoch 215, Loss: 0.4288454648496258\n",
      "Epoch 216, Loss: 0.416730043439161\n",
      "Epoch 217, Loss: 0.4131035226095487\n",
      "Epoch 218, Loss: 0.41919050177663497\n",
      "Epoch 219, Loss: 0.41341632229404196\n",
      "Epoch 220, Loss: 0.411337015720657\n",
      "Epoch 221, Loss: 0.4153124279254653\n",
      "Epoch 222, Loss: 0.4104582809838288\n",
      "Epoch 223, Loss: 0.4101367219181661\n",
      "Epoch 224, Loss: 0.4157081327260397\n",
      "Epoch 225, Loss: 0.4144226163660391\n",
      "Epoch 226, Loss: 0.4098329995970875\n",
      "Epoch 227, Loss: 0.40775029376666666\n",
      "Epoch 228, Loss: 0.41429755898335924\n",
      "Epoch 229, Loss: 0.41521591906294136\n",
      "Epoch 230, Loss: 0.4099844981670613\n",
      "Epoch 231, Loss: 0.4074908343553954\n",
      "Epoch 232, Loss: 0.41404155462298753\n",
      "Epoch 233, Loss: 0.41428398110821113\n",
      "Epoch 234, Loss: 0.411010796569875\n",
      "Epoch 235, Loss: 0.40626047194262166\n",
      "Epoch 236, Loss: 0.409034666887797\n",
      "Epoch 237, Loss: 0.4158159770891869\n",
      "Epoch 238, Loss: 0.4153325557817546\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22030604523861827\n",
      "Test R^2 score: 0.47270805980715297\n",
      "Num of epochs: 239\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Epoch 179, Loss: 0.42867030340024453\n",
      "Epoch 180, Loss: 0.42665902048327814\n",
      "Epoch 181, Loss: 0.4160041986606613\n",
      "Epoch 182, Loss: 0.42380692389414293\n",
      "Epoch 183, Loss: 0.4367609764525626\n",
      "Epoch 184, Loss: 0.42557170506243686\n",
      "Epoch 185, Loss: 0.42106826790053603\n",
      "Epoch 186, Loss: 0.42573876125176086\n",
      "Epoch 187, Loss: 0.41925407360374856\n",
      "Epoch 188, Loss: 0.4183384695092418\n",
      "Epoch 189, Loss: 0.4218813047997579\n",
      "Epoch 190, Loss: 0.4197713005325469\n",
      "Epoch 191, Loss: 0.417197451669247\n",
      "Epoch 192, Loss: 0.41998586832409235\n",
      "Epoch 193, Loss: 0.4198630180807017\n",
      "Epoch 194, Loss: 0.4146118298837611\n",
      "Epoch 195, Loss: 0.41413205840097117\n",
      "Epoch 196, Loss: 0.4155607826414292\n",
      "Epoch 197, Loss: 0.414238532452658\n",
      "Epoch 198, Loss: 0.41297339310852155\n",
      "Epoch 199, Loss: 0.4123900845056213\n",
      "Epoch 200, Loss: 0.4134311180746695\n",
      "Epoch 201, Loss: 0.4127689164145939\n",
      "Epoch 202, Loss: 0.41232720715179455\n",
      "Epoch 203, Loss: 0.41150345937125327\n",
      "Epoch 204, Loss: 0.4115020652257978\n",
      "Epoch 205, Loss: 0.411078297677327\n",
      "Epoch 206, Loss: 0.4110567108542411\n",
      "Epoch 207, Loss: 0.4114023806357039\n",
      "Epoch 208, Loss: 0.41371932293434216\n",
      "Epoch 209, Loss: 0.41813952085771794\n",
      "Epoch 210, Loss: 0.42511728996367454\n",
      "Epoch 211, Loss: 0.42635158522503447\n",
      "Epoch 212, Loss: 0.419673136297028\n",
      "Epoch 213, Loss: 0.41005224089892217\n",
      "Epoch 214, Loss: 0.4205638856971283\n",
      "Epoch 215, Loss: 0.4288454648496258\n",
      "Epoch 216, Loss: 0.416730043439161\n",
      "Epoch 217, Loss: 0.4131035226095487\n",
      "Epoch 218, Loss: 0.41919050177663497\n",
      "Epoch 219, Loss: 0.41341632229404196\n",
      "Epoch 220, Loss: 0.411337015720657\n",
      "Epoch 221, Loss: 0.4153124279254653\n",
      "Epoch 222, Loss: 0.4104582809838288\n",
      "Epoch 223, Loss: 0.4101367219181661\n",
      "Epoch 224, Loss: 0.4157081327260397\n",
      "Epoch 225, Loss: 0.4144226163660391\n",
      "Epoch 226, Loss: 0.4098329995970875\n",
      "Epoch 227, Loss: 0.40775029376666666\n",
      "Epoch 228, Loss: 0.41429755898335924\n",
      "Epoch 229, Loss: 0.41521591906294136\n",
      "Epoch 230, Loss: 0.4099844981670613\n",
      "Epoch 231, Loss: 0.4074908343553954\n",
      "Epoch 232, Loss: 0.41404155462298753\n",
      "Epoch 233, Loss: 0.41428398110821113\n",
      "Epoch 234, Loss: 0.411010796569875\n",
      "Epoch 235, Loss: 0.40626047194262166\n",
      "Epoch 236, Loss: 0.409034666887797\n",
      "Epoch 237, Loss: 0.4158159770891869\n",
      "Epoch 238, Loss: 0.4153325557817546\n",
      "Epoch 239, Loss: 0.40773651613666245\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22336569897629413\n",
      "Test R^2 score: 0.45838467466653815\n",
      "Num of epochs: 240\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Epoch 179, Loss: 0.42867030340024453\n",
      "Epoch 180, Loss: 0.42665902048327814\n",
      "Epoch 181, Loss: 0.4160041986606613\n",
      "Epoch 182, Loss: 0.42380692389414293\n",
      "Epoch 183, Loss: 0.4367609764525626\n",
      "Epoch 184, Loss: 0.42557170506243686\n",
      "Epoch 185, Loss: 0.42106826790053603\n",
      "Epoch 186, Loss: 0.42573876125176086\n",
      "Epoch 187, Loss: 0.41925407360374856\n",
      "Epoch 188, Loss: 0.4183384695092418\n",
      "Epoch 189, Loss: 0.4218813047997579\n",
      "Epoch 190, Loss: 0.4197713005325469\n",
      "Epoch 191, Loss: 0.417197451669247\n",
      "Epoch 192, Loss: 0.41998586832409235\n",
      "Epoch 193, Loss: 0.4198630180807017\n",
      "Epoch 194, Loss: 0.4146118298837611\n",
      "Epoch 195, Loss: 0.41413205840097117\n",
      "Epoch 196, Loss: 0.4155607826414292\n",
      "Epoch 197, Loss: 0.414238532452658\n",
      "Epoch 198, Loss: 0.41297339310852155\n",
      "Epoch 199, Loss: 0.4123900845056213\n",
      "Epoch 200, Loss: 0.4134311180746695\n",
      "Epoch 201, Loss: 0.4127689164145939\n",
      "Epoch 202, Loss: 0.41232720715179455\n",
      "Epoch 203, Loss: 0.41150345937125327\n",
      "Epoch 204, Loss: 0.4115020652257978\n",
      "Epoch 205, Loss: 0.411078297677327\n",
      "Epoch 206, Loss: 0.4110567108542411\n",
      "Epoch 207, Loss: 0.4114023806357039\n",
      "Epoch 208, Loss: 0.41371932293434216\n",
      "Epoch 209, Loss: 0.41813952085771794\n",
      "Epoch 210, Loss: 0.42511728996367454\n",
      "Epoch 211, Loss: 0.42635158522503447\n",
      "Epoch 212, Loss: 0.419673136297028\n",
      "Epoch 213, Loss: 0.41005224089892217\n",
      "Epoch 214, Loss: 0.4205638856971283\n",
      "Epoch 215, Loss: 0.4288454648496258\n",
      "Epoch 216, Loss: 0.416730043439161\n",
      "Epoch 217, Loss: 0.4131035226095487\n",
      "Epoch 218, Loss: 0.41919050177663497\n",
      "Epoch 219, Loss: 0.41341632229404196\n",
      "Epoch 220, Loss: 0.411337015720657\n",
      "Epoch 221, Loss: 0.4153124279254653\n",
      "Epoch 222, Loss: 0.4104582809838288\n",
      "Epoch 223, Loss: 0.4101367219181661\n",
      "Epoch 224, Loss: 0.4157081327260397\n",
      "Epoch 225, Loss: 0.4144226163660391\n",
      "Epoch 226, Loss: 0.4098329995970875\n",
      "Epoch 227, Loss: 0.40775029376666666\n",
      "Epoch 228, Loss: 0.41429755898335924\n",
      "Epoch 229, Loss: 0.41521591906294136\n",
      "Epoch 230, Loss: 0.4099844981670613\n",
      "Epoch 231, Loss: 0.4074908343553954\n",
      "Epoch 232, Loss: 0.41404155462298753\n",
      "Epoch 233, Loss: 0.41428398110821113\n",
      "Epoch 234, Loss: 0.411010796569875\n",
      "Epoch 235, Loss: 0.40626047194262166\n",
      "Epoch 236, Loss: 0.409034666887797\n",
      "Epoch 237, Loss: 0.4158159770891869\n",
      "Epoch 238, Loss: 0.4153325557817546\n",
      "Epoch 239, Loss: 0.40773651613666245\n",
      "Epoch 240, Loss: 0.40720486297242386\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22368445955026783\n",
      "Test R^2 score: 0.45790379405448545\n",
      "Num of epochs: 241\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Epoch 179, Loss: 0.42867030340024453\n",
      "Epoch 180, Loss: 0.42665902048327814\n",
      "Epoch 181, Loss: 0.4160041986606613\n",
      "Epoch 182, Loss: 0.42380692389414293\n",
      "Epoch 183, Loss: 0.4367609764525626\n",
      "Epoch 184, Loss: 0.42557170506243686\n",
      "Epoch 185, Loss: 0.42106826790053603\n",
      "Epoch 186, Loss: 0.42573876125176086\n",
      "Epoch 187, Loss: 0.41925407360374856\n",
      "Epoch 188, Loss: 0.4183384695092418\n",
      "Epoch 189, Loss: 0.4218813047997579\n",
      "Epoch 190, Loss: 0.4197713005325469\n",
      "Epoch 191, Loss: 0.417197451669247\n",
      "Epoch 192, Loss: 0.41998586832409235\n",
      "Epoch 193, Loss: 0.4198630180807017\n",
      "Epoch 194, Loss: 0.4146118298837611\n",
      "Epoch 195, Loss: 0.41413205840097117\n",
      "Epoch 196, Loss: 0.4155607826414292\n",
      "Epoch 197, Loss: 0.414238532452658\n",
      "Epoch 198, Loss: 0.41297339310852155\n",
      "Epoch 199, Loss: 0.4123900845056213\n",
      "Epoch 200, Loss: 0.4134311180746695\n",
      "Epoch 201, Loss: 0.4127689164145939\n",
      "Epoch 202, Loss: 0.41232720715179455\n",
      "Epoch 203, Loss: 0.41150345937125327\n",
      "Epoch 204, Loss: 0.4115020652257978\n",
      "Epoch 205, Loss: 0.411078297677327\n",
      "Epoch 206, Loss: 0.4110567108542411\n",
      "Epoch 207, Loss: 0.4114023806357039\n",
      "Epoch 208, Loss: 0.41371932293434216\n",
      "Epoch 209, Loss: 0.41813952085771794\n",
      "Epoch 210, Loss: 0.42511728996367454\n",
      "Epoch 211, Loss: 0.42635158522503447\n",
      "Epoch 212, Loss: 0.419673136297028\n",
      "Epoch 213, Loss: 0.41005224089892217\n",
      "Epoch 214, Loss: 0.4205638856971283\n",
      "Epoch 215, Loss: 0.4288454648496258\n",
      "Epoch 216, Loss: 0.416730043439161\n",
      "Epoch 217, Loss: 0.4131035226095487\n",
      "Epoch 218, Loss: 0.41919050177663497\n",
      "Epoch 219, Loss: 0.41341632229404196\n",
      "Epoch 220, Loss: 0.411337015720657\n",
      "Epoch 221, Loss: 0.4153124279254653\n",
      "Epoch 222, Loss: 0.4104582809838288\n",
      "Epoch 223, Loss: 0.4101367219181661\n",
      "Epoch 224, Loss: 0.4157081327260397\n",
      "Epoch 225, Loss: 0.4144226163660391\n",
      "Epoch 226, Loss: 0.4098329995970875\n",
      "Epoch 227, Loss: 0.40775029376666666\n",
      "Epoch 228, Loss: 0.41429755898335924\n",
      "Epoch 229, Loss: 0.41521591906294136\n",
      "Epoch 230, Loss: 0.4099844981670613\n",
      "Epoch 231, Loss: 0.4074908343553954\n",
      "Epoch 232, Loss: 0.41404155462298753\n",
      "Epoch 233, Loss: 0.41428398110821113\n",
      "Epoch 234, Loss: 0.411010796569875\n",
      "Epoch 235, Loss: 0.40626047194262166\n",
      "Epoch 236, Loss: 0.409034666887797\n",
      "Epoch 237, Loss: 0.4158159770891869\n",
      "Epoch 238, Loss: 0.4153325557817546\n",
      "Epoch 239, Loss: 0.40773651613666245\n",
      "Epoch 240, Loss: 0.40720486297242386\n",
      "Epoch 241, Loss: 0.41676379700873606\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2328205452465436\n",
      "Test R^2 score: 0.41145413195029057\n",
      "Num of epochs: 242\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Epoch 179, Loss: 0.42867030340024453\n",
      "Epoch 180, Loss: 0.42665902048327814\n",
      "Epoch 181, Loss: 0.4160041986606613\n",
      "Epoch 182, Loss: 0.42380692389414293\n",
      "Epoch 183, Loss: 0.4367609764525626\n",
      "Epoch 184, Loss: 0.42557170506243686\n",
      "Epoch 185, Loss: 0.42106826790053603\n",
      "Epoch 186, Loss: 0.42573876125176086\n",
      "Epoch 187, Loss: 0.41925407360374856\n",
      "Epoch 188, Loss: 0.4183384695092418\n",
      "Epoch 189, Loss: 0.4218813047997579\n",
      "Epoch 190, Loss: 0.4197713005325469\n",
      "Epoch 191, Loss: 0.417197451669247\n",
      "Epoch 192, Loss: 0.41998586832409235\n",
      "Epoch 193, Loss: 0.4198630180807017\n",
      "Epoch 194, Loss: 0.4146118298837611\n",
      "Epoch 195, Loss: 0.41413205840097117\n",
      "Epoch 196, Loss: 0.4155607826414292\n",
      "Epoch 197, Loss: 0.414238532452658\n",
      "Epoch 198, Loss: 0.41297339310852155\n",
      "Epoch 199, Loss: 0.4123900845056213\n",
      "Epoch 200, Loss: 0.4134311180746695\n",
      "Epoch 201, Loss: 0.4127689164145939\n",
      "Epoch 202, Loss: 0.41232720715179455\n",
      "Epoch 203, Loss: 0.41150345937125327\n",
      "Epoch 204, Loss: 0.4115020652257978\n",
      "Epoch 205, Loss: 0.411078297677327\n",
      "Epoch 206, Loss: 0.4110567108542411\n",
      "Epoch 207, Loss: 0.4114023806357039\n",
      "Epoch 208, Loss: 0.41371932293434216\n",
      "Epoch 209, Loss: 0.41813952085771794\n",
      "Epoch 210, Loss: 0.42511728996367454\n",
      "Epoch 211, Loss: 0.42635158522503447\n",
      "Epoch 212, Loss: 0.419673136297028\n",
      "Epoch 213, Loss: 0.41005224089892217\n",
      "Epoch 214, Loss: 0.4205638856971283\n",
      "Epoch 215, Loss: 0.4288454648496258\n",
      "Epoch 216, Loss: 0.416730043439161\n",
      "Epoch 217, Loss: 0.4131035226095487\n",
      "Epoch 218, Loss: 0.41919050177663497\n",
      "Epoch 219, Loss: 0.41341632229404196\n",
      "Epoch 220, Loss: 0.411337015720657\n",
      "Epoch 221, Loss: 0.4153124279254653\n",
      "Epoch 222, Loss: 0.4104582809838288\n",
      "Epoch 223, Loss: 0.4101367219181661\n",
      "Epoch 224, Loss: 0.4157081327260397\n",
      "Epoch 225, Loss: 0.4144226163660391\n",
      "Epoch 226, Loss: 0.4098329995970875\n",
      "Epoch 227, Loss: 0.40775029376666666\n",
      "Epoch 228, Loss: 0.41429755898335924\n",
      "Epoch 229, Loss: 0.41521591906294136\n",
      "Epoch 230, Loss: 0.4099844981670613\n",
      "Epoch 231, Loss: 0.4074908343553954\n",
      "Epoch 232, Loss: 0.41404155462298753\n",
      "Epoch 233, Loss: 0.41428398110821113\n",
      "Epoch 234, Loss: 0.411010796569875\n",
      "Epoch 235, Loss: 0.40626047194262166\n",
      "Epoch 236, Loss: 0.409034666887797\n",
      "Epoch 237, Loss: 0.4158159770891869\n",
      "Epoch 238, Loss: 0.4153325557817546\n",
      "Epoch 239, Loss: 0.40773651613666245\n",
      "Epoch 240, Loss: 0.40720486297242386\n",
      "Epoch 241, Loss: 0.41676379700873606\n",
      "Epoch 242, Loss: 0.4163271136351227\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21846692700784487\n",
      "Test R^2 score: 0.4816740806770047\n",
      "Num of epochs: 243\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Epoch 179, Loss: 0.42867030340024453\n",
      "Epoch 180, Loss: 0.42665902048327814\n",
      "Epoch 181, Loss: 0.4160041986606613\n",
      "Epoch 182, Loss: 0.42380692389414293\n",
      "Epoch 183, Loss: 0.4367609764525626\n",
      "Epoch 184, Loss: 0.42557170506243686\n",
      "Epoch 185, Loss: 0.42106826790053603\n",
      "Epoch 186, Loss: 0.42573876125176086\n",
      "Epoch 187, Loss: 0.41925407360374856\n",
      "Epoch 188, Loss: 0.4183384695092418\n",
      "Epoch 189, Loss: 0.4218813047997579\n",
      "Epoch 190, Loss: 0.4197713005325469\n",
      "Epoch 191, Loss: 0.417197451669247\n",
      "Epoch 192, Loss: 0.41998586832409235\n",
      "Epoch 193, Loss: 0.4198630180807017\n",
      "Epoch 194, Loss: 0.4146118298837611\n",
      "Epoch 195, Loss: 0.41413205840097117\n",
      "Epoch 196, Loss: 0.4155607826414292\n",
      "Epoch 197, Loss: 0.414238532452658\n",
      "Epoch 198, Loss: 0.41297339310852155\n",
      "Epoch 199, Loss: 0.4123900845056213\n",
      "Epoch 200, Loss: 0.4134311180746695\n",
      "Epoch 201, Loss: 0.4127689164145939\n",
      "Epoch 202, Loss: 0.41232720715179455\n",
      "Epoch 203, Loss: 0.41150345937125327\n",
      "Epoch 204, Loss: 0.4115020652257978\n",
      "Epoch 205, Loss: 0.411078297677327\n",
      "Epoch 206, Loss: 0.4110567108542411\n",
      "Epoch 207, Loss: 0.4114023806357039\n",
      "Epoch 208, Loss: 0.41371932293434216\n",
      "Epoch 209, Loss: 0.41813952085771794\n",
      "Epoch 210, Loss: 0.42511728996367454\n",
      "Epoch 211, Loss: 0.42635158522503447\n",
      "Epoch 212, Loss: 0.419673136297028\n",
      "Epoch 213, Loss: 0.41005224089892217\n",
      "Epoch 214, Loss: 0.4205638856971283\n",
      "Epoch 215, Loss: 0.4288454648496258\n",
      "Epoch 216, Loss: 0.416730043439161\n",
      "Epoch 217, Loss: 0.4131035226095487\n",
      "Epoch 218, Loss: 0.41919050177663497\n",
      "Epoch 219, Loss: 0.41341632229404196\n",
      "Epoch 220, Loss: 0.411337015720657\n",
      "Epoch 221, Loss: 0.4153124279254653\n",
      "Epoch 222, Loss: 0.4104582809838288\n",
      "Epoch 223, Loss: 0.4101367219181661\n",
      "Epoch 224, Loss: 0.4157081327260397\n",
      "Epoch 225, Loss: 0.4144226163660391\n",
      "Epoch 226, Loss: 0.4098329995970875\n",
      "Epoch 227, Loss: 0.40775029376666666\n",
      "Epoch 228, Loss: 0.41429755898335924\n",
      "Epoch 229, Loss: 0.41521591906294136\n",
      "Epoch 230, Loss: 0.4099844981670613\n",
      "Epoch 231, Loss: 0.4074908343553954\n",
      "Epoch 232, Loss: 0.41404155462298753\n",
      "Epoch 233, Loss: 0.41428398110821113\n",
      "Epoch 234, Loss: 0.411010796569875\n",
      "Epoch 235, Loss: 0.40626047194262166\n",
      "Epoch 236, Loss: 0.409034666887797\n",
      "Epoch 237, Loss: 0.4158159770891869\n",
      "Epoch 238, Loss: 0.4153325557817546\n",
      "Epoch 239, Loss: 0.40773651613666245\n",
      "Epoch 240, Loss: 0.40720486297242386\n",
      "Epoch 241, Loss: 0.41676379700873606\n",
      "Epoch 242, Loss: 0.4163271136351227\n",
      "Epoch 243, Loss: 0.4079038079306381\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21953899323712114\n",
      "Test R^2 score: 0.47682857575740967\n",
      "Num of epochs: 244\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Epoch 179, Loss: 0.42867030340024453\n",
      "Epoch 180, Loss: 0.42665902048327814\n",
      "Epoch 181, Loss: 0.4160041986606613\n",
      "Epoch 182, Loss: 0.42380692389414293\n",
      "Epoch 183, Loss: 0.4367609764525626\n",
      "Epoch 184, Loss: 0.42557170506243686\n",
      "Epoch 185, Loss: 0.42106826790053603\n",
      "Epoch 186, Loss: 0.42573876125176086\n",
      "Epoch 187, Loss: 0.41925407360374856\n",
      "Epoch 188, Loss: 0.4183384695092418\n",
      "Epoch 189, Loss: 0.4218813047997579\n",
      "Epoch 190, Loss: 0.4197713005325469\n",
      "Epoch 191, Loss: 0.417197451669247\n",
      "Epoch 192, Loss: 0.41998586832409235\n",
      "Epoch 193, Loss: 0.4198630180807017\n",
      "Epoch 194, Loss: 0.4146118298837611\n",
      "Epoch 195, Loss: 0.41413205840097117\n",
      "Epoch 196, Loss: 0.4155607826414292\n",
      "Epoch 197, Loss: 0.414238532452658\n",
      "Epoch 198, Loss: 0.41297339310852155\n",
      "Epoch 199, Loss: 0.4123900845056213\n",
      "Epoch 200, Loss: 0.4134311180746695\n",
      "Epoch 201, Loss: 0.4127689164145939\n",
      "Epoch 202, Loss: 0.41232720715179455\n",
      "Epoch 203, Loss: 0.41150345937125327\n",
      "Epoch 204, Loss: 0.4115020652257978\n",
      "Epoch 205, Loss: 0.411078297677327\n",
      "Epoch 206, Loss: 0.4110567108542411\n",
      "Epoch 207, Loss: 0.4114023806357039\n",
      "Epoch 208, Loss: 0.41371932293434216\n",
      "Epoch 209, Loss: 0.41813952085771794\n",
      "Epoch 210, Loss: 0.42511728996367454\n",
      "Epoch 211, Loss: 0.42635158522503447\n",
      "Epoch 212, Loss: 0.419673136297028\n",
      "Epoch 213, Loss: 0.41005224089892217\n",
      "Epoch 214, Loss: 0.4205638856971283\n",
      "Epoch 215, Loss: 0.4288454648496258\n",
      "Epoch 216, Loss: 0.416730043439161\n",
      "Epoch 217, Loss: 0.4131035226095487\n",
      "Epoch 218, Loss: 0.41919050177663497\n",
      "Epoch 219, Loss: 0.41341632229404196\n",
      "Epoch 220, Loss: 0.411337015720657\n",
      "Epoch 221, Loss: 0.4153124279254653\n",
      "Epoch 222, Loss: 0.4104582809838288\n",
      "Epoch 223, Loss: 0.4101367219181661\n",
      "Epoch 224, Loss: 0.4157081327260397\n",
      "Epoch 225, Loss: 0.4144226163660391\n",
      "Epoch 226, Loss: 0.4098329995970875\n",
      "Epoch 227, Loss: 0.40775029376666666\n",
      "Epoch 228, Loss: 0.41429755898335924\n",
      "Epoch 229, Loss: 0.41521591906294136\n",
      "Epoch 230, Loss: 0.4099844981670613\n",
      "Epoch 231, Loss: 0.4074908343553954\n",
      "Epoch 232, Loss: 0.41404155462298753\n",
      "Epoch 233, Loss: 0.41428398110821113\n",
      "Epoch 234, Loss: 0.411010796569875\n",
      "Epoch 235, Loss: 0.40626047194262166\n",
      "Epoch 236, Loss: 0.409034666887797\n",
      "Epoch 237, Loss: 0.4158159770891869\n",
      "Epoch 238, Loss: 0.4153325557817546\n",
      "Epoch 239, Loss: 0.40773651613666245\n",
      "Epoch 240, Loss: 0.40720486297242386\n",
      "Epoch 241, Loss: 0.41676379700873606\n",
      "Epoch 242, Loss: 0.4163271136351227\n",
      "Epoch 243, Loss: 0.4079038079306381\n",
      "Epoch 244, Loss: 0.41018584008428094\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.23752774252701844\n",
      "Test R^2 score: 0.3872089592033495\n",
      "Num of epochs: 245\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Epoch 179, Loss: 0.42867030340024453\n",
      "Epoch 180, Loss: 0.42665902048327814\n",
      "Epoch 181, Loss: 0.4160041986606613\n",
      "Epoch 182, Loss: 0.42380692389414293\n",
      "Epoch 183, Loss: 0.4367609764525626\n",
      "Epoch 184, Loss: 0.42557170506243686\n",
      "Epoch 185, Loss: 0.42106826790053603\n",
      "Epoch 186, Loss: 0.42573876125176086\n",
      "Epoch 187, Loss: 0.41925407360374856\n",
      "Epoch 188, Loss: 0.4183384695092418\n",
      "Epoch 189, Loss: 0.4218813047997579\n",
      "Epoch 190, Loss: 0.4197713005325469\n",
      "Epoch 191, Loss: 0.417197451669247\n",
      "Epoch 192, Loss: 0.41998586832409235\n",
      "Epoch 193, Loss: 0.4198630180807017\n",
      "Epoch 194, Loss: 0.4146118298837611\n",
      "Epoch 195, Loss: 0.41413205840097117\n",
      "Epoch 196, Loss: 0.4155607826414292\n",
      "Epoch 197, Loss: 0.414238532452658\n",
      "Epoch 198, Loss: 0.41297339310852155\n",
      "Epoch 199, Loss: 0.4123900845056213\n",
      "Epoch 200, Loss: 0.4134311180746695\n",
      "Epoch 201, Loss: 0.4127689164145939\n",
      "Epoch 202, Loss: 0.41232720715179455\n",
      "Epoch 203, Loss: 0.41150345937125327\n",
      "Epoch 204, Loss: 0.4115020652257978\n",
      "Epoch 205, Loss: 0.411078297677327\n",
      "Epoch 206, Loss: 0.4110567108542411\n",
      "Epoch 207, Loss: 0.4114023806357039\n",
      "Epoch 208, Loss: 0.41371932293434216\n",
      "Epoch 209, Loss: 0.41813952085771794\n",
      "Epoch 210, Loss: 0.42511728996367454\n",
      "Epoch 211, Loss: 0.42635158522503447\n",
      "Epoch 212, Loss: 0.419673136297028\n",
      "Epoch 213, Loss: 0.41005224089892217\n",
      "Epoch 214, Loss: 0.4205638856971283\n",
      "Epoch 215, Loss: 0.4288454648496258\n",
      "Epoch 216, Loss: 0.416730043439161\n",
      "Epoch 217, Loss: 0.4131035226095487\n",
      "Epoch 218, Loss: 0.41919050177663497\n",
      "Epoch 219, Loss: 0.41341632229404196\n",
      "Epoch 220, Loss: 0.411337015720657\n",
      "Epoch 221, Loss: 0.4153124279254653\n",
      "Epoch 222, Loss: 0.4104582809838288\n",
      "Epoch 223, Loss: 0.4101367219181661\n",
      "Epoch 224, Loss: 0.4157081327260397\n",
      "Epoch 225, Loss: 0.4144226163660391\n",
      "Epoch 226, Loss: 0.4098329995970875\n",
      "Epoch 227, Loss: 0.40775029376666666\n",
      "Epoch 228, Loss: 0.41429755898335924\n",
      "Epoch 229, Loss: 0.41521591906294136\n",
      "Epoch 230, Loss: 0.4099844981670613\n",
      "Epoch 231, Loss: 0.4074908343553954\n",
      "Epoch 232, Loss: 0.41404155462298753\n",
      "Epoch 233, Loss: 0.41428398110821113\n",
      "Epoch 234, Loss: 0.411010796569875\n",
      "Epoch 235, Loss: 0.40626047194262166\n",
      "Epoch 236, Loss: 0.409034666887797\n",
      "Epoch 237, Loss: 0.4158159770891869\n",
      "Epoch 238, Loss: 0.4153325557817546\n",
      "Epoch 239, Loss: 0.40773651613666245\n",
      "Epoch 240, Loss: 0.40720486297242386\n",
      "Epoch 241, Loss: 0.41676379700873606\n",
      "Epoch 242, Loss: 0.4163271136351227\n",
      "Epoch 243, Loss: 0.4079038079306381\n",
      "Epoch 244, Loss: 0.41018584008428094\n",
      "Epoch 245, Loss: 0.4183221731020751\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22083028120576242\n",
      "Test R^2 score: 0.4712571068225531\n",
      "Num of epochs: 246\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Epoch 179, Loss: 0.42867030340024453\n",
      "Epoch 180, Loss: 0.42665902048327814\n",
      "Epoch 181, Loss: 0.4160041986606613\n",
      "Epoch 182, Loss: 0.42380692389414293\n",
      "Epoch 183, Loss: 0.4367609764525626\n",
      "Epoch 184, Loss: 0.42557170506243686\n",
      "Epoch 185, Loss: 0.42106826790053603\n",
      "Epoch 186, Loss: 0.42573876125176086\n",
      "Epoch 187, Loss: 0.41925407360374856\n",
      "Epoch 188, Loss: 0.4183384695092418\n",
      "Epoch 189, Loss: 0.4218813047997579\n",
      "Epoch 190, Loss: 0.4197713005325469\n",
      "Epoch 191, Loss: 0.417197451669247\n",
      "Epoch 192, Loss: 0.41998586832409235\n",
      "Epoch 193, Loss: 0.4198630180807017\n",
      "Epoch 194, Loss: 0.4146118298837611\n",
      "Epoch 195, Loss: 0.41413205840097117\n",
      "Epoch 196, Loss: 0.4155607826414292\n",
      "Epoch 197, Loss: 0.414238532452658\n",
      "Epoch 198, Loss: 0.41297339310852155\n",
      "Epoch 199, Loss: 0.4123900845056213\n",
      "Epoch 200, Loss: 0.4134311180746695\n",
      "Epoch 201, Loss: 0.4127689164145939\n",
      "Epoch 202, Loss: 0.41232720715179455\n",
      "Epoch 203, Loss: 0.41150345937125327\n",
      "Epoch 204, Loss: 0.4115020652257978\n",
      "Epoch 205, Loss: 0.411078297677327\n",
      "Epoch 206, Loss: 0.4110567108542411\n",
      "Epoch 207, Loss: 0.4114023806357039\n",
      "Epoch 208, Loss: 0.41371932293434216\n",
      "Epoch 209, Loss: 0.41813952085771794\n",
      "Epoch 210, Loss: 0.42511728996367454\n",
      "Epoch 211, Loss: 0.42635158522503447\n",
      "Epoch 212, Loss: 0.419673136297028\n",
      "Epoch 213, Loss: 0.41005224089892217\n",
      "Epoch 214, Loss: 0.4205638856971283\n",
      "Epoch 215, Loss: 0.4288454648496258\n",
      "Epoch 216, Loss: 0.416730043439161\n",
      "Epoch 217, Loss: 0.4131035226095487\n",
      "Epoch 218, Loss: 0.41919050177663497\n",
      "Epoch 219, Loss: 0.41341632229404196\n",
      "Epoch 220, Loss: 0.411337015720657\n",
      "Epoch 221, Loss: 0.4153124279254653\n",
      "Epoch 222, Loss: 0.4104582809838288\n",
      "Epoch 223, Loss: 0.4101367219181661\n",
      "Epoch 224, Loss: 0.4157081327260397\n",
      "Epoch 225, Loss: 0.4144226163660391\n",
      "Epoch 226, Loss: 0.4098329995970875\n",
      "Epoch 227, Loss: 0.40775029376666666\n",
      "Epoch 228, Loss: 0.41429755898335924\n",
      "Epoch 229, Loss: 0.41521591906294136\n",
      "Epoch 230, Loss: 0.4099844981670613\n",
      "Epoch 231, Loss: 0.4074908343553954\n",
      "Epoch 232, Loss: 0.41404155462298753\n",
      "Epoch 233, Loss: 0.41428398110821113\n",
      "Epoch 234, Loss: 0.411010796569875\n",
      "Epoch 235, Loss: 0.40626047194262166\n",
      "Epoch 236, Loss: 0.409034666887797\n",
      "Epoch 237, Loss: 0.4158159770891869\n",
      "Epoch 238, Loss: 0.4153325557817546\n",
      "Epoch 239, Loss: 0.40773651613666245\n",
      "Epoch 240, Loss: 0.40720486297242386\n",
      "Epoch 241, Loss: 0.41676379700873606\n",
      "Epoch 242, Loss: 0.4163271136351227\n",
      "Epoch 243, Loss: 0.4079038079306381\n",
      "Epoch 244, Loss: 0.41018584008428094\n",
      "Epoch 245, Loss: 0.4183221731020751\n",
      "Epoch 246, Loss: 0.4083151230189892\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21849454809990362\n",
      "Test R^2 score: 0.4818798232163291\n",
      "Num of epochs: 247\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Epoch 179, Loss: 0.42867030340024453\n",
      "Epoch 180, Loss: 0.42665902048327814\n",
      "Epoch 181, Loss: 0.4160041986606613\n",
      "Epoch 182, Loss: 0.42380692389414293\n",
      "Epoch 183, Loss: 0.4367609764525626\n",
      "Epoch 184, Loss: 0.42557170506243686\n",
      "Epoch 185, Loss: 0.42106826790053603\n",
      "Epoch 186, Loss: 0.42573876125176086\n",
      "Epoch 187, Loss: 0.41925407360374856\n",
      "Epoch 188, Loss: 0.4183384695092418\n",
      "Epoch 189, Loss: 0.4218813047997579\n",
      "Epoch 190, Loss: 0.4197713005325469\n",
      "Epoch 191, Loss: 0.417197451669247\n",
      "Epoch 192, Loss: 0.41998586832409235\n",
      "Epoch 193, Loss: 0.4198630180807017\n",
      "Epoch 194, Loss: 0.4146118298837611\n",
      "Epoch 195, Loss: 0.41413205840097117\n",
      "Epoch 196, Loss: 0.4155607826414292\n",
      "Epoch 197, Loss: 0.414238532452658\n",
      "Epoch 198, Loss: 0.41297339310852155\n",
      "Epoch 199, Loss: 0.4123900845056213\n",
      "Epoch 200, Loss: 0.4134311180746695\n",
      "Epoch 201, Loss: 0.4127689164145939\n",
      "Epoch 202, Loss: 0.41232720715179455\n",
      "Epoch 203, Loss: 0.41150345937125327\n",
      "Epoch 204, Loss: 0.4115020652257978\n",
      "Epoch 205, Loss: 0.411078297677327\n",
      "Epoch 206, Loss: 0.4110567108542411\n",
      "Epoch 207, Loss: 0.4114023806357039\n",
      "Epoch 208, Loss: 0.41371932293434216\n",
      "Epoch 209, Loss: 0.41813952085771794\n",
      "Epoch 210, Loss: 0.42511728996367454\n",
      "Epoch 211, Loss: 0.42635158522503447\n",
      "Epoch 212, Loss: 0.419673136297028\n",
      "Epoch 213, Loss: 0.41005224089892217\n",
      "Epoch 214, Loss: 0.4205638856971283\n",
      "Epoch 215, Loss: 0.4288454648496258\n",
      "Epoch 216, Loss: 0.416730043439161\n",
      "Epoch 217, Loss: 0.4131035226095487\n",
      "Epoch 218, Loss: 0.41919050177663497\n",
      "Epoch 219, Loss: 0.41341632229404196\n",
      "Epoch 220, Loss: 0.411337015720657\n",
      "Epoch 221, Loss: 0.4153124279254653\n",
      "Epoch 222, Loss: 0.4104582809838288\n",
      "Epoch 223, Loss: 0.4101367219181661\n",
      "Epoch 224, Loss: 0.4157081327260397\n",
      "Epoch 225, Loss: 0.4144226163660391\n",
      "Epoch 226, Loss: 0.4098329995970875\n",
      "Epoch 227, Loss: 0.40775029376666666\n",
      "Epoch 228, Loss: 0.41429755898335924\n",
      "Epoch 229, Loss: 0.41521591906294136\n",
      "Epoch 230, Loss: 0.4099844981670613\n",
      "Epoch 231, Loss: 0.4074908343553954\n",
      "Epoch 232, Loss: 0.41404155462298753\n",
      "Epoch 233, Loss: 0.41428398110821113\n",
      "Epoch 234, Loss: 0.411010796569875\n",
      "Epoch 235, Loss: 0.40626047194262166\n",
      "Epoch 236, Loss: 0.409034666887797\n",
      "Epoch 237, Loss: 0.4158159770891869\n",
      "Epoch 238, Loss: 0.4153325557817546\n",
      "Epoch 239, Loss: 0.40773651613666245\n",
      "Epoch 240, Loss: 0.40720486297242386\n",
      "Epoch 241, Loss: 0.41676379700873606\n",
      "Epoch 242, Loss: 0.4163271136351227\n",
      "Epoch 243, Loss: 0.4079038079306381\n",
      "Epoch 244, Loss: 0.41018584008428094\n",
      "Epoch 245, Loss: 0.4183221731020751\n",
      "Epoch 246, Loss: 0.4083151230189892\n",
      "Epoch 247, Loss: 0.403887555337203\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22510324218390065\n",
      "Test R^2 score: 0.4499688726754261\n",
      "Num of epochs: 248\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Epoch 179, Loss: 0.42867030340024453\n",
      "Epoch 180, Loss: 0.42665902048327814\n",
      "Epoch 181, Loss: 0.4160041986606613\n",
      "Epoch 182, Loss: 0.42380692389414293\n",
      "Epoch 183, Loss: 0.4367609764525626\n",
      "Epoch 184, Loss: 0.42557170506243686\n",
      "Epoch 185, Loss: 0.42106826790053603\n",
      "Epoch 186, Loss: 0.42573876125176086\n",
      "Epoch 187, Loss: 0.41925407360374856\n",
      "Epoch 188, Loss: 0.4183384695092418\n",
      "Epoch 189, Loss: 0.4218813047997579\n",
      "Epoch 190, Loss: 0.4197713005325469\n",
      "Epoch 191, Loss: 0.417197451669247\n",
      "Epoch 192, Loss: 0.41998586832409235\n",
      "Epoch 193, Loss: 0.4198630180807017\n",
      "Epoch 194, Loss: 0.4146118298837611\n",
      "Epoch 195, Loss: 0.41413205840097117\n",
      "Epoch 196, Loss: 0.4155607826414292\n",
      "Epoch 197, Loss: 0.414238532452658\n",
      "Epoch 198, Loss: 0.41297339310852155\n",
      "Epoch 199, Loss: 0.4123900845056213\n",
      "Epoch 200, Loss: 0.4134311180746695\n",
      "Epoch 201, Loss: 0.4127689164145939\n",
      "Epoch 202, Loss: 0.41232720715179455\n",
      "Epoch 203, Loss: 0.41150345937125327\n",
      "Epoch 204, Loss: 0.4115020652257978\n",
      "Epoch 205, Loss: 0.411078297677327\n",
      "Epoch 206, Loss: 0.4110567108542411\n",
      "Epoch 207, Loss: 0.4114023806357039\n",
      "Epoch 208, Loss: 0.41371932293434216\n",
      "Epoch 209, Loss: 0.41813952085771794\n",
      "Epoch 210, Loss: 0.42511728996367454\n",
      "Epoch 211, Loss: 0.42635158522503447\n",
      "Epoch 212, Loss: 0.419673136297028\n",
      "Epoch 213, Loss: 0.41005224089892217\n",
      "Epoch 214, Loss: 0.4205638856971283\n",
      "Epoch 215, Loss: 0.4288454648496258\n",
      "Epoch 216, Loss: 0.416730043439161\n",
      "Epoch 217, Loss: 0.4131035226095487\n",
      "Epoch 218, Loss: 0.41919050177663497\n",
      "Epoch 219, Loss: 0.41341632229404196\n",
      "Epoch 220, Loss: 0.411337015720657\n",
      "Epoch 221, Loss: 0.4153124279254653\n",
      "Epoch 222, Loss: 0.4104582809838288\n",
      "Epoch 223, Loss: 0.4101367219181661\n",
      "Epoch 224, Loss: 0.4157081327260397\n",
      "Epoch 225, Loss: 0.4144226163660391\n",
      "Epoch 226, Loss: 0.4098329995970875\n",
      "Epoch 227, Loss: 0.40775029376666666\n",
      "Epoch 228, Loss: 0.41429755898335924\n",
      "Epoch 229, Loss: 0.41521591906294136\n",
      "Epoch 230, Loss: 0.4099844981670613\n",
      "Epoch 231, Loss: 0.4074908343553954\n",
      "Epoch 232, Loss: 0.41404155462298753\n",
      "Epoch 233, Loss: 0.41428398110821113\n",
      "Epoch 234, Loss: 0.411010796569875\n",
      "Epoch 235, Loss: 0.40626047194262166\n",
      "Epoch 236, Loss: 0.409034666887797\n",
      "Epoch 237, Loss: 0.4158159770891869\n",
      "Epoch 238, Loss: 0.4153325557817546\n",
      "Epoch 239, Loss: 0.40773651613666245\n",
      "Epoch 240, Loss: 0.40720486297242386\n",
      "Epoch 241, Loss: 0.41676379700873606\n",
      "Epoch 242, Loss: 0.4163271136351227\n",
      "Epoch 243, Loss: 0.4079038079306381\n",
      "Epoch 244, Loss: 0.41018584008428094\n",
      "Epoch 245, Loss: 0.4183221731020751\n",
      "Epoch 246, Loss: 0.4083151230189892\n",
      "Epoch 247, Loss: 0.403887555337203\n",
      "Epoch 248, Loss: 0.4087575223213056\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2194205721093702\n",
      "Test R^2 score: 0.4778651978334868\n",
      "Num of epochs: 249\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Epoch 179, Loss: 0.42867030340024453\n",
      "Epoch 180, Loss: 0.42665902048327814\n",
      "Epoch 181, Loss: 0.4160041986606613\n",
      "Epoch 182, Loss: 0.42380692389414293\n",
      "Epoch 183, Loss: 0.4367609764525626\n",
      "Epoch 184, Loss: 0.42557170506243686\n",
      "Epoch 185, Loss: 0.42106826790053603\n",
      "Epoch 186, Loss: 0.42573876125176086\n",
      "Epoch 187, Loss: 0.41925407360374856\n",
      "Epoch 188, Loss: 0.4183384695092418\n",
      "Epoch 189, Loss: 0.4218813047997579\n",
      "Epoch 190, Loss: 0.4197713005325469\n",
      "Epoch 191, Loss: 0.417197451669247\n",
      "Epoch 192, Loss: 0.41998586832409235\n",
      "Epoch 193, Loss: 0.4198630180807017\n",
      "Epoch 194, Loss: 0.4146118298837611\n",
      "Epoch 195, Loss: 0.41413205840097117\n",
      "Epoch 196, Loss: 0.4155607826414292\n",
      "Epoch 197, Loss: 0.414238532452658\n",
      "Epoch 198, Loss: 0.41297339310852155\n",
      "Epoch 199, Loss: 0.4123900845056213\n",
      "Epoch 200, Loss: 0.4134311180746695\n",
      "Epoch 201, Loss: 0.4127689164145939\n",
      "Epoch 202, Loss: 0.41232720715179455\n",
      "Epoch 203, Loss: 0.41150345937125327\n",
      "Epoch 204, Loss: 0.4115020652257978\n",
      "Epoch 205, Loss: 0.411078297677327\n",
      "Epoch 206, Loss: 0.4110567108542411\n",
      "Epoch 207, Loss: 0.4114023806357039\n",
      "Epoch 208, Loss: 0.41371932293434216\n",
      "Epoch 209, Loss: 0.41813952085771794\n",
      "Epoch 210, Loss: 0.42511728996367454\n",
      "Epoch 211, Loss: 0.42635158522503447\n",
      "Epoch 212, Loss: 0.419673136297028\n",
      "Epoch 213, Loss: 0.41005224089892217\n",
      "Epoch 214, Loss: 0.4205638856971283\n",
      "Epoch 215, Loss: 0.4288454648496258\n",
      "Epoch 216, Loss: 0.416730043439161\n",
      "Epoch 217, Loss: 0.4131035226095487\n",
      "Epoch 218, Loss: 0.41919050177663497\n",
      "Epoch 219, Loss: 0.41341632229404196\n",
      "Epoch 220, Loss: 0.411337015720657\n",
      "Epoch 221, Loss: 0.4153124279254653\n",
      "Epoch 222, Loss: 0.4104582809838288\n",
      "Epoch 223, Loss: 0.4101367219181661\n",
      "Epoch 224, Loss: 0.4157081327260397\n",
      "Epoch 225, Loss: 0.4144226163660391\n",
      "Epoch 226, Loss: 0.4098329995970875\n",
      "Epoch 227, Loss: 0.40775029376666666\n",
      "Epoch 228, Loss: 0.41429755898335924\n",
      "Epoch 229, Loss: 0.41521591906294136\n",
      "Epoch 230, Loss: 0.4099844981670613\n",
      "Epoch 231, Loss: 0.4074908343553954\n",
      "Epoch 232, Loss: 0.41404155462298753\n",
      "Epoch 233, Loss: 0.41428398110821113\n",
      "Epoch 234, Loss: 0.411010796569875\n",
      "Epoch 235, Loss: 0.40626047194262166\n",
      "Epoch 236, Loss: 0.409034666887797\n",
      "Epoch 237, Loss: 0.4158159770891869\n",
      "Epoch 238, Loss: 0.4153325557817546\n",
      "Epoch 239, Loss: 0.40773651613666245\n",
      "Epoch 240, Loss: 0.40720486297242386\n",
      "Epoch 241, Loss: 0.41676379700873606\n",
      "Epoch 242, Loss: 0.4163271136351227\n",
      "Epoch 243, Loss: 0.4079038079306381\n",
      "Epoch 244, Loss: 0.41018584008428094\n",
      "Epoch 245, Loss: 0.4183221731020751\n",
      "Epoch 246, Loss: 0.4083151230189892\n",
      "Epoch 247, Loss: 0.403887555337203\n",
      "Epoch 248, Loss: 0.4087575223213056\n",
      "Epoch 249, Loss: 0.40489636999784445\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22274467889928484\n",
      "Test R^2 score: 0.4618290613791163\n",
      "Num of epochs: 250\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Epoch 179, Loss: 0.42867030340024453\n",
      "Epoch 180, Loss: 0.42665902048327814\n",
      "Epoch 181, Loss: 0.4160041986606613\n",
      "Epoch 182, Loss: 0.42380692389414293\n",
      "Epoch 183, Loss: 0.4367609764525626\n",
      "Epoch 184, Loss: 0.42557170506243686\n",
      "Epoch 185, Loss: 0.42106826790053603\n",
      "Epoch 186, Loss: 0.42573876125176086\n",
      "Epoch 187, Loss: 0.41925407360374856\n",
      "Epoch 188, Loss: 0.4183384695092418\n",
      "Epoch 189, Loss: 0.4218813047997579\n",
      "Epoch 190, Loss: 0.4197713005325469\n",
      "Epoch 191, Loss: 0.417197451669247\n",
      "Epoch 192, Loss: 0.41998586832409235\n",
      "Epoch 193, Loss: 0.4198630180807017\n",
      "Epoch 194, Loss: 0.4146118298837611\n",
      "Epoch 195, Loss: 0.41413205840097117\n",
      "Epoch 196, Loss: 0.4155607826414292\n",
      "Epoch 197, Loss: 0.414238532452658\n",
      "Epoch 198, Loss: 0.41297339310852155\n",
      "Epoch 199, Loss: 0.4123900845056213\n",
      "Epoch 200, Loss: 0.4134311180746695\n",
      "Epoch 201, Loss: 0.4127689164145939\n",
      "Epoch 202, Loss: 0.41232720715179455\n",
      "Epoch 203, Loss: 0.41150345937125327\n",
      "Epoch 204, Loss: 0.4115020652257978\n",
      "Epoch 205, Loss: 0.411078297677327\n",
      "Epoch 206, Loss: 0.4110567108542411\n",
      "Epoch 207, Loss: 0.4114023806357039\n",
      "Epoch 208, Loss: 0.41371932293434216\n",
      "Epoch 209, Loss: 0.41813952085771794\n",
      "Epoch 210, Loss: 0.42511728996367454\n",
      "Epoch 211, Loss: 0.42635158522503447\n",
      "Epoch 212, Loss: 0.419673136297028\n",
      "Epoch 213, Loss: 0.41005224089892217\n",
      "Epoch 214, Loss: 0.4205638856971283\n",
      "Epoch 215, Loss: 0.4288454648496258\n",
      "Epoch 216, Loss: 0.416730043439161\n",
      "Epoch 217, Loss: 0.4131035226095487\n",
      "Epoch 218, Loss: 0.41919050177663497\n",
      "Epoch 219, Loss: 0.41341632229404196\n",
      "Epoch 220, Loss: 0.411337015720657\n",
      "Epoch 221, Loss: 0.4153124279254653\n",
      "Epoch 222, Loss: 0.4104582809838288\n",
      "Epoch 223, Loss: 0.4101367219181661\n",
      "Epoch 224, Loss: 0.4157081327260397\n",
      "Epoch 225, Loss: 0.4144226163660391\n",
      "Epoch 226, Loss: 0.4098329995970875\n",
      "Epoch 227, Loss: 0.40775029376666666\n",
      "Epoch 228, Loss: 0.41429755898335924\n",
      "Epoch 229, Loss: 0.41521591906294136\n",
      "Epoch 230, Loss: 0.4099844981670613\n",
      "Epoch 231, Loss: 0.4074908343553954\n",
      "Epoch 232, Loss: 0.41404155462298753\n",
      "Epoch 233, Loss: 0.41428398110821113\n",
      "Epoch 234, Loss: 0.411010796569875\n",
      "Epoch 235, Loss: 0.40626047194262166\n",
      "Epoch 236, Loss: 0.409034666887797\n",
      "Epoch 237, Loss: 0.4158159770891869\n",
      "Epoch 238, Loss: 0.4153325557817546\n",
      "Epoch 239, Loss: 0.40773651613666245\n",
      "Epoch 240, Loss: 0.40720486297242386\n",
      "Epoch 241, Loss: 0.41676379700873606\n",
      "Epoch 242, Loss: 0.4163271136351227\n",
      "Epoch 243, Loss: 0.4079038079306381\n",
      "Epoch 244, Loss: 0.41018584008428094\n",
      "Epoch 245, Loss: 0.4183221731020751\n",
      "Epoch 246, Loss: 0.4083151230189892\n",
      "Epoch 247, Loss: 0.403887555337203\n",
      "Epoch 248, Loss: 0.4087575223213056\n",
      "Epoch 249, Loss: 0.40489636999784445\n",
      "Epoch 250, Loss: 0.4028637127989142\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22483429055059645\n",
      "Test R^2 score: 0.45143564167802136\n",
      "Num of epochs: 251\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Epoch 179, Loss: 0.42867030340024453\n",
      "Epoch 180, Loss: 0.42665902048327814\n",
      "Epoch 181, Loss: 0.4160041986606613\n",
      "Epoch 182, Loss: 0.42380692389414293\n",
      "Epoch 183, Loss: 0.4367609764525626\n",
      "Epoch 184, Loss: 0.42557170506243686\n",
      "Epoch 185, Loss: 0.42106826790053603\n",
      "Epoch 186, Loss: 0.42573876125176086\n",
      "Epoch 187, Loss: 0.41925407360374856\n",
      "Epoch 188, Loss: 0.4183384695092418\n",
      "Epoch 189, Loss: 0.4218813047997579\n",
      "Epoch 190, Loss: 0.4197713005325469\n",
      "Epoch 191, Loss: 0.417197451669247\n",
      "Epoch 192, Loss: 0.41998586832409235\n",
      "Epoch 193, Loss: 0.4198630180807017\n",
      "Epoch 194, Loss: 0.4146118298837611\n",
      "Epoch 195, Loss: 0.41413205840097117\n",
      "Epoch 196, Loss: 0.4155607826414292\n",
      "Epoch 197, Loss: 0.414238532452658\n",
      "Epoch 198, Loss: 0.41297339310852155\n",
      "Epoch 199, Loss: 0.4123900845056213\n",
      "Epoch 200, Loss: 0.4134311180746695\n",
      "Epoch 201, Loss: 0.4127689164145939\n",
      "Epoch 202, Loss: 0.41232720715179455\n",
      "Epoch 203, Loss: 0.41150345937125327\n",
      "Epoch 204, Loss: 0.4115020652257978\n",
      "Epoch 205, Loss: 0.411078297677327\n",
      "Epoch 206, Loss: 0.4110567108542411\n",
      "Epoch 207, Loss: 0.4114023806357039\n",
      "Epoch 208, Loss: 0.41371932293434216\n",
      "Epoch 209, Loss: 0.41813952085771794\n",
      "Epoch 210, Loss: 0.42511728996367454\n",
      "Epoch 211, Loss: 0.42635158522503447\n",
      "Epoch 212, Loss: 0.419673136297028\n",
      "Epoch 213, Loss: 0.41005224089892217\n",
      "Epoch 214, Loss: 0.4205638856971283\n",
      "Epoch 215, Loss: 0.4288454648496258\n",
      "Epoch 216, Loss: 0.416730043439161\n",
      "Epoch 217, Loss: 0.4131035226095487\n",
      "Epoch 218, Loss: 0.41919050177663497\n",
      "Epoch 219, Loss: 0.41341632229404196\n",
      "Epoch 220, Loss: 0.411337015720657\n",
      "Epoch 221, Loss: 0.4153124279254653\n",
      "Epoch 222, Loss: 0.4104582809838288\n",
      "Epoch 223, Loss: 0.4101367219181661\n",
      "Epoch 224, Loss: 0.4157081327260397\n",
      "Epoch 225, Loss: 0.4144226163660391\n",
      "Epoch 226, Loss: 0.4098329995970875\n",
      "Epoch 227, Loss: 0.40775029376666666\n",
      "Epoch 228, Loss: 0.41429755898335924\n",
      "Epoch 229, Loss: 0.41521591906294136\n",
      "Epoch 230, Loss: 0.4099844981670613\n",
      "Epoch 231, Loss: 0.4074908343553954\n",
      "Epoch 232, Loss: 0.41404155462298753\n",
      "Epoch 233, Loss: 0.41428398110821113\n",
      "Epoch 234, Loss: 0.411010796569875\n",
      "Epoch 235, Loss: 0.40626047194262166\n",
      "Epoch 236, Loss: 0.409034666887797\n",
      "Epoch 237, Loss: 0.4158159770891869\n",
      "Epoch 238, Loss: 0.4153325557817546\n",
      "Epoch 239, Loss: 0.40773651613666245\n",
      "Epoch 240, Loss: 0.40720486297242386\n",
      "Epoch 241, Loss: 0.41676379700873606\n",
      "Epoch 242, Loss: 0.4163271136351227\n",
      "Epoch 243, Loss: 0.4079038079306381\n",
      "Epoch 244, Loss: 0.41018584008428094\n",
      "Epoch 245, Loss: 0.4183221731020751\n",
      "Epoch 246, Loss: 0.4083151230189892\n",
      "Epoch 247, Loss: 0.403887555337203\n",
      "Epoch 248, Loss: 0.4087575223213056\n",
      "Epoch 249, Loss: 0.40489636999784445\n",
      "Epoch 250, Loss: 0.4028637127989142\n",
      "Epoch 251, Loss: 0.40329884617463313\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22103173431451886\n",
      "Test R^2 score: 0.46965751662581384\n",
      "Num of epochs: 252\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Epoch 179, Loss: 0.42867030340024453\n",
      "Epoch 180, Loss: 0.42665902048327814\n",
      "Epoch 181, Loss: 0.4160041986606613\n",
      "Epoch 182, Loss: 0.42380692389414293\n",
      "Epoch 183, Loss: 0.4367609764525626\n",
      "Epoch 184, Loss: 0.42557170506243686\n",
      "Epoch 185, Loss: 0.42106826790053603\n",
      "Epoch 186, Loss: 0.42573876125176086\n",
      "Epoch 187, Loss: 0.41925407360374856\n",
      "Epoch 188, Loss: 0.4183384695092418\n",
      "Epoch 189, Loss: 0.4218813047997579\n",
      "Epoch 190, Loss: 0.4197713005325469\n",
      "Epoch 191, Loss: 0.417197451669247\n",
      "Epoch 192, Loss: 0.41998586832409235\n",
      "Epoch 193, Loss: 0.4198630180807017\n",
      "Epoch 194, Loss: 0.4146118298837611\n",
      "Epoch 195, Loss: 0.41413205840097117\n",
      "Epoch 196, Loss: 0.4155607826414292\n",
      "Epoch 197, Loss: 0.414238532452658\n",
      "Epoch 198, Loss: 0.41297339310852155\n",
      "Epoch 199, Loss: 0.4123900845056213\n",
      "Epoch 200, Loss: 0.4134311180746695\n",
      "Epoch 201, Loss: 0.4127689164145939\n",
      "Epoch 202, Loss: 0.41232720715179455\n",
      "Epoch 203, Loss: 0.41150345937125327\n",
      "Epoch 204, Loss: 0.4115020652257978\n",
      "Epoch 205, Loss: 0.411078297677327\n",
      "Epoch 206, Loss: 0.4110567108542411\n",
      "Epoch 207, Loss: 0.4114023806357039\n",
      "Epoch 208, Loss: 0.41371932293434216\n",
      "Epoch 209, Loss: 0.41813952085771794\n",
      "Epoch 210, Loss: 0.42511728996367454\n",
      "Epoch 211, Loss: 0.42635158522503447\n",
      "Epoch 212, Loss: 0.419673136297028\n",
      "Epoch 213, Loss: 0.41005224089892217\n",
      "Epoch 214, Loss: 0.4205638856971283\n",
      "Epoch 215, Loss: 0.4288454648496258\n",
      "Epoch 216, Loss: 0.416730043439161\n",
      "Epoch 217, Loss: 0.4131035226095487\n",
      "Epoch 218, Loss: 0.41919050177663497\n",
      "Epoch 219, Loss: 0.41341632229404196\n",
      "Epoch 220, Loss: 0.411337015720657\n",
      "Epoch 221, Loss: 0.4153124279254653\n",
      "Epoch 222, Loss: 0.4104582809838288\n",
      "Epoch 223, Loss: 0.4101367219181661\n",
      "Epoch 224, Loss: 0.4157081327260397\n",
      "Epoch 225, Loss: 0.4144226163660391\n",
      "Epoch 226, Loss: 0.4098329995970875\n",
      "Epoch 227, Loss: 0.40775029376666666\n",
      "Epoch 228, Loss: 0.41429755898335924\n",
      "Epoch 229, Loss: 0.41521591906294136\n",
      "Epoch 230, Loss: 0.4099844981670613\n",
      "Epoch 231, Loss: 0.4074908343553954\n",
      "Epoch 232, Loss: 0.41404155462298753\n",
      "Epoch 233, Loss: 0.41428398110821113\n",
      "Epoch 234, Loss: 0.411010796569875\n",
      "Epoch 235, Loss: 0.40626047194262166\n",
      "Epoch 236, Loss: 0.409034666887797\n",
      "Epoch 237, Loss: 0.4158159770891869\n",
      "Epoch 238, Loss: 0.4153325557817546\n",
      "Epoch 239, Loss: 0.40773651613666245\n",
      "Epoch 240, Loss: 0.40720486297242386\n",
      "Epoch 241, Loss: 0.41676379700873606\n",
      "Epoch 242, Loss: 0.4163271136351227\n",
      "Epoch 243, Loss: 0.4079038079306381\n",
      "Epoch 244, Loss: 0.41018584008428094\n",
      "Epoch 245, Loss: 0.4183221731020751\n",
      "Epoch 246, Loss: 0.4083151230189892\n",
      "Epoch 247, Loss: 0.403887555337203\n",
      "Epoch 248, Loss: 0.4087575223213056\n",
      "Epoch 249, Loss: 0.40489636999784445\n",
      "Epoch 250, Loss: 0.4028637127989142\n",
      "Epoch 251, Loss: 0.40329884617463313\n",
      "Epoch 252, Loss: 0.4063995709543235\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22679905002616227\n",
      "Test R^2 score: 0.44183295941053835\n",
      "Num of epochs: 253\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Epoch 179, Loss: 0.42867030340024453\n",
      "Epoch 180, Loss: 0.42665902048327814\n",
      "Epoch 181, Loss: 0.4160041986606613\n",
      "Epoch 182, Loss: 0.42380692389414293\n",
      "Epoch 183, Loss: 0.4367609764525626\n",
      "Epoch 184, Loss: 0.42557170506243686\n",
      "Epoch 185, Loss: 0.42106826790053603\n",
      "Epoch 186, Loss: 0.42573876125176086\n",
      "Epoch 187, Loss: 0.41925407360374856\n",
      "Epoch 188, Loss: 0.4183384695092418\n",
      "Epoch 189, Loss: 0.4218813047997579\n",
      "Epoch 190, Loss: 0.4197713005325469\n",
      "Epoch 191, Loss: 0.417197451669247\n",
      "Epoch 192, Loss: 0.41998586832409235\n",
      "Epoch 193, Loss: 0.4198630180807017\n",
      "Epoch 194, Loss: 0.4146118298837611\n",
      "Epoch 195, Loss: 0.41413205840097117\n",
      "Epoch 196, Loss: 0.4155607826414292\n",
      "Epoch 197, Loss: 0.414238532452658\n",
      "Epoch 198, Loss: 0.41297339310852155\n",
      "Epoch 199, Loss: 0.4123900845056213\n",
      "Epoch 200, Loss: 0.4134311180746695\n",
      "Epoch 201, Loss: 0.4127689164145939\n",
      "Epoch 202, Loss: 0.41232720715179455\n",
      "Epoch 203, Loss: 0.41150345937125327\n",
      "Epoch 204, Loss: 0.4115020652257978\n",
      "Epoch 205, Loss: 0.411078297677327\n",
      "Epoch 206, Loss: 0.4110567108542411\n",
      "Epoch 207, Loss: 0.4114023806357039\n",
      "Epoch 208, Loss: 0.41371932293434216\n",
      "Epoch 209, Loss: 0.41813952085771794\n",
      "Epoch 210, Loss: 0.42511728996367454\n",
      "Epoch 211, Loss: 0.42635158522503447\n",
      "Epoch 212, Loss: 0.419673136297028\n",
      "Epoch 213, Loss: 0.41005224089892217\n",
      "Epoch 214, Loss: 0.4205638856971283\n",
      "Epoch 215, Loss: 0.4288454648496258\n",
      "Epoch 216, Loss: 0.416730043439161\n",
      "Epoch 217, Loss: 0.4131035226095487\n",
      "Epoch 218, Loss: 0.41919050177663497\n",
      "Epoch 219, Loss: 0.41341632229404196\n",
      "Epoch 220, Loss: 0.411337015720657\n",
      "Epoch 221, Loss: 0.4153124279254653\n",
      "Epoch 222, Loss: 0.4104582809838288\n",
      "Epoch 223, Loss: 0.4101367219181661\n",
      "Epoch 224, Loss: 0.4157081327260397\n",
      "Epoch 225, Loss: 0.4144226163660391\n",
      "Epoch 226, Loss: 0.4098329995970875\n",
      "Epoch 227, Loss: 0.40775029376666666\n",
      "Epoch 228, Loss: 0.41429755898335924\n",
      "Epoch 229, Loss: 0.41521591906294136\n",
      "Epoch 230, Loss: 0.4099844981670613\n",
      "Epoch 231, Loss: 0.4074908343553954\n",
      "Epoch 232, Loss: 0.41404155462298753\n",
      "Epoch 233, Loss: 0.41428398110821113\n",
      "Epoch 234, Loss: 0.411010796569875\n",
      "Epoch 235, Loss: 0.40626047194262166\n",
      "Epoch 236, Loss: 0.409034666887797\n",
      "Epoch 237, Loss: 0.4158159770891869\n",
      "Epoch 238, Loss: 0.4153325557817546\n",
      "Epoch 239, Loss: 0.40773651613666245\n",
      "Epoch 240, Loss: 0.40720486297242386\n",
      "Epoch 241, Loss: 0.41676379700873606\n",
      "Epoch 242, Loss: 0.4163271136351227\n",
      "Epoch 243, Loss: 0.4079038079306381\n",
      "Epoch 244, Loss: 0.41018584008428094\n",
      "Epoch 245, Loss: 0.4183221731020751\n",
      "Epoch 246, Loss: 0.4083151230189892\n",
      "Epoch 247, Loss: 0.403887555337203\n",
      "Epoch 248, Loss: 0.4087575223213056\n",
      "Epoch 249, Loss: 0.40489636999784445\n",
      "Epoch 250, Loss: 0.4028637127989142\n",
      "Epoch 251, Loss: 0.40329884617463313\n",
      "Epoch 252, Loss: 0.4063995709543235\n",
      "Epoch 253, Loss: 0.4039770141828027\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.222127532852899\n",
      "Test R^2 score: 0.4650043030519161\n",
      "Num of epochs: 254\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Epoch 179, Loss: 0.42867030340024453\n",
      "Epoch 180, Loss: 0.42665902048327814\n",
      "Epoch 181, Loss: 0.4160041986606613\n",
      "Epoch 182, Loss: 0.42380692389414293\n",
      "Epoch 183, Loss: 0.4367609764525626\n",
      "Epoch 184, Loss: 0.42557170506243686\n",
      "Epoch 185, Loss: 0.42106826790053603\n",
      "Epoch 186, Loss: 0.42573876125176086\n",
      "Epoch 187, Loss: 0.41925407360374856\n",
      "Epoch 188, Loss: 0.4183384695092418\n",
      "Epoch 189, Loss: 0.4218813047997579\n",
      "Epoch 190, Loss: 0.4197713005325469\n",
      "Epoch 191, Loss: 0.417197451669247\n",
      "Epoch 192, Loss: 0.41998586832409235\n",
      "Epoch 193, Loss: 0.4198630180807017\n",
      "Epoch 194, Loss: 0.4146118298837611\n",
      "Epoch 195, Loss: 0.41413205840097117\n",
      "Epoch 196, Loss: 0.4155607826414292\n",
      "Epoch 197, Loss: 0.414238532452658\n",
      "Epoch 198, Loss: 0.41297339310852155\n",
      "Epoch 199, Loss: 0.4123900845056213\n",
      "Epoch 200, Loss: 0.4134311180746695\n",
      "Epoch 201, Loss: 0.4127689164145939\n",
      "Epoch 202, Loss: 0.41232720715179455\n",
      "Epoch 203, Loss: 0.41150345937125327\n",
      "Epoch 204, Loss: 0.4115020652257978\n",
      "Epoch 205, Loss: 0.411078297677327\n",
      "Epoch 206, Loss: 0.4110567108542411\n",
      "Epoch 207, Loss: 0.4114023806357039\n",
      "Epoch 208, Loss: 0.41371932293434216\n",
      "Epoch 209, Loss: 0.41813952085771794\n",
      "Epoch 210, Loss: 0.42511728996367454\n",
      "Epoch 211, Loss: 0.42635158522503447\n",
      "Epoch 212, Loss: 0.419673136297028\n",
      "Epoch 213, Loss: 0.41005224089892217\n",
      "Epoch 214, Loss: 0.4205638856971283\n",
      "Epoch 215, Loss: 0.4288454648496258\n",
      "Epoch 216, Loss: 0.416730043439161\n",
      "Epoch 217, Loss: 0.4131035226095487\n",
      "Epoch 218, Loss: 0.41919050177663497\n",
      "Epoch 219, Loss: 0.41341632229404196\n",
      "Epoch 220, Loss: 0.411337015720657\n",
      "Epoch 221, Loss: 0.4153124279254653\n",
      "Epoch 222, Loss: 0.4104582809838288\n",
      "Epoch 223, Loss: 0.4101367219181661\n",
      "Epoch 224, Loss: 0.4157081327260397\n",
      "Epoch 225, Loss: 0.4144226163660391\n",
      "Epoch 226, Loss: 0.4098329995970875\n",
      "Epoch 227, Loss: 0.40775029376666666\n",
      "Epoch 228, Loss: 0.41429755898335924\n",
      "Epoch 229, Loss: 0.41521591906294136\n",
      "Epoch 230, Loss: 0.4099844981670613\n",
      "Epoch 231, Loss: 0.4074908343553954\n",
      "Epoch 232, Loss: 0.41404155462298753\n",
      "Epoch 233, Loss: 0.41428398110821113\n",
      "Epoch 234, Loss: 0.411010796569875\n",
      "Epoch 235, Loss: 0.40626047194262166\n",
      "Epoch 236, Loss: 0.409034666887797\n",
      "Epoch 237, Loss: 0.4158159770891869\n",
      "Epoch 238, Loss: 0.4153325557817546\n",
      "Epoch 239, Loss: 0.40773651613666245\n",
      "Epoch 240, Loss: 0.40720486297242386\n",
      "Epoch 241, Loss: 0.41676379700873606\n",
      "Epoch 242, Loss: 0.4163271136351227\n",
      "Epoch 243, Loss: 0.4079038079306381\n",
      "Epoch 244, Loss: 0.41018584008428094\n",
      "Epoch 245, Loss: 0.4183221731020751\n",
      "Epoch 246, Loss: 0.4083151230189892\n",
      "Epoch 247, Loss: 0.403887555337203\n",
      "Epoch 248, Loss: 0.4087575223213056\n",
      "Epoch 249, Loss: 0.40489636999784445\n",
      "Epoch 250, Loss: 0.4028637127989142\n",
      "Epoch 251, Loss: 0.40329884617463313\n",
      "Epoch 252, Loss: 0.4063995709543235\n",
      "Epoch 253, Loss: 0.4039770141828027\n",
      "Epoch 254, Loss: 0.40232352789271325\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22139836391338039\n",
      "Test R^2 score: 0.46837423700190034\n",
      "Num of epochs: 255\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Epoch 179, Loss: 0.42867030340024453\n",
      "Epoch 180, Loss: 0.42665902048327814\n",
      "Epoch 181, Loss: 0.4160041986606613\n",
      "Epoch 182, Loss: 0.42380692389414293\n",
      "Epoch 183, Loss: 0.4367609764525626\n",
      "Epoch 184, Loss: 0.42557170506243686\n",
      "Epoch 185, Loss: 0.42106826790053603\n",
      "Epoch 186, Loss: 0.42573876125176086\n",
      "Epoch 187, Loss: 0.41925407360374856\n",
      "Epoch 188, Loss: 0.4183384695092418\n",
      "Epoch 189, Loss: 0.4218813047997579\n",
      "Epoch 190, Loss: 0.4197713005325469\n",
      "Epoch 191, Loss: 0.417197451669247\n",
      "Epoch 192, Loss: 0.41998586832409235\n",
      "Epoch 193, Loss: 0.4198630180807017\n",
      "Epoch 194, Loss: 0.4146118298837611\n",
      "Epoch 195, Loss: 0.41413205840097117\n",
      "Epoch 196, Loss: 0.4155607826414292\n",
      "Epoch 197, Loss: 0.414238532452658\n",
      "Epoch 198, Loss: 0.41297339310852155\n",
      "Epoch 199, Loss: 0.4123900845056213\n",
      "Epoch 200, Loss: 0.4134311180746695\n",
      "Epoch 201, Loss: 0.4127689164145939\n",
      "Epoch 202, Loss: 0.41232720715179455\n",
      "Epoch 203, Loss: 0.41150345937125327\n",
      "Epoch 204, Loss: 0.4115020652257978\n",
      "Epoch 205, Loss: 0.411078297677327\n",
      "Epoch 206, Loss: 0.4110567108542411\n",
      "Epoch 207, Loss: 0.4114023806357039\n",
      "Epoch 208, Loss: 0.41371932293434216\n",
      "Epoch 209, Loss: 0.41813952085771794\n",
      "Epoch 210, Loss: 0.42511728996367454\n",
      "Epoch 211, Loss: 0.42635158522503447\n",
      "Epoch 212, Loss: 0.419673136297028\n",
      "Epoch 213, Loss: 0.41005224089892217\n",
      "Epoch 214, Loss: 0.4205638856971283\n",
      "Epoch 215, Loss: 0.4288454648496258\n",
      "Epoch 216, Loss: 0.416730043439161\n",
      "Epoch 217, Loss: 0.4131035226095487\n",
      "Epoch 218, Loss: 0.41919050177663497\n",
      "Epoch 219, Loss: 0.41341632229404196\n",
      "Epoch 220, Loss: 0.411337015720657\n",
      "Epoch 221, Loss: 0.4153124279254653\n",
      "Epoch 222, Loss: 0.4104582809838288\n",
      "Epoch 223, Loss: 0.4101367219181661\n",
      "Epoch 224, Loss: 0.4157081327260397\n",
      "Epoch 225, Loss: 0.4144226163660391\n",
      "Epoch 226, Loss: 0.4098329995970875\n",
      "Epoch 227, Loss: 0.40775029376666666\n",
      "Epoch 228, Loss: 0.41429755898335924\n",
      "Epoch 229, Loss: 0.41521591906294136\n",
      "Epoch 230, Loss: 0.4099844981670613\n",
      "Epoch 231, Loss: 0.4074908343553954\n",
      "Epoch 232, Loss: 0.41404155462298753\n",
      "Epoch 233, Loss: 0.41428398110821113\n",
      "Epoch 234, Loss: 0.411010796569875\n",
      "Epoch 235, Loss: 0.40626047194262166\n",
      "Epoch 236, Loss: 0.409034666887797\n",
      "Epoch 237, Loss: 0.4158159770891869\n",
      "Epoch 238, Loss: 0.4153325557817546\n",
      "Epoch 239, Loss: 0.40773651613666245\n",
      "Epoch 240, Loss: 0.40720486297242386\n",
      "Epoch 241, Loss: 0.41676379700873606\n",
      "Epoch 242, Loss: 0.4163271136351227\n",
      "Epoch 243, Loss: 0.4079038079306381\n",
      "Epoch 244, Loss: 0.41018584008428094\n",
      "Epoch 245, Loss: 0.4183221731020751\n",
      "Epoch 246, Loss: 0.4083151230189892\n",
      "Epoch 247, Loss: 0.403887555337203\n",
      "Epoch 248, Loss: 0.4087575223213056\n",
      "Epoch 249, Loss: 0.40489636999784445\n",
      "Epoch 250, Loss: 0.4028637127989142\n",
      "Epoch 251, Loss: 0.40329884617463313\n",
      "Epoch 252, Loss: 0.4063995709543235\n",
      "Epoch 253, Loss: 0.4039770141828027\n",
      "Epoch 254, Loss: 0.40232352789271325\n",
      "Epoch 255, Loss: 0.40085487433081396\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2221552489987006\n",
      "Test R^2 score: 0.46466102562033845\n",
      "Num of epochs: 256\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Epoch 179, Loss: 0.42867030340024453\n",
      "Epoch 180, Loss: 0.42665902048327814\n",
      "Epoch 181, Loss: 0.4160041986606613\n",
      "Epoch 182, Loss: 0.42380692389414293\n",
      "Epoch 183, Loss: 0.4367609764525626\n",
      "Epoch 184, Loss: 0.42557170506243686\n",
      "Epoch 185, Loss: 0.42106826790053603\n",
      "Epoch 186, Loss: 0.42573876125176086\n",
      "Epoch 187, Loss: 0.41925407360374856\n",
      "Epoch 188, Loss: 0.4183384695092418\n",
      "Epoch 189, Loss: 0.4218813047997579\n",
      "Epoch 190, Loss: 0.4197713005325469\n",
      "Epoch 191, Loss: 0.417197451669247\n",
      "Epoch 192, Loss: 0.41998586832409235\n",
      "Epoch 193, Loss: 0.4198630180807017\n",
      "Epoch 194, Loss: 0.4146118298837611\n",
      "Epoch 195, Loss: 0.41413205840097117\n",
      "Epoch 196, Loss: 0.4155607826414292\n",
      "Epoch 197, Loss: 0.414238532452658\n",
      "Epoch 198, Loss: 0.41297339310852155\n",
      "Epoch 199, Loss: 0.4123900845056213\n",
      "Epoch 200, Loss: 0.4134311180746695\n",
      "Epoch 201, Loss: 0.4127689164145939\n",
      "Epoch 202, Loss: 0.41232720715179455\n",
      "Epoch 203, Loss: 0.41150345937125327\n",
      "Epoch 204, Loss: 0.4115020652257978\n",
      "Epoch 205, Loss: 0.411078297677327\n",
      "Epoch 206, Loss: 0.4110567108542411\n",
      "Epoch 207, Loss: 0.4114023806357039\n",
      "Epoch 208, Loss: 0.41371932293434216\n",
      "Epoch 209, Loss: 0.41813952085771794\n",
      "Epoch 210, Loss: 0.42511728996367454\n",
      "Epoch 211, Loss: 0.42635158522503447\n",
      "Epoch 212, Loss: 0.419673136297028\n",
      "Epoch 213, Loss: 0.41005224089892217\n",
      "Epoch 214, Loss: 0.4205638856971283\n",
      "Epoch 215, Loss: 0.4288454648496258\n",
      "Epoch 216, Loss: 0.416730043439161\n",
      "Epoch 217, Loss: 0.4131035226095487\n",
      "Epoch 218, Loss: 0.41919050177663497\n",
      "Epoch 219, Loss: 0.41341632229404196\n",
      "Epoch 220, Loss: 0.411337015720657\n",
      "Epoch 221, Loss: 0.4153124279254653\n",
      "Epoch 222, Loss: 0.4104582809838288\n",
      "Epoch 223, Loss: 0.4101367219181661\n",
      "Epoch 224, Loss: 0.4157081327260397\n",
      "Epoch 225, Loss: 0.4144226163660391\n",
      "Epoch 226, Loss: 0.4098329995970875\n",
      "Epoch 227, Loss: 0.40775029376666666\n",
      "Epoch 228, Loss: 0.41429755898335924\n",
      "Epoch 229, Loss: 0.41521591906294136\n",
      "Epoch 230, Loss: 0.4099844981670613\n",
      "Epoch 231, Loss: 0.4074908343553954\n",
      "Epoch 232, Loss: 0.41404155462298753\n",
      "Epoch 233, Loss: 0.41428398110821113\n",
      "Epoch 234, Loss: 0.411010796569875\n",
      "Epoch 235, Loss: 0.40626047194262166\n",
      "Epoch 236, Loss: 0.409034666887797\n",
      "Epoch 237, Loss: 0.4158159770891869\n",
      "Epoch 238, Loss: 0.4153325557817546\n",
      "Epoch 239, Loss: 0.40773651613666245\n",
      "Epoch 240, Loss: 0.40720486297242386\n",
      "Epoch 241, Loss: 0.41676379700873606\n",
      "Epoch 242, Loss: 0.4163271136351227\n",
      "Epoch 243, Loss: 0.4079038079306381\n",
      "Epoch 244, Loss: 0.41018584008428094\n",
      "Epoch 245, Loss: 0.4183221731020751\n",
      "Epoch 246, Loss: 0.4083151230189892\n",
      "Epoch 247, Loss: 0.403887555337203\n",
      "Epoch 248, Loss: 0.4087575223213056\n",
      "Epoch 249, Loss: 0.40489636999784445\n",
      "Epoch 250, Loss: 0.4028637127989142\n",
      "Epoch 251, Loss: 0.40329884617463313\n",
      "Epoch 252, Loss: 0.4063995709543235\n",
      "Epoch 253, Loss: 0.4039770141828027\n",
      "Epoch 254, Loss: 0.40232352789271325\n",
      "Epoch 255, Loss: 0.40085487433081396\n",
      "Epoch 256, Loss: 0.4013585184836403\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2216483634580369\n",
      "Test R^2 score: 0.46736084501984193\n",
      "Num of epochs: 257\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Epoch 179, Loss: 0.42867030340024453\n",
      "Epoch 180, Loss: 0.42665902048327814\n",
      "Epoch 181, Loss: 0.4160041986606613\n",
      "Epoch 182, Loss: 0.42380692389414293\n",
      "Epoch 183, Loss: 0.4367609764525626\n",
      "Epoch 184, Loss: 0.42557170506243686\n",
      "Epoch 185, Loss: 0.42106826790053603\n",
      "Epoch 186, Loss: 0.42573876125176086\n",
      "Epoch 187, Loss: 0.41925407360374856\n",
      "Epoch 188, Loss: 0.4183384695092418\n",
      "Epoch 189, Loss: 0.4218813047997579\n",
      "Epoch 190, Loss: 0.4197713005325469\n",
      "Epoch 191, Loss: 0.417197451669247\n",
      "Epoch 192, Loss: 0.41998586832409235\n",
      "Epoch 193, Loss: 0.4198630180807017\n",
      "Epoch 194, Loss: 0.4146118298837611\n",
      "Epoch 195, Loss: 0.41413205840097117\n",
      "Epoch 196, Loss: 0.4155607826414292\n",
      "Epoch 197, Loss: 0.414238532452658\n",
      "Epoch 198, Loss: 0.41297339310852155\n",
      "Epoch 199, Loss: 0.4123900845056213\n",
      "Epoch 200, Loss: 0.4134311180746695\n",
      "Epoch 201, Loss: 0.4127689164145939\n",
      "Epoch 202, Loss: 0.41232720715179455\n",
      "Epoch 203, Loss: 0.41150345937125327\n",
      "Epoch 204, Loss: 0.4115020652257978\n",
      "Epoch 205, Loss: 0.411078297677327\n",
      "Epoch 206, Loss: 0.4110567108542411\n",
      "Epoch 207, Loss: 0.4114023806357039\n",
      "Epoch 208, Loss: 0.41371932293434216\n",
      "Epoch 209, Loss: 0.41813952085771794\n",
      "Epoch 210, Loss: 0.42511728996367454\n",
      "Epoch 211, Loss: 0.42635158522503447\n",
      "Epoch 212, Loss: 0.419673136297028\n",
      "Epoch 213, Loss: 0.41005224089892217\n",
      "Epoch 214, Loss: 0.4205638856971283\n",
      "Epoch 215, Loss: 0.4288454648496258\n",
      "Epoch 216, Loss: 0.416730043439161\n",
      "Epoch 217, Loss: 0.4131035226095487\n",
      "Epoch 218, Loss: 0.41919050177663497\n",
      "Epoch 219, Loss: 0.41341632229404196\n",
      "Epoch 220, Loss: 0.411337015720657\n",
      "Epoch 221, Loss: 0.4153124279254653\n",
      "Epoch 222, Loss: 0.4104582809838288\n",
      "Epoch 223, Loss: 0.4101367219181661\n",
      "Epoch 224, Loss: 0.4157081327260397\n",
      "Epoch 225, Loss: 0.4144226163660391\n",
      "Epoch 226, Loss: 0.4098329995970875\n",
      "Epoch 227, Loss: 0.40775029376666666\n",
      "Epoch 228, Loss: 0.41429755898335924\n",
      "Epoch 229, Loss: 0.41521591906294136\n",
      "Epoch 230, Loss: 0.4099844981670613\n",
      "Epoch 231, Loss: 0.4074908343553954\n",
      "Epoch 232, Loss: 0.41404155462298753\n",
      "Epoch 233, Loss: 0.41428398110821113\n",
      "Epoch 234, Loss: 0.411010796569875\n",
      "Epoch 235, Loss: 0.40626047194262166\n",
      "Epoch 236, Loss: 0.409034666887797\n",
      "Epoch 237, Loss: 0.4158159770891869\n",
      "Epoch 238, Loss: 0.4153325557817546\n",
      "Epoch 239, Loss: 0.40773651613666245\n",
      "Epoch 240, Loss: 0.40720486297242386\n",
      "Epoch 241, Loss: 0.41676379700873606\n",
      "Epoch 242, Loss: 0.4163271136351227\n",
      "Epoch 243, Loss: 0.4079038079306381\n",
      "Epoch 244, Loss: 0.41018584008428094\n",
      "Epoch 245, Loss: 0.4183221731020751\n",
      "Epoch 246, Loss: 0.4083151230189892\n",
      "Epoch 247, Loss: 0.403887555337203\n",
      "Epoch 248, Loss: 0.4087575223213056\n",
      "Epoch 249, Loss: 0.40489636999784445\n",
      "Epoch 250, Loss: 0.4028637127989142\n",
      "Epoch 251, Loss: 0.40329884617463313\n",
      "Epoch 252, Loss: 0.4063995709543235\n",
      "Epoch 253, Loss: 0.4039770141828027\n",
      "Epoch 254, Loss: 0.40232352789271325\n",
      "Epoch 255, Loss: 0.40085487433081396\n",
      "Epoch 256, Loss: 0.4013585184836403\n",
      "Epoch 257, Loss: 0.401038171909843\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22694147378798216\n",
      "Test R^2 score: 0.4412439513946553\n",
      "Num of epochs: 258\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Epoch 179, Loss: 0.42867030340024453\n",
      "Epoch 180, Loss: 0.42665902048327814\n",
      "Epoch 181, Loss: 0.4160041986606613\n",
      "Epoch 182, Loss: 0.42380692389414293\n",
      "Epoch 183, Loss: 0.4367609764525626\n",
      "Epoch 184, Loss: 0.42557170506243686\n",
      "Epoch 185, Loss: 0.42106826790053603\n",
      "Epoch 186, Loss: 0.42573876125176086\n",
      "Epoch 187, Loss: 0.41925407360374856\n",
      "Epoch 188, Loss: 0.4183384695092418\n",
      "Epoch 189, Loss: 0.4218813047997579\n",
      "Epoch 190, Loss: 0.4197713005325469\n",
      "Epoch 191, Loss: 0.417197451669247\n",
      "Epoch 192, Loss: 0.41998586832409235\n",
      "Epoch 193, Loss: 0.4198630180807017\n",
      "Epoch 194, Loss: 0.4146118298837611\n",
      "Epoch 195, Loss: 0.41413205840097117\n",
      "Epoch 196, Loss: 0.4155607826414292\n",
      "Epoch 197, Loss: 0.414238532452658\n",
      "Epoch 198, Loss: 0.41297339310852155\n",
      "Epoch 199, Loss: 0.4123900845056213\n",
      "Epoch 200, Loss: 0.4134311180746695\n",
      "Epoch 201, Loss: 0.4127689164145939\n",
      "Epoch 202, Loss: 0.41232720715179455\n",
      "Epoch 203, Loss: 0.41150345937125327\n",
      "Epoch 204, Loss: 0.4115020652257978\n",
      "Epoch 205, Loss: 0.411078297677327\n",
      "Epoch 206, Loss: 0.4110567108542411\n",
      "Epoch 207, Loss: 0.4114023806357039\n",
      "Epoch 208, Loss: 0.41371932293434216\n",
      "Epoch 209, Loss: 0.41813952085771794\n",
      "Epoch 210, Loss: 0.42511728996367454\n",
      "Epoch 211, Loss: 0.42635158522503447\n",
      "Epoch 212, Loss: 0.419673136297028\n",
      "Epoch 213, Loss: 0.41005224089892217\n",
      "Epoch 214, Loss: 0.4205638856971283\n",
      "Epoch 215, Loss: 0.4288454648496258\n",
      "Epoch 216, Loss: 0.416730043439161\n",
      "Epoch 217, Loss: 0.4131035226095487\n",
      "Epoch 218, Loss: 0.41919050177663497\n",
      "Epoch 219, Loss: 0.41341632229404196\n",
      "Epoch 220, Loss: 0.411337015720657\n",
      "Epoch 221, Loss: 0.4153124279254653\n",
      "Epoch 222, Loss: 0.4104582809838288\n",
      "Epoch 223, Loss: 0.4101367219181661\n",
      "Epoch 224, Loss: 0.4157081327260397\n",
      "Epoch 225, Loss: 0.4144226163660391\n",
      "Epoch 226, Loss: 0.4098329995970875\n",
      "Epoch 227, Loss: 0.40775029376666666\n",
      "Epoch 228, Loss: 0.41429755898335924\n",
      "Epoch 229, Loss: 0.41521591906294136\n",
      "Epoch 230, Loss: 0.4099844981670613\n",
      "Epoch 231, Loss: 0.4074908343553954\n",
      "Epoch 232, Loss: 0.41404155462298753\n",
      "Epoch 233, Loss: 0.41428398110821113\n",
      "Epoch 234, Loss: 0.411010796569875\n",
      "Epoch 235, Loss: 0.40626047194262166\n",
      "Epoch 236, Loss: 0.409034666887797\n",
      "Epoch 237, Loss: 0.4158159770891869\n",
      "Epoch 238, Loss: 0.4153325557817546\n",
      "Epoch 239, Loss: 0.40773651613666245\n",
      "Epoch 240, Loss: 0.40720486297242386\n",
      "Epoch 241, Loss: 0.41676379700873606\n",
      "Epoch 242, Loss: 0.4163271136351227\n",
      "Epoch 243, Loss: 0.4079038079306381\n",
      "Epoch 244, Loss: 0.41018584008428094\n",
      "Epoch 245, Loss: 0.4183221731020751\n",
      "Epoch 246, Loss: 0.4083151230189892\n",
      "Epoch 247, Loss: 0.403887555337203\n",
      "Epoch 248, Loss: 0.4087575223213056\n",
      "Epoch 249, Loss: 0.40489636999784445\n",
      "Epoch 250, Loss: 0.4028637127989142\n",
      "Epoch 251, Loss: 0.40329884617463313\n",
      "Epoch 252, Loss: 0.4063995709543235\n",
      "Epoch 253, Loss: 0.4039770141828027\n",
      "Epoch 254, Loss: 0.40232352789271325\n",
      "Epoch 255, Loss: 0.40085487433081396\n",
      "Epoch 256, Loss: 0.4013585184836403\n",
      "Epoch 257, Loss: 0.401038171909843\n",
      "Epoch 258, Loss: 0.4020229653351035\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22228530130949958\n",
      "Test R^2 score: 0.46383577046100083\n",
      "Num of epochs: 259\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Epoch 179, Loss: 0.42867030340024453\n",
      "Epoch 180, Loss: 0.42665902048327814\n",
      "Epoch 181, Loss: 0.4160041986606613\n",
      "Epoch 182, Loss: 0.42380692389414293\n",
      "Epoch 183, Loss: 0.4367609764525626\n",
      "Epoch 184, Loss: 0.42557170506243686\n",
      "Epoch 185, Loss: 0.42106826790053603\n",
      "Epoch 186, Loss: 0.42573876125176086\n",
      "Epoch 187, Loss: 0.41925407360374856\n",
      "Epoch 188, Loss: 0.4183384695092418\n",
      "Epoch 189, Loss: 0.4218813047997579\n",
      "Epoch 190, Loss: 0.4197713005325469\n",
      "Epoch 191, Loss: 0.417197451669247\n",
      "Epoch 192, Loss: 0.41998586832409235\n",
      "Epoch 193, Loss: 0.4198630180807017\n",
      "Epoch 194, Loss: 0.4146118298837611\n",
      "Epoch 195, Loss: 0.41413205840097117\n",
      "Epoch 196, Loss: 0.4155607826414292\n",
      "Epoch 197, Loss: 0.414238532452658\n",
      "Epoch 198, Loss: 0.41297339310852155\n",
      "Epoch 199, Loss: 0.4123900845056213\n",
      "Epoch 200, Loss: 0.4134311180746695\n",
      "Epoch 201, Loss: 0.4127689164145939\n",
      "Epoch 202, Loss: 0.41232720715179455\n",
      "Epoch 203, Loss: 0.41150345937125327\n",
      "Epoch 204, Loss: 0.4115020652257978\n",
      "Epoch 205, Loss: 0.411078297677327\n",
      "Epoch 206, Loss: 0.4110567108542411\n",
      "Epoch 207, Loss: 0.4114023806357039\n",
      "Epoch 208, Loss: 0.41371932293434216\n",
      "Epoch 209, Loss: 0.41813952085771794\n",
      "Epoch 210, Loss: 0.42511728996367454\n",
      "Epoch 211, Loss: 0.42635158522503447\n",
      "Epoch 212, Loss: 0.419673136297028\n",
      "Epoch 213, Loss: 0.41005224089892217\n",
      "Epoch 214, Loss: 0.4205638856971283\n",
      "Epoch 215, Loss: 0.4288454648496258\n",
      "Epoch 216, Loss: 0.416730043439161\n",
      "Epoch 217, Loss: 0.4131035226095487\n",
      "Epoch 218, Loss: 0.41919050177663497\n",
      "Epoch 219, Loss: 0.41341632229404196\n",
      "Epoch 220, Loss: 0.411337015720657\n",
      "Epoch 221, Loss: 0.4153124279254653\n",
      "Epoch 222, Loss: 0.4104582809838288\n",
      "Epoch 223, Loss: 0.4101367219181661\n",
      "Epoch 224, Loss: 0.4157081327260397\n",
      "Epoch 225, Loss: 0.4144226163660391\n",
      "Epoch 226, Loss: 0.4098329995970875\n",
      "Epoch 227, Loss: 0.40775029376666666\n",
      "Epoch 228, Loss: 0.41429755898335924\n",
      "Epoch 229, Loss: 0.41521591906294136\n",
      "Epoch 230, Loss: 0.4099844981670613\n",
      "Epoch 231, Loss: 0.4074908343553954\n",
      "Epoch 232, Loss: 0.41404155462298753\n",
      "Epoch 233, Loss: 0.41428398110821113\n",
      "Epoch 234, Loss: 0.411010796569875\n",
      "Epoch 235, Loss: 0.40626047194262166\n",
      "Epoch 236, Loss: 0.409034666887797\n",
      "Epoch 237, Loss: 0.4158159770891869\n",
      "Epoch 238, Loss: 0.4153325557817546\n",
      "Epoch 239, Loss: 0.40773651613666245\n",
      "Epoch 240, Loss: 0.40720486297242386\n",
      "Epoch 241, Loss: 0.41676379700873606\n",
      "Epoch 242, Loss: 0.4163271136351227\n",
      "Epoch 243, Loss: 0.4079038079306381\n",
      "Epoch 244, Loss: 0.41018584008428094\n",
      "Epoch 245, Loss: 0.4183221731020751\n",
      "Epoch 246, Loss: 0.4083151230189892\n",
      "Epoch 247, Loss: 0.403887555337203\n",
      "Epoch 248, Loss: 0.4087575223213056\n",
      "Epoch 249, Loss: 0.40489636999784445\n",
      "Epoch 250, Loss: 0.4028637127989142\n",
      "Epoch 251, Loss: 0.40329884617463313\n",
      "Epoch 252, Loss: 0.4063995709543235\n",
      "Epoch 253, Loss: 0.4039770141828027\n",
      "Epoch 254, Loss: 0.40232352789271325\n",
      "Epoch 255, Loss: 0.40085487433081396\n",
      "Epoch 256, Loss: 0.4013585184836403\n",
      "Epoch 257, Loss: 0.401038171909843\n",
      "Epoch 258, Loss: 0.4020229653351035\n",
      "Epoch 259, Loss: 0.4038903224025568\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.23137370122774664\n",
      "Test R^2 score: 0.4191114752220597\n",
      "Num of epochs: 260\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Epoch 179, Loss: 0.42867030340024453\n",
      "Epoch 180, Loss: 0.42665902048327814\n",
      "Epoch 181, Loss: 0.4160041986606613\n",
      "Epoch 182, Loss: 0.42380692389414293\n",
      "Epoch 183, Loss: 0.4367609764525626\n",
      "Epoch 184, Loss: 0.42557170506243686\n",
      "Epoch 185, Loss: 0.42106826790053603\n",
      "Epoch 186, Loss: 0.42573876125176086\n",
      "Epoch 187, Loss: 0.41925407360374856\n",
      "Epoch 188, Loss: 0.4183384695092418\n",
      "Epoch 189, Loss: 0.4218813047997579\n",
      "Epoch 190, Loss: 0.4197713005325469\n",
      "Epoch 191, Loss: 0.417197451669247\n",
      "Epoch 192, Loss: 0.41998586832409235\n",
      "Epoch 193, Loss: 0.4198630180807017\n",
      "Epoch 194, Loss: 0.4146118298837611\n",
      "Epoch 195, Loss: 0.41413205840097117\n",
      "Epoch 196, Loss: 0.4155607826414292\n",
      "Epoch 197, Loss: 0.414238532452658\n",
      "Epoch 198, Loss: 0.41297339310852155\n",
      "Epoch 199, Loss: 0.4123900845056213\n",
      "Epoch 200, Loss: 0.4134311180746695\n",
      "Epoch 201, Loss: 0.4127689164145939\n",
      "Epoch 202, Loss: 0.41232720715179455\n",
      "Epoch 203, Loss: 0.41150345937125327\n",
      "Epoch 204, Loss: 0.4115020652257978\n",
      "Epoch 205, Loss: 0.411078297677327\n",
      "Epoch 206, Loss: 0.4110567108542411\n",
      "Epoch 207, Loss: 0.4114023806357039\n",
      "Epoch 208, Loss: 0.41371932293434216\n",
      "Epoch 209, Loss: 0.41813952085771794\n",
      "Epoch 210, Loss: 0.42511728996367454\n",
      "Epoch 211, Loss: 0.42635158522503447\n",
      "Epoch 212, Loss: 0.419673136297028\n",
      "Epoch 213, Loss: 0.41005224089892217\n",
      "Epoch 214, Loss: 0.4205638856971283\n",
      "Epoch 215, Loss: 0.4288454648496258\n",
      "Epoch 216, Loss: 0.416730043439161\n",
      "Epoch 217, Loss: 0.4131035226095487\n",
      "Epoch 218, Loss: 0.41919050177663497\n",
      "Epoch 219, Loss: 0.41341632229404196\n",
      "Epoch 220, Loss: 0.411337015720657\n",
      "Epoch 221, Loss: 0.4153124279254653\n",
      "Epoch 222, Loss: 0.4104582809838288\n",
      "Epoch 223, Loss: 0.4101367219181661\n",
      "Epoch 224, Loss: 0.4157081327260397\n",
      "Epoch 225, Loss: 0.4144226163660391\n",
      "Epoch 226, Loss: 0.4098329995970875\n",
      "Epoch 227, Loss: 0.40775029376666666\n",
      "Epoch 228, Loss: 0.41429755898335924\n",
      "Epoch 229, Loss: 0.41521591906294136\n",
      "Epoch 230, Loss: 0.4099844981670613\n",
      "Epoch 231, Loss: 0.4074908343553954\n",
      "Epoch 232, Loss: 0.41404155462298753\n",
      "Epoch 233, Loss: 0.41428398110821113\n",
      "Epoch 234, Loss: 0.411010796569875\n",
      "Epoch 235, Loss: 0.40626047194262166\n",
      "Epoch 236, Loss: 0.409034666887797\n",
      "Epoch 237, Loss: 0.4158159770891869\n",
      "Epoch 238, Loss: 0.4153325557817546\n",
      "Epoch 239, Loss: 0.40773651613666245\n",
      "Epoch 240, Loss: 0.40720486297242386\n",
      "Epoch 241, Loss: 0.41676379700873606\n",
      "Epoch 242, Loss: 0.4163271136351227\n",
      "Epoch 243, Loss: 0.4079038079306381\n",
      "Epoch 244, Loss: 0.41018584008428094\n",
      "Epoch 245, Loss: 0.4183221731020751\n",
      "Epoch 246, Loss: 0.4083151230189892\n",
      "Epoch 247, Loss: 0.403887555337203\n",
      "Epoch 248, Loss: 0.4087575223213056\n",
      "Epoch 249, Loss: 0.40489636999784445\n",
      "Epoch 250, Loss: 0.4028637127989142\n",
      "Epoch 251, Loss: 0.40329884617463313\n",
      "Epoch 252, Loss: 0.4063995709543235\n",
      "Epoch 253, Loss: 0.4039770141828027\n",
      "Epoch 254, Loss: 0.40232352789271325\n",
      "Epoch 255, Loss: 0.40085487433081396\n",
      "Epoch 256, Loss: 0.4013585184836403\n",
      "Epoch 257, Loss: 0.401038171909843\n",
      "Epoch 258, Loss: 0.4020229653351035\n",
      "Epoch 259, Loss: 0.4038903224025568\n",
      "Epoch 260, Loss: 0.4061704337624061\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.223416552374516\n",
      "Test R^2 score: 0.45856107409616365\n",
      "Num of epochs: 261\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Epoch 179, Loss: 0.42867030340024453\n",
      "Epoch 180, Loss: 0.42665902048327814\n",
      "Epoch 181, Loss: 0.4160041986606613\n",
      "Epoch 182, Loss: 0.42380692389414293\n",
      "Epoch 183, Loss: 0.4367609764525626\n",
      "Epoch 184, Loss: 0.42557170506243686\n",
      "Epoch 185, Loss: 0.42106826790053603\n",
      "Epoch 186, Loss: 0.42573876125176086\n",
      "Epoch 187, Loss: 0.41925407360374856\n",
      "Epoch 188, Loss: 0.4183384695092418\n",
      "Epoch 189, Loss: 0.4218813047997579\n",
      "Epoch 190, Loss: 0.4197713005325469\n",
      "Epoch 191, Loss: 0.417197451669247\n",
      "Epoch 192, Loss: 0.41998586832409235\n",
      "Epoch 193, Loss: 0.4198630180807017\n",
      "Epoch 194, Loss: 0.4146118298837611\n",
      "Epoch 195, Loss: 0.41413205840097117\n",
      "Epoch 196, Loss: 0.4155607826414292\n",
      "Epoch 197, Loss: 0.414238532452658\n",
      "Epoch 198, Loss: 0.41297339310852155\n",
      "Epoch 199, Loss: 0.4123900845056213\n",
      "Epoch 200, Loss: 0.4134311180746695\n",
      "Epoch 201, Loss: 0.4127689164145939\n",
      "Epoch 202, Loss: 0.41232720715179455\n",
      "Epoch 203, Loss: 0.41150345937125327\n",
      "Epoch 204, Loss: 0.4115020652257978\n",
      "Epoch 205, Loss: 0.411078297677327\n",
      "Epoch 206, Loss: 0.4110567108542411\n",
      "Epoch 207, Loss: 0.4114023806357039\n",
      "Epoch 208, Loss: 0.41371932293434216\n",
      "Epoch 209, Loss: 0.41813952085771794\n",
      "Epoch 210, Loss: 0.42511728996367454\n",
      "Epoch 211, Loss: 0.42635158522503447\n",
      "Epoch 212, Loss: 0.419673136297028\n",
      "Epoch 213, Loss: 0.41005224089892217\n",
      "Epoch 214, Loss: 0.4205638856971283\n",
      "Epoch 215, Loss: 0.4288454648496258\n",
      "Epoch 216, Loss: 0.416730043439161\n",
      "Epoch 217, Loss: 0.4131035226095487\n",
      "Epoch 218, Loss: 0.41919050177663497\n",
      "Epoch 219, Loss: 0.41341632229404196\n",
      "Epoch 220, Loss: 0.411337015720657\n",
      "Epoch 221, Loss: 0.4153124279254653\n",
      "Epoch 222, Loss: 0.4104582809838288\n",
      "Epoch 223, Loss: 0.4101367219181661\n",
      "Epoch 224, Loss: 0.4157081327260397\n",
      "Epoch 225, Loss: 0.4144226163660391\n",
      "Epoch 226, Loss: 0.4098329995970875\n",
      "Epoch 227, Loss: 0.40775029376666666\n",
      "Epoch 228, Loss: 0.41429755898335924\n",
      "Epoch 229, Loss: 0.41521591906294136\n",
      "Epoch 230, Loss: 0.4099844981670613\n",
      "Epoch 231, Loss: 0.4074908343553954\n",
      "Epoch 232, Loss: 0.41404155462298753\n",
      "Epoch 233, Loss: 0.41428398110821113\n",
      "Epoch 234, Loss: 0.411010796569875\n",
      "Epoch 235, Loss: 0.40626047194262166\n",
      "Epoch 236, Loss: 0.409034666887797\n",
      "Epoch 237, Loss: 0.4158159770891869\n",
      "Epoch 238, Loss: 0.4153325557817546\n",
      "Epoch 239, Loss: 0.40773651613666245\n",
      "Epoch 240, Loss: 0.40720486297242386\n",
      "Epoch 241, Loss: 0.41676379700873606\n",
      "Epoch 242, Loss: 0.4163271136351227\n",
      "Epoch 243, Loss: 0.4079038079306381\n",
      "Epoch 244, Loss: 0.41018584008428094\n",
      "Epoch 245, Loss: 0.4183221731020751\n",
      "Epoch 246, Loss: 0.4083151230189892\n",
      "Epoch 247, Loss: 0.403887555337203\n",
      "Epoch 248, Loss: 0.4087575223213056\n",
      "Epoch 249, Loss: 0.40489636999784445\n",
      "Epoch 250, Loss: 0.4028637127989142\n",
      "Epoch 251, Loss: 0.40329884617463313\n",
      "Epoch 252, Loss: 0.4063995709543235\n",
      "Epoch 253, Loss: 0.4039770141828027\n",
      "Epoch 254, Loss: 0.40232352789271325\n",
      "Epoch 255, Loss: 0.40085487433081396\n",
      "Epoch 256, Loss: 0.4013585184836403\n",
      "Epoch 257, Loss: 0.401038171909843\n",
      "Epoch 258, Loss: 0.4020229653351035\n",
      "Epoch 259, Loss: 0.4038903224025568\n",
      "Epoch 260, Loss: 0.4061704337624061\n",
      "Epoch 261, Loss: 0.40752030716947196\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.23255365929770325\n",
      "Test R^2 score: 0.41354104771933\n",
      "Num of epochs: 262\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Epoch 179, Loss: 0.42867030340024453\n",
      "Epoch 180, Loss: 0.42665902048327814\n",
      "Epoch 181, Loss: 0.4160041986606613\n",
      "Epoch 182, Loss: 0.42380692389414293\n",
      "Epoch 183, Loss: 0.4367609764525626\n",
      "Epoch 184, Loss: 0.42557170506243686\n",
      "Epoch 185, Loss: 0.42106826790053603\n",
      "Epoch 186, Loss: 0.42573876125176086\n",
      "Epoch 187, Loss: 0.41925407360374856\n",
      "Epoch 188, Loss: 0.4183384695092418\n",
      "Epoch 189, Loss: 0.4218813047997579\n",
      "Epoch 190, Loss: 0.4197713005325469\n",
      "Epoch 191, Loss: 0.417197451669247\n",
      "Epoch 192, Loss: 0.41998586832409235\n",
      "Epoch 193, Loss: 0.4198630180807017\n",
      "Epoch 194, Loss: 0.4146118298837611\n",
      "Epoch 195, Loss: 0.41413205840097117\n",
      "Epoch 196, Loss: 0.4155607826414292\n",
      "Epoch 197, Loss: 0.414238532452658\n",
      "Epoch 198, Loss: 0.41297339310852155\n",
      "Epoch 199, Loss: 0.4123900845056213\n",
      "Epoch 200, Loss: 0.4134311180746695\n",
      "Epoch 201, Loss: 0.4127689164145939\n",
      "Epoch 202, Loss: 0.41232720715179455\n",
      "Epoch 203, Loss: 0.41150345937125327\n",
      "Epoch 204, Loss: 0.4115020652257978\n",
      "Epoch 205, Loss: 0.411078297677327\n",
      "Epoch 206, Loss: 0.4110567108542411\n",
      "Epoch 207, Loss: 0.4114023806357039\n",
      "Epoch 208, Loss: 0.41371932293434216\n",
      "Epoch 209, Loss: 0.41813952085771794\n",
      "Epoch 210, Loss: 0.42511728996367454\n",
      "Epoch 211, Loss: 0.42635158522503447\n",
      "Epoch 212, Loss: 0.419673136297028\n",
      "Epoch 213, Loss: 0.41005224089892217\n",
      "Epoch 214, Loss: 0.4205638856971283\n",
      "Epoch 215, Loss: 0.4288454648496258\n",
      "Epoch 216, Loss: 0.416730043439161\n",
      "Epoch 217, Loss: 0.4131035226095487\n",
      "Epoch 218, Loss: 0.41919050177663497\n",
      "Epoch 219, Loss: 0.41341632229404196\n",
      "Epoch 220, Loss: 0.411337015720657\n",
      "Epoch 221, Loss: 0.4153124279254653\n",
      "Epoch 222, Loss: 0.4104582809838288\n",
      "Epoch 223, Loss: 0.4101367219181661\n",
      "Epoch 224, Loss: 0.4157081327260397\n",
      "Epoch 225, Loss: 0.4144226163660391\n",
      "Epoch 226, Loss: 0.4098329995970875\n",
      "Epoch 227, Loss: 0.40775029376666666\n",
      "Epoch 228, Loss: 0.41429755898335924\n",
      "Epoch 229, Loss: 0.41521591906294136\n",
      "Epoch 230, Loss: 0.4099844981670613\n",
      "Epoch 231, Loss: 0.4074908343553954\n",
      "Epoch 232, Loss: 0.41404155462298753\n",
      "Epoch 233, Loss: 0.41428398110821113\n",
      "Epoch 234, Loss: 0.411010796569875\n",
      "Epoch 235, Loss: 0.40626047194262166\n",
      "Epoch 236, Loss: 0.409034666887797\n",
      "Epoch 237, Loss: 0.4158159770891869\n",
      "Epoch 238, Loss: 0.4153325557817546\n",
      "Epoch 239, Loss: 0.40773651613666245\n",
      "Epoch 240, Loss: 0.40720486297242386\n",
      "Epoch 241, Loss: 0.41676379700873606\n",
      "Epoch 242, Loss: 0.4163271136351227\n",
      "Epoch 243, Loss: 0.4079038079306381\n",
      "Epoch 244, Loss: 0.41018584008428094\n",
      "Epoch 245, Loss: 0.4183221731020751\n",
      "Epoch 246, Loss: 0.4083151230189892\n",
      "Epoch 247, Loss: 0.403887555337203\n",
      "Epoch 248, Loss: 0.4087575223213056\n",
      "Epoch 249, Loss: 0.40489636999784445\n",
      "Epoch 250, Loss: 0.4028637127989142\n",
      "Epoch 251, Loss: 0.40329884617463313\n",
      "Epoch 252, Loss: 0.4063995709543235\n",
      "Epoch 253, Loss: 0.4039770141828027\n",
      "Epoch 254, Loss: 0.40232352789271325\n",
      "Epoch 255, Loss: 0.40085487433081396\n",
      "Epoch 256, Loss: 0.4013585184836403\n",
      "Epoch 257, Loss: 0.401038171909843\n",
      "Epoch 258, Loss: 0.4020229653351035\n",
      "Epoch 259, Loss: 0.4038903224025568\n",
      "Epoch 260, Loss: 0.4061704337624061\n",
      "Epoch 261, Loss: 0.40752030716947196\n",
      "Epoch 262, Loss: 0.4085568442371171\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22208886793849159\n",
      "Test R^2 score: 0.4652408971834027\n",
      "Num of epochs: 263\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Epoch 179, Loss: 0.42867030340024453\n",
      "Epoch 180, Loss: 0.42665902048327814\n",
      "Epoch 181, Loss: 0.4160041986606613\n",
      "Epoch 182, Loss: 0.42380692389414293\n",
      "Epoch 183, Loss: 0.4367609764525626\n",
      "Epoch 184, Loss: 0.42557170506243686\n",
      "Epoch 185, Loss: 0.42106826790053603\n",
      "Epoch 186, Loss: 0.42573876125176086\n",
      "Epoch 187, Loss: 0.41925407360374856\n",
      "Epoch 188, Loss: 0.4183384695092418\n",
      "Epoch 189, Loss: 0.4218813047997579\n",
      "Epoch 190, Loss: 0.4197713005325469\n",
      "Epoch 191, Loss: 0.417197451669247\n",
      "Epoch 192, Loss: 0.41998586832409235\n",
      "Epoch 193, Loss: 0.4198630180807017\n",
      "Epoch 194, Loss: 0.4146118298837611\n",
      "Epoch 195, Loss: 0.41413205840097117\n",
      "Epoch 196, Loss: 0.4155607826414292\n",
      "Epoch 197, Loss: 0.414238532452658\n",
      "Epoch 198, Loss: 0.41297339310852155\n",
      "Epoch 199, Loss: 0.4123900845056213\n",
      "Epoch 200, Loss: 0.4134311180746695\n",
      "Epoch 201, Loss: 0.4127689164145939\n",
      "Epoch 202, Loss: 0.41232720715179455\n",
      "Epoch 203, Loss: 0.41150345937125327\n",
      "Epoch 204, Loss: 0.4115020652257978\n",
      "Epoch 205, Loss: 0.411078297677327\n",
      "Epoch 206, Loss: 0.4110567108542411\n",
      "Epoch 207, Loss: 0.4114023806357039\n",
      "Epoch 208, Loss: 0.41371932293434216\n",
      "Epoch 209, Loss: 0.41813952085771794\n",
      "Epoch 210, Loss: 0.42511728996367454\n",
      "Epoch 211, Loss: 0.42635158522503447\n",
      "Epoch 212, Loss: 0.419673136297028\n",
      "Epoch 213, Loss: 0.41005224089892217\n",
      "Epoch 214, Loss: 0.4205638856971283\n",
      "Epoch 215, Loss: 0.4288454648496258\n",
      "Epoch 216, Loss: 0.416730043439161\n",
      "Epoch 217, Loss: 0.4131035226095487\n",
      "Epoch 218, Loss: 0.41919050177663497\n",
      "Epoch 219, Loss: 0.41341632229404196\n",
      "Epoch 220, Loss: 0.411337015720657\n",
      "Epoch 221, Loss: 0.4153124279254653\n",
      "Epoch 222, Loss: 0.4104582809838288\n",
      "Epoch 223, Loss: 0.4101367219181661\n",
      "Epoch 224, Loss: 0.4157081327260397\n",
      "Epoch 225, Loss: 0.4144226163660391\n",
      "Epoch 226, Loss: 0.4098329995970875\n",
      "Epoch 227, Loss: 0.40775029376666666\n",
      "Epoch 228, Loss: 0.41429755898335924\n",
      "Epoch 229, Loss: 0.41521591906294136\n",
      "Epoch 230, Loss: 0.4099844981670613\n",
      "Epoch 231, Loss: 0.4074908343553954\n",
      "Epoch 232, Loss: 0.41404155462298753\n",
      "Epoch 233, Loss: 0.41428398110821113\n",
      "Epoch 234, Loss: 0.411010796569875\n",
      "Epoch 235, Loss: 0.40626047194262166\n",
      "Epoch 236, Loss: 0.409034666887797\n",
      "Epoch 237, Loss: 0.4158159770891869\n",
      "Epoch 238, Loss: 0.4153325557817546\n",
      "Epoch 239, Loss: 0.40773651613666245\n",
      "Epoch 240, Loss: 0.40720486297242386\n",
      "Epoch 241, Loss: 0.41676379700873606\n",
      "Epoch 242, Loss: 0.4163271136351227\n",
      "Epoch 243, Loss: 0.4079038079306381\n",
      "Epoch 244, Loss: 0.41018584008428094\n",
      "Epoch 245, Loss: 0.4183221731020751\n",
      "Epoch 246, Loss: 0.4083151230189892\n",
      "Epoch 247, Loss: 0.403887555337203\n",
      "Epoch 248, Loss: 0.4087575223213056\n",
      "Epoch 249, Loss: 0.40489636999784445\n",
      "Epoch 250, Loss: 0.4028637127989142\n",
      "Epoch 251, Loss: 0.40329884617463313\n",
      "Epoch 252, Loss: 0.4063995709543235\n",
      "Epoch 253, Loss: 0.4039770141828027\n",
      "Epoch 254, Loss: 0.40232352789271325\n",
      "Epoch 255, Loss: 0.40085487433081396\n",
      "Epoch 256, Loss: 0.4013585184836403\n",
      "Epoch 257, Loss: 0.401038171909843\n",
      "Epoch 258, Loss: 0.4020229653351035\n",
      "Epoch 259, Loss: 0.4038903224025568\n",
      "Epoch 260, Loss: 0.4061704337624061\n",
      "Epoch 261, Loss: 0.40752030716947196\n",
      "Epoch 262, Loss: 0.4085568442371171\n",
      "Epoch 263, Loss: 0.40261644547833497\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.224674254757889\n",
      "Test R^2 score: 0.45296288474501795\n",
      "Num of epochs: 264\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Epoch 179, Loss: 0.42867030340024453\n",
      "Epoch 180, Loss: 0.42665902048327814\n",
      "Epoch 181, Loss: 0.4160041986606613\n",
      "Epoch 182, Loss: 0.42380692389414293\n",
      "Epoch 183, Loss: 0.4367609764525626\n",
      "Epoch 184, Loss: 0.42557170506243686\n",
      "Epoch 185, Loss: 0.42106826790053603\n",
      "Epoch 186, Loss: 0.42573876125176086\n",
      "Epoch 187, Loss: 0.41925407360374856\n",
      "Epoch 188, Loss: 0.4183384695092418\n",
      "Epoch 189, Loss: 0.4218813047997579\n",
      "Epoch 190, Loss: 0.4197713005325469\n",
      "Epoch 191, Loss: 0.417197451669247\n",
      "Epoch 192, Loss: 0.41998586832409235\n",
      "Epoch 193, Loss: 0.4198630180807017\n",
      "Epoch 194, Loss: 0.4146118298837611\n",
      "Epoch 195, Loss: 0.41413205840097117\n",
      "Epoch 196, Loss: 0.4155607826414292\n",
      "Epoch 197, Loss: 0.414238532452658\n",
      "Epoch 198, Loss: 0.41297339310852155\n",
      "Epoch 199, Loss: 0.4123900845056213\n",
      "Epoch 200, Loss: 0.4134311180746695\n",
      "Epoch 201, Loss: 0.4127689164145939\n",
      "Epoch 202, Loss: 0.41232720715179455\n",
      "Epoch 203, Loss: 0.41150345937125327\n",
      "Epoch 204, Loss: 0.4115020652257978\n",
      "Epoch 205, Loss: 0.411078297677327\n",
      "Epoch 206, Loss: 0.4110567108542411\n",
      "Epoch 207, Loss: 0.4114023806357039\n",
      "Epoch 208, Loss: 0.41371932293434216\n",
      "Epoch 209, Loss: 0.41813952085771794\n",
      "Epoch 210, Loss: 0.42511728996367454\n",
      "Epoch 211, Loss: 0.42635158522503447\n",
      "Epoch 212, Loss: 0.419673136297028\n",
      "Epoch 213, Loss: 0.41005224089892217\n",
      "Epoch 214, Loss: 0.4205638856971283\n",
      "Epoch 215, Loss: 0.4288454648496258\n",
      "Epoch 216, Loss: 0.416730043439161\n",
      "Epoch 217, Loss: 0.4131035226095487\n",
      "Epoch 218, Loss: 0.41919050177663497\n",
      "Epoch 219, Loss: 0.41341632229404196\n",
      "Epoch 220, Loss: 0.411337015720657\n",
      "Epoch 221, Loss: 0.4153124279254653\n",
      "Epoch 222, Loss: 0.4104582809838288\n",
      "Epoch 223, Loss: 0.4101367219181661\n",
      "Epoch 224, Loss: 0.4157081327260397\n",
      "Epoch 225, Loss: 0.4144226163660391\n",
      "Epoch 226, Loss: 0.4098329995970875\n",
      "Epoch 227, Loss: 0.40775029376666666\n",
      "Epoch 228, Loss: 0.41429755898335924\n",
      "Epoch 229, Loss: 0.41521591906294136\n",
      "Epoch 230, Loss: 0.4099844981670613\n",
      "Epoch 231, Loss: 0.4074908343553954\n",
      "Epoch 232, Loss: 0.41404155462298753\n",
      "Epoch 233, Loss: 0.41428398110821113\n",
      "Epoch 234, Loss: 0.411010796569875\n",
      "Epoch 235, Loss: 0.40626047194262166\n",
      "Epoch 236, Loss: 0.409034666887797\n",
      "Epoch 237, Loss: 0.4158159770891869\n",
      "Epoch 238, Loss: 0.4153325557817546\n",
      "Epoch 239, Loss: 0.40773651613666245\n",
      "Epoch 240, Loss: 0.40720486297242386\n",
      "Epoch 241, Loss: 0.41676379700873606\n",
      "Epoch 242, Loss: 0.4163271136351227\n",
      "Epoch 243, Loss: 0.4079038079306381\n",
      "Epoch 244, Loss: 0.41018584008428094\n",
      "Epoch 245, Loss: 0.4183221731020751\n",
      "Epoch 246, Loss: 0.4083151230189892\n",
      "Epoch 247, Loss: 0.403887555337203\n",
      "Epoch 248, Loss: 0.4087575223213056\n",
      "Epoch 249, Loss: 0.40489636999784445\n",
      "Epoch 250, Loss: 0.4028637127989142\n",
      "Epoch 251, Loss: 0.40329884617463313\n",
      "Epoch 252, Loss: 0.4063995709543235\n",
      "Epoch 253, Loss: 0.4039770141828027\n",
      "Epoch 254, Loss: 0.40232352789271325\n",
      "Epoch 255, Loss: 0.40085487433081396\n",
      "Epoch 256, Loss: 0.4013585184836403\n",
      "Epoch 257, Loss: 0.401038171909843\n",
      "Epoch 258, Loss: 0.4020229653351035\n",
      "Epoch 259, Loss: 0.4038903224025568\n",
      "Epoch 260, Loss: 0.4061704337624061\n",
      "Epoch 261, Loss: 0.40752030716947196\n",
      "Epoch 262, Loss: 0.4085568442371171\n",
      "Epoch 263, Loss: 0.40261644547833497\n",
      "Epoch 264, Loss: 0.39916727140987407\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2248928931063244\n",
      "Test R^2 score: 0.4517926558914432\n",
      "Num of epochs: 265\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Epoch 179, Loss: 0.42867030340024453\n",
      "Epoch 180, Loss: 0.42665902048327814\n",
      "Epoch 181, Loss: 0.4160041986606613\n",
      "Epoch 182, Loss: 0.42380692389414293\n",
      "Epoch 183, Loss: 0.4367609764525626\n",
      "Epoch 184, Loss: 0.42557170506243686\n",
      "Epoch 185, Loss: 0.42106826790053603\n",
      "Epoch 186, Loss: 0.42573876125176086\n",
      "Epoch 187, Loss: 0.41925407360374856\n",
      "Epoch 188, Loss: 0.4183384695092418\n",
      "Epoch 189, Loss: 0.4218813047997579\n",
      "Epoch 190, Loss: 0.4197713005325469\n",
      "Epoch 191, Loss: 0.417197451669247\n",
      "Epoch 192, Loss: 0.41998586832409235\n",
      "Epoch 193, Loss: 0.4198630180807017\n",
      "Epoch 194, Loss: 0.4146118298837611\n",
      "Epoch 195, Loss: 0.41413205840097117\n",
      "Epoch 196, Loss: 0.4155607826414292\n",
      "Epoch 197, Loss: 0.414238532452658\n",
      "Epoch 198, Loss: 0.41297339310852155\n",
      "Epoch 199, Loss: 0.4123900845056213\n",
      "Epoch 200, Loss: 0.4134311180746695\n",
      "Epoch 201, Loss: 0.4127689164145939\n",
      "Epoch 202, Loss: 0.41232720715179455\n",
      "Epoch 203, Loss: 0.41150345937125327\n",
      "Epoch 204, Loss: 0.4115020652257978\n",
      "Epoch 205, Loss: 0.411078297677327\n",
      "Epoch 206, Loss: 0.4110567108542411\n",
      "Epoch 207, Loss: 0.4114023806357039\n",
      "Epoch 208, Loss: 0.41371932293434216\n",
      "Epoch 209, Loss: 0.41813952085771794\n",
      "Epoch 210, Loss: 0.42511728996367454\n",
      "Epoch 211, Loss: 0.42635158522503447\n",
      "Epoch 212, Loss: 0.419673136297028\n",
      "Epoch 213, Loss: 0.41005224089892217\n",
      "Epoch 214, Loss: 0.4205638856971283\n",
      "Epoch 215, Loss: 0.4288454648496258\n",
      "Epoch 216, Loss: 0.416730043439161\n",
      "Epoch 217, Loss: 0.4131035226095487\n",
      "Epoch 218, Loss: 0.41919050177663497\n",
      "Epoch 219, Loss: 0.41341632229404196\n",
      "Epoch 220, Loss: 0.411337015720657\n",
      "Epoch 221, Loss: 0.4153124279254653\n",
      "Epoch 222, Loss: 0.4104582809838288\n",
      "Epoch 223, Loss: 0.4101367219181661\n",
      "Epoch 224, Loss: 0.4157081327260397\n",
      "Epoch 225, Loss: 0.4144226163660391\n",
      "Epoch 226, Loss: 0.4098329995970875\n",
      "Epoch 227, Loss: 0.40775029376666666\n",
      "Epoch 228, Loss: 0.41429755898335924\n",
      "Epoch 229, Loss: 0.41521591906294136\n",
      "Epoch 230, Loss: 0.4099844981670613\n",
      "Epoch 231, Loss: 0.4074908343553954\n",
      "Epoch 232, Loss: 0.41404155462298753\n",
      "Epoch 233, Loss: 0.41428398110821113\n",
      "Epoch 234, Loss: 0.411010796569875\n",
      "Epoch 235, Loss: 0.40626047194262166\n",
      "Epoch 236, Loss: 0.409034666887797\n",
      "Epoch 237, Loss: 0.4158159770891869\n",
      "Epoch 238, Loss: 0.4153325557817546\n",
      "Epoch 239, Loss: 0.40773651613666245\n",
      "Epoch 240, Loss: 0.40720486297242386\n",
      "Epoch 241, Loss: 0.41676379700873606\n",
      "Epoch 242, Loss: 0.4163271136351227\n",
      "Epoch 243, Loss: 0.4079038079306381\n",
      "Epoch 244, Loss: 0.41018584008428094\n",
      "Epoch 245, Loss: 0.4183221731020751\n",
      "Epoch 246, Loss: 0.4083151230189892\n",
      "Epoch 247, Loss: 0.403887555337203\n",
      "Epoch 248, Loss: 0.4087575223213056\n",
      "Epoch 249, Loss: 0.40489636999784445\n",
      "Epoch 250, Loss: 0.4028637127989142\n",
      "Epoch 251, Loss: 0.40329884617463313\n",
      "Epoch 252, Loss: 0.4063995709543235\n",
      "Epoch 253, Loss: 0.4039770141828027\n",
      "Epoch 254, Loss: 0.40232352789271325\n",
      "Epoch 255, Loss: 0.40085487433081396\n",
      "Epoch 256, Loss: 0.4013585184836403\n",
      "Epoch 257, Loss: 0.401038171909843\n",
      "Epoch 258, Loss: 0.4020229653351035\n",
      "Epoch 259, Loss: 0.4038903224025568\n",
      "Epoch 260, Loss: 0.4061704337624061\n",
      "Epoch 261, Loss: 0.40752030716947196\n",
      "Epoch 262, Loss: 0.4085568442371171\n",
      "Epoch 263, Loss: 0.40261644547833497\n",
      "Epoch 264, Loss: 0.39916727140987407\n",
      "Epoch 265, Loss: 0.39918720546249864\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22216519287459852\n",
      "Test R^2 score: 0.4647422631745651\n",
      "Num of epochs: 266\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Epoch 179, Loss: 0.42867030340024453\n",
      "Epoch 180, Loss: 0.42665902048327814\n",
      "Epoch 181, Loss: 0.4160041986606613\n",
      "Epoch 182, Loss: 0.42380692389414293\n",
      "Epoch 183, Loss: 0.4367609764525626\n",
      "Epoch 184, Loss: 0.42557170506243686\n",
      "Epoch 185, Loss: 0.42106826790053603\n",
      "Epoch 186, Loss: 0.42573876125176086\n",
      "Epoch 187, Loss: 0.41925407360374856\n",
      "Epoch 188, Loss: 0.4183384695092418\n",
      "Epoch 189, Loss: 0.4218813047997579\n",
      "Epoch 190, Loss: 0.4197713005325469\n",
      "Epoch 191, Loss: 0.417197451669247\n",
      "Epoch 192, Loss: 0.41998586832409235\n",
      "Epoch 193, Loss: 0.4198630180807017\n",
      "Epoch 194, Loss: 0.4146118298837611\n",
      "Epoch 195, Loss: 0.41413205840097117\n",
      "Epoch 196, Loss: 0.4155607826414292\n",
      "Epoch 197, Loss: 0.414238532452658\n",
      "Epoch 198, Loss: 0.41297339310852155\n",
      "Epoch 199, Loss: 0.4123900845056213\n",
      "Epoch 200, Loss: 0.4134311180746695\n",
      "Epoch 201, Loss: 0.4127689164145939\n",
      "Epoch 202, Loss: 0.41232720715179455\n",
      "Epoch 203, Loss: 0.41150345937125327\n",
      "Epoch 204, Loss: 0.4115020652257978\n",
      "Epoch 205, Loss: 0.411078297677327\n",
      "Epoch 206, Loss: 0.4110567108542411\n",
      "Epoch 207, Loss: 0.4114023806357039\n",
      "Epoch 208, Loss: 0.41371932293434216\n",
      "Epoch 209, Loss: 0.41813952085771794\n",
      "Epoch 210, Loss: 0.42511728996367454\n",
      "Epoch 211, Loss: 0.42635158522503447\n",
      "Epoch 212, Loss: 0.419673136297028\n",
      "Epoch 213, Loss: 0.41005224089892217\n",
      "Epoch 214, Loss: 0.4205638856971283\n",
      "Epoch 215, Loss: 0.4288454648496258\n",
      "Epoch 216, Loss: 0.416730043439161\n",
      "Epoch 217, Loss: 0.4131035226095487\n",
      "Epoch 218, Loss: 0.41919050177663497\n",
      "Epoch 219, Loss: 0.41341632229404196\n",
      "Epoch 220, Loss: 0.411337015720657\n",
      "Epoch 221, Loss: 0.4153124279254653\n",
      "Epoch 222, Loss: 0.4104582809838288\n",
      "Epoch 223, Loss: 0.4101367219181661\n",
      "Epoch 224, Loss: 0.4157081327260397\n",
      "Epoch 225, Loss: 0.4144226163660391\n",
      "Epoch 226, Loss: 0.4098329995970875\n",
      "Epoch 227, Loss: 0.40775029376666666\n",
      "Epoch 228, Loss: 0.41429755898335924\n",
      "Epoch 229, Loss: 0.41521591906294136\n",
      "Epoch 230, Loss: 0.4099844981670613\n",
      "Epoch 231, Loss: 0.4074908343553954\n",
      "Epoch 232, Loss: 0.41404155462298753\n",
      "Epoch 233, Loss: 0.41428398110821113\n",
      "Epoch 234, Loss: 0.411010796569875\n",
      "Epoch 235, Loss: 0.40626047194262166\n",
      "Epoch 236, Loss: 0.409034666887797\n",
      "Epoch 237, Loss: 0.4158159770891869\n",
      "Epoch 238, Loss: 0.4153325557817546\n",
      "Epoch 239, Loss: 0.40773651613666245\n",
      "Epoch 240, Loss: 0.40720486297242386\n",
      "Epoch 241, Loss: 0.41676379700873606\n",
      "Epoch 242, Loss: 0.4163271136351227\n",
      "Epoch 243, Loss: 0.4079038079306381\n",
      "Epoch 244, Loss: 0.41018584008428094\n",
      "Epoch 245, Loss: 0.4183221731020751\n",
      "Epoch 246, Loss: 0.4083151230189892\n",
      "Epoch 247, Loss: 0.403887555337203\n",
      "Epoch 248, Loss: 0.4087575223213056\n",
      "Epoch 249, Loss: 0.40489636999784445\n",
      "Epoch 250, Loss: 0.4028637127989142\n",
      "Epoch 251, Loss: 0.40329884617463313\n",
      "Epoch 252, Loss: 0.4063995709543235\n",
      "Epoch 253, Loss: 0.4039770141828027\n",
      "Epoch 254, Loss: 0.40232352789271325\n",
      "Epoch 255, Loss: 0.40085487433081396\n",
      "Epoch 256, Loss: 0.4013585184836403\n",
      "Epoch 257, Loss: 0.401038171909843\n",
      "Epoch 258, Loss: 0.4020229653351035\n",
      "Epoch 259, Loss: 0.4038903224025568\n",
      "Epoch 260, Loss: 0.4061704337624061\n",
      "Epoch 261, Loss: 0.40752030716947196\n",
      "Epoch 262, Loss: 0.4085568442371171\n",
      "Epoch 263, Loss: 0.40261644547833497\n",
      "Epoch 264, Loss: 0.39916727140987407\n",
      "Epoch 265, Loss: 0.39918720546249864\n",
      "Epoch 266, Loss: 0.4018616982923893\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.23048508967129946\n",
      "Test R^2 score: 0.42388779418235173\n",
      "Num of epochs: 267\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Epoch 179, Loss: 0.42867030340024453\n",
      "Epoch 180, Loss: 0.42665902048327814\n",
      "Epoch 181, Loss: 0.4160041986606613\n",
      "Epoch 182, Loss: 0.42380692389414293\n",
      "Epoch 183, Loss: 0.4367609764525626\n",
      "Epoch 184, Loss: 0.42557170506243686\n",
      "Epoch 185, Loss: 0.42106826790053603\n",
      "Epoch 186, Loss: 0.42573876125176086\n",
      "Epoch 187, Loss: 0.41925407360374856\n",
      "Epoch 188, Loss: 0.4183384695092418\n",
      "Epoch 189, Loss: 0.4218813047997579\n",
      "Epoch 190, Loss: 0.4197713005325469\n",
      "Epoch 191, Loss: 0.417197451669247\n",
      "Epoch 192, Loss: 0.41998586832409235\n",
      "Epoch 193, Loss: 0.4198630180807017\n",
      "Epoch 194, Loss: 0.4146118298837611\n",
      "Epoch 195, Loss: 0.41413205840097117\n",
      "Epoch 196, Loss: 0.4155607826414292\n",
      "Epoch 197, Loss: 0.414238532452658\n",
      "Epoch 198, Loss: 0.41297339310852155\n",
      "Epoch 199, Loss: 0.4123900845056213\n",
      "Epoch 200, Loss: 0.4134311180746695\n",
      "Epoch 201, Loss: 0.4127689164145939\n",
      "Epoch 202, Loss: 0.41232720715179455\n",
      "Epoch 203, Loss: 0.41150345937125327\n",
      "Epoch 204, Loss: 0.4115020652257978\n",
      "Epoch 205, Loss: 0.411078297677327\n",
      "Epoch 206, Loss: 0.4110567108542411\n",
      "Epoch 207, Loss: 0.4114023806357039\n",
      "Epoch 208, Loss: 0.41371932293434216\n",
      "Epoch 209, Loss: 0.41813952085771794\n",
      "Epoch 210, Loss: 0.42511728996367454\n",
      "Epoch 211, Loss: 0.42635158522503447\n",
      "Epoch 212, Loss: 0.419673136297028\n",
      "Epoch 213, Loss: 0.41005224089892217\n",
      "Epoch 214, Loss: 0.4205638856971283\n",
      "Epoch 215, Loss: 0.4288454648496258\n",
      "Epoch 216, Loss: 0.416730043439161\n",
      "Epoch 217, Loss: 0.4131035226095487\n",
      "Epoch 218, Loss: 0.41919050177663497\n",
      "Epoch 219, Loss: 0.41341632229404196\n",
      "Epoch 220, Loss: 0.411337015720657\n",
      "Epoch 221, Loss: 0.4153124279254653\n",
      "Epoch 222, Loss: 0.4104582809838288\n",
      "Epoch 223, Loss: 0.4101367219181661\n",
      "Epoch 224, Loss: 0.4157081327260397\n",
      "Epoch 225, Loss: 0.4144226163660391\n",
      "Epoch 226, Loss: 0.4098329995970875\n",
      "Epoch 227, Loss: 0.40775029376666666\n",
      "Epoch 228, Loss: 0.41429755898335924\n",
      "Epoch 229, Loss: 0.41521591906294136\n",
      "Epoch 230, Loss: 0.4099844981670613\n",
      "Epoch 231, Loss: 0.4074908343553954\n",
      "Epoch 232, Loss: 0.41404155462298753\n",
      "Epoch 233, Loss: 0.41428398110821113\n",
      "Epoch 234, Loss: 0.411010796569875\n",
      "Epoch 235, Loss: 0.40626047194262166\n",
      "Epoch 236, Loss: 0.409034666887797\n",
      "Epoch 237, Loss: 0.4158159770891869\n",
      "Epoch 238, Loss: 0.4153325557817546\n",
      "Epoch 239, Loss: 0.40773651613666245\n",
      "Epoch 240, Loss: 0.40720486297242386\n",
      "Epoch 241, Loss: 0.41676379700873606\n",
      "Epoch 242, Loss: 0.4163271136351227\n",
      "Epoch 243, Loss: 0.4079038079306381\n",
      "Epoch 244, Loss: 0.41018584008428094\n",
      "Epoch 245, Loss: 0.4183221731020751\n",
      "Epoch 246, Loss: 0.4083151230189892\n",
      "Epoch 247, Loss: 0.403887555337203\n",
      "Epoch 248, Loss: 0.4087575223213056\n",
      "Epoch 249, Loss: 0.40489636999784445\n",
      "Epoch 250, Loss: 0.4028637127989142\n",
      "Epoch 251, Loss: 0.40329884617463313\n",
      "Epoch 252, Loss: 0.4063995709543235\n",
      "Epoch 253, Loss: 0.4039770141828027\n",
      "Epoch 254, Loss: 0.40232352789271325\n",
      "Epoch 255, Loss: 0.40085487433081396\n",
      "Epoch 256, Loss: 0.4013585184836403\n",
      "Epoch 257, Loss: 0.401038171909843\n",
      "Epoch 258, Loss: 0.4020229653351035\n",
      "Epoch 259, Loss: 0.4038903224025568\n",
      "Epoch 260, Loss: 0.4061704337624061\n",
      "Epoch 261, Loss: 0.40752030716947196\n",
      "Epoch 262, Loss: 0.4085568442371171\n",
      "Epoch 263, Loss: 0.40261644547833497\n",
      "Epoch 264, Loss: 0.39916727140987407\n",
      "Epoch 265, Loss: 0.39918720546249864\n",
      "Epoch 266, Loss: 0.4018616982923893\n",
      "Epoch 267, Loss: 0.40409750330247396\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2221734961924075\n",
      "Test R^2 score: 0.4645944395209121\n",
      "Num of epochs: 268\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Epoch 179, Loss: 0.42867030340024453\n",
      "Epoch 180, Loss: 0.42665902048327814\n",
      "Epoch 181, Loss: 0.4160041986606613\n",
      "Epoch 182, Loss: 0.42380692389414293\n",
      "Epoch 183, Loss: 0.4367609764525626\n",
      "Epoch 184, Loss: 0.42557170506243686\n",
      "Epoch 185, Loss: 0.42106826790053603\n",
      "Epoch 186, Loss: 0.42573876125176086\n",
      "Epoch 187, Loss: 0.41925407360374856\n",
      "Epoch 188, Loss: 0.4183384695092418\n",
      "Epoch 189, Loss: 0.4218813047997579\n",
      "Epoch 190, Loss: 0.4197713005325469\n",
      "Epoch 191, Loss: 0.417197451669247\n",
      "Epoch 192, Loss: 0.41998586832409235\n",
      "Epoch 193, Loss: 0.4198630180807017\n",
      "Epoch 194, Loss: 0.4146118298837611\n",
      "Epoch 195, Loss: 0.41413205840097117\n",
      "Epoch 196, Loss: 0.4155607826414292\n",
      "Epoch 197, Loss: 0.414238532452658\n",
      "Epoch 198, Loss: 0.41297339310852155\n",
      "Epoch 199, Loss: 0.4123900845056213\n",
      "Epoch 200, Loss: 0.4134311180746695\n",
      "Epoch 201, Loss: 0.4127689164145939\n",
      "Epoch 202, Loss: 0.41232720715179455\n",
      "Epoch 203, Loss: 0.41150345937125327\n",
      "Epoch 204, Loss: 0.4115020652257978\n",
      "Epoch 205, Loss: 0.411078297677327\n",
      "Epoch 206, Loss: 0.4110567108542411\n",
      "Epoch 207, Loss: 0.4114023806357039\n",
      "Epoch 208, Loss: 0.41371932293434216\n",
      "Epoch 209, Loss: 0.41813952085771794\n",
      "Epoch 210, Loss: 0.42511728996367454\n",
      "Epoch 211, Loss: 0.42635158522503447\n",
      "Epoch 212, Loss: 0.419673136297028\n",
      "Epoch 213, Loss: 0.41005224089892217\n",
      "Epoch 214, Loss: 0.4205638856971283\n",
      "Epoch 215, Loss: 0.4288454648496258\n",
      "Epoch 216, Loss: 0.416730043439161\n",
      "Epoch 217, Loss: 0.4131035226095487\n",
      "Epoch 218, Loss: 0.41919050177663497\n",
      "Epoch 219, Loss: 0.41341632229404196\n",
      "Epoch 220, Loss: 0.411337015720657\n",
      "Epoch 221, Loss: 0.4153124279254653\n",
      "Epoch 222, Loss: 0.4104582809838288\n",
      "Epoch 223, Loss: 0.4101367219181661\n",
      "Epoch 224, Loss: 0.4157081327260397\n",
      "Epoch 225, Loss: 0.4144226163660391\n",
      "Epoch 226, Loss: 0.4098329995970875\n",
      "Epoch 227, Loss: 0.40775029376666666\n",
      "Epoch 228, Loss: 0.41429755898335924\n",
      "Epoch 229, Loss: 0.41521591906294136\n",
      "Epoch 230, Loss: 0.4099844981670613\n",
      "Epoch 231, Loss: 0.4074908343553954\n",
      "Epoch 232, Loss: 0.41404155462298753\n",
      "Epoch 233, Loss: 0.41428398110821113\n",
      "Epoch 234, Loss: 0.411010796569875\n",
      "Epoch 235, Loss: 0.40626047194262166\n",
      "Epoch 236, Loss: 0.409034666887797\n",
      "Epoch 237, Loss: 0.4158159770891869\n",
      "Epoch 238, Loss: 0.4153325557817546\n",
      "Epoch 239, Loss: 0.40773651613666245\n",
      "Epoch 240, Loss: 0.40720486297242386\n",
      "Epoch 241, Loss: 0.41676379700873606\n",
      "Epoch 242, Loss: 0.4163271136351227\n",
      "Epoch 243, Loss: 0.4079038079306381\n",
      "Epoch 244, Loss: 0.41018584008428094\n",
      "Epoch 245, Loss: 0.4183221731020751\n",
      "Epoch 246, Loss: 0.4083151230189892\n",
      "Epoch 247, Loss: 0.403887555337203\n",
      "Epoch 248, Loss: 0.4087575223213056\n",
      "Epoch 249, Loss: 0.40489636999784445\n",
      "Epoch 250, Loss: 0.4028637127989142\n",
      "Epoch 251, Loss: 0.40329884617463313\n",
      "Epoch 252, Loss: 0.4063995709543235\n",
      "Epoch 253, Loss: 0.4039770141828027\n",
      "Epoch 254, Loss: 0.40232352789271325\n",
      "Epoch 255, Loss: 0.40085487433081396\n",
      "Epoch 256, Loss: 0.4013585184836403\n",
      "Epoch 257, Loss: 0.401038171909843\n",
      "Epoch 258, Loss: 0.4020229653351035\n",
      "Epoch 259, Loss: 0.4038903224025568\n",
      "Epoch 260, Loss: 0.4061704337624061\n",
      "Epoch 261, Loss: 0.40752030716947196\n",
      "Epoch 262, Loss: 0.4085568442371171\n",
      "Epoch 263, Loss: 0.40261644547833497\n",
      "Epoch 264, Loss: 0.39916727140987407\n",
      "Epoch 265, Loss: 0.39918720546249864\n",
      "Epoch 266, Loss: 0.4018616982923893\n",
      "Epoch 267, Loss: 0.40409750330247396\n",
      "Epoch 268, Loss: 0.4030983154573023\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22732173591784183\n",
      "Test R^2 score: 0.4394986772771787\n",
      "Num of epochs: 269\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Epoch 179, Loss: 0.42867030340024453\n",
      "Epoch 180, Loss: 0.42665902048327814\n",
      "Epoch 181, Loss: 0.4160041986606613\n",
      "Epoch 182, Loss: 0.42380692389414293\n",
      "Epoch 183, Loss: 0.4367609764525626\n",
      "Epoch 184, Loss: 0.42557170506243686\n",
      "Epoch 185, Loss: 0.42106826790053603\n",
      "Epoch 186, Loss: 0.42573876125176086\n",
      "Epoch 187, Loss: 0.41925407360374856\n",
      "Epoch 188, Loss: 0.4183384695092418\n",
      "Epoch 189, Loss: 0.4218813047997579\n",
      "Epoch 190, Loss: 0.4197713005325469\n",
      "Epoch 191, Loss: 0.417197451669247\n",
      "Epoch 192, Loss: 0.41998586832409235\n",
      "Epoch 193, Loss: 0.4198630180807017\n",
      "Epoch 194, Loss: 0.4146118298837611\n",
      "Epoch 195, Loss: 0.41413205840097117\n",
      "Epoch 196, Loss: 0.4155607826414292\n",
      "Epoch 197, Loss: 0.414238532452658\n",
      "Epoch 198, Loss: 0.41297339310852155\n",
      "Epoch 199, Loss: 0.4123900845056213\n",
      "Epoch 200, Loss: 0.4134311180746695\n",
      "Epoch 201, Loss: 0.4127689164145939\n",
      "Epoch 202, Loss: 0.41232720715179455\n",
      "Epoch 203, Loss: 0.41150345937125327\n",
      "Epoch 204, Loss: 0.4115020652257978\n",
      "Epoch 205, Loss: 0.411078297677327\n",
      "Epoch 206, Loss: 0.4110567108542411\n",
      "Epoch 207, Loss: 0.4114023806357039\n",
      "Epoch 208, Loss: 0.41371932293434216\n",
      "Epoch 209, Loss: 0.41813952085771794\n",
      "Epoch 210, Loss: 0.42511728996367454\n",
      "Epoch 211, Loss: 0.42635158522503447\n",
      "Epoch 212, Loss: 0.419673136297028\n",
      "Epoch 213, Loss: 0.41005224089892217\n",
      "Epoch 214, Loss: 0.4205638856971283\n",
      "Epoch 215, Loss: 0.4288454648496258\n",
      "Epoch 216, Loss: 0.416730043439161\n",
      "Epoch 217, Loss: 0.4131035226095487\n",
      "Epoch 218, Loss: 0.41919050177663497\n",
      "Epoch 219, Loss: 0.41341632229404196\n",
      "Epoch 220, Loss: 0.411337015720657\n",
      "Epoch 221, Loss: 0.4153124279254653\n",
      "Epoch 222, Loss: 0.4104582809838288\n",
      "Epoch 223, Loss: 0.4101367219181661\n",
      "Epoch 224, Loss: 0.4157081327260397\n",
      "Epoch 225, Loss: 0.4144226163660391\n",
      "Epoch 226, Loss: 0.4098329995970875\n",
      "Epoch 227, Loss: 0.40775029376666666\n",
      "Epoch 228, Loss: 0.41429755898335924\n",
      "Epoch 229, Loss: 0.41521591906294136\n",
      "Epoch 230, Loss: 0.4099844981670613\n",
      "Epoch 231, Loss: 0.4074908343553954\n",
      "Epoch 232, Loss: 0.41404155462298753\n",
      "Epoch 233, Loss: 0.41428398110821113\n",
      "Epoch 234, Loss: 0.411010796569875\n",
      "Epoch 235, Loss: 0.40626047194262166\n",
      "Epoch 236, Loss: 0.409034666887797\n",
      "Epoch 237, Loss: 0.4158159770891869\n",
      "Epoch 238, Loss: 0.4153325557817546\n",
      "Epoch 239, Loss: 0.40773651613666245\n",
      "Epoch 240, Loss: 0.40720486297242386\n",
      "Epoch 241, Loss: 0.41676379700873606\n",
      "Epoch 242, Loss: 0.4163271136351227\n",
      "Epoch 243, Loss: 0.4079038079306381\n",
      "Epoch 244, Loss: 0.41018584008428094\n",
      "Epoch 245, Loss: 0.4183221731020751\n",
      "Epoch 246, Loss: 0.4083151230189892\n",
      "Epoch 247, Loss: 0.403887555337203\n",
      "Epoch 248, Loss: 0.4087575223213056\n",
      "Epoch 249, Loss: 0.40489636999784445\n",
      "Epoch 250, Loss: 0.4028637127989142\n",
      "Epoch 251, Loss: 0.40329884617463313\n",
      "Epoch 252, Loss: 0.4063995709543235\n",
      "Epoch 253, Loss: 0.4039770141828027\n",
      "Epoch 254, Loss: 0.40232352789271325\n",
      "Epoch 255, Loss: 0.40085487433081396\n",
      "Epoch 256, Loss: 0.4013585184836403\n",
      "Epoch 257, Loss: 0.401038171909843\n",
      "Epoch 258, Loss: 0.4020229653351035\n",
      "Epoch 259, Loss: 0.4038903224025568\n",
      "Epoch 260, Loss: 0.4061704337624061\n",
      "Epoch 261, Loss: 0.40752030716947196\n",
      "Epoch 262, Loss: 0.4085568442371171\n",
      "Epoch 263, Loss: 0.40261644547833497\n",
      "Epoch 264, Loss: 0.39916727140987407\n",
      "Epoch 265, Loss: 0.39918720546249864\n",
      "Epoch 266, Loss: 0.4018616982923893\n",
      "Epoch 267, Loss: 0.40409750330247396\n",
      "Epoch 268, Loss: 0.4030983154573023\n",
      "Epoch 269, Loss: 0.40148977741823705\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2225855362994537\n",
      "Test R^2 score: 0.4628739604239991\n",
      "Num of epochs: 270\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Epoch 179, Loss: 0.42867030340024453\n",
      "Epoch 180, Loss: 0.42665902048327814\n",
      "Epoch 181, Loss: 0.4160041986606613\n",
      "Epoch 182, Loss: 0.42380692389414293\n",
      "Epoch 183, Loss: 0.4367609764525626\n",
      "Epoch 184, Loss: 0.42557170506243686\n",
      "Epoch 185, Loss: 0.42106826790053603\n",
      "Epoch 186, Loss: 0.42573876125176086\n",
      "Epoch 187, Loss: 0.41925407360374856\n",
      "Epoch 188, Loss: 0.4183384695092418\n",
      "Epoch 189, Loss: 0.4218813047997579\n",
      "Epoch 190, Loss: 0.4197713005325469\n",
      "Epoch 191, Loss: 0.417197451669247\n",
      "Epoch 192, Loss: 0.41998586832409235\n",
      "Epoch 193, Loss: 0.4198630180807017\n",
      "Epoch 194, Loss: 0.4146118298837611\n",
      "Epoch 195, Loss: 0.41413205840097117\n",
      "Epoch 196, Loss: 0.4155607826414292\n",
      "Epoch 197, Loss: 0.414238532452658\n",
      "Epoch 198, Loss: 0.41297339310852155\n",
      "Epoch 199, Loss: 0.4123900845056213\n",
      "Epoch 200, Loss: 0.4134311180746695\n",
      "Epoch 201, Loss: 0.4127689164145939\n",
      "Epoch 202, Loss: 0.41232720715179455\n",
      "Epoch 203, Loss: 0.41150345937125327\n",
      "Epoch 204, Loss: 0.4115020652257978\n",
      "Epoch 205, Loss: 0.411078297677327\n",
      "Epoch 206, Loss: 0.4110567108542411\n",
      "Epoch 207, Loss: 0.4114023806357039\n",
      "Epoch 208, Loss: 0.41371932293434216\n",
      "Epoch 209, Loss: 0.41813952085771794\n",
      "Epoch 210, Loss: 0.42511728996367454\n",
      "Epoch 211, Loss: 0.42635158522503447\n",
      "Epoch 212, Loss: 0.419673136297028\n",
      "Epoch 213, Loss: 0.41005224089892217\n",
      "Epoch 214, Loss: 0.4205638856971283\n",
      "Epoch 215, Loss: 0.4288454648496258\n",
      "Epoch 216, Loss: 0.416730043439161\n",
      "Epoch 217, Loss: 0.4131035226095487\n",
      "Epoch 218, Loss: 0.41919050177663497\n",
      "Epoch 219, Loss: 0.41341632229404196\n",
      "Epoch 220, Loss: 0.411337015720657\n",
      "Epoch 221, Loss: 0.4153124279254653\n",
      "Epoch 222, Loss: 0.4104582809838288\n",
      "Epoch 223, Loss: 0.4101367219181661\n",
      "Epoch 224, Loss: 0.4157081327260397\n",
      "Epoch 225, Loss: 0.4144226163660391\n",
      "Epoch 226, Loss: 0.4098329995970875\n",
      "Epoch 227, Loss: 0.40775029376666666\n",
      "Epoch 228, Loss: 0.41429755898335924\n",
      "Epoch 229, Loss: 0.41521591906294136\n",
      "Epoch 230, Loss: 0.4099844981670613\n",
      "Epoch 231, Loss: 0.4074908343553954\n",
      "Epoch 232, Loss: 0.41404155462298753\n",
      "Epoch 233, Loss: 0.41428398110821113\n",
      "Epoch 234, Loss: 0.411010796569875\n",
      "Epoch 235, Loss: 0.40626047194262166\n",
      "Epoch 236, Loss: 0.409034666887797\n",
      "Epoch 237, Loss: 0.4158159770891869\n",
      "Epoch 238, Loss: 0.4153325557817546\n",
      "Epoch 239, Loss: 0.40773651613666245\n",
      "Epoch 240, Loss: 0.40720486297242386\n",
      "Epoch 241, Loss: 0.41676379700873606\n",
      "Epoch 242, Loss: 0.4163271136351227\n",
      "Epoch 243, Loss: 0.4079038079306381\n",
      "Epoch 244, Loss: 0.41018584008428094\n",
      "Epoch 245, Loss: 0.4183221731020751\n",
      "Epoch 246, Loss: 0.4083151230189892\n",
      "Epoch 247, Loss: 0.403887555337203\n",
      "Epoch 248, Loss: 0.4087575223213056\n",
      "Epoch 249, Loss: 0.40489636999784445\n",
      "Epoch 250, Loss: 0.4028637127989142\n",
      "Epoch 251, Loss: 0.40329884617463313\n",
      "Epoch 252, Loss: 0.4063995709543235\n",
      "Epoch 253, Loss: 0.4039770141828027\n",
      "Epoch 254, Loss: 0.40232352789271325\n",
      "Epoch 255, Loss: 0.40085487433081396\n",
      "Epoch 256, Loss: 0.4013585184836403\n",
      "Epoch 257, Loss: 0.401038171909843\n",
      "Epoch 258, Loss: 0.4020229653351035\n",
      "Epoch 259, Loss: 0.4038903224025568\n",
      "Epoch 260, Loss: 0.4061704337624061\n",
      "Epoch 261, Loss: 0.40752030716947196\n",
      "Epoch 262, Loss: 0.4085568442371171\n",
      "Epoch 263, Loss: 0.40261644547833497\n",
      "Epoch 264, Loss: 0.39916727140987407\n",
      "Epoch 265, Loss: 0.39918720546249864\n",
      "Epoch 266, Loss: 0.4018616982923893\n",
      "Epoch 267, Loss: 0.40409750330247396\n",
      "Epoch 268, Loss: 0.4030983154573023\n",
      "Epoch 269, Loss: 0.40148977741823705\n",
      "Epoch 270, Loss: 0.3979682402950119\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22488696788044807\n",
      "Test R^2 score: 0.4518083236961049\n",
      "Num of epochs: 271\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Epoch 179, Loss: 0.42867030340024453\n",
      "Epoch 180, Loss: 0.42665902048327814\n",
      "Epoch 181, Loss: 0.4160041986606613\n",
      "Epoch 182, Loss: 0.42380692389414293\n",
      "Epoch 183, Loss: 0.4367609764525626\n",
      "Epoch 184, Loss: 0.42557170506243686\n",
      "Epoch 185, Loss: 0.42106826790053603\n",
      "Epoch 186, Loss: 0.42573876125176086\n",
      "Epoch 187, Loss: 0.41925407360374856\n",
      "Epoch 188, Loss: 0.4183384695092418\n",
      "Epoch 189, Loss: 0.4218813047997579\n",
      "Epoch 190, Loss: 0.4197713005325469\n",
      "Epoch 191, Loss: 0.417197451669247\n",
      "Epoch 192, Loss: 0.41998586832409235\n",
      "Epoch 193, Loss: 0.4198630180807017\n",
      "Epoch 194, Loss: 0.4146118298837611\n",
      "Epoch 195, Loss: 0.41413205840097117\n",
      "Epoch 196, Loss: 0.4155607826414292\n",
      "Epoch 197, Loss: 0.414238532452658\n",
      "Epoch 198, Loss: 0.41297339310852155\n",
      "Epoch 199, Loss: 0.4123900845056213\n",
      "Epoch 200, Loss: 0.4134311180746695\n",
      "Epoch 201, Loss: 0.4127689164145939\n",
      "Epoch 202, Loss: 0.41232720715179455\n",
      "Epoch 203, Loss: 0.41150345937125327\n",
      "Epoch 204, Loss: 0.4115020652257978\n",
      "Epoch 205, Loss: 0.411078297677327\n",
      "Epoch 206, Loss: 0.4110567108542411\n",
      "Epoch 207, Loss: 0.4114023806357039\n",
      "Epoch 208, Loss: 0.41371932293434216\n",
      "Epoch 209, Loss: 0.41813952085771794\n",
      "Epoch 210, Loss: 0.42511728996367454\n",
      "Epoch 211, Loss: 0.42635158522503447\n",
      "Epoch 212, Loss: 0.419673136297028\n",
      "Epoch 213, Loss: 0.41005224089892217\n",
      "Epoch 214, Loss: 0.4205638856971283\n",
      "Epoch 215, Loss: 0.4288454648496258\n",
      "Epoch 216, Loss: 0.416730043439161\n",
      "Epoch 217, Loss: 0.4131035226095487\n",
      "Epoch 218, Loss: 0.41919050177663497\n",
      "Epoch 219, Loss: 0.41341632229404196\n",
      "Epoch 220, Loss: 0.411337015720657\n",
      "Epoch 221, Loss: 0.4153124279254653\n",
      "Epoch 222, Loss: 0.4104582809838288\n",
      "Epoch 223, Loss: 0.4101367219181661\n",
      "Epoch 224, Loss: 0.4157081327260397\n",
      "Epoch 225, Loss: 0.4144226163660391\n",
      "Epoch 226, Loss: 0.4098329995970875\n",
      "Epoch 227, Loss: 0.40775029376666666\n",
      "Epoch 228, Loss: 0.41429755898335924\n",
      "Epoch 229, Loss: 0.41521591906294136\n",
      "Epoch 230, Loss: 0.4099844981670613\n",
      "Epoch 231, Loss: 0.4074908343553954\n",
      "Epoch 232, Loss: 0.41404155462298753\n",
      "Epoch 233, Loss: 0.41428398110821113\n",
      "Epoch 234, Loss: 0.411010796569875\n",
      "Epoch 235, Loss: 0.40626047194262166\n",
      "Epoch 236, Loss: 0.409034666887797\n",
      "Epoch 237, Loss: 0.4158159770891869\n",
      "Epoch 238, Loss: 0.4153325557817546\n",
      "Epoch 239, Loss: 0.40773651613666245\n",
      "Epoch 240, Loss: 0.40720486297242386\n",
      "Epoch 241, Loss: 0.41676379700873606\n",
      "Epoch 242, Loss: 0.4163271136351227\n",
      "Epoch 243, Loss: 0.4079038079306381\n",
      "Epoch 244, Loss: 0.41018584008428094\n",
      "Epoch 245, Loss: 0.4183221731020751\n",
      "Epoch 246, Loss: 0.4083151230189892\n",
      "Epoch 247, Loss: 0.403887555337203\n",
      "Epoch 248, Loss: 0.4087575223213056\n",
      "Epoch 249, Loss: 0.40489636999784445\n",
      "Epoch 250, Loss: 0.4028637127989142\n",
      "Epoch 251, Loss: 0.40329884617463313\n",
      "Epoch 252, Loss: 0.4063995709543235\n",
      "Epoch 253, Loss: 0.4039770141828027\n",
      "Epoch 254, Loss: 0.40232352789271325\n",
      "Epoch 255, Loss: 0.40085487433081396\n",
      "Epoch 256, Loss: 0.4013585184836403\n",
      "Epoch 257, Loss: 0.401038171909843\n",
      "Epoch 258, Loss: 0.4020229653351035\n",
      "Epoch 259, Loss: 0.4038903224025568\n",
      "Epoch 260, Loss: 0.4061704337624061\n",
      "Epoch 261, Loss: 0.40752030716947196\n",
      "Epoch 262, Loss: 0.4085568442371171\n",
      "Epoch 263, Loss: 0.40261644547833497\n",
      "Epoch 264, Loss: 0.39916727140987407\n",
      "Epoch 265, Loss: 0.39918720546249864\n",
      "Epoch 266, Loss: 0.4018616982923893\n",
      "Epoch 267, Loss: 0.40409750330247396\n",
      "Epoch 268, Loss: 0.4030983154573023\n",
      "Epoch 269, Loss: 0.40148977741823705\n",
      "Epoch 270, Loss: 0.3979682402950119\n",
      "Epoch 271, Loss: 0.39712887326045615\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22666443833867728\n",
      "Test R^2 score: 0.4428309431190055\n",
      "Num of epochs: 272\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Epoch 179, Loss: 0.42867030340024453\n",
      "Epoch 180, Loss: 0.42665902048327814\n",
      "Epoch 181, Loss: 0.4160041986606613\n",
      "Epoch 182, Loss: 0.42380692389414293\n",
      "Epoch 183, Loss: 0.4367609764525626\n",
      "Epoch 184, Loss: 0.42557170506243686\n",
      "Epoch 185, Loss: 0.42106826790053603\n",
      "Epoch 186, Loss: 0.42573876125176086\n",
      "Epoch 187, Loss: 0.41925407360374856\n",
      "Epoch 188, Loss: 0.4183384695092418\n",
      "Epoch 189, Loss: 0.4218813047997579\n",
      "Epoch 190, Loss: 0.4197713005325469\n",
      "Epoch 191, Loss: 0.417197451669247\n",
      "Epoch 192, Loss: 0.41998586832409235\n",
      "Epoch 193, Loss: 0.4198630180807017\n",
      "Epoch 194, Loss: 0.4146118298837611\n",
      "Epoch 195, Loss: 0.41413205840097117\n",
      "Epoch 196, Loss: 0.4155607826414292\n",
      "Epoch 197, Loss: 0.414238532452658\n",
      "Epoch 198, Loss: 0.41297339310852155\n",
      "Epoch 199, Loss: 0.4123900845056213\n",
      "Epoch 200, Loss: 0.4134311180746695\n",
      "Epoch 201, Loss: 0.4127689164145939\n",
      "Epoch 202, Loss: 0.41232720715179455\n",
      "Epoch 203, Loss: 0.41150345937125327\n",
      "Epoch 204, Loss: 0.4115020652257978\n",
      "Epoch 205, Loss: 0.411078297677327\n",
      "Epoch 206, Loss: 0.4110567108542411\n",
      "Epoch 207, Loss: 0.4114023806357039\n",
      "Epoch 208, Loss: 0.41371932293434216\n",
      "Epoch 209, Loss: 0.41813952085771794\n",
      "Epoch 210, Loss: 0.42511728996367454\n",
      "Epoch 211, Loss: 0.42635158522503447\n",
      "Epoch 212, Loss: 0.419673136297028\n",
      "Epoch 213, Loss: 0.41005224089892217\n",
      "Epoch 214, Loss: 0.4205638856971283\n",
      "Epoch 215, Loss: 0.4288454648496258\n",
      "Epoch 216, Loss: 0.416730043439161\n",
      "Epoch 217, Loss: 0.4131035226095487\n",
      "Epoch 218, Loss: 0.41919050177663497\n",
      "Epoch 219, Loss: 0.41341632229404196\n",
      "Epoch 220, Loss: 0.411337015720657\n",
      "Epoch 221, Loss: 0.4153124279254653\n",
      "Epoch 222, Loss: 0.4104582809838288\n",
      "Epoch 223, Loss: 0.4101367219181661\n",
      "Epoch 224, Loss: 0.4157081327260397\n",
      "Epoch 225, Loss: 0.4144226163660391\n",
      "Epoch 226, Loss: 0.4098329995970875\n",
      "Epoch 227, Loss: 0.40775029376666666\n",
      "Epoch 228, Loss: 0.41429755898335924\n",
      "Epoch 229, Loss: 0.41521591906294136\n",
      "Epoch 230, Loss: 0.4099844981670613\n",
      "Epoch 231, Loss: 0.4074908343553954\n",
      "Epoch 232, Loss: 0.41404155462298753\n",
      "Epoch 233, Loss: 0.41428398110821113\n",
      "Epoch 234, Loss: 0.411010796569875\n",
      "Epoch 235, Loss: 0.40626047194262166\n",
      "Epoch 236, Loss: 0.409034666887797\n",
      "Epoch 237, Loss: 0.4158159770891869\n",
      "Epoch 238, Loss: 0.4153325557817546\n",
      "Epoch 239, Loss: 0.40773651613666245\n",
      "Epoch 240, Loss: 0.40720486297242386\n",
      "Epoch 241, Loss: 0.41676379700873606\n",
      "Epoch 242, Loss: 0.4163271136351227\n",
      "Epoch 243, Loss: 0.4079038079306381\n",
      "Epoch 244, Loss: 0.41018584008428094\n",
      "Epoch 245, Loss: 0.4183221731020751\n",
      "Epoch 246, Loss: 0.4083151230189892\n",
      "Epoch 247, Loss: 0.403887555337203\n",
      "Epoch 248, Loss: 0.4087575223213056\n",
      "Epoch 249, Loss: 0.40489636999784445\n",
      "Epoch 250, Loss: 0.4028637127989142\n",
      "Epoch 251, Loss: 0.40329884617463313\n",
      "Epoch 252, Loss: 0.4063995709543235\n",
      "Epoch 253, Loss: 0.4039770141828027\n",
      "Epoch 254, Loss: 0.40232352789271325\n",
      "Epoch 255, Loss: 0.40085487433081396\n",
      "Epoch 256, Loss: 0.4013585184836403\n",
      "Epoch 257, Loss: 0.401038171909843\n",
      "Epoch 258, Loss: 0.4020229653351035\n",
      "Epoch 259, Loss: 0.4038903224025568\n",
      "Epoch 260, Loss: 0.4061704337624061\n",
      "Epoch 261, Loss: 0.40752030716947196\n",
      "Epoch 262, Loss: 0.4085568442371171\n",
      "Epoch 263, Loss: 0.40261644547833497\n",
      "Epoch 264, Loss: 0.39916727140987407\n",
      "Epoch 265, Loss: 0.39918720546249864\n",
      "Epoch 266, Loss: 0.4018616982923893\n",
      "Epoch 267, Loss: 0.40409750330247396\n",
      "Epoch 268, Loss: 0.4030983154573023\n",
      "Epoch 269, Loss: 0.40148977741823705\n",
      "Epoch 270, Loss: 0.3979682402950119\n",
      "Epoch 271, Loss: 0.39712887326045615\n",
      "Epoch 272, Loss: 0.3976166253873399\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22393494410231993\n",
      "Test R^2 score: 0.45603613761330497\n",
      "Num of epochs: 273\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Epoch 179, Loss: 0.42867030340024453\n",
      "Epoch 180, Loss: 0.42665902048327814\n",
      "Epoch 181, Loss: 0.4160041986606613\n",
      "Epoch 182, Loss: 0.42380692389414293\n",
      "Epoch 183, Loss: 0.4367609764525626\n",
      "Epoch 184, Loss: 0.42557170506243686\n",
      "Epoch 185, Loss: 0.42106826790053603\n",
      "Epoch 186, Loss: 0.42573876125176086\n",
      "Epoch 187, Loss: 0.41925407360374856\n",
      "Epoch 188, Loss: 0.4183384695092418\n",
      "Epoch 189, Loss: 0.4218813047997579\n",
      "Epoch 190, Loss: 0.4197713005325469\n",
      "Epoch 191, Loss: 0.417197451669247\n",
      "Epoch 192, Loss: 0.41998586832409235\n",
      "Epoch 193, Loss: 0.4198630180807017\n",
      "Epoch 194, Loss: 0.4146118298837611\n",
      "Epoch 195, Loss: 0.41413205840097117\n",
      "Epoch 196, Loss: 0.4155607826414292\n",
      "Epoch 197, Loss: 0.414238532452658\n",
      "Epoch 198, Loss: 0.41297339310852155\n",
      "Epoch 199, Loss: 0.4123900845056213\n",
      "Epoch 200, Loss: 0.4134311180746695\n",
      "Epoch 201, Loss: 0.4127689164145939\n",
      "Epoch 202, Loss: 0.41232720715179455\n",
      "Epoch 203, Loss: 0.41150345937125327\n",
      "Epoch 204, Loss: 0.4115020652257978\n",
      "Epoch 205, Loss: 0.411078297677327\n",
      "Epoch 206, Loss: 0.4110567108542411\n",
      "Epoch 207, Loss: 0.4114023806357039\n",
      "Epoch 208, Loss: 0.41371932293434216\n",
      "Epoch 209, Loss: 0.41813952085771794\n",
      "Epoch 210, Loss: 0.42511728996367454\n",
      "Epoch 211, Loss: 0.42635158522503447\n",
      "Epoch 212, Loss: 0.419673136297028\n",
      "Epoch 213, Loss: 0.41005224089892217\n",
      "Epoch 214, Loss: 0.4205638856971283\n",
      "Epoch 215, Loss: 0.4288454648496258\n",
      "Epoch 216, Loss: 0.416730043439161\n",
      "Epoch 217, Loss: 0.4131035226095487\n",
      "Epoch 218, Loss: 0.41919050177663497\n",
      "Epoch 219, Loss: 0.41341632229404196\n",
      "Epoch 220, Loss: 0.411337015720657\n",
      "Epoch 221, Loss: 0.4153124279254653\n",
      "Epoch 222, Loss: 0.4104582809838288\n",
      "Epoch 223, Loss: 0.4101367219181661\n",
      "Epoch 224, Loss: 0.4157081327260397\n",
      "Epoch 225, Loss: 0.4144226163660391\n",
      "Epoch 226, Loss: 0.4098329995970875\n",
      "Epoch 227, Loss: 0.40775029376666666\n",
      "Epoch 228, Loss: 0.41429755898335924\n",
      "Epoch 229, Loss: 0.41521591906294136\n",
      "Epoch 230, Loss: 0.4099844981670613\n",
      "Epoch 231, Loss: 0.4074908343553954\n",
      "Epoch 232, Loss: 0.41404155462298753\n",
      "Epoch 233, Loss: 0.41428398110821113\n",
      "Epoch 234, Loss: 0.411010796569875\n",
      "Epoch 235, Loss: 0.40626047194262166\n",
      "Epoch 236, Loss: 0.409034666887797\n",
      "Epoch 237, Loss: 0.4158159770891869\n",
      "Epoch 238, Loss: 0.4153325557817546\n",
      "Epoch 239, Loss: 0.40773651613666245\n",
      "Epoch 240, Loss: 0.40720486297242386\n",
      "Epoch 241, Loss: 0.41676379700873606\n",
      "Epoch 242, Loss: 0.4163271136351227\n",
      "Epoch 243, Loss: 0.4079038079306381\n",
      "Epoch 244, Loss: 0.41018584008428094\n",
      "Epoch 245, Loss: 0.4183221731020751\n",
      "Epoch 246, Loss: 0.4083151230189892\n",
      "Epoch 247, Loss: 0.403887555337203\n",
      "Epoch 248, Loss: 0.4087575223213056\n",
      "Epoch 249, Loss: 0.40489636999784445\n",
      "Epoch 250, Loss: 0.4028637127989142\n",
      "Epoch 251, Loss: 0.40329884617463313\n",
      "Epoch 252, Loss: 0.4063995709543235\n",
      "Epoch 253, Loss: 0.4039770141828027\n",
      "Epoch 254, Loss: 0.40232352789271325\n",
      "Epoch 255, Loss: 0.40085487433081396\n",
      "Epoch 256, Loss: 0.4013585184836403\n",
      "Epoch 257, Loss: 0.401038171909843\n",
      "Epoch 258, Loss: 0.4020229653351035\n",
      "Epoch 259, Loss: 0.4038903224025568\n",
      "Epoch 260, Loss: 0.4061704337624061\n",
      "Epoch 261, Loss: 0.40752030716947196\n",
      "Epoch 262, Loss: 0.4085568442371171\n",
      "Epoch 263, Loss: 0.40261644547833497\n",
      "Epoch 264, Loss: 0.39916727140987407\n",
      "Epoch 265, Loss: 0.39918720546249864\n",
      "Epoch 266, Loss: 0.4018616982923893\n",
      "Epoch 267, Loss: 0.40409750330247396\n",
      "Epoch 268, Loss: 0.4030983154573023\n",
      "Epoch 269, Loss: 0.40148977741823705\n",
      "Epoch 270, Loss: 0.3979682402950119\n",
      "Epoch 271, Loss: 0.39712887326045615\n",
      "Epoch 272, Loss: 0.3976166253873399\n",
      "Epoch 273, Loss: 0.3994664761725427\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2361641791845107\n",
      "Test R^2 score: 0.3950425662880534\n",
      "Num of epochs: 274\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Epoch 179, Loss: 0.42867030340024453\n",
      "Epoch 180, Loss: 0.42665902048327814\n",
      "Epoch 181, Loss: 0.4160041986606613\n",
      "Epoch 182, Loss: 0.42380692389414293\n",
      "Epoch 183, Loss: 0.4367609764525626\n",
      "Epoch 184, Loss: 0.42557170506243686\n",
      "Epoch 185, Loss: 0.42106826790053603\n",
      "Epoch 186, Loss: 0.42573876125176086\n",
      "Epoch 187, Loss: 0.41925407360374856\n",
      "Epoch 188, Loss: 0.4183384695092418\n",
      "Epoch 189, Loss: 0.4218813047997579\n",
      "Epoch 190, Loss: 0.4197713005325469\n",
      "Epoch 191, Loss: 0.417197451669247\n",
      "Epoch 192, Loss: 0.41998586832409235\n",
      "Epoch 193, Loss: 0.4198630180807017\n",
      "Epoch 194, Loss: 0.4146118298837611\n",
      "Epoch 195, Loss: 0.41413205840097117\n",
      "Epoch 196, Loss: 0.4155607826414292\n",
      "Epoch 197, Loss: 0.414238532452658\n",
      "Epoch 198, Loss: 0.41297339310852155\n",
      "Epoch 199, Loss: 0.4123900845056213\n",
      "Epoch 200, Loss: 0.4134311180746695\n",
      "Epoch 201, Loss: 0.4127689164145939\n",
      "Epoch 202, Loss: 0.41232720715179455\n",
      "Epoch 203, Loss: 0.41150345937125327\n",
      "Epoch 204, Loss: 0.4115020652257978\n",
      "Epoch 205, Loss: 0.411078297677327\n",
      "Epoch 206, Loss: 0.4110567108542411\n",
      "Epoch 207, Loss: 0.4114023806357039\n",
      "Epoch 208, Loss: 0.41371932293434216\n",
      "Epoch 209, Loss: 0.41813952085771794\n",
      "Epoch 210, Loss: 0.42511728996367454\n",
      "Epoch 211, Loss: 0.42635158522503447\n",
      "Epoch 212, Loss: 0.419673136297028\n",
      "Epoch 213, Loss: 0.41005224089892217\n",
      "Epoch 214, Loss: 0.4205638856971283\n",
      "Epoch 215, Loss: 0.4288454648496258\n",
      "Epoch 216, Loss: 0.416730043439161\n",
      "Epoch 217, Loss: 0.4131035226095487\n",
      "Epoch 218, Loss: 0.41919050177663497\n",
      "Epoch 219, Loss: 0.41341632229404196\n",
      "Epoch 220, Loss: 0.411337015720657\n",
      "Epoch 221, Loss: 0.4153124279254653\n",
      "Epoch 222, Loss: 0.4104582809838288\n",
      "Epoch 223, Loss: 0.4101367219181661\n",
      "Epoch 224, Loss: 0.4157081327260397\n",
      "Epoch 225, Loss: 0.4144226163660391\n",
      "Epoch 226, Loss: 0.4098329995970875\n",
      "Epoch 227, Loss: 0.40775029376666666\n",
      "Epoch 228, Loss: 0.41429755898335924\n",
      "Epoch 229, Loss: 0.41521591906294136\n",
      "Epoch 230, Loss: 0.4099844981670613\n",
      "Epoch 231, Loss: 0.4074908343553954\n",
      "Epoch 232, Loss: 0.41404155462298753\n",
      "Epoch 233, Loss: 0.41428398110821113\n",
      "Epoch 234, Loss: 0.411010796569875\n",
      "Epoch 235, Loss: 0.40626047194262166\n",
      "Epoch 236, Loss: 0.409034666887797\n",
      "Epoch 237, Loss: 0.4158159770891869\n",
      "Epoch 238, Loss: 0.4153325557817546\n",
      "Epoch 239, Loss: 0.40773651613666245\n",
      "Epoch 240, Loss: 0.40720486297242386\n",
      "Epoch 241, Loss: 0.41676379700873606\n",
      "Epoch 242, Loss: 0.4163271136351227\n",
      "Epoch 243, Loss: 0.4079038079306381\n",
      "Epoch 244, Loss: 0.41018584008428094\n",
      "Epoch 245, Loss: 0.4183221731020751\n",
      "Epoch 246, Loss: 0.4083151230189892\n",
      "Epoch 247, Loss: 0.403887555337203\n",
      "Epoch 248, Loss: 0.4087575223213056\n",
      "Epoch 249, Loss: 0.40489636999784445\n",
      "Epoch 250, Loss: 0.4028637127989142\n",
      "Epoch 251, Loss: 0.40329884617463313\n",
      "Epoch 252, Loss: 0.4063995709543235\n",
      "Epoch 253, Loss: 0.4039770141828027\n",
      "Epoch 254, Loss: 0.40232352789271325\n",
      "Epoch 255, Loss: 0.40085487433081396\n",
      "Epoch 256, Loss: 0.4013585184836403\n",
      "Epoch 257, Loss: 0.401038171909843\n",
      "Epoch 258, Loss: 0.4020229653351035\n",
      "Epoch 259, Loss: 0.4038903224025568\n",
      "Epoch 260, Loss: 0.4061704337624061\n",
      "Epoch 261, Loss: 0.40752030716947196\n",
      "Epoch 262, Loss: 0.4085568442371171\n",
      "Epoch 263, Loss: 0.40261644547833497\n",
      "Epoch 264, Loss: 0.39916727140987407\n",
      "Epoch 265, Loss: 0.39918720546249864\n",
      "Epoch 266, Loss: 0.4018616982923893\n",
      "Epoch 267, Loss: 0.40409750330247396\n",
      "Epoch 268, Loss: 0.4030983154573023\n",
      "Epoch 269, Loss: 0.40148977741823705\n",
      "Epoch 270, Loss: 0.3979682402950119\n",
      "Epoch 271, Loss: 0.39712887326045615\n",
      "Epoch 272, Loss: 0.3976166253873399\n",
      "Epoch 273, Loss: 0.3994664761725427\n",
      "Epoch 274, Loss: 0.40664772591817466\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.226878600193599\n",
      "Test R^2 score: 0.44111517125013283\n",
      "Num of epochs: 275\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Epoch 179, Loss: 0.42867030340024453\n",
      "Epoch 180, Loss: 0.42665902048327814\n",
      "Epoch 181, Loss: 0.4160041986606613\n",
      "Epoch 182, Loss: 0.42380692389414293\n",
      "Epoch 183, Loss: 0.4367609764525626\n",
      "Epoch 184, Loss: 0.42557170506243686\n",
      "Epoch 185, Loss: 0.42106826790053603\n",
      "Epoch 186, Loss: 0.42573876125176086\n",
      "Epoch 187, Loss: 0.41925407360374856\n",
      "Epoch 188, Loss: 0.4183384695092418\n",
      "Epoch 189, Loss: 0.4218813047997579\n",
      "Epoch 190, Loss: 0.4197713005325469\n",
      "Epoch 191, Loss: 0.417197451669247\n",
      "Epoch 192, Loss: 0.41998586832409235\n",
      "Epoch 193, Loss: 0.4198630180807017\n",
      "Epoch 194, Loss: 0.4146118298837611\n",
      "Epoch 195, Loss: 0.41413205840097117\n",
      "Epoch 196, Loss: 0.4155607826414292\n",
      "Epoch 197, Loss: 0.414238532452658\n",
      "Epoch 198, Loss: 0.41297339310852155\n",
      "Epoch 199, Loss: 0.4123900845056213\n",
      "Epoch 200, Loss: 0.4134311180746695\n",
      "Epoch 201, Loss: 0.4127689164145939\n",
      "Epoch 202, Loss: 0.41232720715179455\n",
      "Epoch 203, Loss: 0.41150345937125327\n",
      "Epoch 204, Loss: 0.4115020652257978\n",
      "Epoch 205, Loss: 0.411078297677327\n",
      "Epoch 206, Loss: 0.4110567108542411\n",
      "Epoch 207, Loss: 0.4114023806357039\n",
      "Epoch 208, Loss: 0.41371932293434216\n",
      "Epoch 209, Loss: 0.41813952085771794\n",
      "Epoch 210, Loss: 0.42511728996367454\n",
      "Epoch 211, Loss: 0.42635158522503447\n",
      "Epoch 212, Loss: 0.419673136297028\n",
      "Epoch 213, Loss: 0.41005224089892217\n",
      "Epoch 214, Loss: 0.4205638856971283\n",
      "Epoch 215, Loss: 0.4288454648496258\n",
      "Epoch 216, Loss: 0.416730043439161\n",
      "Epoch 217, Loss: 0.4131035226095487\n",
      "Epoch 218, Loss: 0.41919050177663497\n",
      "Epoch 219, Loss: 0.41341632229404196\n",
      "Epoch 220, Loss: 0.411337015720657\n",
      "Epoch 221, Loss: 0.4153124279254653\n",
      "Epoch 222, Loss: 0.4104582809838288\n",
      "Epoch 223, Loss: 0.4101367219181661\n",
      "Epoch 224, Loss: 0.4157081327260397\n",
      "Epoch 225, Loss: 0.4144226163660391\n",
      "Epoch 226, Loss: 0.4098329995970875\n",
      "Epoch 227, Loss: 0.40775029376666666\n",
      "Epoch 228, Loss: 0.41429755898335924\n",
      "Epoch 229, Loss: 0.41521591906294136\n",
      "Epoch 230, Loss: 0.4099844981670613\n",
      "Epoch 231, Loss: 0.4074908343553954\n",
      "Epoch 232, Loss: 0.41404155462298753\n",
      "Epoch 233, Loss: 0.41428398110821113\n",
      "Epoch 234, Loss: 0.411010796569875\n",
      "Epoch 235, Loss: 0.40626047194262166\n",
      "Epoch 236, Loss: 0.409034666887797\n",
      "Epoch 237, Loss: 0.4158159770891869\n",
      "Epoch 238, Loss: 0.4153325557817546\n",
      "Epoch 239, Loss: 0.40773651613666245\n",
      "Epoch 240, Loss: 0.40720486297242386\n",
      "Epoch 241, Loss: 0.41676379700873606\n",
      "Epoch 242, Loss: 0.4163271136351227\n",
      "Epoch 243, Loss: 0.4079038079306381\n",
      "Epoch 244, Loss: 0.41018584008428094\n",
      "Epoch 245, Loss: 0.4183221731020751\n",
      "Epoch 246, Loss: 0.4083151230189892\n",
      "Epoch 247, Loss: 0.403887555337203\n",
      "Epoch 248, Loss: 0.4087575223213056\n",
      "Epoch 249, Loss: 0.40489636999784445\n",
      "Epoch 250, Loss: 0.4028637127989142\n",
      "Epoch 251, Loss: 0.40329884617463313\n",
      "Epoch 252, Loss: 0.4063995709543235\n",
      "Epoch 253, Loss: 0.4039770141828027\n",
      "Epoch 254, Loss: 0.40232352789271325\n",
      "Epoch 255, Loss: 0.40085487433081396\n",
      "Epoch 256, Loss: 0.4013585184836403\n",
      "Epoch 257, Loss: 0.401038171909843\n",
      "Epoch 258, Loss: 0.4020229653351035\n",
      "Epoch 259, Loss: 0.4038903224025568\n",
      "Epoch 260, Loss: 0.4061704337624061\n",
      "Epoch 261, Loss: 0.40752030716947196\n",
      "Epoch 262, Loss: 0.4085568442371171\n",
      "Epoch 263, Loss: 0.40261644547833497\n",
      "Epoch 264, Loss: 0.39916727140987407\n",
      "Epoch 265, Loss: 0.39918720546249864\n",
      "Epoch 266, Loss: 0.4018616982923893\n",
      "Epoch 267, Loss: 0.40409750330247396\n",
      "Epoch 268, Loss: 0.4030983154573023\n",
      "Epoch 269, Loss: 0.40148977741823705\n",
      "Epoch 270, Loss: 0.3979682402950119\n",
      "Epoch 271, Loss: 0.39712887326045615\n",
      "Epoch 272, Loss: 0.3976166253873399\n",
      "Epoch 273, Loss: 0.3994664761725427\n",
      "Epoch 274, Loss: 0.40664772591817466\n",
      "Epoch 275, Loss: 0.4160374917744293\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.24243509269674254\n",
      "Test R^2 score: 0.36272481542743595\n",
      "Num of epochs: 276\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Epoch 179, Loss: 0.42867030340024453\n",
      "Epoch 180, Loss: 0.42665902048327814\n",
      "Epoch 181, Loss: 0.4160041986606613\n",
      "Epoch 182, Loss: 0.42380692389414293\n",
      "Epoch 183, Loss: 0.4367609764525626\n",
      "Epoch 184, Loss: 0.42557170506243686\n",
      "Epoch 185, Loss: 0.42106826790053603\n",
      "Epoch 186, Loss: 0.42573876125176086\n",
      "Epoch 187, Loss: 0.41925407360374856\n",
      "Epoch 188, Loss: 0.4183384695092418\n",
      "Epoch 189, Loss: 0.4218813047997579\n",
      "Epoch 190, Loss: 0.4197713005325469\n",
      "Epoch 191, Loss: 0.417197451669247\n",
      "Epoch 192, Loss: 0.41998586832409235\n",
      "Epoch 193, Loss: 0.4198630180807017\n",
      "Epoch 194, Loss: 0.4146118298837611\n",
      "Epoch 195, Loss: 0.41413205840097117\n",
      "Epoch 196, Loss: 0.4155607826414292\n",
      "Epoch 197, Loss: 0.414238532452658\n",
      "Epoch 198, Loss: 0.41297339310852155\n",
      "Epoch 199, Loss: 0.4123900845056213\n",
      "Epoch 200, Loss: 0.4134311180746695\n",
      "Epoch 201, Loss: 0.4127689164145939\n",
      "Epoch 202, Loss: 0.41232720715179455\n",
      "Epoch 203, Loss: 0.41150345937125327\n",
      "Epoch 204, Loss: 0.4115020652257978\n",
      "Epoch 205, Loss: 0.411078297677327\n",
      "Epoch 206, Loss: 0.4110567108542411\n",
      "Epoch 207, Loss: 0.4114023806357039\n",
      "Epoch 208, Loss: 0.41371932293434216\n",
      "Epoch 209, Loss: 0.41813952085771794\n",
      "Epoch 210, Loss: 0.42511728996367454\n",
      "Epoch 211, Loss: 0.42635158522503447\n",
      "Epoch 212, Loss: 0.419673136297028\n",
      "Epoch 213, Loss: 0.41005224089892217\n",
      "Epoch 214, Loss: 0.4205638856971283\n",
      "Epoch 215, Loss: 0.4288454648496258\n",
      "Epoch 216, Loss: 0.416730043439161\n",
      "Epoch 217, Loss: 0.4131035226095487\n",
      "Epoch 218, Loss: 0.41919050177663497\n",
      "Epoch 219, Loss: 0.41341632229404196\n",
      "Epoch 220, Loss: 0.411337015720657\n",
      "Epoch 221, Loss: 0.4153124279254653\n",
      "Epoch 222, Loss: 0.4104582809838288\n",
      "Epoch 223, Loss: 0.4101367219181661\n",
      "Epoch 224, Loss: 0.4157081327260397\n",
      "Epoch 225, Loss: 0.4144226163660391\n",
      "Epoch 226, Loss: 0.4098329995970875\n",
      "Epoch 227, Loss: 0.40775029376666666\n",
      "Epoch 228, Loss: 0.41429755898335924\n",
      "Epoch 229, Loss: 0.41521591906294136\n",
      "Epoch 230, Loss: 0.4099844981670613\n",
      "Epoch 231, Loss: 0.4074908343553954\n",
      "Epoch 232, Loss: 0.41404155462298753\n",
      "Epoch 233, Loss: 0.41428398110821113\n",
      "Epoch 234, Loss: 0.411010796569875\n",
      "Epoch 235, Loss: 0.40626047194262166\n",
      "Epoch 236, Loss: 0.409034666887797\n",
      "Epoch 237, Loss: 0.4158159770891869\n",
      "Epoch 238, Loss: 0.4153325557817546\n",
      "Epoch 239, Loss: 0.40773651613666245\n",
      "Epoch 240, Loss: 0.40720486297242386\n",
      "Epoch 241, Loss: 0.41676379700873606\n",
      "Epoch 242, Loss: 0.4163271136351227\n",
      "Epoch 243, Loss: 0.4079038079306381\n",
      "Epoch 244, Loss: 0.41018584008428094\n",
      "Epoch 245, Loss: 0.4183221731020751\n",
      "Epoch 246, Loss: 0.4083151230189892\n",
      "Epoch 247, Loss: 0.403887555337203\n",
      "Epoch 248, Loss: 0.4087575223213056\n",
      "Epoch 249, Loss: 0.40489636999784445\n",
      "Epoch 250, Loss: 0.4028637127989142\n",
      "Epoch 251, Loss: 0.40329884617463313\n",
      "Epoch 252, Loss: 0.4063995709543235\n",
      "Epoch 253, Loss: 0.4039770141828027\n",
      "Epoch 254, Loss: 0.40232352789271325\n",
      "Epoch 255, Loss: 0.40085487433081396\n",
      "Epoch 256, Loss: 0.4013585184836403\n",
      "Epoch 257, Loss: 0.401038171909843\n",
      "Epoch 258, Loss: 0.4020229653351035\n",
      "Epoch 259, Loss: 0.4038903224025568\n",
      "Epoch 260, Loss: 0.4061704337624061\n",
      "Epoch 261, Loss: 0.40752030716947196\n",
      "Epoch 262, Loss: 0.4085568442371171\n",
      "Epoch 263, Loss: 0.40261644547833497\n",
      "Epoch 264, Loss: 0.39916727140987407\n",
      "Epoch 265, Loss: 0.39918720546249864\n",
      "Epoch 266, Loss: 0.4018616982923893\n",
      "Epoch 267, Loss: 0.40409750330247396\n",
      "Epoch 268, Loss: 0.4030983154573023\n",
      "Epoch 269, Loss: 0.40148977741823705\n",
      "Epoch 270, Loss: 0.3979682402950119\n",
      "Epoch 271, Loss: 0.39712887326045615\n",
      "Epoch 272, Loss: 0.3976166253873399\n",
      "Epoch 273, Loss: 0.3994664761725427\n",
      "Epoch 274, Loss: 0.40664772591817466\n",
      "Epoch 275, Loss: 0.4160374917744293\n",
      "Epoch 276, Loss: 0.42157817924529983\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22241347261379965\n",
      "Test R^2 score: 0.46400649537995464\n",
      "Num of epochs: 277\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Epoch 179, Loss: 0.42867030340024453\n",
      "Epoch 180, Loss: 0.42665902048327814\n",
      "Epoch 181, Loss: 0.4160041986606613\n",
      "Epoch 182, Loss: 0.42380692389414293\n",
      "Epoch 183, Loss: 0.4367609764525626\n",
      "Epoch 184, Loss: 0.42557170506243686\n",
      "Epoch 185, Loss: 0.42106826790053603\n",
      "Epoch 186, Loss: 0.42573876125176086\n",
      "Epoch 187, Loss: 0.41925407360374856\n",
      "Epoch 188, Loss: 0.4183384695092418\n",
      "Epoch 189, Loss: 0.4218813047997579\n",
      "Epoch 190, Loss: 0.4197713005325469\n",
      "Epoch 191, Loss: 0.417197451669247\n",
      "Epoch 192, Loss: 0.41998586832409235\n",
      "Epoch 193, Loss: 0.4198630180807017\n",
      "Epoch 194, Loss: 0.4146118298837611\n",
      "Epoch 195, Loss: 0.41413205840097117\n",
      "Epoch 196, Loss: 0.4155607826414292\n",
      "Epoch 197, Loss: 0.414238532452658\n",
      "Epoch 198, Loss: 0.41297339310852155\n",
      "Epoch 199, Loss: 0.4123900845056213\n",
      "Epoch 200, Loss: 0.4134311180746695\n",
      "Epoch 201, Loss: 0.4127689164145939\n",
      "Epoch 202, Loss: 0.41232720715179455\n",
      "Epoch 203, Loss: 0.41150345937125327\n",
      "Epoch 204, Loss: 0.4115020652257978\n",
      "Epoch 205, Loss: 0.411078297677327\n",
      "Epoch 206, Loss: 0.4110567108542411\n",
      "Epoch 207, Loss: 0.4114023806357039\n",
      "Epoch 208, Loss: 0.41371932293434216\n",
      "Epoch 209, Loss: 0.41813952085771794\n",
      "Epoch 210, Loss: 0.42511728996367454\n",
      "Epoch 211, Loss: 0.42635158522503447\n",
      "Epoch 212, Loss: 0.419673136297028\n",
      "Epoch 213, Loss: 0.41005224089892217\n",
      "Epoch 214, Loss: 0.4205638856971283\n",
      "Epoch 215, Loss: 0.4288454648496258\n",
      "Epoch 216, Loss: 0.416730043439161\n",
      "Epoch 217, Loss: 0.4131035226095487\n",
      "Epoch 218, Loss: 0.41919050177663497\n",
      "Epoch 219, Loss: 0.41341632229404196\n",
      "Epoch 220, Loss: 0.411337015720657\n",
      "Epoch 221, Loss: 0.4153124279254653\n",
      "Epoch 222, Loss: 0.4104582809838288\n",
      "Epoch 223, Loss: 0.4101367219181661\n",
      "Epoch 224, Loss: 0.4157081327260397\n",
      "Epoch 225, Loss: 0.4144226163660391\n",
      "Epoch 226, Loss: 0.4098329995970875\n",
      "Epoch 227, Loss: 0.40775029376666666\n",
      "Epoch 228, Loss: 0.41429755898335924\n",
      "Epoch 229, Loss: 0.41521591906294136\n",
      "Epoch 230, Loss: 0.4099844981670613\n",
      "Epoch 231, Loss: 0.4074908343553954\n",
      "Epoch 232, Loss: 0.41404155462298753\n",
      "Epoch 233, Loss: 0.41428398110821113\n",
      "Epoch 234, Loss: 0.411010796569875\n",
      "Epoch 235, Loss: 0.40626047194262166\n",
      "Epoch 236, Loss: 0.409034666887797\n",
      "Epoch 237, Loss: 0.4158159770891869\n",
      "Epoch 238, Loss: 0.4153325557817546\n",
      "Epoch 239, Loss: 0.40773651613666245\n",
      "Epoch 240, Loss: 0.40720486297242386\n",
      "Epoch 241, Loss: 0.41676379700873606\n",
      "Epoch 242, Loss: 0.4163271136351227\n",
      "Epoch 243, Loss: 0.4079038079306381\n",
      "Epoch 244, Loss: 0.41018584008428094\n",
      "Epoch 245, Loss: 0.4183221731020751\n",
      "Epoch 246, Loss: 0.4083151230189892\n",
      "Epoch 247, Loss: 0.403887555337203\n",
      "Epoch 248, Loss: 0.4087575223213056\n",
      "Epoch 249, Loss: 0.40489636999784445\n",
      "Epoch 250, Loss: 0.4028637127989142\n",
      "Epoch 251, Loss: 0.40329884617463313\n",
      "Epoch 252, Loss: 0.4063995709543235\n",
      "Epoch 253, Loss: 0.4039770141828027\n",
      "Epoch 254, Loss: 0.40232352789271325\n",
      "Epoch 255, Loss: 0.40085487433081396\n",
      "Epoch 256, Loss: 0.4013585184836403\n",
      "Epoch 257, Loss: 0.401038171909843\n",
      "Epoch 258, Loss: 0.4020229653351035\n",
      "Epoch 259, Loss: 0.4038903224025568\n",
      "Epoch 260, Loss: 0.4061704337624061\n",
      "Epoch 261, Loss: 0.40752030716947196\n",
      "Epoch 262, Loss: 0.4085568442371171\n",
      "Epoch 263, Loss: 0.40261644547833497\n",
      "Epoch 264, Loss: 0.39916727140987407\n",
      "Epoch 265, Loss: 0.39918720546249864\n",
      "Epoch 266, Loss: 0.4018616982923893\n",
      "Epoch 267, Loss: 0.40409750330247396\n",
      "Epoch 268, Loss: 0.4030983154573023\n",
      "Epoch 269, Loss: 0.40148977741823705\n",
      "Epoch 270, Loss: 0.3979682402950119\n",
      "Epoch 271, Loss: 0.39712887326045615\n",
      "Epoch 272, Loss: 0.3976166253873399\n",
      "Epoch 273, Loss: 0.3994664761725427\n",
      "Epoch 274, Loss: 0.40664772591817466\n",
      "Epoch 275, Loss: 0.4160374917744293\n",
      "Epoch 276, Loss: 0.42157817924529983\n",
      "Epoch 277, Loss: 0.3991758200300099\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22533851347982042\n",
      "Test R^2 score: 0.450313194743103\n",
      "Num of epochs: 278\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Epoch 179, Loss: 0.42867030340024453\n",
      "Epoch 180, Loss: 0.42665902048327814\n",
      "Epoch 181, Loss: 0.4160041986606613\n",
      "Epoch 182, Loss: 0.42380692389414293\n",
      "Epoch 183, Loss: 0.4367609764525626\n",
      "Epoch 184, Loss: 0.42557170506243686\n",
      "Epoch 185, Loss: 0.42106826790053603\n",
      "Epoch 186, Loss: 0.42573876125176086\n",
      "Epoch 187, Loss: 0.41925407360374856\n",
      "Epoch 188, Loss: 0.4183384695092418\n",
      "Epoch 189, Loss: 0.4218813047997579\n",
      "Epoch 190, Loss: 0.4197713005325469\n",
      "Epoch 191, Loss: 0.417197451669247\n",
      "Epoch 192, Loss: 0.41998586832409235\n",
      "Epoch 193, Loss: 0.4198630180807017\n",
      "Epoch 194, Loss: 0.4146118298837611\n",
      "Epoch 195, Loss: 0.41413205840097117\n",
      "Epoch 196, Loss: 0.4155607826414292\n",
      "Epoch 197, Loss: 0.414238532452658\n",
      "Epoch 198, Loss: 0.41297339310852155\n",
      "Epoch 199, Loss: 0.4123900845056213\n",
      "Epoch 200, Loss: 0.4134311180746695\n",
      "Epoch 201, Loss: 0.4127689164145939\n",
      "Epoch 202, Loss: 0.41232720715179455\n",
      "Epoch 203, Loss: 0.41150345937125327\n",
      "Epoch 204, Loss: 0.4115020652257978\n",
      "Epoch 205, Loss: 0.411078297677327\n",
      "Epoch 206, Loss: 0.4110567108542411\n",
      "Epoch 207, Loss: 0.4114023806357039\n",
      "Epoch 208, Loss: 0.41371932293434216\n",
      "Epoch 209, Loss: 0.41813952085771794\n",
      "Epoch 210, Loss: 0.42511728996367454\n",
      "Epoch 211, Loss: 0.42635158522503447\n",
      "Epoch 212, Loss: 0.419673136297028\n",
      "Epoch 213, Loss: 0.41005224089892217\n",
      "Epoch 214, Loss: 0.4205638856971283\n",
      "Epoch 215, Loss: 0.4288454648496258\n",
      "Epoch 216, Loss: 0.416730043439161\n",
      "Epoch 217, Loss: 0.4131035226095487\n",
      "Epoch 218, Loss: 0.41919050177663497\n",
      "Epoch 219, Loss: 0.41341632229404196\n",
      "Epoch 220, Loss: 0.411337015720657\n",
      "Epoch 221, Loss: 0.4153124279254653\n",
      "Epoch 222, Loss: 0.4104582809838288\n",
      "Epoch 223, Loss: 0.4101367219181661\n",
      "Epoch 224, Loss: 0.4157081327260397\n",
      "Epoch 225, Loss: 0.4144226163660391\n",
      "Epoch 226, Loss: 0.4098329995970875\n",
      "Epoch 227, Loss: 0.40775029376666666\n",
      "Epoch 228, Loss: 0.41429755898335924\n",
      "Epoch 229, Loss: 0.41521591906294136\n",
      "Epoch 230, Loss: 0.4099844981670613\n",
      "Epoch 231, Loss: 0.4074908343553954\n",
      "Epoch 232, Loss: 0.41404155462298753\n",
      "Epoch 233, Loss: 0.41428398110821113\n",
      "Epoch 234, Loss: 0.411010796569875\n",
      "Epoch 235, Loss: 0.40626047194262166\n",
      "Epoch 236, Loss: 0.409034666887797\n",
      "Epoch 237, Loss: 0.4158159770891869\n",
      "Epoch 238, Loss: 0.4153325557817546\n",
      "Epoch 239, Loss: 0.40773651613666245\n",
      "Epoch 240, Loss: 0.40720486297242386\n",
      "Epoch 241, Loss: 0.41676379700873606\n",
      "Epoch 242, Loss: 0.4163271136351227\n",
      "Epoch 243, Loss: 0.4079038079306381\n",
      "Epoch 244, Loss: 0.41018584008428094\n",
      "Epoch 245, Loss: 0.4183221731020751\n",
      "Epoch 246, Loss: 0.4083151230189892\n",
      "Epoch 247, Loss: 0.403887555337203\n",
      "Epoch 248, Loss: 0.4087575223213056\n",
      "Epoch 249, Loss: 0.40489636999784445\n",
      "Epoch 250, Loss: 0.4028637127989142\n",
      "Epoch 251, Loss: 0.40329884617463313\n",
      "Epoch 252, Loss: 0.4063995709543235\n",
      "Epoch 253, Loss: 0.4039770141828027\n",
      "Epoch 254, Loss: 0.40232352789271325\n",
      "Epoch 255, Loss: 0.40085487433081396\n",
      "Epoch 256, Loss: 0.4013585184836403\n",
      "Epoch 257, Loss: 0.401038171909843\n",
      "Epoch 258, Loss: 0.4020229653351035\n",
      "Epoch 259, Loss: 0.4038903224025568\n",
      "Epoch 260, Loss: 0.4061704337624061\n",
      "Epoch 261, Loss: 0.40752030716947196\n",
      "Epoch 262, Loss: 0.4085568442371171\n",
      "Epoch 263, Loss: 0.40261644547833497\n",
      "Epoch 264, Loss: 0.39916727140987407\n",
      "Epoch 265, Loss: 0.39918720546249864\n",
      "Epoch 266, Loss: 0.4018616982923893\n",
      "Epoch 267, Loss: 0.40409750330247396\n",
      "Epoch 268, Loss: 0.4030983154573023\n",
      "Epoch 269, Loss: 0.40148977741823705\n",
      "Epoch 270, Loss: 0.3979682402950119\n",
      "Epoch 271, Loss: 0.39712887326045615\n",
      "Epoch 272, Loss: 0.3976166253873399\n",
      "Epoch 273, Loss: 0.3994664761725427\n",
      "Epoch 274, Loss: 0.40664772591817466\n",
      "Epoch 275, Loss: 0.4160374917744293\n",
      "Epoch 276, Loss: 0.42157817924529983\n",
      "Epoch 277, Loss: 0.3991758200300099\n",
      "Epoch 278, Loss: 0.4024471779631351\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.24078393479951676\n",
      "Test R^2 score: 0.37146964611327543\n",
      "Num of epochs: 279\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Epoch 179, Loss: 0.42867030340024453\n",
      "Epoch 180, Loss: 0.42665902048327814\n",
      "Epoch 181, Loss: 0.4160041986606613\n",
      "Epoch 182, Loss: 0.42380692389414293\n",
      "Epoch 183, Loss: 0.4367609764525626\n",
      "Epoch 184, Loss: 0.42557170506243686\n",
      "Epoch 185, Loss: 0.42106826790053603\n",
      "Epoch 186, Loss: 0.42573876125176086\n",
      "Epoch 187, Loss: 0.41925407360374856\n",
      "Epoch 188, Loss: 0.4183384695092418\n",
      "Epoch 189, Loss: 0.4218813047997579\n",
      "Epoch 190, Loss: 0.4197713005325469\n",
      "Epoch 191, Loss: 0.417197451669247\n",
      "Epoch 192, Loss: 0.41998586832409235\n",
      "Epoch 193, Loss: 0.4198630180807017\n",
      "Epoch 194, Loss: 0.4146118298837611\n",
      "Epoch 195, Loss: 0.41413205840097117\n",
      "Epoch 196, Loss: 0.4155607826414292\n",
      "Epoch 197, Loss: 0.414238532452658\n",
      "Epoch 198, Loss: 0.41297339310852155\n",
      "Epoch 199, Loss: 0.4123900845056213\n",
      "Epoch 200, Loss: 0.4134311180746695\n",
      "Epoch 201, Loss: 0.4127689164145939\n",
      "Epoch 202, Loss: 0.41232720715179455\n",
      "Epoch 203, Loss: 0.41150345937125327\n",
      "Epoch 204, Loss: 0.4115020652257978\n",
      "Epoch 205, Loss: 0.411078297677327\n",
      "Epoch 206, Loss: 0.4110567108542411\n",
      "Epoch 207, Loss: 0.4114023806357039\n",
      "Epoch 208, Loss: 0.41371932293434216\n",
      "Epoch 209, Loss: 0.41813952085771794\n",
      "Epoch 210, Loss: 0.42511728996367454\n",
      "Epoch 211, Loss: 0.42635158522503447\n",
      "Epoch 212, Loss: 0.419673136297028\n",
      "Epoch 213, Loss: 0.41005224089892217\n",
      "Epoch 214, Loss: 0.4205638856971283\n",
      "Epoch 215, Loss: 0.4288454648496258\n",
      "Epoch 216, Loss: 0.416730043439161\n",
      "Epoch 217, Loss: 0.4131035226095487\n",
      "Epoch 218, Loss: 0.41919050177663497\n",
      "Epoch 219, Loss: 0.41341632229404196\n",
      "Epoch 220, Loss: 0.411337015720657\n",
      "Epoch 221, Loss: 0.4153124279254653\n",
      "Epoch 222, Loss: 0.4104582809838288\n",
      "Epoch 223, Loss: 0.4101367219181661\n",
      "Epoch 224, Loss: 0.4157081327260397\n",
      "Epoch 225, Loss: 0.4144226163660391\n",
      "Epoch 226, Loss: 0.4098329995970875\n",
      "Epoch 227, Loss: 0.40775029376666666\n",
      "Epoch 228, Loss: 0.41429755898335924\n",
      "Epoch 229, Loss: 0.41521591906294136\n",
      "Epoch 230, Loss: 0.4099844981670613\n",
      "Epoch 231, Loss: 0.4074908343553954\n",
      "Epoch 232, Loss: 0.41404155462298753\n",
      "Epoch 233, Loss: 0.41428398110821113\n",
      "Epoch 234, Loss: 0.411010796569875\n",
      "Epoch 235, Loss: 0.40626047194262166\n",
      "Epoch 236, Loss: 0.409034666887797\n",
      "Epoch 237, Loss: 0.4158159770891869\n",
      "Epoch 238, Loss: 0.4153325557817546\n",
      "Epoch 239, Loss: 0.40773651613666245\n",
      "Epoch 240, Loss: 0.40720486297242386\n",
      "Epoch 241, Loss: 0.41676379700873606\n",
      "Epoch 242, Loss: 0.4163271136351227\n",
      "Epoch 243, Loss: 0.4079038079306381\n",
      "Epoch 244, Loss: 0.41018584008428094\n",
      "Epoch 245, Loss: 0.4183221731020751\n",
      "Epoch 246, Loss: 0.4083151230189892\n",
      "Epoch 247, Loss: 0.403887555337203\n",
      "Epoch 248, Loss: 0.4087575223213056\n",
      "Epoch 249, Loss: 0.40489636999784445\n",
      "Epoch 250, Loss: 0.4028637127989142\n",
      "Epoch 251, Loss: 0.40329884617463313\n",
      "Epoch 252, Loss: 0.4063995709543235\n",
      "Epoch 253, Loss: 0.4039770141828027\n",
      "Epoch 254, Loss: 0.40232352789271325\n",
      "Epoch 255, Loss: 0.40085487433081396\n",
      "Epoch 256, Loss: 0.4013585184836403\n",
      "Epoch 257, Loss: 0.401038171909843\n",
      "Epoch 258, Loss: 0.4020229653351035\n",
      "Epoch 259, Loss: 0.4038903224025568\n",
      "Epoch 260, Loss: 0.4061704337624061\n",
      "Epoch 261, Loss: 0.40752030716947196\n",
      "Epoch 262, Loss: 0.4085568442371171\n",
      "Epoch 263, Loss: 0.40261644547833497\n",
      "Epoch 264, Loss: 0.39916727140987407\n",
      "Epoch 265, Loss: 0.39918720546249864\n",
      "Epoch 266, Loss: 0.4018616982923893\n",
      "Epoch 267, Loss: 0.40409750330247396\n",
      "Epoch 268, Loss: 0.4030983154573023\n",
      "Epoch 269, Loss: 0.40148977741823705\n",
      "Epoch 270, Loss: 0.3979682402950119\n",
      "Epoch 271, Loss: 0.39712887326045615\n",
      "Epoch 272, Loss: 0.3976166253873399\n",
      "Epoch 273, Loss: 0.3994664761725427\n",
      "Epoch 274, Loss: 0.40664772591817466\n",
      "Epoch 275, Loss: 0.4160374917744293\n",
      "Epoch 276, Loss: 0.42157817924529983\n",
      "Epoch 277, Loss: 0.3991758200300099\n",
      "Epoch 278, Loss: 0.4024471779631351\n",
      "Epoch 279, Loss: 0.4158416169220002\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22483795251196878\n",
      "Test R^2 score: 0.45117510537908373\n",
      "Num of epochs: 280\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Epoch 179, Loss: 0.42867030340024453\n",
      "Epoch 180, Loss: 0.42665902048327814\n",
      "Epoch 181, Loss: 0.4160041986606613\n",
      "Epoch 182, Loss: 0.42380692389414293\n",
      "Epoch 183, Loss: 0.4367609764525626\n",
      "Epoch 184, Loss: 0.42557170506243686\n",
      "Epoch 185, Loss: 0.42106826790053603\n",
      "Epoch 186, Loss: 0.42573876125176086\n",
      "Epoch 187, Loss: 0.41925407360374856\n",
      "Epoch 188, Loss: 0.4183384695092418\n",
      "Epoch 189, Loss: 0.4218813047997579\n",
      "Epoch 190, Loss: 0.4197713005325469\n",
      "Epoch 191, Loss: 0.417197451669247\n",
      "Epoch 192, Loss: 0.41998586832409235\n",
      "Epoch 193, Loss: 0.4198630180807017\n",
      "Epoch 194, Loss: 0.4146118298837611\n",
      "Epoch 195, Loss: 0.41413205840097117\n",
      "Epoch 196, Loss: 0.4155607826414292\n",
      "Epoch 197, Loss: 0.414238532452658\n",
      "Epoch 198, Loss: 0.41297339310852155\n",
      "Epoch 199, Loss: 0.4123900845056213\n",
      "Epoch 200, Loss: 0.4134311180746695\n",
      "Epoch 201, Loss: 0.4127689164145939\n",
      "Epoch 202, Loss: 0.41232720715179455\n",
      "Epoch 203, Loss: 0.41150345937125327\n",
      "Epoch 204, Loss: 0.4115020652257978\n",
      "Epoch 205, Loss: 0.411078297677327\n",
      "Epoch 206, Loss: 0.4110567108542411\n",
      "Epoch 207, Loss: 0.4114023806357039\n",
      "Epoch 208, Loss: 0.41371932293434216\n",
      "Epoch 209, Loss: 0.41813952085771794\n",
      "Epoch 210, Loss: 0.42511728996367454\n",
      "Epoch 211, Loss: 0.42635158522503447\n",
      "Epoch 212, Loss: 0.419673136297028\n",
      "Epoch 213, Loss: 0.41005224089892217\n",
      "Epoch 214, Loss: 0.4205638856971283\n",
      "Epoch 215, Loss: 0.4288454648496258\n",
      "Epoch 216, Loss: 0.416730043439161\n",
      "Epoch 217, Loss: 0.4131035226095487\n",
      "Epoch 218, Loss: 0.41919050177663497\n",
      "Epoch 219, Loss: 0.41341632229404196\n",
      "Epoch 220, Loss: 0.411337015720657\n",
      "Epoch 221, Loss: 0.4153124279254653\n",
      "Epoch 222, Loss: 0.4104582809838288\n",
      "Epoch 223, Loss: 0.4101367219181661\n",
      "Epoch 224, Loss: 0.4157081327260397\n",
      "Epoch 225, Loss: 0.4144226163660391\n",
      "Epoch 226, Loss: 0.4098329995970875\n",
      "Epoch 227, Loss: 0.40775029376666666\n",
      "Epoch 228, Loss: 0.41429755898335924\n",
      "Epoch 229, Loss: 0.41521591906294136\n",
      "Epoch 230, Loss: 0.4099844981670613\n",
      "Epoch 231, Loss: 0.4074908343553954\n",
      "Epoch 232, Loss: 0.41404155462298753\n",
      "Epoch 233, Loss: 0.41428398110821113\n",
      "Epoch 234, Loss: 0.411010796569875\n",
      "Epoch 235, Loss: 0.40626047194262166\n",
      "Epoch 236, Loss: 0.409034666887797\n",
      "Epoch 237, Loss: 0.4158159770891869\n",
      "Epoch 238, Loss: 0.4153325557817546\n",
      "Epoch 239, Loss: 0.40773651613666245\n",
      "Epoch 240, Loss: 0.40720486297242386\n",
      "Epoch 241, Loss: 0.41676379700873606\n",
      "Epoch 242, Loss: 0.4163271136351227\n",
      "Epoch 243, Loss: 0.4079038079306381\n",
      "Epoch 244, Loss: 0.41018584008428094\n",
      "Epoch 245, Loss: 0.4183221731020751\n",
      "Epoch 246, Loss: 0.4083151230189892\n",
      "Epoch 247, Loss: 0.403887555337203\n",
      "Epoch 248, Loss: 0.4087575223213056\n",
      "Epoch 249, Loss: 0.40489636999784445\n",
      "Epoch 250, Loss: 0.4028637127989142\n",
      "Epoch 251, Loss: 0.40329884617463313\n",
      "Epoch 252, Loss: 0.4063995709543235\n",
      "Epoch 253, Loss: 0.4039770141828027\n",
      "Epoch 254, Loss: 0.40232352789271325\n",
      "Epoch 255, Loss: 0.40085487433081396\n",
      "Epoch 256, Loss: 0.4013585184836403\n",
      "Epoch 257, Loss: 0.401038171909843\n",
      "Epoch 258, Loss: 0.4020229653351035\n",
      "Epoch 259, Loss: 0.4038903224025568\n",
      "Epoch 260, Loss: 0.4061704337624061\n",
      "Epoch 261, Loss: 0.40752030716947196\n",
      "Epoch 262, Loss: 0.4085568442371171\n",
      "Epoch 263, Loss: 0.40261644547833497\n",
      "Epoch 264, Loss: 0.39916727140987407\n",
      "Epoch 265, Loss: 0.39918720546249864\n",
      "Epoch 266, Loss: 0.4018616982923893\n",
      "Epoch 267, Loss: 0.40409750330247396\n",
      "Epoch 268, Loss: 0.4030983154573023\n",
      "Epoch 269, Loss: 0.40148977741823705\n",
      "Epoch 270, Loss: 0.3979682402950119\n",
      "Epoch 271, Loss: 0.39712887326045615\n",
      "Epoch 272, Loss: 0.3976166253873399\n",
      "Epoch 273, Loss: 0.3994664761725427\n",
      "Epoch 274, Loss: 0.40664772591817466\n",
      "Epoch 275, Loss: 0.4160374917744293\n",
      "Epoch 276, Loss: 0.42157817924529983\n",
      "Epoch 277, Loss: 0.3991758200300099\n",
      "Epoch 278, Loss: 0.4024471779631351\n",
      "Epoch 279, Loss: 0.4158416169220002\n",
      "Epoch 280, Loss: 0.4109940102017761\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22492721350001238\n",
      "Test R^2 score: 0.45201156265290465\n",
      "Num of epochs: 281\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Epoch 179, Loss: 0.42867030340024453\n",
      "Epoch 180, Loss: 0.42665902048327814\n",
      "Epoch 181, Loss: 0.4160041986606613\n",
      "Epoch 182, Loss: 0.42380692389414293\n",
      "Epoch 183, Loss: 0.4367609764525626\n",
      "Epoch 184, Loss: 0.42557170506243686\n",
      "Epoch 185, Loss: 0.42106826790053603\n",
      "Epoch 186, Loss: 0.42573876125176086\n",
      "Epoch 187, Loss: 0.41925407360374856\n",
      "Epoch 188, Loss: 0.4183384695092418\n",
      "Epoch 189, Loss: 0.4218813047997579\n",
      "Epoch 190, Loss: 0.4197713005325469\n",
      "Epoch 191, Loss: 0.417197451669247\n",
      "Epoch 192, Loss: 0.41998586832409235\n",
      "Epoch 193, Loss: 0.4198630180807017\n",
      "Epoch 194, Loss: 0.4146118298837611\n",
      "Epoch 195, Loss: 0.41413205840097117\n",
      "Epoch 196, Loss: 0.4155607826414292\n",
      "Epoch 197, Loss: 0.414238532452658\n",
      "Epoch 198, Loss: 0.41297339310852155\n",
      "Epoch 199, Loss: 0.4123900845056213\n",
      "Epoch 200, Loss: 0.4134311180746695\n",
      "Epoch 201, Loss: 0.4127689164145939\n",
      "Epoch 202, Loss: 0.41232720715179455\n",
      "Epoch 203, Loss: 0.41150345937125327\n",
      "Epoch 204, Loss: 0.4115020652257978\n",
      "Epoch 205, Loss: 0.411078297677327\n",
      "Epoch 206, Loss: 0.4110567108542411\n",
      "Epoch 207, Loss: 0.4114023806357039\n",
      "Epoch 208, Loss: 0.41371932293434216\n",
      "Epoch 209, Loss: 0.41813952085771794\n",
      "Epoch 210, Loss: 0.42511728996367454\n",
      "Epoch 211, Loss: 0.42635158522503447\n",
      "Epoch 212, Loss: 0.419673136297028\n",
      "Epoch 213, Loss: 0.41005224089892217\n",
      "Epoch 214, Loss: 0.4205638856971283\n",
      "Epoch 215, Loss: 0.4288454648496258\n",
      "Epoch 216, Loss: 0.416730043439161\n",
      "Epoch 217, Loss: 0.4131035226095487\n",
      "Epoch 218, Loss: 0.41919050177663497\n",
      "Epoch 219, Loss: 0.41341632229404196\n",
      "Epoch 220, Loss: 0.411337015720657\n",
      "Epoch 221, Loss: 0.4153124279254653\n",
      "Epoch 222, Loss: 0.4104582809838288\n",
      "Epoch 223, Loss: 0.4101367219181661\n",
      "Epoch 224, Loss: 0.4157081327260397\n",
      "Epoch 225, Loss: 0.4144226163660391\n",
      "Epoch 226, Loss: 0.4098329995970875\n",
      "Epoch 227, Loss: 0.40775029376666666\n",
      "Epoch 228, Loss: 0.41429755898335924\n",
      "Epoch 229, Loss: 0.41521591906294136\n",
      "Epoch 230, Loss: 0.4099844981670613\n",
      "Epoch 231, Loss: 0.4074908343553954\n",
      "Epoch 232, Loss: 0.41404155462298753\n",
      "Epoch 233, Loss: 0.41428398110821113\n",
      "Epoch 234, Loss: 0.411010796569875\n",
      "Epoch 235, Loss: 0.40626047194262166\n",
      "Epoch 236, Loss: 0.409034666887797\n",
      "Epoch 237, Loss: 0.4158159770891869\n",
      "Epoch 238, Loss: 0.4153325557817546\n",
      "Epoch 239, Loss: 0.40773651613666245\n",
      "Epoch 240, Loss: 0.40720486297242386\n",
      "Epoch 241, Loss: 0.41676379700873606\n",
      "Epoch 242, Loss: 0.4163271136351227\n",
      "Epoch 243, Loss: 0.4079038079306381\n",
      "Epoch 244, Loss: 0.41018584008428094\n",
      "Epoch 245, Loss: 0.4183221731020751\n",
      "Epoch 246, Loss: 0.4083151230189892\n",
      "Epoch 247, Loss: 0.403887555337203\n",
      "Epoch 248, Loss: 0.4087575223213056\n",
      "Epoch 249, Loss: 0.40489636999784445\n",
      "Epoch 250, Loss: 0.4028637127989142\n",
      "Epoch 251, Loss: 0.40329884617463313\n",
      "Epoch 252, Loss: 0.4063995709543235\n",
      "Epoch 253, Loss: 0.4039770141828027\n",
      "Epoch 254, Loss: 0.40232352789271325\n",
      "Epoch 255, Loss: 0.40085487433081396\n",
      "Epoch 256, Loss: 0.4013585184836403\n",
      "Epoch 257, Loss: 0.401038171909843\n",
      "Epoch 258, Loss: 0.4020229653351035\n",
      "Epoch 259, Loss: 0.4038903224025568\n",
      "Epoch 260, Loss: 0.4061704337624061\n",
      "Epoch 261, Loss: 0.40752030716947196\n",
      "Epoch 262, Loss: 0.4085568442371171\n",
      "Epoch 263, Loss: 0.40261644547833497\n",
      "Epoch 264, Loss: 0.39916727140987407\n",
      "Epoch 265, Loss: 0.39918720546249864\n",
      "Epoch 266, Loss: 0.4018616982923893\n",
      "Epoch 267, Loss: 0.40409750330247396\n",
      "Epoch 268, Loss: 0.4030983154573023\n",
      "Epoch 269, Loss: 0.40148977741823705\n",
      "Epoch 270, Loss: 0.3979682402950119\n",
      "Epoch 271, Loss: 0.39712887326045615\n",
      "Epoch 272, Loss: 0.3976166253873399\n",
      "Epoch 273, Loss: 0.3994664761725427\n",
      "Epoch 274, Loss: 0.40664772591817466\n",
      "Epoch 275, Loss: 0.4160374917744293\n",
      "Epoch 276, Loss: 0.42157817924529983\n",
      "Epoch 277, Loss: 0.3991758200300099\n",
      "Epoch 278, Loss: 0.4024471779631351\n",
      "Epoch 279, Loss: 0.4158416169220002\n",
      "Epoch 280, Loss: 0.4109940102017761\n",
      "Epoch 281, Loss: 0.40367779348858235\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2409915105123667\n",
      "Test R^2 score: 0.36996768756012766\n",
      "Num of epochs: 282\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Epoch 179, Loss: 0.42867030340024453\n",
      "Epoch 180, Loss: 0.42665902048327814\n",
      "Epoch 181, Loss: 0.4160041986606613\n",
      "Epoch 182, Loss: 0.42380692389414293\n",
      "Epoch 183, Loss: 0.4367609764525626\n",
      "Epoch 184, Loss: 0.42557170506243686\n",
      "Epoch 185, Loss: 0.42106826790053603\n",
      "Epoch 186, Loss: 0.42573876125176086\n",
      "Epoch 187, Loss: 0.41925407360374856\n",
      "Epoch 188, Loss: 0.4183384695092418\n",
      "Epoch 189, Loss: 0.4218813047997579\n",
      "Epoch 190, Loss: 0.4197713005325469\n",
      "Epoch 191, Loss: 0.417197451669247\n",
      "Epoch 192, Loss: 0.41998586832409235\n",
      "Epoch 193, Loss: 0.4198630180807017\n",
      "Epoch 194, Loss: 0.4146118298837611\n",
      "Epoch 195, Loss: 0.41413205840097117\n",
      "Epoch 196, Loss: 0.4155607826414292\n",
      "Epoch 197, Loss: 0.414238532452658\n",
      "Epoch 198, Loss: 0.41297339310852155\n",
      "Epoch 199, Loss: 0.4123900845056213\n",
      "Epoch 200, Loss: 0.4134311180746695\n",
      "Epoch 201, Loss: 0.4127689164145939\n",
      "Epoch 202, Loss: 0.41232720715179455\n",
      "Epoch 203, Loss: 0.41150345937125327\n",
      "Epoch 204, Loss: 0.4115020652257978\n",
      "Epoch 205, Loss: 0.411078297677327\n",
      "Epoch 206, Loss: 0.4110567108542411\n",
      "Epoch 207, Loss: 0.4114023806357039\n",
      "Epoch 208, Loss: 0.41371932293434216\n",
      "Epoch 209, Loss: 0.41813952085771794\n",
      "Epoch 210, Loss: 0.42511728996367454\n",
      "Epoch 211, Loss: 0.42635158522503447\n",
      "Epoch 212, Loss: 0.419673136297028\n",
      "Epoch 213, Loss: 0.41005224089892217\n",
      "Epoch 214, Loss: 0.4205638856971283\n",
      "Epoch 215, Loss: 0.4288454648496258\n",
      "Epoch 216, Loss: 0.416730043439161\n",
      "Epoch 217, Loss: 0.4131035226095487\n",
      "Epoch 218, Loss: 0.41919050177663497\n",
      "Epoch 219, Loss: 0.41341632229404196\n",
      "Epoch 220, Loss: 0.411337015720657\n",
      "Epoch 221, Loss: 0.4153124279254653\n",
      "Epoch 222, Loss: 0.4104582809838288\n",
      "Epoch 223, Loss: 0.4101367219181661\n",
      "Epoch 224, Loss: 0.4157081327260397\n",
      "Epoch 225, Loss: 0.4144226163660391\n",
      "Epoch 226, Loss: 0.4098329995970875\n",
      "Epoch 227, Loss: 0.40775029376666666\n",
      "Epoch 228, Loss: 0.41429755898335924\n",
      "Epoch 229, Loss: 0.41521591906294136\n",
      "Epoch 230, Loss: 0.4099844981670613\n",
      "Epoch 231, Loss: 0.4074908343553954\n",
      "Epoch 232, Loss: 0.41404155462298753\n",
      "Epoch 233, Loss: 0.41428398110821113\n",
      "Epoch 234, Loss: 0.411010796569875\n",
      "Epoch 235, Loss: 0.40626047194262166\n",
      "Epoch 236, Loss: 0.409034666887797\n",
      "Epoch 237, Loss: 0.4158159770891869\n",
      "Epoch 238, Loss: 0.4153325557817546\n",
      "Epoch 239, Loss: 0.40773651613666245\n",
      "Epoch 240, Loss: 0.40720486297242386\n",
      "Epoch 241, Loss: 0.41676379700873606\n",
      "Epoch 242, Loss: 0.4163271136351227\n",
      "Epoch 243, Loss: 0.4079038079306381\n",
      "Epoch 244, Loss: 0.41018584008428094\n",
      "Epoch 245, Loss: 0.4183221731020751\n",
      "Epoch 246, Loss: 0.4083151230189892\n",
      "Epoch 247, Loss: 0.403887555337203\n",
      "Epoch 248, Loss: 0.4087575223213056\n",
      "Epoch 249, Loss: 0.40489636999784445\n",
      "Epoch 250, Loss: 0.4028637127989142\n",
      "Epoch 251, Loss: 0.40329884617463313\n",
      "Epoch 252, Loss: 0.4063995709543235\n",
      "Epoch 253, Loss: 0.4039770141828027\n",
      "Epoch 254, Loss: 0.40232352789271325\n",
      "Epoch 255, Loss: 0.40085487433081396\n",
      "Epoch 256, Loss: 0.4013585184836403\n",
      "Epoch 257, Loss: 0.401038171909843\n",
      "Epoch 258, Loss: 0.4020229653351035\n",
      "Epoch 259, Loss: 0.4038903224025568\n",
      "Epoch 260, Loss: 0.4061704337624061\n",
      "Epoch 261, Loss: 0.40752030716947196\n",
      "Epoch 262, Loss: 0.4085568442371171\n",
      "Epoch 263, Loss: 0.40261644547833497\n",
      "Epoch 264, Loss: 0.39916727140987407\n",
      "Epoch 265, Loss: 0.39918720546249864\n",
      "Epoch 266, Loss: 0.4018616982923893\n",
      "Epoch 267, Loss: 0.40409750330247396\n",
      "Epoch 268, Loss: 0.4030983154573023\n",
      "Epoch 269, Loss: 0.40148977741823705\n",
      "Epoch 270, Loss: 0.3979682402950119\n",
      "Epoch 271, Loss: 0.39712887326045615\n",
      "Epoch 272, Loss: 0.3976166253873399\n",
      "Epoch 273, Loss: 0.3994664761725427\n",
      "Epoch 274, Loss: 0.40664772591817466\n",
      "Epoch 275, Loss: 0.4160374917744293\n",
      "Epoch 276, Loss: 0.42157817924529983\n",
      "Epoch 277, Loss: 0.3991758200300099\n",
      "Epoch 278, Loss: 0.4024471779631351\n",
      "Epoch 279, Loss: 0.4158416169220002\n",
      "Epoch 280, Loss: 0.4109940102017761\n",
      "Epoch 281, Loss: 0.40367779348858235\n",
      "Epoch 282, Loss: 0.4169002494142847\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21721753688353432\n",
      "Test R^2 score: 0.4880895391379951\n",
      "Num of epochs: 283\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Epoch 179, Loss: 0.42867030340024453\n",
      "Epoch 180, Loss: 0.42665902048327814\n",
      "Epoch 181, Loss: 0.4160041986606613\n",
      "Epoch 182, Loss: 0.42380692389414293\n",
      "Epoch 183, Loss: 0.4367609764525626\n",
      "Epoch 184, Loss: 0.42557170506243686\n",
      "Epoch 185, Loss: 0.42106826790053603\n",
      "Epoch 186, Loss: 0.42573876125176086\n",
      "Epoch 187, Loss: 0.41925407360374856\n",
      "Epoch 188, Loss: 0.4183384695092418\n",
      "Epoch 189, Loss: 0.4218813047997579\n",
      "Epoch 190, Loss: 0.4197713005325469\n",
      "Epoch 191, Loss: 0.417197451669247\n",
      "Epoch 192, Loss: 0.41998586832409235\n",
      "Epoch 193, Loss: 0.4198630180807017\n",
      "Epoch 194, Loss: 0.4146118298837611\n",
      "Epoch 195, Loss: 0.41413205840097117\n",
      "Epoch 196, Loss: 0.4155607826414292\n",
      "Epoch 197, Loss: 0.414238532452658\n",
      "Epoch 198, Loss: 0.41297339310852155\n",
      "Epoch 199, Loss: 0.4123900845056213\n",
      "Epoch 200, Loss: 0.4134311180746695\n",
      "Epoch 201, Loss: 0.4127689164145939\n",
      "Epoch 202, Loss: 0.41232720715179455\n",
      "Epoch 203, Loss: 0.41150345937125327\n",
      "Epoch 204, Loss: 0.4115020652257978\n",
      "Epoch 205, Loss: 0.411078297677327\n",
      "Epoch 206, Loss: 0.4110567108542411\n",
      "Epoch 207, Loss: 0.4114023806357039\n",
      "Epoch 208, Loss: 0.41371932293434216\n",
      "Epoch 209, Loss: 0.41813952085771794\n",
      "Epoch 210, Loss: 0.42511728996367454\n",
      "Epoch 211, Loss: 0.42635158522503447\n",
      "Epoch 212, Loss: 0.419673136297028\n",
      "Epoch 213, Loss: 0.41005224089892217\n",
      "Epoch 214, Loss: 0.4205638856971283\n",
      "Epoch 215, Loss: 0.4288454648496258\n",
      "Epoch 216, Loss: 0.416730043439161\n",
      "Epoch 217, Loss: 0.4131035226095487\n",
      "Epoch 218, Loss: 0.41919050177663497\n",
      "Epoch 219, Loss: 0.41341632229404196\n",
      "Epoch 220, Loss: 0.411337015720657\n",
      "Epoch 221, Loss: 0.4153124279254653\n",
      "Epoch 222, Loss: 0.4104582809838288\n",
      "Epoch 223, Loss: 0.4101367219181661\n",
      "Epoch 224, Loss: 0.4157081327260397\n",
      "Epoch 225, Loss: 0.4144226163660391\n",
      "Epoch 226, Loss: 0.4098329995970875\n",
      "Epoch 227, Loss: 0.40775029376666666\n",
      "Epoch 228, Loss: 0.41429755898335924\n",
      "Epoch 229, Loss: 0.41521591906294136\n",
      "Epoch 230, Loss: 0.4099844981670613\n",
      "Epoch 231, Loss: 0.4074908343553954\n",
      "Epoch 232, Loss: 0.41404155462298753\n",
      "Epoch 233, Loss: 0.41428398110821113\n",
      "Epoch 234, Loss: 0.411010796569875\n",
      "Epoch 235, Loss: 0.40626047194262166\n",
      "Epoch 236, Loss: 0.409034666887797\n",
      "Epoch 237, Loss: 0.4158159770891869\n",
      "Epoch 238, Loss: 0.4153325557817546\n",
      "Epoch 239, Loss: 0.40773651613666245\n",
      "Epoch 240, Loss: 0.40720486297242386\n",
      "Epoch 241, Loss: 0.41676379700873606\n",
      "Epoch 242, Loss: 0.4163271136351227\n",
      "Epoch 243, Loss: 0.4079038079306381\n",
      "Epoch 244, Loss: 0.41018584008428094\n",
      "Epoch 245, Loss: 0.4183221731020751\n",
      "Epoch 246, Loss: 0.4083151230189892\n",
      "Epoch 247, Loss: 0.403887555337203\n",
      "Epoch 248, Loss: 0.4087575223213056\n",
      "Epoch 249, Loss: 0.40489636999784445\n",
      "Epoch 250, Loss: 0.4028637127989142\n",
      "Epoch 251, Loss: 0.40329884617463313\n",
      "Epoch 252, Loss: 0.4063995709543235\n",
      "Epoch 253, Loss: 0.4039770141828027\n",
      "Epoch 254, Loss: 0.40232352789271325\n",
      "Epoch 255, Loss: 0.40085487433081396\n",
      "Epoch 256, Loss: 0.4013585184836403\n",
      "Epoch 257, Loss: 0.401038171909843\n",
      "Epoch 258, Loss: 0.4020229653351035\n",
      "Epoch 259, Loss: 0.4038903224025568\n",
      "Epoch 260, Loss: 0.4061704337624061\n",
      "Epoch 261, Loss: 0.40752030716947196\n",
      "Epoch 262, Loss: 0.4085568442371171\n",
      "Epoch 263, Loss: 0.40261644547833497\n",
      "Epoch 264, Loss: 0.39916727140987407\n",
      "Epoch 265, Loss: 0.39918720546249864\n",
      "Epoch 266, Loss: 0.4018616982923893\n",
      "Epoch 267, Loss: 0.40409750330247396\n",
      "Epoch 268, Loss: 0.4030983154573023\n",
      "Epoch 269, Loss: 0.40148977741823705\n",
      "Epoch 270, Loss: 0.3979682402950119\n",
      "Epoch 271, Loss: 0.39712887326045615\n",
      "Epoch 272, Loss: 0.3976166253873399\n",
      "Epoch 273, Loss: 0.3994664761725427\n",
      "Epoch 274, Loss: 0.40664772591817466\n",
      "Epoch 275, Loss: 0.4160374917744293\n",
      "Epoch 276, Loss: 0.42157817924529983\n",
      "Epoch 277, Loss: 0.3991758200300099\n",
      "Epoch 278, Loss: 0.4024471779631351\n",
      "Epoch 279, Loss: 0.4158416169220002\n",
      "Epoch 280, Loss: 0.4109940102017761\n",
      "Epoch 281, Loss: 0.40367779348858235\n",
      "Epoch 282, Loss: 0.4169002494142847\n",
      "Epoch 283, Loss: 0.4040475896870828\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.21719709780249274\n",
      "Test R^2 score: 0.487410861793256\n",
      "Num of epochs: 284\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Epoch 179, Loss: 0.42867030340024453\n",
      "Epoch 180, Loss: 0.42665902048327814\n",
      "Epoch 181, Loss: 0.4160041986606613\n",
      "Epoch 182, Loss: 0.42380692389414293\n",
      "Epoch 183, Loss: 0.4367609764525626\n",
      "Epoch 184, Loss: 0.42557170506243686\n",
      "Epoch 185, Loss: 0.42106826790053603\n",
      "Epoch 186, Loss: 0.42573876125176086\n",
      "Epoch 187, Loss: 0.41925407360374856\n",
      "Epoch 188, Loss: 0.4183384695092418\n",
      "Epoch 189, Loss: 0.4218813047997579\n",
      "Epoch 190, Loss: 0.4197713005325469\n",
      "Epoch 191, Loss: 0.417197451669247\n",
      "Epoch 192, Loss: 0.41998586832409235\n",
      "Epoch 193, Loss: 0.4198630180807017\n",
      "Epoch 194, Loss: 0.4146118298837611\n",
      "Epoch 195, Loss: 0.41413205840097117\n",
      "Epoch 196, Loss: 0.4155607826414292\n",
      "Epoch 197, Loss: 0.414238532452658\n",
      "Epoch 198, Loss: 0.41297339310852155\n",
      "Epoch 199, Loss: 0.4123900845056213\n",
      "Epoch 200, Loss: 0.4134311180746695\n",
      "Epoch 201, Loss: 0.4127689164145939\n",
      "Epoch 202, Loss: 0.41232720715179455\n",
      "Epoch 203, Loss: 0.41150345937125327\n",
      "Epoch 204, Loss: 0.4115020652257978\n",
      "Epoch 205, Loss: 0.411078297677327\n",
      "Epoch 206, Loss: 0.4110567108542411\n",
      "Epoch 207, Loss: 0.4114023806357039\n",
      "Epoch 208, Loss: 0.41371932293434216\n",
      "Epoch 209, Loss: 0.41813952085771794\n",
      "Epoch 210, Loss: 0.42511728996367454\n",
      "Epoch 211, Loss: 0.42635158522503447\n",
      "Epoch 212, Loss: 0.419673136297028\n",
      "Epoch 213, Loss: 0.41005224089892217\n",
      "Epoch 214, Loss: 0.4205638856971283\n",
      "Epoch 215, Loss: 0.4288454648496258\n",
      "Epoch 216, Loss: 0.416730043439161\n",
      "Epoch 217, Loss: 0.4131035226095487\n",
      "Epoch 218, Loss: 0.41919050177663497\n",
      "Epoch 219, Loss: 0.41341632229404196\n",
      "Epoch 220, Loss: 0.411337015720657\n",
      "Epoch 221, Loss: 0.4153124279254653\n",
      "Epoch 222, Loss: 0.4104582809838288\n",
      "Epoch 223, Loss: 0.4101367219181661\n",
      "Epoch 224, Loss: 0.4157081327260397\n",
      "Epoch 225, Loss: 0.4144226163660391\n",
      "Epoch 226, Loss: 0.4098329995970875\n",
      "Epoch 227, Loss: 0.40775029376666666\n",
      "Epoch 228, Loss: 0.41429755898335924\n",
      "Epoch 229, Loss: 0.41521591906294136\n",
      "Epoch 230, Loss: 0.4099844981670613\n",
      "Epoch 231, Loss: 0.4074908343553954\n",
      "Epoch 232, Loss: 0.41404155462298753\n",
      "Epoch 233, Loss: 0.41428398110821113\n",
      "Epoch 234, Loss: 0.411010796569875\n",
      "Epoch 235, Loss: 0.40626047194262166\n",
      "Epoch 236, Loss: 0.409034666887797\n",
      "Epoch 237, Loss: 0.4158159770891869\n",
      "Epoch 238, Loss: 0.4153325557817546\n",
      "Epoch 239, Loss: 0.40773651613666245\n",
      "Epoch 240, Loss: 0.40720486297242386\n",
      "Epoch 241, Loss: 0.41676379700873606\n",
      "Epoch 242, Loss: 0.4163271136351227\n",
      "Epoch 243, Loss: 0.4079038079306381\n",
      "Epoch 244, Loss: 0.41018584008428094\n",
      "Epoch 245, Loss: 0.4183221731020751\n",
      "Epoch 246, Loss: 0.4083151230189892\n",
      "Epoch 247, Loss: 0.403887555337203\n",
      "Epoch 248, Loss: 0.4087575223213056\n",
      "Epoch 249, Loss: 0.40489636999784445\n",
      "Epoch 250, Loss: 0.4028637127989142\n",
      "Epoch 251, Loss: 0.40329884617463313\n",
      "Epoch 252, Loss: 0.4063995709543235\n",
      "Epoch 253, Loss: 0.4039770141828027\n",
      "Epoch 254, Loss: 0.40232352789271325\n",
      "Epoch 255, Loss: 0.40085487433081396\n",
      "Epoch 256, Loss: 0.4013585184836403\n",
      "Epoch 257, Loss: 0.401038171909843\n",
      "Epoch 258, Loss: 0.4020229653351035\n",
      "Epoch 259, Loss: 0.4038903224025568\n",
      "Epoch 260, Loss: 0.4061704337624061\n",
      "Epoch 261, Loss: 0.40752030716947196\n",
      "Epoch 262, Loss: 0.4085568442371171\n",
      "Epoch 263, Loss: 0.40261644547833497\n",
      "Epoch 264, Loss: 0.39916727140987407\n",
      "Epoch 265, Loss: 0.39918720546249864\n",
      "Epoch 266, Loss: 0.4018616982923893\n",
      "Epoch 267, Loss: 0.40409750330247396\n",
      "Epoch 268, Loss: 0.4030983154573023\n",
      "Epoch 269, Loss: 0.40148977741823705\n",
      "Epoch 270, Loss: 0.3979682402950119\n",
      "Epoch 271, Loss: 0.39712887326045615\n",
      "Epoch 272, Loss: 0.3976166253873399\n",
      "Epoch 273, Loss: 0.3994664761725427\n",
      "Epoch 274, Loss: 0.40664772591817466\n",
      "Epoch 275, Loss: 0.4160374917744293\n",
      "Epoch 276, Loss: 0.42157817924529983\n",
      "Epoch 277, Loss: 0.3991758200300099\n",
      "Epoch 278, Loss: 0.4024471779631351\n",
      "Epoch 279, Loss: 0.4158416169220002\n",
      "Epoch 280, Loss: 0.4109940102017761\n",
      "Epoch 281, Loss: 0.40367779348858235\n",
      "Epoch 282, Loss: 0.4169002494142847\n",
      "Epoch 283, Loss: 0.4040475896870828\n",
      "Epoch 284, Loss: 0.4088327762653357\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22356365148185606\n",
      "Test R^2 score: 0.457603279014072\n",
      "Num of epochs: 285\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Epoch 179, Loss: 0.42867030340024453\n",
      "Epoch 180, Loss: 0.42665902048327814\n",
      "Epoch 181, Loss: 0.4160041986606613\n",
      "Epoch 182, Loss: 0.42380692389414293\n",
      "Epoch 183, Loss: 0.4367609764525626\n",
      "Epoch 184, Loss: 0.42557170506243686\n",
      "Epoch 185, Loss: 0.42106826790053603\n",
      "Epoch 186, Loss: 0.42573876125176086\n",
      "Epoch 187, Loss: 0.41925407360374856\n",
      "Epoch 188, Loss: 0.4183384695092418\n",
      "Epoch 189, Loss: 0.4218813047997579\n",
      "Epoch 190, Loss: 0.4197713005325469\n",
      "Epoch 191, Loss: 0.417197451669247\n",
      "Epoch 192, Loss: 0.41998586832409235\n",
      "Epoch 193, Loss: 0.4198630180807017\n",
      "Epoch 194, Loss: 0.4146118298837611\n",
      "Epoch 195, Loss: 0.41413205840097117\n",
      "Epoch 196, Loss: 0.4155607826414292\n",
      "Epoch 197, Loss: 0.414238532452658\n",
      "Epoch 198, Loss: 0.41297339310852155\n",
      "Epoch 199, Loss: 0.4123900845056213\n",
      "Epoch 200, Loss: 0.4134311180746695\n",
      "Epoch 201, Loss: 0.4127689164145939\n",
      "Epoch 202, Loss: 0.41232720715179455\n",
      "Epoch 203, Loss: 0.41150345937125327\n",
      "Epoch 204, Loss: 0.4115020652257978\n",
      "Epoch 205, Loss: 0.411078297677327\n",
      "Epoch 206, Loss: 0.4110567108542411\n",
      "Epoch 207, Loss: 0.4114023806357039\n",
      "Epoch 208, Loss: 0.41371932293434216\n",
      "Epoch 209, Loss: 0.41813952085771794\n",
      "Epoch 210, Loss: 0.42511728996367454\n",
      "Epoch 211, Loss: 0.42635158522503447\n",
      "Epoch 212, Loss: 0.419673136297028\n",
      "Epoch 213, Loss: 0.41005224089892217\n",
      "Epoch 214, Loss: 0.4205638856971283\n",
      "Epoch 215, Loss: 0.4288454648496258\n",
      "Epoch 216, Loss: 0.416730043439161\n",
      "Epoch 217, Loss: 0.4131035226095487\n",
      "Epoch 218, Loss: 0.41919050177663497\n",
      "Epoch 219, Loss: 0.41341632229404196\n",
      "Epoch 220, Loss: 0.411337015720657\n",
      "Epoch 221, Loss: 0.4153124279254653\n",
      "Epoch 222, Loss: 0.4104582809838288\n",
      "Epoch 223, Loss: 0.4101367219181661\n",
      "Epoch 224, Loss: 0.4157081327260397\n",
      "Epoch 225, Loss: 0.4144226163660391\n",
      "Epoch 226, Loss: 0.4098329995970875\n",
      "Epoch 227, Loss: 0.40775029376666666\n",
      "Epoch 228, Loss: 0.41429755898335924\n",
      "Epoch 229, Loss: 0.41521591906294136\n",
      "Epoch 230, Loss: 0.4099844981670613\n",
      "Epoch 231, Loss: 0.4074908343553954\n",
      "Epoch 232, Loss: 0.41404155462298753\n",
      "Epoch 233, Loss: 0.41428398110821113\n",
      "Epoch 234, Loss: 0.411010796569875\n",
      "Epoch 235, Loss: 0.40626047194262166\n",
      "Epoch 236, Loss: 0.409034666887797\n",
      "Epoch 237, Loss: 0.4158159770891869\n",
      "Epoch 238, Loss: 0.4153325557817546\n",
      "Epoch 239, Loss: 0.40773651613666245\n",
      "Epoch 240, Loss: 0.40720486297242386\n",
      "Epoch 241, Loss: 0.41676379700873606\n",
      "Epoch 242, Loss: 0.4163271136351227\n",
      "Epoch 243, Loss: 0.4079038079306381\n",
      "Epoch 244, Loss: 0.41018584008428094\n",
      "Epoch 245, Loss: 0.4183221731020751\n",
      "Epoch 246, Loss: 0.4083151230189892\n",
      "Epoch 247, Loss: 0.403887555337203\n",
      "Epoch 248, Loss: 0.4087575223213056\n",
      "Epoch 249, Loss: 0.40489636999784445\n",
      "Epoch 250, Loss: 0.4028637127989142\n",
      "Epoch 251, Loss: 0.40329884617463313\n",
      "Epoch 252, Loss: 0.4063995709543235\n",
      "Epoch 253, Loss: 0.4039770141828027\n",
      "Epoch 254, Loss: 0.40232352789271325\n",
      "Epoch 255, Loss: 0.40085487433081396\n",
      "Epoch 256, Loss: 0.4013585184836403\n",
      "Epoch 257, Loss: 0.401038171909843\n",
      "Epoch 258, Loss: 0.4020229653351035\n",
      "Epoch 259, Loss: 0.4038903224025568\n",
      "Epoch 260, Loss: 0.4061704337624061\n",
      "Epoch 261, Loss: 0.40752030716947196\n",
      "Epoch 262, Loss: 0.4085568442371171\n",
      "Epoch 263, Loss: 0.40261644547833497\n",
      "Epoch 264, Loss: 0.39916727140987407\n",
      "Epoch 265, Loss: 0.39918720546249864\n",
      "Epoch 266, Loss: 0.4018616982923893\n",
      "Epoch 267, Loss: 0.40409750330247396\n",
      "Epoch 268, Loss: 0.4030983154573023\n",
      "Epoch 269, Loss: 0.40148977741823705\n",
      "Epoch 270, Loss: 0.3979682402950119\n",
      "Epoch 271, Loss: 0.39712887326045615\n",
      "Epoch 272, Loss: 0.3976166253873399\n",
      "Epoch 273, Loss: 0.3994664761725427\n",
      "Epoch 274, Loss: 0.40664772591817466\n",
      "Epoch 275, Loss: 0.4160374917744293\n",
      "Epoch 276, Loss: 0.42157817924529983\n",
      "Epoch 277, Loss: 0.3991758200300099\n",
      "Epoch 278, Loss: 0.4024471779631351\n",
      "Epoch 279, Loss: 0.4158416169220002\n",
      "Epoch 280, Loss: 0.4109940102017761\n",
      "Epoch 281, Loss: 0.40367779348858235\n",
      "Epoch 282, Loss: 0.4169002494142847\n",
      "Epoch 283, Loss: 0.4040475896870828\n",
      "Epoch 284, Loss: 0.4088327762653357\n",
      "Epoch 285, Loss: 0.407029797337259\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22488422171922953\n",
      "Test R^2 score: 0.4525744015471474\n",
      "Num of epochs: 286\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Epoch 179, Loss: 0.42867030340024453\n",
      "Epoch 180, Loss: 0.42665902048327814\n",
      "Epoch 181, Loss: 0.4160041986606613\n",
      "Epoch 182, Loss: 0.42380692389414293\n",
      "Epoch 183, Loss: 0.4367609764525626\n",
      "Epoch 184, Loss: 0.42557170506243686\n",
      "Epoch 185, Loss: 0.42106826790053603\n",
      "Epoch 186, Loss: 0.42573876125176086\n",
      "Epoch 187, Loss: 0.41925407360374856\n",
      "Epoch 188, Loss: 0.4183384695092418\n",
      "Epoch 189, Loss: 0.4218813047997579\n",
      "Epoch 190, Loss: 0.4197713005325469\n",
      "Epoch 191, Loss: 0.417197451669247\n",
      "Epoch 192, Loss: 0.41998586832409235\n",
      "Epoch 193, Loss: 0.4198630180807017\n",
      "Epoch 194, Loss: 0.4146118298837611\n",
      "Epoch 195, Loss: 0.41413205840097117\n",
      "Epoch 196, Loss: 0.4155607826414292\n",
      "Epoch 197, Loss: 0.414238532452658\n",
      "Epoch 198, Loss: 0.41297339310852155\n",
      "Epoch 199, Loss: 0.4123900845056213\n",
      "Epoch 200, Loss: 0.4134311180746695\n",
      "Epoch 201, Loss: 0.4127689164145939\n",
      "Epoch 202, Loss: 0.41232720715179455\n",
      "Epoch 203, Loss: 0.41150345937125327\n",
      "Epoch 204, Loss: 0.4115020652257978\n",
      "Epoch 205, Loss: 0.411078297677327\n",
      "Epoch 206, Loss: 0.4110567108542411\n",
      "Epoch 207, Loss: 0.4114023806357039\n",
      "Epoch 208, Loss: 0.41371932293434216\n",
      "Epoch 209, Loss: 0.41813952085771794\n",
      "Epoch 210, Loss: 0.42511728996367454\n",
      "Epoch 211, Loss: 0.42635158522503447\n",
      "Epoch 212, Loss: 0.419673136297028\n",
      "Epoch 213, Loss: 0.41005224089892217\n",
      "Epoch 214, Loss: 0.4205638856971283\n",
      "Epoch 215, Loss: 0.4288454648496258\n",
      "Epoch 216, Loss: 0.416730043439161\n",
      "Epoch 217, Loss: 0.4131035226095487\n",
      "Epoch 218, Loss: 0.41919050177663497\n",
      "Epoch 219, Loss: 0.41341632229404196\n",
      "Epoch 220, Loss: 0.411337015720657\n",
      "Epoch 221, Loss: 0.4153124279254653\n",
      "Epoch 222, Loss: 0.4104582809838288\n",
      "Epoch 223, Loss: 0.4101367219181661\n",
      "Epoch 224, Loss: 0.4157081327260397\n",
      "Epoch 225, Loss: 0.4144226163660391\n",
      "Epoch 226, Loss: 0.4098329995970875\n",
      "Epoch 227, Loss: 0.40775029376666666\n",
      "Epoch 228, Loss: 0.41429755898335924\n",
      "Epoch 229, Loss: 0.41521591906294136\n",
      "Epoch 230, Loss: 0.4099844981670613\n",
      "Epoch 231, Loss: 0.4074908343553954\n",
      "Epoch 232, Loss: 0.41404155462298753\n",
      "Epoch 233, Loss: 0.41428398110821113\n",
      "Epoch 234, Loss: 0.411010796569875\n",
      "Epoch 235, Loss: 0.40626047194262166\n",
      "Epoch 236, Loss: 0.409034666887797\n",
      "Epoch 237, Loss: 0.4158159770891869\n",
      "Epoch 238, Loss: 0.4153325557817546\n",
      "Epoch 239, Loss: 0.40773651613666245\n",
      "Epoch 240, Loss: 0.40720486297242386\n",
      "Epoch 241, Loss: 0.41676379700873606\n",
      "Epoch 242, Loss: 0.4163271136351227\n",
      "Epoch 243, Loss: 0.4079038079306381\n",
      "Epoch 244, Loss: 0.41018584008428094\n",
      "Epoch 245, Loss: 0.4183221731020751\n",
      "Epoch 246, Loss: 0.4083151230189892\n",
      "Epoch 247, Loss: 0.403887555337203\n",
      "Epoch 248, Loss: 0.4087575223213056\n",
      "Epoch 249, Loss: 0.40489636999784445\n",
      "Epoch 250, Loss: 0.4028637127989142\n",
      "Epoch 251, Loss: 0.40329884617463313\n",
      "Epoch 252, Loss: 0.4063995709543235\n",
      "Epoch 253, Loss: 0.4039770141828027\n",
      "Epoch 254, Loss: 0.40232352789271325\n",
      "Epoch 255, Loss: 0.40085487433081396\n",
      "Epoch 256, Loss: 0.4013585184836403\n",
      "Epoch 257, Loss: 0.401038171909843\n",
      "Epoch 258, Loss: 0.4020229653351035\n",
      "Epoch 259, Loss: 0.4038903224025568\n",
      "Epoch 260, Loss: 0.4061704337624061\n",
      "Epoch 261, Loss: 0.40752030716947196\n",
      "Epoch 262, Loss: 0.4085568442371171\n",
      "Epoch 263, Loss: 0.40261644547833497\n",
      "Epoch 264, Loss: 0.39916727140987407\n",
      "Epoch 265, Loss: 0.39918720546249864\n",
      "Epoch 266, Loss: 0.4018616982923893\n",
      "Epoch 267, Loss: 0.40409750330247396\n",
      "Epoch 268, Loss: 0.4030983154573023\n",
      "Epoch 269, Loss: 0.40148977741823705\n",
      "Epoch 270, Loss: 0.3979682402950119\n",
      "Epoch 271, Loss: 0.39712887326045615\n",
      "Epoch 272, Loss: 0.3976166253873399\n",
      "Epoch 273, Loss: 0.3994664761725427\n",
      "Epoch 274, Loss: 0.40664772591817466\n",
      "Epoch 275, Loss: 0.4160374917744293\n",
      "Epoch 276, Loss: 0.42157817924529983\n",
      "Epoch 277, Loss: 0.3991758200300099\n",
      "Epoch 278, Loss: 0.4024471779631351\n",
      "Epoch 279, Loss: 0.4158416169220002\n",
      "Epoch 280, Loss: 0.4109940102017761\n",
      "Epoch 281, Loss: 0.40367779348858235\n",
      "Epoch 282, Loss: 0.4169002494142847\n",
      "Epoch 283, Loss: 0.4040475896870828\n",
      "Epoch 284, Loss: 0.4088327762653357\n",
      "Epoch 285, Loss: 0.407029797337259\n",
      "Epoch 286, Loss: 0.402515504342948\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22939280368020057\n",
      "Test R^2 score: 0.43063661454352764\n",
      "Num of epochs: 287\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Epoch 179, Loss: 0.42867030340024453\n",
      "Epoch 180, Loss: 0.42665902048327814\n",
      "Epoch 181, Loss: 0.4160041986606613\n",
      "Epoch 182, Loss: 0.42380692389414293\n",
      "Epoch 183, Loss: 0.4367609764525626\n",
      "Epoch 184, Loss: 0.42557170506243686\n",
      "Epoch 185, Loss: 0.42106826790053603\n",
      "Epoch 186, Loss: 0.42573876125176086\n",
      "Epoch 187, Loss: 0.41925407360374856\n",
      "Epoch 188, Loss: 0.4183384695092418\n",
      "Epoch 189, Loss: 0.4218813047997579\n",
      "Epoch 190, Loss: 0.4197713005325469\n",
      "Epoch 191, Loss: 0.417197451669247\n",
      "Epoch 192, Loss: 0.41998586832409235\n",
      "Epoch 193, Loss: 0.4198630180807017\n",
      "Epoch 194, Loss: 0.4146118298837611\n",
      "Epoch 195, Loss: 0.41413205840097117\n",
      "Epoch 196, Loss: 0.4155607826414292\n",
      "Epoch 197, Loss: 0.414238532452658\n",
      "Epoch 198, Loss: 0.41297339310852155\n",
      "Epoch 199, Loss: 0.4123900845056213\n",
      "Epoch 200, Loss: 0.4134311180746695\n",
      "Epoch 201, Loss: 0.4127689164145939\n",
      "Epoch 202, Loss: 0.41232720715179455\n",
      "Epoch 203, Loss: 0.41150345937125327\n",
      "Epoch 204, Loss: 0.4115020652257978\n",
      "Epoch 205, Loss: 0.411078297677327\n",
      "Epoch 206, Loss: 0.4110567108542411\n",
      "Epoch 207, Loss: 0.4114023806357039\n",
      "Epoch 208, Loss: 0.41371932293434216\n",
      "Epoch 209, Loss: 0.41813952085771794\n",
      "Epoch 210, Loss: 0.42511728996367454\n",
      "Epoch 211, Loss: 0.42635158522503447\n",
      "Epoch 212, Loss: 0.419673136297028\n",
      "Epoch 213, Loss: 0.41005224089892217\n",
      "Epoch 214, Loss: 0.4205638856971283\n",
      "Epoch 215, Loss: 0.4288454648496258\n",
      "Epoch 216, Loss: 0.416730043439161\n",
      "Epoch 217, Loss: 0.4131035226095487\n",
      "Epoch 218, Loss: 0.41919050177663497\n",
      "Epoch 219, Loss: 0.41341632229404196\n",
      "Epoch 220, Loss: 0.411337015720657\n",
      "Epoch 221, Loss: 0.4153124279254653\n",
      "Epoch 222, Loss: 0.4104582809838288\n",
      "Epoch 223, Loss: 0.4101367219181661\n",
      "Epoch 224, Loss: 0.4157081327260397\n",
      "Epoch 225, Loss: 0.4144226163660391\n",
      "Epoch 226, Loss: 0.4098329995970875\n",
      "Epoch 227, Loss: 0.40775029376666666\n",
      "Epoch 228, Loss: 0.41429755898335924\n",
      "Epoch 229, Loss: 0.41521591906294136\n",
      "Epoch 230, Loss: 0.4099844981670613\n",
      "Epoch 231, Loss: 0.4074908343553954\n",
      "Epoch 232, Loss: 0.41404155462298753\n",
      "Epoch 233, Loss: 0.41428398110821113\n",
      "Epoch 234, Loss: 0.411010796569875\n",
      "Epoch 235, Loss: 0.40626047194262166\n",
      "Epoch 236, Loss: 0.409034666887797\n",
      "Epoch 237, Loss: 0.4158159770891869\n",
      "Epoch 238, Loss: 0.4153325557817546\n",
      "Epoch 239, Loss: 0.40773651613666245\n",
      "Epoch 240, Loss: 0.40720486297242386\n",
      "Epoch 241, Loss: 0.41676379700873606\n",
      "Epoch 242, Loss: 0.4163271136351227\n",
      "Epoch 243, Loss: 0.4079038079306381\n",
      "Epoch 244, Loss: 0.41018584008428094\n",
      "Epoch 245, Loss: 0.4183221731020751\n",
      "Epoch 246, Loss: 0.4083151230189892\n",
      "Epoch 247, Loss: 0.403887555337203\n",
      "Epoch 248, Loss: 0.4087575223213056\n",
      "Epoch 249, Loss: 0.40489636999784445\n",
      "Epoch 250, Loss: 0.4028637127989142\n",
      "Epoch 251, Loss: 0.40329884617463313\n",
      "Epoch 252, Loss: 0.4063995709543235\n",
      "Epoch 253, Loss: 0.4039770141828027\n",
      "Epoch 254, Loss: 0.40232352789271325\n",
      "Epoch 255, Loss: 0.40085487433081396\n",
      "Epoch 256, Loss: 0.4013585184836403\n",
      "Epoch 257, Loss: 0.401038171909843\n",
      "Epoch 258, Loss: 0.4020229653351035\n",
      "Epoch 259, Loss: 0.4038903224025568\n",
      "Epoch 260, Loss: 0.4061704337624061\n",
      "Epoch 261, Loss: 0.40752030716947196\n",
      "Epoch 262, Loss: 0.4085568442371171\n",
      "Epoch 263, Loss: 0.40261644547833497\n",
      "Epoch 264, Loss: 0.39916727140987407\n",
      "Epoch 265, Loss: 0.39918720546249864\n",
      "Epoch 266, Loss: 0.4018616982923893\n",
      "Epoch 267, Loss: 0.40409750330247396\n",
      "Epoch 268, Loss: 0.4030983154573023\n",
      "Epoch 269, Loss: 0.40148977741823705\n",
      "Epoch 270, Loss: 0.3979682402950119\n",
      "Epoch 271, Loss: 0.39712887326045615\n",
      "Epoch 272, Loss: 0.3976166253873399\n",
      "Epoch 273, Loss: 0.3994664761725427\n",
      "Epoch 274, Loss: 0.40664772591817466\n",
      "Epoch 275, Loss: 0.4160374917744293\n",
      "Epoch 276, Loss: 0.42157817924529983\n",
      "Epoch 277, Loss: 0.3991758200300099\n",
      "Epoch 278, Loss: 0.4024471779631351\n",
      "Epoch 279, Loss: 0.4158416169220002\n",
      "Epoch 280, Loss: 0.4109940102017761\n",
      "Epoch 281, Loss: 0.40367779348858235\n",
      "Epoch 282, Loss: 0.4169002494142847\n",
      "Epoch 283, Loss: 0.4040475896870828\n",
      "Epoch 284, Loss: 0.4088327762653357\n",
      "Epoch 285, Loss: 0.407029797337259\n",
      "Epoch 286, Loss: 0.402515504342948\n",
      "Epoch 287, Loss: 0.4052148799645245\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22920590481102018\n",
      "Test R^2 score: 0.43019852893634536\n",
      "Num of epochs: 288\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Epoch 179, Loss: 0.42867030340024453\n",
      "Epoch 180, Loss: 0.42665902048327814\n",
      "Epoch 181, Loss: 0.4160041986606613\n",
      "Epoch 182, Loss: 0.42380692389414293\n",
      "Epoch 183, Loss: 0.4367609764525626\n",
      "Epoch 184, Loss: 0.42557170506243686\n",
      "Epoch 185, Loss: 0.42106826790053603\n",
      "Epoch 186, Loss: 0.42573876125176086\n",
      "Epoch 187, Loss: 0.41925407360374856\n",
      "Epoch 188, Loss: 0.4183384695092418\n",
      "Epoch 189, Loss: 0.4218813047997579\n",
      "Epoch 190, Loss: 0.4197713005325469\n",
      "Epoch 191, Loss: 0.417197451669247\n",
      "Epoch 192, Loss: 0.41998586832409235\n",
      "Epoch 193, Loss: 0.4198630180807017\n",
      "Epoch 194, Loss: 0.4146118298837611\n",
      "Epoch 195, Loss: 0.41413205840097117\n",
      "Epoch 196, Loss: 0.4155607826414292\n",
      "Epoch 197, Loss: 0.414238532452658\n",
      "Epoch 198, Loss: 0.41297339310852155\n",
      "Epoch 199, Loss: 0.4123900845056213\n",
      "Epoch 200, Loss: 0.4134311180746695\n",
      "Epoch 201, Loss: 0.4127689164145939\n",
      "Epoch 202, Loss: 0.41232720715179455\n",
      "Epoch 203, Loss: 0.41150345937125327\n",
      "Epoch 204, Loss: 0.4115020652257978\n",
      "Epoch 205, Loss: 0.411078297677327\n",
      "Epoch 206, Loss: 0.4110567108542411\n",
      "Epoch 207, Loss: 0.4114023806357039\n",
      "Epoch 208, Loss: 0.41371932293434216\n",
      "Epoch 209, Loss: 0.41813952085771794\n",
      "Epoch 210, Loss: 0.42511728996367454\n",
      "Epoch 211, Loss: 0.42635158522503447\n",
      "Epoch 212, Loss: 0.419673136297028\n",
      "Epoch 213, Loss: 0.41005224089892217\n",
      "Epoch 214, Loss: 0.4205638856971283\n",
      "Epoch 215, Loss: 0.4288454648496258\n",
      "Epoch 216, Loss: 0.416730043439161\n",
      "Epoch 217, Loss: 0.4131035226095487\n",
      "Epoch 218, Loss: 0.41919050177663497\n",
      "Epoch 219, Loss: 0.41341632229404196\n",
      "Epoch 220, Loss: 0.411337015720657\n",
      "Epoch 221, Loss: 0.4153124279254653\n",
      "Epoch 222, Loss: 0.4104582809838288\n",
      "Epoch 223, Loss: 0.4101367219181661\n",
      "Epoch 224, Loss: 0.4157081327260397\n",
      "Epoch 225, Loss: 0.4144226163660391\n",
      "Epoch 226, Loss: 0.4098329995970875\n",
      "Epoch 227, Loss: 0.40775029376666666\n",
      "Epoch 228, Loss: 0.41429755898335924\n",
      "Epoch 229, Loss: 0.41521591906294136\n",
      "Epoch 230, Loss: 0.4099844981670613\n",
      "Epoch 231, Loss: 0.4074908343553954\n",
      "Epoch 232, Loss: 0.41404155462298753\n",
      "Epoch 233, Loss: 0.41428398110821113\n",
      "Epoch 234, Loss: 0.411010796569875\n",
      "Epoch 235, Loss: 0.40626047194262166\n",
      "Epoch 236, Loss: 0.409034666887797\n",
      "Epoch 237, Loss: 0.4158159770891869\n",
      "Epoch 238, Loss: 0.4153325557817546\n",
      "Epoch 239, Loss: 0.40773651613666245\n",
      "Epoch 240, Loss: 0.40720486297242386\n",
      "Epoch 241, Loss: 0.41676379700873606\n",
      "Epoch 242, Loss: 0.4163271136351227\n",
      "Epoch 243, Loss: 0.4079038079306381\n",
      "Epoch 244, Loss: 0.41018584008428094\n",
      "Epoch 245, Loss: 0.4183221731020751\n",
      "Epoch 246, Loss: 0.4083151230189892\n",
      "Epoch 247, Loss: 0.403887555337203\n",
      "Epoch 248, Loss: 0.4087575223213056\n",
      "Epoch 249, Loss: 0.40489636999784445\n",
      "Epoch 250, Loss: 0.4028637127989142\n",
      "Epoch 251, Loss: 0.40329884617463313\n",
      "Epoch 252, Loss: 0.4063995709543235\n",
      "Epoch 253, Loss: 0.4039770141828027\n",
      "Epoch 254, Loss: 0.40232352789271325\n",
      "Epoch 255, Loss: 0.40085487433081396\n",
      "Epoch 256, Loss: 0.4013585184836403\n",
      "Epoch 257, Loss: 0.401038171909843\n",
      "Epoch 258, Loss: 0.4020229653351035\n",
      "Epoch 259, Loss: 0.4038903224025568\n",
      "Epoch 260, Loss: 0.4061704337624061\n",
      "Epoch 261, Loss: 0.40752030716947196\n",
      "Epoch 262, Loss: 0.4085568442371171\n",
      "Epoch 263, Loss: 0.40261644547833497\n",
      "Epoch 264, Loss: 0.39916727140987407\n",
      "Epoch 265, Loss: 0.39918720546249864\n",
      "Epoch 266, Loss: 0.4018616982923893\n",
      "Epoch 267, Loss: 0.40409750330247396\n",
      "Epoch 268, Loss: 0.4030983154573023\n",
      "Epoch 269, Loss: 0.40148977741823705\n",
      "Epoch 270, Loss: 0.3979682402950119\n",
      "Epoch 271, Loss: 0.39712887326045615\n",
      "Epoch 272, Loss: 0.3976166253873399\n",
      "Epoch 273, Loss: 0.3994664761725427\n",
      "Epoch 274, Loss: 0.40664772591817466\n",
      "Epoch 275, Loss: 0.4160374917744293\n",
      "Epoch 276, Loss: 0.42157817924529983\n",
      "Epoch 277, Loss: 0.3991758200300099\n",
      "Epoch 278, Loss: 0.4024471779631351\n",
      "Epoch 279, Loss: 0.4158416169220002\n",
      "Epoch 280, Loss: 0.4109940102017761\n",
      "Epoch 281, Loss: 0.40367779348858235\n",
      "Epoch 282, Loss: 0.4169002494142847\n",
      "Epoch 283, Loss: 0.4040475896870828\n",
      "Epoch 284, Loss: 0.4088327762653357\n",
      "Epoch 285, Loss: 0.407029797337259\n",
      "Epoch 286, Loss: 0.402515504342948\n",
      "Epoch 287, Loss: 0.4052148799645245\n",
      "Epoch 288, Loss: 0.4009055757189085\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.223586138002081\n",
      "Test R^2 score: 0.4570455410368749\n",
      "Num of epochs: 289\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Epoch 179, Loss: 0.42867030340024453\n",
      "Epoch 180, Loss: 0.42665902048327814\n",
      "Epoch 181, Loss: 0.4160041986606613\n",
      "Epoch 182, Loss: 0.42380692389414293\n",
      "Epoch 183, Loss: 0.4367609764525626\n",
      "Epoch 184, Loss: 0.42557170506243686\n",
      "Epoch 185, Loss: 0.42106826790053603\n",
      "Epoch 186, Loss: 0.42573876125176086\n",
      "Epoch 187, Loss: 0.41925407360374856\n",
      "Epoch 188, Loss: 0.4183384695092418\n",
      "Epoch 189, Loss: 0.4218813047997579\n",
      "Epoch 190, Loss: 0.4197713005325469\n",
      "Epoch 191, Loss: 0.417197451669247\n",
      "Epoch 192, Loss: 0.41998586832409235\n",
      "Epoch 193, Loss: 0.4198630180807017\n",
      "Epoch 194, Loss: 0.4146118298837611\n",
      "Epoch 195, Loss: 0.41413205840097117\n",
      "Epoch 196, Loss: 0.4155607826414292\n",
      "Epoch 197, Loss: 0.414238532452658\n",
      "Epoch 198, Loss: 0.41297339310852155\n",
      "Epoch 199, Loss: 0.4123900845056213\n",
      "Epoch 200, Loss: 0.4134311180746695\n",
      "Epoch 201, Loss: 0.4127689164145939\n",
      "Epoch 202, Loss: 0.41232720715179455\n",
      "Epoch 203, Loss: 0.41150345937125327\n",
      "Epoch 204, Loss: 0.4115020652257978\n",
      "Epoch 205, Loss: 0.411078297677327\n",
      "Epoch 206, Loss: 0.4110567108542411\n",
      "Epoch 207, Loss: 0.4114023806357039\n",
      "Epoch 208, Loss: 0.41371932293434216\n",
      "Epoch 209, Loss: 0.41813952085771794\n",
      "Epoch 210, Loss: 0.42511728996367454\n",
      "Epoch 211, Loss: 0.42635158522503447\n",
      "Epoch 212, Loss: 0.419673136297028\n",
      "Epoch 213, Loss: 0.41005224089892217\n",
      "Epoch 214, Loss: 0.4205638856971283\n",
      "Epoch 215, Loss: 0.4288454648496258\n",
      "Epoch 216, Loss: 0.416730043439161\n",
      "Epoch 217, Loss: 0.4131035226095487\n",
      "Epoch 218, Loss: 0.41919050177663497\n",
      "Epoch 219, Loss: 0.41341632229404196\n",
      "Epoch 220, Loss: 0.411337015720657\n",
      "Epoch 221, Loss: 0.4153124279254653\n",
      "Epoch 222, Loss: 0.4104582809838288\n",
      "Epoch 223, Loss: 0.4101367219181661\n",
      "Epoch 224, Loss: 0.4157081327260397\n",
      "Epoch 225, Loss: 0.4144226163660391\n",
      "Epoch 226, Loss: 0.4098329995970875\n",
      "Epoch 227, Loss: 0.40775029376666666\n",
      "Epoch 228, Loss: 0.41429755898335924\n",
      "Epoch 229, Loss: 0.41521591906294136\n",
      "Epoch 230, Loss: 0.4099844981670613\n",
      "Epoch 231, Loss: 0.4074908343553954\n",
      "Epoch 232, Loss: 0.41404155462298753\n",
      "Epoch 233, Loss: 0.41428398110821113\n",
      "Epoch 234, Loss: 0.411010796569875\n",
      "Epoch 235, Loss: 0.40626047194262166\n",
      "Epoch 236, Loss: 0.409034666887797\n",
      "Epoch 237, Loss: 0.4158159770891869\n",
      "Epoch 238, Loss: 0.4153325557817546\n",
      "Epoch 239, Loss: 0.40773651613666245\n",
      "Epoch 240, Loss: 0.40720486297242386\n",
      "Epoch 241, Loss: 0.41676379700873606\n",
      "Epoch 242, Loss: 0.4163271136351227\n",
      "Epoch 243, Loss: 0.4079038079306381\n",
      "Epoch 244, Loss: 0.41018584008428094\n",
      "Epoch 245, Loss: 0.4183221731020751\n",
      "Epoch 246, Loss: 0.4083151230189892\n",
      "Epoch 247, Loss: 0.403887555337203\n",
      "Epoch 248, Loss: 0.4087575223213056\n",
      "Epoch 249, Loss: 0.40489636999784445\n",
      "Epoch 250, Loss: 0.4028637127989142\n",
      "Epoch 251, Loss: 0.40329884617463313\n",
      "Epoch 252, Loss: 0.4063995709543235\n",
      "Epoch 253, Loss: 0.4039770141828027\n",
      "Epoch 254, Loss: 0.40232352789271325\n",
      "Epoch 255, Loss: 0.40085487433081396\n",
      "Epoch 256, Loss: 0.4013585184836403\n",
      "Epoch 257, Loss: 0.401038171909843\n",
      "Epoch 258, Loss: 0.4020229653351035\n",
      "Epoch 259, Loss: 0.4038903224025568\n",
      "Epoch 260, Loss: 0.4061704337624061\n",
      "Epoch 261, Loss: 0.40752030716947196\n",
      "Epoch 262, Loss: 0.4085568442371171\n",
      "Epoch 263, Loss: 0.40261644547833497\n",
      "Epoch 264, Loss: 0.39916727140987407\n",
      "Epoch 265, Loss: 0.39918720546249864\n",
      "Epoch 266, Loss: 0.4018616982923893\n",
      "Epoch 267, Loss: 0.40409750330247396\n",
      "Epoch 268, Loss: 0.4030983154573023\n",
      "Epoch 269, Loss: 0.40148977741823705\n",
      "Epoch 270, Loss: 0.3979682402950119\n",
      "Epoch 271, Loss: 0.39712887326045615\n",
      "Epoch 272, Loss: 0.3976166253873399\n",
      "Epoch 273, Loss: 0.3994664761725427\n",
      "Epoch 274, Loss: 0.40664772591817466\n",
      "Epoch 275, Loss: 0.4160374917744293\n",
      "Epoch 276, Loss: 0.42157817924529983\n",
      "Epoch 277, Loss: 0.3991758200300099\n",
      "Epoch 278, Loss: 0.4024471779631351\n",
      "Epoch 279, Loss: 0.4158416169220002\n",
      "Epoch 280, Loss: 0.4109940102017761\n",
      "Epoch 281, Loss: 0.40367779348858235\n",
      "Epoch 282, Loss: 0.4169002494142847\n",
      "Epoch 283, Loss: 0.4040475896870828\n",
      "Epoch 284, Loss: 0.4088327762653357\n",
      "Epoch 285, Loss: 0.407029797337259\n",
      "Epoch 286, Loss: 0.402515504342948\n",
      "Epoch 287, Loss: 0.4052148799645245\n",
      "Epoch 288, Loss: 0.4009055757189085\n",
      "Epoch 289, Loss: 0.4053528673397846\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22405546372961324\n",
      "Test R^2 score: 0.4544415358292111\n",
      "Num of epochs: 290\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Epoch 179, Loss: 0.42867030340024453\n",
      "Epoch 180, Loss: 0.42665902048327814\n",
      "Epoch 181, Loss: 0.4160041986606613\n",
      "Epoch 182, Loss: 0.42380692389414293\n",
      "Epoch 183, Loss: 0.4367609764525626\n",
      "Epoch 184, Loss: 0.42557170506243686\n",
      "Epoch 185, Loss: 0.42106826790053603\n",
      "Epoch 186, Loss: 0.42573876125176086\n",
      "Epoch 187, Loss: 0.41925407360374856\n",
      "Epoch 188, Loss: 0.4183384695092418\n",
      "Epoch 189, Loss: 0.4218813047997579\n",
      "Epoch 190, Loss: 0.4197713005325469\n",
      "Epoch 191, Loss: 0.417197451669247\n",
      "Epoch 192, Loss: 0.41998586832409235\n",
      "Epoch 193, Loss: 0.4198630180807017\n",
      "Epoch 194, Loss: 0.4146118298837611\n",
      "Epoch 195, Loss: 0.41413205840097117\n",
      "Epoch 196, Loss: 0.4155607826414292\n",
      "Epoch 197, Loss: 0.414238532452658\n",
      "Epoch 198, Loss: 0.41297339310852155\n",
      "Epoch 199, Loss: 0.4123900845056213\n",
      "Epoch 200, Loss: 0.4134311180746695\n",
      "Epoch 201, Loss: 0.4127689164145939\n",
      "Epoch 202, Loss: 0.41232720715179455\n",
      "Epoch 203, Loss: 0.41150345937125327\n",
      "Epoch 204, Loss: 0.4115020652257978\n",
      "Epoch 205, Loss: 0.411078297677327\n",
      "Epoch 206, Loss: 0.4110567108542411\n",
      "Epoch 207, Loss: 0.4114023806357039\n",
      "Epoch 208, Loss: 0.41371932293434216\n",
      "Epoch 209, Loss: 0.41813952085771794\n",
      "Epoch 210, Loss: 0.42511728996367454\n",
      "Epoch 211, Loss: 0.42635158522503447\n",
      "Epoch 212, Loss: 0.419673136297028\n",
      "Epoch 213, Loss: 0.41005224089892217\n",
      "Epoch 214, Loss: 0.4205638856971283\n",
      "Epoch 215, Loss: 0.4288454648496258\n",
      "Epoch 216, Loss: 0.416730043439161\n",
      "Epoch 217, Loss: 0.4131035226095487\n",
      "Epoch 218, Loss: 0.41919050177663497\n",
      "Epoch 219, Loss: 0.41341632229404196\n",
      "Epoch 220, Loss: 0.411337015720657\n",
      "Epoch 221, Loss: 0.4153124279254653\n",
      "Epoch 222, Loss: 0.4104582809838288\n",
      "Epoch 223, Loss: 0.4101367219181661\n",
      "Epoch 224, Loss: 0.4157081327260397\n",
      "Epoch 225, Loss: 0.4144226163660391\n",
      "Epoch 226, Loss: 0.4098329995970875\n",
      "Epoch 227, Loss: 0.40775029376666666\n",
      "Epoch 228, Loss: 0.41429755898335924\n",
      "Epoch 229, Loss: 0.41521591906294136\n",
      "Epoch 230, Loss: 0.4099844981670613\n",
      "Epoch 231, Loss: 0.4074908343553954\n",
      "Epoch 232, Loss: 0.41404155462298753\n",
      "Epoch 233, Loss: 0.41428398110821113\n",
      "Epoch 234, Loss: 0.411010796569875\n",
      "Epoch 235, Loss: 0.40626047194262166\n",
      "Epoch 236, Loss: 0.409034666887797\n",
      "Epoch 237, Loss: 0.4158159770891869\n",
      "Epoch 238, Loss: 0.4153325557817546\n",
      "Epoch 239, Loss: 0.40773651613666245\n",
      "Epoch 240, Loss: 0.40720486297242386\n",
      "Epoch 241, Loss: 0.41676379700873606\n",
      "Epoch 242, Loss: 0.4163271136351227\n",
      "Epoch 243, Loss: 0.4079038079306381\n",
      "Epoch 244, Loss: 0.41018584008428094\n",
      "Epoch 245, Loss: 0.4183221731020751\n",
      "Epoch 246, Loss: 0.4083151230189892\n",
      "Epoch 247, Loss: 0.403887555337203\n",
      "Epoch 248, Loss: 0.4087575223213056\n",
      "Epoch 249, Loss: 0.40489636999784445\n",
      "Epoch 250, Loss: 0.4028637127989142\n",
      "Epoch 251, Loss: 0.40329884617463313\n",
      "Epoch 252, Loss: 0.4063995709543235\n",
      "Epoch 253, Loss: 0.4039770141828027\n",
      "Epoch 254, Loss: 0.40232352789271325\n",
      "Epoch 255, Loss: 0.40085487433081396\n",
      "Epoch 256, Loss: 0.4013585184836403\n",
      "Epoch 257, Loss: 0.401038171909843\n",
      "Epoch 258, Loss: 0.4020229653351035\n",
      "Epoch 259, Loss: 0.4038903224025568\n",
      "Epoch 260, Loss: 0.4061704337624061\n",
      "Epoch 261, Loss: 0.40752030716947196\n",
      "Epoch 262, Loss: 0.4085568442371171\n",
      "Epoch 263, Loss: 0.40261644547833497\n",
      "Epoch 264, Loss: 0.39916727140987407\n",
      "Epoch 265, Loss: 0.39918720546249864\n",
      "Epoch 266, Loss: 0.4018616982923893\n",
      "Epoch 267, Loss: 0.40409750330247396\n",
      "Epoch 268, Loss: 0.4030983154573023\n",
      "Epoch 269, Loss: 0.40148977741823705\n",
      "Epoch 270, Loss: 0.3979682402950119\n",
      "Epoch 271, Loss: 0.39712887326045615\n",
      "Epoch 272, Loss: 0.3976166253873399\n",
      "Epoch 273, Loss: 0.3994664761725427\n",
      "Epoch 274, Loss: 0.40664772591817466\n",
      "Epoch 275, Loss: 0.4160374917744293\n",
      "Epoch 276, Loss: 0.42157817924529983\n",
      "Epoch 277, Loss: 0.3991758200300099\n",
      "Epoch 278, Loss: 0.4024471779631351\n",
      "Epoch 279, Loss: 0.4158416169220002\n",
      "Epoch 280, Loss: 0.4109940102017761\n",
      "Epoch 281, Loss: 0.40367779348858235\n",
      "Epoch 282, Loss: 0.4169002494142847\n",
      "Epoch 283, Loss: 0.4040475896870828\n",
      "Epoch 284, Loss: 0.4088327762653357\n",
      "Epoch 285, Loss: 0.407029797337259\n",
      "Epoch 286, Loss: 0.402515504342948\n",
      "Epoch 287, Loss: 0.4052148799645245\n",
      "Epoch 288, Loss: 0.4009055757189085\n",
      "Epoch 289, Loss: 0.4053528673397846\n",
      "Epoch 290, Loss: 0.39793991358824765\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.23344262215923775\n",
      "Test R^2 score: 0.40730850524867757\n",
      "Num of epochs: 291\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Epoch 179, Loss: 0.42867030340024453\n",
      "Epoch 180, Loss: 0.42665902048327814\n",
      "Epoch 181, Loss: 0.4160041986606613\n",
      "Epoch 182, Loss: 0.42380692389414293\n",
      "Epoch 183, Loss: 0.4367609764525626\n",
      "Epoch 184, Loss: 0.42557170506243686\n",
      "Epoch 185, Loss: 0.42106826790053603\n",
      "Epoch 186, Loss: 0.42573876125176086\n",
      "Epoch 187, Loss: 0.41925407360374856\n",
      "Epoch 188, Loss: 0.4183384695092418\n",
      "Epoch 189, Loss: 0.4218813047997579\n",
      "Epoch 190, Loss: 0.4197713005325469\n",
      "Epoch 191, Loss: 0.417197451669247\n",
      "Epoch 192, Loss: 0.41998586832409235\n",
      "Epoch 193, Loss: 0.4198630180807017\n",
      "Epoch 194, Loss: 0.4146118298837611\n",
      "Epoch 195, Loss: 0.41413205840097117\n",
      "Epoch 196, Loss: 0.4155607826414292\n",
      "Epoch 197, Loss: 0.414238532452658\n",
      "Epoch 198, Loss: 0.41297339310852155\n",
      "Epoch 199, Loss: 0.4123900845056213\n",
      "Epoch 200, Loss: 0.4134311180746695\n",
      "Epoch 201, Loss: 0.4127689164145939\n",
      "Epoch 202, Loss: 0.41232720715179455\n",
      "Epoch 203, Loss: 0.41150345937125327\n",
      "Epoch 204, Loss: 0.4115020652257978\n",
      "Epoch 205, Loss: 0.411078297677327\n",
      "Epoch 206, Loss: 0.4110567108542411\n",
      "Epoch 207, Loss: 0.4114023806357039\n",
      "Epoch 208, Loss: 0.41371932293434216\n",
      "Epoch 209, Loss: 0.41813952085771794\n",
      "Epoch 210, Loss: 0.42511728996367454\n",
      "Epoch 211, Loss: 0.42635158522503447\n",
      "Epoch 212, Loss: 0.419673136297028\n",
      "Epoch 213, Loss: 0.41005224089892217\n",
      "Epoch 214, Loss: 0.4205638856971283\n",
      "Epoch 215, Loss: 0.4288454648496258\n",
      "Epoch 216, Loss: 0.416730043439161\n",
      "Epoch 217, Loss: 0.4131035226095487\n",
      "Epoch 218, Loss: 0.41919050177663497\n",
      "Epoch 219, Loss: 0.41341632229404196\n",
      "Epoch 220, Loss: 0.411337015720657\n",
      "Epoch 221, Loss: 0.4153124279254653\n",
      "Epoch 222, Loss: 0.4104582809838288\n",
      "Epoch 223, Loss: 0.4101367219181661\n",
      "Epoch 224, Loss: 0.4157081327260397\n",
      "Epoch 225, Loss: 0.4144226163660391\n",
      "Epoch 226, Loss: 0.4098329995970875\n",
      "Epoch 227, Loss: 0.40775029376666666\n",
      "Epoch 228, Loss: 0.41429755898335924\n",
      "Epoch 229, Loss: 0.41521591906294136\n",
      "Epoch 230, Loss: 0.4099844981670613\n",
      "Epoch 231, Loss: 0.4074908343553954\n",
      "Epoch 232, Loss: 0.41404155462298753\n",
      "Epoch 233, Loss: 0.41428398110821113\n",
      "Epoch 234, Loss: 0.411010796569875\n",
      "Epoch 235, Loss: 0.40626047194262166\n",
      "Epoch 236, Loss: 0.409034666887797\n",
      "Epoch 237, Loss: 0.4158159770891869\n",
      "Epoch 238, Loss: 0.4153325557817546\n",
      "Epoch 239, Loss: 0.40773651613666245\n",
      "Epoch 240, Loss: 0.40720486297242386\n",
      "Epoch 241, Loss: 0.41676379700873606\n",
      "Epoch 242, Loss: 0.4163271136351227\n",
      "Epoch 243, Loss: 0.4079038079306381\n",
      "Epoch 244, Loss: 0.41018584008428094\n",
      "Epoch 245, Loss: 0.4183221731020751\n",
      "Epoch 246, Loss: 0.4083151230189892\n",
      "Epoch 247, Loss: 0.403887555337203\n",
      "Epoch 248, Loss: 0.4087575223213056\n",
      "Epoch 249, Loss: 0.40489636999784445\n",
      "Epoch 250, Loss: 0.4028637127989142\n",
      "Epoch 251, Loss: 0.40329884617463313\n",
      "Epoch 252, Loss: 0.4063995709543235\n",
      "Epoch 253, Loss: 0.4039770141828027\n",
      "Epoch 254, Loss: 0.40232352789271325\n",
      "Epoch 255, Loss: 0.40085487433081396\n",
      "Epoch 256, Loss: 0.4013585184836403\n",
      "Epoch 257, Loss: 0.401038171909843\n",
      "Epoch 258, Loss: 0.4020229653351035\n",
      "Epoch 259, Loss: 0.4038903224025568\n",
      "Epoch 260, Loss: 0.4061704337624061\n",
      "Epoch 261, Loss: 0.40752030716947196\n",
      "Epoch 262, Loss: 0.4085568442371171\n",
      "Epoch 263, Loss: 0.40261644547833497\n",
      "Epoch 264, Loss: 0.39916727140987407\n",
      "Epoch 265, Loss: 0.39918720546249864\n",
      "Epoch 266, Loss: 0.4018616982923893\n",
      "Epoch 267, Loss: 0.40409750330247396\n",
      "Epoch 268, Loss: 0.4030983154573023\n",
      "Epoch 269, Loss: 0.40148977741823705\n",
      "Epoch 270, Loss: 0.3979682402950119\n",
      "Epoch 271, Loss: 0.39712887326045615\n",
      "Epoch 272, Loss: 0.3976166253873399\n",
      "Epoch 273, Loss: 0.3994664761725427\n",
      "Epoch 274, Loss: 0.40664772591817466\n",
      "Epoch 275, Loss: 0.4160374917744293\n",
      "Epoch 276, Loss: 0.42157817924529983\n",
      "Epoch 277, Loss: 0.3991758200300099\n",
      "Epoch 278, Loss: 0.4024471779631351\n",
      "Epoch 279, Loss: 0.4158416169220002\n",
      "Epoch 280, Loss: 0.4109940102017761\n",
      "Epoch 281, Loss: 0.40367779348858235\n",
      "Epoch 282, Loss: 0.4169002494142847\n",
      "Epoch 283, Loss: 0.4040475896870828\n",
      "Epoch 284, Loss: 0.4088327762653357\n",
      "Epoch 285, Loss: 0.407029797337259\n",
      "Epoch 286, Loss: 0.402515504342948\n",
      "Epoch 287, Loss: 0.4052148799645245\n",
      "Epoch 288, Loss: 0.4009055757189085\n",
      "Epoch 289, Loss: 0.4053528673397846\n",
      "Epoch 290, Loss: 0.39793991358824765\n",
      "Epoch 291, Loss: 0.4052915270341599\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2221129397473679\n",
      "Test R^2 score: 0.46454069852129953\n",
      "Num of epochs: 292\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Epoch 179, Loss: 0.42867030340024453\n",
      "Epoch 180, Loss: 0.42665902048327814\n",
      "Epoch 181, Loss: 0.4160041986606613\n",
      "Epoch 182, Loss: 0.42380692389414293\n",
      "Epoch 183, Loss: 0.4367609764525626\n",
      "Epoch 184, Loss: 0.42557170506243686\n",
      "Epoch 185, Loss: 0.42106826790053603\n",
      "Epoch 186, Loss: 0.42573876125176086\n",
      "Epoch 187, Loss: 0.41925407360374856\n",
      "Epoch 188, Loss: 0.4183384695092418\n",
      "Epoch 189, Loss: 0.4218813047997579\n",
      "Epoch 190, Loss: 0.4197713005325469\n",
      "Epoch 191, Loss: 0.417197451669247\n",
      "Epoch 192, Loss: 0.41998586832409235\n",
      "Epoch 193, Loss: 0.4198630180807017\n",
      "Epoch 194, Loss: 0.4146118298837611\n",
      "Epoch 195, Loss: 0.41413205840097117\n",
      "Epoch 196, Loss: 0.4155607826414292\n",
      "Epoch 197, Loss: 0.414238532452658\n",
      "Epoch 198, Loss: 0.41297339310852155\n",
      "Epoch 199, Loss: 0.4123900845056213\n",
      "Epoch 200, Loss: 0.4134311180746695\n",
      "Epoch 201, Loss: 0.4127689164145939\n",
      "Epoch 202, Loss: 0.41232720715179455\n",
      "Epoch 203, Loss: 0.41150345937125327\n",
      "Epoch 204, Loss: 0.4115020652257978\n",
      "Epoch 205, Loss: 0.411078297677327\n",
      "Epoch 206, Loss: 0.4110567108542411\n",
      "Epoch 207, Loss: 0.4114023806357039\n",
      "Epoch 208, Loss: 0.41371932293434216\n",
      "Epoch 209, Loss: 0.41813952085771794\n",
      "Epoch 210, Loss: 0.42511728996367454\n",
      "Epoch 211, Loss: 0.42635158522503447\n",
      "Epoch 212, Loss: 0.419673136297028\n",
      "Epoch 213, Loss: 0.41005224089892217\n",
      "Epoch 214, Loss: 0.4205638856971283\n",
      "Epoch 215, Loss: 0.4288454648496258\n",
      "Epoch 216, Loss: 0.416730043439161\n",
      "Epoch 217, Loss: 0.4131035226095487\n",
      "Epoch 218, Loss: 0.41919050177663497\n",
      "Epoch 219, Loss: 0.41341632229404196\n",
      "Epoch 220, Loss: 0.411337015720657\n",
      "Epoch 221, Loss: 0.4153124279254653\n",
      "Epoch 222, Loss: 0.4104582809838288\n",
      "Epoch 223, Loss: 0.4101367219181661\n",
      "Epoch 224, Loss: 0.4157081327260397\n",
      "Epoch 225, Loss: 0.4144226163660391\n",
      "Epoch 226, Loss: 0.4098329995970875\n",
      "Epoch 227, Loss: 0.40775029376666666\n",
      "Epoch 228, Loss: 0.41429755898335924\n",
      "Epoch 229, Loss: 0.41521591906294136\n",
      "Epoch 230, Loss: 0.4099844981670613\n",
      "Epoch 231, Loss: 0.4074908343553954\n",
      "Epoch 232, Loss: 0.41404155462298753\n",
      "Epoch 233, Loss: 0.41428398110821113\n",
      "Epoch 234, Loss: 0.411010796569875\n",
      "Epoch 235, Loss: 0.40626047194262166\n",
      "Epoch 236, Loss: 0.409034666887797\n",
      "Epoch 237, Loss: 0.4158159770891869\n",
      "Epoch 238, Loss: 0.4153325557817546\n",
      "Epoch 239, Loss: 0.40773651613666245\n",
      "Epoch 240, Loss: 0.40720486297242386\n",
      "Epoch 241, Loss: 0.41676379700873606\n",
      "Epoch 242, Loss: 0.4163271136351227\n",
      "Epoch 243, Loss: 0.4079038079306381\n",
      "Epoch 244, Loss: 0.41018584008428094\n",
      "Epoch 245, Loss: 0.4183221731020751\n",
      "Epoch 246, Loss: 0.4083151230189892\n",
      "Epoch 247, Loss: 0.403887555337203\n",
      "Epoch 248, Loss: 0.4087575223213056\n",
      "Epoch 249, Loss: 0.40489636999784445\n",
      "Epoch 250, Loss: 0.4028637127989142\n",
      "Epoch 251, Loss: 0.40329884617463313\n",
      "Epoch 252, Loss: 0.4063995709543235\n",
      "Epoch 253, Loss: 0.4039770141828027\n",
      "Epoch 254, Loss: 0.40232352789271325\n",
      "Epoch 255, Loss: 0.40085487433081396\n",
      "Epoch 256, Loss: 0.4013585184836403\n",
      "Epoch 257, Loss: 0.401038171909843\n",
      "Epoch 258, Loss: 0.4020229653351035\n",
      "Epoch 259, Loss: 0.4038903224025568\n",
      "Epoch 260, Loss: 0.4061704337624061\n",
      "Epoch 261, Loss: 0.40752030716947196\n",
      "Epoch 262, Loss: 0.4085568442371171\n",
      "Epoch 263, Loss: 0.40261644547833497\n",
      "Epoch 264, Loss: 0.39916727140987407\n",
      "Epoch 265, Loss: 0.39918720546249864\n",
      "Epoch 266, Loss: 0.4018616982923893\n",
      "Epoch 267, Loss: 0.40409750330247396\n",
      "Epoch 268, Loss: 0.4030983154573023\n",
      "Epoch 269, Loss: 0.40148977741823705\n",
      "Epoch 270, Loss: 0.3979682402950119\n",
      "Epoch 271, Loss: 0.39712887326045615\n",
      "Epoch 272, Loss: 0.3976166253873399\n",
      "Epoch 273, Loss: 0.3994664761725427\n",
      "Epoch 274, Loss: 0.40664772591817466\n",
      "Epoch 275, Loss: 0.4160374917744293\n",
      "Epoch 276, Loss: 0.42157817924529983\n",
      "Epoch 277, Loss: 0.3991758200300099\n",
      "Epoch 278, Loss: 0.4024471779631351\n",
      "Epoch 279, Loss: 0.4158416169220002\n",
      "Epoch 280, Loss: 0.4109940102017761\n",
      "Epoch 281, Loss: 0.40367779348858235\n",
      "Epoch 282, Loss: 0.4169002494142847\n",
      "Epoch 283, Loss: 0.4040475896870828\n",
      "Epoch 284, Loss: 0.4088327762653357\n",
      "Epoch 285, Loss: 0.407029797337259\n",
      "Epoch 286, Loss: 0.402515504342948\n",
      "Epoch 287, Loss: 0.4052148799645245\n",
      "Epoch 288, Loss: 0.4009055757189085\n",
      "Epoch 289, Loss: 0.4053528673397846\n",
      "Epoch 290, Loss: 0.39793991358824765\n",
      "Epoch 291, Loss: 0.4052915270341599\n",
      "Epoch 292, Loss: 0.40244545623289163\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22964980376763808\n",
      "Test R^2 score: 0.4270877088473788\n",
      "Num of epochs: 293\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Epoch 179, Loss: 0.42867030340024453\n",
      "Epoch 180, Loss: 0.42665902048327814\n",
      "Epoch 181, Loss: 0.4160041986606613\n",
      "Epoch 182, Loss: 0.42380692389414293\n",
      "Epoch 183, Loss: 0.4367609764525626\n",
      "Epoch 184, Loss: 0.42557170506243686\n",
      "Epoch 185, Loss: 0.42106826790053603\n",
      "Epoch 186, Loss: 0.42573876125176086\n",
      "Epoch 187, Loss: 0.41925407360374856\n",
      "Epoch 188, Loss: 0.4183384695092418\n",
      "Epoch 189, Loss: 0.4218813047997579\n",
      "Epoch 190, Loss: 0.4197713005325469\n",
      "Epoch 191, Loss: 0.417197451669247\n",
      "Epoch 192, Loss: 0.41998586832409235\n",
      "Epoch 193, Loss: 0.4198630180807017\n",
      "Epoch 194, Loss: 0.4146118298837611\n",
      "Epoch 195, Loss: 0.41413205840097117\n",
      "Epoch 196, Loss: 0.4155607826414292\n",
      "Epoch 197, Loss: 0.414238532452658\n",
      "Epoch 198, Loss: 0.41297339310852155\n",
      "Epoch 199, Loss: 0.4123900845056213\n",
      "Epoch 200, Loss: 0.4134311180746695\n",
      "Epoch 201, Loss: 0.4127689164145939\n",
      "Epoch 202, Loss: 0.41232720715179455\n",
      "Epoch 203, Loss: 0.41150345937125327\n",
      "Epoch 204, Loss: 0.4115020652257978\n",
      "Epoch 205, Loss: 0.411078297677327\n",
      "Epoch 206, Loss: 0.4110567108542411\n",
      "Epoch 207, Loss: 0.4114023806357039\n",
      "Epoch 208, Loss: 0.41371932293434216\n",
      "Epoch 209, Loss: 0.41813952085771794\n",
      "Epoch 210, Loss: 0.42511728996367454\n",
      "Epoch 211, Loss: 0.42635158522503447\n",
      "Epoch 212, Loss: 0.419673136297028\n",
      "Epoch 213, Loss: 0.41005224089892217\n",
      "Epoch 214, Loss: 0.4205638856971283\n",
      "Epoch 215, Loss: 0.4288454648496258\n",
      "Epoch 216, Loss: 0.416730043439161\n",
      "Epoch 217, Loss: 0.4131035226095487\n",
      "Epoch 218, Loss: 0.41919050177663497\n",
      "Epoch 219, Loss: 0.41341632229404196\n",
      "Epoch 220, Loss: 0.411337015720657\n",
      "Epoch 221, Loss: 0.4153124279254653\n",
      "Epoch 222, Loss: 0.4104582809838288\n",
      "Epoch 223, Loss: 0.4101367219181661\n",
      "Epoch 224, Loss: 0.4157081327260397\n",
      "Epoch 225, Loss: 0.4144226163660391\n",
      "Epoch 226, Loss: 0.4098329995970875\n",
      "Epoch 227, Loss: 0.40775029376666666\n",
      "Epoch 228, Loss: 0.41429755898335924\n",
      "Epoch 229, Loss: 0.41521591906294136\n",
      "Epoch 230, Loss: 0.4099844981670613\n",
      "Epoch 231, Loss: 0.4074908343553954\n",
      "Epoch 232, Loss: 0.41404155462298753\n",
      "Epoch 233, Loss: 0.41428398110821113\n",
      "Epoch 234, Loss: 0.411010796569875\n",
      "Epoch 235, Loss: 0.40626047194262166\n",
      "Epoch 236, Loss: 0.409034666887797\n",
      "Epoch 237, Loss: 0.4158159770891869\n",
      "Epoch 238, Loss: 0.4153325557817546\n",
      "Epoch 239, Loss: 0.40773651613666245\n",
      "Epoch 240, Loss: 0.40720486297242386\n",
      "Epoch 241, Loss: 0.41676379700873606\n",
      "Epoch 242, Loss: 0.4163271136351227\n",
      "Epoch 243, Loss: 0.4079038079306381\n",
      "Epoch 244, Loss: 0.41018584008428094\n",
      "Epoch 245, Loss: 0.4183221731020751\n",
      "Epoch 246, Loss: 0.4083151230189892\n",
      "Epoch 247, Loss: 0.403887555337203\n",
      "Epoch 248, Loss: 0.4087575223213056\n",
      "Epoch 249, Loss: 0.40489636999784445\n",
      "Epoch 250, Loss: 0.4028637127989142\n",
      "Epoch 251, Loss: 0.40329884617463313\n",
      "Epoch 252, Loss: 0.4063995709543235\n",
      "Epoch 253, Loss: 0.4039770141828027\n",
      "Epoch 254, Loss: 0.40232352789271325\n",
      "Epoch 255, Loss: 0.40085487433081396\n",
      "Epoch 256, Loss: 0.4013585184836403\n",
      "Epoch 257, Loss: 0.401038171909843\n",
      "Epoch 258, Loss: 0.4020229653351035\n",
      "Epoch 259, Loss: 0.4038903224025568\n",
      "Epoch 260, Loss: 0.4061704337624061\n",
      "Epoch 261, Loss: 0.40752030716947196\n",
      "Epoch 262, Loss: 0.4085568442371171\n",
      "Epoch 263, Loss: 0.40261644547833497\n",
      "Epoch 264, Loss: 0.39916727140987407\n",
      "Epoch 265, Loss: 0.39918720546249864\n",
      "Epoch 266, Loss: 0.4018616982923893\n",
      "Epoch 267, Loss: 0.40409750330247396\n",
      "Epoch 268, Loss: 0.4030983154573023\n",
      "Epoch 269, Loss: 0.40148977741823705\n",
      "Epoch 270, Loss: 0.3979682402950119\n",
      "Epoch 271, Loss: 0.39712887326045615\n",
      "Epoch 272, Loss: 0.3976166253873399\n",
      "Epoch 273, Loss: 0.3994664761725427\n",
      "Epoch 274, Loss: 0.40664772591817466\n",
      "Epoch 275, Loss: 0.4160374917744293\n",
      "Epoch 276, Loss: 0.42157817924529983\n",
      "Epoch 277, Loss: 0.3991758200300099\n",
      "Epoch 278, Loss: 0.4024471779631351\n",
      "Epoch 279, Loss: 0.4158416169220002\n",
      "Epoch 280, Loss: 0.4109940102017761\n",
      "Epoch 281, Loss: 0.40367779348858235\n",
      "Epoch 282, Loss: 0.4169002494142847\n",
      "Epoch 283, Loss: 0.4040475896870828\n",
      "Epoch 284, Loss: 0.4088327762653357\n",
      "Epoch 285, Loss: 0.407029797337259\n",
      "Epoch 286, Loss: 0.402515504342948\n",
      "Epoch 287, Loss: 0.4052148799645245\n",
      "Epoch 288, Loss: 0.4009055757189085\n",
      "Epoch 289, Loss: 0.4053528673397846\n",
      "Epoch 290, Loss: 0.39793991358824765\n",
      "Epoch 291, Loss: 0.4052915270341599\n",
      "Epoch 292, Loss: 0.40244545623289163\n",
      "Epoch 293, Loss: 0.40846720280302085\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22370351388332194\n",
      "Test R^2 score: 0.45732685813867086\n",
      "Num of epochs: 294\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Epoch 179, Loss: 0.42867030340024453\n",
      "Epoch 180, Loss: 0.42665902048327814\n",
      "Epoch 181, Loss: 0.4160041986606613\n",
      "Epoch 182, Loss: 0.42380692389414293\n",
      "Epoch 183, Loss: 0.4367609764525626\n",
      "Epoch 184, Loss: 0.42557170506243686\n",
      "Epoch 185, Loss: 0.42106826790053603\n",
      "Epoch 186, Loss: 0.42573876125176086\n",
      "Epoch 187, Loss: 0.41925407360374856\n",
      "Epoch 188, Loss: 0.4183384695092418\n",
      "Epoch 189, Loss: 0.4218813047997579\n",
      "Epoch 190, Loss: 0.4197713005325469\n",
      "Epoch 191, Loss: 0.417197451669247\n",
      "Epoch 192, Loss: 0.41998586832409235\n",
      "Epoch 193, Loss: 0.4198630180807017\n",
      "Epoch 194, Loss: 0.4146118298837611\n",
      "Epoch 195, Loss: 0.41413205840097117\n",
      "Epoch 196, Loss: 0.4155607826414292\n",
      "Epoch 197, Loss: 0.414238532452658\n",
      "Epoch 198, Loss: 0.41297339310852155\n",
      "Epoch 199, Loss: 0.4123900845056213\n",
      "Epoch 200, Loss: 0.4134311180746695\n",
      "Epoch 201, Loss: 0.4127689164145939\n",
      "Epoch 202, Loss: 0.41232720715179455\n",
      "Epoch 203, Loss: 0.41150345937125327\n",
      "Epoch 204, Loss: 0.4115020652257978\n",
      "Epoch 205, Loss: 0.411078297677327\n",
      "Epoch 206, Loss: 0.4110567108542411\n",
      "Epoch 207, Loss: 0.4114023806357039\n",
      "Epoch 208, Loss: 0.41371932293434216\n",
      "Epoch 209, Loss: 0.41813952085771794\n",
      "Epoch 210, Loss: 0.42511728996367454\n",
      "Epoch 211, Loss: 0.42635158522503447\n",
      "Epoch 212, Loss: 0.419673136297028\n",
      "Epoch 213, Loss: 0.41005224089892217\n",
      "Epoch 214, Loss: 0.4205638856971283\n",
      "Epoch 215, Loss: 0.4288454648496258\n",
      "Epoch 216, Loss: 0.416730043439161\n",
      "Epoch 217, Loss: 0.4131035226095487\n",
      "Epoch 218, Loss: 0.41919050177663497\n",
      "Epoch 219, Loss: 0.41341632229404196\n",
      "Epoch 220, Loss: 0.411337015720657\n",
      "Epoch 221, Loss: 0.4153124279254653\n",
      "Epoch 222, Loss: 0.4104582809838288\n",
      "Epoch 223, Loss: 0.4101367219181661\n",
      "Epoch 224, Loss: 0.4157081327260397\n",
      "Epoch 225, Loss: 0.4144226163660391\n",
      "Epoch 226, Loss: 0.4098329995970875\n",
      "Epoch 227, Loss: 0.40775029376666666\n",
      "Epoch 228, Loss: 0.41429755898335924\n",
      "Epoch 229, Loss: 0.41521591906294136\n",
      "Epoch 230, Loss: 0.4099844981670613\n",
      "Epoch 231, Loss: 0.4074908343553954\n",
      "Epoch 232, Loss: 0.41404155462298753\n",
      "Epoch 233, Loss: 0.41428398110821113\n",
      "Epoch 234, Loss: 0.411010796569875\n",
      "Epoch 235, Loss: 0.40626047194262166\n",
      "Epoch 236, Loss: 0.409034666887797\n",
      "Epoch 237, Loss: 0.4158159770891869\n",
      "Epoch 238, Loss: 0.4153325557817546\n",
      "Epoch 239, Loss: 0.40773651613666245\n",
      "Epoch 240, Loss: 0.40720486297242386\n",
      "Epoch 241, Loss: 0.41676379700873606\n",
      "Epoch 242, Loss: 0.4163271136351227\n",
      "Epoch 243, Loss: 0.4079038079306381\n",
      "Epoch 244, Loss: 0.41018584008428094\n",
      "Epoch 245, Loss: 0.4183221731020751\n",
      "Epoch 246, Loss: 0.4083151230189892\n",
      "Epoch 247, Loss: 0.403887555337203\n",
      "Epoch 248, Loss: 0.4087575223213056\n",
      "Epoch 249, Loss: 0.40489636999784445\n",
      "Epoch 250, Loss: 0.4028637127989142\n",
      "Epoch 251, Loss: 0.40329884617463313\n",
      "Epoch 252, Loss: 0.4063995709543235\n",
      "Epoch 253, Loss: 0.4039770141828027\n",
      "Epoch 254, Loss: 0.40232352789271325\n",
      "Epoch 255, Loss: 0.40085487433081396\n",
      "Epoch 256, Loss: 0.4013585184836403\n",
      "Epoch 257, Loss: 0.401038171909843\n",
      "Epoch 258, Loss: 0.4020229653351035\n",
      "Epoch 259, Loss: 0.4038903224025568\n",
      "Epoch 260, Loss: 0.4061704337624061\n",
      "Epoch 261, Loss: 0.40752030716947196\n",
      "Epoch 262, Loss: 0.4085568442371171\n",
      "Epoch 263, Loss: 0.40261644547833497\n",
      "Epoch 264, Loss: 0.39916727140987407\n",
      "Epoch 265, Loss: 0.39918720546249864\n",
      "Epoch 266, Loss: 0.4018616982923893\n",
      "Epoch 267, Loss: 0.40409750330247396\n",
      "Epoch 268, Loss: 0.4030983154573023\n",
      "Epoch 269, Loss: 0.40148977741823705\n",
      "Epoch 270, Loss: 0.3979682402950119\n",
      "Epoch 271, Loss: 0.39712887326045615\n",
      "Epoch 272, Loss: 0.3976166253873399\n",
      "Epoch 273, Loss: 0.3994664761725427\n",
      "Epoch 274, Loss: 0.40664772591817466\n",
      "Epoch 275, Loss: 0.4160374917744293\n",
      "Epoch 276, Loss: 0.42157817924529983\n",
      "Epoch 277, Loss: 0.3991758200300099\n",
      "Epoch 278, Loss: 0.4024471779631351\n",
      "Epoch 279, Loss: 0.4158416169220002\n",
      "Epoch 280, Loss: 0.4109940102017761\n",
      "Epoch 281, Loss: 0.40367779348858235\n",
      "Epoch 282, Loss: 0.4169002494142847\n",
      "Epoch 283, Loss: 0.4040475896870828\n",
      "Epoch 284, Loss: 0.4088327762653357\n",
      "Epoch 285, Loss: 0.407029797337259\n",
      "Epoch 286, Loss: 0.402515504342948\n",
      "Epoch 287, Loss: 0.4052148799645245\n",
      "Epoch 288, Loss: 0.4009055757189085\n",
      "Epoch 289, Loss: 0.4053528673397846\n",
      "Epoch 290, Loss: 0.39793991358824765\n",
      "Epoch 291, Loss: 0.4052915270341599\n",
      "Epoch 292, Loss: 0.40244545623289163\n",
      "Epoch 293, Loss: 0.40846720280302085\n",
      "Epoch 294, Loss: 0.3972046796923518\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2304265286684729\n",
      "Test R^2 score: 0.4257011779897301\n",
      "Num of epochs: 295\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Epoch 179, Loss: 0.42867030340024453\n",
      "Epoch 180, Loss: 0.42665902048327814\n",
      "Epoch 181, Loss: 0.4160041986606613\n",
      "Epoch 182, Loss: 0.42380692389414293\n",
      "Epoch 183, Loss: 0.4367609764525626\n",
      "Epoch 184, Loss: 0.42557170506243686\n",
      "Epoch 185, Loss: 0.42106826790053603\n",
      "Epoch 186, Loss: 0.42573876125176086\n",
      "Epoch 187, Loss: 0.41925407360374856\n",
      "Epoch 188, Loss: 0.4183384695092418\n",
      "Epoch 189, Loss: 0.4218813047997579\n",
      "Epoch 190, Loss: 0.4197713005325469\n",
      "Epoch 191, Loss: 0.417197451669247\n",
      "Epoch 192, Loss: 0.41998586832409235\n",
      "Epoch 193, Loss: 0.4198630180807017\n",
      "Epoch 194, Loss: 0.4146118298837611\n",
      "Epoch 195, Loss: 0.41413205840097117\n",
      "Epoch 196, Loss: 0.4155607826414292\n",
      "Epoch 197, Loss: 0.414238532452658\n",
      "Epoch 198, Loss: 0.41297339310852155\n",
      "Epoch 199, Loss: 0.4123900845056213\n",
      "Epoch 200, Loss: 0.4134311180746695\n",
      "Epoch 201, Loss: 0.4127689164145939\n",
      "Epoch 202, Loss: 0.41232720715179455\n",
      "Epoch 203, Loss: 0.41150345937125327\n",
      "Epoch 204, Loss: 0.4115020652257978\n",
      "Epoch 205, Loss: 0.411078297677327\n",
      "Epoch 206, Loss: 0.4110567108542411\n",
      "Epoch 207, Loss: 0.4114023806357039\n",
      "Epoch 208, Loss: 0.41371932293434216\n",
      "Epoch 209, Loss: 0.41813952085771794\n",
      "Epoch 210, Loss: 0.42511728996367454\n",
      "Epoch 211, Loss: 0.42635158522503447\n",
      "Epoch 212, Loss: 0.419673136297028\n",
      "Epoch 213, Loss: 0.41005224089892217\n",
      "Epoch 214, Loss: 0.4205638856971283\n",
      "Epoch 215, Loss: 0.4288454648496258\n",
      "Epoch 216, Loss: 0.416730043439161\n",
      "Epoch 217, Loss: 0.4131035226095487\n",
      "Epoch 218, Loss: 0.41919050177663497\n",
      "Epoch 219, Loss: 0.41341632229404196\n",
      "Epoch 220, Loss: 0.411337015720657\n",
      "Epoch 221, Loss: 0.4153124279254653\n",
      "Epoch 222, Loss: 0.4104582809838288\n",
      "Epoch 223, Loss: 0.4101367219181661\n",
      "Epoch 224, Loss: 0.4157081327260397\n",
      "Epoch 225, Loss: 0.4144226163660391\n",
      "Epoch 226, Loss: 0.4098329995970875\n",
      "Epoch 227, Loss: 0.40775029376666666\n",
      "Epoch 228, Loss: 0.41429755898335924\n",
      "Epoch 229, Loss: 0.41521591906294136\n",
      "Epoch 230, Loss: 0.4099844981670613\n",
      "Epoch 231, Loss: 0.4074908343553954\n",
      "Epoch 232, Loss: 0.41404155462298753\n",
      "Epoch 233, Loss: 0.41428398110821113\n",
      "Epoch 234, Loss: 0.411010796569875\n",
      "Epoch 235, Loss: 0.40626047194262166\n",
      "Epoch 236, Loss: 0.409034666887797\n",
      "Epoch 237, Loss: 0.4158159770891869\n",
      "Epoch 238, Loss: 0.4153325557817546\n",
      "Epoch 239, Loss: 0.40773651613666245\n",
      "Epoch 240, Loss: 0.40720486297242386\n",
      "Epoch 241, Loss: 0.41676379700873606\n",
      "Epoch 242, Loss: 0.4163271136351227\n",
      "Epoch 243, Loss: 0.4079038079306381\n",
      "Epoch 244, Loss: 0.41018584008428094\n",
      "Epoch 245, Loss: 0.4183221731020751\n",
      "Epoch 246, Loss: 0.4083151230189892\n",
      "Epoch 247, Loss: 0.403887555337203\n",
      "Epoch 248, Loss: 0.4087575223213056\n",
      "Epoch 249, Loss: 0.40489636999784445\n",
      "Epoch 250, Loss: 0.4028637127989142\n",
      "Epoch 251, Loss: 0.40329884617463313\n",
      "Epoch 252, Loss: 0.4063995709543235\n",
      "Epoch 253, Loss: 0.4039770141828027\n",
      "Epoch 254, Loss: 0.40232352789271325\n",
      "Epoch 255, Loss: 0.40085487433081396\n",
      "Epoch 256, Loss: 0.4013585184836403\n",
      "Epoch 257, Loss: 0.401038171909843\n",
      "Epoch 258, Loss: 0.4020229653351035\n",
      "Epoch 259, Loss: 0.4038903224025568\n",
      "Epoch 260, Loss: 0.4061704337624061\n",
      "Epoch 261, Loss: 0.40752030716947196\n",
      "Epoch 262, Loss: 0.4085568442371171\n",
      "Epoch 263, Loss: 0.40261644547833497\n",
      "Epoch 264, Loss: 0.39916727140987407\n",
      "Epoch 265, Loss: 0.39918720546249864\n",
      "Epoch 266, Loss: 0.4018616982923893\n",
      "Epoch 267, Loss: 0.40409750330247396\n",
      "Epoch 268, Loss: 0.4030983154573023\n",
      "Epoch 269, Loss: 0.40148977741823705\n",
      "Epoch 270, Loss: 0.3979682402950119\n",
      "Epoch 271, Loss: 0.39712887326045615\n",
      "Epoch 272, Loss: 0.3976166253873399\n",
      "Epoch 273, Loss: 0.3994664761725427\n",
      "Epoch 274, Loss: 0.40664772591817466\n",
      "Epoch 275, Loss: 0.4160374917744293\n",
      "Epoch 276, Loss: 0.42157817924529983\n",
      "Epoch 277, Loss: 0.3991758200300099\n",
      "Epoch 278, Loss: 0.4024471779631351\n",
      "Epoch 279, Loss: 0.4158416169220002\n",
      "Epoch 280, Loss: 0.4109940102017761\n",
      "Epoch 281, Loss: 0.40367779348858235\n",
      "Epoch 282, Loss: 0.4169002494142847\n",
      "Epoch 283, Loss: 0.4040475896870828\n",
      "Epoch 284, Loss: 0.4088327762653357\n",
      "Epoch 285, Loss: 0.407029797337259\n",
      "Epoch 286, Loss: 0.402515504342948\n",
      "Epoch 287, Loss: 0.4052148799645245\n",
      "Epoch 288, Loss: 0.4009055757189085\n",
      "Epoch 289, Loss: 0.4053528673397846\n",
      "Epoch 290, Loss: 0.39793991358824765\n",
      "Epoch 291, Loss: 0.4052915270341599\n",
      "Epoch 292, Loss: 0.40244545623289163\n",
      "Epoch 293, Loss: 0.40846720280302085\n",
      "Epoch 294, Loss: 0.3972046796923518\n",
      "Epoch 295, Loss: 0.4062959938422654\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.24672970359542237\n",
      "Test R^2 score: 0.3402150026866383\n",
      "Num of epochs: 296\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Epoch 179, Loss: 0.42867030340024453\n",
      "Epoch 180, Loss: 0.42665902048327814\n",
      "Epoch 181, Loss: 0.4160041986606613\n",
      "Epoch 182, Loss: 0.42380692389414293\n",
      "Epoch 183, Loss: 0.4367609764525626\n",
      "Epoch 184, Loss: 0.42557170506243686\n",
      "Epoch 185, Loss: 0.42106826790053603\n",
      "Epoch 186, Loss: 0.42573876125176086\n",
      "Epoch 187, Loss: 0.41925407360374856\n",
      "Epoch 188, Loss: 0.4183384695092418\n",
      "Epoch 189, Loss: 0.4218813047997579\n",
      "Epoch 190, Loss: 0.4197713005325469\n",
      "Epoch 191, Loss: 0.417197451669247\n",
      "Epoch 192, Loss: 0.41998586832409235\n",
      "Epoch 193, Loss: 0.4198630180807017\n",
      "Epoch 194, Loss: 0.4146118298837611\n",
      "Epoch 195, Loss: 0.41413205840097117\n",
      "Epoch 196, Loss: 0.4155607826414292\n",
      "Epoch 197, Loss: 0.414238532452658\n",
      "Epoch 198, Loss: 0.41297339310852155\n",
      "Epoch 199, Loss: 0.4123900845056213\n",
      "Epoch 200, Loss: 0.4134311180746695\n",
      "Epoch 201, Loss: 0.4127689164145939\n",
      "Epoch 202, Loss: 0.41232720715179455\n",
      "Epoch 203, Loss: 0.41150345937125327\n",
      "Epoch 204, Loss: 0.4115020652257978\n",
      "Epoch 205, Loss: 0.411078297677327\n",
      "Epoch 206, Loss: 0.4110567108542411\n",
      "Epoch 207, Loss: 0.4114023806357039\n",
      "Epoch 208, Loss: 0.41371932293434216\n",
      "Epoch 209, Loss: 0.41813952085771794\n",
      "Epoch 210, Loss: 0.42511728996367454\n",
      "Epoch 211, Loss: 0.42635158522503447\n",
      "Epoch 212, Loss: 0.419673136297028\n",
      "Epoch 213, Loss: 0.41005224089892217\n",
      "Epoch 214, Loss: 0.4205638856971283\n",
      "Epoch 215, Loss: 0.4288454648496258\n",
      "Epoch 216, Loss: 0.416730043439161\n",
      "Epoch 217, Loss: 0.4131035226095487\n",
      "Epoch 218, Loss: 0.41919050177663497\n",
      "Epoch 219, Loss: 0.41341632229404196\n",
      "Epoch 220, Loss: 0.411337015720657\n",
      "Epoch 221, Loss: 0.4153124279254653\n",
      "Epoch 222, Loss: 0.4104582809838288\n",
      "Epoch 223, Loss: 0.4101367219181661\n",
      "Epoch 224, Loss: 0.4157081327260397\n",
      "Epoch 225, Loss: 0.4144226163660391\n",
      "Epoch 226, Loss: 0.4098329995970875\n",
      "Epoch 227, Loss: 0.40775029376666666\n",
      "Epoch 228, Loss: 0.41429755898335924\n",
      "Epoch 229, Loss: 0.41521591906294136\n",
      "Epoch 230, Loss: 0.4099844981670613\n",
      "Epoch 231, Loss: 0.4074908343553954\n",
      "Epoch 232, Loss: 0.41404155462298753\n",
      "Epoch 233, Loss: 0.41428398110821113\n",
      "Epoch 234, Loss: 0.411010796569875\n",
      "Epoch 235, Loss: 0.40626047194262166\n",
      "Epoch 236, Loss: 0.409034666887797\n",
      "Epoch 237, Loss: 0.4158159770891869\n",
      "Epoch 238, Loss: 0.4153325557817546\n",
      "Epoch 239, Loss: 0.40773651613666245\n",
      "Epoch 240, Loss: 0.40720486297242386\n",
      "Epoch 241, Loss: 0.41676379700873606\n",
      "Epoch 242, Loss: 0.4163271136351227\n",
      "Epoch 243, Loss: 0.4079038079306381\n",
      "Epoch 244, Loss: 0.41018584008428094\n",
      "Epoch 245, Loss: 0.4183221731020751\n",
      "Epoch 246, Loss: 0.4083151230189892\n",
      "Epoch 247, Loss: 0.403887555337203\n",
      "Epoch 248, Loss: 0.4087575223213056\n",
      "Epoch 249, Loss: 0.40489636999784445\n",
      "Epoch 250, Loss: 0.4028637127989142\n",
      "Epoch 251, Loss: 0.40329884617463313\n",
      "Epoch 252, Loss: 0.4063995709543235\n",
      "Epoch 253, Loss: 0.4039770141828027\n",
      "Epoch 254, Loss: 0.40232352789271325\n",
      "Epoch 255, Loss: 0.40085487433081396\n",
      "Epoch 256, Loss: 0.4013585184836403\n",
      "Epoch 257, Loss: 0.401038171909843\n",
      "Epoch 258, Loss: 0.4020229653351035\n",
      "Epoch 259, Loss: 0.4038903224025568\n",
      "Epoch 260, Loss: 0.4061704337624061\n",
      "Epoch 261, Loss: 0.40752030716947196\n",
      "Epoch 262, Loss: 0.4085568442371171\n",
      "Epoch 263, Loss: 0.40261644547833497\n",
      "Epoch 264, Loss: 0.39916727140987407\n",
      "Epoch 265, Loss: 0.39918720546249864\n",
      "Epoch 266, Loss: 0.4018616982923893\n",
      "Epoch 267, Loss: 0.40409750330247396\n",
      "Epoch 268, Loss: 0.4030983154573023\n",
      "Epoch 269, Loss: 0.40148977741823705\n",
      "Epoch 270, Loss: 0.3979682402950119\n",
      "Epoch 271, Loss: 0.39712887326045615\n",
      "Epoch 272, Loss: 0.3976166253873399\n",
      "Epoch 273, Loss: 0.3994664761725427\n",
      "Epoch 274, Loss: 0.40664772591817466\n",
      "Epoch 275, Loss: 0.4160374917744293\n",
      "Epoch 276, Loss: 0.42157817924529983\n",
      "Epoch 277, Loss: 0.3991758200300099\n",
      "Epoch 278, Loss: 0.4024471779631351\n",
      "Epoch 279, Loss: 0.4158416169220002\n",
      "Epoch 280, Loss: 0.4109940102017761\n",
      "Epoch 281, Loss: 0.40367779348858235\n",
      "Epoch 282, Loss: 0.4169002494142847\n",
      "Epoch 283, Loss: 0.4040475896870828\n",
      "Epoch 284, Loss: 0.4088327762653357\n",
      "Epoch 285, Loss: 0.407029797337259\n",
      "Epoch 286, Loss: 0.402515504342948\n",
      "Epoch 287, Loss: 0.4052148799645245\n",
      "Epoch 288, Loss: 0.4009055757189085\n",
      "Epoch 289, Loss: 0.4053528673397846\n",
      "Epoch 290, Loss: 0.39793991358824765\n",
      "Epoch 291, Loss: 0.4052915270341599\n",
      "Epoch 292, Loss: 0.40244545623289163\n",
      "Epoch 293, Loss: 0.40846720280302085\n",
      "Epoch 294, Loss: 0.3972046796923518\n",
      "Epoch 295, Loss: 0.4062959938422654\n",
      "Epoch 296, Loss: 0.4169741052642322\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22592033426300637\n",
      "Test R^2 score: 0.44550712381721946\n",
      "Num of epochs: 297\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Epoch 179, Loss: 0.42867030340024453\n",
      "Epoch 180, Loss: 0.42665902048327814\n",
      "Epoch 181, Loss: 0.4160041986606613\n",
      "Epoch 182, Loss: 0.42380692389414293\n",
      "Epoch 183, Loss: 0.4367609764525626\n",
      "Epoch 184, Loss: 0.42557170506243686\n",
      "Epoch 185, Loss: 0.42106826790053603\n",
      "Epoch 186, Loss: 0.42573876125176086\n",
      "Epoch 187, Loss: 0.41925407360374856\n",
      "Epoch 188, Loss: 0.4183384695092418\n",
      "Epoch 189, Loss: 0.4218813047997579\n",
      "Epoch 190, Loss: 0.4197713005325469\n",
      "Epoch 191, Loss: 0.417197451669247\n",
      "Epoch 192, Loss: 0.41998586832409235\n",
      "Epoch 193, Loss: 0.4198630180807017\n",
      "Epoch 194, Loss: 0.4146118298837611\n",
      "Epoch 195, Loss: 0.41413205840097117\n",
      "Epoch 196, Loss: 0.4155607826414292\n",
      "Epoch 197, Loss: 0.414238532452658\n",
      "Epoch 198, Loss: 0.41297339310852155\n",
      "Epoch 199, Loss: 0.4123900845056213\n",
      "Epoch 200, Loss: 0.4134311180746695\n",
      "Epoch 201, Loss: 0.4127689164145939\n",
      "Epoch 202, Loss: 0.41232720715179455\n",
      "Epoch 203, Loss: 0.41150345937125327\n",
      "Epoch 204, Loss: 0.4115020652257978\n",
      "Epoch 205, Loss: 0.411078297677327\n",
      "Epoch 206, Loss: 0.4110567108542411\n",
      "Epoch 207, Loss: 0.4114023806357039\n",
      "Epoch 208, Loss: 0.41371932293434216\n",
      "Epoch 209, Loss: 0.41813952085771794\n",
      "Epoch 210, Loss: 0.42511728996367454\n",
      "Epoch 211, Loss: 0.42635158522503447\n",
      "Epoch 212, Loss: 0.419673136297028\n",
      "Epoch 213, Loss: 0.41005224089892217\n",
      "Epoch 214, Loss: 0.4205638856971283\n",
      "Epoch 215, Loss: 0.4288454648496258\n",
      "Epoch 216, Loss: 0.416730043439161\n",
      "Epoch 217, Loss: 0.4131035226095487\n",
      "Epoch 218, Loss: 0.41919050177663497\n",
      "Epoch 219, Loss: 0.41341632229404196\n",
      "Epoch 220, Loss: 0.411337015720657\n",
      "Epoch 221, Loss: 0.4153124279254653\n",
      "Epoch 222, Loss: 0.4104582809838288\n",
      "Epoch 223, Loss: 0.4101367219181661\n",
      "Epoch 224, Loss: 0.4157081327260397\n",
      "Epoch 225, Loss: 0.4144226163660391\n",
      "Epoch 226, Loss: 0.4098329995970875\n",
      "Epoch 227, Loss: 0.40775029376666666\n",
      "Epoch 228, Loss: 0.41429755898335924\n",
      "Epoch 229, Loss: 0.41521591906294136\n",
      "Epoch 230, Loss: 0.4099844981670613\n",
      "Epoch 231, Loss: 0.4074908343553954\n",
      "Epoch 232, Loss: 0.41404155462298753\n",
      "Epoch 233, Loss: 0.41428398110821113\n",
      "Epoch 234, Loss: 0.411010796569875\n",
      "Epoch 235, Loss: 0.40626047194262166\n",
      "Epoch 236, Loss: 0.409034666887797\n",
      "Epoch 237, Loss: 0.4158159770891869\n",
      "Epoch 238, Loss: 0.4153325557817546\n",
      "Epoch 239, Loss: 0.40773651613666245\n",
      "Epoch 240, Loss: 0.40720486297242386\n",
      "Epoch 241, Loss: 0.41676379700873606\n",
      "Epoch 242, Loss: 0.4163271136351227\n",
      "Epoch 243, Loss: 0.4079038079306381\n",
      "Epoch 244, Loss: 0.41018584008428094\n",
      "Epoch 245, Loss: 0.4183221731020751\n",
      "Epoch 246, Loss: 0.4083151230189892\n",
      "Epoch 247, Loss: 0.403887555337203\n",
      "Epoch 248, Loss: 0.4087575223213056\n",
      "Epoch 249, Loss: 0.40489636999784445\n",
      "Epoch 250, Loss: 0.4028637127989142\n",
      "Epoch 251, Loss: 0.40329884617463313\n",
      "Epoch 252, Loss: 0.4063995709543235\n",
      "Epoch 253, Loss: 0.4039770141828027\n",
      "Epoch 254, Loss: 0.40232352789271325\n",
      "Epoch 255, Loss: 0.40085487433081396\n",
      "Epoch 256, Loss: 0.4013585184836403\n",
      "Epoch 257, Loss: 0.401038171909843\n",
      "Epoch 258, Loss: 0.4020229653351035\n",
      "Epoch 259, Loss: 0.4038903224025568\n",
      "Epoch 260, Loss: 0.4061704337624061\n",
      "Epoch 261, Loss: 0.40752030716947196\n",
      "Epoch 262, Loss: 0.4085568442371171\n",
      "Epoch 263, Loss: 0.40261644547833497\n",
      "Epoch 264, Loss: 0.39916727140987407\n",
      "Epoch 265, Loss: 0.39918720546249864\n",
      "Epoch 266, Loss: 0.4018616982923893\n",
      "Epoch 267, Loss: 0.40409750330247396\n",
      "Epoch 268, Loss: 0.4030983154573023\n",
      "Epoch 269, Loss: 0.40148977741823705\n",
      "Epoch 270, Loss: 0.3979682402950119\n",
      "Epoch 271, Loss: 0.39712887326045615\n",
      "Epoch 272, Loss: 0.3976166253873399\n",
      "Epoch 273, Loss: 0.3994664761725427\n",
      "Epoch 274, Loss: 0.40664772591817466\n",
      "Epoch 275, Loss: 0.4160374917744293\n",
      "Epoch 276, Loss: 0.42157817924529983\n",
      "Epoch 277, Loss: 0.3991758200300099\n",
      "Epoch 278, Loss: 0.4024471779631351\n",
      "Epoch 279, Loss: 0.4158416169220002\n",
      "Epoch 280, Loss: 0.4109940102017761\n",
      "Epoch 281, Loss: 0.40367779348858235\n",
      "Epoch 282, Loss: 0.4169002494142847\n",
      "Epoch 283, Loss: 0.4040475896870828\n",
      "Epoch 284, Loss: 0.4088327762653357\n",
      "Epoch 285, Loss: 0.407029797337259\n",
      "Epoch 286, Loss: 0.402515504342948\n",
      "Epoch 287, Loss: 0.4052148799645245\n",
      "Epoch 288, Loss: 0.4009055757189085\n",
      "Epoch 289, Loss: 0.4053528673397846\n",
      "Epoch 290, Loss: 0.39793991358824765\n",
      "Epoch 291, Loss: 0.4052915270341599\n",
      "Epoch 292, Loss: 0.40244545623289163\n",
      "Epoch 293, Loss: 0.40846720280302085\n",
      "Epoch 294, Loss: 0.3972046796923518\n",
      "Epoch 295, Loss: 0.4062959938422654\n",
      "Epoch 296, Loss: 0.4169741052642322\n",
      "Epoch 297, Loss: 0.41250457616637426\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22216489300659095\n",
      "Test R^2 score: 0.46399961373566073\n",
      "Num of epochs: 298\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Epoch 179, Loss: 0.42867030340024453\n",
      "Epoch 180, Loss: 0.42665902048327814\n",
      "Epoch 181, Loss: 0.4160041986606613\n",
      "Epoch 182, Loss: 0.42380692389414293\n",
      "Epoch 183, Loss: 0.4367609764525626\n",
      "Epoch 184, Loss: 0.42557170506243686\n",
      "Epoch 185, Loss: 0.42106826790053603\n",
      "Epoch 186, Loss: 0.42573876125176086\n",
      "Epoch 187, Loss: 0.41925407360374856\n",
      "Epoch 188, Loss: 0.4183384695092418\n",
      "Epoch 189, Loss: 0.4218813047997579\n",
      "Epoch 190, Loss: 0.4197713005325469\n",
      "Epoch 191, Loss: 0.417197451669247\n",
      "Epoch 192, Loss: 0.41998586832409235\n",
      "Epoch 193, Loss: 0.4198630180807017\n",
      "Epoch 194, Loss: 0.4146118298837611\n",
      "Epoch 195, Loss: 0.41413205840097117\n",
      "Epoch 196, Loss: 0.4155607826414292\n",
      "Epoch 197, Loss: 0.414238532452658\n",
      "Epoch 198, Loss: 0.41297339310852155\n",
      "Epoch 199, Loss: 0.4123900845056213\n",
      "Epoch 200, Loss: 0.4134311180746695\n",
      "Epoch 201, Loss: 0.4127689164145939\n",
      "Epoch 202, Loss: 0.41232720715179455\n",
      "Epoch 203, Loss: 0.41150345937125327\n",
      "Epoch 204, Loss: 0.4115020652257978\n",
      "Epoch 205, Loss: 0.411078297677327\n",
      "Epoch 206, Loss: 0.4110567108542411\n",
      "Epoch 207, Loss: 0.4114023806357039\n",
      "Epoch 208, Loss: 0.41371932293434216\n",
      "Epoch 209, Loss: 0.41813952085771794\n",
      "Epoch 210, Loss: 0.42511728996367454\n",
      "Epoch 211, Loss: 0.42635158522503447\n",
      "Epoch 212, Loss: 0.419673136297028\n",
      "Epoch 213, Loss: 0.41005224089892217\n",
      "Epoch 214, Loss: 0.4205638856971283\n",
      "Epoch 215, Loss: 0.4288454648496258\n",
      "Epoch 216, Loss: 0.416730043439161\n",
      "Epoch 217, Loss: 0.4131035226095487\n",
      "Epoch 218, Loss: 0.41919050177663497\n",
      "Epoch 219, Loss: 0.41341632229404196\n",
      "Epoch 220, Loss: 0.411337015720657\n",
      "Epoch 221, Loss: 0.4153124279254653\n",
      "Epoch 222, Loss: 0.4104582809838288\n",
      "Epoch 223, Loss: 0.4101367219181661\n",
      "Epoch 224, Loss: 0.4157081327260397\n",
      "Epoch 225, Loss: 0.4144226163660391\n",
      "Epoch 226, Loss: 0.4098329995970875\n",
      "Epoch 227, Loss: 0.40775029376666666\n",
      "Epoch 228, Loss: 0.41429755898335924\n",
      "Epoch 229, Loss: 0.41521591906294136\n",
      "Epoch 230, Loss: 0.4099844981670613\n",
      "Epoch 231, Loss: 0.4074908343553954\n",
      "Epoch 232, Loss: 0.41404155462298753\n",
      "Epoch 233, Loss: 0.41428398110821113\n",
      "Epoch 234, Loss: 0.411010796569875\n",
      "Epoch 235, Loss: 0.40626047194262166\n",
      "Epoch 236, Loss: 0.409034666887797\n",
      "Epoch 237, Loss: 0.4158159770891869\n",
      "Epoch 238, Loss: 0.4153325557817546\n",
      "Epoch 239, Loss: 0.40773651613666245\n",
      "Epoch 240, Loss: 0.40720486297242386\n",
      "Epoch 241, Loss: 0.41676379700873606\n",
      "Epoch 242, Loss: 0.4163271136351227\n",
      "Epoch 243, Loss: 0.4079038079306381\n",
      "Epoch 244, Loss: 0.41018584008428094\n",
      "Epoch 245, Loss: 0.4183221731020751\n",
      "Epoch 246, Loss: 0.4083151230189892\n",
      "Epoch 247, Loss: 0.403887555337203\n",
      "Epoch 248, Loss: 0.4087575223213056\n",
      "Epoch 249, Loss: 0.40489636999784445\n",
      "Epoch 250, Loss: 0.4028637127989142\n",
      "Epoch 251, Loss: 0.40329884617463313\n",
      "Epoch 252, Loss: 0.4063995709543235\n",
      "Epoch 253, Loss: 0.4039770141828027\n",
      "Epoch 254, Loss: 0.40232352789271325\n",
      "Epoch 255, Loss: 0.40085487433081396\n",
      "Epoch 256, Loss: 0.4013585184836403\n",
      "Epoch 257, Loss: 0.401038171909843\n",
      "Epoch 258, Loss: 0.4020229653351035\n",
      "Epoch 259, Loss: 0.4038903224025568\n",
      "Epoch 260, Loss: 0.4061704337624061\n",
      "Epoch 261, Loss: 0.40752030716947196\n",
      "Epoch 262, Loss: 0.4085568442371171\n",
      "Epoch 263, Loss: 0.40261644547833497\n",
      "Epoch 264, Loss: 0.39916727140987407\n",
      "Epoch 265, Loss: 0.39918720546249864\n",
      "Epoch 266, Loss: 0.4018616982923893\n",
      "Epoch 267, Loss: 0.40409750330247396\n",
      "Epoch 268, Loss: 0.4030983154573023\n",
      "Epoch 269, Loss: 0.40148977741823705\n",
      "Epoch 270, Loss: 0.3979682402950119\n",
      "Epoch 271, Loss: 0.39712887326045615\n",
      "Epoch 272, Loss: 0.3976166253873399\n",
      "Epoch 273, Loss: 0.3994664761725427\n",
      "Epoch 274, Loss: 0.40664772591817466\n",
      "Epoch 275, Loss: 0.4160374917744293\n",
      "Epoch 276, Loss: 0.42157817924529983\n",
      "Epoch 277, Loss: 0.3991758200300099\n",
      "Epoch 278, Loss: 0.4024471779631351\n",
      "Epoch 279, Loss: 0.4158416169220002\n",
      "Epoch 280, Loss: 0.4109940102017761\n",
      "Epoch 281, Loss: 0.40367779348858235\n",
      "Epoch 282, Loss: 0.4169002494142847\n",
      "Epoch 283, Loss: 0.4040475896870828\n",
      "Epoch 284, Loss: 0.4088327762653357\n",
      "Epoch 285, Loss: 0.407029797337259\n",
      "Epoch 286, Loss: 0.402515504342948\n",
      "Epoch 287, Loss: 0.4052148799645245\n",
      "Epoch 288, Loss: 0.4009055757189085\n",
      "Epoch 289, Loss: 0.4053528673397846\n",
      "Epoch 290, Loss: 0.39793991358824765\n",
      "Epoch 291, Loss: 0.4052915270341599\n",
      "Epoch 292, Loss: 0.40244545623289163\n",
      "Epoch 293, Loss: 0.40846720280302085\n",
      "Epoch 294, Loss: 0.3972046796923518\n",
      "Epoch 295, Loss: 0.4062959938422654\n",
      "Epoch 296, Loss: 0.4169741052642322\n",
      "Epoch 297, Loss: 0.41250457616637426\n",
      "Epoch 298, Loss: 0.39804568379441985\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.2437225805719174\n",
      "Test R^2 score: 0.355377901707327\n",
      "Num of epochs: 299\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Epoch 179, Loss: 0.42867030340024453\n",
      "Epoch 180, Loss: 0.42665902048327814\n",
      "Epoch 181, Loss: 0.4160041986606613\n",
      "Epoch 182, Loss: 0.42380692389414293\n",
      "Epoch 183, Loss: 0.4367609764525626\n",
      "Epoch 184, Loss: 0.42557170506243686\n",
      "Epoch 185, Loss: 0.42106826790053603\n",
      "Epoch 186, Loss: 0.42573876125176086\n",
      "Epoch 187, Loss: 0.41925407360374856\n",
      "Epoch 188, Loss: 0.4183384695092418\n",
      "Epoch 189, Loss: 0.4218813047997579\n",
      "Epoch 190, Loss: 0.4197713005325469\n",
      "Epoch 191, Loss: 0.417197451669247\n",
      "Epoch 192, Loss: 0.41998586832409235\n",
      "Epoch 193, Loss: 0.4198630180807017\n",
      "Epoch 194, Loss: 0.4146118298837611\n",
      "Epoch 195, Loss: 0.41413205840097117\n",
      "Epoch 196, Loss: 0.4155607826414292\n",
      "Epoch 197, Loss: 0.414238532452658\n",
      "Epoch 198, Loss: 0.41297339310852155\n",
      "Epoch 199, Loss: 0.4123900845056213\n",
      "Epoch 200, Loss: 0.4134311180746695\n",
      "Epoch 201, Loss: 0.4127689164145939\n",
      "Epoch 202, Loss: 0.41232720715179455\n",
      "Epoch 203, Loss: 0.41150345937125327\n",
      "Epoch 204, Loss: 0.4115020652257978\n",
      "Epoch 205, Loss: 0.411078297677327\n",
      "Epoch 206, Loss: 0.4110567108542411\n",
      "Epoch 207, Loss: 0.4114023806357039\n",
      "Epoch 208, Loss: 0.41371932293434216\n",
      "Epoch 209, Loss: 0.41813952085771794\n",
      "Epoch 210, Loss: 0.42511728996367454\n",
      "Epoch 211, Loss: 0.42635158522503447\n",
      "Epoch 212, Loss: 0.419673136297028\n",
      "Epoch 213, Loss: 0.41005224089892217\n",
      "Epoch 214, Loss: 0.4205638856971283\n",
      "Epoch 215, Loss: 0.4288454648496258\n",
      "Epoch 216, Loss: 0.416730043439161\n",
      "Epoch 217, Loss: 0.4131035226095487\n",
      "Epoch 218, Loss: 0.41919050177663497\n",
      "Epoch 219, Loss: 0.41341632229404196\n",
      "Epoch 220, Loss: 0.411337015720657\n",
      "Epoch 221, Loss: 0.4153124279254653\n",
      "Epoch 222, Loss: 0.4104582809838288\n",
      "Epoch 223, Loss: 0.4101367219181661\n",
      "Epoch 224, Loss: 0.4157081327260397\n",
      "Epoch 225, Loss: 0.4144226163660391\n",
      "Epoch 226, Loss: 0.4098329995970875\n",
      "Epoch 227, Loss: 0.40775029376666666\n",
      "Epoch 228, Loss: 0.41429755898335924\n",
      "Epoch 229, Loss: 0.41521591906294136\n",
      "Epoch 230, Loss: 0.4099844981670613\n",
      "Epoch 231, Loss: 0.4074908343553954\n",
      "Epoch 232, Loss: 0.41404155462298753\n",
      "Epoch 233, Loss: 0.41428398110821113\n",
      "Epoch 234, Loss: 0.411010796569875\n",
      "Epoch 235, Loss: 0.40626047194262166\n",
      "Epoch 236, Loss: 0.409034666887797\n",
      "Epoch 237, Loss: 0.4158159770891869\n",
      "Epoch 238, Loss: 0.4153325557817546\n",
      "Epoch 239, Loss: 0.40773651613666245\n",
      "Epoch 240, Loss: 0.40720486297242386\n",
      "Epoch 241, Loss: 0.41676379700873606\n",
      "Epoch 242, Loss: 0.4163271136351227\n",
      "Epoch 243, Loss: 0.4079038079306381\n",
      "Epoch 244, Loss: 0.41018584008428094\n",
      "Epoch 245, Loss: 0.4183221731020751\n",
      "Epoch 246, Loss: 0.4083151230189892\n",
      "Epoch 247, Loss: 0.403887555337203\n",
      "Epoch 248, Loss: 0.4087575223213056\n",
      "Epoch 249, Loss: 0.40489636999784445\n",
      "Epoch 250, Loss: 0.4028637127989142\n",
      "Epoch 251, Loss: 0.40329884617463313\n",
      "Epoch 252, Loss: 0.4063995709543235\n",
      "Epoch 253, Loss: 0.4039770141828027\n",
      "Epoch 254, Loss: 0.40232352789271325\n",
      "Epoch 255, Loss: 0.40085487433081396\n",
      "Epoch 256, Loss: 0.4013585184836403\n",
      "Epoch 257, Loss: 0.401038171909843\n",
      "Epoch 258, Loss: 0.4020229653351035\n",
      "Epoch 259, Loss: 0.4038903224025568\n",
      "Epoch 260, Loss: 0.4061704337624061\n",
      "Epoch 261, Loss: 0.40752030716947196\n",
      "Epoch 262, Loss: 0.4085568442371171\n",
      "Epoch 263, Loss: 0.40261644547833497\n",
      "Epoch 264, Loss: 0.39916727140987407\n",
      "Epoch 265, Loss: 0.39918720546249864\n",
      "Epoch 266, Loss: 0.4018616982923893\n",
      "Epoch 267, Loss: 0.40409750330247396\n",
      "Epoch 268, Loss: 0.4030983154573023\n",
      "Epoch 269, Loss: 0.40148977741823705\n",
      "Epoch 270, Loss: 0.3979682402950119\n",
      "Epoch 271, Loss: 0.39712887326045615\n",
      "Epoch 272, Loss: 0.3976166253873399\n",
      "Epoch 273, Loss: 0.3994664761725427\n",
      "Epoch 274, Loss: 0.40664772591817466\n",
      "Epoch 275, Loss: 0.4160374917744293\n",
      "Epoch 276, Loss: 0.42157817924529983\n",
      "Epoch 277, Loss: 0.3991758200300099\n",
      "Epoch 278, Loss: 0.4024471779631351\n",
      "Epoch 279, Loss: 0.4158416169220002\n",
      "Epoch 280, Loss: 0.4109940102017761\n",
      "Epoch 281, Loss: 0.40367779348858235\n",
      "Epoch 282, Loss: 0.4169002494142847\n",
      "Epoch 283, Loss: 0.4040475896870828\n",
      "Epoch 284, Loss: 0.4088327762653357\n",
      "Epoch 285, Loss: 0.407029797337259\n",
      "Epoch 286, Loss: 0.402515504342948\n",
      "Epoch 287, Loss: 0.4052148799645245\n",
      "Epoch 288, Loss: 0.4009055757189085\n",
      "Epoch 289, Loss: 0.4053528673397846\n",
      "Epoch 290, Loss: 0.39793991358824765\n",
      "Epoch 291, Loss: 0.4052915270341599\n",
      "Epoch 292, Loss: 0.40244545623289163\n",
      "Epoch 293, Loss: 0.40846720280302085\n",
      "Epoch 294, Loss: 0.3972046796923518\n",
      "Epoch 295, Loss: 0.4062959938422654\n",
      "Epoch 296, Loss: 0.4169741052642322\n",
      "Epoch 297, Loss: 0.41250457616637426\n",
      "Epoch 298, Loss: 0.39804568379441985\n",
      "Epoch 299, Loss: 0.4152989191112419\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22535576965191656\n",
      "Test R^2 score: 0.4493414120043573\n",
      "Num of epochs: 300\n",
      "Epoch 1, Loss: 0.5661834015323667\n",
      "Epoch 2, Loss: 0.5626369415588923\n",
      "Epoch 3, Loss: 0.5598375837203123\n",
      "Epoch 4, Loss: 0.5578473579777717\n",
      "Epoch 5, Loss: 0.5566148450804481\n",
      "Epoch 6, Loss: 0.5561457257634804\n",
      "Epoch 7, Loss: 0.556426505684494\n",
      "Epoch 8, Loss: 0.5569106400769877\n",
      "Epoch 9, Loss: 0.5570857894755818\n",
      "Epoch 10, Loss: 0.5568954687498959\n",
      "Epoch 11, Loss: 0.5564457066897077\n",
      "Epoch 12, Loss: 0.5558247526622697\n",
      "Epoch 13, Loss: 0.5550629594249218\n",
      "Epoch 14, Loss: 0.5540614826603999\n",
      "Epoch 15, Loss: 0.5524683065947233\n",
      "Epoch 16, Loss: 0.5496887843738881\n",
      "Epoch 17, Loss: 0.5449827700262395\n",
      "Epoch 18, Loss: 0.538172969252933\n",
      "Epoch 19, Loss: 0.529041214462359\n",
      "Epoch 20, Loss: 0.5200428845530104\n",
      "Epoch 21, Loss: 0.5167188601382692\n",
      "Epoch 22, Loss: 0.5179622160670619\n",
      "Epoch 23, Loss: 0.5144919170100595\n",
      "Epoch 24, Loss: 0.5103382971667757\n",
      "Epoch 25, Loss: 0.5027982669710171\n",
      "Epoch 26, Loss: 0.5018779238167959\n",
      "Epoch 27, Loss: 0.501730962490019\n",
      "Epoch 28, Loss: 0.49972647397444503\n",
      "Epoch 29, Loss: 0.4971114106041433\n",
      "Epoch 30, Loss: 0.4926635619690716\n",
      "Epoch 31, Loss: 0.4910082692860073\n",
      "Epoch 32, Loss: 0.4882087195886695\n",
      "Epoch 33, Loss: 0.4882874450290599\n",
      "Epoch 34, Loss: 0.48804503258384396\n",
      "Epoch 35, Loss: 0.48343963447499066\n",
      "Epoch 36, Loss: 0.48260531625076253\n",
      "Epoch 37, Loss: 0.4820813355477277\n",
      "Epoch 38, Loss: 0.4788549815827858\n",
      "Epoch 39, Loss: 0.47996444908255204\n",
      "Epoch 40, Loss: 0.47640546181207893\n",
      "Epoch 41, Loss: 0.4737144321235052\n",
      "Epoch 42, Loss: 0.47446340506120327\n",
      "Epoch 43, Loss: 0.47184232510243496\n",
      "Epoch 44, Loss: 0.468642222411837\n",
      "Epoch 45, Loss: 0.4704592219274423\n",
      "Epoch 46, Loss: 0.4685334977212005\n",
      "Epoch 47, Loss: 0.4664299133023188\n",
      "Epoch 48, Loss: 0.4692312631072299\n",
      "Epoch 49, Loss: 0.46540039456961\n",
      "Epoch 50, Loss: 0.46565197156068694\n",
      "Epoch 51, Loss: 0.46557154700668135\n",
      "Epoch 52, Loss: 0.46206373890654306\n",
      "Epoch 53, Loss: 0.46289489035914727\n",
      "Epoch 54, Loss: 0.46318242979536806\n",
      "Epoch 55, Loss: 0.4605155403536551\n",
      "Epoch 56, Loss: 0.45984807016648593\n",
      "Epoch 57, Loss: 0.460210582588931\n",
      "Epoch 58, Loss: 0.45821213384099013\n",
      "Epoch 59, Loss: 0.4576253371707661\n",
      "Epoch 60, Loss: 0.45770263264919697\n",
      "Epoch 61, Loss: 0.4562924927036441\n",
      "Epoch 62, Loss: 0.4550329685318889\n",
      "Epoch 63, Loss: 0.4549444599890082\n",
      "Epoch 64, Loss: 0.454520608483011\n",
      "Epoch 65, Loss: 0.45321596811000114\n",
      "Epoch 66, Loss: 0.4526538372403444\n",
      "Epoch 67, Loss: 0.4526574254572087\n",
      "Epoch 68, Loss: 0.4518835556571032\n",
      "Epoch 69, Loss: 0.4508633239710644\n",
      "Epoch 70, Loss: 0.449812355920287\n",
      "Epoch 71, Loss: 0.44902377665781934\n",
      "Epoch 72, Loss: 0.4484207196701449\n",
      "Epoch 73, Loss: 0.4481284801395904\n",
      "Epoch 74, Loss: 0.44948213568186085\n",
      "Epoch 75, Loss: 0.455756210251356\n",
      "Epoch 76, Loss: 0.46232546335394215\n",
      "Epoch 77, Loss: 0.4474555865683405\n",
      "Epoch 78, Loss: 0.4538961622788181\n",
      "Epoch 79, Loss: 0.45330649062701506\n",
      "Epoch 80, Loss: 0.4463855797638984\n",
      "Epoch 81, Loss: 0.45683282636648886\n",
      "Epoch 82, Loss: 0.44672831281931946\n",
      "Epoch 83, Loss: 0.4474552202463073\n",
      "Epoch 84, Loss: 0.4491966573838816\n",
      "Epoch 85, Loss: 0.4443511457250974\n",
      "Epoch 86, Loss: 0.4482980165640211\n",
      "Epoch 87, Loss: 0.44234530393057353\n",
      "Epoch 88, Loss: 0.44731363097182864\n",
      "Epoch 89, Loss: 0.4436764696477442\n",
      "Epoch 90, Loss: 0.4418245713299159\n",
      "Epoch 91, Loss: 0.44425770835972517\n",
      "Epoch 92, Loss: 0.44081307110735246\n",
      "Epoch 93, Loss: 0.4422271993764081\n",
      "Epoch 94, Loss: 0.4411081134323679\n",
      "Epoch 95, Loss: 0.4394559224357576\n",
      "Epoch 96, Loss: 0.4411351206746202\n",
      "Epoch 97, Loss: 0.44027399326560485\n",
      "Epoch 98, Loss: 0.43839941216885353\n",
      "Epoch 99, Loss: 0.43945934715104623\n",
      "Epoch 100, Loss: 0.43844740330991555\n",
      "Epoch 101, Loss: 0.43738438577276184\n",
      "Epoch 102, Loss: 0.4383674094905646\n",
      "Epoch 103, Loss: 0.4379090032200363\n",
      "Epoch 104, Loss: 0.43636433477598713\n",
      "Epoch 105, Loss: 0.43639592093957336\n",
      "Epoch 106, Loss: 0.436783595721656\n",
      "Epoch 107, Loss: 0.4358326440584459\n",
      "Epoch 108, Loss: 0.4349197525786685\n",
      "Epoch 109, Loss: 0.4348600985832262\n",
      "Epoch 110, Loss: 0.4351905083311962\n",
      "Epoch 111, Loss: 0.43545305413359836\n",
      "Epoch 112, Loss: 0.4348516346596658\n",
      "Epoch 113, Loss: 0.433585037968721\n",
      "Epoch 114, Loss: 0.43288215462315316\n",
      "Epoch 115, Loss: 0.4332689494970817\n",
      "Epoch 116, Loss: 0.43504602347729976\n",
      "Epoch 117, Loss: 0.4384648718687907\n",
      "Epoch 118, Loss: 0.4398186922134826\n",
      "Epoch 119, Loss: 0.4340704625651017\n",
      "Epoch 120, Loss: 0.43228668953048804\n",
      "Epoch 121, Loss: 0.43856944776176915\n",
      "Epoch 122, Loss: 0.4442397464133483\n",
      "Epoch 123, Loss: 0.43782935347646273\n",
      "Epoch 124, Loss: 0.4330929450081219\n",
      "Epoch 125, Loss: 0.43803260944637473\n",
      "Epoch 126, Loss: 0.4314321471900013\n",
      "Epoch 127, Loss: 0.4323309991553439\n",
      "Epoch 128, Loss: 0.43973774488005224\n",
      "Epoch 129, Loss: 0.43458750830071624\n",
      "Epoch 130, Loss: 0.42980105893549136\n",
      "Epoch 131, Loss: 0.43392969125158026\n",
      "Epoch 132, Loss: 0.43085043198407913\n",
      "Epoch 133, Loss: 0.42872579631385566\n",
      "Epoch 134, Loss: 0.4333196065483096\n",
      "Epoch 135, Loss: 0.4327876183694571\n",
      "Epoch 136, Loss: 0.4284607107050828\n",
      "Epoch 137, Loss: 0.4287007880258581\n",
      "Epoch 138, Loss: 0.42994287011527216\n",
      "Epoch 139, Loss: 0.42726515373222124\n",
      "Epoch 140, Loss: 0.42703321984761805\n",
      "Epoch 141, Loss: 0.4291663564137692\n",
      "Epoch 142, Loss: 0.42967537949546925\n",
      "Epoch 143, Loss: 0.4276635620863527\n",
      "Epoch 144, Loss: 0.42617726938835393\n",
      "Epoch 145, Loss: 0.4270931994841507\n",
      "Epoch 146, Loss: 0.42830553633794316\n",
      "Epoch 147, Loss: 0.4272620149098253\n",
      "Epoch 148, Loss: 0.42507883630968935\n",
      "Epoch 149, Loss: 0.42435747481215347\n",
      "Epoch 150, Loss: 0.42452943149327393\n",
      "Epoch 151, Loss: 0.4250239716108527\n",
      "Epoch 152, Loss: 0.4255246605422791\n",
      "Epoch 153, Loss: 0.4253525631973668\n",
      "Epoch 154, Loss: 0.4248278907489857\n",
      "Epoch 155, Loss: 0.4232181783431597\n",
      "Epoch 156, Loss: 0.4218400128303087\n",
      "Epoch 157, Loss: 0.4221833303261162\n",
      "Epoch 158, Loss: 0.4230044046853522\n",
      "Epoch 159, Loss: 0.4255630213890742\n",
      "Epoch 160, Loss: 0.42928211856711684\n",
      "Epoch 161, Loss: 0.4275640383657732\n",
      "Epoch 162, Loss: 0.4241573268196851\n",
      "Epoch 163, Loss: 0.42103206345473854\n",
      "Epoch 164, Loss: 0.41991543432220046\n",
      "Epoch 165, Loss: 0.4209080493652618\n",
      "Epoch 166, Loss: 0.42254647047347005\n",
      "Epoch 167, Loss: 0.4242666410667844\n",
      "Epoch 168, Loss: 0.4250368733398334\n",
      "Epoch 169, Loss: 0.4253797300290431\n",
      "Epoch 170, Loss: 0.4223570542069413\n",
      "Epoch 171, Loss: 0.41844113118289095\n",
      "Epoch 172, Loss: 0.4184949539431824\n",
      "Epoch 173, Loss: 0.42162842078903584\n",
      "Epoch 174, Loss: 0.4253006593904512\n",
      "Epoch 175, Loss: 0.4235760866687639\n",
      "Epoch 176, Loss: 0.4178764918817333\n",
      "Epoch 177, Loss: 0.4167976729752714\n",
      "Epoch 178, Loss: 0.4210107746365154\n",
      "Epoch 179, Loss: 0.42867030340024453\n",
      "Epoch 180, Loss: 0.42665902048327814\n",
      "Epoch 181, Loss: 0.4160041986606613\n",
      "Epoch 182, Loss: 0.42380692389414293\n",
      "Epoch 183, Loss: 0.4367609764525626\n",
      "Epoch 184, Loss: 0.42557170506243686\n",
      "Epoch 185, Loss: 0.42106826790053603\n",
      "Epoch 186, Loss: 0.42573876125176086\n",
      "Epoch 187, Loss: 0.41925407360374856\n",
      "Epoch 188, Loss: 0.4183384695092418\n",
      "Epoch 189, Loss: 0.4218813047997579\n",
      "Epoch 190, Loss: 0.4197713005325469\n",
      "Epoch 191, Loss: 0.417197451669247\n",
      "Epoch 192, Loss: 0.41998586832409235\n",
      "Epoch 193, Loss: 0.4198630180807017\n",
      "Epoch 194, Loss: 0.4146118298837611\n",
      "Epoch 195, Loss: 0.41413205840097117\n",
      "Epoch 196, Loss: 0.4155607826414292\n",
      "Epoch 197, Loss: 0.414238532452658\n",
      "Epoch 198, Loss: 0.41297339310852155\n",
      "Epoch 199, Loss: 0.4123900845056213\n",
      "Epoch 200, Loss: 0.4134311180746695\n",
      "Epoch 201, Loss: 0.4127689164145939\n",
      "Epoch 202, Loss: 0.41232720715179455\n",
      "Epoch 203, Loss: 0.41150345937125327\n",
      "Epoch 204, Loss: 0.4115020652257978\n",
      "Epoch 205, Loss: 0.411078297677327\n",
      "Epoch 206, Loss: 0.4110567108542411\n",
      "Epoch 207, Loss: 0.4114023806357039\n",
      "Epoch 208, Loss: 0.41371932293434216\n",
      "Epoch 209, Loss: 0.41813952085771794\n",
      "Epoch 210, Loss: 0.42511728996367454\n",
      "Epoch 211, Loss: 0.42635158522503447\n",
      "Epoch 212, Loss: 0.419673136297028\n",
      "Epoch 213, Loss: 0.41005224089892217\n",
      "Epoch 214, Loss: 0.4205638856971283\n",
      "Epoch 215, Loss: 0.4288454648496258\n",
      "Epoch 216, Loss: 0.416730043439161\n",
      "Epoch 217, Loss: 0.4131035226095487\n",
      "Epoch 218, Loss: 0.41919050177663497\n",
      "Epoch 219, Loss: 0.41341632229404196\n",
      "Epoch 220, Loss: 0.411337015720657\n",
      "Epoch 221, Loss: 0.4153124279254653\n",
      "Epoch 222, Loss: 0.4104582809838288\n",
      "Epoch 223, Loss: 0.4101367219181661\n",
      "Epoch 224, Loss: 0.4157081327260397\n",
      "Epoch 225, Loss: 0.4144226163660391\n",
      "Epoch 226, Loss: 0.4098329995970875\n",
      "Epoch 227, Loss: 0.40775029376666666\n",
      "Epoch 228, Loss: 0.41429755898335924\n",
      "Epoch 229, Loss: 0.41521591906294136\n",
      "Epoch 230, Loss: 0.4099844981670613\n",
      "Epoch 231, Loss: 0.4074908343553954\n",
      "Epoch 232, Loss: 0.41404155462298753\n",
      "Epoch 233, Loss: 0.41428398110821113\n",
      "Epoch 234, Loss: 0.411010796569875\n",
      "Epoch 235, Loss: 0.40626047194262166\n",
      "Epoch 236, Loss: 0.409034666887797\n",
      "Epoch 237, Loss: 0.4158159770891869\n",
      "Epoch 238, Loss: 0.4153325557817546\n",
      "Epoch 239, Loss: 0.40773651613666245\n",
      "Epoch 240, Loss: 0.40720486297242386\n",
      "Epoch 241, Loss: 0.41676379700873606\n",
      "Epoch 242, Loss: 0.4163271136351227\n",
      "Epoch 243, Loss: 0.4079038079306381\n",
      "Epoch 244, Loss: 0.41018584008428094\n",
      "Epoch 245, Loss: 0.4183221731020751\n",
      "Epoch 246, Loss: 0.4083151230189892\n",
      "Epoch 247, Loss: 0.403887555337203\n",
      "Epoch 248, Loss: 0.4087575223213056\n",
      "Epoch 249, Loss: 0.40489636999784445\n",
      "Epoch 250, Loss: 0.4028637127989142\n",
      "Epoch 251, Loss: 0.40329884617463313\n",
      "Epoch 252, Loss: 0.4063995709543235\n",
      "Epoch 253, Loss: 0.4039770141828027\n",
      "Epoch 254, Loss: 0.40232352789271325\n",
      "Epoch 255, Loss: 0.40085487433081396\n",
      "Epoch 256, Loss: 0.4013585184836403\n",
      "Epoch 257, Loss: 0.401038171909843\n",
      "Epoch 258, Loss: 0.4020229653351035\n",
      "Epoch 259, Loss: 0.4038903224025568\n",
      "Epoch 260, Loss: 0.4061704337624061\n",
      "Epoch 261, Loss: 0.40752030716947196\n",
      "Epoch 262, Loss: 0.4085568442371171\n",
      "Epoch 263, Loss: 0.40261644547833497\n",
      "Epoch 264, Loss: 0.39916727140987407\n",
      "Epoch 265, Loss: 0.39918720546249864\n",
      "Epoch 266, Loss: 0.4018616982923893\n",
      "Epoch 267, Loss: 0.40409750330247396\n",
      "Epoch 268, Loss: 0.4030983154573023\n",
      "Epoch 269, Loss: 0.40148977741823705\n",
      "Epoch 270, Loss: 0.3979682402950119\n",
      "Epoch 271, Loss: 0.39712887326045615\n",
      "Epoch 272, Loss: 0.3976166253873399\n",
      "Epoch 273, Loss: 0.3994664761725427\n",
      "Epoch 274, Loss: 0.40664772591817466\n",
      "Epoch 275, Loss: 0.4160374917744293\n",
      "Epoch 276, Loss: 0.42157817924529983\n",
      "Epoch 277, Loss: 0.3991758200300099\n",
      "Epoch 278, Loss: 0.4024471779631351\n",
      "Epoch 279, Loss: 0.4158416169220002\n",
      "Epoch 280, Loss: 0.4109940102017761\n",
      "Epoch 281, Loss: 0.40367779348858235\n",
      "Epoch 282, Loss: 0.4169002494142847\n",
      "Epoch 283, Loss: 0.4040475896870828\n",
      "Epoch 284, Loss: 0.4088327762653357\n",
      "Epoch 285, Loss: 0.407029797337259\n",
      "Epoch 286, Loss: 0.402515504342948\n",
      "Epoch 287, Loss: 0.4052148799645245\n",
      "Epoch 288, Loss: 0.4009055757189085\n",
      "Epoch 289, Loss: 0.4053528673397846\n",
      "Epoch 290, Loss: 0.39793991358824765\n",
      "Epoch 291, Loss: 0.4052915270341599\n",
      "Epoch 292, Loss: 0.40244545623289163\n",
      "Epoch 293, Loss: 0.40846720280302085\n",
      "Epoch 294, Loss: 0.3972046796923518\n",
      "Epoch 295, Loss: 0.4062959938422654\n",
      "Epoch 296, Loss: 0.4169741052642322\n",
      "Epoch 297, Loss: 0.41250457616637426\n",
      "Epoch 298, Loss: 0.39804568379441985\n",
      "Epoch 299, Loss: 0.4152989191112419\n",
      "Epoch 300, Loss: 0.4078402937264094\n",
      "Training completed.\n",
      "Training completed.\n",
      "Testing model...\n",
      "Test RMSE: 0.22303004700704018\n",
      "Test R^2 score: 0.4599510178547535\n",
      "Completed.\n"
     ]
    }
   ],
   "source": [
    "for num_epochs in num_epochs_list:\n",
    "  # Set the seed\n",
    "  torch.manual_seed(seed)\n",
    "\n",
    "  print(f'Num of epochs: {num_epochs}')\n",
    "  \n",
    "  model = train_model(num_epochs)\n",
    "\n",
    "  print(\"Training completed.\")\n",
    "  print(\"Testing model...\")\n",
    "\n",
    "  test_pred, rmse, r2_score = test_model(model)\n",
    "  r2_scores_list.append(r2_score)\n",
    "  rmse_list.append(rmse)\n",
    "\n",
    "print(\"Completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the graph to visualise the relationship between epochs and r^2 score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.08130789191335341,\n",
       " -0.053207219358976876,\n",
       " -0.031331766796814264,\n",
       " -0.015236610982118481,\n",
       " -0.00444679250162916,\n",
       " 0.00018785050973924022,\n",
       " 0.000948174097381127,\n",
       " 0.0011356302631368997,\n",
       " 0.0023032763847067317,\n",
       " 0.004427031657866343,\n",
       " 0.0073639977343665786,\n",
       " 0.011077887625765004,\n",
       " 0.016592852133862634,\n",
       " 0.027130840133325007,\n",
       " 0.047955824661566115,\n",
       " 0.08474059205313716,\n",
       " 0.13676852576280407,\n",
       " 0.1990980567803159,\n",
       " 0.2609027919615022,\n",
       " 0.2722639019415289,\n",
       " 0.25464274609303456,\n",
       " 0.2763147234406286,\n",
       " 0.28620327135508106,\n",
       " 0.339758459892728,\n",
       " 0.35266620150637,\n",
       " 0.33341686591484654,\n",
       " 0.34499248048582837,\n",
       " 0.3738030940355503,\n",
       " 0.38672828782295,\n",
       " 0.3759666488540271,\n",
       " 0.3904894812551848,\n",
       " 0.38771327813080425,\n",
       " 0.36587906118287705,\n",
       " 0.40021558430218834,\n",
       " 0.41572831663141363,\n",
       " 0.3962113919532084,\n",
       " 0.42269671264603004,\n",
       " 0.4384114414328082,\n",
       " 0.4172805607293688,\n",
       " 0.4228420713801373,\n",
       " 0.44096051096622085,\n",
       " 0.40425046479860566,\n",
       " 0.42099331093842857,\n",
       " 0.4494475292540413,\n",
       " 0.4180059898035685,\n",
       " 0.4472844624465423,\n",
       " 0.4758654746131652,\n",
       " 0.4531156921942268,\n",
       " 0.4395045385321926,\n",
       " 0.4770319017835061,\n",
       " 0.4573368695632056,\n",
       " 0.437410134930681,\n",
       " 0.4702620943457101,\n",
       " 0.45035826663097867,\n",
       " 0.45429632405221704,\n",
       " 0.4818615409307476,\n",
       " 0.46659656284677986,\n",
       " 0.46499177938007347,\n",
       " 0.4842465762601702,\n",
       " 0.46095978301937834,\n",
       " 0.47124184312787765,\n",
       " 0.48476687806126784,\n",
       " 0.4655319144507931,\n",
       " 0.4849276327804087,\n",
       " 0.4871931865717825,\n",
       " 0.4647064960115019,\n",
       " 0.4900891219135701,\n",
       " 0.4721915217807401,\n",
       " 0.49077299099520827,\n",
       " 0.4886100937242728,\n",
       " 0.4837093506529376,\n",
       " 0.4941292697603028,\n",
       " 0.45505606189678854,\n",
       " 0.48732331626475,\n",
       " 0.37709320932371115,\n",
       " 0.5006663263559245,\n",
       " 0.49547205665656185,\n",
       " 0.43053451014246547,\n",
       " 0.46968008788696974,\n",
       " 0.48117644377385377,\n",
       " 0.4566074323881224,\n",
       " 0.4531473752264795,\n",
       " 0.5029223597330532,\n",
       " 0.5045198204517183,\n",
       " 0.4475364086156613,\n",
       " 0.4912902798330205,\n",
       " 0.4964158001275788,\n",
       " 0.4582558901976437,\n",
       " 0.4750332385009889,\n",
       " 0.5037809244918738,\n",
       " 0.4914134699196723,\n",
       " 0.4697872957218661,\n",
       " 0.5029095562890409,\n",
       " 0.494369441231148,\n",
       " 0.4626077327391633,\n",
       " 0.5038483572633133,\n",
       " 0.4984783601785043,\n",
       " 0.47992816649266096,\n",
       " 0.5045320768058841,\n",
       " 0.49780556485877137,\n",
       " 0.47251234454532487,\n",
       " 0.5027237469190777,\n",
       " 0.49318937714340016,\n",
       " 0.4899179009298466,\n",
       " 0.5074645887824376,\n",
       " 0.4852144264196342,\n",
       " 0.496956800774172,\n",
       " 0.5004364782138162,\n",
       " 0.47989573392040835,\n",
       " 0.509151186007655,\n",
       " 0.48249843084998695,\n",
       " 0.5061175757556869,\n",
       " 0.498834325260232,\n",
       " 0.48243544910287767,\n",
       " 0.5094647019439327,\n",
       " 0.4467974982761484,\n",
       " 0.5087247360890033,\n",
       " 0.4841539191475638,\n",
       " 0.48598159082308484,\n",
       " 0.5007394638428897,\n",
       " 0.4031909975696018,\n",
       " 0.5112362747018646,\n",
       " 0.5136611688343748,\n",
       " 0.46194243900596105,\n",
       " 0.5133884787255856,\n",
       " 0.5025123465664478,\n",
       " 0.4209934505579185,\n",
       " 0.5058279956341178,\n",
       " 0.5075030594512195,\n",
       " 0.47510054567907856,\n",
       " 0.5150335166687102,\n",
       " 0.505521978208959,\n",
       " 0.4486881359438095,\n",
       " 0.4998124001357702,\n",
       " 0.4868865477730445,\n",
       " 0.49492101682177053,\n",
       " 0.5152923686522382,\n",
       " 0.4890512931143805,\n",
       " 0.4844837722453457,\n",
       " 0.5009428699927062,\n",
       " 0.46297215825404925,\n",
       " 0.5143851311808719,\n",
       " 0.5084913741733825,\n",
       " 0.47671298235113957,\n",
       " 0.5023436301975743,\n",
       " 0.4665969213034791,\n",
       " 0.5083096481156524,\n",
       " 0.5040628636502787,\n",
       " 0.48886627799691246,\n",
       " 0.5045087344856616,\n",
       " 0.4687334530925304,\n",
       " 0.5068958302316007,\n",
       " 0.4777617724969699,\n",
       " 0.5089377852170449,\n",
       " 0.49541697086552405,\n",
       " 0.4841640145407395,\n",
       " 0.5036917708193185,\n",
       " 0.46074043786063146,\n",
       " 0.504843161813556,\n",
       " 0.4477920839385261,\n",
       " 0.5073137768569589,\n",
       " 0.4867306049935086,\n",
       " 0.4971796659549319,\n",
       " 0.5076547597422503,\n",
       " 0.46474192439164913,\n",
       " 0.5026560161648398,\n",
       " 0.44520491343316165,\n",
       " 0.5046386000179881,\n",
       " 0.465948251073539,\n",
       " 0.5051762609504655,\n",
       " 0.5020248295732203,\n",
       " 0.46032479291644746,\n",
       " 0.501432240798326,\n",
       " 0.4524646467845581,\n",
       " 0.504210517467121,\n",
       " 0.4935171353791382,\n",
       " 0.4505240610435144,\n",
       " 0.4935499850089136,\n",
       " 0.438928847267185,\n",
       " 0.5020999688885095,\n",
       " 0.49189840119854933,\n",
       " 0.37525267903062326,\n",
       " 0.5011815167595887,\n",
       " 0.5077018425115615,\n",
       " 0.44263001207714553,\n",
       " 0.49265862944198685,\n",
       " 0.4901453320982067,\n",
       " 0.4515978203693445,\n",
       " 0.5049417508682542,\n",
       " 0.5012701181707842,\n",
       " 0.4460856011487701,\n",
       " 0.4815055336659881,\n",
       " 0.46832951589455685,\n",
       " 0.4833602948024797,\n",
       " 0.49832067810758257,\n",
       " 0.4685175066420575,\n",
       " 0.4844404662486379,\n",
       " 0.4918075128302132,\n",
       " 0.4740701721794912,\n",
       " 0.49100051883251505,\n",
       " 0.46206589885106575,\n",
       " 0.48256372067813796,\n",
       " 0.47332375975070123,\n",
       " 0.4905775555677588,\n",
       " 0.46723067418706143,\n",
       " 0.4863684112179101,\n",
       " 0.4522353864320205,\n",
       " 0.4796275725125862,\n",
       " 0.39185741266230767,\n",
       " 0.46870809998560586,\n",
       " 0.4419159307386303,\n",
       " 0.48963498398547417,\n",
       " 0.47410399856288726,\n",
       " 0.3744616205422112,\n",
       " 0.4871465678381168,\n",
       " 0.4983434236781004,\n",
       " 0.43134831332041873,\n",
       " 0.4892117709385873,\n",
       " 0.499681202527148,\n",
       " 0.4658803634551907,\n",
       " 0.4998898436139997,\n",
       " 0.48851793026347434,\n",
       " 0.4199261144227355,\n",
       " 0.4730602899040089,\n",
       " 0.46295439135471617,\n",
       " 0.46472639419772543,\n",
       " 0.4729530204855426,\n",
       " 0.4249368674029983,\n",
       " 0.49001953136480253,\n",
       " 0.4869250989803459,\n",
       " 0.41727297843915406,\n",
       " 0.4626588300528194,\n",
       " 0.447488119319251,\n",
       " 0.47665578916954343,\n",
       " 0.47122057823909536,\n",
       " 0.40548343233314993,\n",
       " 0.4768931662846588,\n",
       " 0.47270805980715297,\n",
       " 0.45838467466653815,\n",
       " 0.45790379405448545,\n",
       " 0.41145413195029057,\n",
       " 0.4816740806770047,\n",
       " 0.47682857575740967,\n",
       " 0.3872089592033495,\n",
       " 0.4712571068225531,\n",
       " 0.4818798232163291,\n",
       " 0.4499688726754261,\n",
       " 0.4778651978334868,\n",
       " 0.4618290613791163,\n",
       " 0.45143564167802136,\n",
       " 0.46965751662581384,\n",
       " 0.44183295941053835,\n",
       " 0.4650043030519161,\n",
       " 0.46837423700190034,\n",
       " 0.46466102562033845,\n",
       " 0.46736084501984193,\n",
       " 0.4412439513946553,\n",
       " 0.46383577046100083,\n",
       " 0.4191114752220597,\n",
       " 0.45856107409616365,\n",
       " 0.41354104771933,\n",
       " 0.4652408971834027,\n",
       " 0.45296288474501795,\n",
       " 0.4517926558914432,\n",
       " 0.4647422631745651,\n",
       " 0.42388779418235173,\n",
       " 0.4645944395209121,\n",
       " 0.4394986772771787,\n",
       " 0.4628739604239991,\n",
       " 0.4518083236961049,\n",
       " 0.4428309431190055,\n",
       " 0.45603613761330497,\n",
       " 0.3950425662880534,\n",
       " 0.44111517125013283,\n",
       " 0.36272481542743595,\n",
       " 0.46400649537995464,\n",
       " 0.450313194743103,\n",
       " 0.37146964611327543,\n",
       " 0.45117510537908373,\n",
       " 0.45201156265290465,\n",
       " 0.36996768756012766,\n",
       " 0.4880895391379951,\n",
       " 0.487410861793256,\n",
       " 0.457603279014072,\n",
       " 0.4525744015471474,\n",
       " 0.43063661454352764,\n",
       " 0.43019852893634536,\n",
       " 0.4570455410368749,\n",
       " 0.4544415358292111,\n",
       " 0.40730850524867757,\n",
       " 0.46454069852129953,\n",
       " 0.4270877088473788,\n",
       " 0.45732685813867086,\n",
       " 0.4257011779897301,\n",
       " 0.3402150026866383,\n",
       " 0.44550712381721946,\n",
       " 0.46399961373566073,\n",
       " 0.355377901707327,\n",
       " 0.4493414120043573,\n",
       " 0.4599510178547535]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_scores_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the line graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(num_epochs_list, r2_scores_list, color='b', linestyle='-')\n",
    "plt.title('num_epochs vs. R^2 score')\n",
    "plt.xlabel('num_epochs')\n",
    "plt.ylabel('r^2 score') \n",
    "plt.grid(True)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max R^2 score: 0.5152923686522382\n",
      "Corresponding RMSE: 0.21112116739526332\n",
      "Corresponding num_epochs: 137\n"
     ]
    }
   ],
   "source": [
    "max_r2_score = max(r2_scores_list)\n",
    "corresponding_rmse = rmse_list[r2_scores_list.index(max_r2_score)]\n",
    "corresponding_num_epochs = num_epochs_list[r2_scores_list.index(max_r2_score)]\n",
    "\n",
    "print(f'Max R^2 score: {max_r2_score}')\n",
    "print(f'Corresponding RMSE: {corresponding_rmse}')\n",
    "print(f'Corresponding num_epochs: {corresponding_num_epochs}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
